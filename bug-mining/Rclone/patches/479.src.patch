diff --git a/backend/s3/s3.go b/backend/s3/s3.go
index 5fcdb6b90..db8294ba6 100644
--- a/backend/s3/s3.go
+++ b/backend/s3/s3.go
@@ -539,6 +539,11 @@ func init() {
 			Help:     "Concurrency for multipart uploads.",
 			Default:  2,
 			Advanced: true,
+		}, {
+			Name:     "force_path_style",
+			Help:     "If true use path style access if false use virtual hosted style.\nSome providers (eg Aliyun OSS or Netease COS) require this.",
+			Default:  true,
+			Advanced: true,
 		}},
 	})
 }
@@ -569,6 +574,7 @@ type Options struct {
 	DisableChecksum      bool          `config:"disable_checksum"`
 	SessionToken         string        `config:"session_token"`
 	UploadConcurrency    int           `config:"upload_concurrency"`
+	ForcePathStyle       bool          `config:"force_path_style"`
 }
 
 // Fs represents a remote s3 server
@@ -707,7 +713,7 @@ func s3Connection(opt *Options) (*s3.S3, *session.Session, error) {
 		WithCredentials(cred).
 		WithEndpoint(opt.Endpoint).
 		WithHTTPClient(fshttp.NewClient(fs.Config)).
-		WithS3ForcePathStyle(true)
+		WithS3ForcePathStyle(opt.ForcePathStyle)
 	// awsConfig.WithLogLevel(aws.LogDebugWithSigning)
 	ses := session.New()
 	c := s3.New(ses, awsConfig)
diff --git a/docs/content/s3.md b/docs/content/s3.md
index d71939aa3..83e3bebe0 100644
--- a/docs/content/s3.md
+++ b/docs/content/s3.md
@@ -402,6 +402,16 @@ Note that 2 chunks of this size are buffered in memory per transfer.
 If you are transferring large files over high speed links and you have
 enough memory, then increasing this will speed up the transfers.
 
+#### --s3-force-path-style=BOOL ####
+
+If this is true (the default) then rclone will use path style access,
+if false then rclone will use virtual path style. See [the AWS S3
+docs](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#access-bucket-intro)
+for more info.
+
+Some providers (eg Aliyun OSS or Netease COS) require this set to
+`false`.  It can also be set in the config in the advanced section.
+
 #### --s3-upload-concurrency ####
 
 Number of chunks of the same file that are uploaded concurrently.
