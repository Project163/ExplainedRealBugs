<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Sat Nov 08 20:53:30 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[PDFBOX-847] FlateFilter.java swallows Exceptions (should rethrow)</title>
                <link>https://issues.apache.org/jira/browse/PDFBOX-847</link>
                <project id="12310760" key="PDFBOX">PDFBox</project>
                    <description>&lt;p&gt;I just re-discovered an issue in FlateFilter.java, which i mentioned quite a while ago on the mailinglist; and which was agreed to be an misfeature &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;In FlateFilter.java, at lines 115ff, we find this piece of code:&lt;/p&gt;

&lt;p&gt;                    try &lt;br/&gt;
                    {&lt;br/&gt;
                        // decoding not needed&lt;br/&gt;
                        while ((amountRead = decompressor.read(buffer, 0, Math.min(mayRead,BUFFER_SIZE))) != -1)&lt;/p&gt;
                        {
                            result.write(buffer, 0, amountRead);
                        }
&lt;p&gt;                    }&lt;br/&gt;
                    catch (OutOfMemoryError exception) &lt;/p&gt;
                    {
                        // if the stream is corrupt an OutOfMemoryError may occur
                        log.error(&quot;Stop reading corrupt stream&quot;);
                    }&lt;br/&gt;
                    catch (ZipException exception) &lt;br/&gt;
                    {                        // if the stream is corrupt an OutOfMemoryError may occur                        log.error(&quot;Stop reading corrupt stream&quot;);                    }
&lt;p&gt;                    catch (EOFException exception) &lt;/p&gt;
                    {
                        // if the stream is corrupt an OutOfMemoryError may occur
                        log.error(&quot;Stop reading corrupt stream&quot;);
                    }

&lt;p&gt;which means these Exceptions are discarded and not reported upstream to the caller. This is very infortunate, as the caller has no means to discover that text extraction is incomplete. I discovered this on troubleshooting Alfresco DMS, which uses PDFBox for indexing PDF documents - except an innocent log message, Alfresco does not know that conversion has failed.&lt;/p&gt;

&lt;p&gt;Proposed solution is to re-throw all 3 Exceptions and let the caller handle the exceptions &lt;/p&gt;</description>
                <environment></environment>
        <key id="12475589">PDFBOX-847</key>
            <summary>FlateFilter.java swallows Exceptions (should rethrow)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lehmi">Andreas Lehmk&#252;hler</assignee>
                                    <reporter username="gyro.gearless">Andreas Wollschlaeger</reporter>
                        <labels>
                    </labels>
                <created>Fri, 1 Oct 2010 09:29:33 +0000</created>
                <updated>Tue, 29 May 2012 16:21:57 +0000</updated>
                            <resolved>Fri, 6 Jan 2012 07:14:20 +0000</resolved>
                                    <version>1.2.1</version>
                                    <fixVersion>1.7.0</fixVersion>
                                    <component>Text extraction</component>
                        <due></due>
                            <votes>6</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="12916934" author="adamnichols" created="Fri, 1 Oct 2010 16:13:06 +0000"  >&lt;p&gt;There doesn&apos;t seem to be much point in catching them just to log a message and re-throw them.  Why not just remove the surrounding try/catch and let the exceptions be thrown?  Keeping the log messages doesn&apos;t seem to be all that important and the caller should define some catch block which does something more meaningful than just a log message.&lt;/p&gt;</comment>
                            <comment id="12929217" author="slowlearner" created="Sat, 6 Nov 2010 21:33:47 +0000"  >&lt;p&gt;It&apos;s further complicated by the fact that though 3 exception types are caught, only a single msg text is logged. It&apos;s useless for investigating a possible underlying cause.&lt;/p&gt;</comment>
                            <comment id="13181129" author="stevelan" created="Fri, 6 Jan 2012 05:37:42 +0000"  >&lt;p&gt;What makes this particularly nasty is one of the clients of this method, PDFTextStripper.processPages calls it once per page, so out of memory errors can be continually rethrown and supressed for a single large PDF document, completely crippling a JVM.&lt;/p&gt;</comment>
                            <comment id="13181177" author="lehmi" created="Fri, 6 Jan 2012 07:14:20 +0000"  >&lt;p&gt;The exceptions will be re-thrown as proposed. I also added a more precise error message. I added the changes in revision 1227993.&lt;/p&gt;

&lt;p&gt;Thanks for the contribution and the heads up!&lt;/p&gt;</comment>
                            <comment id="13192086" author="laubrino" created="Tue, 24 Jan 2012 12:35:26 +0000"  >&lt;p&gt;Hi. &lt;br/&gt;
Thanks for fixing this. &lt;br/&gt;
I have additional comment to this issue. IMHO you should never try to catch OutOfMemoryError, especialy in a library. OutOfMemoryError is an error, not an exception. &lt;/p&gt;

&lt;p&gt;OutOfMemoryError is a subclass of Error  class. And javadoc states that:&lt;/p&gt;

&lt;p&gt;An Error is a subclass of Throwable that indicates serious problems that a reasonable application should not try to catch. Most such errors are abnormal conditions. &lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;http://docs.oracle.com/javase/6/docs/api/java/lang/Error.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://docs.oracle.com/javase/6/docs/api/java/lang/Error.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13192102" author="laubrino" created="Tue, 24 Jan 2012 12:53:42 +0000"  >&lt;p&gt;Proper fix should be not to catch the OutOfMemoryError at all. If you encounter this state, you cannot be even able to write something to a log. In a multithreaded application you cannot guarantee anything. &lt;/p&gt;

&lt;p&gt;So please do not catch OutOfMemoryError at all.&lt;/p&gt;</comment>
                            <comment id="13192122" author="tboehme" created="Tue, 24 Jan 2012 13:01:08 +0000"  >&lt;p&gt;I second the previous comment about OutOfMemoryError. Since the error is re-thrown there is no added value in first catching it (hiding the error would be bad as well). Also from an API point of view catching the error is of no use since it is not declared as as possible &apos;exception&apos; - and there is no need to since at every point an OutOfMemoryError may occur. If an application decides to catch OOM or the JVM is setup to print OOM stack trace the source of the OOM to be in FlateFilter can still be deduced (however only in single thread applications; in multi thread applications the OOM might be triggered by another thread - another point against catching it).&lt;/p&gt;</comment>
                            <comment id="13192126" author="tboehme" created="Tue, 24 Jan 2012 13:14:51 +0000"  >&lt;p&gt;removed catching the OOM in r1235240&lt;/p&gt;</comment>
                            <comment id="13192178" author="adamnichols" created="Tue, 24 Jan 2012 14:28:57 +0000"  >&lt;p&gt;Should we be catching ZipException and EOFException here without letting the caller know that it was unable to decompress the stream?&lt;/p&gt;

&lt;p&gt;As for the proposed solution of catching them and then re-throwing them, why not just not catch them in the first place?  The caller will be able to log them if they see fit, and they&apos;ll have the stacktrace to get to the exact line which caused the issue (e.g. was it a problem reading or a problem writing?).  If the exception is re-thrown, the stacktrace will point to the catch block, which is less helpful.&lt;/p&gt;</comment>
                            <comment id="13194510" author="mahesh.yadav" created="Fri, 27 Jan 2012 06:19:34 +0000"  >&lt;p&gt;Will this not open &lt;a href=&quot;https://issues.apache.org/jira/browse/PDFBOX-453&quot; title=&quot;FlateFilter decode() throwing OutOfMemoryError&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PDFBOX-453&quot;&gt;&lt;del&gt;PDFBOX-453&lt;/del&gt;&lt;/a&gt; bug?.&lt;/p&gt;

&lt;p&gt;I am having this issue of getting log messages &quot;FlateFilter: stop reading corrupt stream&quot; and it crashes my application.&lt;/p&gt;

&lt;p&gt;Users are uploading scanned documents saved as pdf ranging from 20-80 MB. Is there no mechanism by which we determine that incoming stream is corrupted?.&lt;/p&gt;

&lt;p&gt;Or else in my case at least will it be possible to find that pdf page/(whole pdf) contains scanned image so that I can skip text extraction of that page. Does that help?.&lt;/p&gt;


&lt;p&gt;Any help would be appreciated.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Mahesh&lt;/p&gt;</comment>
                            <comment id="13194552" author="tboehme" created="Fri, 27 Jan 2012 08:51:09 +0000"  >&lt;p&gt;Regarding determining corrupt stream:&lt;br/&gt;
in case of FlateFilter PDFBox relies on the ZIP implementation of Java. If it is broken there is not much we can do about it (beside notifying Oracle). Alternate Java ZIP implementations are slower (may perform better in multi-thread environments).&lt;/p&gt;

&lt;p&gt;Regarding OutOfMemoryExceptions:&lt;br/&gt;
the reasons for not catching them are explained in the above comments. If the OOM is simply because of a large image in most cases it should be enough to do PDDocument.load with RandomAccessFile instead of RandomAccessBuffer.&lt;br/&gt;
However there are two places where a filter (e.g. FlateFilter) will write to memory in every case:&lt;br/&gt;
PDStream.getPartiallyFilteredStream and PDInlinedImage.createImage&lt;br/&gt;
in both cases the filter writes the result into an ByteArrayOutputStream. Here a configurable maximum size which might be enforced by a wrapper class of ByteArrayOutputStream could help to prevent OOM. However this was not the reason for &lt;a href=&quot;https://issues.apache.org/jira/browse/PDFBOX-453&quot; title=&quot;FlateFilter decode() throwing OutOfMemoryError&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PDFBOX-453&quot;&gt;&lt;del&gt;PDFBOX-453&lt;/del&gt;&lt;/a&gt;. Thus first we would need a test case showing that this is a real problem.&lt;/p&gt;

&lt;p&gt;Further more having an OOM while decompressing a stream does not necessarily mean that the stream is corrupt. It could also be that you have a memory leak or an memory intensive parallel task and only by accident no bytes were left while reading the stream.&lt;/p&gt;

&lt;p&gt;Regarding skipping pages:&lt;br/&gt;
with the current parser the PDF is processed sequentially. Thus streams will be read (but not decoded) in every case. If you configure PDFBox to not handle images there should be no problem with broken streams (at least if the stream is correctly closed by &apos;endstream&apos;). Again: use RandomAccessFile instead of RandomAccessBuffer if you have memory problems.&lt;br/&gt;
With the work on a new parser (&lt;a href=&quot;https://issues.apache.org/jira/browse/PDFBOX-1000&quot; title=&quot;Conforming parser&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PDFBOX-1000&quot;&gt;&lt;del&gt;PDFBOX-1000&lt;/del&gt;&lt;/a&gt;) it will be possible to only touch needed objects and thus image streams can be ignored completely.&lt;/p&gt;

&lt;p&gt;Regarding detection of picture PDF (text as scannend image):&lt;br/&gt;
you could have an image handler which only stores/provides image dimensions and deduce from a whole page image that it could be scanned text. However e.g. with journals you might have large background images so that is not a real indicator. You need also to count characters on page to decide if page contains only scanned text. In my tests even picture PDF documents contained text up to 60-80 characters because heading/footer was printed as normal text. Thus this is quite a tricky task.&lt;/p&gt;</comment>
                            <comment id="13194577" author="mahesh.yadav" created="Fri, 27 Jan 2012 09:33:40 +0000"  >&lt;p&gt;Thanks Timo, appreciate your quick response&lt;/p&gt;

&lt;p&gt;We have heavy DMS usage and we are using jackrabbit as repository. Our server got crashed when some users uploaded pdf around 50-80 MB scanned pdf document (this time there was no FlateFilter message).  I am looking forward to your  to your suggestion (RandomAccessFile instead of RandomAccessBuffer).&lt;/p&gt;

&lt;p&gt;We use jackrabbit and only difference that we have is we have our own custom parser (not provided by jackrabbit) for parsing pdf and we interact with pdfbox as shown below.&lt;/p&gt;

&lt;p&gt;PDFParser parser = new PDFParser(new BufferedInputStream(stream));&lt;br/&gt;
PDDocument document = parser.getPDDocument(); &lt;br/&gt;
parser.parse();&lt;br/&gt;
PDFTextStripper stripper = new PDFTextStripper();&lt;br/&gt;
stripper.setLineSeparator(&quot;\n&quot;);&lt;br/&gt;
stripper.writeText(document, writer)&lt;/p&gt;

&lt;p&gt;I think we need to change above approach and use &quot; PDDocument.load&quot; with RandomAccessFile &lt;/p&gt;

&lt;p&gt;Thanks  &lt;br/&gt;
Mahesh&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>85053</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            13 years, 43 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0zizb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>205377</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>