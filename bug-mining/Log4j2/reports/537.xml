<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 19:34:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[LOG4J2-1076] Flume appender fails to perform</title>
                <link>https://issues.apache.org/jira/browse/LOG4J2-1076</link>
                <project id="12310790" key="LOG4J2">Log4j 2</project>
                    <description>&lt;p&gt;Recently I was testing log4j2-flume appender performance and thought to share the results as I believe they reflect some bugs/flaws in the current implementation. I conducted a series of in which I used the same 2.2 GB base file. I wrote a small java application that read he file line by line and log each line log4j2 with flume appender that sends it to another flume instance on a remote machine. I measured the time it took and traffic between the end points as I was mainly curious in the avro compression abilities.&lt;/p&gt;

&lt;p&gt;First, Log4j2 Flumes&apos; appender support only GZIP compression (and only for the body) so first I was curious if this feature actually compatible with the flume&apos;s defalte compression method for avro. I found out that it didn&apos;t, and in order to make it work I would have to write my own gzipDecoder on the other side.&lt;/p&gt;

&lt;p&gt;Type Avro:&lt;br/&gt;
1. The process of sending the logs was VERY VERY long (over 2 hours), and crushed several times.&lt;br/&gt;
2. The more surprising part was that the traffic measured on the link was over 2G (when I used GZIP compression), and even closer to 3G (without compression). I am not even sure why there was such an overhead, but that&#8217;s what I saw several times.&lt;br/&gt;
3. The event were send one by one even when I defined a batch mode of 1000. After reading the code a little bit, I found out that batch mode is currently not supported and will might be possible on the next release -  &lt;a href=&quot;https://issues.apache.org/jira/browse/LOG4J2-1044?jql=project%20%3D%20LOG4J2%20AND%20priority%20%3D%20Major%20AND%20resolution%20%3D%20Unresolved%20AND%20text%20~%20%22flume%22%20ORDER%20BY%20key%20DESC&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/LOG4J2-1044?jql=project%20%3D%20LOG4J2%20AND%20priority%20%3D%20Major%20AND%20resolution%20%3D%20Unresolved%20AND%20text%20~%20%22flume%22%20ORDER%20BY%20key%20DESC&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Type Persistent:&lt;br/&gt;
1. Crushed several times after a little while and stopped sending messages. It didn&#8217;t look like the flume instance was the one that crushes so my guess is that the BerkelyDB thread or something like that. I could not figured out what exactly.&lt;br/&gt;
2. During the same time it crushed (which seems pretty connected to the issue) I got alerts regarding IO stating Disk IO &amp;gt; 90%. Again, not sure why it happened, but it happened on several occasions and only when I tried the persistent type.&lt;br/&gt;
3. Batch mode though worked.&lt;/p&gt;

&lt;p&gt;Type Embedded:&lt;br/&gt;
1. The documentation in log4j website about it does not reflect the the way to configure this type. I had to work my way through the errors until I got my code to run, and even then it didn&#8217;t really seem like it sends anything. Not sure why, and I probably need to look deeper into it.&lt;/p&gt;

&lt;p&gt;Since Avro type is the only one that seems to work without a significant crush, I tested this mode of operation by adding a local Flume which get the data from the log4j2 appender and ship it to the remote Flume using deflate compression. Using this setup it took 1276484 ms ~ 21 Minutes.&lt;/p&gt;

&lt;p&gt;Another important thing I wanted to point out is once I removed all the appenders, it took only 10781 ms (about 10-11 seconds) to read the file. With file appender it took 99682 ms (about 1.5 minutes). So the performance drawback when using the flume appender seems pretty huge, but it can probably be reduced using the async logger mode.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12843262">LOG4J2-1076</key>
            <summary>Flume appender fails to perform</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="10101">Abandoned</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="tezra">tzachi</reporter>
                        <labels>
                    </labels>
                <created>Tue, 7 Jul 2015 18:26:25 +0000</created>
                <updated>Sun, 23 Jun 2019 08:27:21 +0000</updated>
                            <resolved>Sun, 23 Jun 2019 08:27:21 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="14617795" author="ralph.goers@dslextreme.com" created="Wed, 8 Jul 2015 01:23:41 +0000"  >&lt;p&gt;This is opened as a bug but there isn&apos;t anything here specific to fix. As you noted, the bug with batching of Avro events has been corrected. You really should test against that.  As for the other issues, you say they &quot;crushed&quot; (I believe you mean &quot;crashed&quot;) but you haven&apos;t provided any details as to what the problem might be.&lt;/p&gt;

&lt;p&gt;As for the embedded variation, the web site does document and, in fact, shows two example configurations. The log4j-samples project has a sample project that uses the embedded variation and the log4j-flume project has two unit tests for the embedded agent.  You should be able to look at any of those and get an idea of how to make it work.&lt;/p&gt;</comment>
                            <comment id="14617858" author="tezra" created="Wed, 8 Jul 2015 02:20:37 +0000"  >&lt;p&gt;Hey Ralph,&lt;/p&gt;

&lt;p&gt;1. In order to make it compatible with Flume&apos;s Avro source, I think that a &quot;deflate&quot; compression method should be supported, especially when (as mentioned) the compression ratio is significantly better than the current GZIP compression.&lt;br/&gt;
2. I will test it against the fix for batching the events as soon as it becomes available (on v2.4).&lt;br/&gt;
3. Sorry for my typos, I did mean crashed, and I didn&apos;t provide any details because there was nothing in the logs besides system alerts for Disk IO &amp;gt; 90% when I used the Persistent mode. The Avro mode crashes might be a result of the terminal crash, so you can ignore my comment on this for now.&lt;br/&gt;
4. It should not take over 2 Hours to send 2G, especially when it took me 20 minutes using a local flume instance using the exact same link. I could not find any heavy load performance test results using this appender, but from my tests it looks like there are several issues with both Avro and Persistent mode when trying to use this appender on high number of events to a remote machine (I wish I could pin point it more).&lt;br/&gt;
5. I am well aware to the embeded variation example, but it didn&apos;t work until I changed the configuration to the embeded agent configuration as described in the flume project &lt;a href=&quot;https://flume.apache.org/FlumeDeveloperGuide.html#embedded-agent&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://flume.apache.org/FlumeDeveloperGuide.html#embedded-agent&lt;/a&gt;. Regarding the unit test you mentioned, you can take a look at embedded.xml under the test resources for log4j2flume-ng and see that it matches the flume project documentation and not the log4j2 flume appender one.&lt;/p&gt;

&lt;p&gt;I agree that there is not a particular bug, but I wasn&apos;t sure what is the best way to mark this issue. Let me know if you want me to split it to several tickets, change the ticket type from bug to something else or provide you with more information.&lt;/p&gt;</comment>
                            <comment id="14618239" author="garydgregory" created="Wed, 8 Jul 2015 08:55:33 +0000"  >&lt;p&gt;You can test the 2.4-SNAPSHOT by building from our Git master or pointing Maven to &lt;a href=&quot;https://repository.apache.org/content/groups/snapshots/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://repository.apache.org/content/groups/snapshots/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14618726" author="ralph.goers@dslextreme.com" created="Wed, 8 Jul 2015 14:45:59 +0000"  >&lt;p&gt;Unfortunately, the compression for the event body was added about a year before compression was added to Flume. If it had already been there we certainly would have just taken advantage of that.  If you would like to see support for Flume&apos;s compression added then I would recommend creating a separate enhancement request for that.&lt;/p&gt;

&lt;p&gt;As for the performance, if you are seeing disk I/O &amp;gt; 90% then I would expect that that is what is making things slow.&lt;/p&gt;

&lt;p&gt;If you need help getting the embedded appender to run just ask questions on the dev or user list. However, its performance probably won&apos;t be much different than the persistent appender unless you set dataDir to InMemory, in which case it won&apos;t write to disk (and could suffer data loss if the JVM crashes).&lt;/p&gt;</comment>
                            <comment id="14619933" author="tezra" created="Thu, 9 Jul 2015 05:34:58 +0000"  >&lt;p&gt;OK,&lt;br/&gt;
I guess you can close this ticket as a bug as its not pin pointed to a certain code logic. &lt;br/&gt;
Though, I believe that these findings are important in matter of Avro appender performance under high load. If it was possible to attach a test code I would do that but it actually more of a setup of a Java application that uses log4j, and a remote instance.&lt;/p&gt;

&lt;p&gt;I will open an enhancement request for the deflate compression and will update in case I can find the reason for the performance drawback after I try the 2.4-SNAPSHOT.&lt;/p&gt;</comment>
                            <comment id="14620175" author="ralph.goers@dslextreme.com" created="Thu, 9 Jul 2015 09:23:07 +0000"  >&lt;p&gt;What hardware are you running on. In particular, what kind of disks. Is there anything else going on?  With a 90% disk I/o rate I am inclined to say that the problem is the hardware you are using, not the software. For example, you should only use local disk, not NAS or SAN.&lt;/p&gt;</comment>
                            <comment id="14620835" author="tezra" created="Thu, 9 Jul 2015 16:57:13 +0000"  >&lt;p&gt;I find it hard to believe that this is a hardware issue from several reasons:&lt;br/&gt;
1. I am using local SSD&lt;br/&gt;
2. I don&apos;t see any issues when using other appenders (e.g FileAppender).&lt;br/&gt;
3. I only see it when I use the &quot;Persistent&quot; type within the Avro Appender&lt;/p&gt;</comment>
                            <comment id="16870489" author="ralph.goers@dslextreme.com" created="Sun, 23 Jun 2019 08:27:21 +0000"  >&lt;p&gt;The performance of the Flume Appender does need to be looked at but there are other tickets specific to that.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 21 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2gy8v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>