<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 19:31:28 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[LOG4J2-279] Logging from log4j2 FlumeAppender with BerkeleyDB agent from Jetty webapp to Avro source with full queue raises ClosedByInterruptException</title>
                <link>https://issues.apache.org/jira/browse/LOG4J2-279</link>
                <project id="12310790" key="LOG4J2">Log4j 2</project>
                    <description>&lt;p&gt;Attempting to embed a Flume agent in another app does not work very well. I have found a repro of a very simple Jetty app using the log4j2 FlumeAppender to connect to a subsequent Flume agent with a full channel.&lt;/p&gt;

&lt;p&gt;The impact is that I don&apos;t believe the BerkeleyDB agent can be safely used.&lt;/p&gt;

&lt;p&gt;Steps:&lt;br/&gt;
1. Setup an additional Flume server (the subsequent server) with an avro source and make the channel fill up (in my environment the subsequent server gets an OutOfMemoryError and then starts queueing events.)&lt;br/&gt;
2. Extract the enclosed project. Edit the flume-embedded-hot-deploy/src/main/resource/log4j2.xml and configure the Agent for the FlumeAppender with the details of the subsequent server.&lt;br/&gt;
3. mvn clean install&lt;br/&gt;
4. Change to flume-embedded-hot-deploy&lt;br/&gt;
5. mvn clean package -P debug  (note that you can set it to suspend until a debugger is attached with mvn clean package -P debug,suspend)&lt;br/&gt;
6. Wait for Jetty to startup - and then for a few seconds.&lt;/p&gt;

&lt;p&gt;Expected results:&lt;br/&gt;
Some complaints about the subsequent server being full but an otherwise happy server.&lt;/p&gt;

&lt;p&gt;Actual results:&lt;br/&gt;
When using the log4j2 Persistent agent (which uses Berkeley DB as a store):&lt;br/&gt;
2013-06-03 14:01:14,804 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; server.AbstractConnector (AbstractConnector.java:265) - Started ServerConnector@75a213c0&lt;/p&gt;
{HTTP/1.1}
{0.0.0.0:8080}
&lt;p&gt;2013-06-03 14:01:22,779 DEBUG &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-3&amp;#93;&lt;/span&gt; ipc.NettyTransceiver (NettyTransceiver.java:314) - Disconnecting from collector1-sal-flex-van.dev-globalrelay.net/10.21.30.20:36892&lt;br/&gt;
2013-06-03 14:01:22,789 ERROR An exception occurred processing Appender FlumeAppender org.apache.logging.log4j.LoggingException: Exception occurred writing log event&lt;br/&gt;
	at org.apache.logging.log4j.flume.appender.FlumePersistentManager.send(FlumePersistentManager.java:176)&lt;br/&gt;
	at org.apache.logging.log4j.flume.appender.FlumeAppender.append(FlumeAppender.java:86)&lt;br/&gt;
	at org.apache.logging.log4j.core.config.AppenderControl.callAppender(AppenderControl.java:102)&lt;br/&gt;
	at org.apache.logging.log4j.core.config.LoggerConfig.callAppenders(LoggerConfig.java:424)&lt;br/&gt;
	at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:405)&lt;br/&gt;
	at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:366)&lt;br/&gt;
	at org.apache.logging.log4j.core.Logger.log(Logger.java:110)&lt;br/&gt;
	at org.apache.logging.log4j.spi.AbstractLoggerWrapper.log(AbstractLoggerWrapper.java:55)&lt;br/&gt;
	at org.slf4j.impl.SLF4JLogger.debug(SLF4JLogger.java:139)&lt;br/&gt;
	at org.apache.avro.ipc.NettyTransceiver$NettyClientAvroHandler.handleUpstream(NettyTransceiver.java:491)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:792)&lt;br/&gt;
	at org.jboss.netty.handler.codec.frame.FrameDecoder.cleanup(FrameDecoder.java:348)&lt;br/&gt;
	at org.jboss.netty.handler.codec.frame.FrameDecoder.channelDisconnected(FrameDecoder.java:230)&lt;br/&gt;
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:107)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)&lt;br/&gt;
	at org.jboss.netty.channel.Channels.fireChannelDisconnected(Channels.java:399)&lt;br/&gt;
	at org.jboss.netty.channel.Channels$4.run(Channels.java:389)&lt;br/&gt;
	at org.jboss.netty.channel.socket.ChannelRunnableWrapper.run(ChannelRunnableWrapper.java:41)&lt;br/&gt;
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.processEventQueue(AbstractNioWorker.java:352)&lt;br/&gt;
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:236)&lt;br/&gt;
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:38)&lt;br/&gt;
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:722)&lt;br/&gt;
Caused by: com.sleepycat.je.ThreadInterruptedException: (JE 5.0.73) Environment must be closed, caused by: com.sleepycat.je.ThreadInterruptedException: Environment invalid because of previous exception: (JE 5.0.73) /var/local/flume/castellan-reader-berkeley-db Channel closed, may be due to thread interrupt THREAD_INTERRUPTED: InterruptedException may cause incorrect internal state, unable to continue. Environment is invalid and must be closed.&lt;br/&gt;
	at com.sleepycat.je.ThreadInterruptedException.wrapSelf(ThreadInterruptedException.java:99)&lt;br/&gt;
	at com.sleepycat.je.dbi.EnvironmentImpl.checkIfInvalid(EnvironmentImpl.java:1512)&lt;br/&gt;
	at com.sleepycat.je.Transaction.checkEnv(Transaction.java:850)&lt;br/&gt;
	at com.sleepycat.je.Transaction.abort(Transaction.java:204)&lt;br/&gt;
	at org.apache.logging.log4j.flume.appender.FlumePersistentManager.send(FlumePersistentManager.java:171)&lt;br/&gt;
	... 26 more&lt;br/&gt;
Caused by: com.sleepycat.je.ThreadInterruptedException: Environment invalid because of previous exception: (JE 5.0.73) /var/local/flume/castellan-reader-berkeley-db Channel closed, may be due to thread interrupt THREAD_INTERRUPTED: InterruptedException may cause incorrect internal state, unable to continue. Environment is invalid and must be closed.&lt;br/&gt;
	at com.sleepycat.je.log.FileManager$LogEndFileDescriptor.force(FileManager.java:3054)&lt;br/&gt;
	at com.sleepycat.je.log.FileManager$LogEndFileDescriptor.access$500(FileManager.java:2710)&lt;br/&gt;
	at com.sleepycat.je.log.FileManager.syncLogEnd(FileManager.java:2022)&lt;br/&gt;
	at com.sleepycat.je.log.FSyncManager.executeFSync(FSyncManager.java:282)&lt;br/&gt;
	at com.sleepycat.je.log.FSyncManager.fsync(FSyncManager.java:233)&lt;br/&gt;
	at com.sleepycat.je.log.FileManager.groupSync(FileManager.java:2070)&lt;br/&gt;
	at com.sleepycat.je.log.LogManager.multiLog(LogManager.java:403)&lt;br/&gt;
	at com.sleepycat.je.log.LogManager.log(LogManager.java:335)&lt;br/&gt;
	at com.sleepycat.je.txn.Txn.logCommitEntry(Txn.java:957)&lt;br/&gt;
	at com.sleepycat.je.txn.Txn.commit(Txn.java:719)&lt;br/&gt;
	at com.sleepycat.je.txn.Txn.commit(Txn.java:584)&lt;br/&gt;
	at com.sleepycat.je.Transaction.commit(Transaction.java:317)&lt;br/&gt;
	at org.apache.logging.log4j.flume.appender.FlumePersistentManager.send(FlumePersistentManager.java:167)&lt;br/&gt;
	... 26 more&lt;br/&gt;
Caused by: java.nio.channels.ClosedByInterruptException&lt;br/&gt;
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)&lt;br/&gt;
	at sun.nio.ch.FileChannelImpl.force(FileChannelImpl.java:367)&lt;br/&gt;
	at com.sleepycat.je.log.FileManager$LogEndFileDescriptor.force(FileManager.java:3043)&lt;br/&gt;
	... 38 more&lt;/p&gt;

&lt;p&gt;Suppositions:&lt;br/&gt;
I believe this is an issue with the handling of a failed put or take. The failure path interacts with rollback or the Avro client in bad ways.&lt;br/&gt;
For example, the Avro client uses a SynchronousQueue to do rendezvous. That queue uses InterruptedException internally. However, the FileChannel uses the NIO FileChannel (and AbstractInterruptibleChannel) which fails if its thread gets interrupted. My debugging sessions show that java.util.concurrent.CountDownLatch is a common source of InterruptedExceptions. CountDownLatch is also used by the Avro client.&lt;/p&gt;

&lt;p&gt;Some docs:&lt;br/&gt;
&lt;a href=&quot;http://jira.codehaus.org/browse/JETTY-80&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://jira.codehaus.org/browse/JETTY-80&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://www.oracle.com/technetwork/products/berkeleydb/if-097768.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.oracle.com/technetwork/products/berkeleydb/if-097768.html&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12652228">LOG4J2-279</key>
            <summary>Logging from log4j2 FlumeAppender with BerkeleyDB agent from Jetty webapp to Avro source with full queue raises ClosedByInterruptException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ejsarge">Edward Sargisson</reporter>
                        <labels>
                    </labels>
                <created>Tue, 11 Jun 2013 16:49:09 +0000</created>
                <updated>Thu, 4 Jul 2013 15:15:40 +0000</updated>
                            <resolved>Thu, 4 Jul 2013 15:15:40 +0000</resolved>
                                    <version>2.0-beta7</version>
                                    <fixVersion>2.0-beta8</fixVersion>
                                    <component>Flume Appender</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="13694535" author="ralph.goers@dslextreme.com" created="Thu, 27 Jun 2013 07:03:20 +0000"  >&lt;p&gt;I ran the provided test and was able to duplicate the problem. However I also got the following stack trace that seems to indicate that the problem is that the Netty thread is logging to Flume and is getting a thread interruption, most likely for the socket connection, and the first thing to detect it is Berkeley DB.  I&apos;m considering ways to deal with this but this can easily be avoided by routing events from Avro to some other Appender.&lt;/p&gt;

&lt;p&gt;2013-06-25 15:44:16,836 ERROR An exception occurred processing Appender FlumeAppender org.apache.logging.log4j.LoggingException: Exception occurred writing log event&lt;br/&gt;
	at org.apache.logging.log4j.flume.appender.FlumePersistentManager.send(FlumePersistentManager.java:176)&lt;br/&gt;
	at org.apache.logging.log4j.flume.appender.FlumeAppender.append(FlumeAppender.java:86)&lt;br/&gt;
	at org.apache.logging.log4j.core.config.AppenderControl.callAppender(AppenderControl.java:102)&lt;br/&gt;
	at org.apache.logging.log4j.core.config.LoggerConfig.callAppenders(LoggerConfig.java:424)&lt;br/&gt;
	at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:405)&lt;br/&gt;
	at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:366)&lt;br/&gt;
	at org.apache.logging.log4j.core.Logger.log(Logger.java:110)&lt;br/&gt;
	at org.apache.logging.log4j.spi.AbstractLoggerWrapper.log(AbstractLoggerWrapper.java:55)&lt;br/&gt;
	at org.slf4j.impl.SLF4JLogger.debug(SLF4JLogger.java:139)&lt;br/&gt;
	at org.apache.avro.ipc.NettyTransceiver$NettyClientAvroHandler.handleUpstream(NettyTransceiver.java:491)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:792)&lt;br/&gt;
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.channelUnbound(SimpleChannelUpstreamHandler.java:203)&lt;br/&gt;
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:100)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)&lt;br/&gt;
	at org.jboss.netty.channel.Channels.fireChannelUnbound(Channels.java:436)&lt;br/&gt;
	at org.jboss.netty.channel.Channels$5.run(Channels.java:424)&lt;br/&gt;
	at org.jboss.netty.channel.socket.ChannelRunnableWrapper.run(ChannelRunnableWrapper.java:41)&lt;br/&gt;
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.processEventQueue(AbstractNioWorker.java:352)&lt;br/&gt;
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:236)&lt;br/&gt;
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:38)&lt;br/&gt;
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:722)&lt;br/&gt;
Caused by: com.sleepycat.je.ThreadInterruptedException: (JE 5.0.73) Environment must be closed, caused by: com.sleepycat.je.ThreadInterruptedException: Environment invalid because of previous exception: (JE 5.0.73) /tmp/castellan-reader-berkeley-db Thread interrupted prior to logging the commit THREAD_INTERRUPTED: InterruptedException may cause incorrect internal state, unable to continue. Environment is invalid and must be closed.&lt;br/&gt;
	at com.sleepycat.je.ThreadInterruptedException.wrapSelf(ThreadInterruptedException.java:99)&lt;br/&gt;
	at com.sleepycat.je.dbi.EnvironmentImpl.checkIfInvalid(EnvironmentImpl.java:1512)&lt;br/&gt;
	at com.sleepycat.je.Transaction.checkEnv(Transaction.java:850)&lt;br/&gt;
	at com.sleepycat.je.Transaction.abort(Transaction.java:204)&lt;br/&gt;
	at org.apache.logging.log4j.flume.appender.FlumePersistentManager.send(FlumePersistentManager.java:171)&lt;br/&gt;
	... 25 more&lt;br/&gt;
Caused by: com.sleepycat.je.ThreadInterruptedException: Environment invalid because of previous exception: (JE 5.0.73) /tmp/castellan-reader-berkeley-db Thread interrupted prior to logging the commit THREAD_INTERRUPTED: InterruptedException may cause incorrect internal state, unable to continue. Environment is invalid and must be closed.&lt;br/&gt;
	at com.sleepycat.je.txn.Txn.preLogCommitCheck(Txn.java:1006)&lt;br/&gt;
	at com.sleepycat.je.txn.Txn.logCommitEntry(Txn.java:952)&lt;br/&gt;
	at com.sleepycat.je.txn.Txn.commit(Txn.java:719)&lt;br/&gt;
	at com.sleepycat.je.txn.Txn.commit(Txn.java:584)&lt;br/&gt;
	at com.sleepycat.je.Transaction.commit(Transaction.java:317)&lt;br/&gt;
	at org.apache.logging.log4j.flume.appender.FlumePersistentManager.send(FlumePersistentManager.java:167)&lt;br/&gt;
	... 25 more&lt;/p&gt;</comment>
                            <comment id="13700129" author="ralph.goers@dslextreme.com" created="Thu, 4 Jul 2013 15:15:40 +0000"  >&lt;p&gt;Resolved in revision 1499780. Note that there were two issues here:&lt;br/&gt;
1. Interrupts were breaking Berkeley DB.&lt;br/&gt;
2. Logging of Avro and Flume to the Flume Appender causes and endless loop of logging events.  As a consequence the Flume Appender now filters out all org.apache.flume and org.apache.avro events.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                            <outwardlinks description="supercedes">
                                        <issuelink>
            <issuekey id="12650746">FLUME-2067</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12587254" name="flume-embedded-web-flume-2067.tar.gz" size="4575" author="ejsarge" created="Tue, 11 Jun 2013 16:49:32 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>332552</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 20 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ld9z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>332881</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>