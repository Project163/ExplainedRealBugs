<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 19:39:23 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[LOG4J2-2106] May blocked when two compress action</title>
                <link>https://issues.apache.org/jira/browse/LOG4J2-2106</link>
                <project id="12310790" key="LOG4J2">Log4j 2</project>
                    <description>&lt;p&gt;     My log file is very large, so I set the config about compression. The policies is as follows:&lt;br/&gt;
     &amp;lt;Policies&amp;gt;&lt;br/&gt;
           &amp;lt;OnStartupTriggeringPolicy/&amp;gt;&lt;br/&gt;
           &amp;lt;TimeBasedTriggeringPolicy/&amp;gt;&lt;br/&gt;
     &amp;lt;/Policies&amp;gt;&lt;br/&gt;
     When restart the service on the hour,  this will trigger the two policies. And I find that the log can not be written for a while. &lt;br/&gt;
     I think, there would be two compress actions. In the file RollingFileManager(package org.apache.logging.log4j.core.appender.rolling), the actions will submit to asyncExecutor which will create a new thread for every work. That mean the log file will be compressed by the two actions. Is this the cause?&lt;/p&gt;

&lt;p&gt; Thanks.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13116934">LOG4J2-2106</key>
            <summary>May blocked when two compress action</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="skopt">skopt</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Nov 2017 10:33:02 +0000</created>
                <updated>Wed, 22 Nov 2017 15:08:28 +0000</updated>
                                            <version>2.9.1</version>
                                                    <component>Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16246928" author="skopt" created="Fri, 10 Nov 2017 02:26:16 +0000"  >&lt;p&gt;   Reading the code, I find the cause. In the function rollover of class RollingFileManager, it will block until all the asynchronous operation is completed. Because the log is very large, the compression triggered by OnStartupTriggeringPolicy will cost several minutes.  So the rollover() function will keep the synchronized lock for a long time when processing rollover triggered by TimeBasedTriggeringPolicy.  At that time, the write function will be blocked for waiting the same synchronized lock.&lt;br/&gt;
   As it will block the application,  should the rollover be parallel processed? The file will create a temp file fro compress and the synchronized lock for the rollover would ensure that a file will not rename at the same time. Is the semaphore still necessary?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="16247031" author="ralph.goers@dslextreme.com" created="Fri, 10 Nov 2017 05:30:27 +0000"  >&lt;p&gt;The problem isn&apos;t that rollover is synchronized but that checkRollover is synchronized. Two rollovers cannot be allowed to happen concurrently but we should be able to determine if rollovers are required concurrently.&lt;/p&gt;

&lt;p&gt;Some of the isTriggeringEvent implementations might require synchronization but not all of them do. Specifically, CronTriggeringPolicy, CompositeTriggeringPolicy and OnStartupTriggeringPolicy do not. Furthermore, SizeBasedTriggeringPolicy and TimeBasedTriggeringPolicy each can be independently synchronized - and don&apos;t need to synchronize on the FileManager as rollover does.&lt;/p&gt;</comment>
                            <comment id="16247201" author="skopt" created="Fri, 10 Nov 2017 08:37:36 +0000"  >&lt;p&gt;Can we shrink the rang of synchronized? I think it no need to synchronize the whole checkRollover.  Remove the synchronized from checkRollover and rollover. Add synchronized for triggeringPolicy.isTriggeringEvent(event).  In rollover(), add synchronized after  acquire the semaphore.&lt;/p&gt;</comment>
                            <comment id="16247509" author="jira-bot" created="Fri, 10 Nov 2017 13:46:27 +0000"  >&lt;p&gt;Commit aad2f132b27f9e2667c2b43fb58ce59e3914edb3 in logging-log4j2&apos;s branch refs/heads/master from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ralphgoers&quot; class=&quot;user-hover&quot; rel=&quot;ralphgoers&quot;&gt;ralphgoers&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=logging-log4j2.git;h=aad2f13&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=logging-log4j2.git;h=aad2f13&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/LOG4J2-2106&quot; title=&quot;May blocked when two compress action&quot; class=&quot;issue-link&quot; data-issue-key=&quot;LOG4J2-2106&quot;&gt;LOG4J2-2106&lt;/a&gt; Reduce locking when checking for rollover&lt;/p&gt;</comment>
                            <comment id="16247537" author="ralph.goers@dslextreme.com" created="Fri, 10 Nov 2017 14:06:56 +0000"  >&lt;p&gt;Please checkout from master and verify the fix works for you. If it does, please close the issue.&lt;/p&gt;</comment>
                            <comment id="16248908" author="remkop@yahoo.com" created="Sun, 12 Nov 2017 16:19:14 +0000"  >&lt;p&gt;Reviewing commit aad2f13:&lt;/p&gt;

&lt;p&gt;To be honest, I am not sure why this would solve the issue... Ralph, why do you think RollingFileManager::checkRollover being synchronized was the cause of the described latency spikes? Noting that the issue occurs when a rollover is in progress, and ultimately the thread will need to wait for the rollover to complete before it can write bytes again,  I&apos;m unsure that making the triggering policy more concurrent will have a dramatic impact. But perhaps I&apos;m missing something.&lt;/p&gt;

&lt;p&gt;About the changes:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Potential issue 1&lt;/b&gt;&lt;br/&gt;
 &lt;tt&gt;RollingFileManager::getFileSize&lt;/tt&gt; (called from both TimeBasedTriggeringPolicy and SizeBasedTriggeringPolicy) is not a synchronized method but reads the byteBuffer position which is updated in synchronized blocks in OutputStreamManager. Should this method be synchronized in RollingFileManager?&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Would need careful checking to ensure we don&apos;t introduce the risk of deadlock. (I haven&apos;t looked in detail yet.)&lt;/li&gt;
	&lt;li&gt;This re-introduces a (brief) period where some triggering policies synchronize on the FileManger. Would this defeat the purpose?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;b&gt;Potential issue 2&lt;/b&gt;&lt;br/&gt;
The manager&apos;s PatternProcessor could potentially be modified by two threads simultaneously if there are two different TriggeringPolicy instances (e.g. a TimeBasedTriggeringPolicy and a SizeBasedTriggeringPolicy) that both decide the specified event is a triggering event. Is synchronization on the manager or on the PatternProcessor required?&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Optimization&lt;/b&gt;&lt;br/&gt;
 Does &lt;tt&gt;TimeBasedTriggeringPolicy::isTriggeringEvent&lt;/tt&gt; need to be a synchronized method? If &lt;tt&gt;nextRolloverMillis&lt;/tt&gt; is made volatile I think we only need to synchronize after we decided we may need to return &lt;tt&gt;true&lt;/tt&gt;... Something like this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;volatile&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; nextRolloverMillis; &lt;span class=&quot;code-comment&quot;&gt;// needs to be &lt;span class=&quot;code-keyword&quot;&gt;volatile&lt;/span&gt;
&lt;/span&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isTriggeringEvent(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; LogEvent event) {
        &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; nowMillis = event.getTimeMillis();
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (nowMillis &amp;gt;= nextRolloverMillis) {
            &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
                &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (manager.getFileSize() == 0) {
                    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
                }
                nextRolloverMillis = ThreadLocalRandom.current().nextLong(0, 1 + maxRandomDelayMillis)
                        + manager.getPatternProcessor().getNextTime(nowMillis, interval, modulate);
                &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
            }
        }
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;b&gt;Idea for future enhancement&lt;/b&gt;&lt;br/&gt;
RollingFileManager::setTriggeringPolicy can be simplified now. Prior to the introduction of the &lt;tt&gt;ReadWriteLock updateLock&lt;/tt&gt; field, RollingFileManager needed to work hard to make changing the TriggeringPolicy lock-free. Given that this policy rarely changes, a simple lock may be better. Now that &lt;tt&gt;setTriggeringPolicy&lt;/tt&gt; is guarded by a write lock, can the lock-free stuff be removed?&lt;/p&gt;</comment>
                            <comment id="16248918" author="ralph.goers@dslextreme.com" created="Sun, 12 Nov 2017 17:07:05 +0000"  >&lt;p&gt;That is a good question.  Both rollover and checkRollover synchronize on the FileManager. So all calls to checkRollover are synchronized and will be blocked by rollover. rollover calls rollover(strategy). It waits for any async tasks to be completed before it will execute (to prevent trying to compress the same file). This will cause a second call to rollover to block until all async threads are complete, which will cause threads to block waiting to log.&lt;/p&gt;

&lt;p&gt;The logic in rollover(strategy) of waiting for the async thread to complete is correct and is required. But I don&apos;t believe logging should be blocked while the rollover completes. So this may only partially solve the reporter&apos;s issue. &lt;/p&gt;

&lt;p&gt;&lt;b&gt;Potential Issue 1&lt;/b&gt;&lt;br/&gt;
I made isTriggeringEvent in both TimeBasedTriggeringPolicy and SizeBasedTriggeringPolicy synchronized. However, both update the file time so both need to use the same lock. I will need to create a lock for them to synchronize on.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Potential Issue 2&lt;/b&gt;&lt;br/&gt;
That is really the same as Potential Issue 1 and the same fix should apply.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Optimization&lt;/b&gt;&lt;br/&gt;
I don&apos;t think that will work as the call to getNextTime needs to be locked against changes by calls to updateTime from SizeBasedTriggeringPolicy. That could be done by synchronizing those methods.&lt;/p&gt;

&lt;p&gt;But I now see another issue. It seems that we allow the patternProcessor to be replaced on a reconfiguration. Currently it copies the time values from the old pattern processor to the new one. But that only works properly if the pattern processor time values cannot be changed after the new copy is made or only use the new PatternProcessor after the values are copied. Right now updateData isn&apos;t synchronized at all. &lt;/p&gt;

&lt;p&gt;&lt;b&gt;Idea for future enhancement&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;I am not sure why this needs to be a future enhancement. setTriggeringPolicy should start the new Policy before it is set in the FileManager.  There still could be threads trying to use the TriggeringPolicy after stop is called, but for the current TriggeringPolicies that won&apos;t cause a problem. Then again, I only added the lock because start was being called after the update was performed. Yes, the TriggeringPolicyUpdater shouldn&apos;t be necessary.&lt;/p&gt;</comment>
                            <comment id="16248973" author="ralph.goers@dslextreme.com" created="Sun, 12 Nov 2017 19:52:59 +0000"  >&lt;p&gt;I have just realized that this fix also opens up another problem. With the changes multiple threads can now check isTriggeringEvent simultaneously. That means multiple threads can now think they are supposed to trigger a rollover. We can&apos;t have that.&lt;/p&gt;</comment>
                            <comment id="16248989" author="jira-bot" created="Sun, 12 Nov 2017 21:07:40 +0000"  >&lt;p&gt;Commit 6b6947540dc43dfa9829f219ef60222566586cc4 in logging-log4j2&apos;s branch refs/heads/master from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ralphgoers&quot; class=&quot;user-hover&quot; rel=&quot;ralphgoers&quot;&gt;ralphgoers&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=logging-log4j2.git;h=6b69475&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=logging-log4j2.git;h=6b69475&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/LOG4J2-2106&quot; title=&quot;May blocked when two compress action&quot; class=&quot;issue-link&quot; data-issue-key=&quot;LOG4J2-2106&quot;&gt;LOG4J2-2106&lt;/a&gt; - Revert changes&lt;/p&gt;</comment>
                            <comment id="16248990" author="ralph.goers@dslextreme.com" created="Sun, 12 Nov 2017 21:07:58 +0000"  >&lt;p&gt;Reverted the changes while I rethink this.&lt;/p&gt;</comment>
                            <comment id="16249630" author="ralph.goers@dslextreme.com" created="Mon, 13 Nov 2017 14:06:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=remkop%40yahoo.com&quot; class=&quot;user-hover&quot; rel=&quot;remkop@yahoo.com&quot;&gt;remkop@yahoo.com&lt;/a&gt; It seems to me that locking on the checkRollover method won&apos;t be required so long as each TriggeringPolicy only returns true once per rollover interval. The thing is, I don&apos;t know how to accomplish that for the SizeBasedTriggeringPolicy since it will remain true until the rollover puts a new file in place. We would need some logic to prevent it from being true twice and then maybe reset itself when the file size is again less than the max?&lt;/p&gt;</comment>
                            <comment id="16258272" author="remkop@yahoo.com" created="Sun, 19 Nov 2017 00:45:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ralph.goers%40dslextreme.com&quot; class=&quot;user-hover&quot; rel=&quot;ralph.goers@dslextreme.com&quot;&gt;ralph.goers@dslextreme.com&lt;/a&gt; Looking back at your earlier comment&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Both rollover and checkRollover synchronize on the FileManager. So all calls to checkRollover are synchronized and will be blocked by rollover. rollover calls rollover(strategy). It waits for any async tasks to be completed before it will execute (to prevent trying to compress the same file). This will cause a second call to rollover to block until all async threads are complete, which will cause threads to block waiting to log.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So, when a rollover is in progress, we block the second call to &lt;tt&gt;rollover&lt;/tt&gt; to prevent two threads from trying to compress the same thing twice. How about, instead of blocking in &lt;tt&gt;rollover&lt;/tt&gt; we return immediately when we detect that a rollover is already in progress? (The rollover request is essentially already being honored by another thread. Seems pointless to wait and then perform another rollover immediately after the first one...)&lt;/p&gt;

&lt;p&gt;This could be done with a &lt;tt&gt;volatile boolean isRolloverInProgress&lt;/tt&gt; flag that is read before trying to acquire the lock (double checked locking pattern). This should dramatically improve throughput without deep surgery of the code (I hope).&lt;/p&gt;</comment>
                            <comment id="16258274" author="ralph.goers@dslextreme.com" created="Sun, 19 Nov 2017 00:47:38 +0000"  >&lt;p&gt;OK. I will look into that.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13120244">LOG4J2-2125</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3mjav:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>