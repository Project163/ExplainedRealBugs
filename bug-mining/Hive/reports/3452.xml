<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:33:13 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-10538] Fix NPE in FileSinkOperator from hashcode mismatch</title>
                <link>https://issues.apache.org/jira/browse/HIVE-10538</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;A Null Pointer Exception occurs when in FileSinkOperator when using bucketed tables and distribute by with multiFileSpray enabled. The following snippet query reproduces this issue:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;set hive.enforce.bucketing = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
set hive.exec.reducers.max = 20;

create table bucket_a(key &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, value_a string) clustered by (key) into 256 buckets;
create table bucket_b(key &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, value_b string) clustered by (key) into 256 buckets;
create table bucket_ab(key &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, value_a string, value_b string) clustered by (key) into 256 buckets;

-- Insert data into bucket_a and bucket_b

insert overwrite table bucket_ab
select a.key, a.value_a, b.value_b from bucket_a a join bucket_b b on (a.key = b.key) distribute by key;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following stack trace is logged.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2015-04-29 12:54:12,841 FATAL [pool-110-thread-1]: ExecReducer (ExecReducer.java:reduce(255)) - org.apache.hadoop.hive.ql.metadata.HiveException: Hive &lt;span class=&quot;code-object&quot;&gt;Runtime&lt;/span&gt; Error &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; processing row (tag=0) {&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;:{},&lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;:{&lt;span class=&quot;code-quote&quot;&gt;&quot;_col0&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;113&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;_col1&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_113&quot;&lt;/span&gt;}}
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:244)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:444)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.findWriterOffset(FileSinkOperator.java:819)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:747)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:88)
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:235)
	... 8 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12826088">HIVE-10538</key>
            <summary>Fix NPE in FileSinkOperator from hashcode mismatch</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="petersla">Peter Slawski</assignee>
                                    <reporter username="petersla">Peter Slawski</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Apr 2015 20:06:38 +0000</created>
                <updated>Fri, 5 Jun 2015 21:50:35 +0000</updated>
                            <resolved>Thu, 7 May 2015 20:48:33 +0000</resolved>
                                    <version>1.0.0</version>
                    <version>1.2.0</version>
                                    <fixVersion>1.3.0</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="14520122" author="petersla" created="Wed, 29 Apr 2015 20:12:19 +0000"  >&lt;p&gt;Currently working on testing the fix for this issue.&lt;/p&gt;</comment>
                            <comment id="14523591" author="petersla" created="Fri, 1 May 2015 18:25:17 +0000"  >&lt;p&gt;The Null Pointer Exception occurs due to a mismatch on the hashcode computed from a row in ReduceSinkOperator and FileSinkOperator. ReduceSinkOperator&apos;s hashcode is used by the partitioner to distribute rows to reducers. The FileSinkOperator&apos;s hashcode is used to compute the row&apos;s bucket number at the reducer. If the hashcodes mismatch, the bucket number computed is not one of the expected bucket numbers for that reducer. This causes a Null Pointer Exception.&lt;/p&gt;

&lt;p&gt;ReduceSinkOperator was computing a different hashcode because its bucketNumber field was initialized to valid bucket number, 0. The attached patch initializes this bucketNumber field to an invalid number, -1. This fixes ReduceSinkOperator to compute the same hashcode as FileSinkOperator.&lt;/p&gt;

&lt;p&gt;The NPE can be reproduced in a simpler query which is included as a qtest in the patch.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;set hive.enforce.bucketing = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
set mapred.reduce.tasks = 16;

create table bucket_many(key &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, value string) clustered by (key) into 256 buckets;

insert overwrite table bucket_many
select * from src;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14523651" author="gopalv" created="Fri, 1 May 2015 18:47:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=petersla&quot; class=&quot;user-hover&quot; rel=&quot;petersla&quot;&gt;petersla&lt;/a&gt;: Is the fix really down to initializing a transient correctly?&lt;/p&gt;</comment>
                            <comment id="14523765" author="petersla" created="Fri, 1 May 2015 19:32:16 +0000"  >&lt;p&gt;Yes. Here is an explanation that refers to how this transient is used.&lt;/p&gt;

&lt;p&gt;The transient is used to compute the row&apos;s hash in &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java#L368&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;ReduceSinkOperator.java#L368&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;        hashCode = computeHashCode(row, bucketNumber);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If the given the bucket number is valid (which would always be as the transient is initialized to a valid number) the computed hashcode would be always multiplied by 31, see &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java#L488&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;ReduceSinkOperator.java#L488&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  ...
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; computeHashCode(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; row, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; buckNum) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; HiveException {
  ...
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = 0; i &amp;lt; partitionEval.length; i++) {
        &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; o = partitionEval[i].evaluate(row);
        keyHashCode = keyHashCode * 31
            + ObjectInspectorUtils.hashCode(o, partitionObjectInspectors[i]);
      }
    }
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; hashCode = buckNum &amp;lt; 0 ? keyHashCode : keyHashCode * 31 + buckNum;
    ...
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; hashCode;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;FileSinkOperator recomputes the hashcode at findWriterOffset(), but won&apos;t multiple by 31. This causes a different bucket number to be computed than expected. bucketMap only contains mappings for the bucket numbers that is expected for the current reducer to receive. From &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java#L811&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;FileSinkOperator.java#L811&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; findWriterOffset(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; row) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; HiveException {
  ...
      &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = 0; i &amp;lt; partitionEval.length; i++) {
        &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; o = partitionEval[i].evaluate(row);
        keyHashCode = keyHashCode * 31
            + ObjectInspectorUtils.hashCode(o, partitionObjectInspectors[i]);
      }
      key.setHashCode(keyHashCode);
      &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; bucketNum = prtner.getBucket(key, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, totalFiles);
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; bucketMap.get(bucketNum);
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The transient was introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8151&quot; title=&quot;Dynamic partition sort optimization inserts record wrongly to partition when used with GroupBy&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8151&quot;&gt;&lt;del&gt;HIVE-8151&lt;/del&gt;&lt;/a&gt; which refactored the bucket number from a local variable to a transient field. Initially, the local variable was initialized to -1. The refactor changed the code so that the transient field was used instead.&lt;/p&gt;</comment>
                            <comment id="14523801" author="gopalv" created="Fri, 1 May 2015 19:56:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=petersla&quot; class=&quot;user-hover&quot; rel=&quot;petersla&quot;&gt;petersla&lt;/a&gt;: that&apos;s a very clear explanation - +1 tests pending.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasanth_j&quot; class=&quot;user-hover&quot; rel=&quot;prasanth_j&quot;&gt;prasanth_j&lt;/a&gt;: do we need to pull this in for 1.2.0?&lt;/p&gt;</comment>
                            <comment id="14523825" author="prasanth_j" created="Fri, 1 May 2015 20:13:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=petersla&quot; class=&quot;user-hover&quot; rel=&quot;petersla&quot;&gt;petersla&lt;/a&gt; Thanks for the patch!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt; Yes. I think we should pull this for 1.2.0 as it is critical and no workaround.&lt;/p&gt;</comment>
                            <comment id="14529098" author="hiveqa" created="Tue, 5 May 2015 19:19:27 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12730336/HIVE-10538.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12730336/HIVE-10538.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 33 failed/errored test(s), 8901 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_authorization_parts
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_static
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_join_unencrypted_tbl
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_join_with_different_encryption_keys
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_load_data_to_encrypted_tables
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_select_read_only_encrypted_tbl
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_disallow_transform
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_droppartition
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_sba_drop_table
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_alterpart_loc
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_gby
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_udf_udaf
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_complex_types_multi_single_reducer
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_lateral_view_explode2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_25
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_top_level
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_timestamp_funcs
org.apache.hadoop.hive.ql.security.TestStorageBasedClientSideAuthorizationProvider.testSimplePrivileges
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationDrops.testDropDatabase
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationDrops.testDropPartition
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationDrops.testDropTable
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationDrops.testDropView
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProvider.testSimplePrivileges
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProviderWithACL.testSimplePrivileges
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationReads.testReadDbFailure
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationReads.testReadDbSuccess
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationReads.testReadTableFailure
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationReads.testReadTableSuccess
org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.TestSQLStdHiveAccessControllerHS2.testConfigProcessing
org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.TestSQLStdHiveAccessControllerHS2.testConfigProcessingCustomSetWhitelistAppend
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3737/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3737/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3737/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3737/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3737/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3737/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 33 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12730336 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14529128" author="gopalv" created="Tue, 5 May 2015 19:41:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=petersla&quot; class=&quot;user-hover&quot; rel=&quot;petersla&quot;&gt;petersla&lt;/a&gt;: the Spark driver failures look related, can you take a look (looks like rows are being reordered only in Spark?).&lt;/p&gt;</comment>
                            <comment id="14529134" author="petersla" created="Tue, 5 May 2015 19:44:12 +0000"  >&lt;p&gt;Will do.&lt;/p&gt;</comment>
                            <comment id="14529673" author="petersla" created="Wed, 6 May 2015 00:52:27 +0000"  >&lt;p&gt;The Spark driver failures are caused by this change. This would be expected if a row&apos;s hashcode affected its ordering in Spark. This patch makes it so that HiveKey&apos;s hashcode outputted from ReduceSinkOperator is no longer always multiplied by 31 (as explained previously).&lt;/p&gt;

&lt;p&gt;Also, for at least those failed qtests, the row ordering/output in the expected output differs across MapRed, Tez, and Spark. So, execution engine affects ordering.&lt;/p&gt;

&lt;p&gt;From &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/test/results/clientpositive/spark/groupby_complex_types_multi_single_reducer.q.out#L221&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;spark/groupby_complex_types_multi_single_reducer.q.out#L221&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;POSTHOOK: query: SELECT DEST2.* FROM DEST2
POSTHOOK: type: QUERY
POSTHOOK: Input: &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;@dest2
#### A masked pattern was here ####
{&lt;span class=&quot;code-quote&quot;&gt;&quot;120&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_120&quot;&lt;/span&gt;}	2
{&lt;span class=&quot;code-quote&quot;&gt;&quot;129&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_129&quot;&lt;/span&gt;}	2
{&lt;span class=&quot;code-quote&quot;&gt;&quot;160&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_160&quot;&lt;/span&gt;}	1
{&lt;span class=&quot;code-quote&quot;&gt;&quot;26&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_26&quot;&lt;/span&gt;}	2
{&lt;span class=&quot;code-quote&quot;&gt;&quot;27&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_27&quot;&lt;/span&gt;}	1
{&lt;span class=&quot;code-quote&quot;&gt;&quot;288&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_288&quot;&lt;/span&gt;}	2
{&lt;span class=&quot;code-quote&quot;&gt;&quot;298&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_298&quot;&lt;/span&gt;}	3
{&lt;span class=&quot;code-quote&quot;&gt;&quot;30&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_30&quot;&lt;/span&gt;}	1
{&lt;span class=&quot;code-quote&quot;&gt;&quot;311&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_311&quot;&lt;/span&gt;}	3
{&lt;span class=&quot;code-quote&quot;&gt;&quot;74&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_74&quot;&lt;/span&gt;}	1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;From &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/test/results/clientpositive/groupby_complex_types_multi_single_reducer.q.out#L240&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;groupby_complex_types_multi_single_reducer.q.out#L240&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;POSTHOOK: query: SELECT DEST2.* FROM DEST2
POSTHOOK: type: QUERY
POSTHOOK: Input: &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;@dest2
#### A masked pattern was here ####
{&lt;span class=&quot;code-quote&quot;&gt;&quot;0&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_0&quot;&lt;/span&gt;}	3
{&lt;span class=&quot;code-quote&quot;&gt;&quot;10&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_10&quot;&lt;/span&gt;}	1
{&lt;span class=&quot;code-quote&quot;&gt;&quot;100&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_100&quot;&lt;/span&gt;}	2
{&lt;span class=&quot;code-quote&quot;&gt;&quot;103&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_103&quot;&lt;/span&gt;}	2
{&lt;span class=&quot;code-quote&quot;&gt;&quot;104&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_104&quot;&lt;/span&gt;}	2
{&lt;span class=&quot;code-quote&quot;&gt;&quot;105&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_105&quot;&lt;/span&gt;}	1
{&lt;span class=&quot;code-quote&quot;&gt;&quot;11&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_11&quot;&lt;/span&gt;}	1
{&lt;span class=&quot;code-quote&quot;&gt;&quot;111&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_111&quot;&lt;/span&gt;}	1
{&lt;span class=&quot;code-quote&quot;&gt;&quot;113&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_113&quot;&lt;/span&gt;}	2
{&lt;span class=&quot;code-quote&quot;&gt;&quot;114&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;val_114&quot;&lt;/span&gt;}	1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14529690" author="prasanth_j" created="Wed, 6 May 2015 01:06:01 +0000"  >&lt;p&gt;The result difference seems to be an expected change because of hashcode difference. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=petersla&quot; class=&quot;user-hover&quot; rel=&quot;petersla&quot;&gt;petersla&lt;/a&gt; Can you put an updated patch by running the tests again with &quot;-Dtest.output.overwrite=true&quot; option? This will overwrite the q.out files.&lt;/p&gt;</comment>
                            <comment id="14529707" author="petersla" created="Wed, 6 May 2015 01:18:12 +0000"  >&lt;p&gt;Great, I&apos;ve been working on just that. I&apos;ll be able to posted an updated patch tomorrow.&lt;/p&gt;</comment>
                            <comment id="14529809" author="petersla" created="Wed, 6 May 2015 03:08:00 +0000"  >&lt;p&gt;I&apos;ve attached the second revision of the patch which updates failed Spark qtests.&lt;/p&gt;</comment>
                            <comment id="14532554" author="hiveqa" created="Thu, 7 May 2015 12:42:46 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12730695/HIVE-10538.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12730695/HIVE-10538.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 8907 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_cast_constant
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3796/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3796/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3796/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3796/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3796/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3796/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12730695 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14533288" author="prasanth_j" created="Thu, 7 May 2015 19:58:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=petersla&quot; class=&quot;user-hover&quot; rel=&quot;petersla&quot;&gt;petersla&lt;/a&gt; What JDK version were you using when you re-generated the out files? I am using 1.7.0_55 and I am getting the same output as reported by the precommit test.&lt;/p&gt;</comment>
                            <comment id="14533295" author="prasanth_j" created="Thu, 7 May 2015 20:05:11 +0000"  >&lt;p&gt;Precommit tests used jdk1.7.0_45.&lt;/p&gt;</comment>
                            <comment id="14533314" author="prasanth_j" created="Thu, 7 May 2015 20:20:19 +0000"  >&lt;p&gt;vector_cast_constant.q test case is updated. It now shows result similar to precommit run.&lt;/p&gt;</comment>
                            <comment id="14533347" author="prasanth_j" created="Thu, 7 May 2015 20:43:09 +0000"  >&lt;p&gt;Committed the lastest patch to master and branch-1.2. I re-ran the test using JDK 7 and it produces the same result for me as precommit test run.  &lt;br/&gt;
Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=petersla&quot; class=&quot;user-hover&quot; rel=&quot;petersla&quot;&gt;petersla&lt;/a&gt; for the patch and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt; for the review!&lt;/p&gt;</comment>
                            <comment id="14533450" author="petersla" created="Thu, 7 May 2015 21:47:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasanth_j&quot; class=&quot;user-hover&quot; rel=&quot;prasanth_j&quot;&gt;prasanth_j&lt;/a&gt;, Thanks for resolving that last failed test and getting this fix in.&lt;/p&gt;

&lt;p&gt;I was initially using Oracle&apos;s JDK 1.7.0_60, but didn&apos;t have luck with 1.7.0_45 either. I also tried the OpenJDK version I already had installed, 1.7.0_79.&lt;/p&gt;</comment>
                            <comment id="14548824" author="sushanth" created="Mon, 18 May 2015 19:52:01 +0000"  >&lt;p&gt;This issue has been fixed and released as part of the 1.2.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12730336" name="HIVE-10538.1.patch" size="12559" author="prasanth_j" created="Tue, 5 May 2015 00:28:33 +0000"/>
                            <attachment id="12730075" name="HIVE-10538.1.patch" size="12559" author="prasanth_j" created="Mon, 4 May 2015 00:26:45 +0000"/>
                            <attachment id="12729797" name="HIVE-10538.1.patch" size="12559" author="petersla" created="Fri, 1 May 2015 18:18:49 +0000"/>
                            <attachment id="12730695" name="HIVE-10538.2.patch" size="21595" author="petersla" created="Wed, 6 May 2015 03:08:00 +0000"/>
                            <attachment id="12731256" name="HIVE-10538.3.patch" size="19900" author="prasanth_j" created="Thu, 7 May 2015 20:20:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 27 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2e3rr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>