<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:29:43 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-8966] Delta files created by hive hcatalog streaming cannot be compacted</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8966</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;hive hcatalog streaming will also create a file like bucket_n_flush_length in each delta directory. Where &quot;n&quot; is the bucket number. But the compactor.CompactorMR think this file also needs to compact. However this file of course cannot be compacted, so compactor.CompactorMR will not continue to do the compaction. &lt;/p&gt;

&lt;p&gt;Did a test, after removed the bucket_n_flush_length file, then the &quot;alter table partition compact&quot; finished successfully. If don&apos;t delete that file, nothing will be compacted. &lt;br/&gt;
This is probably a very severity bug. Both 0.13 and 0.14 have this issue&lt;/p&gt;</description>
                <environment>&lt;p&gt;hive&lt;/p&gt;</environment>
        <key id="12757795">HIVE-8966</key>
            <summary>Delta files created by hive hcatalog streaming cannot be compacted</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gates">Alan Gates</assignee>
                                    <reporter username="jihongliu">Jihong Liu</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Nov 2014 20:32:53 +0000</created>
                <updated>Thu, 19 Feb 2015 18:22:01 +0000</updated>
                            <resolved>Tue, 27 Jan 2015 19:19:39 +0000</resolved>
                                    <version>0.14.0</version>
                                    <fixVersion>1.0.0</fixVersion>
                                    <component>HCatalog</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>10</watches>
                                                                                                                <comments>
                            <comment id="14226794" author="alangates" created="Wed, 26 Nov 2014 20:48:20 +0000"  >&lt;p&gt;This flush length file should be removed when the batch is closed.  Are you closing the transaction batch on a regular basis?&lt;/p&gt;</comment>
                            <comment id="14226872" author="jihongliu" created="Wed, 26 Nov 2014 22:08:43 +0000"  >&lt;p&gt;Yes. Closed the transaction batch. Suggest to do either the following two updates, or do both:&lt;/p&gt;

&lt;p&gt;1. if a file is non-bucket file, don&apos;t try to compact it. So update the following code:&lt;br/&gt;
   in org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.java&lt;br/&gt;
  Change the following code:&lt;/p&gt;

&lt;p&gt;  private void addFileToMap(Matcher matcher, Path file, boolean sawBase,&lt;br/&gt;
                              Map&amp;lt;Integer, BucketTracker&amp;gt; splitToBucketMap) {&lt;br/&gt;
      if (!matcher.find()) &lt;/p&gt;
{
        LOG.warn(&quot;Found a non-bucket file that we thought matched the bucket pattern! &quot; +
            file.toString());
      }

&lt;p&gt;   .....&lt;br/&gt;
 to:&lt;br/&gt;
   private void addFileToMap(Matcher matcher, Path file, boolean sawBase,&lt;br/&gt;
                              Map&amp;lt;Integer, BucketTracker&amp;gt; splitToBucketMap) {&lt;br/&gt;
      if (!matcher.find()) &lt;/p&gt;
{
        LOG.warn(&quot;Found a non-bucket file that we thought matched the bucket pattern! &quot; +
            file.toString());
        return;
      }
&lt;p&gt;     ....&lt;/p&gt;

&lt;p&gt;2. don&apos;t use the bucket file pattern to name to &quot;flush_length&quot; file. So update the following code:&lt;br/&gt;
  in org.apache.hadoop.hive.ql.io.orc.OrcRecordUpdater.java&lt;br/&gt;
 change the following code:&lt;br/&gt;
   static Path getSideFile(org.apache.tools.ant.types.Path main) &lt;/p&gt;
{
     return new Path(main + &quot;_flush_length&quot;);
   }

&lt;p&gt;to:&lt;br/&gt;
 static Path getSideFile(org.apache.tools.ant.types.Path main) {&lt;br/&gt;
	if (main.toString().startsWith(&quot;bucket_&quot;)) &lt;/p&gt;
{
	     return new Path(&quot;bkt&quot;+main.toString().substring(6)+ &quot;_flush_length&quot;);
	}
&lt;p&gt;              else return new Path(main + &quot;_flush_length&quot;);&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;after did the above updates and re-compiled the hive-exec.jar, the compaction works fine now&lt;/p&gt;</comment>
                            <comment id="14226890" author="alangates" created="Wed, 26 Nov 2014 22:19:10 +0000"  >&lt;p&gt;1 might be the right thing to do.  2 breaks backward compatibility.  Before we do that though I&apos;d like to understand why you still see the flush length files hanging around.  In my tests I don&apos;t see this issue because the flush length file is properly cleaned up.  I want to make sure that its existence doesn&apos;t mean something else is wrong.&lt;/p&gt;

&lt;p&gt;Do you see the flush length files in all delta directories or only the most recent?  &lt;/p&gt;</comment>
                            <comment id="14226925" author="jihongliu" created="Wed, 26 Nov 2014 22:43:34 +0000"  >&lt;p&gt;That flush_length file is only in the most recent delta. By the way, for streaming loading, a transaction batch is probably always open since data keeps coming. Is it possible to do compaction in the streaming loading environment? Thanks &lt;/p&gt;</comment>
                            <comment id="14226943" author="alangates" created="Wed, 26 Nov 2014 22:54:56 +0000"  >&lt;p&gt;Ok, that makes sense.  You&apos;re current delta has the file because it&apos;s still open and being written to.  It also explains why my tests don&apos;t see it, as they don&apos;t run long enough.  The streaming is always done by the time the compactor kicks in.  Why don&apos;t you post a patch to this JIRA with the change for 1, and I can get that committed.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hagleitn&quot; class=&quot;user-hover&quot; rel=&quot;hagleitn&quot;&gt;hagleitn&lt;/a&gt;, I&apos;d like to put this in 0.14.1 as well as trunk if you&apos;re ok with it, since it blocks compaction for users using the streaming interface.&lt;/p&gt;</comment>
                            <comment id="14227045" author="hagleitn" created="Thu, 27 Nov 2014 00:25:47 +0000"  >&lt;p&gt;+1 for 0.14.1&lt;/p&gt;</comment>
                            <comment id="14232306" author="jihongliu" created="Tue, 2 Dec 2014 23:41:12 +0000"  >&lt;p&gt;Thanks. So now the fix is in 0.14.1?&lt;/p&gt;</comment>
                            <comment id="14233768" author="jihongliu" created="Thu, 4 Dec 2014 01:27:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/i#browse/HIVE-8966&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/i#browse/HIVE-8966&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14233775" author="jihongliu" created="Thu, 4 Dec 2014 01:30:26 +0000"  >&lt;p&gt;Patch for HIVE08966&lt;/p&gt;</comment>
                            <comment id="14233790" author="jihongliu" created="Thu, 4 Dec 2014 01:40:05 +0000"  >&lt;p&gt;The patch is attached. Please review. Thanks&lt;/p&gt;</comment>
                            <comment id="14234769" author="jihongliu" created="Thu, 4 Dec 2014 23:11:34 +0000"  >&lt;p&gt;I think we may have to withdraw this patch for now. It looks like currently hive must not support doing compaction and loading in the same time for a partition. &lt;br/&gt;
Without this patch, if loading for a partition is not completely finished, compaction will always fail, so nothing happen. After apply this patch, compaction will go through and finish. However we may loss data! I did a test. Data could be lost if we do compaction meanwhile the loading is not finished yet. &lt;br/&gt;
But if keep the current version, it must be a limitation for hive. If streaming load to a partition for a long period, performance will be affected if cannot do compaction on it. &lt;/p&gt;

&lt;p&gt;For completely solve this issue, my initial thinking is that the delta files with open transaction should not be compacted. Currently they must be inlcuded, and it is probably the reason for data lost. But other closed delta files should be able to compact. So we can do compaction and loading in the same time.&lt;/p&gt;</comment>
                            <comment id="14235645" author="alangates" created="Fri, 5 Dec 2014 15:40:59 +0000"  >&lt;p&gt;Jihong, thanks for doing the testing on this.  &lt;/p&gt;

&lt;p&gt;We could change this to not compact the current delta file, or we could change the cleaner to not remove the delta file that was still open during compaction.  I&apos;ll try to look at this in the next couple of days.  We need to get this fixed for 0.14.1.&lt;/p&gt;</comment>
                            <comment id="14235923" author="jihongliu" created="Fri, 5 Dec 2014 19:07:24 +0000"  >&lt;p&gt;Great. I am working on that now. Will update you after finished the testing.&lt;/p&gt;</comment>
                            <comment id="14237046" author="jihongliu" created="Sun, 7 Dec 2014 04:41:34 +0000"  >&lt;p&gt;The scenario of data lost:&lt;br/&gt;
Assume when start compaction there are two deltas, delta_00011_00020 and delta_00021_00030, where the transaction batch in the first one is closed, and the second one still has transaction batch open. After compaction is finished, the status in compaction_ queue  will become &#8220;ready_for_clean&#8221;. Then clean process will be triggered. Cleaner will remove all deltas if its transaction id is less than the base which just created and if there is no lock on it. In the meantime, we still load data into the second delta. When finish loading and close the transaction batch, cleaner detects no lock on that, so delete it. So the new data added after compaction will be lost. &lt;/p&gt;</comment>
                            <comment id="14237047" author="jihongliu" created="Sun, 7 Dec 2014 04:42:48 +0000"  >&lt;p&gt;Solution: &lt;br/&gt;
if the last delta has any file which is in bucket file pattern, but actually is non bucket file, don&#8217;t compact this delta. When a transaction is not close, a delta will have a file like bucket_n_flash_length, which is non bucket file. Actually for any reason, if the last delta has a file with bucket file pattern but not compactable, we should ignore this delta. Since after compaction, the delta will be removed. So if the whole delta cannot be compacted, leave it as what it is. So in the above scenario, the second delta will not be compacted. And the cleaner will not remove it because it has higher transaction id than the new created compaction file(base or delta). &lt;br/&gt;
The reason we only do the above for the last delta is to consider the case that two or more transaction batches may be created and the last one is close first. Then if the last delta gets compacted, the transaction id in the base will be big, so all deltas will be removed by cleaner. So data could be lost. In this case, in the list of deltas for compaction, at least one delta has that bucket_n_flash_length file inside. Since we do not ignore it, the compaction will be auto-fail, so nothing happen, no data lost. In this case, the compaction can only be done after all transaction batches are closed. Although it is not so good, at least no data lost.&lt;br/&gt;
The patch is attached. It adds one method to test whether needs to remove the last delta from the delta list. And before process the delta list, run that method.  After applying this patch, no data is lost. We can do either major or minor compaction meanwhile keeping loading data in the same time.&lt;/p&gt;</comment>
                            <comment id="14237048" author="jihongliu" created="Sun, 7 Dec 2014 04:43:23 +0000"  >&lt;p&gt;By the way, hive may need another cleaning process which auto removes the bucket_n_flash_length file if the connection is actually closed.  A program may not be able to close a transaction batch, due to many reasons, for example, network disconnected, server shutdown, application killed, and etc. So if the connection which creates a batch has been closed, that bucket_n_flash_length file needs to be removed. Otherwise that delta and the deltas after it can never be compacted unless we remove that file manually.&lt;/p&gt;</comment>
                            <comment id="14237057" author="hiveqa" created="Sun, 7 Dec 2014 05:07:41 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12685584/HIVE-8966.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12685584/HIVE-8966.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1985/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1985/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1985/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1985/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1985/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1985/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-1985/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java&apos;
Reverted &apos;common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/scheduler/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit-hadoop2/target itests/hive-minikdc/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/core/target hcatalog/streaming/target hcatalog/server-extensions/target hcatalog/hcatalog-pig-adapter/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target accumulo-handler/target hwi/target common/target common/src/gen common/src/java/org/apache/hadoop/hive/conf/HiveConf.java.orig contrib/target service/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target ql/src/test/results/clientpositive/parquet_array_of_multi_field_struct_gen_schema.q.out ql/src/test/results/clientpositive/parquet_decimal_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_unannotated_groups_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_single_field_struct_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_unannotated_primitives_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_structs_gen_schema.q.out ql/src/test/results/clientpositive/parquet_avro_array_of_primitives_gen_schema.q.out ql/src/test/results/clientpositive/parquet_thrift_array_of_single_field_struct_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_optional_elements_gen_schema.q.out ql/src/test/results/clientpositive/parquet_avro_array_of_single_field_struct_gen_schema.q.out ql/src/test/results/clientpositive/parquet_thrift_array_of_primitives_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_structs_gen_schema_ext.q.out ql/src/test/results/clientpositive/parquet_array_of_required_elements_gen_schema.q.out ql/src/test/queries/clientpositive/parquet_avro_array_of_single_field_struct_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_single_field_struct_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_structs_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_multi_field_struct_gen_schema.q ql/src/test/queries/clientpositive/parquet_thrift_array_of_primitives_gen_schema.q ql/src/test/queries/clientpositive/parquet_thrift_array_of_single_field_struct_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_required_elements_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_unannotated_groups_gen_schema.q ql/src/test/queries/clientpositive/parquet_avro_array_of_primitives_gen_schema.q ql/src/test/queries/clientpositive/parquet_decimal_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_structs_gen_schema_ext.q ql/src/test/queries/clientpositive/parquet_array_of_optional_elements_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_unannotated_primitives_gen_schema.q ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java.orig ql/src/java/org/apache/hadoop/hive/ql/io/parquet/convert/ParquetSchemaReader.java ql/src/java/org/apache/hadoop/hive/ql/io/parquet/convert/ParquetToHiveSchemaConverter.java
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1643648.

At revision 1643648.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12685584 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14237062" author="jihongliu" created="Sun, 7 Dec 2014 05:34:41 +0000"  >&lt;p&gt;Hi Alan,I have created a new patch. It works fine. The patch is pasted in that jira, also added comment about the logic. Please have a look.&#160;Thanks and have a good dayJihong&lt;br/&gt;
      From: Alan Gates (JIRA) &amp;lt;jira@apache.org&amp;gt;&#160;&lt;br/&gt;
 To: jhliu08@yahoo.com &lt;br/&gt;
 Sent: Friday, December 5, 2014 7:41 AM&lt;br/&gt;
 Subject: &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Commented&amp;#93;&lt;/span&gt; (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8966&quot; title=&quot;Delta files created by hive hcatalog streaming cannot be compacted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8966&quot;&gt;&lt;del&gt;HIVE-8966&lt;/del&gt;&lt;/a&gt;) Delta files created by hive hcatalog streaming cannot be compacted&lt;/p&gt;


&lt;p&gt;&#160; &#160; [ &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8966?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=14235645#comment-14235645&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-8966?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=14235645#comment-14235645&lt;/a&gt; ] &lt;/p&gt;

&lt;p&gt;Alan Gates commented on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8966&quot; title=&quot;Delta files created by hive hcatalog streaming cannot be compacted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8966&quot;&gt;&lt;del&gt;HIVE-8966&lt;/del&gt;&lt;/a&gt;:&lt;br/&gt;
----------------------------------&lt;/p&gt;

&lt;p&gt;Jihong, thanks for doing the testing on this.&#160; &lt;/p&gt;

&lt;p&gt;We could change this to not compact the current delta file, or we could change the cleaner to not remove the delta file that was still open during compaction.&#160; I&apos;ll try to look at this in the next couple of days.&#160; We need to get this fixed for 0.14.1.&lt;/p&gt;




&lt;p&gt;&amp;#8211;&lt;br/&gt;
This message was sent by Atlassian JIRA&lt;br/&gt;
(v6.3.4#6332)&lt;/p&gt;

</comment>
                            <comment id="14237067" author="jihongliu" created="Sun, 7 Dec 2014 06:04:49 +0000"  >&lt;p&gt;Alan,&lt;br/&gt;
I created a wrong patch about 1 hour ago. Before I removed it. QA automatically did the above test. Please ignore and look the current attached patch. I think it really solves the issue.&lt;/p&gt;</comment>
                            <comment id="14237080" author="hiveqa" created="Sun, 7 Dec 2014 06:49:05 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12685590/HIVE-8966.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12685590/HIVE-8966.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6696 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1986/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1986/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1986/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1986/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1986/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1986/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12685590 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14237257" author="jihongliu" created="Sun, 7 Dec 2014 20:00:54 +0000"  >&lt;p&gt;I am confused about the QA test. The error looks like not related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8966&quot; title=&quot;Delta files created by hive hcatalog streaming cannot be compacted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8966&quot;&gt;&lt;del&gt;HIVE-8966&lt;/del&gt;&lt;/a&gt;.patch. First, was this patch really included in the build? Also this patch is for 0.14.1, not for trunk.&lt;/p&gt;</comment>
                            <comment id="14239636" author="alangates" created="Tue, 9 Dec 2014 16:45:29 +0000"  >&lt;p&gt;Don&apos;t worry about the results from testing, those tests are flaky.  I&apos;ll review the patch.&lt;/p&gt;</comment>
                            <comment id="14239750" author="alangates" created="Tue, 9 Dec 2014 17:59:50 +0000"  >&lt;p&gt;Rather than go remove these directories from the list of deltas I think it makes more sense to change Directory.getAcidState to not include these deltas.  We obviously can&apos;t do that in all cases, as readers need to see these deltas. But we can change it to see that this is the compactor and therefore those should be excluded.  I&apos;ll post a patch with this change.&lt;/p&gt;</comment>
                            <comment id="14240004" author="jihongliu" created="Tue, 9 Dec 2014 20:25:27 +0000"  >&lt;p&gt;I see. Basically there are two solutions. One is that when get the delta list, we don&apos;t include the current delta if it has open tranaction. So uptate the AcidUtil.getAcidState() directly. The other is what I posted here. We first get the delta list, then when do compaction, we don&apos;t compact the last one if there is open transaction. The first solution is better as long as changing getAcidState() doesn&apos;t affact other existing code, since it is a public static method. &lt;br/&gt;
By the way, we should only do that to the current delta (the delta with the largest transaction id), not to all deltas which have open transactions. If I am correct, the base file will be named based on the largest transaction id in the deltas. So if the latest delta is closed, but an early delta has an open transaction, we should not do anything. So simply let the compaction fail. Otherwise, the base will be named by the last transaction id, and all early deltas will be removed. That will cause data lost. This is my understanding, please correct me, it it is not correct. Thanks&lt;/p&gt;</comment>
                            <comment id="14240259" author="alangates" created="Tue, 9 Dec 2014 23:15:32 +0000"  >&lt;p&gt;A new version of the patch that moves Jihong&apos;s code into AcidUtils.getAcidState so that delta directories with flush length files are not put into the list of files to compact.  &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jihongliu&quot; class=&quot;user-hover&quot; rel=&quot;jihongliu&quot;&gt;jihongliu&lt;/a&gt;, could you test this on your end to make sure it addresses your issues.  I&apos;ll also do some long running tests to see that it allows compaction while streaming is ongoing.&lt;/p&gt;</comment>
                            <comment id="14240415" author="owen.omalley" created="Wed, 10 Dec 2014 00:43:23 +0000"  >&lt;p&gt;Alan, your patch looks good +1&lt;/p&gt;</comment>
                            <comment id="14240482" author="hiveqa" created="Wed, 10 Dec 2014 01:36:17 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12686124/HIVE-8966.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12686124/HIVE-8966.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6704 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx_cbo_1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2013/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2013/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2013/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2013/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2013/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2013/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12686124 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14240701" author="jihongliu" created="Wed, 10 Dec 2014 06:00:07 +0000"  >&lt;p&gt;Alan,&lt;br/&gt;
Your idea is very good. But there is an issue here &amp;#8211; we should only do this &quot;compacting&quot; test for the most recent delta, not for all deltas. Following is an example for the reason:&lt;br/&gt;
Assume there are two deltas:&lt;br/&gt;
   1  delta_00011_00020    this delta has open transaction batch&lt;br/&gt;
   2  delta_00021_00030    this delta has no open transaction batch. All closed.&lt;/p&gt;

&lt;p&gt;In the above, the first delta has open transaction batch, the second has not. And the second delta is the most recent delta. This case is possible, especially when multiple threads write to the same partition. If we ignore the first one, then the compaction will success and create a base, like base_00030. Then cleaner will delete all the two deltas since their transaction id are less or equal to the base transaction id. Thus the data in delta 2 will be lost. This is why we should only test the most recent delta, all other deltas will be automatically in the list. Thus in this case, the compaction will be fail, since the &quot;flush_length&quot; file is there. And for this case, the compaction will be success only when all transaction batchs are closed. Although it is not perfect, at least no data lost. Since each delta file and transaction id for compaction is not saved anywhere, probably this is the only solution for now. &lt;br/&gt;
In my removeNotCompactableDeltas() method, we first sort the deltas, then only check the last one. But the name: &quot;removeNotCompactableDeltas&quot; is not good, easy makes confusion. It will be clear if named it as &quot;removeLastDeltaIfNotCompactable&quot;. &lt;br/&gt;
Thanks&lt;/p&gt;</comment>
                            <comment id="14241394" author="alangates" created="Wed, 10 Dec 2014 17:11:24 +0000"  >&lt;p&gt;Right, makes sense.  I need to think about whether it makes more sense to change AcidUtils.getAcidState to catch this as well or whether your approach of post processing it in the compactor makes more sense.&lt;/p&gt;</comment>
                            <comment id="14256032" author="alangates" created="Mon, 22 Dec 2014 18:43:59 +0000"  >&lt;p&gt;A new version of the patch which properly handles not putting any deltas in the list once we see a delta with a flush length file.  Unfortunately, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;owen.omalley&lt;/a&gt; who needs to review this is out for a couple of weeks.  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jihongliu&quot; class=&quot;user-hover&quot; rel=&quot;jihongliu&quot;&gt;jihongliu&lt;/a&gt;, please take a look at this and test it in your environment.&lt;/p&gt;</comment>
                            <comment id="14256700" author="hiveqa" created="Tue, 23 Dec 2014 07:28:53 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12688699/HIVE-8966.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12688699/HIVE-8966.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6724 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_lvj_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2168/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2168/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2168/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2168/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2168/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2168/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12688699 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14264177" author="jihongliu" created="Mon, 5 Jan 2015 04:43:52 +0000"  >&lt;p&gt;Did a test. Generally the new version works as expected. But for the following case, the compaction will always fail:&lt;/p&gt;

&lt;p&gt;1. due to any reason, the writer exits without closing a batch. So the &quot;length&quot; file is still there. This could happen, for example the program is killed, hive/server restarts.&lt;br/&gt;
2. restart the program, so a new writer and a new batch is created and continute to write into the same partition. The data will go to a new delta.&lt;br/&gt;
3. Now we manually delete that &quot;length&quot; file in the previous delta. Then do compaction, but it fails. Even we totally exit the program so that no any open batch and no any &quot;length&quot; file, the compaction will never success for this partition. &lt;/p&gt;

&lt;p&gt;However the current hive 14.0 will work fine for the above case.&lt;/p&gt;</comment>
                            <comment id="14265257" author="alangates" created="Mon, 5 Jan 2015 22:41:03 +0000"  >&lt;p&gt;What error message does it give when it fails?  I would expect this to work.&lt;/p&gt;</comment>
                            <comment id="14266854" author="jihongliu" created="Tue, 6 Jan 2015 22:03:49 +0000"  >&lt;p&gt;The error occur when doing the mapreduce job. Following is log in hivemetastore.log&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:22,506 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: compactor.Worker (Worker.java:run(137)) - Starting MAJOR compaction for ds_infra.event_metrics.date=2014-12-24&lt;br/&gt;
2015-01-06 16:42:22,564 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: impl.TimelineClientImpl (TimelineClientImpl.java:serviceInit(285)) - Timeline service address: &lt;a href=&quot;http://sfdmgctmn003.gid.gap.com:8188/ws/v1/timeline/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://sfdmgctmn003.gid.gap.com:8188/ws/v1/timeline/&lt;/a&gt;&lt;br/&gt;
2015-01-06 16:42:22,622 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: impl.TimelineClientImpl (TimelineClientImpl.java:serviceInit(285)) - Timeline service address: &lt;a href=&quot;http://sfdmgctmn003.gid.gap.com:8188/ws/v1/timeline/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://sfdmgctmn003.gid.gap.com:8188/ws/v1/timeline/&lt;/a&gt;&lt;br/&gt;
2015-01-06 16:42:22,628 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(153)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.&lt;br/&gt;
2015-01-06 16:42:22,753 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: split.JobSplitWriter (JobSplitWriter.java:writeOldSplits(168)) - Max block location exceeded for split: CompactorInputSplit&lt;/p&gt;
{base: hdfs://sfdmgct/apps/hive/warehouse/ds_infra/event_metrics/date=2014-12-24/base_0035304, bucket: 1, length: 292280, deltas: [delta_0035311_0035313, delta_0035479_0035481, delta_0035491_0035493, delta_0035515_0035517, delta_0035533_0035535, delta_0035548_0035550, delta_0035563_0035565, delta_0035578_0035580, delta_0035593_0035595, delta_0035599_0035601, delta_0035656_0035658, delta_0035671_0035673, delta_0035686_0035688, delta_0035701_0035703, delta_0035716_0035718, delta_0035731_0035733, delta_0035746_0035748, delta_0035761_0035763, delta_0035776_0035778, delta_0035791_0035793, delta_0035806_0035808, delta_0035821_0035823, delta_0035830_0035832, delta_0035842_0035844, delta_0035854_0035856, delta_0035866_0035868, delta_0035878_0035880]}
&lt;p&gt; splitsize: 27 maxsize: 10&lt;br/&gt;
2015-01-06 16:42:22,753 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: split.JobSplitWriter (JobSplitWriter.java:writeOldSplits(168)) - Max block location exceeded for split: CompactorInputSplit&lt;/p&gt;
{base: null, bucket: 3, length: 199770, deltas: [delta_0035311_0035313, delta_0035479_0035481, delta_0035491_0035493, delta_0035515_0035517, delta_0035533_0035535, delta_0035548_0035550, delta_0035563_0035565, delta_0035578_0035580, delta_0035593_0035595, delta_0035599_0035601, delta_0035656_0035658, delta_0035671_0035673, delta_0035686_0035688, delta_0035701_0035703, delta_0035716_0035718, delta_0035731_0035733, delta_0035746_0035748, delta_0035761_0035763, delta_0035776_0035778, delta_0035791_0035793, delta_0035806_0035808, delta_0035821_0035823, delta_0035830_0035832, delta_0035842_0035844, delta_0035854_0035856, delta_0035866_0035868, delta_0035878_0035880]}
&lt;p&gt; splitsize: 21 maxsize: 10&lt;br/&gt;
2015-01-06 16:42:22,753 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: split.JobSplitWriter (JobSplitWriter.java:writeOldSplits(168)) - Max block location exceeded for split: CompactorInputSplit&lt;/p&gt;
{base: hdfs://sfdmgct/apps/hive/warehouse/ds_infra/event_metrics/date=2014-12-24/base_0035304, bucket: 0, length: 172391, deltas: [delta_0035311_0035313, delta_0035479_0035481, delta_0035491_0035493, delta_0035515_0035517, delta_0035533_0035535, delta_0035548_0035550, delta_0035563_0035565, delta_0035578_0035580, delta_0035593_0035595, delta_0035599_0035601, delta_0035656_0035658, delta_0035671_0035673, delta_0035686_0035688, delta_0035701_0035703, delta_0035716_0035718, delta_0035731_0035733, delta_0035746_0035748, delta_0035761_0035763, delta_0035776_0035778, delta_0035791_0035793, delta_0035806_0035808, delta_0035821_0035823, delta_0035830_0035832, delta_0035842_0035844, delta_0035854_0035856, delta_0035866_0035868, delta_0035878_0035880]}
&lt;p&gt; splitsize: 30 maxsize: 10&lt;br/&gt;
2015-01-06 16:42:22,777 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(494)) - number of splits:4&lt;br/&gt;
2015-01-06 16:42:22,793 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(583)) - Submitting tokens for job: job_1419291043936_1639&lt;br/&gt;
2015-01-06 16:42:23,000 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(251)) - Submitted application application_1419291043936_1639&lt;br/&gt;
2015-01-06 16:42:23,001 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:submit(1300)) - The url to track the job: &lt;a href=&quot;http://sfdmgctmn002.gid.gap.com:8088/proxy/application_1419291043936_1639/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://sfdmgctmn002.gid.gap.com:8088/proxy/application_1419291043936_1639/&lt;/a&gt;&lt;br/&gt;
2015-01-06 16:42:23,001 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1345)) - Running job: job_1419291043936_1639&lt;br/&gt;
2015-01-06 16:42:30,042 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1366)) - Job job_1419291043936_1639 running in uber mode : false&lt;br/&gt;
2015-01-06 16:42:30,043 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1373)) -  map 0% reduce 0%&lt;br/&gt;
2015-01-06 16:42:35,066 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:printTaskEvents(1452)) - Task Id : attempt_1419291043936_1639_m_000002_0, Status : FAILED&lt;br/&gt;
2015-01-06 16:42:37,078 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1373)) -  map 75% reduce 0%&lt;br/&gt;
2015-01-06 16:42:41,091 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:printTaskEvents(1452)) - Task Id : attempt_1419291043936_1639_m_000002_1, Status : FAILED&lt;br/&gt;
2015-01-06 16:42:45,105 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:printTaskEvents(1452)) - Task Id : attempt_1419291043936_1639_m_000002_2, Status : FAILED&lt;br/&gt;
2015-01-06 16:42:52,124 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1373)) -  map 100% reduce 0%&lt;br/&gt;
2015-01-06 16:42:52,130 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1386)) - Job job_1419291043936_1639 failed with state FAILED due to: Task failed task_1419291043936_1639_m_000002&lt;br/&gt;
Job failed as tasks failed. failedMaps:1 failedReduces:0&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:52,149 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1391)) - Counters: 32&lt;br/&gt;
        File System Counters&lt;br/&gt;
                FILE: Number of bytes read=0&lt;br/&gt;
                FILE: Number of bytes written=668781&lt;br/&gt;
                FILE: Number of read operations=0&lt;br/&gt;
                FILE: Number of large read operations=0&lt;br/&gt;
                FILE: Number of write operations=0&lt;br/&gt;
                HDFS: Number of bytes read=840325&lt;br/&gt;
                HDFS: Number of bytes written=405818&lt;br/&gt;
                HDFS: Number of read operations=243&lt;br/&gt;
                HDFS: Number of large read operations=0&lt;br/&gt;
                HDFS: Number of write operations=3&lt;br/&gt;
        Job Counters&lt;br/&gt;
                Failed map tasks=4&lt;br/&gt;
                Launched map tasks=7&lt;br/&gt;
                Other local map tasks=3&lt;br/&gt;
                Data-local map tasks=4&lt;br/&gt;
                Total time spent by all maps in occupied slots (ms)=32359&lt;br/&gt;
                Total time spent by all reduces in occupied slots (ms)=0&lt;br/&gt;
                Total time spent by all map tasks (ms)=32359&lt;br/&gt;
                Total vcore-seconds taken by all map tasks=32359&lt;br/&gt;
                Total megabyte-seconds taken by all map tasks=463898624&lt;br/&gt;
        Map-Reduce Framework&lt;br/&gt;
                Map input records=3&lt;br/&gt;
                Map output records=0&lt;br/&gt;
                Input split bytes=10663&lt;br/&gt;
                Spilled Records=0&lt;br/&gt;
                Failed Shuffles=0&lt;br/&gt;
                Merged Map outputs=0&lt;br/&gt;
                GC time elapsed (ms)=153&lt;br/&gt;
                CPU time spent (ms)=7680&lt;br/&gt;
                Physical memory (bytes) snapshot=1065402368&lt;br/&gt;
                Virtual memory (bytes) snapshot=39759937536&lt;br/&gt;
                Total committed heap usage (bytes)=6714032128&lt;br/&gt;
        File Input Format Counters&lt;br/&gt;
                Bytes Read=0&lt;br/&gt;
        File Output Format Counters&lt;br/&gt;
                Bytes Written=0&lt;br/&gt;
2015-01-06 16:42:52,150 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: compactor.Worker (Worker.java:run(159)) - Caught exception while trying to compact ds_infra.event_metrics.date=2014-12-24.  Marking clean to avoid repeated failures, java.io.IOException: Job failed!&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:836)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.run(CompactorMR.java:184)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.txn.compactor.Worker.run(Worker.java:145)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:52,150 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: txn.CompactionTxnHandler (CompactionTxnHandler.java:markCleaned(327)) - Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!&lt;/p&gt;



&lt;p&gt;--------------------------------------------------------------------------------------------------------------------------------&lt;br/&gt;
following is mapreduce job log. Got the log from uri mentioned in the above log:  (&lt;a href=&quot;http://sfdmgctmn002.gid.gap.com:8088/proxy/application_1419291043936_1639/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://sfdmgctmn002.gid.gap.com:8088/proxy/application_1419291043936_1639/&lt;/a&gt;)&lt;/p&gt;


&lt;p&gt;2015-01-06 16:42:25,991 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1419291043936_1639_000001&lt;br/&gt;
2015-01-06 16:42:26,304 WARN &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable&lt;br/&gt;
2015-01-06 16:42:26,314 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:&lt;br/&gt;
2015-01-06 16:42:26,314 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id &lt;/p&gt;
{ id: 1639 cluster_timestamp: 1419291043936 }
&lt;p&gt; attemptId: 1 } keyId: -950898635)&lt;br/&gt;
2015-01-06 16:42:26,842 WARN &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.&lt;br/&gt;
2015-01-06 16:42:26,919 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorOutputCommitter&lt;br/&gt;
2015-01-06 16:42:26,921 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorOutputCommitter&lt;br/&gt;
2015-01-06 16:42:26,951 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler&lt;br/&gt;
2015-01-06 16:42:26,951 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher&lt;br/&gt;
2015-01-06 16:42:26,952 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher&lt;br/&gt;
2015-01-06 16:42:26,952 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher&lt;br/&gt;
2015-01-06 16:42:26,952 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler&lt;br/&gt;
2015-01-06 16:42:26,956 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher&lt;br/&gt;
2015-01-06 16:42:26,956 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter&lt;br/&gt;
2015-01-06 16:42:26,957 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter&lt;br/&gt;
2015-01-06 16:42:26,975 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring&lt;br/&gt;
2015-01-06 16:42:26,987 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring&lt;br/&gt;
2015-01-06 16:42:26,999 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring&lt;br/&gt;
2015-01-06 16:42:27,023 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled&lt;br/&gt;
2015-01-06 16:42:27,050 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler&lt;br/&gt;
2015-01-06 16:42:27,191 WARN &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.metrics2.impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-mrappmaster.properties,hadoop-metrics2.properties&lt;br/&gt;
2015-01-06 16:42:27,232 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).&lt;br/&gt;
2015-01-06 16:42:27,232 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started&lt;br/&gt;
2015-01-06 16:42:27,239 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for job_1419291043936_1639 to jobTokenSecretManager&lt;br/&gt;
2015-01-06 16:42:27,327 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing job_1419291043936_1639 because: not enabled;&lt;br/&gt;
2015-01-06 16:42:27,340 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job job_1419291043936_1639 = 845156. Number of splits = 4&lt;br/&gt;
2015-01-06 16:42:27,341 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job job_1419291043936_1639 = 0&lt;br/&gt;
2015-01-06 16:42:27,341 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1419291043936_1639Job Transitioned from NEW to INITED&lt;br/&gt;
2015-01-06 16:42:27,341 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job job_1419291043936_1639.&lt;br/&gt;
2015-01-06 16:42:27,359 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue&lt;br/&gt;
2015-01-06 16:42:27,366 INFO &lt;a href=&quot;#1 for port 57524&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Socket Reader #1 for port 57524&lt;/a&gt; org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 57524&lt;br/&gt;
2015-01-06 16:42:27,379 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server&lt;br/&gt;
2015-01-06 16:42:27,380 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server Responder&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: IPC Server Responder: starting&lt;br/&gt;
2015-01-06 16:42:27,381 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server listener on 57524&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: IPC Server listener on 57524: starting&lt;br/&gt;
2015-01-06 16:42:27,381 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at sfdmgctsn004.gid.gap.com/10.9.21.134:57524&lt;br/&gt;
2015-01-06 16:42:27,429 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog&lt;br/&gt;
2015-01-06 16:42:27,431 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined&lt;br/&gt;
2015-01-06 16:42:27,439 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: Added global filter &apos;safety&apos; (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)&lt;br/&gt;
2015-01-06 16:42:27,472 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce&lt;br/&gt;
2015-01-06 16:42:27,472 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static&lt;br/&gt;
2015-01-06 16:42:27,475 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: adding path spec: /mapreduce/*&lt;br/&gt;
2015-01-06 16:42:27,475 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*&lt;br/&gt;
2015-01-06 16:42:27,482 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: Jetty bound to port 45674&lt;br/&gt;
2015-01-06 16:42:27,482 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.mortbay.log: jetty-6.1.26.hwx&lt;br/&gt;
2015-01-06 16:42:27,505 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.mortbay.log: Extract jar:&lt;a href=&quot;file:/data/sfdmgct05/hadoop/yarn/local/filecache/12/mapreduce.tar.gz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar!/webapps/mapreduce&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:/data/sfdmgct05/hadoop/yarn/local/filecache/12/mapreduce.tar.gz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar!/webapps/mapreduce&lt;/a&gt; to /tmp/Jetty_0_0_0_0_45674_mapreduce____.ycambd/webapp&lt;br/&gt;
2015-01-06 16:42:27,805 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:45674&lt;br/&gt;
2015-01-06 16:42:27,806 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.webapp.WebApps: Web app /mapreduce started at 45674&lt;br/&gt;
2015-01-06 16:42:28,026 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules&lt;br/&gt;
2015-01-06 16:42:28,029 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: JOB_CREATE job_1419291043936_1639&lt;br/&gt;
2015-01-06 16:42:28,030 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue&lt;br/&gt;
2015-01-06 16:42:28,030 INFO &lt;a href=&quot;#1 for port 33406&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 33406&lt;br/&gt;
2015-01-06 16:42:28,034 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server Responder&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: IPC Server Responder: starting&lt;br/&gt;
2015-01-06 16:42:28,034 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server listener on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: IPC Server listener on 33406: starting&lt;br/&gt;
2015-01-06 16:42:28,074 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true&lt;br/&gt;
2015-01-06 16:42:28,075 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3&lt;br/&gt;
2015-01-06 16:42:28,075 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33&lt;br/&gt;
2015-01-06 16:42:28,158 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: maxContainerCapability: &amp;lt;memory:186368, vCores:32&amp;gt;&lt;br/&gt;
2015-01-06 16:42:28,158 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: queue: default&lt;br/&gt;
2015-01-06 16:42:28,160 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500&lt;br/&gt;
2015-01-06 16:42:28,161 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0&lt;br/&gt;
2015-01-06 16:42:28,165 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1419291043936_1639Job Transitioned from INITED to SETUP&lt;br/&gt;
2015-01-06 16:42:28,167 INFO &lt;a href=&quot;#0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CommitterEvent Processor #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_SETUP&lt;br/&gt;
2015-01-06 16:42:28,168 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1419291043936_1639Job Transitioned from SETUP to RUNNING&lt;br/&gt;
2015-01-06 16:42:28,182 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,186 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,188 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,191 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:28,194 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000000 Task Transitioned from NEW to SCHEDULED&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000001 Task Transitioned from NEW to SCHEDULED&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000002 Task Transitioned from NEW to SCHEDULED&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000003 Task Transitioned from NEW to SCHEDULED&lt;br/&gt;
2015-01-06 16:42:28,200 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:28,200 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000001_0 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:28,200 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:28,200 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000003_0 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:28,201 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: mapResourceRequest:&amp;lt;memory:14336, vCores:1&amp;gt;&lt;br/&gt;
2015-01-06 16:42:28,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1419291043936_1639, File: hdfs://sfdmgct:8020/user/hive/.staging/job_1419291043936_1639/job_1419291043936_1639_1.jhist&lt;br/&gt;
2015-01-06 16:42:29,160 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:4 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:29,181 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=8 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:458752, vCores:79&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:30,189 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 4&lt;br/&gt;
2015-01-06 16:42:30,190 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000002 to attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:30,191 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000003 to attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:30,191 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000004 to attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:30,191 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000005 to attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:30,191 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:30,217 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:30,227 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-jar file on the remote FS is hdfs://sfdmgct/user/hive/.staging/job_1419291043936_1639/job.jar&lt;br/&gt;
2015-01-06 16:42:30,229 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-conf file on the remote FS is /user/hive/.staging/job_1419291043936_1639/job.xml&lt;br/&gt;
2015-01-06 16:42:30,231 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container&lt;br/&gt;
2015-01-06 16:42:30,231 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Size of containertokens_dob is 1&lt;br/&gt;
2015-01-06 16:42:30,231 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Putting shuffle token in serviceData&lt;br/&gt;
2015-01-06 16:42:30,247 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:30,248 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:30,248 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:30,249 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:30,249 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:30,249 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:30,250 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000003_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:30,251 INFO &lt;a href=&quot;#0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000002 taskAttempt attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:30,251 INFO &lt;a href=&quot;#1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000003 taskAttempt attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:30,251 INFO &lt;a href=&quot;#2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000004 taskAttempt attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:30,251 INFO &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000005 taskAttempt attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:30,252 INFO &lt;a href=&quot;#2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:30,252 INFO &lt;a href=&quot;#1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:30,252 INFO &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:30,252 INFO &lt;a href=&quot;#0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:30,253 INFO &lt;a href=&quot;#2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:30,266 INFO &lt;a href=&quot;#0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:30,267 INFO &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:30,267 INFO &lt;a href=&quot;#1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:30,294 INFO &lt;a href=&quot;#2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000002_0 : 13562&lt;br/&gt;
2015-01-06 16:42:30,294 INFO &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000003_0 : 13562&lt;br/&gt;
2015-01-06 16:42:30,294 INFO &lt;a href=&quot;#0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000000_0 : 13562&lt;br/&gt;
2015-01-06 16:42:30,294 INFO &lt;a href=&quot;#1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000001_0 : 13562&lt;br/&gt;
2015-01-06 16:42:30,295 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000000_0&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000002 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn004.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:30,297 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,297 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000003_0&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000005 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn004.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:30,297 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000003_0 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,297 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000002_0&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000004 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn004.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:30,298 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,298 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000001_0&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000003 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn004.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:30,298 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000001_0 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,298 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000000 Task Transitioned from SCHEDULED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,298 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000003 Task Transitioned from SCHEDULED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,299 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000002 Task Transitioned from SCHEDULED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,299 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000001 Task Transitioned from SCHEDULED to RUNNING&lt;br/&gt;
2015-01-06 16:42:31,194 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=8 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:401408, vCores:75&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:33,555 INFO &lt;a href=&quot;#1 for port 33406&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:33,572 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 0 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000002 asked for a task&lt;br/&gt;
2015-01-06 16:42:33,572 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 0 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000002 given task: attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:33,587 INFO &lt;a href=&quot;#1 for port 33406&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:33,596 INFO &lt;a href=&quot;#1 for port 33406&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:33,601 INFO &lt;a href=&quot;#1 for port 33406&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:33,602 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000005 asked for a task&lt;br/&gt;
2015-01-06 16:42:33,602 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000005 given task: attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:33,607 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 2 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000003 asked for a task&lt;br/&gt;
2015-01-06 16:42:33,607 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 2 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000003 given task: attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:33,612 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 3 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000004 asked for a task&lt;br/&gt;
2015-01-06 16:42:33,612 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 3 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000004 given task: attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:35,010 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000002_0 is : 0.0&lt;br/&gt;
2015-01-06 16:42:35,014 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 5 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1419291043936_1639_m_000002_0 - exited : java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:35,014 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 5 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_0: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:35,016 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_0: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:35,016 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:35,017 INFO &lt;a href=&quot;#4&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #4&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000004 taskAttempt attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:35,017 INFO &lt;a href=&quot;#4&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #4&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:35,017 INFO &lt;a href=&quot;#4&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #4&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:35,029 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP&lt;br/&gt;
2015-01-06 16:42:35,030 INFO &lt;a href=&quot;#1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CommitterEvent Processor #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT&lt;br/&gt;
2015-01-06 16:42:35,031 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node sfdmgctsn004.gid.gap.com&lt;br/&gt;
2015-01-06 16:42:35,036 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:35,037 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1419291043936_1639_m_000002_1 to list of failed maps&lt;br/&gt;
2015-01-06 16:42:35,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:35,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:401408, vCores:75&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:35,697 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000001_0 is : 0.0&lt;br/&gt;
2015-01-06 16:42:35,734 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 5 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000003_0 is : 0.0&lt;br/&gt;
2015-01-06 16:42:35,833 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 6 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000000_0 is : 0.0&lt;br/&gt;
2015-01-06 16:42:35,896 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 7 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000001_0 is : 1.0&lt;br/&gt;
2015-01-06 16:42:35,901 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 8 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:35,902 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000001_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:35,903 INFO &lt;a href=&quot;#5&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #5&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000003 taskAttempt attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:35,903 INFO &lt;a href=&quot;#5&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #5&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:35,903 INFO &lt;a href=&quot;#5&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #5&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:35,911 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000001_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:35,912 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:35,913 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000001 Task Transitioned from RUNNING to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:35,913 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 1&lt;br/&gt;
2015-01-06 16:42:35,925 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 9 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000003_0 is : 1.0&lt;br/&gt;
2015-01-06 16:42:35,927 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 10 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:35,928 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000003_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:35,929 INFO &lt;a href=&quot;#6&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #6&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000005 taskAttempt attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:35,929 INFO &lt;a href=&quot;#6&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #6&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:35,929 INFO &lt;a href=&quot;#6&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #6&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:35,936 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000003_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:35,936 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:35,936 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000003 Task Transitioned from RUNNING to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:35,937 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 2&lt;br/&gt;
2015-01-06 16:42:36,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 11 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000000_0 is : 1.0&lt;br/&gt;
2015-01-06 16:42:36,037 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 12 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:36,038 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000000_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:36,039 INFO &lt;a href=&quot;#7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #7&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000002 taskAttempt attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:36,039 INFO &lt;a href=&quot;#7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #7&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:36,039 INFO &lt;a href=&quot;#7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #7&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:36,045 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000000_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:36,045 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:36,045 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000000 Task Transitioned from RUNNING to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:36,046 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 3&lt;br/&gt;
2015-01-06 16:42:36,200 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:36,207 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000004&lt;br/&gt;
2015-01-06 16:42:36,207 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 1&lt;br/&gt;
2015-01-06 16:42:36,208 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_0: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:36,208 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1419291043936_1639_01_000006, NodeId: sfdmgctsn003.gid.gap.com:45454, NodeHttpAddress: sfdmgctsn003.gid.gap.com:8042, Resource: &amp;lt;memory:14336, vCores:1&amp;gt;, Priority: 5, Token: Token &lt;/p&gt;
{ kind: ContainerToken, service: 10.9.21.133:45454 }
&lt;p&gt;, ] to fast fail map&lt;br/&gt;
2015-01-06 16:42:36,208 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps&lt;br/&gt;
2015-01-06 16:42:36,208 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000006 to attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:36,208 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:5 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:36,209 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:36,209 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:36,210 INFO &lt;a href=&quot;#8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #8&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000006 taskAttempt attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:36,210 INFO &lt;a href=&quot;#8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #8&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:36,210 INFO &lt;a href=&quot;#8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #8&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn003.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:36,218 INFO &lt;a href=&quot;#8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #8&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000002_1 : 13562&lt;br/&gt;
2015-01-06 16:42:36,219 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000002_1&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000006 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn003.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:36,219 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=3 resourcelimit=&amp;lt;memory:444416, vCores:78&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000002&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000003&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000005&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000000_0: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:5 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000001_0: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:37,211 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000003_0: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:39,096 INFO &lt;a href=&quot;#1 for port 33406&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:39,106 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 0 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000006 asked for a task&lt;br/&gt;
2015-01-06 16:42:39,106 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 0 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000006 given task: attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:40,344 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000002_1 is : 0.0&lt;br/&gt;
2015-01-06 16:42:40,345 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 2 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1419291043936_1639_m_000002_1 - exited : java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:40,345 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 2 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_1: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:40,346 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_1: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:40,346 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:40,347 INFO &lt;a href=&quot;#9&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #9&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000006 taskAttempt attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:40,347 INFO &lt;a href=&quot;#9&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #9&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:40,347 INFO &lt;a href=&quot;#9&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #9&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn003.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:40,353 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP&lt;br/&gt;
2015-01-06 16:42:40,354 INFO &lt;a href=&quot;#2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CommitterEvent Processor #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT&lt;br/&gt;
2015-01-06 16:42:40,354 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED&lt;br/&gt;
2015-01-06 16:42:40,354 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:40,354 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:40,354 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:40,355 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:40,355 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:40,355 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node sfdmgctsn003.gid.gap.com&lt;br/&gt;
2015-01-06 16:42:40,355 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:40,355 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1419291043936_1639_m_000002_2 to list of failed maps&lt;br/&gt;
2015-01-06 16:42:41,215 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:5 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:41,216 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:444416, vCores:78&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000006&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 1&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_1: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1419291043936_1639_01_000007, NodeId: sfdmgctsn003.gid.gap.com:45454, NodeHttpAddress: sfdmgctsn003.gid.gap.com:8042, Resource: &amp;lt;memory:14336, vCores:1&amp;gt;, Priority: 5, Token: Token &lt;/p&gt;
{ kind: ContainerToken, service: 10.9.21.133:45454 }
&lt;p&gt;, ] to fast fail map&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000007 to attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:6 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:42,219 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:42,219 INFO &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000007 taskAttempt attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:42,219 INFO &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:42,219 INFO &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn003.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:42,226 INFO &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000002_2 : 13562&lt;br/&gt;
2015-01-06 16:42:42,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000002_2&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000007 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn003.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:42,227 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:43,220 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:444416, vCores:78&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:43,270 INFO &lt;a href=&quot;#1 for port 33406&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:43,279 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000007 asked for a task&lt;br/&gt;
2015-01-06 16:42:43,279 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000007 given task: attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:44,498 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 3 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000002_2 is : 0.0&lt;br/&gt;
2015-01-06 16:42:44,500 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1419291043936_1639_m_000002_2 - exited : java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:44,500 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_2: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:44,500 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_2: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:44,501 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:44,501 INFO &lt;a href=&quot;#1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000007 taskAttempt attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:44,501 INFO &lt;a href=&quot;#1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:44,501 INFO &lt;a href=&quot;#1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn003.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:44,507 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CommitterEvent Processor #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:44,509 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 2 failures on node sfdmgctsn003.gid.gap.com&lt;br/&gt;
2015-01-06 16:42:44,509 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:44,509 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1419291043936_1639_m_000002_3 to list of failed maps&lt;br/&gt;
2015-01-06 16:42:45,222 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:6 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:45,223 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:444416, vCores:78&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:46,225 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000007&lt;br/&gt;
2015-01-06 16:42:46,225 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 1&lt;br/&gt;
2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1419291043936_1639_01_000008, NodeId: sfdmgctsn005.gid.gap.com:45454, NodeHttpAddress: sfdmgctsn005.gid.gap.com:8042, Resource: &amp;lt;memory:14336, vCores:1&amp;gt;, Priority: 5, Token: Token &lt;/p&gt;
{ kind: ContainerToken, service: 10.9.21.135:45454 }
&lt;p&gt;, ] to fast fail map&lt;br/&gt;
2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_2: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps&lt;br/&gt;
2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000008 to attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:7 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:46,227 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:46,227 INFO &lt;a href=&quot;#0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000008 taskAttempt attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:46,227 INFO &lt;a href=&quot;#0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:46,227 INFO &lt;a href=&quot;#0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn005.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:46,235 INFO &lt;a href=&quot;#0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000002_3 : 13562&lt;br/&gt;
2015-01-06 16:42:46,235 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000002_3&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000008 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn005.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:46,235 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:47,227 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:444416, vCores:78&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:49,199 INFO &lt;a href=&quot;#1 for port 33406&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:49,209 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000008 asked for a task&lt;br/&gt;
2015-01-06 16:42:49,209 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000008 given task: attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:50,432 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 3 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000002_3 is : 0.0&lt;br/&gt;
2015-01-06 16:42:50,434 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1419291043936_1639_m_000002_3 - exited : java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:50,434 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_3: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:50,434 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_3: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:50,435 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:50,435 INFO &lt;a href=&quot;#2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000008 taskAttempt attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:50,435 INFO &lt;a href=&quot;#2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:50,435 INFO &lt;a href=&quot;#2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn005.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:50,441 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP&lt;br/&gt;
2015-01-06 16:42:50,441 INFO &lt;a href=&quot;#4&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CommitterEvent Processor #4&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT&lt;br/&gt;
2015-01-06 16:42:50,442 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED&lt;br/&gt;
2015-01-06 16:42:50,443 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000002 Task Transitioned from RUNNING to FAILED&lt;br/&gt;
2015-01-06 16:42:50,443 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node sfdmgctsn005.gid.gap.com&lt;br/&gt;
2015-01-06 16:42:50,443 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 4&lt;br/&gt;
2015-01-06 16:42:50,443 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Job failed as tasks failed. failedMaps:1 failedReduces:0&lt;br/&gt;
2015-01-06 16:42:50,444 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1419291043936_1639Job Transitioned from RUNNING to FAIL_ABORT&lt;br/&gt;
2015-01-06 16:42:50,444 INFO &lt;a href=&quot;#0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CommitterEvent Processor #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_ABORT&lt;br/&gt;
2015-01-06 16:42:50,455 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1419291043936_1639Job Transitioned from FAIL_ABORT to FAILED&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: RMCommunicator notified that shouldUnregistered is: true&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0&lt;br/&gt;
2015-01-06 16:42:50,485 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://sfdmgct:8020/user/hive/.staging/job_1419291043936_1639/job_1419291043936_1639_1.jhist to hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639-1420580542797-hive-sfdmgctmn003.gid.gap.com%2D32%2Dcompactor%2Dds_infra.eve-1420580570443-3-0-FAILED-default-1420580548162.jhist_tmp&lt;br/&gt;
2015-01-06 16:42:50,504 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639-1420580542797-hive-sfdmgctmn003.gid.gap.com%2D32%2Dcompactor%2Dds_infra.eve-1420580570443-3-0-FAILED-default-1420580548162.jhist_tmp&lt;br/&gt;
2015-01-06 16:42:50,507 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://sfdmgct:8020/user/hive/.staging/job_1419291043936_1639/job_1419291043936_1639_1_conf.xml to hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639_conf.xml_tmp&lt;br/&gt;
2015-01-06 16:42:50,524 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639_conf.xml_tmp&lt;br/&gt;
2015-01-06 16:42:50,530 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639.summary_tmp to hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639.summary&lt;br/&gt;
2015-01-06 16:42:50,531 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639_conf.xml_tmp to hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639_conf.xml&lt;br/&gt;
2015-01-06 16:42:50,533 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639-1420580542797-hive-sfdmgctmn003.gid.gap.com%2D32%2Dcompactor%2Dds_infra.eve-1420580570443-3-0-FAILED-default-1420580548162.jhist_tmp to hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639-1420580542797-hive-sfdmgctmn003.gid.gap.com%2D32%2Dcompactor%2Dds_infra.eve-1420580570443-3-0-FAILED-default-1420580548162.jhist&lt;br/&gt;
2015-01-06 16:42:50,533 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()&lt;br/&gt;
2015-01-06 16:42:50,535 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Setting job diagnostics to Task failed task_1419291043936_1639_m_000002&lt;br/&gt;
Job failed as tasks failed. failedMaps:1 failedReduces:0&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:50,536 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: History url is &lt;a href=&quot;http://sfdmgctmn004.gid.gap.com:19888/jobhistory/job/job_1419291043936_1639&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://sfdmgctmn004.gid.gap.com:19888/jobhistory/job/job_1419291043936_1639&lt;/a&gt;&lt;br/&gt;
2015-01-06 16:42:50,539 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Waiting for application to be successfully unregistered.&lt;br/&gt;
2015-01-06 16:42:51,540 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:7 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:51,541 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://sfdmgct /user/hive/.staging/job_1419291043936_1639&lt;br/&gt;
2015-01-06 16:42:51,543 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: Stopping server on 33406&lt;br/&gt;
2015-01-06 16:42:51,544 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server listener on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 33406&lt;br/&gt;
2015-01-06 16:42:51,545 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;TaskHeartbeatHandler PingChecker&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted&lt;br/&gt;
2015-01-06 16:42:51,545 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server Responder&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: Stopping IPC Server Responder&lt;/p&gt;
</comment>
                            <comment id="14270282" author="alangates" created="Fri, 9 Jan 2015 00:32:38 +0000"  >&lt;p&gt;The issue is that since the writer died with an unclosed batch it left the orc file in a state where it cannot be read without the length file.  So removing the length file means any reader will fail when reading it.&lt;/p&gt;

&lt;p&gt;The proper solution is for the compactor to stop at that partition until it has determined all transactions in that file have committed or aborted.  Then it should compact it using the length file, but properly ignore the length file.  I&apos;ll work on the fix.&lt;/p&gt;</comment>
                            <comment id="14271601" author="jihongliu" created="Fri, 9 Jan 2015 17:54:01 +0000"  >&lt;p&gt;Make sense. It is so great if that solution can be implemented.Thanks&lt;/p&gt;</comment>
                            <comment id="14272112" author="alangates" created="Sat, 10 Jan 2015 00:03:04 +0000"  >&lt;p&gt;This patch takes a new approach.  Rather than changing AcidUtils.getAcidState (as previous 2 attempts) this patch gives a new implementation of ValidTxnList that only returns isTxnRangeValid ALL or NONE, and gives NONE if there are any open transactions &amp;lt;= the max transaction in the range (even if it&apos;s below the range).  This new implementation is used only by the compactor so that it&apos;s understanding of what files it should compact are different than what files a reader views as available for reading.&lt;/p&gt;

&lt;p&gt;I&apos;ve also added tests to TestCompactor to test compaction during streaming and compaction after a streamer has aborted and died without cleaning up.&lt;/p&gt;</comment>
                            <comment id="14272443" author="hiveqa" created="Sat, 10 Jan 2015 11:15:22 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12691437/HIVE-8966.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12691437/HIVE-8966.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 6764 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2322/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2322/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2322/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2322/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2322/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2322/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12691437 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14274433" author="alangates" created="Mon, 12 Jan 2015 23:56:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;owen.omalley&lt;/a&gt; pointed out that I need to change the implementation of ValidCompactorTxnList.isTxnValid to return false for aborted transactions so that aborted records aren&apos;t carried forward in compacted files.  &lt;/p&gt;</comment>
                            <comment id="14275957" author="alangates" created="Tue, 13 Jan 2015 21:16:46 +0000"  >&lt;p&gt;Yet another version of this patch, this one fixes the issue introduced by the last one that adds aborted records to compacted files.&lt;/p&gt;</comment>
                            <comment id="14278515" author="hiveqa" created="Thu, 15 Jan 2015 10:14:37 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12692048/HIVE-8966.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12692048/HIVE-8966.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 7330 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2369/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2369/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2369/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2369/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2369/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2369/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12692048 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14284927" author="owen.omalley" created="Wed, 21 Jan 2015 00:47:42 +0000"  >&lt;p&gt;This looks good, Alan. +1&lt;/p&gt;

&lt;p&gt;One minor nit is that the class javadoc for ValidReadTxnList has &quot;And&quot; instead of the intended &quot;An&quot;.&lt;/p&gt;</comment>
                            <comment id="14284935" author="owen.omalley" created="Wed, 21 Jan 2015 00:53:37 +0000"  >&lt;p&gt;After a little more thought, I&apos;m worried that someone will accidentally create a ValidCompactorTxnList and get confused by the different behavior. I think it would make sense to move it into the compactor package to minimize the chance that someone accidentally uses it by mistake. &lt;/p&gt;</comment>
                            <comment id="14286267" author="vikram.dixit" created="Wed, 21 Jan 2015 21:04:30 +0000"  >&lt;p&gt;+1 for a branch 1.0.&lt;/p&gt;</comment>
                            <comment id="14290349" author="alangates" created="Sat, 24 Jan 2015 01:39:20 +0000"  >&lt;p&gt;Final version of the patch.  Moved ValidCompactorTxnList per Owen&apos;s request.  Also made small changes to StreamingIntegrationTester to make it work properly in cases where you want it to go slowly.&lt;/p&gt;</comment>
                            <comment id="14290583" author="hiveqa" created="Sat, 24 Jan 2015 12:54:10 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12694321/HIVE-8966.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12694321/HIVE-8966.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 7370 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestSparkCliDriver-parallel_join1.q-avro_joins.q-groupby_ppr.q-and-12-more - did not produce a TEST-*.xml file
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2506/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2506/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2506/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2506/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2506/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2506/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12694321 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14292593" author="brocknoland" created="Mon, 26 Jan 2015 23:11:51 +0000"  >&lt;p&gt;Looks like this was committed but I am seeing:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-common: Compilation failure: Compilation failure:
[ERROR] /Users/noland/workspaces/hive-apache/hive/common/src/java/org/apache/hadoop/hive/common/ValidTxnListImpl.java:[23,8] org.apache.hadoop.hive.common.ValidTxnListImpl is not abstract and does not override abstract method getInvalidTransactions() in org.apache.hadoop.hive.common.ValidTxnList
[ERROR] /Users/noland/workspaces/hive-apache/hive/common/src/java/org/apache/hadoop/hive/common/ValidTxnListImpl.java:[46,3] method does not override or implement a method from a supertype
[ERROR] /Users/noland/workspaces/hive-apache/hive/common/src/java/org/apache/hadoop/hive/common/ValidTxnListImpl.java:[54,3] method does not override or implement a method from a supertype
[ERROR] /Users/noland/workspaces/hive-apache/hive/common/src/java/org/apache/hadoop/hive/common/ValidTxnListImpl.java:[121,3] method does not override or implement a method from a supertype
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-common
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14292601" author="alangates" created="Mon, 26 Jan 2015 23:19:30 +0000"  >&lt;p&gt;I did svn add instead of svn rm on a couple of files that moved.  I&apos;ll fix it.&lt;/p&gt;</comment>
                            <comment id="14292615" author="brocknoland" created="Mon, 26 Jan 2015 23:24:42 +0000"  >&lt;p&gt;thx&lt;/p&gt;</comment>
                            <comment id="14292622" author="alangates" created="Mon, 26 Jan 2015 23:31:58 +0000"  >&lt;p&gt;Fixed.&lt;/p&gt;</comment>
                            <comment id="14294010" author="alangates" created="Tue, 27 Jan 2015 19:19:39 +0000"  >&lt;p&gt;Patch 6 checked into trunk.  Patch marked for branch 1 checked into branch 1.&lt;/p&gt;</comment>
                            <comment id="14294911" author="lefty@hortonworks.com" created="Wed, 28 Jan 2015 09:17:18 +0000"  >&lt;p&gt;Any documentation needed?&lt;/p&gt;</comment>
                            <comment id="14295328" author="alangates" created="Wed, 28 Jan 2015 16:11:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;leftylev&lt;/a&gt; no, we just made what should have worked before work properly.&lt;/p&gt;</comment>
                            <comment id="14297958" author="jihongliu" created="Fri, 30 Jan 2015 00:31:57 +0000"  >&lt;p&gt;Thanks Alan.&lt;/p&gt;</comment>
                            <comment id="14297960" author="lefty@hortonworks.com" created="Fri, 30 Jan 2015 00:32:40 +0000"  >&lt;p&gt;Does this also need to be checked into branch-1.1 (formerly known as 0.15)?&lt;/p&gt;</comment>
                            <comment id="14298910" author="alangates" created="Fri, 30 Jan 2015 17:35:41 +0000"  >&lt;p&gt;I confirmed that it is already in 1.1, based on the git logs.&lt;/p&gt;</comment>
                            <comment id="14327567" author="thejas" created="Thu, 19 Feb 2015 14:45:03 +0000"  >&lt;p&gt;Updating release version for jiras resolved in 1.0.0 .&lt;/p&gt;</comment>
                            <comment id="14327880" author="thejas" created="Thu, 19 Feb 2015 18:22:01 +0000"  >&lt;p&gt;This issue has been fixed in Apache Hive 1.0.0. If there is any issue with the fix, please open a new jira to address it.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12694674" name="HIVE-8966-branch-1.patch" size="103575" author="gates" created="Tue, 27 Jan 2015 00:57:28 +0000"/>
                            <attachment id="12686124" name="HIVE-8966.2.patch" size="16858" author="gates" created="Tue, 9 Dec 2014 23:15:32 +0000"/>
                            <attachment id="12688699" name="HIVE-8966.3.patch" size="19232" author="gates" created="Mon, 22 Dec 2014 18:43:59 +0000"/>
                            <attachment id="12691437" name="HIVE-8966.4.patch" size="84374" author="gates" created="Sat, 10 Jan 2015 00:03:04 +0000"/>
                            <attachment id="12692048" name="HIVE-8966.5.patch" size="89403" author="gates" created="Tue, 13 Jan 2015 21:16:46 +0000"/>
                            <attachment id="12694321" name="HIVE-8966.6.patch" size="91211" author="gates" created="Sat, 24 Jan 2015 01:39:20 +0000"/>
                            <attachment id="12685590" name="HIVE-8966.patch" size="2125" author="jihongliu" created="Sun, 7 Dec 2014 05:23:59 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 39 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22s3j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Don&amp;#39;t do compaction on the current delta if it has a file in bucket pattern but not compactable</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>