<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 19:22:51 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-26388] ClassCastException when there is non string type column in source table of CTAS query</title>
                <link>https://issues.apache.org/jira/browse/HIVE-26388</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Steps to reproduce&lt;/p&gt;

&lt;p&gt;cat ql/src/test/queries/clientpositive/ctas_open_csv_serde.q&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;create table T1(abc decimal(10,0));
insert into table T1 values(1.25);
create table T2 row format serde &apos;org.apache.hadoop.hive.serde2.OpenCSVSerde&apos; with serdeproperties (&quot;separatorChar&quot; = &apos;,&apos; , &quot;quoteChar&quot; = &apos;&quot;&apos;) stored as textfile as select * from T1;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Then execute the test case with below command&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;mvn install -Pitests -pl itests/qtest -Dtest=TestMiniLlapLocalCliDriver -Dqfile=ctas_open_csv_serde.q -Dtest.output.overwrite&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Exception trace looks like below&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[ERROR] &#160; TestMiniLlapLocalCliDriver.testCliDriver:62 Client execution failed with error code = 2
running
create table T2 row format serde &apos;org.apache.hadoop.hive.serde2.OpenCSVSerde&apos; with serdeproperties (&quot;separatorChar&quot; = &apos;,&apos; , &quot;quoteChar&quot; = &apos;&quot;&apos;) stored as textfile as select * from T1
fname=ctas_open_csv_serde.q
See ./ql/target/tmp/log/hive.log or ./itests/qtest/target/tmp/log/hive.log, or check ./ql/target/surefire-reports or ./itests/qtest/target/surefire-reports/ for specific test cases logs.
&#160;org.apache.hadoop.hive.ql.metadata.HiveException: Vertex failed, vertexName=Map 1, vertexId=vertex_1657718574697_0001_2_00, diagnostics=[Task failed, taskId=task_1657718574697_0001_2_00_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Error while running task ( failure ) : attempt_1657718574697_0001_2_00_000000_0:java.lang.RuntimeException: java.lang.RuntimeException: Hive Runtime Error while closing operators
&#160; &#160; at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:348)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:276)
&#160; &#160; at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:381)
&#160; &#160; at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:82)
&#160; &#160; at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:69)
&#160; &#160; at java.security.AccessController.doPrivileged(Native Method)
&#160; &#160; at javax.security.auth.Subject.doAs(Subject.java:422)
&#160; &#160; at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
&#160; &#160; at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:69)
&#160; &#160; at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:39)
&#160; &#160; at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
&#160; &#160; at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118)
&#160; &#160; at java.util.concurrent.FutureTask.run(FutureTask.java:266)
&#160; &#160; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
&#160; &#160; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
&#160; &#160; at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: Hive Runtime Error while closing operators
&#160; &#160; at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.close(MapRecordProcessor.java:483)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:310)
&#160; &#160; ... 15 more
Caused by: java.lang.ClassCastException: org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableHiveDecimalObjectInspector cannot be cast to org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector
&#160; &#160; at org.apache.hadoop.hive.serde2.OpenCSVSerde.serialize(OpenCSVSerde.java:119)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1116)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.vector.VectorFileSinkOperator.process(VectorFileSinkOperator.java:111)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.Operator.vectorForward(Operator.java:931)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.process(VectorSelectOperator.java:158)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.Operator.vectorForward(Operator.java:919)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:171)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.closeOp(VectorMapOperator.java:1010)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:686)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.close(MapRecordProcessor.java:459)
&#160; &#160; ... 16 more
], TaskAttempt 1 failed, info=[Error: Error while running task ( failure ) : attempt_1657718574697_0001_2_00_000000_1:java.lang.RuntimeException: java.lang.RuntimeException: Hive Runtime Error while closing operators
&#160; &#160; at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:348)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:276)
&#160; &#160; at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:381)
&#160; &#160; at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:82)
&#160; &#160; at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:69)
&#160; &#160; at java.security.AccessController.doPrivileged(Native Method)
&#160; &#160; at javax.security.auth.Subject.doAs(Subject.java:422)
&#160; &#160; at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
&#160; &#160; at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:69)
&#160; &#160; at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:39)
&#160; &#160; at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
&#160; &#160; at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118)
&#160; &#160; at java.util.concurrent.FutureTask.run(FutureTask.java:266)
&#160; &#160; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
&#160; &#160; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
&#160; &#160; at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: Hive Runtime Error while closing operators
&#160; &#160; at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.close(MapRecordProcessor.java:483)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:310)
&#160; &#160; ... 15 more
Caused by: java.lang.ClassCastException: org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableHiveDecimalObjectInspector cannot be cast to org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector
&#160; &#160; at org.apache.hadoop.hive.serde2.OpenCSVSerde.serialize(OpenCSVSerde.java:119)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1116)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.vector.VectorFileSinkOperator.process(VectorFileSinkOperator.java:111)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.Operator.vectorForward(Operator.java:931)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.process(VectorSelectOperator.java:158)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.Operator.vectorForward(Operator.java:919)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:171)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.closeOp(VectorMapOperator.java:1010)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:686)
&#160; &#160; at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.close(MapRecordProcessor.java:459)
&#160; &#160; ... 16 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13471413">HIVE-26388</key>
            <summary>ClassCastException when there is non string type column in source table of CTAS query</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ayushtkn">Ayush Saxena</assignee>
                                    <reporter username="tarak271">Taraka Rama Rao Lethavadla</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Wed, 13 Jul 2022 13:25:35 +0000</created>
                <updated>Wed, 16 Nov 2022 13:50:18 +0000</updated>
                            <resolved>Wed, 20 Jul 2022 15:42:45 +0000</resolved>
                                                    <fixVersion>4.0.0-alpha-2</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="3000">50m</timespent>
                                <comments>
                            <comment id="17566333" author="ayushtkn" created="Wed, 13 Jul 2022 14:14:36 +0000"  >&lt;p&gt;The OpenCSV serde supports only String column types. It is nothing specific to Decimal type. If you change your query from decimal to Char. You still would get a ClassCastException like:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Caused by: java.lang.ClassCastException: org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableHiveCharObjectInspector cannot be cast to org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In the serialise method, it is mentioned as well the data should be of String type, that is why it goes and :&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;// The data must be of type String
final StringObjectInspector fieldStringOI = (StringObjectInspector) fieldOI;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Not a regression, It would be like that only and kind of feature behaviour that it only supports String type.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;little bit related: &lt;a href=&quot;https://stackoverflow.com/questions/50001124/why-does-all-columns-get-created-as-string-when-i-use-opencsvserde-in-hive&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://stackoverflow.com/questions/50001124/why-does-all-columns-get-created-as-string-when-i-use-opencsvserde-in-hive&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17566348" author="ayushtkn" created="Wed, 13 Jul 2022 14:30:32 +0000"  >&lt;p&gt;A simple patch like this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/OpenCSVSerde.java b/serde/src/java/org/apache/hadoop/hive/serde2/OpenCSVSerde.java
index aceb908859..64a6a828fc 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/OpenCSVSerde.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/OpenCSVSerde.java
@@ -23,6 +23,7 @@
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.hadoop.hive.serde2.objectinspector.StructField;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
+&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.hadoop.hive.serde2.objectinspector.primitive.AbstractPrimitiveWritableObjectInspector;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.hadoop.io.Text;
@@ -116,11 +117,12 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Writable serialize(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; obj, ObjectInspector objInspector) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; SerDe
       &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ObjectInspector fieldOI = outputFieldRefs.get(c).getFieldObjectInspector();
 
       &lt;span class=&quot;code-comment&quot;&gt;// The data must be of type &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;
&lt;/span&gt;-      &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; StringObjectInspector fieldStringOI = (StringObjectInspector) fieldOI;
+      &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; AbstractPrimitiveWritableObjectInspector fieldStringOI = (AbstractPrimitiveWritableObjectInspector) fieldOI;
 
       &lt;span class=&quot;code-comment&quot;&gt;// Convert the field to Java &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, because objects of &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; type
&lt;/span&gt;       &lt;span class=&quot;code-comment&quot;&gt;// can be stored in &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, Text, or some other classes.
&lt;/span&gt;-      outputFields[c] = fieldStringOI.getPrimitiveJavaObject(field);
+      &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; primitiveJavaObject = fieldStringOI.getPrimitiveJavaObject(field);
+      outputFields[c] = primitiveJavaObject != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; ? primitiveJavaObject.toString() : &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
     }
 
     &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; StringWriter writer = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringWriter();

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Can fix the issue I feel for most the cases, but need to check what all return types don&apos;t implement the &lt;tt&gt;toString()&lt;/tt&gt; method, for those types the data will go corrupt, because the toString will return the Object.toString() rather than the actual data...&lt;/p&gt;</comment>
                            <comment id="17569093" author="ayushtkn" created="Wed, 20 Jul 2022 15:42:36 +0000"  >&lt;p&gt;Committed to master.&lt;/p&gt;

&lt;p&gt;Thanx &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tarak271&quot; class=&quot;user-hover&quot; rel=&quot;tarak271&quot;&gt;tarak271&lt;/a&gt; for the report and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dkuzmenko&quot; class=&quot;user-hover&quot; rel=&quot;dkuzmenko&quot;&gt;dkuzmenko&lt;/a&gt; for the review!!!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 17 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z16u1c:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>