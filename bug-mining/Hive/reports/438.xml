<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 17:56:33 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-1509] Monitor the working set of the number of files </title>
                <link>https://issues.apache.org/jira/browse/HIVE-1509</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12470776">HIVE-1509</key>
            <summary>Monitor the working set of the number of files </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nzhang">Ning Zhang</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Wed, 4 Aug 2010 00:07:51 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:29 +0000</updated>
                            <resolved>Thu, 5 Aug 2010 07:38:58 +0000</resolved>
                                    <version>0.6.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                <comments>
                            <comment id="12895106" author="namit" created="Wed, 4 Aug 2010 00:31:48 +0000"  >&lt;p&gt;With dynamic partitions, the number of intermediate files can grow very fast.&lt;/p&gt;

&lt;p&gt;For example, consider a query with 10,000 mappers and 100 files per mapper - it can create up to 1 million files before merging them at the end.&lt;br/&gt;
The cluster may be down by the time the query finishes.&lt;/p&gt;

&lt;p&gt;It is a good idea to track the number of files through a counter, and kill the query if the number exceeds a given threshold&lt;/p&gt;</comment>
                            <comment id="12895312" author="jsensarma" created="Wed, 4 Aug 2010 16:42:06 +0000"  >&lt;p&gt;couple of comments:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;use ProgressCounter.CREATED_FILES directly instead of using valueOf(&quot;CREATED_FILES&quot;)&lt;/li&gt;
	&lt;li&gt;can we move the check for total number of created files to inside checkFatalErrors? we are duplicating some code (for example we just fixed a problem where getCounters() can return null and ignoring that inside checkFatal).&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12895321" author="nzhang" created="Wed, 4 Aug 2010 17:05:39 +0000"  >&lt;p&gt;Good points Joy. Uploading a new patch with these changes. &lt;/p&gt;</comment>
                            <comment id="12895322" author="jsensarma" created="Wed, 4 Aug 2010 17:08:58 +0000"  >&lt;p&gt;can u try bucketmapjoin2.q in clientpositive. it&apos;s failing for me&lt;/p&gt;</comment>
                            <comment id="12895327" author="nzhang" created="Wed, 4 Aug 2010 17:31:52 +0000"  >&lt;p&gt;found the bug. I&apos;ll a new patch after running the tests. &lt;/p&gt;</comment>
                            <comment id="12895355" author="nzhang" created="Wed, 4 Aug 2010 18:39:33 +0000"  >&lt;p&gt;Uploading &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1509&quot; title=&quot;Monitor the working set of the number of files &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1509&quot;&gt;&lt;del&gt;HIVE-1509&lt;/del&gt;&lt;/a&gt;.3.patch which fixed a bug. It passed hadoop 0.17 tests. I&apos;m running 0.20 tests. &lt;/p&gt;</comment>
                            <comment id="12895384" author="jsensarma" created="Wed, 4 Aug 2010 19:46:48 +0000"  >&lt;p&gt;let me know once the tests pass 0.20 and i can commit.&lt;/p&gt;

&lt;p&gt;one more question:&lt;br/&gt;
+    MAXCREATEDFILES(&quot;hive.exec.max.created.files&quot;, 100000),&lt;/p&gt;

&lt;p&gt;i think u may have to append a &apos;L&apos; to 100000 since u are trying to later on do a:&lt;/p&gt;

&lt;p&gt;+      long upperLimit =  HiveConf.getLongVar(job, HiveConf.ConfVars.MAXCREATEDFILES);&lt;/p&gt;

&lt;p&gt;(or switch to using getIntVar). i am a little surprised how this is working because the 100000 would be interpreted as Integer, go to the integer constructor which should leave the long default to -1. (or i guess i have forgotten how this works)&lt;/p&gt;</comment>
                            <comment id="12895404" author="nzhang" created="Wed, 4 Aug 2010 20:23:59 +0000"  >&lt;p&gt;Attaching &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1509&quot; title=&quot;Monitor the working set of the number of files &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1509&quot;&gt;&lt;del&gt;HIVE-1509&lt;/del&gt;&lt;/a&gt;.4.patch to change 100000 to 100000L. I think it passed because we have the parameter set up in hive-default.xml as well.&lt;/p&gt;

&lt;p&gt;All unit tests passed on 0.20 except index_compact_2.q. It is strange that this particular test passed when I run it individually. It also passed when I ran the whole tests again. &lt;/p&gt;</comment>
                            <comment id="12895411" author="jsensarma" created="Wed, 4 Aug 2010 20:43:38 +0000"  >&lt;p&gt;ok - i will run tests on 20 and commit if all clear.&lt;/p&gt;</comment>
                            <comment id="12895472" author="jsensarma" created="Wed, 4 Aug 2010 23:50:45 +0000"  >&lt;p&gt;the test result for dyn_part3.q is not matching the one provided in the patch. it seems that testnegativeclidriver is not executing anything but the first query in the .q file:&lt;/p&gt;


&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; diff -a -I file: -I pfile: -I /tmp/ -I invalidscheme: -I lastUpdateTime -I lastAccessTime -I \&lt;br/&gt;
owner -I transient_lastDdlTime -I java.lang.RuntimeException -I at org -I at sun -I at java -I at junit -\&lt;br/&gt;
I Caused by: -I &lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;0-9&amp;#93;&lt;/span&gt;* more /data/users/jssarma/hive_trunk/build/ql/test/logs/clientnegative/dy\&lt;br/&gt;
n_part3.q.out&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 9a10,27&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: query: create table nzhang_part( key string) partitioned by (value string)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: type: CREATETABLE&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: query: create table nzhang_part( key string) partitioned by (value string)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: type: CREATETABLE&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: Output: default@nzhang_part&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: query: insert overwrite table nzhang_part partition(value) select key, value from \&lt;br/&gt;
src&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: type: QUERY&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: Input: default@src&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: query: create table nzhang_part( key string) partitioned by (value string)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: type: CREATETABLE&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: query: create table nzhang_part( key string) partitioned by (value string)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: type: CREATETABLE&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: Output: default@nzhang_part&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: query: insert overwrite table nzhang_part partition(value) select key, value from \&lt;br/&gt;
src&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: type: QUERY&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: Input: default@src&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask&lt;/p&gt;</comment>
                            <comment id="12895523" author="nzhang" created="Thu, 5 Aug 2010 02:49:56 +0000"  >&lt;p&gt;It&apos;s strange. I didn&apos;t get this diff on both 17 and 20. I&apos;ll run TestNegativeCliDriver again.&lt;/p&gt;</comment>
                            <comment id="12895526" author="nzhang" created="Thu, 5 Aug 2010 03:01:24 +0000"  >&lt;p&gt;The TestNegativeCliDriver ran successfully. In terms of the number of queries in the .q files in neg, I think as long as there is no queries after the first exception, it should be fine. At least this is what dyn_part&lt;span class=&quot;error&quot;&gt;&amp;#91;12&amp;#93;&lt;/span&gt;.q was doing (only the last query thrown expected exception).&lt;/p&gt;</comment>
                            <comment id="12895534" author="jsensarma" created="Thu, 5 Aug 2010 03:33:58 +0000"  >&lt;p&gt;strange - let me retry. can u check the patch one last time? (perhaps it&apos;s not up to date with contents of ur tree?)&lt;/p&gt;</comment>
                            <comment id="12895537" author="nzhang" created="Thu, 5 Aug 2010 04:05:47 +0000"  >&lt;p&gt;Yes, I check the svn diff in my working directory is the same as &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1509&quot; title=&quot;Monitor the working set of the number of files &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1509&quot;&gt;&lt;del&gt;HIVE-1509&lt;/del&gt;&lt;/a&gt;.4.patch. &lt;/p&gt;</comment>
                            <comment id="12895605" author="jsensarma" created="Thu, 5 Aug 2010 07:38:58 +0000"  >&lt;p&gt;committed - thanks Ning.&lt;/p&gt;

&lt;p&gt;it seems that the test problems were likely because there was a problem applying the patch.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12451235" name="HIVE-1509.2.patch" size="14131" author="nzhang" created="Wed, 4 Aug 2010 17:05:39 +0000"/>
                            <attachment id="12451246" name="HIVE-1509.3.patch" size="14445" author="nzhang" created="Wed, 4 Aug 2010 18:39:33 +0000"/>
                            <attachment id="12451260" name="HIVE-1509.4.patch" size="14446" author="nzhang" created="Wed, 4 Aug 2010 20:23:59 +0000"/>
                            <attachment id="12451204" name="HIVE-1509.patch" size="14131" author="nzhang" created="Wed, 4 Aug 2010 07:28:07 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72865</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            15 years, 16 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lffr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123151</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>