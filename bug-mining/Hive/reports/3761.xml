<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:36:19 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-11502] Map side aggregation is extremely slow</title>
                <link>https://issues.apache.org/jira/browse/HIVE-11502</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;For the query as following:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;create table tbl2 as 
select col1, max(col2) as col2 
from tbl1 group by col1;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If the column for group by has many different values (for example 400000) and it is in type double, the map side aggregation is very slow. I ran the query which took more than 3 hours , after 3 hours, I have to kill the query.&lt;br/&gt;
The same query can finish in 7 seconds, if I turn off map side aggregation by:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;set hive.map.aggr = false;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12853136">HIVE-11502</key>
            <summary>Map side aggregation is extremely slow</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ychena">Yongzhi Chen</assignee>
                                    <reporter username="ychena">Yongzhi Chen</reporter>
                        <labels>
                    </labels>
                <created>Sat, 8 Aug 2015 21:34:46 +0000</created>
                <updated>Tue, 16 Feb 2016 23:53:22 +0000</updated>
                            <resolved>Thu, 20 Aug 2015 01:23:26 +0000</resolved>
                                    <version>1.2.0</version>
                                    <fixVersion>1.3.0</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>Logical Optimizer</component>
                    <component>Physical Optimizer</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>13</watches>
                                                                                                                <comments>
                            <comment id="14663199" author="ychena" created="Sat, 8 Aug 2015 23:12:38 +0000"  >&lt;p&gt;It is a regression, I ran the query in 0.13.1 version with hive.map.aggr is true, it finished in 20 seconds.&lt;br/&gt;
In the master branch, the major time spend in following stack.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;HashMap&amp;lt;K,V&amp;gt;.getEntry(Object) line: 465	
HashMap&amp;lt;K,V&amp;gt;.get(Object) line: 417	
PrimitiveObjectInspectorUtils.getTypeEntryFromTypeName(String) line: 373	
PrimitiveTypeInfo.getPrimitiveTypeEntry() line: 85	
PrimitiveTypeInfo.getPrimitiveCategory() line: 63	
WritableDoubleObjectInspector(AbstractPrimitiveObjectInspector).getPrimitiveCategory() line: 58	
ObjectInspectorUtils.compare(Object, ObjectInspector, Object, ObjectInspector, MapEqualComparer) line: 694	
ObjectInspectorUtils.compare(Object, ObjectInspector, Object, ObjectInspector) line: 668	
ListObjectsEqualComparer$FieldComparer.areEqual(Object, Object) line: 127	
ListObjectsEqualComparer.areEqual(Object[], Object[]) line: 172	
KeyWrapperFactory$ListKeyWrapper.equals(Object) line: 101	
HashMap&amp;lt;K,V&amp;gt;.getEntry(Object) line: 467	
HashMap&amp;lt;K,V&amp;gt;.get(Object) line: 417	
GroupByOperator.processHashAggr(Object, ObjectInspector, KeyWrapper) line: 777	
GroupByOperator.processKey(Object, ObjectInspector) line: 693	
GroupByOperator.process(Object, int) line: 761	
SelectOperator(Operator&amp;lt;T&amp;gt;).forward(Object, ObjectInspector) line: 837	
SelectOperator.process(Object, int) line: 88	
TableScanOperator(Operator&amp;lt;T&amp;gt;).forward(Object, ObjectInspector) line: 837	
TableScanOperator.process(Object, int) line: 97	
MapOperator$MapOpCtx.forward(Object) line: 162	
MapOperator.process(Writable) line: 508	
ExecMapper.map(Object, Object, OutputCollector, Reporter) line: 163	
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;It seems that heavily used PrimitiveObjectInspectorUtils.getTypeEntryFromTypeName(String) slows down the query. So I change the code to store the PrimitiveTypeEntry as instance variable in PrimitiveTypeInfo. This does improve  the performance a lot, now the query can finish in 1 hour. But it is still very slow.&lt;br/&gt;
I checked 0.13.1 code, it uses Hashmap too, but much much faster. &lt;br/&gt;
I do not know why the HashMap search is so slow in master branch(and 1.1 or later version). &lt;/p&gt;</comment>
                            <comment id="14679402" author="zshao" created="Sun, 9 Aug 2015 23:30:26 +0000"  >&lt;p&gt;Seems like that the new version of Hive introduced KeyWrapperFactory which wraps keys for HashMap so that all kinds of objects can be used as HashMap keys.  This should not be necessary if the key objects are already capable of being HashMap keys (like Java Primitive Objects and Writable Objects) where hashVode() and equals() are well &lt;/p&gt;</comment>
                            <comment id="14679434" author="ychena" created="Mon, 10 Aug 2015 00:29:46 +0000"  >&lt;p&gt;Confirmed that only double type has regression.  For other types (such as int, bigint, float) used as group by column, there is no performance regression in map side aggregation.  &lt;/p&gt;</comment>
                            <comment id="14680637" author="gopalv" created="Mon, 10 Aug 2015 19:38:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ychena&quot; class=&quot;user-hover&quot; rel=&quot;ychena&quot;&gt;ychena&lt;/a&gt;: I&apos;ve linked the issue to the known issue in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-12217&quot; title=&quot;hashCode in DoubleWritable returns same value for many numbers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-12217&quot;&gt;HADOOP-12217&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Is it possible that you&apos;re testing hive against different versions of Hadoop between 0.13 vs 1.2.?&lt;/p&gt;</comment>
                            <comment id="14680720" author="ychena" created="Mon, 10 Aug 2015 20:36:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt;, I checked the related hadoop code between two versions used by 0.13 and 1.2, there is no change in hadoop side for DoubleWritable. &lt;br/&gt;
I think the regression may relate to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7041&quot; title=&quot;DoubleWritable/ByteWritable should extend their hadoop counterparts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7041&quot;&gt;&lt;del&gt;HIVE-7041&lt;/del&gt;&lt;/a&gt; which switch from using hive&apos;s own DoubleWritable to hadoop&apos;s . But just revert the change cause exceptions, I am still looking at it. &lt;/p&gt;</comment>
                            <comment id="14680740" author="gopalv" created="Mon, 10 Aug 2015 20:48:28 +0000"  >&lt;p&gt;A custom hashcode can be used internal to Hive (i.e group-by etc), but not externally to hive (bucketing into HDFS, results of hash() functions).&lt;/p&gt;

&lt;p&gt;Because that would break external assumptions in a non-backwards-compatible way.&lt;/p&gt;

&lt;p&gt;The reason shuffle + merge is more uniform is because it starts using &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java#L366&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;murmur hashes&lt;/a&gt; for UNIFORM trait RS instead of the builtin writable hash funcs (which are skewed).&lt;/p&gt;

&lt;p&gt;You will probably notice that using a vectorized input format like ORC would not have the issue you&apos;re hitting, since the vector transform inside the operator pipeline gives hive the opportunity to use per-operator specific optimizations.&lt;/p&gt;</comment>
                            <comment id="14680783" author="ychena" created="Mon, 10 Aug 2015 21:16:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt;, I have confirmed that &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7041&quot; title=&quot;DoubleWritable/ByteWritable should extend their hadoop counterparts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7041&quot;&gt;&lt;del&gt;HIVE-7041&lt;/del&gt;&lt;/a&gt; caused the regression. Because the hadoop bug is there for a long time, after hive switch to use hadoop&apos;s hashcode, we got hadoop&apos;s bug. Thanks for find the root cause by pointing the hadoop bug.&lt;/p&gt;

&lt;p&gt;After I add code in serde/src/java/org/apache/hadoop/hive/serde2/io/DoubleWritable.java&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;   @Override
   public int hashCode() {
     long v = Double.doubleToLongBits(super.get());
     return (int) (v ^ (v &amp;gt;&amp;gt;&amp;gt; 32));
   }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The group by query can finish in 15 seconds. &lt;/p&gt;

&lt;p&gt;So next step is, how do we fix the issue now? &lt;/p&gt;</comment>
                            <comment id="14680870" author="gopalv" created="Mon, 10 Aug 2015 22:19:14 +0000"  >&lt;blockquote&gt;&lt;p&gt;So next step is, how do we fix the issue now?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Easiest would be to use vectorization, which doesn&apos;t need any Writables in the inner loop.&lt;/p&gt;

&lt;p&gt;The vector hashcode for doubles would automatically be very similar to your impl (from Arrays.hashCode(double[]))&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;....
        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt; element : a) {
            &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; bits = &lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;.doubleToLongBits(element);
            result = 31 * result + (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)(bits ^ (bits &amp;gt;&amp;gt;&amp;gt; 32));
        }
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; result;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14681015" author="ychena" created="Tue, 11 Aug 2015 00:32:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt;, thanks for the workaround. But I am afraid some users do not want to change their input format. And this HashMap may affect mapjoin too. We help a user workaround this map side aggregation issue by set hive.map.aggr = false; After that, the simple group test case has very good performance, but a more complicated join query with group by as subquery stuck on mapjoin. So we have to let the user turn off mapjoin by set hive.auto.convert.join=false;  The performance hit by this bug is really outstanding. Without workaround, none of the query can finish in several hours. So I think we have to fix it. &lt;/p&gt;</comment>
                            <comment id="14681950" author="ychena" created="Tue, 11 Aug 2015 15:28:54 +0000"  >&lt;p&gt;Could we tell when it is for internal use? Could we assume such class as LazyDouble used only in internal hive?  Attach a test patch to see what the side-effect it is. &lt;/p&gt;</comment>
                            <comment id="14692440" author="hiveqa" created="Tue, 11 Aug 2015 22:58:13 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12749876/HIVE-11502.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12749876/HIVE-11502.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 9348 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4925/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4925/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4925/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4925/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4925/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4925/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12749876 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14692640" author="ychena" created="Wed, 12 Aug 2015 00:23:26 +0000"  >&lt;p&gt;The failure is not related:&lt;br/&gt;
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit&lt;br/&gt;
Table/View &apos;TXNS&apos; already exists in Schema &apos;APP&apos;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt;, could you review the patch and check if the change is safe to use? &lt;/p&gt;
</comment>
                            <comment id="14693556" author="ychena" created="Wed, 12 Aug 2015 14:21:17 +0000"  >&lt;p&gt;The basic idea of the fix is in LazyDouble, I separate hashcode for internal use from hashcode for hdfs.&lt;br/&gt;
The aggregation hashmap use LazyDouble, and I think hadoop use the value by DoubleWritable object which is an instance variable in&lt;br/&gt;
LazyDouble (data). The change let LazyDouble calculate its own hashcode instead of blindly use data&apos;s. &lt;br/&gt;
I do not see risk here. You can assume the LazyDouble as a vectorized object which only has one element in it.&lt;br/&gt;
Please correct me, if you find anything is not right. &lt;br/&gt;
Thanks&lt;/p&gt;</comment>
                            <comment id="14695787" author="gopalv" created="Thu, 13 Aug 2015 19:14:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;I do not see risk here. You can assume the LazyDouble as a vectorized object which only has one element in it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Changing a hashcode of an actual type breaks bucketed joins - the lhs &amp;amp; rhs of the join has to use the exact same hashcode.&lt;/p&gt;

&lt;p&gt;Vectorization overrides that inside VectorHashKeyWrapper, which serves as a model for this fix.&lt;/p&gt;

&lt;p&gt;The new hash computation needs to only go in place of the Arrays.hashCode() in the ListKeyWrapper - so that the only exposure to the uniform hashCode is within map-side aggregation.&lt;/p&gt;</comment>
                            <comment id="14696341" author="ychena" created="Fri, 14 Aug 2015 02:21:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt;, thanks for your advice. Attach second patch. &lt;/p&gt;</comment>
                            <comment id="14696862" author="hiveqa" created="Fri, 14 Aug 2015 10:57:53 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12750428/HIVE-11502.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12750428/HIVE-11502.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 9357 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestDummy - did not produce a TEST-*.xml file
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4962/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4962/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4962/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4962/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4962/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4962/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12750428 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14696920" author="ychena" created="Fri, 14 Aug 2015 11:47:58 +0000"  >&lt;p&gt;The TestDummy failure is not related:&lt;/p&gt;

&lt;p&gt;It failed because of FileNotFoundException:    &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; + javac -cp /home/hiveptest/54.147.251.176-hiveptest-2/maven/org/apache/hive/hive-exec/2.0.0-SNAPSHOT/hive-exec-2.0.0-SNAPSHOT.jar /tmp/UDFExampleAdd.java -d /tmp&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; + jar -cf /tmp/udfexampleadd-1.0.jar -C /tmp UDFExampleAdd.class&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; java.io.FileNotFoundException: /tmp/UDFExampleAdd.class (No such file or directory)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; 	at java.io.FileInputStream.open(Native Method)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; 	at java.io.FileInputStream.&amp;lt;init&amp;gt;(FileInputStream.java:146)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; 	at sun.tools.jar.Main.copy(Main.java:791)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; 	at sun.tools.jar.Main.addFile(Main.java:740)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; 	at sun.tools.jar.Main.create(Main.java:491)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; 	at sun.tools.jar.Main.run(Main.java:201)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; 	at sun.tools.jar.Main.main(Main.java:1177)&lt;/p&gt;</comment>
                            <comment id="14701640" author="csun" created="Tue, 18 Aug 2015 17:23:11 +0000"  >&lt;p&gt;LGTM +1.&lt;br/&gt;
Can you remove the extra line in the else branch? We don&apos;t need to rerun the test for this change.&lt;/p&gt;</comment>
                            <comment id="14701657" author="ychena" created="Tue, 18 Aug 2015 17:34:04 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt; for reviewing the change, I attached patch 3 to remove the extra line. &lt;/p&gt;</comment>
                            <comment id="14702269" author="hiveqa" created="Wed, 19 Aug 2015 01:18:39 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12751070/HIVE-11502.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12751070/HIVE-11502.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 9370 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_parquet_types
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5002/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5002/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5002/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5002/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5002/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5002/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12751070 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14702409" author="ychena" created="Wed, 19 Aug 2015 04:03:44 +0000"  >&lt;p&gt;The vectorized_parquet_types failure is not related.&lt;br/&gt;
It is just random failure caused by data precision. &lt;/p&gt;

&lt;p&gt;&amp;lt; 1	121	1	8	1.1749999970197678	2.062159062730128	90.33&lt;br/&gt;
&amp;#8212;&lt;br/&gt;
&amp;gt; 1	121	1	8	1.1749999970197678	2.0621590627301285	90.33&lt;br/&gt;
378c378&lt;br/&gt;
&amp;lt; 3	120	1	7	1.171428578240531	1.8	90.21&lt;br/&gt;
&amp;#8212;&lt;br/&gt;
&amp;gt; 3	120	1	7	1.171428578240531	1.7999999999999996	90.21&lt;/p&gt;

&lt;p&gt;Same test passed on my local machine.&lt;/p&gt;

</comment>
                            <comment id="14703102" author="xuefuz" created="Wed, 19 Aug 2015 14:34:28 +0000"  >&lt;p&gt;For my understanding, it&apos;s interesting to know why changing in ListKeyWrapper&apos;s hashcode solves the problem. I originally thought the problem is with hashcode for DoubleWritable. Any explanation would be appreciated.&lt;/p&gt;</comment>
                            <comment id="14704081" author="ychena" created="Thu, 20 Aug 2015 01:01:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;xuefuz&lt;/a&gt;, for GroupBy&apos;s aggregate hashmap uses ListKeyWrapper as key, so it uses the ListKey&apos;s hashcode. The HashMap does not directly use DoubleWritable&apos;s hashcode, so we can play in between. And it is safe too: The ListKeyWrapper is only used by groupby, so it is only used  internal to hive. &lt;/p&gt;</comment>
                            <comment id="14704114" author="csun" created="Thu, 20 Aug 2015 01:23:26 +0000"  >&lt;p&gt;Committed to master and branch-1. Thanks Yongzhi!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12770623">HIVE-9495</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12904132">HIVE-12093</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12862507">HIVE-11761</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12844236">HADOOP-12217</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12749876" name="HIVE-11502.1.patch" size="1406" author="ychena" created="Tue, 11 Aug 2015 15:47:11 +0000"/>
                            <attachment id="12750428" name="HIVE-11502.2.patch" size="1479" author="ychena" created="Fri, 14 Aug 2015 02:23:32 +0000"/>
                            <attachment id="12751070" name="HIVE-11502.3.patch" size="1477" author="ychena" created="Tue, 18 Aug 2015 17:32:43 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 13 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2ihyv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>