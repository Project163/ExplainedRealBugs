<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:22:32 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-7747] Submitting a query to Spark from HiveServer2 fails [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-7747</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;&lt;tt&gt;spark.serializer&lt;/tt&gt; is set to &lt;tt&gt;org.apache.spark.serializer.KryoSerializer&lt;/tt&gt;. Same configuration works fine from Hive CLI.&lt;/p&gt;

&lt;p&gt;Spark tasks fails with following error:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 9, 192.168.168.216): java.lang.IllegalStateException: unread block data
        java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2421)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1382)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:84)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:181)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12734562">HIVE-7747</key>
            <summary>Submitting a query to Spark from HiveServer2 fails [Spark Branch]</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vkorukanti">Venki Korukanti</assignee>
                                    <reporter username="vkorukanti">Venki Korukanti</reporter>
                        <labels>
                    </labels>
                <created>Sat, 16 Aug 2014 01:52:51 +0000</created>
                <updated>Fri, 29 May 2015 02:27:38 +0000</updated>
                            <resolved>Wed, 20 Aug 2014 17:50:02 +0000</resolved>
                                    <version>spark-branch</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14102589" author="vkorukanti" created="Tue, 19 Aug 2014 18:16:52 +0000"  >&lt;p&gt;When I run the spark job locally (spark.master=local), it completes successfully. It repros only on the Spark cluster. Similar exception is seen in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7437&quot; title=&quot;Check if servlet-api and jetty module in Spark library are an issue for hive-spark integration [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7437&quot;&gt;&lt;del&gt;HIVE-7437&lt;/del&gt;&lt;/a&gt;. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7437&quot; title=&quot;Check if servlet-api and jetty module in Spark library are an issue for hive-spark integration [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7437&quot;&gt;&lt;del&gt;HIVE-7437&lt;/del&gt;&lt;/a&gt; suggested shading jetty/servlet classes, but I still see the same exception.&lt;/p&gt;</comment>
                            <comment id="14103138" author="vkorukanti" created="Wed, 20 Aug 2014 00:29:18 +0000"  >&lt;p&gt;Problem is that we ship a wrong jar to Spark cluster. Instead of hive-exec, we ship hive-common. In SparkClient, we get the jar from HiveConf.getJar() which returns that jar that contains the initialization class. Initialization class given to HiveConf is different in HS2 versus CLI. In CliDriver (see run() method), SessionState.class (contained in hive-exec jar) is passed to HiveConf. In HS2 no initialization class is passed which defaults to HiveConf.class (contained in hive-common). &lt;/p&gt;

&lt;p&gt;The error thrown in Spark task is strange. Not sure if it is the standard error that is throw if no classes are found on classpath. Attaching a fix to pass SessionState.class as initilization class to HiveConf in HiveSessionImpl. It is a general fix, not specific to spark branch.&lt;/p&gt;</comment>
                            <comment id="14103150" author="brocknoland" created="Wed, 20 Aug 2014 00:35:31 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;I think we can apply this to trunk if the tests pass!&lt;/p&gt;</comment>
                            <comment id="14103354" author="hiveqa" created="Wed, 20 Aug 2014 04:22:50 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12662930/HIVE-7747.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12662930/HIVE-7747.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 6003 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.jdbc.TestJdbcWithMiniMr.org.apache.hive.jdbc.TestJdbcWithMiniMr
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/412/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/412/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/412/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/412/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-412/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-412/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12662930&lt;/p&gt;</comment>
                            <comment id="14103706" author="vkorukanti" created="Wed, 20 Aug 2014 10:01:58 +0000"  >&lt;p&gt;Test failure here is related to the change. Failure is complicated. It turns out that output of &lt;tt&gt;HiveConf(srcHiveConf, SessionState.class)&lt;/tt&gt; is not same as srcHiveConf in terms of (property, value) pairs. Executed as part of constructor, the &lt;tt&gt;HiveConf.initialize&lt;/tt&gt; method applies system properties on top of copied properties from srcHiveConf. So from the moment srcHiveConf is created to the moment of cloning HiveConf if there are any System properties set, cloned HiveConf inherits those properties. In the test case (&lt;tt&gt;MiniHS2&lt;/tt&gt;) scratchdir property is modified in System properties (See &lt;a href=&quot;https://github.com/apache/hive/blob/trunk/itests/hive-unit/src/main/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java#L184&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;), but the default scratchdir value is &lt;tt&gt;${test.tmp.dir}/scratchdir&lt;/tt&gt; from hive-site.xml. Scrathdir set in &lt;tt&gt;MiniHS2&lt;/tt&gt; is never used before, but with this change HS2 started using it. Scratchdir created in &lt;tt&gt;MiniHS2&lt;/tt&gt; (See &lt;a href=&quot;https://github.com/apache/hive/blob/trunk/itests/hive-unit/src/main/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java#L183&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;) doesn&apos;t have 777 permissions, so whenever we have user impersonation there are issues (thats where the test is failing). Before this change, scratchdir is always &lt;tt&gt;${test.tmp.dir}/scratchdir&lt;/tt&gt; which is created in HS2 with 777 permissions (See &lt;a href=&quot;https://github.com/apache/hive/blob/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java#L3458&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;), so there were no issues with the impersonation. &lt;/p&gt;

&lt;p&gt;I think it is better to fix this in SparkClient by fetching the jar directly than through HiveConf, to avoid unexpected issues.&lt;/p&gt;
</comment>
                            <comment id="14103717" author="vkorukanti" created="Wed, 20 Aug 2014 10:13:55 +0000"  >&lt;p&gt;Attaching v2 patch specific to spark-branch.&lt;/p&gt;</comment>
                            <comment id="14103793" author="hiveqa" created="Wed, 20 Aug 2014 11:58:51 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12663103/HIVE-7747.2-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12663103/HIVE-7747.2-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 9 failed/errored test(s), 5958 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_union2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_union3
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_union5
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_union7
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_union8
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_union9
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_fs_default_name2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/66/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/66/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/66/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/66/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-66/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-66/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12663103&lt;/p&gt;</comment>
                            <comment id="14104205" author="brocknoland" created="Wed, 20 Aug 2014 17:48:53 +0000"  >&lt;p&gt;Wow, nice analysis! +1&lt;/p&gt;</comment>
                            <comment id="14104211" author="brocknoland" created="Wed, 20 Aug 2014 17:50:02 +0000"  >&lt;p&gt;Thank you so much Venki! I have committed this to spark!&lt;/p&gt;</comment>
                            <comment id="14189815" author="qiaohaijun" created="Thu, 30 Oct 2014 08:53:38 +0000"  >
&lt;p&gt;1&lt;br/&gt;
2&lt;br/&gt;
3&lt;br/&gt;
4&lt;br/&gt;
5&lt;br/&gt;
6&lt;br/&gt;
7&lt;br/&gt;
8&lt;br/&gt;
9&lt;br/&gt;
10&lt;br/&gt;
11&lt;br/&gt;
12&lt;br/&gt;
13&lt;br/&gt;
14&lt;br/&gt;
15&lt;br/&gt;
Error: org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 2.0 failed 4 times, most recent failure: Lost task 7.3 in stage 2.0 (TID 28, cloud1014113114.wd.nm.ss.nop.sogou-op.org): java.lang.IllegalStateException: unread block data&lt;br/&gt;
        java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2421)&lt;br/&gt;
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1382)&lt;br/&gt;
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)&lt;br/&gt;
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)&lt;br/&gt;
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)&lt;br/&gt;
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)&lt;br/&gt;
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)&lt;br/&gt;
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)&lt;br/&gt;
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)&lt;br/&gt;
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:160)&lt;br/&gt;
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
        java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Driver stacktrace: (state=,code=0)&lt;/p&gt;

&lt;p&gt;&amp;#8212;&lt;/p&gt;

&lt;p&gt;spark 1.1.1 &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12723734">HIVE-7292</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12728027">HIVE-7437</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12662930" name="HIVE-7747.1.patch" size="794" author="vkorukanti" created="Wed, 20 Aug 2014 00:33:17 +0000"/>
                            <attachment id="12663103" name="HIVE-7747.2-spark.patch" size="701" author="vkorukanti" created="Wed, 20 Aug 2014 10:13:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>412502</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 3 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1yyo7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>412489</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>