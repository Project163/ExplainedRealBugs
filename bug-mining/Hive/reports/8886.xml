<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 19:27:20 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-28804] The user does not have the permission for the table hdfs, but can delete the metadata</title>
                <link>https://issues.apache.org/jira/browse/HIVE-28804</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When I create a table using the &lt;b&gt;hdfs&lt;/b&gt; user and write data into it, and then use the &lt;b&gt;hive&lt;/b&gt; user to delete this table, the engine side shows that the deletion is successful. However, the metastore log indicates that the deletion failed due to insufficient permissions when deleting the HDFS directory. Nevertheless, the metadata has been deleted. This situation may result in the data of this table becoming junk data.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;The following exception is from version 3.1.2, but I have found that it also occurs in version 4.0.1.&lt;/p&gt;

&lt;p&gt;the exception:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2025-03-04 16:44:27,617 | WARN | org.apache.hadoop.hive.metastore.utils.FileUtils | Failed to move to trash: hdfs:&lt;span class=&quot;code-comment&quot;&gt;//myns/warehouse/tablespace/managed/hive/test_drop; Force to delete it.
&lt;/span&gt;2025-03-04 16:44:27,621 | ERROR | org.apache.hadoop.hive.metastore.utils.MetaStoreUtils | Got exception: org.apache.hadoop.security.AccessControlException Permission denied: user=hive, access=ALL, inode=&lt;span class=&quot;code-quote&quot;&gt;&quot;/warehouse/tablespace/managed/hive/test_drop&quot;&lt;/span&gt;:hdfs:hadoop:drwxr-xr-x
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkSubAccess(FSPermissionChecker.java:455)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:356)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermissionWithContext(FSPermissionChecker.java:370)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:240)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1943)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:105)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3300)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1153)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:725)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:614)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:582)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:566)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1116)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:983)
&#160; &#160; &#160; &#160; at java.security.AccessController.doPrivileged(Native Method)
&#160; &#160; &#160; &#160; at javax.security.auth.Subject.doAs(Subject.java:422)
&#160; &#160; &#160; &#160; at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1890)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2997)org.apache.hadoop.security.AccessControlException: Permission denied: user=hive, access=ALL, inode=&lt;span class=&quot;code-quote&quot;&gt;&quot;/warehouse/tablespace/managed/hive/test_drop&quot;&lt;/span&gt;:hdfs:hadoop:drwxr-xr-x
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkSubAccess(FSPermissionChecker.java:455)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:356)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermissionWithContext(FSPermissionChecker.java:370)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:240)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1943)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:105)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3300)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1153)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:725)
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:614)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:582)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:566)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1116)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:983)
&#160; &#160; &#160; &#160; at java.security.AccessController.doPrivileged(Native Method)
&#160; &#160; &#160; &#160; at javax.security.auth.Subject.doAs(Subject.java:422)
&#160; &#160; &#160; &#160; at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1890)
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2997)&#160; &#160; &#160; &#160; at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_352]
&#160; &#160; &#160; &#160; at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_352]
&#160; &#160; &#160; &#160; at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_352]
&#160; &#160; &#160; &#160; at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_352]
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121) ~[hadoop-common-3.3.3.jar:?]
&#160; &#160; &#160; &#160; at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88) ~[hadoop-common-3.3.3.jar:?]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1664) ~[hadoop-hdfs-client-3.3.3.jar:?]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:992) ~[hadoop-hdfs-client-3.3.3.jar:?]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:989) ~[hadoop-hdfs-client-3.3.3.jar:?]
&#160; &#160; &#160; &#160; at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) ~[hadoop-common-3.3.3.jar:?]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:999) ~[hadoop-hdfs-client-3.3.3.jar:?]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hive.metastore.utils.FileUtils.moveToTrash(FileUtils.java:97) ~[hive-exec-3.1.2.jar:3.1.2]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl.deleteDir(HiveMetaStoreFsImpl.java:41) [hive-exec-3.1.2.jar:3.1.2]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hive.metastore.Warehouse.deleteDir(Warehouse.java:363) [hive-exec-3.1.2.jar:3.1.2]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hive.metastore.Warehouse.deleteDir(Warehouse.java:351) [hive-exec-3.1.2.jar:3.1.2]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.deleteTableData(HiveMetaStore.java:2586) [hive-exec-3.1.2.jar:3.1.2]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table_core(HiveMetaStore.java:2559) [hive-exec-3.1.2.jar:3.1.2]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table_with_environment_context(HiveMetaStore.java:2708) [hive-exec-3.1.2.jar:3.1.2]
&#160; &#160; &#160; &#160; at sun.reflect.GeneratedMethodAccessor238.invoke(Unknown Source) ~[?:?]
&#160; &#160; &#160; &#160; at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
&#160; &#160; &#160; &#160; at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) [hive-exec-3.1.2.jar:3.1.2]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) [hive-exec-3.1.2.jar:3.1.2]
&#160; &#160; &#160; &#160; at com.sun.proxy.$Proxy27.drop_table_with_environment_context(Unknown Source) [?:?]
&#160; &#160; &#160; &#160; at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_table_with_environment_context.getResult(ThriftHiveMetastore.java:15068) [hive-exec-3.1.2.jar:3.1.2]
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;After I modified the code, the deletion of the table failed and an exception was thrown by the engine side as follows:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:Table metadata not deleted since hdfs:&lt;span class=&quot;code-comment&quot;&gt;//myns/warehouse/tablespace/managed/hive/test_drop_2 is not writable by mytest/x86-231-master1-90-176@x86.test.2)
&lt;/span&gt;&#160; &#160; at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:1207)
&#160; &#160; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
&#160; &#160; at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
&#160; &#160; at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
&#160; &#160; at java.lang.reflect.Method.invoke(Method.java:498)
&#160; &#160; at org.apache.spark.sql.hive.client.Shim_v0_14.dropTable(HiveShim.scala:1326)
&#160; &#160; at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$dropTable$1(HiveClientImpl.scala:573)
&#160; &#160; at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
&#160; &#160; at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:298)
&#160; &#160; at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:229)
&#160; &#160; at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:228)
&#160; &#160; at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:278)
&#160; &#160; at org.apache.spark.sql.hive.client.HiveClientImpl.dropTable(HiveClientImpl.scala:573)
&#160; &#160; at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$dropTable$1(HiveExternalCatalog.scala:525)
&#160; &#160; at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
&#160; &#160; at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:101)
&#160; &#160; ... 60 more
Caused by: MetaException(message:Table metadata not deleted since hdfs:&lt;span class=&quot;code-comment&quot;&gt;//myns/warehouse/tablespace/managed/hive/test_drop_2 is not writable by mytest/x86-231-master1-90-176@x86.test.2)
&lt;/span&gt;&#160; &#160; at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_table_with_environment_context_result$drop_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:48279)
&#160; &#160; at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_table_with_environment_context_result$drop_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:48256)
&#160; &#160; at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_table_with_environment_context_result.read(ThriftHiveMetastore.java:48198)
&#160; &#160; at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88)
&#160; &#160; at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_table_with_environment_context(ThriftHiveMetastore.java:1378)
&#160; &#160; at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_table_with_environment_context(ThriftHiveMetastore.java:1362)
&#160; &#160; at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.drop_table_with_environment_context(HiveMetaStoreClient.java:2402)
&#160; &#160; at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.drop_table_with_environment_context(SessionHiveMetaStoreClient.java:114)
&#160; &#160; at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropTable(HiveMetaStoreClient.java:1093)
&#160; &#160; at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropTable(HiveMetaStoreClient.java:1029)
&#160; &#160; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
&#160; &#160; at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
&#160; &#160; at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
&#160; &#160; at java.lang.reflect.Method.invoke(Method.java:498)
&#160; &#160; at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)
&#160; &#160; at com.sun.proxy.$Proxy44.dropTable(Unknown Source)
&#160; &#160; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
&#160; &#160; at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
&#160; &#160; at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
&#160; &#160; at java.lang.reflect.Method.invoke(Method.java:498)
&#160; &#160; at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2327)
&#160; &#160; at com.sun.proxy.$Proxy44.dropTable(Unknown Source)
&#160; &#160; at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:1201)
&#160; &#160; ... 75 more
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13610879">HIVE-28804</key>
            <summary>The user does not have the permission for the table hdfs, but can delete the metadata</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zengxl">zengxl</assignee>
                                    <reporter username="zengxl">zengxl</reporter>
                        <labels>
                            <label>patch</label>
                            <label>pull-request-available</label>
                    </labels>
                <created>Thu, 6 Mar 2025 11:55:59 +0000</created>
                <updated>Mon, 28 Jul 2025 08:41:10 +0000</updated>
                            <resolved>Wed, 23 Jul 2025 13:53:57 +0000</resolved>
                                    <version>3.1.2</version>
                    <version>4.0.1</version>
                                    <fixVersion>4.2.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="17932974" author="zengxl" created="Thu, 6 Mar 2025 12:03:33 +0000"  >&lt;p&gt;At the same time, the addition of logs is to know how long it takes to delete metadata and HDFS data respectively when deleting a table.&lt;/p&gt;</comment>
                            <comment id="18005526" author="dkuzmenko" created="Tue, 15 Jul 2025 07:43:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zengxl&quot; class=&quot;user-hover&quot; rel=&quot;zengxl&quot;&gt;zengxl&lt;/a&gt; see comments in the PR. This is not a valid usage pattern for a managed table.&lt;/p&gt;</comment>
                            <comment id="18009270" author="dkuzmenko" created="Wed, 23 Jul 2025 13:53:50 +0000"  >&lt;p&gt;Merged to master&lt;/p&gt;

&lt;p&gt;Thanks for the fix, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zengxl&quot; class=&quot;user-hover&quot; rel=&quot;zengxl&quot;&gt;zengxl&lt;/a&gt; !&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311020" key="com.atlassian.jira.plugin.system.customfieldtypes:url">
                        <customfieldname>External issue URL</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[https://github.com/apache/hive/pull/5875]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12314421" key="com.atlassian.jira.plugin.system.customfieldtypes:labels">
                        <customfieldname>Language</customfieldname>
                        <customfieldvalues>
                                        <label>Java</label>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            16 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1um1s:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12344397">3.1.2</customfieldvalue>
    <customfieldvalue id="12354786">4.0.1</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>