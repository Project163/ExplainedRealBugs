<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:53:50 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-16534] Add capability to tell aborted transactions apart from open transactions in ValidTxnList</title>
                <link>https://issues.apache.org/jira/browse/HIVE-16534</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently in ValidReadTxnList, open transactions and aborted transactions are stored together in one array. That makes it impossible to extract just aborted transactions or open transactions.&lt;/p&gt;

&lt;p&gt;For ValidCompactorTxnList this is fine, since we only store aborted transactions but no open transactions.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13066879">HIVE-16534</key>
            <summary>Add capability to tell aborted transactions apart from open transactions in ValidTxnList</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wzheng">Wei Zheng</assignee>
                                    <reporter username="wzheng">Wei Zheng</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Apr 2017 22:54:03 +0000</created>
                <updated>Tue, 22 May 2018 23:58:14 +0000</updated>
                            <resolved>Tue, 2 May 2017 20:54:23 +0000</resolved>
                                                    <fixVersion>3.0.0</fixVersion>
                                    <component>Transactions</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="15983794" author="wzheng" created="Tue, 25 Apr 2017 23:10:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ekoifman&quot; class=&quot;user-hover&quot; rel=&quot;ekoifman&quot;&gt;ekoifman&lt;/a&gt; Can you take a look at WIP patch 1?&lt;/p&gt;</comment>
                            <comment id="15983882" author="ekoifman" created="Wed, 26 Apr 2017 00:24:39 +0000"  >&lt;p&gt;I think this needs some tests.  For example, &lt;br/&gt;
_int index = Arrays.binarySearch(exceptions, txn);_should return -1 if txn is not found.&lt;br/&gt;
which means &lt;em&gt;if (abortedBits.get(index)) {&lt;/em&gt; will fail with some ArrayIndexOutOfBounds or something&lt;/p&gt;


&lt;p&gt;ValidReadTxnList.isTxnRangeAborted() is doing (maxTxnId-minTxnId) binary searches.  Why not just do 1 for minTxnId and then use nextSetBit(int fromIndex) to find next aborted txn and see if it equals minTxnId + 1, etc.&lt;/p&gt;


&lt;p&gt;Also, you don&apos;t need to override isTxnRangeAborted() ValidCompactorTxnList.&lt;/p&gt;

&lt;p&gt;some javadoc on new methods would be useful&lt;/p&gt;</comment>
                            <comment id="15985262" author="wzheng" created="Wed, 26 Apr 2017 17:54:44 +0000"  >&lt;p&gt;For ValidReadTxnList.isTxnRangeAborted, I think I shouldn&apos;t have performed check for every txn in exceptions. Instead I should just scan every txn from min to max in the specified range, and for each of them, check if it&apos;s aborted by searching exceptions and the bitset. I corrected that. &lt;/p&gt;

&lt;p&gt;I think the override of isTxnRangeAborted in ValidCompactorTxnList is necessary. The reason is for ValidCompactorTxnList, &quot;exceptions&quot; includes aborted txns only (see TxnUtils.createValidCompactTxnList). So we don&apos;t maintain a bitset for it as it&apos;s not necessary. So in the implementation of that method we have a slight difference which is we omit the check against the bitset.&lt;/p&gt;

&lt;p&gt;I will add JavaDoc and tests.&lt;/p&gt;</comment>
                            <comment id="15985284" author="ekoifman" created="Wed, 26 Apr 2017 18:07:18 +0000"  >&lt;p&gt;using nextSetBig() is also linear but faster for cases where not all txn are aborted; you&apos;d still want to do Binary Search to find the minTxn in the exceptions list&lt;br/&gt;
if there are no aborted txns, the BitSet is empty and &quot;abortedBits.get(index)&quot; is always false - that is why it&apos;s the same for both.&lt;/p&gt;
</comment>
                            <comment id="15985600" author="wzheng" created="Wed, 26 Apr 2017 21:30:07 +0000"  >&lt;p&gt;OK, I agree the override for isTxnRangeAborted is not necessary. I also adopted the approach you suggested which is to use nextSetBit to check if an aborted transaction falls into the range between min and max.&lt;/p&gt;</comment>
                            <comment id="15987768" author="wzheng" created="Thu, 27 Apr 2017 21:48:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ekoifman&quot; class=&quot;user-hover&quot; rel=&quot;ekoifman&quot;&gt;ekoifman&lt;/a&gt; Can you take a look at patch 2?&lt;/p&gt;</comment>
                            <comment id="15989172" author="ekoifman" created="Fri, 28 Apr 2017 17:15:18 +0000"  >&lt;p&gt;you refactored ValidReadTxnList() c&apos;tor and removed the sorting of exceptions - why?&lt;br/&gt;
writeToString() always creates 3 &apos;:&apos; - why does the deserializer need cases like &lt;em&gt;if (values.length &amp;lt; 3) {&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;wouldn&apos;t be simpler to just serialize the BitSet as &quot;0010110....&quot; - it&apos;s very compact and the deserializer wouldn&apos;t have to sort and do multiple binary searches.... &lt;/p&gt;

&lt;p&gt;why does &lt;em&gt;isTxnAborted()&lt;/em&gt; need a binary search?  why not just look up the in the bitset?&lt;/p&gt;

&lt;p&gt;&lt;em&gt;bitSet.set(0, bitSet.length()); // for ValidCompactorTxnList, everything in exceptio&lt;/em&gt; - shouldn&apos;t this turn all the bits ON?&lt;br/&gt;
Nit: seems like ValidCompactorTxnList() c&apos;tor could do this  since it&apos;s always the case for compactor&lt;/p&gt;
</comment>
                            <comment id="15989239" author="wzheng" created="Fri, 28 Apr 2017 18:00:03 +0000"  >&lt;p&gt;The sorting of exceptions in ValidReadTxnList is troublesome for the accompanying BitSet, as we have to sort the BitSet in the same manner. So I removed the sorting logic in the ctor and added &quot;oder by txn_id&quot; to TxnHandler.getOpenTxns so we don&apos;t need to worry about sorting later on.&lt;/p&gt;

&lt;p&gt;It&apos;s true that we always have 3 &apos;:&apos;. But if some fields are missing, e.g. &quot;1:2::&quot;, then String.split() will only return an array of size 2.&lt;/p&gt;

&lt;p&gt;I do serialize the BitSet into a byte array before sending it over Thrift interface. After receiving it I convert it back to BitSet since the bit manipulation is convenient.&lt;/p&gt;

&lt;p&gt;I need to binary search in isTxnAborted() to get the index for the txnid, then look up in the bitset using that index.&lt;/p&gt;

&lt;p&gt;bitSet.set(0, bitSet.length()) does turn all the bits on, right?&lt;/p&gt;</comment>
                            <comment id="15989271" author="ekoifman" created="Fri, 28 Apr 2017 18:22:06 +0000"  >
&lt;blockquote&gt;&lt;p&gt;I do serialize the BitSet into a byte array before sending it over Thrift interface. After receiving it I convert it back to BitSet since the bit manipulation is convenient.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I meant in writeToString() - seems like that would make reading from string much simper/efficient&lt;/p&gt;

&lt;p&gt;You are right about the other points&lt;/p&gt;</comment>
                            <comment id="15989294" author="ekoifman" created="Fri, 28 Apr 2017 18:51:12 +0000"  >&lt;p&gt;another thought: I think implementation of isTxnRangeAborted() is problematic&lt;br/&gt;
suppose we do an insert in Table1/part1 with txnid=5.  Then there is no activity on this table for a month.&lt;br/&gt;
Then there is another insert into Table1/part1 with txnid=1000000.&lt;br/&gt;
After compaction we get a delta_5_1000000.&lt;/p&gt;

&lt;p&gt;so now this method is going to do 1M binary searches....&lt;/p&gt;

&lt;p&gt;If (isAborted(minTxnId) &amp;amp;&amp;amp; isAborted(maxTxnId) &amp;amp;&amp;amp; (the number of on bits in BitSet between index of minTxnId and maxTxnId is max - min + 1) - then all txns in range in question are aborted - this gives ALL&lt;/p&gt;

&lt;p&gt;I&apos;m not sure how to do NONE/SOME efficiently&lt;/p&gt;</comment>
                            <comment id="15989305" author="wzheng" created="Fri, 28 Apr 2017 19:04:19 +0000"  >&lt;p&gt;We can drop this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (txnId &amp;lt;= maxTxnId) {
      firstAbortedTxnIndex = Arrays.binarySearch(exceptions, txnId);
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (firstAbortedTxnIndex &amp;gt;= 0) {
        &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
      }
      txnId++;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The main usage of above code is to locate the index for first aborted txn in the range so that we can save some unnecessary iterations when scanning the BitSet. But in your example which is very likely to be a common situation, this is not acceptable.&lt;/p&gt;

&lt;p&gt;Considering the BitSet is not big (comparing to the gap between 5 and 1000000), we can just start from index 0 and scan thru the BitSet. I think this should be ok.&lt;/p&gt;</comment>
                            <comment id="15991589" author="wzheng" created="Mon, 1 May 2017 21:29:25 +0000"  >&lt;p&gt;patch 3 removes the binary search logic in isTxnRangeAborted as commented above.&lt;/p&gt;</comment>
                            <comment id="15991638" author="ekoifman" created="Mon, 1 May 2017 21:58:55 +0000"  >&lt;p&gt;+1 patch 3 pending tests&lt;br/&gt;
Could you add a comment that the exception list is excepted the sorted when passed in ValidReadTxnList&lt;/p&gt;
</comment>
                            <comment id="15991657" author="wzheng" created="Mon, 1 May 2017 22:16:09 +0000"  >&lt;p&gt;Added the comment for ValidTxnList.readFromString&lt;/p&gt;</comment>
                            <comment id="15991764" author="hiveqa" created="Mon, 1 May 2017 23:20:13 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12865830/HIVE-16534.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12865830/HIVE-16534.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4970/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4970/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4970/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4970/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-4970/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-4970/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hiveptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-05-01 23:20:05.963
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;MAVEN_OPTS=-Xmx1g &apos;
+ MAVEN_OPTS=&apos;-Xmx1g &apos;
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4970/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-05-01 23:20:05.966
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 2f79bd6 HIVE-16520: Cache hive metadata in metastore (Daniel Dai, Vaibhav Gumashta, reviewed by Thejas Nair)
+ git clean -f -d
+ git checkout master
Already on &apos;master&apos;
Your branch is up-to-date with &apos;origin/master&apos;.
+ git reset --hard origin/master
HEAD is now at 2f79bd6 HIVE-16520: Cache hive metadata in metastore (Daniel Dai, Vaibhav Gumashta, reviewed by Thejas Nair)
+ git merge --ff-only origin/master
Already up-to-date.
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-05-01 23:20:11.973
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: patch failed: metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp:6055
error: metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp: patch does not apply
error: patch failed: metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php:15489
error: metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php: patch does not apply
error: patch failed: metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java:51
error: metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java: patch does not apply
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12865830 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15991989" author="hiveqa" created="Tue, 2 May 2017 02:04:03 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4974/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4974/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4974/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4974/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-4974/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-4974/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hiveptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-05-02 02:03:35.278
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;MAVEN_OPTS=-Xmx1g &apos;
+ MAVEN_OPTS=&apos;-Xmx1g &apos;
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4974/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-05-02 02:03:35.280
+ cd apache-github-source-source
+ git fetch origin
From https://github.com/apache/hive
   62fbdd8..5ab03cb  master     -&amp;gt; origin/master
+ git reset --hard HEAD
HEAD is now at 62fbdd8 Add license and notice file for storage-api
+ git clean -f -d
Removing metastore/scripts/upgrade/derby/040-HIVE-16399.derby.sql
Removing metastore/scripts/upgrade/mssql/025-HIVE-16399.mssql.sql
Removing metastore/scripts/upgrade/mysql/040-HIVE-16399.mysql.sql
Removing metastore/scripts/upgrade/oracle/040-HIVE-16399.oracle.sql
Removing metastore/scripts/upgrade/postgres/039-HIVE-16399.postgres.sql
+ git checkout master
Already on &apos;master&apos;
Your branch is behind &apos;origin/master&apos; by 2 commits, and can be fast-forwarded.
  (use &quot;git pull&quot; to update your local branch)
+ git reset --hard origin/master
HEAD is now at 5ab03cb HIVE-16524: Remove the redundant item type in hiveserver2.jsp and QueryProfileTmpl.jamon (ZhangBing via Xuefu)
+ git merge --ff-only origin/master
Already up-to-date.
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-05-02 02:03:40.406
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/common/ValidCompactorTxnList.java
patching file common/src/java/org/apache/hadoop/hive/common/ValidReadTxnList.java
patching file common/src/java/org/apache/hadoop/hive/common/ValidTxnList.java
patching file common/src/test/org/apache/hadoop/hive/common/TestValidReadTxnList.java
patching file itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/txn/compactor/TestCompactor.java
patching file metastore/if/hive_metastore.thrift
patching file metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp
patching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.cpp
patching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.h
patching file metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetOpenTxnsResponse.java
patching file metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php
patching file metastore/src/gen/thrift/gen-php/metastore/Types.php
patching file metastore/src/gen/thrift/gen-py/hive_metastore/ttypes.py
patching file metastore/src/gen/thrift/gen-rb/hive_metastore_types.rb
patching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
patching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java
patching file metastore/src/test/org/apache/hadoop/hive/metastore/txn/TestValidCompactorTxnList.java
patching file ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hiveptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven
[ERROR] COMPILATION ERROR : 
[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-common: Compilation failure
[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-common
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12865844 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15991995" author="hiveqa" created="Tue, 2 May 2017 02:07:36 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4977/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4977/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4977/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4977/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-4977/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-4977/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hiveptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-05-02 02:07:19.555
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;MAVEN_OPTS=-Xmx1g &apos;
+ MAVEN_OPTS=&apos;-Xmx1g &apos;
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4977/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-05-02 02:07:19.557
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 5ab03cb HIVE-16524: Remove the redundant item type in hiveserver2.jsp and QueryProfileTmpl.jamon (ZhangBing via Xuefu)
+ git clean -f -d
Removing metastore/scripts/upgrade/hive/
Removing ql/src/test/queries/clientpositive/sysdb.q
Removing ql/src/test/results/clientpositive/llap/sysdb.q.out
+ git checkout master
Already on &apos;master&apos;
Your branch is up-to-date with &apos;origin/master&apos;.
+ git reset --hard origin/master
HEAD is now at 5ab03cb HIVE-16524: Remove the redundant item type in hiveserver2.jsp and QueryProfileTmpl.jamon (ZhangBing via Xuefu)
+ git merge --ff-only origin/master
Already up-to-date.
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-05-02 02:07:20.082
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/common/ValidCompactorTxnList.java
patching file common/src/java/org/apache/hadoop/hive/common/ValidReadTxnList.java
patching file common/src/java/org/apache/hadoop/hive/common/ValidTxnList.java
patching file common/src/test/org/apache/hadoop/hive/common/TestValidReadTxnList.java
patching file itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/txn/compactor/TestCompactor.java
patching file metastore/if/hive_metastore.thrift
patching file metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp
patching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.cpp
patching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.h
patching file metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetOpenTxnsResponse.java
patching file metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php
patching file metastore/src/gen/thrift/gen-php/metastore/Types.php
patching file metastore/src/gen/thrift/gen-py/hive_metastore/ttypes.py
patching file metastore/src/gen/thrift/gen-rb/hive_metastore_types.rb
patching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
patching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java
patching file metastore/src/test/org/apache/hadoop/hive/metastore/txn/TestValidCompactorTxnList.java
patching file ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hiveptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven
[ERROR] COMPILATION ERROR : 
[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-common: Compilation failure
[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-common
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12865844 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15992283" author="hiveqa" created="Tue, 2 May 2017 03:32:51 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 3 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 257 failed/errored test(s), 10634 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_join] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_mapjoin] (batchId=10)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_partition] (batchId=68)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_project] (batchId=18)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_delete] (batchId=77)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_delete_own_table] (batchId=62)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_update] (batchId=8)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_update_own_table] (batchId=73)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_orig_table] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_tmp_table] (batchId=48)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_no_match] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_partitioned] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_whole_partition] (batchId=9)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_acid_dynamic_partition] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_nonacid_from_acid] (batchId=69)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_orig_table] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_update_delete] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=71)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table] (batchId=54)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_partitioned] (batchId=71)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_tmp_table] (batchId=4)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_acid] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_reader] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_ppd_exception] (batchId=32)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=73)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[transform_acid] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=64)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts_special_characters] (batchId=68)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_non_partitioned] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_partitioned] (batchId=49)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_types] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_orig_table] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_tmp_table] (batchId=34)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_two_cols] (batchId=20)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_no_match] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_non_partitioned] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_partitioned] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_acid3] (batchId=26)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_join_part_col_char] (batchId=22)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_dynamic] (batchId=163)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_static] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=137)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[acid_globallimit] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[acid_vectorization_missing_cols] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_partitioned] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_tmp_table] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_no_match] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_whole_partition] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_orig_table] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_update_delete] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_partitioned] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_tmp_table] (batchId=142)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part_update] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table_update] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part_update] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table_update] (batchId=142)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_non_partitioned] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_partitioned] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_types] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_tmp_table] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_two_cols] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_no_match] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_non_partitioned] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_partitioned] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_acid3] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[delete_orig_table] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[update_orig_table] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_join_part_col_char] (batchId=96)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[acid_overwrite] (batchId=88)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns (batchId=209)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testOpenTxnNotExcluded (batchId=209)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange (batchId=209)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxns (batchId=209)
org.apache.hadoop.hive.metastore.txn.TestCompactionTxnHandler.testMarkCleanedCleansTxnsAndTxnComponents (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandler.testAbortTxn (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandler.testOpenTxn (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandler.testValidTxnsEmpty (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandler.testValidTxnsNoneOpen (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandler.testValidTxnsSomeOpen (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandlerNoConnectionPool.testOpenTxn (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestValidCompactorTxnList.writeToString (batchId=193)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnMR (batchId=210)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnTez (batchId=210)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnMR (batchId=210)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnTez (batchId=210)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnMR (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnTez (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnMR (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnTez (batchId=213)
org.apache.hadoop.hive.ql.TestTxnCommands.testDelete (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testErrors (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testExplicitRollback (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testImplicitRollback (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeCardinalityViolation (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeCase (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeDeleteUpdate (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD01 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD02 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDelete (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDeleteNoCardCheck (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleInserts (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testQuotedIdentifier (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testQuotedIdentifier2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testReadMyOwnInsert (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testSimpleAcidInsert (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testTimeOutReaper (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2.testACIDwithSchemaEvolutionAndCompaction (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testAcidWithSchemaEvolution (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testAlterTable (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testBucketizedInputFormat (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testCompactWithDelete (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge2 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testETLSplitStrategyForACID (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testFailHeartbeater (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testFileSystemUnCaching (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testInitiatorWithMultipleFailedCompactions (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge2 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge3 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMergeWithPredicate (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsertStatement (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNoHistory (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion1 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion2 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testSimpleRead (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.updateDeletePartitioned (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.writeBetweenWorkerAndCleaner (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testACIDwithSchemaEvolutionAndCompaction (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAcidWithSchemaEvolution (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAlterTable (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testBucketizedInputFormat (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testCompactWithDelete (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDeleteIn (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testETLSplitStrategyForACID (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testFailHeartbeater (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testFileSystemUnCaching (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testInitiatorWithMultipleFailedCompactions (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge2 (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge3 (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMultiInsertStatement (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNoHistory (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion1 (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion2 (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion3 (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcNoPPD (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcPPD (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testSimpleRead (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testUpdateMixedCase (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.updateDeletePartitioned (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.writeBetweenWorkerAndCleaner (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testACIDwithSchemaEvolutionAndCompaction (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAcidWithSchemaEvolution (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAlterTable (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testBucketizedInputFormat (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testCompactWithDelete (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDeleteIn (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testETLSplitStrategyForACID (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testFailHeartbeater (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testFileSystemUnCaching (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testInitiatorWithMultipleFailedCompactions (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge2 (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge3 (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertStatement (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNoHistory (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion1 (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion2 (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcNoPPD (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcPPD (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testSimpleRead (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testUpdateMixedCase (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.updateDeletePartitioned (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.writeBetweenWorkerAndCleaner (batchId=272)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.checkExpectedLocks2 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testCompletedTxnComponents (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testDynamicPartitionInsert (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way01 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way02 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned01 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned02 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned01 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned02 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMetastoreTablesCleanup (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMultiInsert (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking10 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking11 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking3 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking5 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking7 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking8 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking9 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.updateSelectUpdate (batchId=276)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningInsert (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningInsert (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningUpdate (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithInsertsAndDeletes (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithOnlyInserts (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testTableProperties (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.cleanEmptyAbortedTxns (batchId=253)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=187)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=187)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=187)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=187)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=187)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=187)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4982/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4982/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4982/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4982/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-4982/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-4982/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 257 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12865844 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15992486" author="hiveqa" created="Tue, 2 May 2017 07:30:41 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12865883/HIVE-16534.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12865883/HIVE-16534.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 3 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 5 failed/errored test(s), 10635 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns (batchId=209)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange (batchId=209)
org.apache.hadoop.hive.metastore.txn.TestValidCompactorTxnList.writeToString (batchId=193)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4987/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4987/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4987/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4987/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-4987/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-4987/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12865883 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15993311" author="hiveqa" created="Tue, 2 May 2017 17:22:15 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12865883/HIVE-16534.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12865883/HIVE-16534.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 3 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 5 failed/errored test(s), 10637 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns (batchId=209)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange (batchId=209)
org.apache.hadoop.hive.metastore.txn.TestValidCompactorTxnList.writeToString (batchId=193)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4998/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4998/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4998/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4998/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-4998/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-4998/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12865883 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15993538" author="hiveqa" created="Tue, 2 May 2017 19:12:53 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12866005/HIVE-16534.7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12866005/HIVE-16534.7.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 4 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 10637 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[ppd_windowing2] (batchId=10)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5000/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5000/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5000/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5000/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5000/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5000/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12866005 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15993724" author="wzheng" created="Tue, 2 May 2017 20:54:23 +0000"  >&lt;p&gt;Committed patch 7 to master. Thanks Eugene for the review.&lt;/p&gt;</comment>
                            <comment id="16485913" author="vgarg" created="Tue, 22 May 2018 23:58:14 +0000"  >&lt;p&gt;Hive 3.0.0 has been released so closing this jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13068247">HIVE-16565</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13074335">HIVE-16743</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="13009340">HIVE-14881</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12865024" name="HIVE-16534.1.patch" size="460794" author="wzheng" created="Tue, 25 Apr 2017 23:10:11 +0000"/>
                            <attachment id="12865429" name="HIVE-16534.2.patch" size="471995" author="wzheng" created="Thu, 27 Apr 2017 21:47:51 +0000"/>
                            <attachment id="12865821" name="HIVE-16534.3.patch" size="471502" author="wzheng" created="Mon, 1 May 2017 21:24:39 +0000"/>
                            <attachment id="12865830" name="HIVE-16534.4.patch" size="471822" author="wzheng" created="Mon, 1 May 2017 22:16:09 +0000"/>
                            <attachment id="12865844" name="HIVE-16534.5.patch" size="475927" author="wzheng" created="Mon, 1 May 2017 23:46:56 +0000"/>
                            <attachment id="12865883" name="HIVE-16534.6.patch" size="475928" author="wzheng" created="Tue, 2 May 2017 06:33:30 +0000"/>
                            <attachment id="12866005" name="HIVE-16534.7.patch" size="477874" author="wzheng" created="Tue, 2 May 2017 16:43:58 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 26 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3e3nj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12340268">3.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>