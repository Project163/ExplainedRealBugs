<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:02:06 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-3303] Fix error code inconsistency bug in mapreduce_stack_trace.q and mapreduce_stack_trace_turnoff.q when running hive on hadoop23</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3303</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;when running hive on hadoop23, mapreduce_stack_trace.q and mapreduce_stack_trace_turnoff.q are having inconsistent error code diffs:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; diff -a /home/cloudera/Code/hive/build/ql/test/logs/clientnegative/mapreduce_stack_trace.q.out /home/cloudera/Code/hive/ql/src/test/results/clientnegative/mapreduce_stack_trace.q.out&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;lt; FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; FAILED: Execution Error, return code 20000 from org.apache.hadoop.hive.ql.exec.MapRedTask. Unable to initialize custom script.&lt;/p&gt;


&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; diff -a /home/cloudera/Code/hive/build/ql/test/logs/clientnegative/mapreduce_stack_trace_turnoff.q.out /home/cloudera/Code/hive/ql/src/test/results/clientnegative/mapreduce_stack_trace_turnoff.q.out&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 5c5&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;lt; FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &#8212;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; FAILED: Execution Error, return code 20000 from org.apache.hadoop.hive.ql.exec.MapRedTask. Unable to initialize custom script&lt;/p&gt;

&lt;p&gt;The error code 20000(which indicates unable to initialize custom script) could not be retrieved. &lt;/p&gt;
</description>
                <environment></environment>
        <key id="12600252">HIVE-3303</key>
            <summary>Fix error code inconsistency bug in mapreduce_stack_trace.q and mapreduce_stack_trace_turnoff.q when running hive on hadoop23</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zhenxiao">Zhenxiao Luo</assignee>
                                    <reporter username="zhenxiao">Zhenxiao Luo</reporter>
                        <labels>
                    </labels>
                <created>Thu, 26 Jul 2012 01:14:26 +0000</created>
                <updated>Thu, 10 Jan 2013 19:53:47 +0000</updated>
                            <resolved>Tue, 31 Jul 2012 05:43:53 +0000</resolved>
                                                    <fixVersion>0.10.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="13422816" author="zhenxiao" created="Thu, 26 Jul 2012 01:35:21 +0000"  >&lt;p&gt;The problem is, hadoop23 is getting Task-diagnostics differently from hadoop20.&lt;/p&gt;

&lt;p&gt;In hadoop20, Task-diagnostics is retrieved via jobSubmitClient in JobClient.java:&lt;/p&gt;

&lt;p&gt; public String[] getTaskDiagnostics(TaskAttemptID id) throws IOException &lt;/p&gt;
{
      return jobSubmitClient.getTaskDiagnostics(id);
    }

&lt;p&gt;And in JobTracker.java, all the related logs are put into diagnostic info:&lt;/p&gt;


&lt;p&gt;public synchronized String[] getTaskDiagnostics(TaskAttemptID taskId)&lt;br/&gt;
    throws IOException {&lt;/p&gt;

&lt;p&gt;    JobID jobId = taskId.getJobID();&lt;br/&gt;
    TaskID tipId = taskId.getTaskID();&lt;br/&gt;
    JobInProgress job = jobs.get(jobId);&lt;br/&gt;
    if (job == null) &lt;/p&gt;
{
      throw new IllegalArgumentException(&quot;Job &quot; + jobId + &quot; not found.&quot;);
    }
&lt;p&gt;    TaskInProgress tip = job.getTaskInProgress(tipId);&lt;br/&gt;
    if (tip == null) &lt;/p&gt;
{
      throw new IllegalArgumentException(&quot;TIP &quot; + tipId + &quot; not found.&quot;);
    }
&lt;p&gt;    List&amp;lt;String&amp;gt; taskDiagnosticInfo = tip.getDiagnosticInfo(taskId);&lt;br/&gt;
    return ((taskDiagnosticInfo == null) ? null&lt;br/&gt;
            : taskDiagnosticInfo.toArray(new String&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;));&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;Here is the diagnostic info in hadoop20:&lt;/p&gt;

&lt;p&gt;java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row &lt;/p&gt;
{&quot;key&quot;:&quot;238&quot;,&quot;value&quot;:&quot;val_238&quot;}
&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:161)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:358)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.MapTask.run(MapTask.java:307)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.Child.main(Child.java:170)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row &lt;/p&gt;
{&quot;key&quot;:&quot;238&quot;,&quot;value&quot;:&quot;val_238&quot;}
&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:548)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:143)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     ... 4 more&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: &lt;span class=&quot;error&quot;&gt;&amp;#91;Error 20000&amp;#93;&lt;/span&gt;: Unable to initialize custom script.&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.ScriptOperator.processOp(ScriptOperator.java:346)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:762)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:84)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:762)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:83)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:762)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:529)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     ... 5 more&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Caused by: java.io.IOException: Cannot run program &quot;script_does_not_exist&quot;: java.io.IOException: error=2, No such file or directory&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.lang.ProcessBuilder.start(ProcessBuilder.java:475)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.ScriptOperator.processOp(ScriptOperator.java:305)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     ... 14 more&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Caused by: java.io.IOException: java.io.IOException: error=2, No such file or directory&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.lang.UNIXProcess.&amp;lt;init&amp;gt;(UNIXProcess.java:164)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.lang.ProcessImpl.start(ProcessImpl.java:81)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.lang.ProcessBuilder.start(ProcessBuilder.java:468)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     ... 15 more&lt;/p&gt;

&lt;p&gt;The error code &lt;span class=&quot;error&quot;&gt;&amp;#91;20000&amp;#93;&lt;/span&gt; appears in the diagnostic info, and could be retrieved by Hive.&lt;/p&gt;

&lt;p&gt;While, in hadoop23, in Job.java, a different execution path is:&lt;/p&gt;


&lt;p&gt;public String[] getTaskDiagnostics(final TaskAttemptID taskid)&lt;br/&gt;
      throws IOException, InterruptedException {&lt;br/&gt;
    ensureState(JobState.RUNNING);&lt;br/&gt;
    return ugi.doAs(new PrivilegedExceptionAction&amp;lt;String[]&amp;gt;() {&lt;br/&gt;
      @Override&lt;br/&gt;
      public String[] run() throws IOException, InterruptedException &lt;/p&gt;
{
        return cluster.getClient().getTaskDiagnostics(taskid);
      }
&lt;p&gt;    });&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;Here is the diagnostic info in hadoop23:&lt;br/&gt;
java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row &lt;/p&gt;
{&quot;key&quot;:&quot;238&quot;,&quot;value&quot;:&quot;val_238&quot;}
&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:161)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:161)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:393)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:393)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.MapTask.run(MapTask.java:327)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.Child$4.run(Child.java:270)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at javax.security.auth.Subject.doAs(Subject.java:416)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1332)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.Child.main(Child.java:264)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row &lt;/p&gt;
{&quot;key&quot;:&quot;238&quot;,&quot;value&quot;:&quot;val_238&quot;}
&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:548)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:143)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     ... 8 more&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; C&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.MapTask.run(MapTask.java:327)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.Child$4.run(Child.java:270)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at javax.security.auth.Subject.doAs(Subject.java:416)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1332)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.mapred.Child.main(Child.java:264)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row &lt;/p&gt;
{&quot;key&quot;:&quot;238&quot;,&quot;value&quot;:&quot;val_238&quot;}
&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:548)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:143)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     ... 8 more&lt;/p&gt;

&lt;p&gt;Except for the Hive Runtime exception saying error while processing row, no more info is get in the diagnostic info.&lt;/p&gt;

&lt;p&gt;Since hive is using Hadoop&apos;s diagnostic info to extract Error Code, in hadoop 23, error code is only set to be 2(as no other error code could be extracted).&lt;/p&gt;

&lt;p&gt;JobDebugger.java, getTasksInfo() function:&lt;/p&gt;

&lt;p&gt;if (t.getTaskStatus() != TaskCompletionEvent.Status.SUCCEEDED) {&lt;br/&gt;
            if (ti.getErrorCode() == 0) &lt;/p&gt;
{
              String[] diags = rj.getTaskDiagnostics(t.getTaskAttemptId());
              ti.setErrorCode(extractErrorCode(diags));
              ti.setDiagnosticMesgs(diags);
            }


&lt;p&gt;I think the possible solution is to have separate expected outputs for hadoop20 and hadoop23. Since mapreduce_stack_trace.q and mapreduce_stack_trace_turnoff.q are the testcases for Negative MiniMRCluster, there is no such utility there.&lt;/p&gt;

&lt;p&gt;any suggestions are appreciated.&lt;/p&gt;</comment>
                            <comment id="13422856" author="cwsteinbach" created="Thu, 26 Jul 2012 02:51:11 +0000"  >&lt;p&gt;We should use the &lt;span class=&quot;error&quot;&gt;&amp;#91;INCLUDE|EXCLUDE&amp;#93;&lt;/span&gt;_HADOOP_MAJOR_VERSIONS macros to fix this. The 0.23 behavior should be the standard going forward, so please create mapreduce_stack_trace_h20.q and use the INCLUDE macro, and EXCLUDE 0.20 from mapreduce_stack_trace.q&lt;/p&gt;</comment>
                            <comment id="13422916" author="zhenxiao" created="Thu, 26 Jul 2012 06:12:09 +0000"  >&lt;p&gt;review request submitted at:&lt;br/&gt;
&lt;a href=&quot;https://reviews.facebook.net/D4365&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D4365&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13423329" author="ashutoshc" created="Thu, 26 Jul 2012 18:25:24 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13425542" author="ashutoshc" created="Tue, 31 Jul 2012 05:43:53 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Zhenxiao!&lt;/p&gt;</comment>
                            <comment id="13425913" author="hudson" created="Tue, 31 Jul 2012 16:42:52 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1579 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1579/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1579/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3303&quot; title=&quot;Fix error code inconsistency bug in mapreduce_stack_trace.q and mapreduce_stack_trace_turnoff.q when running hive on hadoop23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3303&quot;&gt;&lt;del&gt;HIVE-3303&lt;/del&gt;&lt;/a&gt;: Fix error code inconsistency bug in mapreduce_stack_trace.q and mapreduce_stack_trace_turnoff.q when running hive on hadoop23 (Zhenxiao Luo via Ashutosh Chauhan) (Revision 1367413)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1367413&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1367413&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/build-common.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/mapreduce_stack_trace.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/mapreduce_stack_trace_hadoop20.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/mapreduce_stack_trace_turnoff.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/mapreduce_stack_trace_turnoff_hadoop20.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/mapreduce_stack_trace.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/mapreduce_stack_trace_hadoop20.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/mapreduce_stack_trace_turnoff.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/mapreduce_stack_trace_turnoff_hadoop20.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548021" author="hudson" created="Wed, 9 Jan 2013 10:23:59 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3303&quot; title=&quot;Fix error code inconsistency bug in mapreduce_stack_trace.q and mapreduce_stack_trace_turnoff.q when running hive on hadoop23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3303&quot;&gt;&lt;del&gt;HIVE-3303&lt;/del&gt;&lt;/a&gt;: Fix error code inconsistency bug in mapreduce_stack_trace.q and mapreduce_stack_trace_turnoff.q when running hive on hadoop23 (Zhenxiao Luo via Ashutosh Chauhan) (Revision 1367413)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1367413&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1367413&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/build-common.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/mapreduce_stack_trace.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/mapreduce_stack_trace_hadoop20.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/mapreduce_stack_trace_turnoff.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/mapreduce_stack_trace_turnoff_hadoop20.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/mapreduce_stack_trace.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/mapreduce_stack_trace_hadoop20.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/mapreduce_stack_trace_turnoff.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/mapreduce_stack_trace_turnoff_hadoop20.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550203" author="ashutoshc" created="Thu, 10 Jan 2013 19:53:47 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12600246">HIVE-3301</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12537962" name="HIVE-3303.1.patch.txt" size="8225" author="zhenxiao" created="Thu, 26 Jul 2012 06:13:11 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>242373</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 45 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02u6n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14491</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>