<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:05:53 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-3992] Hive RCFile::sync(long) does a sub-sequence linear search for sync blocks</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3992</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The following function does some bad I/O&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; void sync(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; position) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
  ...
      &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
        seek(position + 4); &lt;span class=&quot;code-comment&quot;&gt;// skip escape
&lt;/span&gt;        in.readFully(syncCheck);
        &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; syncLen = sync.length;
        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = 0; in.getPos() &amp;lt; end; i++) {
          &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; j = 0;
          &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (; j &amp;lt; syncLen; j++) {
            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (sync[j] != syncCheck[(i + j) % syncLen]) {
              &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
            }
          }
          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (j == syncLen) {
            in.seek(in.getPos() - SYNC_SIZE); &lt;span class=&quot;code-comment&quot;&gt;// position before
&lt;/span&gt;            &lt;span class=&quot;code-comment&quot;&gt;// sync
&lt;/span&gt;            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
          }
          syncCheck[i % syncLen] = in.readByte();
        }
      }
...
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This causes a rather large number of readByte() calls which are passed onto a ByteBuffer via a single byte array.&lt;/p&gt;

&lt;p&gt;This results in rather a large amount of CPU being burnt in a the linear search for the sync pattern in the input RCFile (upto 92% for a skewed example - a trivial map-join + limit 100).&lt;/p&gt;

&lt;p&gt;This behaviour should be avoided at best or at least replaced by a rolling hash for efficient comparison, since it has a known byte-width of 16 bytes.&lt;/p&gt;

&lt;p&gt;Attached the stack trace from a Yourkit profile.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Ubuntu x86_64/java-1.6/hadoop-2.0.3&lt;/p&gt;</environment>
        <key id="12631143">HIVE-3992</key>
            <summary>Hive RCFile::sync(long) does a sub-sequence linear search for sync blocks</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gopalv">Gopal Vijayaraghavan</assignee>
                                    <reporter username="gopalv">Gopal Vijayaraghavan</reporter>
                        <labels>
                    </labels>
                <created>Wed, 6 Feb 2013 21:23:08 +0000</created>
                <updated>Thu, 16 May 2013 21:11:05 +0000</updated>
                            <resolved>Mon, 8 Apr 2013 04:42:05 +0000</resolved>
                                                    <fixVersion>0.11.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="13572846" author="gopalv" created="Wed, 6 Feb 2013 21:24:11 +0000"  >&lt;p&gt;Profile view of RCFile::sync(long)&lt;/p&gt;</comment>
                            <comment id="13572927" author="vinodkv" created="Wed, 6 Feb 2013 22:23:34 +0000"  >&lt;p&gt;This is one of the big things that is solved by the ORC file (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3874&quot; title=&quot;Create a new Optimized Row Columnar file format for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3874&quot;&gt;&lt;del&gt;HIVE-3874&lt;/del&gt;&lt;/a&gt;). Not saying that it shouldn&apos;t be fixed in RCFile, but we will need to modify RCFile to similarly include some kind of file header/footer to index into the row-groups.&lt;/p&gt;</comment>
                            <comment id="13573298" author="gopalv" created="Thu, 7 Feb 2013 08:06:22 +0000"  >&lt;p&gt;We can&apos;t fix it when the map-splits are properly distributed onto different map-tasks. &lt;/p&gt;

&lt;p&gt;But as the profile shows, we have a CombineHiveRecordReader which is reading multiple splits in the same process using different RCFileRecordReaders.&lt;/p&gt;

&lt;p&gt;I put in some prints to check for sync behaviour of readers.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ip-10-195-75-130: split = 0-67108864
ip-10-195-75-130: sync = 57
ip-10-195-75-130: Last seen sync = 70351814 (in 57-67108864)
ip-10-195-75-130: split = 67108864-134217728
ip-10-195-75-130: sync = 70351814
ip-10-195-75-130: Last seen sync = 136274939 (in 70351814-134217728)
ip-10-195-75-130: split = 134217728-157715536
ip-10-195-75-130: sync = 136274939
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;so every preceding RCFileRecordReader knows what was the last sync point, except the next one fails to use that information &amp;amp; does a fresh sync().&lt;/p&gt;

&lt;p&gt;We need a sync cache within the same process for the same file-split. &lt;/p&gt;

&lt;p&gt;I.e find me the last sync where sync.end &amp;gt; split.start &amp;amp;&amp;amp; sync.start &amp;lt; split.start for the same path.&lt;/p&gt;

&lt;p&gt;Holding that info in-memory should avoid sync passes after the first 57 byte sync-check.&lt;/p&gt;</comment>
                            <comment id="13573368" author="gopalv" created="Thu, 7 Feb 2013 10:32:27 +0000"  >&lt;p&gt;Cuts down on Sync calls in 2 ways.&lt;/p&gt;

&lt;p&gt;1) Does not do sync if ExecMapper.getDone() == true&lt;br/&gt;
2) Caches sync points encountered during previous iterations of the same file (previous split)&lt;/p&gt;</comment>
                            <comment id="13573402" author="gopalv" created="Thu, 7 Feb 2013 11:36:37 +0000"  >&lt;p&gt;Testing dummy query (to simulate a &quot;col in (select ...)&quot; style query) at SCALE=10&lt;/p&gt;

&lt;p&gt;select /&lt;b&gt;+MAPJOIN(time_dim)&lt;/b&gt;/ store_sales_rc.ss_item_sk from store_sales_rc join time_dim on (store_sales_rc.ss_sold_time_sk = time_dim.t_time_sk) limit 100;&lt;/p&gt;

&lt;p&gt;Before&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2013-02-07 06:32:02,164 Stage-1 map = 0%,  reduce = 0%
2013-02-07 06:32:20,082 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 53.9 sec
2013-02-07 06:32:21,127 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 61.59 sec
Job 0: Map: 8   Cumulative CPU: 61.59 sec   HDFS Read: 104763092 HDFS Write: 4749 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 1 seconds 590 msec
Time taken: 34.572 seconds, Fetched: 100 row(s)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2013-02-07 06:35:29,413 Stage-1 map = 0%,  reduce = 0%
2013-02-07 06:35:43,200 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 9.31 sec
2013-02-07 06:35:44,247 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 39.45 sec
MapReduce Total cumulative CPU time: 39 seconds 450 msec
Ended Job = job_1359695160319_0164
MapReduce Jobs Launched: 
Job 0: Map: 8   Cumulative CPU: 39.45 sec   HDFS Read: 25416952 HDFS Write: 4749 SUCCESS
Total MapReduce CPU Time Spent: 39 seconds 450 msec
Time taken: 31.351 seconds, Fetched: 100 row(s)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now the interesting bit is that even though we cut down the CPU cost by almost 50%, the over-all latency drops only by 2 secs.&lt;/p&gt;</comment>
                            <comment id="13582752" author="gopalv" created="Thu, 21 Feb 2013 01:02:03 +0000"  >&lt;p&gt;Patch optimizes for rcfile splits when they are being merged in a CombineFileSplit instance.&lt;/p&gt;</comment>
                            <comment id="13605085" author="gopalv" created="Mon, 18 Mar 2013 13:08:10 +0000"  >&lt;p&gt;From the best of my understanding, this is affecting performance in the short-circuited read because the &quot;in&quot; stream is not buffered &amp;amp; fires 1 byte read() syscalls.&lt;/p&gt;</comment>
                            <comment id="13619267" author="ashutoshc" created="Mon, 1 Apr 2013 22:43:27 +0000"  >&lt;p&gt;I have a question related to 1) Does not do sync if ExecMapper.getDone() == true&lt;br/&gt;
Outside of Hive (meaning using RCFile independent of Hive), getDone() will always be false, so this if block will always be skipped and part of this optimization will not fire. That is alright, but want to make sure this will not result in wrong results for that scenario. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt; Is that correct?&lt;/p&gt;</comment>
                            <comment id="13619365" author="gopalv" created="Tue, 2 Apr 2013 00:18:14 +0000"  >&lt;p&gt;That part of the patch can be dropped if hive created record readers only when the mapper is processing, but it does create &amp;amp; sync record readers irrespective of whether the reader is needed or not.&lt;/p&gt;

&lt;p&gt;Making hive less eager about that would remove the need for that line, but this patch gave performance improvements with the least code change instead of a patch higher above that affects all record reader inits.&lt;/p&gt;</comment>
                            <comment id="13619857" author="ashutoshc" created="Tue, 2 Apr 2013 14:36:44 +0000"  >&lt;p&gt;Following tests failed on trunk:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Test org.apache.hadoop.hive.ql.io.TestRCFile FAILED&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Begin query: mapjoin_test_outer.q&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Deleted &lt;a href=&quot;file:/home/ashutosh/hive/build/ql/test/data/warehouse/dest_1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:/home/ashutosh/hive/build/ql/test/data/warehouse/dest_1&lt;/a&gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running: diff -a /home/ashutosh/hive/build/ql/test/logs/clientpositive/mapjoin_test_outer.q.out /home/ashutosh/hive/ql/src/test/results/clientpositive/mapjoin_test_outer.q.out&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 414d413&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;lt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 569a569&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 1320d1319&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;lt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 1475a1475&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Exception: Client execution results failed with error code = 1&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; See build/ql/tmp/hive.log, or try &quot;ant test ... -Dtest.silent=false&quot; to get more logs.&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Failed query: mapjoin_test_outer.q&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13620123" author="gopalv" created="Tue, 2 Apr 2013 18:47:59 +0000"  >&lt;p&gt;That seems odd, I haven&apos;t run tests on this since early Feb. Let me rebase this patch and update it.&lt;/p&gt;</comment>
                            <comment id="13622221" author="gopalv" created="Thu, 4 Apr 2013 13:55:54 +0000"  >&lt;p&gt;Update patch to trunk.&lt;/p&gt;

&lt;p&gt;Fix the test failure where overlapping splits of varying sizes over the same file are read.&lt;/p&gt;

&lt;p&gt;Fix thread-safety issues &amp;amp; GC overhead errors (for HBase use-case), with a Synchronized WeakHashMap.&lt;/p&gt;</comment>
                            <comment id="13622620" author="ashutoshc" created="Thu, 4 Apr 2013 18:24:52 +0000"  >&lt;p&gt;I didnt intend to say that ExecMapper.getDone() should be removed. I was trying to understand if that if check is always false (which will be if RCFile is used outside of Hive) correctness is not compromised. For Hive, it will still provide speedup. If thats true (which your previous comment seem to indicate) I think we can keep that.&lt;br/&gt;
Secondly, putting an entry into map after doing null-check looks bit suspicious to me. Better is to use Guava&apos;s MapMaker classes for this. You can do &lt;tt&gt;ConcurrentMap map = new MapMaker().weakkeys().weakvalues.makeMap();&lt;/tt&gt; and than &lt;tt&gt;map.putIfAbsent()&lt;/tt&gt; We already have dependency on guava, so using guava should not be a problem. &lt;br/&gt;
Also, I will suggest to create a ReviewBoard or Phabricator entry for this, as we iterate on the patch.&lt;/p&gt;</comment>
                            <comment id="13622622" author="ashutoshc" created="Thu, 4 Apr 2013 18:27:12 +0000"  >&lt;p&gt;I also didn&apos;t get your point about GC overhead errors (for HBase use-case). How could that have been a problem?&lt;/p&gt;</comment>
                            <comment id="13622699" author="gopalv" created="Thu, 4 Apr 2013 19:36:04 +0000"  >&lt;p&gt;I think the ExecMapper.getDone() is breaking layering &amp;amp; control. Once I thought about it more, I couldn&apos;t retain it as there is no way to really turn it off once a mapper runs (say, you want to read an RCFile in the cleanup code for the mapper).&lt;/p&gt;

&lt;p&gt;The GC overhead errors were due to the fact that the cache grows without bounds for a long running process. The weak hashmap works as a solution for that &amp;amp; will invalidate the cache as the weak-refs are collected by the gc.&lt;/p&gt;</comment>
                            <comment id="13622990" author="owen.omalley" created="Thu, 4 Apr 2013 23:34:21 +0000"  >&lt;p&gt;A couple of comments on your patch:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;You don&apos;t use and don&apos;t need the start of the previous split.&lt;/li&gt;
	&lt;li&gt;The fields in the cache entry should be package private instead of public.&lt;/li&gt;
	&lt;li&gt;I&apos;m concerned in corner cases you&apos;ll use a lot of RAM for the cache. Maybe we should put a limit of 100 files in the cache.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13623331" author="gopalv" created="Fri, 5 Apr 2013 03:54:31 +0000"  >&lt;p&gt;Combined with Ashutosh&apos;s comment on using Guava, it makes sense to use Guava&apos;s cache impls instead of implementing my own from scratch.&lt;/p&gt;

&lt;p&gt;Will update the patch today.&lt;/p&gt;</comment>
                            <comment id="13623730" author="ashutoshc" created="Fri, 5 Apr 2013 15:45:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt; Actually I take that Guava&apos;s suggestion back. I just realized that it will introduce runtime dependency of RCFile on guava. Currently we don&apos;t send guava to task nodes and I dont see a strong reason here to make that change. So, lets keep using your old version of synchronized weak hash map.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;owen.omalley&lt;/a&gt; Implementing such limits in cache (which means implementing some variant of LRU cache) often brings new bugs and causes problems than what it solves. See, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3098&quot; title=&quot;Memory leak from large number of FileSystem instances in FileSystem.CACHE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3098&quot;&gt;&lt;del&gt;HIVE-3098&lt;/del&gt;&lt;/a&gt; for one such discussion. In my opinion, corner case will be too rare occurence in practice, my suggestion will be to not implement such limits. What do you think?&lt;/p&gt;</comment>
                            <comment id="13624881" author="gopalv" created="Sun, 7 Apr 2013 11:34:37 +0000"  >&lt;p&gt;Update patch to use a flat hash, with a hive conf option to turn it off and a synchronized weak hashmap&lt;/p&gt;</comment>
                            <comment id="13624882" author="gopalv" created="Sun, 7 Apr 2013 11:41:49 +0000"  >&lt;p&gt;I find that this does improve performance a fair bit &lt;/p&gt;

&lt;p&gt;A count(1) over a store_sales_rc_10 went from 122.988 seconds to 112.805 secs on a single node cluster.&lt;/p&gt;

&lt;p&gt;After digging down deeper, I found that the real culprit is the CombineInputFormat. A single split generalted look like this&lt;/p&gt;

&lt;p&gt;/user/hive/warehouse/tpcds_bin_flat_rc_10.db/store_sales/000002_0:0+67108864,&lt;br/&gt;
/user/hive/warehouse/tpcds_bin_flat_rc_10.db/store_sales/000002_0:67108864+67108864,&lt;br/&gt;
/user/hive/warehouse/tpcds_bin_flat_rc_10.db/store_sales/000002_0:134217728+24563332&lt;/p&gt;

&lt;p&gt;all wrapped up into a single InputSplitShim - which syncs twice, which is where I&apos;m saving the CPU here with the cache.&lt;/p&gt;

&lt;p&gt;If we could combine splits for real in the combine input format phase, then this band-aid cache will become redundant.&lt;/p&gt;</comment>
                            <comment id="13625057" author="ashutoshc" created="Mon, 8 Apr 2013 00:21:19 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13625132" author="ashutoshc" created="Mon, 8 Apr 2013 04:42:05 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Gopal!&lt;/p&gt;</comment>
                            <comment id="13625290" author="hudson" created="Mon, 8 Apr 2013 11:25:19 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #145 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/145/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/145/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3992&quot; title=&quot;Hive RCFile::sync(long) does a sub-sequence linear search for sync blocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3992&quot;&gt;&lt;del&gt;HIVE-3992&lt;/del&gt;&lt;/a&gt; : Hive RCFile::sync(long) does a sub-sequence linear search for sync blocks (Gopal V via Ashutosh Chauhan) (Revision 1465536)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1465536&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1465536&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/RCFileRecordReader.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13625572" author="hudson" created="Mon, 8 Apr 2013 17:29:14 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2051 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2051/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2051/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3992&quot; title=&quot;Hive RCFile::sync(long) does a sub-sequence linear search for sync blocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3992&quot;&gt;&lt;del&gt;HIVE-3992&lt;/del&gt;&lt;/a&gt; : Hive RCFile::sync(long) does a sub-sequence linear search for sync blocks (Gopal V via Ashutosh Chauhan) (Revision 1465536)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1465536&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1465536&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/RCFileRecordReader.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12644763">HIVE-4423</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12576983" name="HIVE-3992.2.patch" size="3173" author="gopalv" created="Thu, 4 Apr 2013 13:55:54 +0000"/>
                            <attachment id="12577443" name="HIVE-3992.3.patch" size="3914" author="gopalv" created="Sun, 7 Apr 2013 11:34:37 +0000"/>
                            <attachment id="12568401" name="HIVE-3992.patch" size="3505" author="gopalv" created="Thu, 7 Feb 2013 10:32:27 +0000"/>
                            <attachment id="12568297" name="select-join-limit.html" size="149698" author="gopalv" created="Wed, 6 Feb 2013 21:24:11 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>311639</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 33 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1hs4v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>311985</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Rely on previous sync-points when syncing within the same RCFile and avoid unnecessary I/O</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>rcfile hive </customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>