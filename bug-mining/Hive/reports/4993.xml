<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:48:39 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-15054] Hive insertion query execution fails on Hive on Spark</title>
                <link>https://issues.apache.org/jira/browse/HIVE-15054</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The query of &lt;tt&gt;insert overwrite table tbl1&lt;/tt&gt; sometimes will fail with the following errors. Seems we are constructing taskAttemptId with partitionId which is not unique if there are multiple attempts.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ava.lang.IllegalStateException: Hit error while closing operators - failing tree: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to rename output from: hdfs://table1/.hive-staging_hive_2016-06-14_01-53-17_386_3231646810118049146-9/_task_tmp.-ext-10002/_tmp.002148_0 to: hdfs://table1/.hive-staging_hive_2016-06-14_01-53-17_386_3231646810118049146-9/_tmp.-ext-10002/002148_0
at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.close(SparkMapRecordHandler.java:202)
at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.closeRecordProcessor(HiveMapFunctionResultList.java:58)
at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:106)
at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41)
at scala.collection.Iterator$class.foreach(Iterator.scala:727)
at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$1$$anonfun$apply$15.apply(AsyncRDDActions.scala:120)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</description>
                <environment></environment>
        <key id="13015122">HIVE-15054</key>
            <summary>Hive insertion query execution fails on Hive on Spark</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="aihuaxu">Aihua Xu</assignee>
                                    <reporter username="aihuaxu">Aihua Xu</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Oct 2016 15:53:42 +0000</created>
                <updated>Fri, 21 Jul 2017 18:26:23 +0000</updated>
                            <resolved>Mon, 7 Nov 2016 03:27:09 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="15605696" author="aihuaxu" created="Tue, 25 Oct 2016 16:04:27 +0000"  >&lt;p&gt;patch-1: initial patch. Change the id from the partitionId to taskAttemptId. It would cause some test failures per the comment. Will see the test result and I will fix it in the following patch.&lt;/p&gt;

&lt;p&gt;So the problem is: if we use partitionId as part of &lt;tt&gt;mapred.task.id&lt;/tt&gt; and the taskId is used as the filename in FileSinkOp, then there will be a conflict if there is a retry on the same task. Switch to taskAttemptId which should be unique.&lt;/p&gt;</comment>
                            <comment id="15605705" author="aihuaxu" created="Tue, 25 Oct 2016 16:05:27 +0000"  >&lt;p&gt;+ &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;xuefuz&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;jxiang&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szehon&quot; class=&quot;user-hover&quot; rel=&quot;szehon&quot;&gt;szehon&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="15605709" author="xuefuz" created="Tue, 25 Oct 2016 16:06:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aihuaxu&quot; class=&quot;user-hover&quot; rel=&quot;aihuaxu&quot;&gt;aihuaxu&lt;/a&gt; thanks for looking at this.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;/&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chengxiang+li&quot; class=&quot;user-hover&quot; rel=&quot;chengxiang li&quot;&gt;chengxiang li&lt;/a&gt;, I think we attempted to fix this before. Can you review the patch?&lt;/p&gt;</comment>
                            <comment id="15607064" author="lirui" created="Wed, 26 Oct 2016 01:49:54 +0000"  >&lt;p&gt;Yeah I tried something similar in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-13066&quot; title=&quot;Hive on Spark gives incorrect results when speculation is on&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-13066&quot;&gt;&lt;del&gt;HIVE-13066&lt;/del&gt;&lt;/a&gt;. I&apos;ll mark it as dup and let&apos;s fix it here.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aihuaxu&quot; class=&quot;user-hover&quot; rel=&quot;aihuaxu&quot;&gt;aihuaxu&lt;/a&gt;, what I don&apos;t understand is why the error doesn&apos;t always happen. I wasn&apos;t able to reproduce &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-13066&quot; title=&quot;Hive on Spark gives incorrect results when speculation is on&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-13066&quot;&gt;&lt;del&gt;HIVE-13066&lt;/del&gt;&lt;/a&gt;, and I guess not all tasks with multiple attempts will trigger the issue here. Could you do some more investigation to find out? Thanks.&lt;/p&gt;</comment>
                            <comment id="15608359" author="aihuaxu" created="Wed, 26 Oct 2016 12:49:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt; Thanks for taking a look. It would be hard to repro. It depends on which state the first executor is when it&apos;s aborted or dies. You will see such issue when the task is done with the writing the data to a tmp file and renaming to the file tmp file while at that time spark kills such task in your case or the executor loses the connection. The case I have seen is,  the connection to the executor times out but the executor is almost done with its work (the result is finished writing and renamed to the final tmp file and only thing left is to report to the driver that the task is done).  &lt;/p&gt;

&lt;p&gt; If the rename doesn&apos;t happen, then you won&apos;t see such issue. &lt;/p&gt;</comment>
                            <comment id="15608509" author="hiveqa" created="Wed, 26 Oct 2016 13:51:20 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12835320/HIVE-15054.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12835320/HIVE-15054.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 10 failed/errored test(s), 10621 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[auto_sortmerge_join_16] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[root_dir_external_table] (batchId=157)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_16] (batchId=114)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[parquet_join] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[sample10] (batchId=112)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[temp_table_gb1] (batchId=106)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_between_in] (batchId=116)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJarWithoutAddDriverClazz[0] (batchId=164)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[0] (batchId=164)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[1] (batchId=164)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1820/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1820/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1820/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1820/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-1820/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-1820/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 10 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12835320 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15608577" author="lirui" created="Wed, 26 Oct 2016 14:19:03 +0000"  >&lt;p&gt;Thanks for the explanations Aihua.&lt;br/&gt;
I&apos;m not sure which format is better: &lt;tt&gt;partitionId_attemptNumber&lt;/tt&gt;, or just &lt;tt&gt;taskAttemptId&lt;/tt&gt;. Does hive rely on the attemptNumber to identify the multiple outputs for the same task/partition?&lt;/p&gt;</comment>
                            <comment id="15608832" author="aihuaxu" created="Wed, 26 Oct 2016 15:49:20 +0000"  >&lt;p&gt;Hive doesn&apos;t use attemptNumber. I feel taskAttemptId is better since it matches with what is expected and other engines like tez and MR (expecting taskId and attemptId here). That info helps in the diagnostics. &lt;/p&gt;

&lt;p&gt;How do you think?&lt;/p&gt;</comment>
                            <comment id="15609278" author="aihuaxu" created="Wed, 26 Oct 2016 18:35:39 +0000"  >&lt;p&gt;From the test failures, actually hive in some cases are expecting taskId_attemptNumber format although attemptNumber is not used. I will change to &lt;tt&gt;taskAttemptId_0&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="15609895" author="hiveqa" created="Wed, 26 Oct 2016 22:34:04 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12835401/HIVE-15054.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12835401/HIVE-15054.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 9 failed/errored test(s), 10621 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[auto_sortmerge_join_16] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[root_dir_external_table] (batchId=157)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_16] (batchId=114)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[sample10] (batchId=112)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[temp_table_gb1] (batchId=106)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_between_in] (batchId=116)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJarWithoutAddDriverClazz[0] (batchId=164)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[0] (batchId=164)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[1] (batchId=164)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1829/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1829/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1829/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1829/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-1829/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-1829/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12835401 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15610276" author="lirui" created="Thu, 27 Oct 2016 01:24:10 +0000"  >&lt;p&gt;I could be wrong, but from what I remember, partitionId_attemptNumber is closer to MR&apos;s taskId_attemptNumber. If task 0 has two attempts, we&apos;ll have 0_0 and 0_1. If we use taskAttemptId, that&apos;ll be two unique numbers. Not sure if hive can understand the two attempts are for the same task/partition.&lt;/p&gt;</comment>
                            <comment id="15610342" author="aihuaxu" created="Thu, 27 Oct 2016 01:54:40 +0000"  >&lt;p&gt;I&apos;m still trying understand the difference between them. Seems both should work, but I&apos;m seeing some test problems.&lt;/p&gt;


</comment>
                            <comment id="15613083" author="aihuaxu" created="Thu, 27 Oct 2016 20:18:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt; It&apos;s strange that with taskAttemptId_0, it will cause sample10.q e.g. to produce different result while partitionId_attemptNumber is fine. Can&apos;t figure out why. Do you have any insights?&lt;/p&gt;

&lt;p&gt;I can see that some of our tests could fail if somehow the first attempt fails and generates the file like 000000_1 since some test output list the file names, but I guess MR would have the same problem as well.&lt;/p&gt;</comment>
                            <comment id="15614437" author="lirui" created="Fri, 28 Oct 2016 06:12:48 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aihuaxu&quot; class=&quot;user-hover&quot; rel=&quot;aihuaxu&quot;&gt;aihuaxu&lt;/a&gt;, I don&apos;t know for sure either.&lt;br/&gt;
My hunch is that since taskAttemptId are all unique numbers, how can hive know whether two attempts are for the same task or not?&lt;/p&gt;</comment>
                            <comment id="15614491" author="lirui" created="Fri, 28 Oct 2016 06:36:34 +0000"  >&lt;p&gt;This is how MR generates the attempt Id: &lt;a href=&quot;https://hadoop.apache.org/docs/r2.6.0/api/org/apache/hadoop/mapreduce/TaskAttemptID.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://hadoop.apache.org/docs/r2.6.0/api/org/apache/hadoop/mapreduce/TaskAttemptID.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We&apos;ll be very close to the format (e.g. &lt;tt&gt;attempt_200707121733_0003_m_000005_0&lt;/tt&gt;) if we use partitionId_attemptNumber. Except we&apos;re using stage Id instead of job Id.&lt;/p&gt;</comment>
                            <comment id="15615310" author="aihuaxu" created="Fri, 28 Oct 2016 12:57:50 +0000"  >&lt;p&gt;Yeah. Seems hive is using 000005 part to track if they are the same task or not somewhere.  Originally I thought that info was only used for the final filename. I will take another look how that was used in hive.&lt;/p&gt;</comment>
                            <comment id="15616394" author="aihuaxu" created="Fri, 28 Oct 2016 20:04:19 +0000"  >&lt;p&gt;patch-3: switch to partitionId_attemptNumber. Spark will have a different taskId for the different attempts of the same task while hive needs to use the same id to figure out if the data are duplicate. So seems we have to use partitionId_attemptNumber here. &lt;/p&gt;</comment>
                            <comment id="15616426" author="aihuaxu" created="Fri, 28 Oct 2016 20:10:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt; You are right that hive needs to use the same id to figure out it&apos;s the same task. Spark has different taskId for different task attempt. Seems partitionId is the closest choice. &lt;/p&gt;</comment>
                            <comment id="15617224" author="hiveqa" created="Sat, 29 Oct 2016 02:16:24 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12835872/HIVE-15054.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12835872/HIVE-15054.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 10626 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=91)
org.apache.hive.spark.client.TestSparkClient.testJobSubmission (batchId=272)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1873/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1873/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1873/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1873/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-1873/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-1873/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12835872 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15621481" author="lirui" created="Mon, 31 Oct 2016 07:14:05 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aihuaxu&quot; class=&quot;user-hover&quot; rel=&quot;aihuaxu&quot;&gt;aihuaxu&lt;/a&gt; for the investigation and update!&lt;br/&gt;
The patch looks good. But I find the comments a little bit confusing. How about something like this&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-comment&quot;&gt;// Hive requires &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; TaskAttemptId to be unique. MR&lt;span class=&quot;code-quote&quot;&gt;&apos;s TaskAttemptId is composed of &lt;span class=&quot;code-quote&quot;&gt;&quot;attempt_timestamp_jobNum_m/r_taskNum_attemptNum&quot;&lt;/span&gt;. The counterpart &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Spark should be &lt;span class=&quot;code-quote&quot;&gt;&quot;attempt_timestamp_stageNum_m/r_partitionId_attemptNum&quot;&lt;/span&gt;. When there&apos;&lt;/span&gt;re multiple attempts &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; a task, Hive will rely on the partitionId to figure out &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; the data are duplicate or not (see org.apache.hadoop.hive.ql.exec.Utils.removeTempOrDuplicateFiles)  when collecting the &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; outputs&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15622518" author="aihuaxu" created="Mon, 31 Oct 2016 15:46:51 +0000"  >&lt;p&gt;patch-4: update the comment.&lt;/p&gt;</comment>
                            <comment id="15622519" author="aihuaxu" created="Mon, 31 Oct 2016 15:47:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt; I think what you provided is better. Just updated the comments in the patch.&lt;/p&gt;</comment>
                            <comment id="15627560" author="lirui" created="Wed, 2 Nov 2016 03:39:09 +0000"  >&lt;p&gt;Thanks for updating &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aihuaxu&quot; class=&quot;user-hover&quot; rel=&quot;aihuaxu&quot;&gt;aihuaxu&lt;/a&gt;. +1&lt;/p&gt;</comment>
                            <comment id="15633088" author="hiveqa" created="Thu, 3 Nov 2016 15:24:55 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12836843/HIVE-15054.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12836843/HIVE-15054.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1945/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1945/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1945/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1945/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-1945/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-1945/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hiveptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ date &apos;+%Y-%m-%d %T.%3N&apos;
2016-11-03 15:23:59.713
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;MAVEN_OPTS=-Xmx1g -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ MAVEN_OPTS=&apos;-Xmx1g -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-1945/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2016-11-03 15:23:59.716
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 345353c HIVE-15039: A better job monitor console output for HoS (Rui reviewed by Xuefu and Ferdinand)
+ git clean -f -d
+ git checkout master
Already on &apos;master&apos;
Your branch is up-to-date with &apos;origin/master&apos;.
+ git reset --hard origin/master
HEAD is now at 345353c HIVE-15039: A better job monitor console output for HoS (Rui reviewed by Xuefu and Ferdinand)
+ git merge --ff-only origin/master
Already up-to-date.
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2016-11-03 15:24:00.603
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
Going to apply patch with: patch -p1
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HivePairFlatMapFunction.java
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hiveptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/metastore/parser/Filter.g
DataNucleus Enhancer (version 4.1.6) for API &quot;JDO&quot;
DataNucleus Enhancer : Classpath
&amp;gt;&amp;gt;  /usr/share/maven/boot/plexus-classworlds-2.x.jar
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDatabase
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MType
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTable
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MConstraint
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MOrder
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStringList
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartition
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MIndex
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRole
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRoleMap
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMasterKey
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MVersionTable
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MResourceUri
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFunction
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationLog
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId
DataNucleus Enhancer completed with success for 30 classes. Timings : input=183 ms, enhance=242 ms, total=425 ms. Consult the log for full details
Generating vector expression code
Generating vector expression test code
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-remote-resources-plugin:1.5:process (default) on project hive-exec: Error resolving project artifact: Could not transfer artifact org.pentaho:pentaho-aggdesigner-algorithm:pom:5.1.5-jhyde from/to datanucleus (http://www.datanucleus.org/downloads/maven2): Connect to localhost:3128 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused for project org.pentaho:pentaho-aggdesigner-algorithm:jar:5.1.5-jhyde -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12836843 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15637310" author="hiveqa" created="Fri, 4 Nov 2016 18:50:27 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12837165/HIVE-15054.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12837165/HIVE-15054.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 10628 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_4] (batchId=91)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1968/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1968/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1968/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1968/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-1968/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-1968/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12837165 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15642975" author="lirui" created="Mon, 7 Nov 2016 03:27:10 +0000"  >&lt;p&gt;Committed to master. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aihuaxu&quot; class=&quot;user-hover&quot; rel=&quot;aihuaxu&quot;&gt;aihuaxu&lt;/a&gt; for the fix.&lt;/p&gt;</comment>
                            <comment id="15644283" author="aihuaxu" created="Mon, 7 Nov 2016 14:15:48 +0000"  >&lt;p&gt;Thanks Rui.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12939717">HIVE-13066</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12835320" name="HIVE-15054.1.patch" size="1169" author="aihuaxu" created="Wed, 26 Oct 2016 13:00:45 +0000"/>
                            <attachment id="12835401" name="HIVE-15054.2.patch" size="1113" author="aihuaxu" created="Wed, 26 Oct 2016 19:13:32 +0000"/>
                            <attachment id="12835872" name="HIVE-15054.3.patch" size="1465" author="aihuaxu" created="Fri, 28 Oct 2016 20:00:34 +0000"/>
                            <attachment id="12837165" name="HIVE-15054.4.patch" size="1469" author="aihuaxu" created="Fri, 4 Nov 2016 15:50:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 2 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i35d9z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>