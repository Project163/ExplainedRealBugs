<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:09:16 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-3562] Some limit can be pushed down to map stage</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3562</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Queries with limit clause (with reasonable number), for example&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;select * from src order by key limit 10;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;makes operator tree, &lt;br/&gt;
TS-SEL-RS-EXT-LIMIT-FS&lt;/p&gt;

&lt;p&gt;But LIMIT can be partially calculated in RS, reducing size of shuffling.&lt;br/&gt;
TS-SEL-RS(TOP-N)-EXT-LIMIT-FS&lt;/p&gt;</description>
                <environment></environment>
        <key id="12611120">HIVE-3562</key>
            <summary>Some limit can be pushed down to map stage</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis Ryu</assignee>
                                    <reporter username="navis">Navis Ryu</reporter>
                        <labels>
                    </labels>
                <created>Wed, 10 Oct 2012 05:12:40 +0000</created>
                <updated>Tue, 14 Sep 2021 01:37:59 +0000</updated>
                            <resolved>Wed, 28 Aug 2013 15:02:57 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>21</watches>
                                                                                                                <comments>
                            <comment id="13472986" author="navis" created="Wed, 10 Oct 2012 05:16:13 +0000"  >&lt;p&gt;without pushdown, &lt;br/&gt;
Map output bytes   9312&lt;br/&gt;
Map output records  500&lt;/p&gt;

&lt;p&gt;with pushdown, &lt;br/&gt;
Map output bytes    981&lt;br/&gt;
Map output records   53&lt;/p&gt;

&lt;p&gt;can be optimized further.&lt;/p&gt;</comment>
                            <comment id="13472988" author="phabricator@reviews.facebook.net" created="Wed, 10 Oct 2012 05:21:02 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;br/&gt;
Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;  DPAL-1910 Some limit can be pushed down to map stage&lt;/p&gt;

&lt;p&gt;  Queries with limit clause (with reasonable number), for example&lt;/p&gt;

&lt;p&gt;  select * from src order by key limit 10;&lt;/p&gt;

&lt;p&gt;  makes operator tree,&lt;br/&gt;
  TS-SEL-RS-EXT-LIMIT-FS&lt;/p&gt;

&lt;p&gt;  But LIMIT can be partially calculated in RS, reducing size of shuffling.&lt;br/&gt;
  TS-SEL-RS(TOP-N)-EXT-LIMIT-FS&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;/p&gt;

&lt;p&gt;MANAGE HERALD DIFFERENTIAL RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/14199/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/herald/transcript/14199/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13500118" author="snarayanan" created="Mon, 19 Nov 2012 10:16:15 +0000"  >&lt;p&gt;I&apos;m interested in this particular optimization. Let&apos;s say the table src have N rows and we&apos;re interested in top-K. If the rows in T are in almost descending order and we&apos;re interested in ascending Top-K (this is very likely when ordering by timestamps), then the number of memcopies will be N * K. See code fragment:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;+    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isTopN(&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] key) {
+      &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; index = Arrays.binarySearch(keys, key, C);
+      index = index &amp;lt; 0 ? -index -1 : index;
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (index &amp;gt;= keys.length - 1) {
+        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
+      }
+      &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.arraycopy(keys, index, keys, index + 1, keys.length - index - 1);
+      keys[index] = Arrays.copyOf(key, key.length);
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
+    }
+  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You could use a linked list, but binary search is not an option in that case.&lt;/p&gt;

&lt;p&gt;An alternate approach to the problem is to use a combination of Hive and Hadoop changes.&lt;/p&gt;

&lt;p&gt;Hadoop change:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;New parameter map.sort.limitrecords which determines how many records each mapper in a job will send to every reducer&lt;/li&gt;
	&lt;li&gt;When writing out local files after sorting, map-task stops after map.sort.limitrecords records for each reducer&lt;/li&gt;
	&lt;li&gt;Effectively, each mapper sends out its top-K records&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Hive change:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Determining when the Top-K optimization is applicable and setting K in ReduceSinkDesc&lt;/li&gt;
	&lt;li&gt;Passing the K value along to MapredWork&lt;/li&gt;
	&lt;li&gt;ExecDriver sets map.sort.limitrecords before executing the job corresponding to the MapredWork&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This change will reduce the amount of I/O that happens on the map-side (writing only 10 rows per reducer as opposed to entire table) and can have a big effect on performance. Furthermore, it is possible to make the sort on the mapper side a top-k sort which can further improve performance - but the deep pocket is really the I/O savings. In my experiments, I see a 5x performance improvement for such queries.&lt;/p&gt;</comment>
                            <comment id="13500165" author="snarayanan" created="Mon, 19 Nov 2012 11:34:25 +0000"  >&lt;p&gt;Apologies, you can use a heap to maintain a top-k as opposed to an array or a linked list. &lt;/p&gt;

&lt;p&gt;You may also want to consider the case where the top-k do not fit in memory. One possibility would be to employ this optimization only if K is less than some threshold.&lt;/p&gt;

&lt;p&gt;This approach has the advantage that it is a Hive-only change and does not depend on a Hadoop change. That is a pretty big plus.&lt;/p&gt;</comment>
                            <comment id="13511402" author="namit" created="Thu, 6 Dec 2012 14:12:51 +0000"  >&lt;p&gt;I think it would be simple to keep it a hive only change.&lt;br/&gt;
I agree that Hadoop change is more general, but it may be painful/time-consuming to backport.&lt;br/&gt;
In most of the cases, k would be small, and it makes perfect sense to put a limit on k, as you suggested above.&lt;/p&gt;

&lt;p&gt;What do you think ?&lt;br/&gt;
Should we go with the hive-only change ?&lt;/p&gt;</comment>
                            <comment id="13511418" author="snarayanan" created="Thu, 6 Dec 2012 14:34:39 +0000"  >&lt;p&gt;Hive-only change is fine. A heap-based isTopN() implementation will be good.&lt;/p&gt;</comment>
                            <comment id="13511434" author="namit" created="Thu, 6 Dec 2012 14:57:55 +0000"  >&lt;p&gt;Cool, can you also review ?&lt;br/&gt;
I will start reviewing too.&lt;/p&gt;</comment>
                            <comment id="13511441" author="namit" created="Thu, 6 Dec 2012 15:08:35 +0000"  >&lt;p&gt;comments on phabricator&lt;/p&gt;</comment>
                            <comment id="13511442" author="phabricator@reviews.facebook.net" created="Thu, 6 Dec 2012 15:09:08 +0000"  >&lt;p&gt;njain has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  As per jira comments, can you add a new parameter for the limit on k ?&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:73 Instead of checking for instanceof, can you add a method in Operator() - something like&lt;br/&gt;
  canLimitBePushed() with a lot of comments, and then the above operators can have this to true.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:358  Can you add a heap based implementation as suggested in jira ?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:86 Can you add lot of comments here - when is this set ?&lt;br/&gt;
  what queries will it benefit etc. ?&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:460 add these in hive-default.xml.template&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q:7 can you add another positive/negative test ?&lt;/p&gt;

&lt;p&gt;  explain select value, sum(key) from src group by value limit 10;&lt;/p&gt;

&lt;p&gt;  The limit should be used in the 2nd MR job if u r inserting into a table.&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q:10 For the 2 negative queries, can you insert into a table also -&lt;br/&gt;
  then the optm. should help&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13511477" author="phabricator@reviews.facebook.net" created="Thu, 6 Dec 2012 15:55:08 +0000"  >&lt;p&gt;tarball has requested changes to the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Not sure if I&apos;m following the right protocol here. Marking this as &quot;Request Changes&quot; per my comments.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:460 Minor suggestion, feel free to ignore &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Prefer parameter name  &quot;hive.limit.twophase.enable&quot;.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:129 Why not limit 0 (unless hive optimizes those away)?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:305 Is this variable not used at all?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:323 This code seems error prone. It has a side effect that&apos;s difficult to understand - it is not obvious that the caller must wipe out value before the next row is processed. Any particular reason we&apos;re caching it at all?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:346 If o1 and o2 are null, shouldn&apos;t this return 0?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  DPAL-1910&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13511482" author="snarayanan" created="Thu, 6 Dec 2012 16:00:39 +0000"  >&lt;p&gt;Added my comments to Phabricator. I&apos;m new to these tools and the process. So, please forgive any mistakes on my part. &lt;/p&gt;

&lt;p&gt;Good stuff, Navis!&lt;/p&gt;</comment>
                            <comment id="13527685" author="navis" created="Mon, 10 Dec 2012 02:14:13 +0000"  >&lt;p&gt;I just wanted to start small not affecting flow over operators but.. ok, I&apos;ll do it.&lt;/p&gt;</comment>
                            <comment id="13527759" author="phabricator@reviews.facebook.net" created="Mon, 10 Dec 2012 08:03:19 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;br/&gt;
Reviewers: JIRA, tarball&lt;/p&gt;

&lt;p&gt;  Addressed some comments (submitting for fail-fast review)&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13527803" author="phabricator@reviews.facebook.net" created="Mon, 10 Dec 2012 09:43:20 +0000"  >&lt;p&gt;tarball has requested changes to the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  conf/hive-default.xml.template:1407 Why is optimization disabled by default? This is good stuff and should be switched on!&lt;br/&gt;
  conf/hive-default.xml.template:1413 10 million seems like a really large threshold. Maybe in the 50k range?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:378 The current implementation doesn&apos;t look like a heap to me. Why not simply use java.util.PriorityQueue?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:383 Shouldn&apos;t nulls be equal to each other?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:379 Better name? TopNHeap?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  DPAL-1910&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13528572" author="phabricator@reviews.facebook.net" created="Tue, 11 Dec 2012 01:27:20 +0000"  >&lt;p&gt;navis has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Is this right direction?&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  conf/hive-default.xml.template:1407 It&apos;s like a convention. When this patch is believed to be fully stable, it&apos;ll be so.&lt;br/&gt;
  conf/hive-default.xml.template:1413 It&apos;s size of memory, not number of rows. 10M seemed to be conservative enough.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:378 I just wanted to keep it compact as is possible because this can be used with map aggregation. I&apos;m thinking of interface which can be implemented by user and configured to be used for this.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:383 In RS, o2 is the key and cannot be null and also, making this class support null key needs some more works. I just ignored that case but yes, some comments could be useful at the least.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  DPAL-1910&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13533636" author="namit" created="Mon, 17 Dec 2012 04:22:03 +0000"  >&lt;p&gt;comments on phabricator&lt;/p&gt;</comment>
                            <comment id="13533638" author="phabricator@reviews.facebook.net" created="Mon, 17 Dec 2012 04:24:11 +0000"  >&lt;p&gt;njain has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  The general direction looks OK&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:79 TODO&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:45 spelling: operator&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:79 Followup: add a new method in Operator.&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q:26 Looks like this optimization should also help if the limit is in a sub-query:&lt;br/&gt;
  Can you add a test ?&lt;/p&gt;

&lt;p&gt;  something like:&lt;/p&gt;

&lt;p&gt;  select ..  from&lt;br/&gt;
  (select key, count(1) from src group by key order by key limit 2) subq&lt;br/&gt;
  join&lt;br/&gt;
  (select key, count(1) from src group by key order by key limit 2) subq2 ..&lt;/p&gt;


&lt;p&gt;  The optimization should be applied to both the sub-queries&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  DPAL-1910&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13542639" author="phabricator@reviews.facebook.net" created="Thu, 3 Jan 2013 01:22:11 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;br/&gt;
Reviewers: JIRA, tarball&lt;/p&gt;

&lt;p&gt;  Addressed comments&lt;br/&gt;
  Prevent multi-GBY single-RS case&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13542689" author="snarayanan" created="Thu, 3 Jan 2013 03:43:41 +0000"  >&lt;p&gt;Looks good to me. +1&lt;/p&gt;</comment>
                            <comment id="13542690" author="phabricator@reviews.facebook.net" created="Thu, 3 Jan 2013 03:44:11 +0000"  >&lt;p&gt;tarball has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Looks good to me. +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13546643" author="phabricator@reviews.facebook.net" created="Tue, 8 Jan 2013 06:16:12 +0000"  >&lt;p&gt;njain has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  conf/hive-default.xml.template:1434 Can you add more details here - a example query would really help ?&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q:16 What is so special about 40 ?&lt;/p&gt;

&lt;p&gt;  set hive.limit.pushdown.heap.threshold explicitly at the beginning of the test, makes the&lt;br/&gt;
  test easier to maintain in the long run.&lt;/p&gt;

&lt;p&gt;  ql/src/test/queries/clientpositive/limit_pushdown.q:34 What is the difference between this and line 3 ?&lt;/p&gt;

&lt;p&gt;  ql/src/test/queries/clientpositive/limit_pushdown.q:10 I think this plan is not correct.&lt;/p&gt;

&lt;p&gt;  Let us say, the values are&lt;br/&gt;
  v1&lt;br/&gt;
  v2&lt;br/&gt;
  ..&lt;br/&gt;
  v10&lt;br/&gt;
  v11&lt;br/&gt;
  v12&lt;br/&gt;
  ..&lt;br/&gt;
  v20&lt;/p&gt;

&lt;p&gt;  The first mapper does not have v8-10, so it emits v1-v7, v11-v13&lt;br/&gt;
  The second mapper contains data for all values, but it only emits v1-v10&lt;/p&gt;

&lt;p&gt;  Since it does not involves a order by, it is possible that the data for v11 will get picked up, which does not contain data from the second mapper. If you are pushing the limit up, you should create an additional MR job which orders the rows - in the above example, making sure that only v1-v10 are picked up.&lt;/p&gt;

&lt;p&gt;  Am I missing something here ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13546648" author="namit" created="Tue, 8 Jan 2013 06:28:41 +0000"  >&lt;p&gt;comments&lt;/p&gt;</comment>
                            <comment id="13546649" author="phabricator@reviews.facebook.net" created="Tue, 8 Jan 2013 06:30:11 +0000"  >&lt;p&gt;njain has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:75 remove the TODO&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q:51 There is no test where the limit is &amp;gt; hive.limit.pushdown.heap.threshold.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:87 Do you want to compare the threshold with the actual limit here ?&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13546661" author="phabricator@reviews.facebook.net" created="Tue, 8 Jan 2013 06:56:11 +0000"  >&lt;p&gt;njain has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Sorry, my earlier comments were assuming that the threshold is for number of rows&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:483 Coming to a earlier comment from Sivaramakrishnan Narayanan, would it be simpler if this was the number of rows ?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:414 Define 40 as a constant somewhere&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13546703" author="phabricator@reviews.facebook.net" created="Tue, 8 Jan 2013 08:42:11 +0000"  >&lt;p&gt;njain has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  I thought about it, even with group bys, my question is still valid.&lt;br/&gt;
  I think, there is a bug.&lt;/p&gt;

&lt;p&gt;  Do you think it would be simpler to allocate a heap with (upto) topN entries instead - throw&lt;br/&gt;
  the memory threshold out. If limit &amp;lt; threshold, use this optimization, otherwise just ignore this&lt;br/&gt;
  optimization.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:441 Isn&apos;t there a bug here ?&lt;/p&gt;

&lt;p&gt;  You are using keyValues last entry to figure out whether it needs to be expanded or not.&lt;br/&gt;
  It may have an issue at the boundary - say entry 40th when a legit. entry is found.&lt;br/&gt;
  It might be simpler to pass the fact whether the entry was found or not.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:468 This is not true if an entry is being inserted in between.&lt;br/&gt;
  I mean, if topN is 100, and we already have 100 entries.&lt;/p&gt;

&lt;p&gt;  If we are inserting 50th entry, we should not be increasing usage&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13546822" author="phabricator@reviews.facebook.net" created="Tue, 8 Jan 2013 12:14:12 +0000"  >&lt;p&gt;navis has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  I think I&apos;m wrong about GBY cases. Should be fixed definitely (in next week, maybe).&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13563464" author="phabricator@reviews.facebook.net" created="Sat, 26 Jan 2013 12:07:11 +0000"  >&lt;p&gt;navis has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  I&apos;m also confusing about GBY cases. I mean group by query with &quot;no ordering&quot; clause, for example,&lt;/p&gt;

&lt;p&gt;  select key,count(value) from src group by key limit 10;&lt;/p&gt;

&lt;p&gt;  I think top-K is still applicable. If key is ranged from K1 to K100, all values for K1~K10 from any mapper are transferred to reducer, which makes valid result. Isn&apos;t it?&lt;/p&gt;

&lt;p&gt;  And for changing threshold from memory to row count, map aggregation would be a good example, which is using memory percent. I also think current implementation is too clumsy, but general direction is right.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13613611" author="phabricator@reviews.facebook.net" created="Tue, 26 Mar 2013 08:25:14 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  1. Used Heap for ORDER BY and Map for GROUP BY&lt;br/&gt;
  2. Added tests for spill/break&lt;br/&gt;
  3. Changed to use percentage for memory threshold&lt;/p&gt;

&lt;p&gt;Reviewers: tarball, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967?vs=24861&amp;amp;id=30483#toc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967?vs=24861&amp;amp;id=30483#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  ql/build.xml&lt;br/&gt;
  ql/ivy.xml&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHashForGBY.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13619381" author="navis" created="Tue, 2 Apr 2013 00:48:56 +0000"  >&lt;p&gt;Passed all tests&lt;/p&gt;</comment>
                            <comment id="13640368" author="namit" created="Wed, 24 Apr 2013 12:12:53 +0000"  >&lt;p&gt;can you refresh ?&lt;/p&gt;</comment>
                            <comment id="13642489" author="phabricator@reviews.facebook.net" created="Fri, 26 Apr 2013 01:38:13 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Refactoring &amp;amp; bug fix&lt;/p&gt;

&lt;p&gt;Reviewers: tarball, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967?vs=30483&amp;amp;id=32943#toc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967?vs=30483&amp;amp;id=32943#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  ql/build.xml&lt;br/&gt;
  ql/ivy.xml&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/join_vc.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q&lt;br/&gt;
  ql/src/test/results/clientpositive/join_vc.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13668536" author="gopalv" created="Tue, 28 May 2013 18:33:35 +0000"  >&lt;p&gt;I have implemented a similar fix as a Combiner in MR (LimitNKeys and LimitNValues) instead of using a hash/heap in-memory.&lt;/p&gt;

&lt;p&gt;This seems to be a lot more memory friendly since it doesn&apos;t need any extra memory, but it doesn&apos;t help the speed of the sort operations as the data size reduction is post-sort.&lt;/p&gt;

&lt;p&gt;And since it works for any writable, it only needs a simple single class implementation (no comparators within the combiner).&lt;/p&gt;

&lt;p&gt;The combiner is only run if there are multiple spills, but if the combiner can be forced by setting &quot;min.num.spills.for.combine&quot; = 0, then we can set a top-k (unique keys/values) selection sort via &quot;map.sort.class&quot; config instead of the default QuickSort impl, without any change to the hadoop core at all.&lt;/p&gt;</comment>
                            <comment id="13738847" author="ashutoshc" created="Tue, 13 Aug 2013 21:19:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt; Your approach sounds interesting, lot less intrusive and memory friendly indeed. If you still have a patch around this, would you like to post it?&lt;/p&gt;</comment>
                            <comment id="13739324" author="hiveqa" created="Wed, 14 Aug 2013 07:06:39 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12580643/HIVE-3562.D5967.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12580643/HIVE-3562.D5967.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/429/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/429/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/429/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/429/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-429/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/ColumnProjectionUtils.java&apos;
Reverted &apos;ql/src/test/results/compiler/plan/join2.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input2.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/join3.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input3.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/join4.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input4.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/join5.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input5.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/join6.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input_testxpath2.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input6.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/join7.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input7.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input_testsequencefile.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input8.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/join8.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/union.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input9.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/udf1.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/udf4.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input_testxpath.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/udf6.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input_part1.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/groupby1.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/udf_case.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/groupby2.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/subq.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/groupby3.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/groupby4.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/groupby5.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/groupby6.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/case_sensitivity.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/udf_when.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input20.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample1.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample2.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample3.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample4.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample5.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample6.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample7.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/cast1.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/join1.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input1.q.xml&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestIntegerCompressionReader.java&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestBitFieldReader.java&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestRunLengthIntegerReader.java&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestRunLengthByteReader.java&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestBitPack.java&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInStream.java&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcFile.java&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/io/sarg/TestSearchArgumentImpl.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/orc/Reader.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/orc/BitFieldReader.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcSerde.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/orc/RunLengthByteReader.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/orc/InStream.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/orc/ReaderImpl.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/sarg/SearchArgument.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/sarg/SearchArgumentImpl.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestRecordReaderImpl.java
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1513744.

At revision 1513744.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13740269" author="gopalv" created="Wed, 14 Aug 2013 22:05:32 +0000"  >&lt;p&gt;I have created &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5093&quot; title=&quot;Use a combiner for LIMIT with GROUP BY and ORDER BY operators&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5093&quot;&gt;&lt;del&gt;HIVE-5093&lt;/del&gt;&lt;/a&gt; to hold my limit combiner patch (rebased to trunk &amp;amp; turned off by default).&lt;/p&gt;</comment>
                            <comment id="13744568" author="phabricator@reviews.facebook.net" created="Tue, 20 Aug 2013 00:42:52 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Rebased to trunk&lt;/p&gt;

&lt;p&gt;Reviewers: tarball, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967?vs=32943&amp;amp;id=38379#toc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967?vs=32943&amp;amp;id=38379#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  ql/build.xml&lt;br/&gt;
  ql/ivy.xml&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13744728" author="hiveqa" created="Tue, 20 Aug 2013 05:45:46 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12598877/HIVE-3562.D5967.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12598877/HIVE-3562.D5967.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 2886 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/482/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/482/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/482/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/482/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13747625" author="ashutoshc" created="Thu, 22 Aug 2013 16:18:47 +0000"  >&lt;p&gt;As always, high quality work, Navis! &lt;br/&gt;
Left few implementation comments on phabricator. Most important ones are:&lt;br/&gt;
1. Is it possible to use one DataStructure (TreeSet probably) for two implementations of ReduceSinkHash. If so, that will simplify this code quite a bit.&lt;br/&gt;
2. Not sure how RS corresponding to distinct will be handled with this optimization. So, I requested for test cases for it.&lt;/p&gt;

&lt;p&gt;Cool stuff. Lets get this in!&lt;/p&gt;</comment>
                            <comment id="13747626" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 16:18:55 +0000"  >&lt;p&gt;ashutoshc has requested changes to the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:528 I think we don&apos;t need a boolean flag. If user has set hive.limit.pushdown.memory.usage=0 it is pretty clear he wants the optimization to be disabled.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java:1187 I didnt fully follow the example here. What are the keys/values/rows here?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:154 select key from src limit 0; implies user doesn&apos;t want any data, so RS doesnt need to emit any thing, this optimization is still valid and super useful here. Isn&apos;t it? So, this should be limit &amp;lt; 0, instead limit &amp;lt;=0&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:157 Can you add a comment why you are subtracting limit * 64 in this calculation of threshold?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:171 I think we need not to special handle limit = 0 by null&apos;ing the collector. As I said above better is to make RSHash to null in that case. This avoids a null check of collector in processOp().&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:325 As I noted above, lets not have this null check. Apart from you null&apos;ing the collector above, could there ever be case when it will be null. I dont think so, in that case lets remove this if-branch from inner loop.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:340 Shall this be instead collect(keyWritable, value) ?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:343 Didn&apos;t get your comment for retry here. Can you add more comment for it?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:346 collect() instead of out.collect() ?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:434-436 transient?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:471 It will be good to add a LOG.DEBUG() here saying, disabling ReduceSinkHash.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:477 I didn&apos;t get your TODO here. Can you explain?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:495 Better name: remove ?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:498 Add a comment here saying values&lt;span class=&quot;error&quot;&gt;&amp;#91;index&amp;#93;&lt;/span&gt; could be null, if flush() was called after this value is added but before remove() is called.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:535 You are using PriorityQueue almost like a sorted set.  I think java.util.TreeSet will suffice what you need here.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:566 I dont see you making use of any feature corresponding to Map interface. Looks like TreeSet would be sufficient here as well.&lt;/p&gt;

&lt;p&gt;  If it so that at both places we can use TreeSet than we do need not these two diff implementation of ReduceSinkHash. This will simplify code quite a bit.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:253-264 This handling of distinct keys case can also be refactored to use ReduceSinkHash. Will be a good idea to take this up in a follow up jira.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:535 Also need to mark it transient.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:91 If we are able to use one DataStructure in ReduceSinkHash (either TreeSet or some other) for both cases, we wont need this boolean.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:46 How are enforcing this condition of applying this optimization only for last RS. Can you add comments about this.&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q:14 Can you also add a test for following query with this optimization on:&lt;br/&gt;
  explain select distinct(key) from src limit 20;&lt;br/&gt;
  explain select count(distinct(key)) from src group by key limit 20;&lt;/p&gt;

&lt;p&gt;  select distinct(key) from src limit 20;&lt;br/&gt;
  select count(distinct(key)) from src group by key limit 20;&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q:43 It will be good to seprate these queries where optimization will not be fired in a seprate .q file.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, ashutoshc, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13747635" author="appodictic" created="Thu, 22 Aug 2013 16:27:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;1. Is it possible to use one DataStructure (TreeSet probably) for two implementations of ReduceSinkHash. If so, that will simplify this code quite a bit.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think we are better off using the MinMaxPriorityQueue&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://highscalability.com/blog/2013/5/22/strategy-stop-using-linked-lists.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://highscalability.com/blog/2013/5/22/strategy-stop-using-linked-lists.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Structures that use Node&apos;s are really inefficient in java. The pointers bloat the structure, and the non-local memory access and causes a lot of cache misses. I benched a similar scenario sorting large tree sets, and even though the big O is smaller (believe it or not) to sort a list then maintain a treeSet.  MinMaxPriorityQueue has a middle-ground implementation which real world works much faster then TreeSet. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.ArrayList;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.Collection;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.Collections;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.LinkedList;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.List;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.Random;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.TreeSet;

&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;TreeSetTest {

    &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; Random r = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Random();
   
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; [] args){
       
        doIt(500000,&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TreeSet&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;());
        doIt(500000,&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TreeSet&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;());
        doIt(500000,&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TreeSet&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;());
        doIt(500000,&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TreeSet&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;());
        {
        List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt; arrayList = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;();
        doIt(500000,arrayList);
        sortIt(arrayList);
        }
        {
            List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt; arrayList = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;();
            doIt(500000,arrayList);
            sortIt(arrayList);
            }
        {
            List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt; arrayList = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; LinkedList&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;();
            doIt(500000,arrayList);
            sortIt(arrayList);
            }
       
        {
            List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt; arrayList = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;();
            doIt(500000,arrayList);
            sortIt(arrayList);
            }
        {
            List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt; arrayList = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;();
            doIt(500000,arrayList);
            sortIt(arrayList);
            }
        doIt(500000,&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TreeSet&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;());
        doIt(500000,&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TreeSet&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;());
        {
            List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt; arrayList = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; LinkedList&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&amp;gt;();
            doIt(500000,arrayList);
            sortIt(arrayList);
            }
       
       
    }
   
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void sortIt(List l){
        &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; start = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis();
        Collections.sort(l);
        &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; end = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis();
        &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(l.getClass().getName()+&lt;span class=&quot;code-quote&quot;&gt;&quot; sort it &quot;&lt;/span&gt;+ (end-start));
    }
   
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void doIt(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; n, Collection l){
        &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; start = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis();
        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i =0;i&amp;lt;n;i++){
            randomDouble(l);
        }
        &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; end = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.currentTimeMillis();
        &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(l.getClass().getName()+&lt;span class=&quot;code-quote&quot;&gt;&quot; add it &quot;&lt;/span&gt;+ (end-start));
    }
   
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void randomDouble(Collection l){
        &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; rangeMin=0;
        &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; rangeMax=20000000;
              
        &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt; randomValue = rangeMin + (rangeMax - rangeMin) * r.nextDouble();
        l.add(randomValue);
    }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13747643" author="ashutoshc" created="Thu, 22 Aug 2013 16:36:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;navis&lt;/a&gt; Can you also add a test case for following query with both this optimization on as well as reducesink dedup optimization on? This will trigger a case for one merged RS for both group by and order by.&lt;br/&gt;
 select value,avg(key) from src group by value order by value limit 20;&lt;/p&gt;</comment>
                            <comment id="13747647" author="ashutoshc" created="Thu, 22 Aug 2013 16:41:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=appodictic&quot; class=&quot;user-hover&quot; rel=&quot;appodictic&quot;&gt;appodictic&lt;/a&gt; I dont care which DS you pick, I am looking for simplicity of implementation. Current patch has two implementation for RSHash which only differs on choice of DS and it appears to me that in both cases underlying DS is used in very similar fashion. If one can be used (whichever it is), this will make code simpler to read, understand and less bug prone.&lt;/p&gt;</comment>
                            <comment id="13747649" author="appodictic" created="Thu, 22 Aug 2013 16:42:52 +0000"  >&lt;p&gt;Makes sense.&lt;/p&gt;</comment>
                            <comment id="13748676" author="ashutoshc" created="Fri, 23 Aug 2013 16:18:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;navis&lt;/a&gt; It occurred to me that this optimization will become very powerful in combination with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4002&quot; title=&quot;Fetch task aggregation for simple group by query&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4002&quot;&gt;&lt;del&gt;HIVE-4002&lt;/del&gt;&lt;/a&gt; Imagine a case where there is a limit which can be pushed up in front of last RS. Than mappers will output very little data and with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4002&quot; title=&quot;Fetch task aggregation for simple group by query&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4002&quot;&gt;&lt;del&gt;HIVE-4002&lt;/del&gt;&lt;/a&gt; we can eliminate reducer altogether. Though these two optimizations cannot occur simultaneously in their current form since RSHash is implemented inside RS. We need to reimplement RSHash in FS. Alternative approach could be to implement RSHash as an operator which can than be put in front of either RS or FS. What do you think?&lt;/p&gt;</comment>
                            <comment id="13748683" author="yhuai" created="Fri, 23 Aug 2013 16:31:49 +0000"  >&lt;p&gt;Implementing RSHash as an operator sounds good. We can also use it in front of the RS of the right table of left semi join. Right now, there is a GBY. It is not straightforward in the query plan.&lt;/p&gt;</comment>
                            <comment id="13749290" author="phabricator@reviews.facebook.net" created="Sat, 24 Aug 2013 03:56:52 +0000"  >&lt;p&gt;navis has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Thanks for a review.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:528 I thought it&apos;s a convention of hive to make configurations for enable/disable and threshold each, which was requested several times till now for me for other issues. I&apos;ll address that.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java:1187 Legend : A(a) --&amp;gt; key A, value a, row A(a)&lt;/p&gt;

&lt;p&gt;  If each mapper takes rows lite this&lt;br/&gt;
  MAP1(RS) : 40(a)-10(b)-30(c)-10(d)-70(e)-80(f)&lt;br/&gt;
  MAP2(RS) : 90(g)-80(h)-60&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/information.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;-40(j)-30(k)-20(l)&lt;br/&gt;
  MAP3(RS) : 40(m)-50&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;-30(o)-30(p)-60(q)-70(r)&lt;/p&gt;

&lt;p&gt;  REDUCER : 10(b,d)-20(l)-30(c,k,o)-40(a,j,m)-50&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;-60(i,q)-70(e,r)-80(f,h)-90(g)&lt;br/&gt;
  REDUCER(LIMIT 3) : 10(b,d)-20(l)-30(c,k,o)&lt;/p&gt;

&lt;p&gt;  with this patch&lt;/p&gt;

&lt;p&gt;  MAP1 : 40(a)-10(b)-30(c)-10(d)&lt;br/&gt;
  MAP2 : 40(j)-30(k)-20(l)&lt;br/&gt;
  MAP3 : 40(m)-50&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;-30(o)-30(p)&lt;/p&gt;

&lt;p&gt;  REDUCER : 10(b,d)-20(l)-30(c,k,o)-40(a,j,m)-50&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
  REDUCER(LIMIT 3) : 10(b,d)-20(l)-30(c,k,o)&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:154 I thought limit 0 is not realistic and can be used for some kind of testing. I&apos;ll address that case but making Hash seemed a little much.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:157 ReduceSinkHash makes arrays for key/value/hashes. It&apos;s for compensating those (not exact but I like the number).&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:325 I think there was a test for RS operator which has no collector. I&apos;ll check that.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:340 Right. I&apos;ve missed that.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:343 It&apos;s possible to add key/value to hash which is flushed right before. But I just forwarded it.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:346 Right.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:434-436 It&apos;s not serializable class. But I&apos;ll add transient mod.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:471 I&apos;ll leave log message in the processOp() method.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:477 Return value can be false only if it&apos;s for GBY. False means the key exists already in RS hash.&lt;br/&gt;
  For case A(a)&lt;del&gt;&amp;gt;A(b)&lt;/del&gt;&amp;gt;B(c) with limit 5, the first A(a) will be stored into hash. For the second A(b), value b should be stored, which means values should be byte[][][] using additional array for each index consuming more memory. But I suspected that case could be a common case with map aggregation. So I just decided to forward A(b) to output collector.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:495 It does not remove anything. This is called after index is removed from RS hash.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:498 Good.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:535 Main difference of HashForOrder from HashForGroupBy is that it should store duplicated keys. As described in comments, A-&amp;gt;B-&amp;gt;B-&amp;gt;C limit 3 should store A,B,B not A,B,C. I believe this behavior can be possibly implemented with simple TreeSet but thought this is way simpler.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:566 I prefer Map rather than Set but I&apos;ll change that.&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q:14 ok&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q:43 ok.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:46 This is not exact description. RS for limit (not last RS). I&apos;ll change this, too.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:253-264 Looks promising. Need more investigation on implementation of distinct.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, ashutoshc, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13749292" author="navis" created="Sat, 24 Aug 2013 04:05:30 +0000"  >&lt;p&gt;I think RSHash should be a entity that can be used in various operators but not independent operator, because the behavior might be dependent to each operator. In current implementation, I&apos;ve modified RS only but the better way to implement this is calculating limit for each operators (bottom up way like CP or PPD) and make HASH for them. (Limit for GBY should be handled in GBY and for simple limit, RS, etc.)&lt;/p&gt;

&lt;p&gt;There seemed remain much works to do. &lt;/p&gt;</comment>
                            <comment id="13749296" author="ashutoshc" created="Sat, 24 Aug 2013 04:21:44 +0000"  >&lt;p&gt;I agree that will be quite a bit of work and given that this patch is out there for long, We should try to get this in without major rework. Though, I think hash for FS will make this optimization with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4002&quot; title=&quot;Fetch task aggregation for simple group by query&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4002&quot;&gt;&lt;del&gt;HIVE-4002&lt;/del&gt;&lt;/a&gt; real cool.  &lt;/p&gt;</comment>
                            <comment id="13749302" author="navis" created="Sat, 24 Aug 2013 04:38:49 +0000"  >&lt;p&gt;Then, FS will be needed for context of limiting rows(limit, key expressions, etc.). I&apos;ll consider that, too.&lt;/p&gt;</comment>
                            <comment id="13749303" author="ashutoshc" created="Sat, 24 Aug 2013 04:41:23 +0000"  >&lt;p&gt;Correct. Thanks a lot for considering. I am fine doing that in seprate jira. FSHashSink will expand scope of this jira unnecessarily.&lt;/p&gt;</comment>
                            <comment id="13749306" author="phabricator@reviews.facebook.net" created="Sat, 24 Aug 2013 04:46:52 +0000"  >&lt;p&gt;ashutoshc has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Good stuff!&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:528 Yeah I know historically we have done that way. But in my experience having more configs always confuses users instead of helping.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java:1187 Looks good. Can you update the patch with this?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:157 Sounds good. Please add it in comment.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:325 Sounds good.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:343 I see. I think just forwarding in this case is simple and better thing to do. So, lets leave it that way. Can you add a comment saying its possible to retry to add this to hash, but we don&apos;t do that yet. Also, collect()&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:434-436 Ah.. right. Than better not to add transient, otherwise will cause confusion.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:477 I see. Can you add comment here that further optimization like this is possible here. We can do this later.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:495 OK.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:535 I see. Missed this difference of duplicates. My major motivation in trying to unifying these two is so that in optimization rule we need not to worry about detecting whether there is a GBY in mapper or not.&lt;br/&gt;
  If using TreeSet will not over complicate this, I will suggest that. But if that complicates things too much here, I am fine with current implementation as well. I will let you decide on that.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:566 Here, using Set is definitely cleaner (and memory efficient) as far as I can see.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:46 Thanks.&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q:14 Thanks. Also, as I said in comment add&lt;br/&gt;
  select value,avg(key) from src group by value order by value limit 20;&lt;br/&gt;
  with reduce sink dedup optimization on.&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q:43 Thanks.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, ashutoshc, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13749927" author="phabricator@reviews.facebook.net" created="Mon, 26 Aug 2013 09:01:00 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Addressed some comments&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA, tarball&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967?vs=38379&amp;amp;id=39009#toc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967?vs=38379&amp;amp;id=39009#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  ql/build.xml&lt;br/&gt;
  ql/ivy.xml&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown_negative.q&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown_negative.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, ashutoshc, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13750007" author="phabricator@reviews.facebook.net" created="Mon, 26 Aug 2013 11:18:52 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Missed ASF header&lt;br/&gt;
  Removed unnecessary array creation in RS&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA, tarball&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967?vs=39009&amp;amp;id=39015#toc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967?vs=39009&amp;amp;id=39015#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  ql/build.xml&lt;br/&gt;
  ql/ivy.xml&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown_negative.q&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown_negative.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, ashutoshc, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13750398" author="phabricator@reviews.facebook.net" created="Mon, 26 Aug 2013 18:50:52 +0000"  >&lt;p&gt;ashutoshc has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Looks pretty good. Just requesting to add few more comments.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  conf/hive-default.xml.template:1586-1590 We can remove this now.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java:1186 Just to add more clarity, say something like: we can push the limit above GBY (running in Reducer), since that will generate single row for each group. This doesn&apos;t necessarily hold for GBY (running in Mappers), so we don&apos;t push limit above it.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:182 It will be good to add comment about what this field is holding. Add a comment saying: This two dimensional array holds key data and a corresponding Union object which contains the tag identifying the aggregate expression for distinct columns.&lt;/p&gt;

&lt;p&gt;  Ideally, instead of this 2-D array, we should have probably enhanced HiveKey class for this logic. We should do that in a follow-up jira.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:267 I didnt follow this logic completely.&lt;br/&gt;
  Seems like this is an optimization not to evaluate union object repeatedly and do system copy for it. Can you add a comment explaining this?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:271 seems like it will be null only for all i = 0. If so, better do if (i==0) check ? Also add comment when this will be null and when it will be non-null?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:260 You made changes to this section, because you found bug or are you purely refactoring this? If you hit upon the bug, can you explain what was it?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java:50-51 It will be good to add comment about what these 2D arrays are holding?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java:52 Also, add comment saying this array holds hashcode for keys.&lt;/p&gt;

&lt;p&gt;  Also, add note that indices of all these arrays must line up.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:82 Nice Comments!&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java:34 It will be good to add a javadoc for this class.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java:36 Also javadoc for this interface.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, ashutoshc, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13750876" author="phabricator@reviews.facebook.net" created="Tue, 27 Aug 2013 01:52:55 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  Addressed comments&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA, tarball&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967?vs=39015&amp;amp;id=39051#toc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967?vs=39015&amp;amp;id=39051#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  ql/build.xml&lt;br/&gt;
  ql/ivy.xml&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/limit_pushdown_negative.q&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/limit_pushdown_negative.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, ashutoshc, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13750955" author="phabricator@reviews.facebook.net" created="Tue, 27 Aug 2013 04:40:53 +0000"  >&lt;p&gt;ashutoshc has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Some limit can be pushed down to map stage&quot;.&lt;/p&gt;

&lt;p&gt;  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D5967&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, tarball, ashutoshc, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13751276" author="navis" created="Tue, 27 Aug 2013 14:01:14 +0000"  >&lt;p&gt;I&apos;m on vacation till next tuesday. Feel free to modify this patch, thanks.&lt;/p&gt;</comment>
                            <comment id="13752476" author="ashutoshc" created="Wed, 28 Aug 2013 15:02:57 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis for your persistence on this one!&lt;/p&gt;</comment>
                            <comment id="13752490" author="gopalv" created="Wed, 28 Aug 2013 15:13:02 +0000"  >&lt;p&gt;Good work Navis.&lt;/p&gt;

&lt;p&gt;Let me mark &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5093&quot; title=&quot;Use a combiner for LIMIT with GROUP BY and ORDER BY operators&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5093&quot;&gt;&lt;del&gt;HIVE-5093&lt;/del&gt;&lt;/a&gt; as obsoleted by this - no need for that hack anymore.&lt;/p&gt;</comment>
                            <comment id="13752529" author="hudson" created="Wed, 28 Aug 2013 16:10:48 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #74 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/74/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/74/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; : Some limit can be pushed down to map stage (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518234&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518234&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/build.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/ivy.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/limit_pushdown.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/limit_pushdown_negative.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/limit_pushdown_negative.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13752543" author="snarayanan" created="Wed, 28 Aug 2013 16:24:09 +0000"  >&lt;p&gt;Good stuff, Navis!&lt;/p&gt;</comment>
                            <comment id="13752552" author="hudson" created="Wed, 28 Aug 2013 16:30:56 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #142 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/142/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/142/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; : Some limit can be pushed down to map stage (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518234&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518234&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/build.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/ivy.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/limit_pushdown.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/limit_pushdown_negative.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/limit_pushdown_negative.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13753307" author="hudson" created="Thu, 29 Aug 2013 05:14:02 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-h0.21 #2295 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2295/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2295/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; : Some limit can be pushed down to map stage (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518234&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518234&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/build.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/ivy.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/limit_pushdown.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/limit_pushdown_negative.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/limit_pushdown_negative.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13753365" author="hudson" created="Thu, 29 Aug 2013 06:33:44 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #387 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/387/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/387/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3562&quot; title=&quot;Some limit can be pushed down to map stage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3562&quot;&gt;&lt;del&gt;HIVE-3562&lt;/del&gt;&lt;/a&gt; : Some limit can be pushed down to map stage (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518234&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518234&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/build.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/ivy.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/limit_pushdown.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/limit_pushdown_negative.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/limit_pushdown.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/limit_pushdown_negative.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795963" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:04 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                            <comment id="13805523" author="sershe" created="Fri, 25 Oct 2013 17:59:15 +0000"  >&lt;p&gt;Quick question - is it intended that excluded is only counted when the key is thrown out immediately? So if this doesn&apos;t happen it is likely to self-disable.&lt;br/&gt;
If the keys all go to the heap and later get evicted, it can still be useful to output less rows esp. if the data size is big and N is comparatively small.&lt;/p&gt;</comment>
                            <comment id="13808846" author="navis" created="Wed, 30 Oct 2013 08:21:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;sershe&lt;/a&gt; Sorry for late reply. I thought the cost of top-n hash(array copy, memory usage, etc.) would be bigger than possible gain of unknown future. Better policy might be implemented in following issue by someone with good idea.&lt;/p&gt;</comment>
                            <comment id="13809865" author="sershe" created="Thu, 31 Oct 2013 02:40:13 +0000"  >&lt;p&gt;Let me file a jira...&lt;/p&gt;</comment>
                            <comment id="14392243" author="lefty@hortonworks.com" created="Thu, 2 Apr 2015 06:50:53 +0000"  >&lt;p&gt;Doc note &amp;amp; questions:  This adds &lt;b&gt;hive.limit.pushdown.memory.usage&lt;/b&gt; to HiveConf.java, so it has been documented in the wiki with the description &quot;The maximum memory to be used for hash in RS operator for top K selection. The default value &apos;-1&apos; means no limit.&quot;&lt;/p&gt;

&lt;p&gt;Q1:  Does RS mean reduce sink?  (If so, I&apos;ll explain that in the description.)&lt;br/&gt;
Q2:  What values can be set?  (The template file originally said the default was 0.3, which implies it&apos;s a proportion of total memory or some such.)&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.limit.pushdown.memory.usage&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Configuration Properties &amp;#8211; hive.limit.pushdown.memory.usage &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="17170367" author="girishsk" created="Mon, 3 Aug 2020 19:15:08 +0000"  >&lt;p&gt;I have a hive query its returning different results with and without limit.&lt;/p&gt;

&lt;p&gt;Let&apos;s say with limit query result set as R1 and without limit query result set as R2.&lt;/p&gt;

&lt;p&gt;These are the following discrepancies:&#160;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;R1 contains some of the column values as null.&#160;&lt;/li&gt;
	&lt;li&gt;R2 doesn&apos;t contain the rows returned by R1.&lt;/li&gt;
	&lt;li&gt;R2 contains all non null column values.&#160;&lt;/li&gt;
	&lt;li&gt;R2 is returning correct results, R1 is returning wrong results.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;After debugging realised that&#160;&lt;b&gt;hive.limit.pushdown.memory.usage=0.1&lt;/b&gt;&#160;&lt;/p&gt;

&lt;p&gt;is the root cause of this issue. after i set this property to -1, R1 starts returning correct rows with non null column values. and R1 results are part of R2 results.&lt;/p&gt;

&lt;p&gt;What could be the problem setting lower value to&#160;&lt;b&gt;hive.limit.pushdown.memory.usage?&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;can it cause data issues in &quot;with limit&quot; hive queries by returning wrong results?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17414659" author="nemon" created="Tue, 14 Sep 2021 01:37:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=girishsk&quot; class=&quot;user-hover&quot; rel=&quot;girishsk&quot;&gt;girishsk&lt;/a&gt;&#160;I reported a same issue , also with some&#160;analysis :&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-24579&quot; title=&quot;Incorrect Result For Groupby With Limit&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-24579&quot;&gt;&lt;del&gt;HIVE-24579&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12663731">HIVE-5093</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12910195">HIVE-12329</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                            <outwardlinks description="supercedes">
                                        <issuelink>
            <issuekey id="12663731">HIVE-5093</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12548523" name="HIVE-3562.D5967.1.patch" size="19572" author="phabricator@reviews.facebook.net" created="Wed, 10 Oct 2012 05:21:02 +0000"/>
                            <attachment id="12560156" name="HIVE-3562.D5967.2.patch" size="44317" author="phabricator@reviews.facebook.net" created="Mon, 10 Dec 2012 08:03:19 +0000"/>
                            <attachment id="12563009" name="HIVE-3562.D5967.3.patch" size="67615" author="phabricator@reviews.facebook.net" created="Thu, 3 Jan 2013 01:22:11 +0000"/>
                            <attachment id="12575492" name="HIVE-3562.D5967.4.patch" size="85315" author="phabricator@reviews.facebook.net" created="Tue, 26 Mar 2013 08:25:14 +0000"/>
                            <attachment id="12580643" name="HIVE-3562.D5967.5.patch" size="92688" author="phabricator@reviews.facebook.net" created="Fri, 26 Apr 2013 01:38:14 +0000"/>
                            <attachment id="12598877" name="HIVE-3562.D5967.6.patch" size="87727" author="phabricator@reviews.facebook.net" created="Tue, 20 Aug 2013 00:42:52 +0000"/>
                            <attachment id="12599898" name="HIVE-3562.D5967.7.patch" size="105125" author="phabricator@reviews.facebook.net" created="Mon, 26 Aug 2013 09:01:00 +0000"/>
                            <attachment id="12599929" name="HIVE-3562.D5967.8.patch" size="107220" author="phabricator@reviews.facebook.net" created="Mon, 26 Aug 2013 11:18:52 +0000"/>
                            <attachment id="12600080" name="HIVE-3562.D5967.9.patch" size="106970" author="phabricator@reviews.facebook.net" created="Tue, 27 Aug 2013 01:52:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>246897</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 9 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i07win:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>44035</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>