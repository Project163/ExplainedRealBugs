<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:24:35 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-7627] FSStatsPublisher does fit into Spark multi-thread task mode[Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-7627</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive table statistic failed on FSStatsPublisher mode, with the following exception in Spark executor side:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;14/08/05 16:46:24 WARN hdfs.DFSClient: DataStreamer Exception
java.io.FileNotFoundException: ID mismatch. Request id and saved id: 20277 , 20278 for file /tmp/hive-root/8833d172-1edd-4508-86db-fdd7a1b0af17/hive_2014-08-05_16-46-03_013_6279446857294757772-1/-ext-10000/tmpstats-0
        at org.apache.hadoop.hdfs.server.namenode.INodeId.checkId(INodeId.java:53)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2952)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2754)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2662)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:584)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:440)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:525)
        at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
       at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1442)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1261)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:525)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): ID mismatch. Request id and saved id: 20277 , 20278 for file /tmp/hive-root/8833d172-1edd-4508-86db-fdd7a1b0af17/hive_2014-08-05_16-46-03_013_6279446857294757772-1/-ext-10000/tmpstats-0
        at org.apache.hadoop.hdfs.server.namenode.INodeId.checkId(INodeId.java:53)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2952)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2754)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2662)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:584)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:440)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

        at org.apache.hadoop.ipc.Client.call(Client.java:1410)
        at org.apache.hadoop.ipc.Client.call(Client.java:1363)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at com.sun.proxy.$Proxy19.addBlock(Unknown Source)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:190)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)
        at com.sun.proxy.$Proxy19.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:361)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1439)
        ... 2 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12732211">HIVE-7627</key>
            <summary>FSStatsPublisher does fit into Spark multi-thread task mode[Spark Branch]</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="chengxiang li">Chengxiang Li</assignee>
                                    <reporter username="chengxiang li">Chengxiang Li</reporter>
                        <labels>
                            <label>spark-m1</label>
                    </labels>
                <created>Wed, 6 Aug 2014 03:01:57 +0000</created>
                <updated>Fri, 29 May 2015 02:30:16 +0000</updated>
                            <resolved>Mon, 29 Sep 2014 18:06:24 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14088744" author="chengxiang li" created="Thu, 7 Aug 2014 03:12:47 +0000"  >&lt;p&gt;Root  cause:&lt;/p&gt;

&lt;p&gt;FSStatsPublisher collect table data info through TableScanOperator in each task, and write collect data into a file each, the file name for each task is set by prefix + conf.getInt(&#8220;mapred.task.partition&#8221;). During Hive on Spark, &quot;mapred.task.partition&quot; is not set, so it&apos;s all the same for all tasks, which means all tasks write to the same file. In HDFS, multi-thread write to  same file with overwrite is true would lead to the previous exception.&lt;/p&gt;

&lt;p&gt;Solution:&lt;/p&gt;

&lt;p&gt;We need to set &quot;mapred.task.partition&quot; in Spark transformation closure, so current problem is that Spark transformation closure can&apos;t get task context information through Spark Java API, it&apos;s only available in Spark Scala API, I&apos;ve created &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2895&quot; title=&quot;Support mapPartitionsWithContext in Spark Java API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2895&quot;&gt;&lt;del&gt;SPARK-2895&lt;/del&gt;&lt;/a&gt; to track this.&lt;/p&gt;</comment>
                            <comment id="14115000" author="chengxiang li" created="Fri, 29 Aug 2014 07:54:29 +0000"  >&lt;p&gt;Use &lt;tt&gt;mapPartitionToPairWithContext()&lt;/tt&gt; instead of &lt;tt&gt;mapPartitionToPair()&lt;/tt&gt; to get access of TaskContext in HiveMapFuction/HiveReduceFunction. &lt;/p&gt;

&lt;p&gt;&lt;b&gt;NOTICE&lt;/b&gt;, this patch depends on &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2895&quot; title=&quot;Support mapPartitionsWithContext in Spark Java API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2895&quot;&gt;&lt;del&gt;SPARK-2895&lt;/del&gt;&lt;/a&gt;, we need to update Spark dependency to latest spark master build after &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2895&quot; title=&quot;Support mapPartitionsWithContext in Spark Java API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2895&quot;&gt;&lt;del&gt;SPARK-2895&lt;/del&gt;&lt;/a&gt; is merged.&lt;/p&gt;</comment>
                            <comment id="14128247" author="chengxiang li" created="Wed, 10 Sep 2014 09:22:48 +0000"  >&lt;p&gt;make taskId field variable of FSStatPublisher would resolve this issue either, since &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2895&quot; title=&quot;Support mapPartitionsWithContext in Spark Java API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2895&quot;&gt;&lt;del&gt;SPARK-2895&lt;/del&gt;&lt;/a&gt; is still under review, we could enable random generated taskId first.&lt;/p&gt;</comment>
                            <comment id="14128338" author="hiveqa" created="Wed, 10 Sep 2014 10:57:40 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12667637/HIVE-7627.2-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12667637/HIVE-7627.2-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 6343 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_fs_default_name2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/123/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/123/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/123/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/123/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-123/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-123/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12667637&lt;/p&gt;</comment>
                            <comment id="14151020" author="hiveqa" created="Sun, 28 Sep 2014 08:23:08 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12671696/HIVE-7627.3-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12671696/HIVE-7627.3-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/167/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/167/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/167/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/167/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-167/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-167/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:115:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:127:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:138:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:149:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:166:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3

As a result, alternative(s) 3 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:518:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
Downloading: http://www.datanucleus.org/downloads/maven2/org/apache/hadoop/hadoop-client/2.3.0-cdh5.1.2/hadoop-client-2.3.0-cdh5.1.2.pom
Downloading: http://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-client/2.3.0-cdh5.1.2/hadoop-client-2.3.0-cdh5.1.2.pom
Downloading: http://www.datanucleus.org/downloads/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.3.0-cdh5.1.2/hadoop-mapreduce-client-app-2.3.0-cdh5.1.2.pom
Downloading: http://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.3.0-cdh5.1.2/hadoop-mapreduce-client-app-2.3.0-cdh5.1.2.pom
Downloading: http://www.datanucleus.org/downloads/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.3.0-cdh5.1.2/hadoop-mapreduce-client-shuffle-2.3.0-cdh5.1.2.pom
Downloading: http://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.3.0-cdh5.1.2/hadoop-mapreduce-client-shuffle-2.3.0-cdh5.1.2.pom
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1909 source files to /data/hive-ptest/working/apache-svn-spark-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol
  symbol:   method get()
  location: class org.apache.spark.TaskContext
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [2.892s]
[INFO] Hive Shims Common ................................. SUCCESS [2.532s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [1.010s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [1.468s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [0.865s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [1.862s]
[INFO] Hive Shims ........................................ SUCCESS [0.243s]
[INFO] Hive Common ....................................... SUCCESS [4.505s]
[INFO] Hive Serde ........................................ SUCCESS [3.837s]
[INFO] Hive Metastore .................................... SUCCESS [11.725s]
[INFO] Hive Ant Utilities ................................ SUCCESS [0.560s]
[INFO] Hive Query Language ............................... FAILURE [18.143s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 50.539s
[INFO] Finished at: Sun Sep 28 04:24:21 EDT 2014
[INFO] Final Memory: 84M/827M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol
[ERROR] symbol:   method get()
[ERROR] location: class org.apache.spark.TaskContext
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12671696&lt;/p&gt;</comment>
                            <comment id="14151065" author="hiveqa" created="Sun, 28 Sep 2014 10:03:15 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12671699/HIVE-7627.4-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12671699/HIVE-7627.4-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/168/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/168/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/168/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/168/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-168/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-168/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:115:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:127:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:138:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:149:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:166:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3

As a result, alternative(s) 3 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:518:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1909 source files to /data/hive-ptest/working/apache-svn-spark-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol
  symbol:   method get()
  location: class org.apache.spark.TaskContext
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol
  symbol:   method get()
  location: class org.apache.spark.TaskContext
[INFO] 2 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [2.923s]
[INFO] Hive Shims Common ................................. SUCCESS [2.534s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [0.731s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [1.442s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [0.684s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [1.729s]
[INFO] Hive Shims ........................................ SUCCESS [0.264s]
[INFO] Hive Common ....................................... SUCCESS [3.298s]
[INFO] Hive Serde ........................................ SUCCESS [3.676s]
[INFO] Hive Metastore .................................... SUCCESS [12.425s]
[INFO] Hive Ant Utilities ................................ SUCCESS [0.546s]
[INFO] Hive Query Language ............................... FAILURE [16.338s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 47.489s
[INFO] Finished at: Sun Sep 28 06:04:28 EDT 2014
[INFO] Final Memory: 86M/945M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol
[ERROR] symbol:   method get()
[ERROR] location: class org.apache.spark.TaskContext
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol
[ERROR] symbol:   method get()
[ERROR] location: class org.apache.spark.TaskContext
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12671699&lt;/p&gt;</comment>
                            <comment id="14151115" author="xuefuz" created="Sun, 28 Sep 2014 14:20:51 +0000"  >&lt;p&gt;The failure may be caused by the snapshot spark library, which may need to be updated to include the fix for &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2895&quot; title=&quot;Support mapPartitionsWithContext in Spark Java API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2895&quot;&gt;&lt;del&gt;SPARK-2895&lt;/del&gt;&lt;/a&gt;. Will do that shortly.&lt;/p&gt;</comment>
                            <comment id="14151252" author="xuefuz" created="Sun, 28 Sep 2014 23:06:16 +0000"  >&lt;p&gt;Reload the same patch to trigger the test.&lt;/p&gt;</comment>
                            <comment id="14151259" author="hiveqa" created="Sun, 28 Sep 2014 23:22:45 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12671721/HIVE-7627.4-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12671721/HIVE-7627.4-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/169/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/169/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/169/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/169/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-169/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-169/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:115:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:127:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:138:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:149:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:166:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3

As a result, alternative(s) 3 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:518:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1909 source files to /data/hive-ptest/working/apache-svn-spark-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol
  symbol:   method get()
  location: class org.apache.spark.TaskContext
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol
  symbol:   method get()
  location: class org.apache.spark.TaskContext
[INFO] 2 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [2.892s]
[INFO] Hive Shims Common ................................. SUCCESS [2.371s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [0.975s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [1.330s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [0.646s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [1.616s]
[INFO] Hive Shims ........................................ SUCCESS [0.247s]
[INFO] Hive Common ....................................... SUCCESS [3.192s]
[INFO] Hive Serde ........................................ SUCCESS [3.826s]
[INFO] Hive Metastore .................................... SUCCESS [11.761s]
[INFO] Hive Ant Utilities ................................ SUCCESS [0.564s]
[INFO] Hive Query Language ............................... FAILURE [18.403s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 48.984s
[INFO] Finished at: Sun Sep 28 19:23:58 EDT 2014
[INFO] Final Memory: 84M/842M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol
[ERROR] symbol:   method get()
[ERROR] location: class org.apache.spark.TaskContext
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol
[ERROR] symbol:   method get()
[ERROR] location: class org.apache.spark.TaskContext
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12671721&lt;/p&gt;</comment>
                            <comment id="14151326" author="hiveqa" created="Mon, 29 Sep 2014 03:23:00 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12671735/HIVE-7627.5-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12671735/HIVE-7627.5-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/170/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/170/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/170/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/170/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-170/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-170/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:115:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:127:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:138:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:149:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:166:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3

As a result, alternative(s) 3 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:518:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1909 source files to /data/hive-ptest/working/apache-svn-spark-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol
  symbol:   method get()
  location: class org.apache.spark.TaskContext
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol
  symbol:   method get()
  location: class org.apache.spark.TaskContext
[INFO] 2 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [3.104s]
[INFO] Hive Shims Common ................................. SUCCESS [2.346s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [0.861s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [1.210s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [0.606s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [1.826s]
[INFO] Hive Shims ........................................ SUCCESS [0.271s]
[INFO] Hive Common ....................................... SUCCESS [3.376s]
[INFO] Hive Serde ........................................ SUCCESS [3.801s]
[INFO] Hive Metastore .................................... SUCCESS [12.085s]
[INFO] Hive Ant Utilities ................................ SUCCESS [0.564s]
[INFO] Hive Query Language ............................... FAILURE [16.142s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 47.034s
[INFO] Finished at: Sun Sep 28 23:24:13 EDT 2014
[INFO] Final Memory: 86M/942M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol
[ERROR] symbol:   method get()
[ERROR] location: class org.apache.spark.TaskContext
[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol
[ERROR] symbol:   method get()
[ERROR] location: class org.apache.spark.TaskContext
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12671735&lt;/p&gt;</comment>
                            <comment id="14151852" author="brocknoland" created="Mon, 29 Sep 2014 16:12:53 +0000"  >&lt;p&gt;Re-uploading the same patch to test the precommit infra.&lt;/p&gt;</comment>
                            <comment id="14151918" author="hiveqa" created="Mon, 29 Sep 2014 17:21:09 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12671815/HIVE-7627.5-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12671815/HIVE-7627.5-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6509 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_fs_default_name2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/173/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/173/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/173/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/173/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-173/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-173/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12671815&lt;/p&gt;</comment>
                            <comment id="14151963" author="xuefuz" created="Mon, 29 Sep 2014 18:03:03 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14151968" author="xuefuz" created="Mon, 29 Sep 2014 18:06:24 +0000"  >&lt;p&gt;Patch committed to Spark branch. Thanks to Chengxiang for the contribution.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12732454">SPARK-2895</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12723734">HIVE-7292</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12732454">SPARK-2895</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12731635">HIVE-7597</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12665291" name="HIVE-7627.1-spark.patch" size="5595" author="chengxiang li" created="Fri, 29 Aug 2014 07:54:29 +0000"/>
                            <attachment id="12667637" name="HIVE-7627.2-spark.patch" size="1096" author="chengxiang li" created="Wed, 10 Sep 2014 09:22:48 +0000"/>
                            <attachment id="12671696" name="HIVE-7627.3-spark.patch" size="1020" author="chengxiang li" created="Sun, 28 Sep 2014 07:54:40 +0000"/>
                            <attachment id="12671721" name="HIVE-7627.4-spark.patch" size="2102" author="xuefuz" created="Sun, 28 Sep 2014 23:06:16 +0000"/>
                            <attachment id="12671699" name="HIVE-7627.4-spark.patch" size="2102" author="chengxiang li" created="Sun, 28 Sep 2014 09:48:31 +0000"/>
                            <attachment id="12671815" name="HIVE-7627.5-spark.patch" size="2102" author="brocknoland" created="Mon, 29 Sep 2014 16:12:53 +0000"/>
                            <attachment id="12671735" name="HIVE-7627.5-spark.patch" size="2102" author="chengxiang li" created="Mon, 29 Sep 2014 03:02:47 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>410240</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 8 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ykxr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>410230</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>