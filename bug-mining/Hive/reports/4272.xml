<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:41:44 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-12951] Reduce Spark executor prewarm timeout to 5s</title>
                <link>https://issues.apache.org/jira/browse/HIVE-12951</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently it&apos;s set to 30s, which tends to be longer than needed. Reduce it to 5s, only considering jvm startup time. (Eventually, we may want to make this configurable.)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12934647">HIVE-12951</key>
            <summary>Reduce Spark executor prewarm timeout to 5s</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="xuefuz">Xuefu Zhang</assignee>
                                    <reporter username="xuefuz">Xuefu Zhang</reporter>
                        <labels>
                    </labels>
                <created>Thu, 28 Jan 2016 00:45:31 +0000</created>
                <updated>Thu, 27 Oct 2016 01:27:38 +0000</updated>
                            <resolved>Thu, 4 Feb 2016 18:45:45 +0000</resolved>
                                    <version>1.2.0</version>
                                    <fixVersion>2.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="15120532" author="xuefuz" created="Thu, 28 Jan 2016 00:52:24 +0000"  >&lt;p&gt;cc: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15120600" author="lirui" created="Thu, 28 Jan 2016 02:03:43 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;xuefuz&lt;/a&gt;, Spark has configurations &lt;tt&gt;spark.scheduler.minRegisteredResourcesRatio&lt;/tt&gt; and &lt;tt&gt;spark.scheduler.maxRegisteredResourcesWaitingTime&lt;/tt&gt;, which I think serve the purpose of pre-warm. I suppose we do this on hive side because we use the number of executors to set the number of reducers?&lt;/p&gt;</comment>
                            <comment id="15120609" author="xuefuz" created="Thu, 28 Jan 2016 02:14:35 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;, thanks for the information. Yes, these seem very relevant. However, I&apos;m not 100% sure if they are equivalent. Looking the description of the first property, I&apos;m not sure what&apos;s &quot;expected resources&quot;. In Hive, user can specify the number of containers (executors) to prewarm (refer to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-11363&quot; title=&quot;Prewarm Hive on Spark containers [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-11363&quot;&gt;&lt;del&gt;HIVE-11363&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Yes, this is used to set higher parallelism by waiting briefly, which is important for performance for short-lived user sessions.&lt;/p&gt;</comment>
                            <comment id="15120629" author="lirui" created="Thu, 28 Jan 2016 02:35:47 +0000"  >&lt;p&gt;Thanks Xuefu for the clarifications!&lt;br/&gt;
I think &quot;expected resources&quot; is something like &lt;tt&gt;spark.executor.instances&lt;/tt&gt; (not considering dynamic allocation). These spark configurations are intended for job execution, i.e. pre-warm before scheduling any tasks. But they won&apos;t help deciding the parallelism on hive side. Therefore what we do here still makes sense.&lt;/p&gt;

&lt;p&gt;The patch LGTM. One concern is that it may cause some tests diff. Otherwise +1.&lt;/p&gt;</comment>
                            <comment id="15120651" author="lirui" created="Thu, 28 Jan 2016 02:54:07 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;xuefuz&lt;/a&gt;, I just thought more about this. Maybe we should use the &quot;expected # executors&quot; instead of &quot;available # executors&quot; to decide the parallelism (fall back to what we do now if &quot;expected&quot; is unavailable, e.g. standalone mode). Intuitively, users have more knowledge about their job and will set the expected # executors accordingly. We should honor that, even if the RM cannot grant the required amount. This way, each executor may be assigned more reducers, but the job is less likely to fail because each reducer handles the expected amount of data. Another benefit is our test outputs can be more deterministic.&lt;/p&gt;

&lt;p&gt;We can do this in separate JIRA if you think it&apos;s OK.&lt;/p&gt;</comment>
                            <comment id="15120769" author="xuefuz" created="Thu, 28 Jan 2016 05:11:05 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;, that&apos;s an interesting idea. I can see that prewarming executors is no longer needed if parallelism is determined by the expected executors. However, prewarming is meant for shor-lived sessions, such as ETL job launched by Oozie. For interactive sessions, this feature doesn&apos;t matter much. Therefore, we probably don&apos;t want to change the way of determining parallelism just for a less common use case.&lt;/p&gt;

&lt;p&gt;Now let&apos;s see if using expected number of executors to determine makes sense in the general case. In this case, we don&apos;t worry about the performance for the first query. Whether we have static or dynamic allocation, the parallelism is determined in the same way if we use the actual number of executors. On the other hand, if we use the expected number of executors, it seems the expected number of executors is undefined in case of dynamic allocation. Also, the expected may not always match the actual. If there is a big difference, there could be performance implications.&lt;/p&gt;

&lt;p&gt;In conclusion, I can certainly see some benefits of using the expected number of executors. However, there also seem some unknowns as well. I think we don&apos;t have to make a call at this point. Maybe we can revisit once we learn more or get more user feedback?&lt;/p&gt;

&lt;p&gt;What do you think? &lt;/p&gt;
</comment>
                            <comment id="15120795" author="lirui" created="Thu, 28 Jan 2016 05:37:16 +0000"  >&lt;p&gt;Generally speaking, I think we have a better chance to get more reducers with expected resources, because RM won&apos;t allocate more resources than requested, right? But #reducers is not determined by #executors alone, and like you said we will need to handle dynamic allocations differently. So I agree we can decide this later when there&apos;s concrete need for it.&lt;/p&gt;</comment>
                            <comment id="15130511" author="hiveqa" created="Wed, 3 Feb 2016 14:51:23 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12785705/HIVE-12951.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12785705/HIVE-12951.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 10048 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.testExecuteStatementAsync
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6851/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6851/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6851/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6851/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6851/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6851/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12785705 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15131538" author="lirui" created="Thu, 4 Feb 2016 01:47:18 +0000"  >&lt;p&gt;+1.&lt;/p&gt;</comment>
                            <comment id="15132763" author="xuefuz" created="Thu, 4 Feb 2016 18:45:45 +0000"  >&lt;p&gt;Committed to master. Thanks, Rui.&lt;/p&gt;</comment>
                            <comment id="15604832" author="richard_xin" created="Tue, 25 Oct 2016 09:56:10 +0000"  >&lt;p&gt;Hi, we are facing issues while using hive-on-spark prewarm feature. (CDH 5.7.2, HIve 1.1.0, spark 1.6.1 on a small cluster of 5 hosts)&lt;br/&gt;
here is what we did:&lt;br/&gt;
1. on CM, we changed &lt;br/&gt;
hive.prewarm.enabled to true, &lt;br/&gt;
hive.execution.engine to spark; &lt;br/&gt;
hive.prewarm.numcontainers to 5&lt;br/&gt;
spark.dynamicAllocation.minExecutors = 5; &lt;br/&gt;
spark.dynamicAllocation.enabled=true&lt;br/&gt;
2. restart hive&lt;br/&gt;
3. when we start a new hive session, the first query is still slow, subsequent ones are much faster, It seems that the prewarm config didn&apos;t take effect.&lt;br/&gt;
Please advise what we have missed.&lt;br/&gt;
Thanks&lt;/p&gt;</comment>
                            <comment id="15605111" author="lirui" created="Tue, 25 Oct 2016 12:01:57 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=richard_xin&quot; class=&quot;user-hover&quot; rel=&quot;richard_xin&quot;&gt;richard_xin&lt;/a&gt;, pre-warm is intended to wait until some containers are launched before we decide the parallelism/start the job. In general, it helps us to have a higher parallelism and better task scheduling. However it doesn&apos;t remove the start-up overhead for the 1st query - anyway we have to wait for the containers to be launched to run the query.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;xuefuz&lt;/a&gt; please add if I missed anything.&lt;/p&gt;</comment>
                            <comment id="15605750" author="xuefuz" created="Tue, 25 Oct 2016 16:20:50 +0000"  >&lt;p&gt;Besides more containers that are already active, the second run also benefits a lot from JIT code generation which cannot be done by prewarning containers.&lt;/p&gt;

&lt;p&gt;The right comparison is to measure the performance with and without container prewarming to see if there is any benefit for your first run and make your decision accordingly.&lt;/p&gt;</comment>
                            <comment id="15607154" author="richard_xin" created="Wed, 26 Oct 2016 02:30:47 +0000"  >&lt;p&gt;Thanks Rui and Xuefu for your quick replies.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; The right comparison is to measure the performance with and without container prewarming to see if there is any benefit for your first run&lt;br/&gt;
we didn&apos;t feel any performance benefit with prewarming for the first run. I assume that &quot;first run&quot; here refers to first run per hive session, instead of first run after hive restarts.&lt;br/&gt;
We are trying to build a web service to run ad-hoc queries against hive, so each call could be the &quot;first call&quot; for the session.  do you have any recommendations on how we should implement the solution? Based to our tests, some sessions&apos; first query under hive on spark is slower than hive on mr. &lt;br/&gt;
Thanks in advance for your insight.&lt;/p&gt;</comment>
                            <comment id="15608847" author="xuefuz" created="Wed, 26 Oct 2016 15:56:21 +0000"  >&lt;p&gt;Prawarming containers tends to help queries that run for a longer time and have multiple stages. It doesn&apos;t help and may have adverse impact if your query is small or has only map stage. The important thing for you is to have a configuration that works for most of your use case.&lt;/p&gt;

&lt;p&gt;As to your webservice, you might want to consider pooling a list of HS2 sessions instead of creating a new one each time a request comes.&lt;/p&gt;</comment>
                            <comment id="15610288" author="richard_xin" created="Thu, 27 Oct 2016 01:27:38 +0000"  >&lt;p&gt;thanks, we will try that&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12848737">HIVE-11363</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12785705" name="HIVE-12951.patch" size="1478" author="xuefuz" created="Tue, 2 Feb 2016 05:40:27 +0000"/>
                            <attachment id="12784789" name="HIVE-12951.patch" size="1478" author="xuefuz" created="Thu, 28 Jan 2016 00:52:24 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 3 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2s2fz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12334255">2.1.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>