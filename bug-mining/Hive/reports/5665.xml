<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:55:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-16832] duplicate ROW__ID possible in multi insert into transactional table</title>
                <link>https://issues.apache.org/jira/browse/HIVE-16832</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; create table AcidTablePart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES (&apos;transactional&apos;=&apos;true&apos;);
 create temporary table if not exists data1 (x int);
 insert into data1 values (1);
 from data1
   insert into AcidTablePart partition(p) select 0, 0, &apos;p&apos; || x
   insert into AcidTablePart partition(p=&apos;p1&apos;) select 0, 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Each branch of this multi-insert create a row in partition p1/bucket0 with ROW__ID=(1,0,0).&lt;br/&gt;
The same can happen when running SQL Merge (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-10924&quot; title=&quot;add support for MERGE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-10924&quot;&gt;&lt;del&gt;HIVE-10924&lt;/del&gt;&lt;/a&gt;) statement that has both Insert and Update clauses when target table has &lt;em&gt;&apos;transactional&apos;=&apos;true&apos;,&apos;transactional_properties&apos;=&apos;default&apos;&lt;/em&gt;  (see &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14035&quot; title=&quot;Enable predicate pushdown to delta files created by ACID Transactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14035&quot;&gt;&lt;del&gt;HIVE-14035&lt;/del&gt;&lt;/a&gt;).  This is so because Merge is internally run as a multi-insert statement.&lt;/p&gt;

&lt;p&gt;The solution relies on statement ID introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-11030&quot; title=&quot;Enhance storage layer to create one delta file per write&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-11030&quot;&gt;&lt;del&gt;HIVE-11030&lt;/del&gt;&lt;/a&gt;.  Each Insert clause of a multi-insert is gets a unique ID.&lt;br/&gt;
The ROW__ID.bucketId now becomes a bit packed triplet (format version, bucketId, statementId).&lt;br/&gt;
(Since ORC stores field names in the data file we can&apos;t rename ROW__ID.bucketId).&lt;br/&gt;
This ensures that there are no collisions and retains desired sort properties of ROW__ID.&lt;br/&gt;
In particular &lt;em&gt;SortedDynPartitionOptimizer&lt;/em&gt; works w/o any changes even in cases where there fewer reducers than buckets.  &lt;/p&gt;
</description>
                <environment></environment>
        <key id="13077771">HIVE-16832</key>
            <summary>duplicate ROW__ID possible in multi insert into transactional table</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ekoifman">Eugene Koifman</assignee>
                                    <reporter username="ekoifman">Eugene Koifman</reporter>
                        <labels>
                    </labels>
                <created>Tue, 6 Jun 2017 18:59:52 +0000</created>
                <updated>Wed, 23 May 2018 00:00:11 +0000</updated>
                            <resolved>Wed, 12 Jul 2017 23:04:30 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>Transactions</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16039852" author="ekoifman" created="Tue, 6 Jun 2017 23:17:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-16832&quot; title=&quot;duplicate ROW__ID possible in multi insert into transactional table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-16832&quot;&gt;&lt;del&gt;HIVE-16832&lt;/del&gt;&lt;/a&gt;.01.patch is an incomplete WIP&lt;br/&gt;
VectorizedOrcAcidRowBatchReader assumes that ROW__ID.bucketId is the same in each split (and each bucket file of a delete_delta) which is no longer the case&lt;/p&gt;

&lt;p&gt;SortedDynPartitionOptimizer needs to ensure that data is sorted by &lt;br/&gt;
by (ROW_&lt;em&gt;ID.bucketId%numBuckets) before it&apos;s sorted by ROW&lt;/em&gt;_ID so that&lt;br/&gt;
FileSinkOperator.process() sees all rows for a given bucket equivalence set before moving on to the next equivalence set.  &lt;/p&gt;</comment>
                            <comment id="16040144" author="hiveqa" created="Wed, 7 Jun 2017 04:16:04 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12871718/HIVE-16832.01.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12871718/HIVE-16832.01.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 4 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 48 failed/errored test(s), 10832 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=157)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query78] (batchId=232)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testEmpty (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testUpdates (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriterTblProperties (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testCanCreateVectorizedAcidRowBatchReaderOnSplit (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=214)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=189)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5559/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5559/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5559/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5559/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5559/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5559/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 48 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12871718 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16055191" author="hiveqa" created="Tue, 20 Jun 2017 06:05:33 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12873581/HIVE-16832.03.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12873581/HIVE-16832.03.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5682/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5682/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5682/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5682/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5682/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5682/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[68,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[73,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[74,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[75,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[80,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[81,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[84,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[89,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[90,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[91,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[96,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[97,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[98,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[99,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[100,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestRecordInspectorImpl.java:[38,41] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/StreamingAssert.java:[150,34] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestBucketIdResolverImpl.java:[43,33] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[57,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[58,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[59,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[60,58] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[245,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[302,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[313,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[324,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[326,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[372,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[501,95] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[504,83] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[506,53] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[507,98] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[521,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[523,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[525,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[533,59] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[541,63] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-hcatalog-streaming
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12873581 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16055468" author="hiveqa" created="Tue, 20 Jun 2017 09:48:47 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12873614/HIVE-16832.04.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12873614/HIVE-16832.04.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5687/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5687/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5687/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5687/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5687/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5687/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/token/Token.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/util/Tool.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar(org/apache/thrift/TException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/conf/Configurable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Callable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/InterruptedException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Boolean.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/ClassNotFoundException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/ql/target/hive-exec-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/ql/ErrorMsg.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Integer.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar(org/apache/commons/logging/Log.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar(org/apache/commons/logging/LogFactory.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobStatus.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobProfile.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Long.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/JavaUtils.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/FileNotFoundException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URISyntaxException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URI.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/metastore/target/hive-metastore-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/metastore/api/MetaException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/Credentials.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/InetAddress.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/UnknownHostException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/text/MessageFormat.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Matcher.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Pattern.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/DELETE.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/FormParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/GET.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/POST.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/PUT.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/Path.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/PathParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/Produces.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/QueryParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/Context.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/SecurityContext.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/UriInfo.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-lang/commons-lang/2.6/commons-lang-2.6.jar(org/apache/commons/lang/StringUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/fs/FileStatus.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/wadl/config/WadlGeneratorConfig.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/wadl/config/WadlGeneratorDescription.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/server/wadl/generators/resourcedoc/WadlGeneratorResourceDocSupport.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/BufferedReader.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStream.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStreamReader.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/PrintWriter.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Map$Entry.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Semaphore.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/CommandLine.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/DefaultExecutor.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/ExecuteWatchdog.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/PumpStreamHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/util/Shell.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Thread.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Runnable.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/ext/ExceptionMapper.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/ext/Provider.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/NotFoundException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobID.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/Groups.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/HashSet.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Set.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/ConcurrentHashMap.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hive/common/util/HiveVersionInfo.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceStability$Evolving.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataInput.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataOutput.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/InputSplit.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar(org/apache/curator/framework/CuratorFramework.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/CreateMode.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/KeeperException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs$Ids.class)]]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:testCompile (default-testCompile) on project hive-hcatalog-streaming: Compilation failure: Compilation failure:
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestRecordInspectorImpl.java:[38,41] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/StreamingAssert.java:[150,34] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestBucketIdResolverImpl.java:[43,33] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[57,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[58,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[59,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[60,58] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[245,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[302,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[313,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[324,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[326,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[372,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[501,95] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[504,83] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[506,53] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[507,98] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[521,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[523,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[525,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[533,59] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[541,63] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-hcatalog-streaming
Destroying 1 processes
Destroying process..
Destroyed 1 processes
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12873614 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16056077" author="hiveqa" created="Tue, 20 Jun 2017 16:56:05 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12873702/HIVE-16832.05.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12873702/HIVE-16832.05.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 15 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 304 failed/errored test(s), 10845 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_join] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_mapjoin] (batchId=10)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_partition] (batchId=69)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_project] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_orig_table] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_tmp_table] (batchId=48)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_no_match] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_partitioned] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_whole_partition] (batchId=9)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_acid_dynamic_partition] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_nonacid_from_acid] (batchId=70)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_orig_table] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_update_delete] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=71)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table] (batchId=54)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_partitioned] (batchId=72)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_tmp_table] (batchId=4)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_acid] (batchId=76)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_reader] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_ppd_exception] (batchId=32)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[transform_acid] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=65)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts_special_characters] (batchId=69)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_non_partitioned] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_partitioned] (batchId=49)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_types] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_orig_table] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_tmp_table] (batchId=34)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_two_cols] (batchId=20)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_no_match] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_non_partitioned] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_partitioned] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_acid3] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_join_part_col_char] (batchId=22)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_dynamic] (batchId=165)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_static] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[acid_globallimit] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_tmp_table] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_no_match] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_partitioned] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_whole_partition] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_orig_table] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_update_delete] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_partitioned] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_tmp_table] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part_update] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table_update] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part_update] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table_update] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_non_partitioned] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_partitioned] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_types] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_tmp_table] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_two_cols] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_no_match] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_non_partitioned] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_partitioned] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_acid3] (batchId=148)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[delete_orig_table] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[update_orig_table] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_join_part_col_char] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[acid_overwrite] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=232)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnMR (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnTez (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnMR (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnTez (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnMR (batchId=217)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnTez (batchId=217)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnMR (batchId=217)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnTez (batchId=217)
org.apache.hadoop.hive.ql.TestTxnCommands.testDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testErrors (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testExplicitRollback (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testImplicitRollback (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeCardinalityViolation (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeDeleteUpdate (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD01 (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD02 (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDeleteNoCardCheck (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleInserts (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testReadMyOwnInsert (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testSimpleAcidInsert (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands2.testACIDwithSchemaEvolutionAndCompaction (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testAcidWithSchemaEvolution (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testAlterTable (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testBucketizedInputFormat (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testCompactWithDelete (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testETLSplitStrategyForACID (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testFileSystemUnCaching (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testInitiatorWithMultipleFailedCompactions (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge3 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMergeWithPredicate (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsert (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsertStatement (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNoHistory (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion1 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testSimpleRead (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.updateDeletePartitioned (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.writeBetweenWorkerAndCleaner (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testACIDwithSchemaEvolutionAndCompaction (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAcidWithSchemaEvolution (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAlterTable (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testBucketizedInputFormat (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testCompactWithDelete (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDeleteIn (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testETLSplitStrategyForACID (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testFileSystemUnCaching (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testInitiatorWithMultipleFailedCompactions (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge3 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMergeWithPredicate (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMultiInsert (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMultiInsertStatement (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNoHistory (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion1 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion3 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcNoPPD (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcPPD (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testSimpleRead (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testUpdateMixedCase (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.updateDeletePartitioned (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.writeBetweenWorkerAndCleaner (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testACIDwithSchemaEvolutionAndCompaction (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAcidWithSchemaEvolution (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAlterTable (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testBucketizedInputFormat (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testCompactWithDelete (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDeleteIn (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testETLSplitStrategyForACID (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testFileSystemUnCaching (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testInitiatorWithMultipleFailedCompactions (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge3 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMergeWithPredicate (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsert (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertStatement (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertVectorized (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNoHistory (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion1 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcNoPPD (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcPPD (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testSimpleRead (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testUpdateMixedCase (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.updateDeletePartitioned (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.writeBetweenWorkerAndCleaner (batchId=277)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testEmpty (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBase (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPair (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPairNoMin (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testUpdates (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriterTblProperties (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testCanCreateVectorizedAcidRowBatchReaderOnSplit (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.checkExpectedLocks2 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testCompletedTxnComponents (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testDynamicPartitionInsert (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way01 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way02 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned01 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned02 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned01 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned02 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMetastoreTablesCleanup (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMultiInsert (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking10 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking11 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking3 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking5 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking7 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking8 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking9 (batchId=281)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=216)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=216)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=216)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningInsert (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningInsert (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithInsertsAndDeletes (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithOnlyInserts (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testTableProperties (batchId=214)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=189)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5692/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5692/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5692/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5692/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5692/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5692/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 304 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12873702 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16058842" author="hiveqa" created="Thu, 22 Jun 2017 06:38:07 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12873989/HIVE-16832.06.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12873989/HIVE-16832.06.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 15 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 188 failed/errored test(s), 10839 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_orig_table] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_tmp_table] (batchId=49)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_partitioned] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_whole_partition] (batchId=9)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_update_delete] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_acid] (batchId=76)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=65)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts_special_characters] (batchId=69)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_non_partitioned] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_partitioned] (batchId=49)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_types] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_orig_table] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_tmp_table] (batchId=34)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_two_cols] (batchId=20)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_non_partitioned] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_partitioned] (batchId=59)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_tmp_table] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_partitioned] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_whole_partition] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_update_delete] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part_update] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table_update] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part_update] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table_update] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_non_partitioned] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_partitioned] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_types] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_tmp_table] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_two_cols] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_non_partitioned] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_partitioned] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[delete_orig_table] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[update_orig_table] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=232)
org.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.ql.TestTxnCommands.testDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeDeleteUpdate (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD01 (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD02 (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDeleteNoCardCheck (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands2.testACIDwithSchemaEvolutionAndCompaction (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testCompactWithDelete (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge3 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMergeWithPredicate (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsert (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.updateDeletePartitioned (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.writeBetweenWorkerAndCleaner (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testACIDwithSchemaEvolutionAndCompaction (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testCompactWithDelete (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDeleteIn (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge3 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMergeWithPredicate (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion3 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcNoPPD (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcPPD (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testUpdateMixedCase (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.updateDeletePartitioned (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.writeBetweenWorkerAndCleaner (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testACIDwithSchemaEvolutionAndCompaction (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testCompactWithDelete (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDeleteIn (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge3 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMergeWithPredicate (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertVectorized (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcNoPPD (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcPPD (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testUpdateMixedCase (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.updateDeletePartitioned (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.writeBetweenWorkerAndCleaner (batchId=277)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testEmpty (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBase (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPair (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPairNoMin (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testUpdates (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriterTblProperties (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testCanCreateVectorizedAcidRowBatchReaderOnSplit (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=216)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=216)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=216)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithInsertsAndDeletes (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=214)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=189)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5728/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5728/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5728/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5728/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5728/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5728/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 188 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12873989 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16060379" author="hiveqa" created="Fri, 23 Jun 2017 03:36:45 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12874171/HIVE-16832.08.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12874171/HIVE-16832.08.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 16 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 76 failed/errored test(s), 10858 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=215)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=190)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5737/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5737/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5737/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5737/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5737/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5737/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 76 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12874171 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16060707" author="hiveqa" created="Fri, 23 Jun 2017 10:35:25 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12874192/HIVE-16832.09.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12874192/HIVE-16832.09.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 16 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 51 failed/errored test(s), 10858 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=190)
org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery (batchId=227)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5744/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5744/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5744/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5744/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5744/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5744/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 51 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12874192 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16061629" author="hiveqa" created="Fri, 23 Jun 2017 23:18:52 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12874324/HIVE-16832.11.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12874324/HIVE-16832.11.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 17 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 33 failed/errored test(s), 10857 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=238)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsert (batchId=269)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5757/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5757/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5757/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5757/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5757/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5757/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 33 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12874324 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16061675" author="hiveqa" created="Sat, 24 Jun 2017 00:16:00 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12874324/HIVE-16832.11.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12874324/HIVE-16832.11.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 17 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 31 failed/errored test(s), 10857 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5758/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5758/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5758/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5758/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5758/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5758/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 31 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12874324 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16066380" author="hiveqa" created="Wed, 28 Jun 2017 11:50:59 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12874793/HIVE-16832.14.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12874793/HIVE-16832.14.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 4 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 26 failed/errored test(s), 10862 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[zero_rows_hdfs] (batchId=241)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=263)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=262)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=190)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5804/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5804/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5804/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5804/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5804/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5804/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 26 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12874793 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16067753" author="hiveqa" created="Thu, 29 Jun 2017 05:19:35 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12874999/HIVE-16832.15.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12874999/HIVE-16832.15.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 12 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 17 failed/errored test(s), 10841 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=238)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=98)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5824/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5824/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5824/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5824/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5824/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5824/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 17 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12874999 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16069180" author="hiveqa" created="Thu, 29 Jun 2017 23:21:20 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12875110/HIVE-16832.16.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12875110/HIVE-16832.16.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 12 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 20 failed/errored test(s), 10833 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=141)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=146)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=100)
org.apache.hadoop.hive.llap.security.TestLlapSignerImpl.testSigning (batchId=290)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5835/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5835/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5835/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5835/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5835/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5835/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 20 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12875110 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16075626" author="hiveqa" created="Wed, 5 Jul 2017 23:34:15 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12875809/HIVE-16832.17.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12875809/HIVE-16832.17.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5896/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5896/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5896/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5896/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5896/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5896/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hiveptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-07-05 23:32:57.513
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;MAVEN_OPTS=-Xmx1g &apos;
+ MAVEN_OPTS=&apos;-Xmx1g &apos;
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-5896/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-07-05 23:32:57.516
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at c39b879 HIVE-16893: move replication dump related work in semantic analysis phase to execution phase using a task (Anishek Agarwal, reviewed by Sankar Hariappan, Daniel Dai)
+ git clean -f -d
+ git checkout master
Already on &apos;master&apos;
Your branch is up-to-date with &apos;origin/master&apos;.
+ git reset --hard origin/master
HEAD is now at c39b879 HIVE-16893: move replication dump related work in semantic analysis phase to execution phase using a task (Anishek Agarwal, reviewed by Sankar Hariappan, Daniel Dai)
+ git merge --ff-only origin/master
Already up-to-date.
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-07-05 23:33:02.202
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
patching file hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/worker/BucketIdResolverImpl.java
patching file hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/worker/MutatorCoordinator.java
patching file hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/worker/MutatorImpl.java
patching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/StreamingAssert.java
patching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java
patching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestBucketIdResolverImpl.java
patching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorImpl.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/AcidOutputFormat.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/RecordIdentifier.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRawRecordMerger.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRecordUpdater.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcAcidRowBatchReader.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/UpdateDeleteSemanticAnalyzer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToInteger.java
patching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands.java
patching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2.java
patching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2WithSplitUpdate.java
patching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2WithSplitUpdateAndVectorization.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/TestAcidUtils.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcRawRecordMerger.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcRecordUpdater.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestVectorizedOrcAcidRowBatchReader.java
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hiveptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven
ANTLR Parser Generator  Version 3.5.2
Output file /data/hiveptest/working/apache-github-source-source/metastore/target/generated-sources/antlr3/org/apache/hadoop/hive/metastore/parser/FilterParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g
org/apache/hadoop/hive/metastore/parser/Filter.g
DataNucleus Enhancer (version 4.1.17) for API &quot;JDO&quot;
DataNucleus Enhancer : Classpath
&amp;gt;&amp;gt;  /usr/share/maven/boot/plexus-classworlds-2.x.jar
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDatabase
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MType
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTable
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MConstraint
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MOrder
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStringList
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartition
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MIndex
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRole
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRoleMap
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMasterKey
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MVersionTable
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMetastoreDBProperties
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MResourceUri
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFunction
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationLog
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId
DataNucleus Enhancer completed with success for 31 classes. Timings : input=153 ms, enhance=224 ms, total=377 ms. Consult the log for full details
ANTLR Parser Generator  Version 3.5.2
Output file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveLexer.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveLexer.g
Output file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
Output file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HintParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HintParser.g
org/apache/hadoop/hive/ql/parse/HintParser.g
Generating vector expression code
Generating vector expression test code
[ERROR] COMPILATION ERROR : 
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:[34,36] cannot find symbol
  symbol:   class BucketCodec
  location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcAcidRowBatchReader.java:[41,36] cannot find symbol
  symbol:   class BucketCodec
  location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRecordUpdater.java:[35,36] cannot find symbol
  symbol:   class BucketCodec
  location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToInteger.java:[27,36] cannot find symbol
  symbol:   class BucketCodec
  location: package org.apache.hadoop.hive.ql.io
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:[34,36] cannot find symbol
[ERROR] symbol:   class BucketCodec
[ERROR] location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcAcidRowBatchReader.java:[41,36] cannot find symbol
[ERROR] symbol:   class BucketCodec
[ERROR] location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRecordUpdater.java:[35,36] cannot find symbol
[ERROR] symbol:   class BucketCodec
[ERROR] location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToInteger.java:[27,36] cannot find symbol
[ERROR] symbol:   class BucketCodec
[ERROR] location: package org.apache.hadoop.hive.ql.io
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12875809 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16075863" author="hiveqa" created="Thu, 6 Jul 2017 03:29:30 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12875831/HIVE-16832.18.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12875831/HIVE-16832.18.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 12 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 12 failed/errored test(s), 10847 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5901/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5901/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5901/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5901/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5901/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5901/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 12 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12875831 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16078875" author="hiveqa" created="Sat, 8 Jul 2017 00:51:26 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12876158/HIVE-16832.19.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12876158/HIVE-16832.19.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 11 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 8 failed/errored test(s), 10848 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5917/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5917/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5917/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5917/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5917/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5917/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12876158 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16078972" author="hiveqa" created="Sat, 8 Jul 2017 05:58:35 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12876176/HIVE-16832.20.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12876176/HIVE-16832.20.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 12 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 8 failed/errored test(s), 10848 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5919/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5919/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5919/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5919/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5919/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5919/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12876176 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16079244" author="hiveqa" created="Sat, 8 Jul 2017 17:39:44 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12876248/HIVE-16832.20.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12876248/HIVE-16832.20.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 12 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 10848 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5920/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5920/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5920/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5920/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5920/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5920/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12876248 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16079255" author="ekoifman" created="Sat, 8 Jul 2017 17:56:00 +0000"  >&lt;p&gt;no related failures (for example, &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5916/#showFailuresLink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5916/#showFailuresLink&lt;/a&gt; has all the same ones)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt;, could you review please&lt;/p&gt;</comment>
                            <comment id="16081773" author="gopalv" created="Tue, 11 Jul 2017 07:08:02 +0000"  >&lt;p&gt;LGTM - +1.&lt;/p&gt;

&lt;p&gt;Minor comments - the bits used for bucket and statement ids are too big and misaligned (i.e 3:14:15), gets very hard to debug if looking at hex output (instead of raw binary). &lt;/p&gt;

&lt;p&gt;With 4k buckets &amp;amp; 4k statements, (3:1(reserved):12:4(reserved):12), allows the hex output to be much more easily read, with 3 hex digits there - also possibly those 5 bits can come of some use later. &lt;/p&gt;

&lt;p&gt;This patch is good and we can make the inner loops faster in a later iteration as the bucketproperty min-max is actually computed across the whole stripe/file (i.e if min==max, then no more checks needed).&lt;/p&gt;

&lt;p&gt;Compressed OTID got a bit bigger with this, perhaps it is better to build lists per statement id instead of storing it - that extra int will eat up 1 long worth of space, but the txn push-down from the main split -&amp;gt; delete deltas should ensure we never read too much data into that structure.&lt;/p&gt;</comment>
                            <comment id="16082294" author="ekoifman" created="Tue, 11 Jul 2017 14:36:17 +0000"  >
&lt;p&gt;I agree that Compressed OTID is now bigger but I&apos;m not sure how useful it&apos;s in the first place.&lt;br/&gt;
Suppose you populate a partition via 100 inserts and 1M rows.  So you have 100 OTIDs.&lt;br/&gt;
Now if you run an update/delete with some WHERE clause it will match rows randomly wrt OTIDs on average.&lt;br/&gt;
So if this delete generates 500 events, it seems likely that you get a lot of distinct OTIDs among them.  Perhaps simply relying on the &quot;push down&quot; to delete deltas is enough and we are better off just keeping 3 arrays.&lt;/p&gt;</comment>
                            <comment id="16082885" author="gopalv" created="Tue, 11 Jul 2017 20:16:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;Suppose you populate a partition via 100 inserts and 1M rows. So you have 100 OTIDs.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, this was an optimization for the possibility that you&apos;re doing an &quot;update every row&quot; merge which would otherwise cause a massive memory jump in deletes (&amp;amp; overflow the 2G limit on arrays).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Perhaps simply relying on the &quot;push down&quot; to delete deltas is enough and we are better off just keeping 3 arrays&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, it might be better - I&apos;ve yet to really look into the delete distribution for a regular CDC workload. The push-down into deletes is a big win anyway.&lt;/p&gt;

&lt;p&gt;Not too worried about the extra size here.&lt;/p&gt;</comment>
                            <comment id="16083104" author="ekoifman" created="Tue, 11 Jul 2017 22:31:22 +0000"  >&lt;p&gt;patch 21 addresses Gopal&apos;s comments&lt;/p&gt;</comment>
                            <comment id="16083333" author="hiveqa" created="Wed, 12 Jul 2017 02:36:52 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12876708/HIVE-16832.21.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12876708/HIVE-16832.21.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 12 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 13 failed/errored test(s), 10853 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.ql.TestTxnCommands.testNonAcidToAcidConversion01 (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion02 (batchId=269)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion02 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion02 (batchId=277)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5969/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5969/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5969/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5969/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5969/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5969/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12876708 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16084858" author="hiveqa" created="Wed, 12 Jul 2017 22:45:27 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12876914/HIVE-16832.22.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12876914/HIVE-16832.22.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 12 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 10 failed/errored test(s), 10888 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver[hbase_queries] (batchId=94)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5989/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5989/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5989/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5989/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5989/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5989/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 10 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12876914 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16084878" author="ekoifman" created="Wed, 12 Jul 2017 23:03:50 +0000"  >&lt;p&gt;no related failures (see builds 5985,5984 for same failures)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-16832&quot; title=&quot;duplicate ROW__ID possible in multi insert into transactional table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-16832&quot;&gt;&lt;del&gt;HIVE-16832&lt;/del&gt;&lt;/a&gt;.22.patch committed to master (3.0)&lt;br/&gt;
thanks Gopal for the review&lt;/p&gt;</comment>
                            <comment id="16085317" author="lefty@hortonworks.com" created="Thu, 13 Jul 2017 07:49:54 +0000"  >&lt;p&gt;No-doc note:  This adds &lt;b&gt;hive.test.bucketcodec.version&lt;/b&gt; to HiveConf.java, but it&apos;s for testing only so no user documentation is needed.&lt;/p&gt;</comment>
                            <comment id="16486330" author="vgarg" created="Wed, 23 May 2018 00:00:11 +0000"  >&lt;p&gt;Hive 3.0.0 has been released so closing this jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12979916">HIVE-14035</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13087695">HIVE-17110</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13121156">HIVE-18158</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="13012089">HIVE-14947</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12871718" name="HIVE-16832.01.patch" size="32406" author="ekoifman" created="Tue, 6 Jun 2017 23:17:02 +0000"/>
                            <attachment id="12873581" name="HIVE-16832.03.patch" size="79403" author="ekoifman" created="Tue, 20 Jun 2017 01:45:01 +0000"/>
                            <attachment id="12873614" name="HIVE-16832.04.patch" size="86154" author="ekoifman" created="Tue, 20 Jun 2017 07:03:43 +0000"/>
                            <attachment id="12873702" name="HIVE-16832.05.patch" size="97118" author="ekoifman" created="Tue, 20 Jun 2017 15:46:25 +0000"/>
                            <attachment id="12873989" name="HIVE-16832.06.patch" size="97346" author="ekoifman" created="Thu, 22 Jun 2017 01:53:47 +0000"/>
                            <attachment id="12874171" name="HIVE-16832.08.patch" size="115263" author="ekoifman" created="Fri, 23 Jun 2017 02:19:25 +0000"/>
                            <attachment id="12874192" name="HIVE-16832.09.patch" size="116312" author="ekoifman" created="Fri, 23 Jun 2017 04:35:54 +0000"/>
                            <attachment id="12874314" name="HIVE-16832.10.patch" size="131501" author="ekoifman" created="Fri, 23 Jun 2017 20:48:23 +0000"/>
                            <attachment id="12874324" name="HIVE-16832.11.patch" size="232296" author="ekoifman" created="Fri, 23 Jun 2017 22:20:55 +0000"/>
                            <attachment id="12874793" name="HIVE-16832.14.patch" size="34909" author="ekoifman" created="Wed, 28 Jun 2017 02:02:47 +0000"/>
                            <attachment id="12874999" name="HIVE-16832.15.patch" size="88800" author="ekoifman" created="Thu, 29 Jun 2017 02:25:16 +0000"/>
                            <attachment id="12875110" name="HIVE-16832.16.patch" size="96826" author="ekoifman" created="Thu, 29 Jun 2017 20:58:25 +0000"/>
                            <attachment id="12875809" name="HIVE-16832.17.patch" size="102131" author="ekoifman" created="Wed, 5 Jul 2017 19:52:22 +0000"/>
                            <attachment id="12875831" name="HIVE-16832.18.patch" size="107373" author="ekoifman" created="Wed, 5 Jul 2017 23:44:44 +0000"/>
                            <attachment id="12876158" name="HIVE-16832.19.patch" size="119555" author="ekoifman" created="Fri, 7 Jul 2017 23:28:54 +0000"/>
                            <attachment id="12876248" name="HIVE-16832.20.patch" size="123945" author="ekoifman" created="Sat, 8 Jul 2017 16:27:04 +0000"/>
                            <attachment id="12876176" name="HIVE-16832.20.patch" size="123945" author="ekoifman" created="Sat, 8 Jul 2017 04:47:46 +0000"/>
                            <attachment id="12876708" name="HIVE-16832.21.patch" size="124412" author="ekoifman" created="Tue, 11 Jul 2017 22:31:12 +0000"/>
                            <attachment id="12876914" name="HIVE-16832.22.patch" size="129972" author="ekoifman" created="Wed, 12 Jul 2017 18:24:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>19.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 26 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3fy0v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12340268">3.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>