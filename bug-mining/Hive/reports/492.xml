<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 17:57:07 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-1633] CombineHiveInputFormat fails with &quot;cannot find dir for emptyFile&quot;</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1633</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12473954">HIVE-1633</key>
            <summary>CombineHiveInputFormat fails with &quot;cannot find dir for emptyFile&quot;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sreekanth">Sreekanth Ramakrishnan</assignee>
                                    <reporter username="amareshwari">Amareshwari Sriramadasu</reporter>
                        <labels>
                    </labels>
                <created>Mon, 13 Sep 2010 06:17:37 +0000</created>
                <updated>Tue, 19 Jan 2016 21:47:38 +0000</updated>
                            <resolved>Wed, 20 Oct 2010 19:33:39 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Clients</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="12908638" author="amareshwari" created="Mon, 13 Sep 2010 06:18:10 +0000"  >&lt;p&gt;Here is full exception trace:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.io.IOException: cannot find dir =
hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile
in partToPartitionInfo:
[xxx......., xxx......., xxx......., ...............
 hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1,
hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/2]
        at
org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getPartitionDescFromPathRecursively(HiveFileFormatUtils.java:277)
        at
org.apache.hadoop.hive.ql.io.CombineHiveInputFormat$CombineHiveInputSplit.&amp;lt;init&amp;gt;(CombineHiveInputFormat.java:100)
        at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:312)
        at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:929)
        at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:921)
        at org.apache.hadoop.mapred.JobClient.access$500(JobClient.java:170)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:838)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:792)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1021)
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:792)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:766)
        at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:610)
        at org.apache.hadoop.hive.ql.exec.MapRedTask.execute(MapRedTask.java:120)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:108)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:55)
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:900)
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:770)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:647)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:140)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:199)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:353)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:156)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12908716" author="he yongqiang" created="Mon, 13 Sep 2010 10:59:50 +0000"  >&lt;p&gt;Amareshwari, more details about your example? From your example, i can not reproduce the problem.&lt;/p&gt;</comment>
                            <comment id="12909666" author="amareshwari" created="Wed, 15 Sep 2010 09:17:49 +0000"  >&lt;p&gt;Sorry for the delay. &lt;br/&gt;
The table has three partitions and 100 columns. It is stored as RCFile with compressed data.&lt;br/&gt;
The query we ran was &quot;select count(&amp;#42;) from &amp;lt;table&amp;gt;&quot; with CombineHiveInputFormat as the input format. We were trying to test &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-1597&quot; title=&quot;combinefileinputformat does not work with non-splittable files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-1597&quot;&gt;&lt;del&gt;MAPREDUCE-1597&lt;/del&gt;&lt;/a&gt; by setting hive.hadoop.supports.splittable.combineinputformat to true. Queries ran fine with Text files.&lt;/p&gt;</comment>
                            <comment id="12909711" author="he yongqiang" created="Wed, 15 Sep 2010 12:36:25 +0000"  >&lt;p&gt;@Amareshwari&lt;/p&gt;

&lt;p&gt;in your example:&lt;br/&gt;
hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile&lt;br/&gt;
in partToPartitionInfo:&lt;br/&gt;
[xxx......., xxx......., xxx......., ...............&lt;br/&gt;
 hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1,&lt;br/&gt;
hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/2]&lt;/p&gt;

&lt;p&gt;If i put these into TestHiveFormatUtils, it can return correct value. Maybe there is some mismatch about &apos;xxx&apos;?&lt;/p&gt;</comment>
                            <comment id="12910001" author="amareshwari" created="Thu, 16 Sep 2010 03:51:59 +0000"  >&lt;p&gt;I replaced the actual file names of xxx, because actual file/host names are internal to our organization. But the problem is CombineHiveInputFormat is looking for PartitionDesc in &quot;hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile&quot; . This dir is not part of the table input data. I think this dir is getting added by FileSinkOperator. &lt;/p&gt;</comment>
                            <comment id="12910002" author="amareshwari" created="Thu, 16 Sep 2010 03:56:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;I replaced the actual file names of xxx.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I meant &quot; I replaced the actual file/host names with xxx&quot;&lt;/p&gt;</comment>
                            <comment id="12910255" author="he yongqiang" created="Thu, 16 Sep 2010 18:32:14 +0000"  >&lt;p&gt;Can you search &lt;br/&gt;
hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1 (replacing xxx with actual file/host names)?&lt;/p&gt;

&lt;p&gt;It should appear one time in partToPartitionInfo and another one time in &quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile&quot;.&lt;/p&gt;</comment>
                            <comment id="12910430" author="amareshwari" created="Fri, 17 Sep 2010 03:34:57 +0000"  >&lt;p&gt;It appears only once as &quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/&quot;. there is no &quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile&quot;&lt;/p&gt;</comment>
                            <comment id="12910431" author="he yongqiang" created="Fri, 17 Sep 2010 03:37:52 +0000"  >&lt;p&gt;so &apos;xxx&apos; part is not the same in &quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/&quot; and &quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile&quot;&lt;br/&gt;
?&lt;/p&gt;</comment>
                            <comment id="12910435" author="amareshwari" created="Fri, 17 Sep 2010 03:55:05 +0000"  >&lt;p&gt;Sorry If I misunderstood your comment. I looked for hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/ in partToPartitionInfo shown in the exception. Only hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/ appears. hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile does not appear in partToPartitionInfo. &lt;/p&gt;</comment>
                            <comment id="12912795" author="he yongqiang" created="Tue, 21 Sep 2010 01:02:14 +0000"  >&lt;p&gt;For a given path, CombineHiveInputFormat does recursive lookup in partToPartitionInfo. If no match found, will lookup for the parent dir (&quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1&quot;) in partToPartitionInfo. In your case, it seems the parent dir exist in partToPartitionInfo. &lt;/p&gt;</comment>
                            <comment id="12913230" author="he yongqiang" created="Tue, 21 Sep 2010 20:29:21 +0000"  >&lt;p&gt;Amareshwari, by adding a testcase in TestHiveFileFormatUtils, you will be able to find out the underlying problem, and then can you post a patch for it?&lt;/p&gt;</comment>
                            <comment id="12918490" author="sreekanth" created="Wed, 6 Oct 2010 12:17:10 +0000"  >&lt;p&gt;I was taking a look at reproducing the issue. The core reason why the exception is present is due to following.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Input format is passed a set of input path.&lt;/li&gt;
	&lt;li&gt;These set of path contains two kind of files, table data files and scratch/tmp files which are created by hive in hdfs.&lt;/li&gt;
	&lt;li&gt;CombineHiveInputFormat tries to compute splits in these temp/scratch file, which causes the  getPartitionDescFromPathRecursively to fail. Causing the query to fail.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I hope this helps, I am still looking at the code, and trying to figure out where the actual addition to input paths are done. So basically I can back track from there. Any help on this would be great.&lt;/p&gt;
</comment>
                            <comment id="12920838" author="sreekanth" created="Thu, 14 Oct 2010 02:58:02 +0000"  >&lt;p&gt;This problem is caused in following scenario:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;NameNode&lt;/tt&gt; is running on default port &lt;tt&gt;8020&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;The data which is to be processed has atleast one empty partition.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The logic how empty partition is dealt is by creating an &lt;tt&gt;emptyFile&lt;/tt&gt; in the scratch directory.&lt;/p&gt;

&lt;p&gt;So when &lt;tt&gt;NameNode&lt;/tt&gt; runs on default port, the URI which &lt;tt&gt;NameNode&lt;/tt&gt; passes on does not contain the port information in authority part. Whereas typically the configuration for hive scratch directory contains the port information. This causes this issue.&lt;/p&gt;</comment>
                            <comment id="12921967" author="sreekanth" created="Mon, 18 Oct 2010 05:07:55 +0000"  >&lt;p&gt;Attaching the patch which fixes this issue. It just makes the temporary empty file to qualified. Not sure of how to add a unit test case for the same.&lt;/p&gt;
</comment>
                            <comment id="12922419" author="amareshwari" created="Tue, 19 Oct 2010 03:55:25 +0000"  >&lt;p&gt;Making it Patch available.&lt;/p&gt;</comment>
                            <comment id="12922644" author="namit" created="Tue, 19 Oct 2010 18:03:48 +0000"  >&lt;p&gt;Yongqiang, can you take a look ?&lt;/p&gt;</comment>
                            <comment id="12922650" author="he yongqiang" created="Tue, 19 Oct 2010 18:10:18 +0000"  >&lt;p&gt;+1 &lt;/p&gt;</comment>
                            <comment id="12923120" author="he yongqiang" created="Wed, 20 Oct 2010 19:33:39 +0000"  >&lt;p&gt;I just committed! Thanks Sreekanth Ramakrishnan!&lt;/p&gt;</comment>
                            <comment id="13598983" author="shuang" created="Mon, 11 Mar 2013 16:59:16 +0000"  >&lt;p&gt;This bug seems to also show up in hive local mode, the empty temporary file path is not qualified with &quot;file:/&quot;.&lt;/p&gt;

&lt;p&gt;2013-03-11 09:34:30,767 INFO  io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(363)) - CombineHiveInputSplit creating pool for &lt;a href=&quot;file:/var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:/var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1&lt;/a&gt;; using filter path &lt;a href=&quot;file:/var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:/var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1&lt;/a&gt;&lt;br/&gt;
2013-03-11 09:34:30,772 INFO  mapred.FileInputFormat (FileInputFormat.java:listStatus(196)) - Total input paths to process : 1&lt;br/&gt;
2013-03-11 09:34:30,778 INFO  mapred.JobClient (JobClient.java:run(919)) - Cleaning up the staging area &lt;a href=&quot;file:/data/hadoop/cache/analytics-mr.sv2/shuang/mapred/staging/shuang-1827099888/.staging/job_local_0001&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:/data/hadoop/cache/analytics-mr.sv2/shuang/mapred/staging/shuang-1827099888/.staging/job_local_0001&lt;/a&gt;&lt;br/&gt;
2013-03-11 09:34:30,778 ERROR security.UserGroupInformation (UserGroupInformation.java:doAs(1180)) - PriviledgedActionException as:shuang (auth:SIMPLE) cause:java.io.FileNotFoundException: File does not exist: /var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1/emptyFile&lt;br/&gt;
2013-03-11 09:34:30,779 ERROR exec.ExecDriver (SessionState.java:printError(365)) - Job Submission failed with exception &apos;java.io.FileNotFoundException(File does not exist: /var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1/emptyFile)&apos;&lt;br/&gt;
java.io.FileNotFoundException: File does not exist: /var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1/emptyFile&lt;br/&gt;
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:562)&lt;br/&gt;
        at org.apache.hadoop.mapred.lib.CombineFileInputFormat$OneFileInfo.&amp;lt;init&amp;gt;(CombineFileInputFormat.java:462)&lt;br/&gt;
        at org.apache.hadoop.mapred.lib.CombineFileInputFormat.getMoreSplits(CombineFileInputFormat.java:256)&lt;br/&gt;
        at org.apache.hadoop.mapred.lib.CombineFileInputFormat.getSplits(CombineFileInputFormat.java:212)&lt;br/&gt;
        at org.apache.hadoop.hive.shims.Hadoop20SShims$CombineFileInputFormatShim.getSplits(Hadoop20SShims.java:347)&lt;br/&gt;
        at org.apache.hadoop.hive.shims.Hadoop20SShims$CombineFileInputFormatShim.getSplits(Hadoop20SShims.java:313)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:377)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:977)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:969)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.access$500(JobClient.java:170)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:880)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:833)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.Subject.doAs(Subject.java:396)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:833)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:807)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:671)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.ExecDriver.main(ExecDriver.java:1092)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.util.RunJar.main(RunJar.java:197)&lt;/p&gt;</comment>
                            <comment id="15107521" author="ergin.demirel" created="Tue, 19 Jan 2016 21:47:38 +0000"  >&lt;p&gt;We are still getting error message when trying to load empty table/file running on local mode. &lt;br/&gt;
Tried adding &quot;file://&quot; in front of the path though it didn&apos;t help. Can someone please clarify the solution here? &lt;/p&gt;

&lt;p&gt;Hive Version: 0.10.0+121-1.cdh4.3.0.p0.16~precise-cdh4.3.0&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.io.FileNotFoundException: File does not exist: /tmp/hdfs/hive_2016-01-19_21-40-07_727_4067638808884572526/-mr-10000/1/emptyFile
    at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:807)
    at org.apache.hadoop.mapred.lib.CombineFileInputFormat$OneFileInfo.&amp;lt;init&amp;gt;(CombineFileInputFormat.java:462)
    at org.apache.hadoop.mapred.lib.CombineFileInputFormat.getMoreSplits(CombineFileInputFormat.java:256)
    at org.apache.hadoop.mapred.lib.CombineFileInputFormat.getSplits(CombineFileInputFormat.java:212)
    at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getSplits(HadoopShimsSecure.java:411)
    at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getSplits(HadoopShimsSecure.java:377)
    at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:387)
    at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:1091)
    at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:1083)
    at org.apache.hadoop.mapred.JobClient.access$600(JobClient.java:174)
    at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:993)
    at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:946)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:396)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)
    at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:946)
    at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:920)
    at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:448)
    at org.apache.hadoop.hive.ql.exec.ExecDriver.main(ExecDriver.java:690)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.util.RunJar.main(RunJar.java:208)
Job Submission failed with exception &lt;span class=&quot;code-quote&quot;&gt;&apos;java.io.FileNotFoundException(File does not exist: /tmp/hdfs/hive_2016-01-19_21-40-07_727_4067638808884572526/-mr-10000/1/emptyFile)&apos;&lt;/span&gt;
Execution failed with exit status: 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12658525">HIVE-4881</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12478376">HIVE-1753</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12457415" name="HIVE-1633.patch" size="829" author="sreekanth" created="Mon, 18 Oct 2010 05:07:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72803</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 44 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg3r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123259</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>