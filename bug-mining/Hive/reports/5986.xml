<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:58:27 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-18090] acid heartbeat fails when metastore is connected via hadoop credential</title>
                <link>https://issues.apache.org/jira/browse/HIVE-18090</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;steps to recreate the issue. assuming two users &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;test&lt;/li&gt;
	&lt;li&gt;another&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;create two jceks files for each user and place them on hdfs with access to that file only allowed to the user. hdfs locations with permissions &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-rwx------   1 another another        492 2017-11-16 13:06 /user/another/another.jceks
-rwx------   1 test test        489 2017-11-16 13:05 /user/test/test.jceks
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;password used to create &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/user/another/another.jceks &amp;#8211; another&lt;/li&gt;
	&lt;li&gt;/user/test/test.jceks &amp;#8211; test&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;on core-site.xml &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hadoop.proxyuser.[superuser].hosts&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;*&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hadoop.proxyuser.[superuser].groups&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;*&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and restart hdfs.&lt;br/&gt;
enable ACID on HS2 (change the required properties).additional changes on  hiveserver2 configs &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
* hive.metastore.warehouse.dir=file:&lt;span class=&quot;code-comment&quot;&gt;///tmp/hive/test-warehouse
&lt;/span&gt;* hive.server2.enable.doAs=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
* remove javax.jdo.option.ConnectionPassword property from hive-site.xml
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;start hiveserver2&lt;/p&gt;

&lt;p&gt;connect to the server using beeline using any user:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
create table a (i &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, b string);
insert into a values (0 , &lt;span class=&quot;code-quote&quot;&gt;&apos;0&apos;&lt;/span&gt;), (1 , &lt;span class=&quot;code-quote&quot;&gt;&apos;1&apos;&lt;/span&gt;), (2 , &lt;span class=&quot;code-quote&quot;&gt;&apos;2&apos;&lt;/span&gt;), (3 , &lt;span class=&quot;code-quote&quot;&gt;&apos;3&apos;&lt;/span&gt;), (4 , &lt;span class=&quot;code-quote&quot;&gt;&apos;4&apos;&lt;/span&gt;), (5 , &lt;span class=&quot;code-quote&quot;&gt;&apos;5&apos;&lt;/span&gt;), (6 , &lt;span class=&quot;code-quote&quot;&gt;&apos;6&apos;&lt;/span&gt;), (7 , &lt;span class=&quot;code-quote&quot;&gt;&apos;7&apos;&lt;/span&gt;), (8 , &lt;span class=&quot;code-quote&quot;&gt;&apos;8&apos;&lt;/span&gt;), (9 , &lt;span class=&quot;code-quote&quot;&gt;&apos;9&apos;&lt;/span&gt;), (10 , &lt;span class=&quot;code-quote&quot;&gt;&apos;10&apos;&lt;/span&gt;), (11 , &lt;span class=&quot;code-quote&quot;&gt;&apos;11&apos;&lt;/span&gt;), (12 , &lt;span class=&quot;code-quote&quot;&gt;&apos;12&apos;&lt;/span&gt;), (13 , &lt;span class=&quot;code-quote&quot;&gt;&apos;13&apos;&lt;/span&gt;), (14 , &lt;span class=&quot;code-quote&quot;&gt;&apos;14&apos;&lt;/span&gt;), (15 , &lt;span class=&quot;code-quote&quot;&gt;&apos;15&apos;&lt;/span&gt;), (16 , &lt;span class=&quot;code-quote&quot;&gt;&apos;16&apos;&lt;/span&gt;), (17 , &lt;span class=&quot;code-quote&quot;&gt;&apos;17&apos;&lt;/span&gt;), (18 , &lt;span class=&quot;code-quote&quot;&gt;&apos;18&apos;&lt;/span&gt;), (19 , &lt;span class=&quot;code-quote&quot;&gt;&apos;19&apos;&lt;/span&gt;), (20 , &lt;span class=&quot;code-quote&quot;&gt;&apos;20&apos;&lt;/span&gt;), (21 , &lt;span class=&quot;code-quote&quot;&gt;&apos;21&apos;&lt;/span&gt;), (22 , &lt;span class=&quot;code-quote&quot;&gt;&apos;22&apos;&lt;/span&gt;), (23 , &lt;span class=&quot;code-quote&quot;&gt;&apos;23&apos;&lt;/span&gt;), (24 , &lt;span class=&quot;code-quote&quot;&gt;&apos;24&apos;&lt;/span&gt;), (25 , &lt;span class=&quot;code-quote&quot;&gt;&apos;25&apos;&lt;/span&gt;), (26 , &lt;span class=&quot;code-quote&quot;&gt;&apos;26&apos;&lt;/span&gt;), (27 , &lt;span class=&quot;code-quote&quot;&gt;&apos;27&apos;&lt;/span&gt;), (28 , &lt;span class=&quot;code-quote&quot;&gt;&apos;28&apos;&lt;/span&gt;), (29 , &lt;span class=&quot;code-quote&quot;&gt;&apos;29&apos;&lt;/span&gt;), (30 , &lt;span class=&quot;code-quote&quot;&gt;&apos;30&apos;&lt;/span&gt;), (31 , &lt;span class=&quot;code-quote&quot;&gt;&apos;31&apos;&lt;/span&gt;), (32 , &lt;span class=&quot;code-quote&quot;&gt;&apos;32&apos;&lt;/span&gt;), (33 , &lt;span class=&quot;code-quote&quot;&gt;&apos;33&apos;&lt;/span&gt;), (34 , &lt;span class=&quot;code-quote&quot;&gt;&apos;34&apos;&lt;/span&gt;), (35 , &lt;span class=&quot;code-quote&quot;&gt;&apos;35&apos;&lt;/span&gt;), (36 , &lt;span class=&quot;code-quote&quot;&gt;&apos;36&apos;&lt;/span&gt;), (37 , &lt;span class=&quot;code-quote&quot;&gt;&apos;37&apos;&lt;/span&gt;), (38 , &lt;span class=&quot;code-quote&quot;&gt;&apos;38&apos;&lt;/span&gt;), (39 , &lt;span class=&quot;code-quote&quot;&gt;&apos;39&apos;&lt;/span&gt;), (40 , &lt;span class=&quot;code-quote&quot;&gt;&apos;40&apos;&lt;/span&gt;), (41 , &lt;span class=&quot;code-quote&quot;&gt;&apos;41&apos;&lt;/span&gt;), (42 , &lt;span class=&quot;code-quote&quot;&gt;&apos;42&apos;&lt;/span&gt;), (43 , &lt;span class=&quot;code-quote&quot;&gt;&apos;43&apos;&lt;/span&gt;), (44 , &lt;span class=&quot;code-quote&quot;&gt;&apos;44&apos;&lt;/span&gt;), (45 , &lt;span class=&quot;code-quote&quot;&gt;&apos;45&apos;&lt;/span&gt;), (46 , &lt;span class=&quot;code-quote&quot;&gt;&apos;46&apos;&lt;/span&gt;), (47 , &lt;span class=&quot;code-quote&quot;&gt;&apos;47&apos;&lt;/span&gt;), (48 , &lt;span class=&quot;code-quote&quot;&gt;&apos;48&apos;&lt;/span&gt;), (49 , &lt;span class=&quot;code-quote&quot;&gt;&apos;49&apos;&lt;/span&gt;), (50 , &lt;span class=&quot;code-quote&quot;&gt;&apos;50&apos;&lt;/span&gt;), (51 , &lt;span class=&quot;code-quote&quot;&gt;&apos;51&apos;&lt;/span&gt;), (52 , &lt;span class=&quot;code-quote&quot;&gt;&apos;52&apos;&lt;/span&gt;), (53 , &lt;span class=&quot;code-quote&quot;&gt;&apos;53&apos;&lt;/span&gt;), (54 , &lt;span class=&quot;code-quote&quot;&gt;&apos;54&apos;&lt;/span&gt;), (55 , &lt;span class=&quot;code-quote&quot;&gt;&apos;55&apos;&lt;/span&gt;), (56 , &lt;span class=&quot;code-quote&quot;&gt;&apos;56&apos;&lt;/span&gt;), (57 , &lt;span class=&quot;code-quote&quot;&gt;&apos;57&apos;&lt;/span&gt;), (58 , &lt;span class=&quot;code-quote&quot;&gt;&apos;58&apos;&lt;/span&gt;), (59 , &lt;span class=&quot;code-quote&quot;&gt;&apos;59&apos;&lt;/span&gt;), (60 , &lt;span class=&quot;code-quote&quot;&gt;&apos;60&apos;&lt;/span&gt;), (61 , &lt;span class=&quot;code-quote&quot;&gt;&apos;61&apos;&lt;/span&gt;), (62 , &lt;span class=&quot;code-quote&quot;&gt;&apos;62&apos;&lt;/span&gt;), (63 , &lt;span class=&quot;code-quote&quot;&gt;&apos;63&apos;&lt;/span&gt;), (64 , &lt;span class=&quot;code-quote&quot;&gt;&apos;64&apos;&lt;/span&gt;), (65 , &lt;span class=&quot;code-quote&quot;&gt;&apos;65&apos;&lt;/span&gt;), (66 , &lt;span class=&quot;code-quote&quot;&gt;&apos;66&apos;&lt;/span&gt;), (67 , &lt;span class=&quot;code-quote&quot;&gt;&apos;67&apos;&lt;/span&gt;), (68 , &lt;span class=&quot;code-quote&quot;&gt;&apos;68&apos;&lt;/span&gt;), (69 , &lt;span class=&quot;code-quote&quot;&gt;&apos;69&apos;&lt;/span&gt;), (70 , &lt;span class=&quot;code-quote&quot;&gt;&apos;70&apos;&lt;/span&gt;), (71 , &lt;span class=&quot;code-quote&quot;&gt;&apos;71&apos;&lt;/span&gt;), (72 , &lt;span class=&quot;code-quote&quot;&gt;&apos;72&apos;&lt;/span&gt;), (73 , &lt;span class=&quot;code-quote&quot;&gt;&apos;73&apos;&lt;/span&gt;), (74 , &lt;span class=&quot;code-quote&quot;&gt;&apos;74&apos;&lt;/span&gt;), (75 , &lt;span class=&quot;code-quote&quot;&gt;&apos;75&apos;&lt;/span&gt;), (76 , &lt;span class=&quot;code-quote&quot;&gt;&apos;76&apos;&lt;/span&gt;), (77 , &lt;span class=&quot;code-quote&quot;&gt;&apos;77&apos;&lt;/span&gt;), (78 , &lt;span class=&quot;code-quote&quot;&gt;&apos;78&apos;&lt;/span&gt;), (79 , &lt;span class=&quot;code-quote&quot;&gt;&apos;79&apos;&lt;/span&gt;), (80 , &lt;span class=&quot;code-quote&quot;&gt;&apos;80&apos;&lt;/span&gt;), (81 , &lt;span class=&quot;code-quote&quot;&gt;&apos;81&apos;&lt;/span&gt;), (82 , &lt;span class=&quot;code-quote&quot;&gt;&apos;82&apos;&lt;/span&gt;), (83 , &lt;span class=&quot;code-quote&quot;&gt;&apos;83&apos;&lt;/span&gt;), (84 , &lt;span class=&quot;code-quote&quot;&gt;&apos;84&apos;&lt;/span&gt;), (85 , &lt;span class=&quot;code-quote&quot;&gt;&apos;85&apos;&lt;/span&gt;), (86 , &lt;span class=&quot;code-quote&quot;&gt;&apos;86&apos;&lt;/span&gt;), (87 , &lt;span class=&quot;code-quote&quot;&gt;&apos;87&apos;&lt;/span&gt;), (88 , &lt;span class=&quot;code-quote&quot;&gt;&apos;88&apos;&lt;/span&gt;), (89 , &lt;span class=&quot;code-quote&quot;&gt;&apos;89&apos;&lt;/span&gt;), (90 , &lt;span class=&quot;code-quote&quot;&gt;&apos;90&apos;&lt;/span&gt;), (91 , &lt;span class=&quot;code-quote&quot;&gt;&apos;91&apos;&lt;/span&gt;), (92 , &lt;span class=&quot;code-quote&quot;&gt;&apos;92&apos;&lt;/span&gt;), (93 , &lt;span class=&quot;code-quote&quot;&gt;&apos;93&apos;&lt;/span&gt;), (94 , &lt;span class=&quot;code-quote&quot;&gt;&apos;94&apos;&lt;/span&gt;), (95 , &lt;span class=&quot;code-quote&quot;&gt;&apos;95&apos;&lt;/span&gt;), (96 , &lt;span class=&quot;code-quote&quot;&gt;&apos;96&apos;&lt;/span&gt;), (97 , &lt;span class=&quot;code-quote&quot;&gt;&apos;97&apos;&lt;/span&gt;), (98 , &lt;span class=&quot;code-quote&quot;&gt;&apos;98&apos;&lt;/span&gt;), (99 , &lt;span class=&quot;code-quote&quot;&gt;&apos;99&apos;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;exit beeline and connect with user another &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
./beeline -u &lt;span class=&quot;code-quote&quot;&gt;&quot;jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//localhost:10000/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;?hive.strict.checks.cartesian.product=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;hive.txn.timeout=4s;hive.txn.heartbeat.threadpool.size=1;hadoop.security.credential.provider.path=jceks://hdfs/user/another/another.jceks;ssl.server.keystore.keypassword=another&quot;&lt;/span&gt; -n another
&lt;/span&gt;
create table another_a_acid (i &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, b string) clustered by (i) into 8 buckets stored as orc tblproperties(&lt;span class=&quot;code-quote&quot;&gt;&apos;transactional&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&apos;&lt;/span&gt;);

insert overwrite table another_a_acid select a2.i, a3.b from a a1 join a a2 join a a3 on 1=1;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;open another beeline session with user test:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
./beeline -u &lt;span class=&quot;code-quote&quot;&gt;&quot;jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//localhost:10000/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;?hive.strict.checks.cartesian.product=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;hive.txn.timeout=4s;hive.txn.heartbeat.threadpool.size=1;hadoop.security.credential.provider.path=jceks://hdfs/user/test/test.jceks;ssl.server.keystore.keypassword=test&quot;&lt;/span&gt; -n test
&lt;/span&gt;
create table a_acid (i &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, b string) clustered by (i) into 8 buckets stored as orc tblproperties(&lt;span class=&quot;code-quote&quot;&gt;&apos;transactional&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&apos;&lt;/span&gt;);

insert overwrite table a_acid select a2.i, a3.b from a a1 join a a2 join a a3 on 1=1;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fails with exception &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2017-11-17T12:15:52,664 DEBUG [Heartbeater-1] retry.RetryInvocationHandler: Exception &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; invoking ClientNamenodeProtocolTranslatorPB.getFileInfo over &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;. Not retrying because &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; once and fail.
org.apache.hadoop.ipc.RemoteException: Permission denied: user=test, access=EXECUTE, inode=&lt;span class=&quot;code-quote&quot;&gt;&quot;/user/another/another.jceks&quot;&lt;/span&gt;:another:another:drwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:259)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:205)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1955)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:109)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:4111)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1137)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:866)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1554) ~[hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.Client.call(Client.java:1498) ~[hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.Client.call(Client.java:1398) ~[hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233) ~[hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at com.sun.proxy.$Proxy30.getFileInfo(Unknown Source) ~[?:?]
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:818) ~[hadoop-hdfs-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_112]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_112]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:291) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:203) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:185) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at com.sun.proxy.$Proxy31.getFileInfo(Unknown Source) [?:?]
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:2165) [hadoop-hdfs-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hdfs.DistributedFileSystem$26.doCall(DistributedFileSystem.java:1442) [hadoop-hdfs-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hdfs.DistributedFileSystem$26.doCall(DistributedFileSystem.java:1438) [hadoop-hdfs-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1438) [hadoop-hdfs-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1447) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.security.alias.JavaKeyStoreProvider.keystoreExists(JavaKeyStoreProvider.java:65) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.&amp;lt;init&amp;gt;(AbstractJavaKeyStoreProvider.java:105) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.security.alias.JavaKeyStoreProvider.&amp;lt;init&amp;gt;(JavaKeyStoreProvider.java:49) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.security.alias.JavaKeyStoreProvider.&amp;lt;init&amp;gt;(JavaKeyStoreProvider.java:41) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.security.alias.JavaKeyStoreProvider$Factory.createProvider(JavaKeyStoreProvider.java:100) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.security.alias.CredentialProviderFactory.getProviders(CredentialProviderFactory.java:61) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.conf.Configuration.getPasswordFromCredentialProviders(Configuration.java:1992) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.conf.Configuration.getPassword(Configuration.java:1972) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.metastore.conf.MetastoreConf.getPassword(MetastoreConf.java:1334) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.ObjectStore.getDataSourceProps(ObjectStore.java:571) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:312) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:76) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:136) [hadoop-common-2.7.3.2.6.1.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.metastore.RawStoreProxy.&amp;lt;init&amp;gt;(RawStoreProxy.java:59) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:677) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:643) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:637) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:544) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at sun.reflect.GeneratedMethodAccessor58.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_112]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_112]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&amp;lt;init&amp;gt;(RetryingHMSHandler.java:80) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:7516) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&amp;lt;init&amp;gt;(HiveMetaStoreClient.java:169) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&amp;lt;init&amp;gt;(SessionHiveMetaStoreClient.java:77) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at sun.reflect.GeneratedConstructorAccessor148.newInstance(Unknown Source) [?:1.8.0_112]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) [?:1.8.0_112]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) [?:1.8.0_112]
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1445) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&amp;lt;init&amp;gt;(RetryingMetaStoreClient.java:83) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4051) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4103) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4083) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.lockmgr.DbTxnManager.getMS(DbTxnManager.java:158) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.lockmgr.DbTxnManager.heartbeat(DbTxnManager.java:610) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.lockmgr.DbTxnManager$Heartbeater.run(DbTxnManager.java:878) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_112]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_112]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_112]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745) [?:1.8.0_112]
2017-11-17T12:15:52,670 ERROR [Heartbeater-1] metastore.RetryingHMSHandler: java.lang.RuntimeException: Error getting metastore password: Configuration problem with provider path.
	at org.apache.hadoop.hive.metastore.ObjectStore.getDataSourceProps(ObjectStore.java:577)
	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:312)
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:76)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:136)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.&amp;lt;init&amp;gt;(RawStoreProxy.java:59)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:677)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:643)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:637)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:544)
	at sun.reflect.GeneratedMethodAccessor58.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&amp;lt;init&amp;gt;(RetryingHMSHandler.java:80)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:7516)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&amp;lt;init&amp;gt;(HiveMetaStoreClient.java:169)
	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&amp;lt;init&amp;gt;(SessionHiveMetaStoreClient.java:77)
	at sun.reflect.GeneratedConstructorAccessor148.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1445)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&amp;lt;init&amp;gt;(RetryingMetaStoreClient.java:83)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:4051)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4103)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:4083)
	at org.apache.hadoop.hive.ql.lockmgr.DbTxnManager.getMS(DbTxnManager.java:158)
	at org.apache.hadoop.hive.ql.lockmgr.DbTxnManager.heartbeat(DbTxnManager.java:610)
	at org.apache.hadoop.hive.ql.lockmgr.DbTxnManager$Heartbeater.run(DbTxnManager.java:878)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.io.IOException: Configuration problem with provider path.
	at org.apache.hadoop.conf.Configuration.getPasswordFromCredentialProviders(Configuration.java:2012)
	at org.apache.hadoop.conf.Configuration.getPassword(Configuration.java:1972)
	at org.apache.hadoop.hive.metastore.conf.MetastoreConf.getPassword(MetastoreConf.java:1334)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDataSourceProps(ObjectStore.java:571)
	... 39 more
Caused by: org.apache.hadoop.security.AccessControlException: Permission denied: user=test, access=EXECUTE, inode=&lt;span class=&quot;code-quote&quot;&gt;&quot;/user/another/another.jceks&quot;&lt;/span&gt;:another:another:drwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:259)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:205)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1955)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:109)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:4111)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1137)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:866)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:2167)
	at org.apache.hadoop.hdfs.DistributedFileSystem$26.doCall(DistributedFileSystem.java:1442)
	at org.apache.hadoop.hdfs.DistributedFileSystem$26.doCall(DistributedFileSystem.java:1438)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1438)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1447)
	at org.apache.hadoop.security.alias.JavaKeyStoreProvider.keystoreExists(JavaKeyStoreProvider.java:65)
	at org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.&amp;lt;init&amp;gt;(AbstractJavaKeyStoreProvider.java:105)
	at org.apache.hadoop.security.alias.JavaKeyStoreProvider.&amp;lt;init&amp;gt;(JavaKeyStoreProvider.java:49)
	at org.apache.hadoop.security.alias.JavaKeyStoreProvider.&amp;lt;init&amp;gt;(JavaKeyStoreProvider.java:41)
	at org.apache.hadoop.security.alias.JavaKeyStoreProvider$Factory.createProvider(JavaKeyStoreProvider.java:100)
	at org.apache.hadoop.security.alias.CredentialProviderFactory.getProviders(CredentialProviderFactory.java:61)
	at org.apache.hadoop.conf.Configuration.getPasswordFromCredentialProviders(Configuration.java:1992)
	... 42 more
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=test, access=EXECUTE, inode=&lt;span class=&quot;code-quote&quot;&gt;&quot;/user/another/another.jceks&quot;&lt;/span&gt;:another:another:drwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:259)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:205)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1955)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:109)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:4111)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1137)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:866)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1498)
	at org.apache.hadoop.ipc.Client.call(Client.java:1398)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at com.sun.proxy.$Proxy30.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:818)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:291)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:203)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:185)
	at com.sun.proxy.$Proxy31.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:2165)
	... 54 more

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;above will only help in recreating the issue, if the &lt;em&gt;insert overwrite&lt;/em&gt; query takes longer than &lt;em&gt;hive.txn.timeout / 2 = 4 / 2 = 2seconds&lt;/em&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13119145">HIVE-18090</key>
            <summary>acid heartbeat fails when metastore is connected via hadoop credential</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="anishek">Anishek Agarwal</assignee>
                                    <reporter username="anishek">Anishek Agarwal</reporter>
                        <labels>
                    </labels>
                <created>Fri, 17 Nov 2017 08:18:14 +0000</created>
                <updated>Tue, 22 May 2018 23:13:26 +0000</updated>
                            <resolved>Wed, 22 Nov 2017 06:03:55 +0000</resolved>
                                    <version>1.3.0</version>
                    <version>2.0.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>HiveServer2</component>
                    <component>Transactions</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16256655" author="anishek" created="Fri, 17 Nov 2017 08:38:39 +0000"  >&lt;p&gt;to start a test run and see the results, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;thejas&lt;/a&gt;/&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ekoifman&quot; class=&quot;user-hover&quot; rel=&quot;ekoifman&quot;&gt;ekoifman&lt;/a&gt; any suggestions as to how do have an automated test for this?&lt;/p&gt;</comment>
                            <comment id="16257364" author="hiveqa" created="Fri, 17 Nov 2017 18:33:48 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12898154/HIVE-18090.0.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12898154/HIVE-18090.0.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 8 failed/errored test(s), 11383 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_2] (batchId=47)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=77)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[unionDistinct_1] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=102)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConstraints (batchId=223)
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema[2] (batchId=187)
org.apache.hive.hcatalog.pig.TestSequenceFileHCatStorer.testWriteChar (batchId=187)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/7888/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/7888/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/7888/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/7888/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-7888/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-7888/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12898154 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16257735" author="ekoifman" created="Fri, 17 Nov 2017 23:19:10 +0000"  >&lt;p&gt;you have &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;tblproperties(&apos;transactional&apos;=&apos;tur&apos;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I assume this is just a typo?&lt;/p&gt;

&lt;p&gt;Also, &lt;em&gt;above will only work if the insert overwrite query takes longer than hive.txn.timeout / 2 = 4 / 2 = 2seconds&lt;/em&gt; - I assume &quot;work&quot; means &quot;reproduce&quot;?&lt;/p&gt;

&lt;p&gt;The thread pool for heartbeating DbTxnManager.heartbeatExecutorService is static so if you are able to create 2 sessions with different users, the pool should have the tread alive with User1 when User2 issues a request, I think.&lt;/p&gt;

&lt;p&gt;otherwise the patch LGTM&lt;br/&gt;
+1&lt;/p&gt;</comment>
                            <comment id="16260895" author="ekoifman" created="Tue, 21 Nov 2017 15:25:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-12366&quot; title=&quot;Refactor Heartbeater logic for transaction&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-12366&quot;&gt;&lt;del&gt;HIVE-12366&lt;/del&gt;&lt;/a&gt; is where shared thread pool for heartbeat was introduced&lt;/p&gt;</comment>
                            <comment id="16261997" author="anishek" created="Wed, 22 Nov 2017 05:46:15 +0000"  >&lt;p&gt;Thanks for the review &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ekoifman&quot; class=&quot;user-hover&quot; rel=&quot;ekoifman&quot;&gt;ekoifman&lt;/a&gt;, Fixed the typos in &quot;Description&quot;, Going to do a quick look at tests failures once before i commit, cant access the apache logs.&lt;/p&gt;</comment>
                            <comment id="16262013" author="anishek" created="Wed, 22 Nov 2017 06:03:56 +0000"  >&lt;p&gt;Patch committed to master !&lt;/p&gt;</comment>
                            <comment id="16484912" author="ashutoshc" created="Tue, 22 May 2018 23:13:26 +0000"  >&lt;p&gt;This jira is resolved and released with Hive 3.0 If you find an issue with it, please create a new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12911397">HIVE-12366</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12898154" name="HIVE-18090.0.patch" size="5706" author="anishek" created="Fri, 17 Nov 2017 08:37:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 26 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3mwwn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>