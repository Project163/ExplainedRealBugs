<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:55:06 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-17010] Fix the overflow problem of Long type in SetSparkReducerParallelism</title>
                <link>https://issues.apache.org/jira/browse/HIVE-17010</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;We use &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SetSparkReducerParallelism.java#L129&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;numberOfBytes&lt;/a&gt; to collect the numberOfBytes of sibling of specified RS. We use Long type and it happens overflow when the data is too big. After happening this situation, the parallelism is decided by &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SetSparkReducerParallelism.java#L184&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;sparkMemoryAndCores.getSecond()&lt;/a&gt; if spark.dynamic.allocation.enabled is true, sparkMemoryAndCores.getSecond is a dymamic value which is decided by spark runtime. For example, the value of sparkMemoryAndCores.getSecond is 5 or 15 randomly. There is possibility that the value may be 1. The may problem here is the overflow of addition of Long type.  You can reproduce the overflow problem by following code&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) {
      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; a1= 9223372036854775807L;
      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; a2=1022672;

      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; res = a1+a2;
      &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(res);  &lt;span class=&quot;code-comment&quot;&gt;//-9223372036853753137
&lt;/span&gt;
      BigInteger b1= BigInteger.valueOf(a1);
      BigInteger b2 = BigInteger.valueOf(a2);

      BigInteger bigRes = b1.add(b2);

      &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(bigRes); &lt;span class=&quot;code-comment&quot;&gt;//9223372036855798479
&lt;/span&gt;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13084105">HIVE-17010</key>
            <summary>Fix the overflow problem of Long type in SetSparkReducerParallelism</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kellyzly">liyunzhang</assignee>
                                    <reporter username="kellyzly">liyunzhang</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Jul 2017 03:05:31 +0000</created>
                <updated>Tue, 22 May 2018 23:57:56 +0000</updated>
                            <resolved>Tue, 11 Jul 2017 03:51:10 +0000</resolved>
                                                    <fixVersion>3.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16073041" author="kellyzly" created="Tue, 4 Jul 2017 02:39:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Ferd&quot; class=&quot;user-hover&quot; rel=&quot;Ferd&quot;&gt;Ferd&lt;/a&gt;: can you help review &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17010&quot; title=&quot;Fix the overflow problem of Long type in SetSparkReducerParallelism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-17010&quot;&gt;&lt;del&gt;HIVE-17010&lt;/del&gt;&lt;/a&gt;.1.patch?&lt;br/&gt;
We can use double to replace long type to solve the overflow problem.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;   &lt;span class=&quot;code-comment&quot;&gt;//&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; max=9223372036854775807
&lt;/span&gt;      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; a1= 9223372036854775807L;
      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; a2=1022672;

      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; res = a1+a2;
      &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(res);  &lt;span class=&quot;code-comment&quot;&gt;//-9223372036853753137
&lt;/span&gt;

      &lt;span class=&quot;code-comment&quot;&gt;//&lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt; max=1.7976931348623157E308
&lt;/span&gt;      &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt; d1= 9223372036854775807L;
      &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt; d2=1022672;

      &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt; dres = d1+d2;
      &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(dres);&lt;span class=&quot;code-comment&quot;&gt;//9.223372036855798E18
&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16075268" author="csun" created="Wed, 5 Jul 2017 19:21:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;We use Long type and it happens overflow when the data is too big.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t understand. How it could overflow with long type? how large is the dataset you used for testing?&lt;/p&gt;</comment>
                            <comment id="16075778" author="kellyzly" created="Thu, 6 Jul 2017 01:47:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt;: found the problem on 3TB data. Actually the biggest table of tpc-ds &quot;store_sales&quot; does not exceed the max value of Long type(2^63-1). But &lt;a href=&quot;https://github.com/hortonworks/hive-testbench/blob/hive14/sample-queries-tpcds/query17.sql&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;TPC-DS/query17&lt;/a&gt; is a query with many join.   We &lt;br/&gt;
 use &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SetSparkReducerParallelism.java#L129&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;numberOfBytes&lt;/a&gt; to collect the numberOfBytes of sibling of specified RS.  Here the sibling of specified RS maybe the result of join of big tables. The result execeed the max value of Long type.&lt;/p&gt;</comment>
                            <comment id="16075808" author="lirui" created="Thu, 6 Jul 2017 02:18:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt;, we use a long to compute the sum of multiple longs. I guess that&apos;s in general a dangerous operation.&lt;/p&gt;</comment>
                            <comment id="16075824" author="kellyzly" created="Thu, 6 Jul 2017 02:38:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;,&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ferd&quot; class=&quot;user-hover&quot; rel=&quot;Ferd&quot;&gt;ferd&lt;/a&gt;: in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17010&quot; title=&quot;Fix the overflow problem of Long type in SetSparkReducerParallelism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-17010&quot;&gt;&lt;del&gt;HIVE-17010&lt;/del&gt;&lt;/a&gt;.patch, use double to replace long type to solve the problem&lt;br/&gt;
similar bug was found in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8689&quot; title=&quot;handle overflows in statistics better&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8689&quot;&gt;&lt;del&gt;HIVE-8689&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8689&quot; title=&quot;handle overflows in statistics better&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8689&quot;&gt;&lt;del&gt;HIVE-8689&lt;/del&gt;&lt;/a&gt;, it use &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java#L1626&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;StatsUtils.safeAdd&lt;/a&gt; to solve the problem. So which solution is better? 1. use double to replace Long 2. use StatsUtils.safeAdd , please give me your suggestion&lt;/p&gt;</comment>
                            <comment id="16075826" author="csun" created="Thu, 6 Jul 2017 02:44:00 +0000"  >&lt;p&gt;With long you need to have ~9000 PB of &lt;tt&gt;numberOfBytes&lt;/tt&gt; for the overflow to happen. It&apos;s interesting that this can occur with 3TB of input data. I&apos;m just wondering if there&apos;s any bug in the code that caused this.&lt;/p&gt;</comment>
                            <comment id="16075839" author="kellyzly" created="Thu, 6 Jul 2017 02:57:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt;: &lt;br/&gt;
the explain of the query17 without &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17010&quot; title=&quot;Fix the overflow problem of Long type in SetSparkReducerParallelism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-17010&quot;&gt;&lt;del&gt;HIVE-17010&lt;/del&gt;&lt;/a&gt;.patch is in &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12875204/query17_explain.log&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;link&lt;/a&gt;.  Reduce3&apos;s datasize  is 9223372036854775807 &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;   Reducer 3 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col28 (type: bigint), _col27 (type: bigint)
                  1 cs_bill_customer_sk (type: bigint), cs_item_sk (type: bigint)
                outputColumnNames: _col1, _col2, _col6, _col8, _col9, _col22, _col27, _col28, _col34, _col35, _col45, _col51, _col63, _col66, _col82
                Statistics: Num rows: 9223372036854775807 Data size: 9223372036854775807 Basic stats: COMPLETE Column stats: PARTIAL
                Reduce Output Operator
                  key expressions: _col22 (type: bigint)
                  sort order: +
                  Map-reduce partition columns: _col22 (type: bigint)
                  Statistics: Num rows: 9223372036854775807 Data size: 9223372036854775807 Basic stats: COMPLETE Column stats: PARTIAL
                  value expressions: _col1 (type: bigint), _col2 (type: bigint), _col6 (type: bigint), _col8 (type: bigint), _col9 (type: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;), _col27 (type: bigint), _col28 (type: bigint), _col34 (type: bigint), _col35 (type: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;), _col45 (type: bigint), _col51 (type: bigint), _col63 (type: bigint), _col66 (type: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;), _col82 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Map9&apos;s datasize is 1022672 &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;        Map 9 
            Map Operator Tree:
                TableScan
                  alias: d1
                  filterExpr: (d_date_sk is not &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; and (d_quarter_name = &lt;span class=&quot;code-quote&quot;&gt;&apos;2000Q1&apos;&lt;/span&gt;)) (type: &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;)
                  Statistics: Num rows: 73049 Data size: 2045372 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (d_date_sk is not &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; and (d_quarter_name = &lt;span class=&quot;code-quote&quot;&gt;&apos;2000Q1&apos;&lt;/span&gt;)) (type: &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;)
                    Statistics: Num rows: 36524 Data size: 1022672 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: d_date_sk (type: bigint)
                      sort order: +
                      Map-reduce partition columns: d_date_sk (type: bigint)
                      Statistics: Num rows: 36524 Data size: 1022672 Basic stats: COMPLETE Column stats: NONE
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There is a join of Map 9 and Reducer3&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;        Reducer 4 &amp;lt;- Map 9 (PARTITION-LEVEL SORT, 1), Reducer 3 (PARTITION-LEVEL SORT, 1)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;9223372036854775807 + 1022672 &lt;br/&gt;
cause the problem&lt;/p&gt;</comment>
                            <comment id="16075852" author="csun" created="Thu, 6 Jul 2017 03:18:17 +0000"  >&lt;p&gt;Ah I see. Sometimes the stats estimation could generate negative values, in which case Hive will use &lt;tt&gt;Long.MAX_VALUE&lt;/tt&gt; for both # of rows and data size. One case I observed previously:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;not ((P1 or P2) or P3)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;When no column stats are available, Hive will simply divide the # of input rows by 2 for each predicate evaluation. Suppose the total input rows is 10, then &lt;tt&gt;P1&lt;/tt&gt;, &lt;tt&gt;P2&lt;/tt&gt; and &lt;tt&gt;P3&lt;/tt&gt; will yield 5 respectively. Operator &lt;tt&gt;or&lt;/tt&gt; adds value from both sides so the expression &lt;tt&gt;((P1 or P2) or P3)&lt;/tt&gt; generates 30 rows. The operator &lt;tt&gt;not&lt;/tt&gt;, on the other hand, will subtract the value of its associated expression from the total input rows. Therefore in the end you will get &lt;tt&gt;10 - 30 = -20&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;For the solution you proposed, I&apos;m inclined to use &lt;tt&gt;StatsUtils.safeAdd&lt;/tt&gt;, but either way should be fine.&lt;/p&gt;</comment>
                            <comment id="16076127" author="kellyzly" created="Thu, 6 Jul 2017 08:02:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt;: update &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17010&quot; title=&quot;Fix the overflow problem of Long type in SetSparkReducerParallelism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-17010&quot;&gt;&lt;del&gt;HIVE-17010&lt;/del&gt;&lt;/a&gt;.2.patch to use &lt;tt&gt;StatsUtils.safeAdd&lt;/tt&gt; to solve the overflow. help review&lt;/p&gt;</comment>
                            <comment id="16076200" author="hiveqa" created="Thu, 6 Jul 2017 09:06:01 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12875874/HIVE-17010.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12875874/HIVE-17010.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 9 failed/errored test(s), 10832 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[infer_bucket_sort_reducers_power_two] (batchId=167)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testParallelCompilation (batchId=226)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5906/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5906/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5906/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5906/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5906/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5906/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12875874 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16077497" author="lirui" created="Fri, 7 Jul 2017 02:42:40 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt;, I think it should be &lt;tt&gt;numberOfBytes = StatsUtils.safeAdd(numberOfBytes, sibling.getStatistics().getDataSize());&lt;/tt&gt; right?&lt;br/&gt;
And thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt; for the detailed analysis. Seems the estimation logic deserves some improvement.&lt;/p&gt;</comment>
                            <comment id="16077513" author="kellyzly" created="Fri, 7 Jul 2017 03:09:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;: thanks for your catch, will update the patch soon&lt;/p&gt;</comment>
                            <comment id="16077517" author="kellyzly" created="Fri, 7 Jul 2017 03:17:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;: help review &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17010&quot; title=&quot;Fix the overflow problem of Long type in SetSparkReducerParallelism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-17010&quot;&gt;&lt;del&gt;HIVE-17010&lt;/del&gt;&lt;/a&gt;.3.patch.&lt;/p&gt;</comment>
                            <comment id="16077534" author="lirui" created="Fri, 7 Jul 2017 03:52:40 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="16077557" author="hiveqa" created="Fri, 7 Jul 2017 04:29:39 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12876022/HIVE-17010.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12876022/HIVE-17010.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 8 failed/errored test(s), 10834 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5914/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5914/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/5914/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/5914/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-5914/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-5914/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12876022 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16079823" author="kellyzly" created="Mon, 10 Jul 2017 03:37:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Ferd&quot; class=&quot;user-hover&quot; rel=&quot;Ferd&quot;&gt;Ferd&lt;/a&gt;: as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt; finished review, please help commit &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17010&quot; title=&quot;Fix the overflow problem of Long type in SetSparkReducerParallelism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-17010&quot;&gt;&lt;del&gt;HIVE-17010&lt;/del&gt;&lt;/a&gt;.3.patch&lt;/p&gt;</comment>
                            <comment id="16081611" author="ferd" created="Tue, 11 Jul 2017 03:51:10 +0000"  >&lt;p&gt;Committed to the upstream. Thanks Liyun for the patch and thanks Chao and Rui for the reviews.&lt;/p&gt;</comment>
                            <comment id="16485850" author="vgarg" created="Tue, 22 May 2018 23:57:56 +0000"  >&lt;p&gt;Hive 3.0.0 has been released so closing this jira.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12875562" name="HIVE-17010.1.patch" size="1669" author="kellyzly" created="Tue, 4 Jul 2017 02:36:32 +0000"/>
                            <attachment id="12875874" name="HIVE-17010.2.patch" size="2686" author="kellyzly" created="Thu, 6 Jul 2017 08:01:09 +0000"/>
                            <attachment id="12876022" name="HIVE-17010.3.patch" size="2718" author="kellyzly" created="Fri, 7 Jul 2017 03:17:21 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 26 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3h073:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>