<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:22:09 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-7624] Reduce operator initialization failed when running multiple MR query on spark</title>
                <link>https://issues.apache.org/jira/browse/HIVE-7624</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The following error occurs when I try to run a query with multiple reduce works (M-&amp;gt;R-&amp;gt;R):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;14/08/05 12:17:07 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 1)&lt;br/&gt;
java.lang.RuntimeException: Reduce operator initialization failed&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.configure(ExecReducer.java:170)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunction.call(HiveReduceFunction.java:53)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunction.call(HiveReduceFunction.java:31)&lt;br/&gt;
        at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:164)&lt;br/&gt;
        at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:164)&lt;br/&gt;
        at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)&lt;br/&gt;
        at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)&lt;br/&gt;
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)&lt;br/&gt;
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
       at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)&lt;br/&gt;
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)&lt;br/&gt;
        at org.apache.spark.scheduler.Task.run(Task.scala:54)&lt;br/&gt;
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:199)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:744)&lt;br/&gt;
Caused by: java.lang.RuntimeException: cannot find field reducesinkkey0 from &lt;span class=&quot;error&quot;&gt;&amp;#91;0:_col0&amp;#93;&lt;/span&gt;&lt;br/&gt;
        at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.getStandardStructFieldRef(ObjectInspectorUtils.java:415)&lt;br/&gt;
        at org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector.getStructFieldRef(StandardStructObjectInspector.java:147)&lt;br/&gt;
&#8230;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I suspect we&apos;re applying the reduce function in wrong order.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12732199">HIVE-7624</key>
            <summary>Reduce operator initialization failed when running multiple MR query on spark</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lirui">Rui Li</assignee>
                                    <reporter username="lirui">Rui Li</reporter>
                        <labels>
                    </labels>
                <created>Wed, 6 Aug 2014 01:32:53 +0000</created>
                <updated>Fri, 29 May 2015 02:30:37 +0000</updated>
                            <resolved>Mon, 18 Aug 2014 16:01:27 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14087264" author="brocknoland" created="Wed, 6 Aug 2014 05:22:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt; In our sync-up you mentioned overwriting values in JobConf for Reduce work. I have found while digging around that we need to clone the jobConf for each MapWork or ReduceWork so they don&apos;t overwrite each other. We should do this in SparkPlanGenerator.generate methods&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    JobConf newJobConf = new JobConf(jobConf);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="14087272" author="lirui" created="Wed, 6 Aug 2014 05:29:06 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;brocknoland&lt;/a&gt; let me try this.&lt;/p&gt;</comment>
                            <comment id="14087281" author="csun" created="Wed, 6 Aug 2014 05:37:43 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;brocknoland&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;, I tried cloning new jobConf today, and it somehow still gave me the same error. Not sure why.&lt;/p&gt;</comment>
                            <comment id="14088993" author="csun" created="Thu, 7 Aug 2014 08:20:52 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ruili&quot; class=&quot;user-hover&quot; rel=&quot;ruili&quot;&gt;ruili&lt;/a&gt;, I spent sometime looking at this bug today. What I found out is that, even with cloned JobConfs,&lt;br/&gt;
in &lt;tt&gt;Utilities.setBaseWork&lt;/tt&gt; it will still create same &lt;tt&gt;planPath&lt;/tt&gt; for different reduce plans. Therefore, only one reduce plan will be left. I think we might need to find some way to allow multiple reduce plan files to co-exist.&lt;br/&gt;
Hope this helps.&lt;/p&gt;</comment>
                            <comment id="14089001" author="lirui" created="Thu, 7 Aug 2014 08:36:09 +0000"  >&lt;p&gt;Thanks very much &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt;. After some debugging, I found this issue is caused in GenMapRedUtils.setKeyAndValueDescForTaskTree, which is called after we compiled the task. In that method we always set the keyDesc of the leaf reduce work according to the root map work. I suppose this is both incorrect and redundant because when a reduce work is created, we already call GenSparkUtils.setupReduceSink to set the keyDesc. I removed these code and the exception is gone.&lt;/p&gt;

&lt;p&gt;However I met another problem: no result is returned for the multi-MR query. (I cloned the jobConf and set a new plan path for the cloned)&lt;/p&gt;</comment>
                            <comment id="14089181" author="lirui" created="Thu, 7 Aug 2014 12:41:30 +0000"  >&lt;p&gt;This patch solves the reducesinkkey0 problem. Map work and reduce work finish successfully.&lt;br/&gt;
However, no result is returned. I checked the log and found the second reduce work got nothing to process. Not sure what is missing here...&lt;/p&gt;

&lt;p&gt;I quickly looked at tez code and find it sets output collector for each reduce sink. (OperatorUtils.setChildrenCollector) Don&apos;t know if this is related though&lt;/p&gt;</comment>
                            <comment id="14089455" author="csun" created="Thu, 7 Aug 2014 17:02:33 +0000"  >&lt;p&gt;Great! Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ruili&quot; class=&quot;user-hover&quot; rel=&quot;ruili&quot;&gt;ruili&lt;/a&gt;. I&apos;ll try this patch.&lt;/p&gt;</comment>
                            <comment id="14089459" author="brocknoland" created="Thu, 7 Aug 2014 17:04:31 +0000"  >&lt;p&gt;During debugging I have used the code below&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;System.err.println(&quot;JoinOperator &quot; + alias + &quot; row = &quot; + SerDeUtils.getJSONString(row, inputObjInspectors[tag]));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I wonder if we should not commit that to each operator for debugging since it&apos;s much easier to see how the rows are filtered, modified...&lt;/p&gt;</comment>
                            <comment id="14089555" author="csun" created="Thu, 7 Aug 2014 18:15:51 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ruili&quot; class=&quot;user-hover&quot; rel=&quot;ruili&quot;&gt;ruili&lt;/a&gt;, I think this patch overlaps a little bit with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7597&quot; title=&quot;Support analyze table [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7597&quot;&gt;&lt;del&gt;HIVE-7597&lt;/del&gt;&lt;/a&gt;, on &lt;tt&gt;GenMapRedUtils&lt;/tt&gt;. I can&apos;t apply the patch due to the conflict.&lt;/p&gt;</comment>
                            <comment id="14089922" author="xuefuz" created="Thu, 7 Aug 2014 22:07:04 +0000"  >&lt;blockquote&gt;
&lt;p&gt;However, no result is returned. I checked the log and found the second reduce work got nothing to process. Not sure what is missing here...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think the problem is caused by FileSinkOperator in reduce-side operator tree. That tree, in MR world, is probably always FileSinkOperator (which write on disk). If we have MRR, then the first R should not write to disk. Instead, it should have RedcueSinkOperator, which outputs the result to the SparkCollector. The result RDD is based on the SparkCollector, which can be picked up by the second R.&lt;/p&gt;

&lt;p&gt;I think we need to modify the operator tree a bit for this to work correctly. Please follow Tez&apos;s way to do this.&lt;/p&gt;</comment>
                            <comment id="14090009" author="csun" created="Thu, 7 Aug 2014 23:06:31 +0000"  >&lt;p&gt;With this patch and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7492&quot; title=&quot;Enhance SparkCollector [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7492&quot;&gt;&lt;del&gt;HIVE-7492&lt;/del&gt;&lt;/a&gt; plus &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7652&quot; title=&quot;Check OutputCollector after closing ExecMapper/ExecReducer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7652&quot;&gt;&lt;del&gt;HIVE-7652&lt;/del&gt;&lt;/a&gt;, group by + reduce by produces correct result on my machine.&lt;br/&gt;
I&apos;m not sure why. Also, not sure whether there&apos;s any further issue.&lt;/p&gt;</comment>
                            <comment id="14090010" author="csun" created="Thu, 7 Aug 2014 23:07:07 +0000"  >&lt;p&gt;sorry should be order by in my last comment.&lt;/p&gt;</comment>
                            <comment id="14090152" author="lirui" created="Fri, 8 Aug 2014 01:28:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;xuefuz&lt;/a&gt; currently the second R does end with a ReduceSink.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt; sorry it&apos;s been a while since I last sync with the upstream. I&apos;ll rebase my branch and run the test again.&lt;/p&gt;</comment>
                            <comment id="14090261" author="lirui" created="Fri, 8 Aug 2014 03:39:28 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt; I updated the patch based on latest code.&lt;br/&gt;
But the group by+order by query still returns nothing for me (with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7492&quot; title=&quot;Enhance SparkCollector [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7492&quot;&gt;&lt;del&gt;HIVE-7492&lt;/del&gt;&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7652&quot; title=&quot;Check OutputCollector after closing ExecMapper/ExecReducer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7652&quot;&gt;&lt;del&gt;HIVE-7652&lt;/del&gt;&lt;/a&gt; in place).&lt;/p&gt;

&lt;p&gt;I&apos;m not sure if this is another issue or the side effect of cloning the job conf. Any ideas?&lt;/p&gt;</comment>
                            <comment id="14090452" author="lirui" created="Fri, 8 Aug 2014 08:04:21 +0000"  >&lt;p&gt;Finally I found this is because we don&apos;t set output collector for RS in ExecReducer. While this is natural for MR where ExecReducer shouldn&apos;t contain RS, we have to do it for spark. The added code just looks for RS and sets collector for it, so there shouldn&apos;t be any regression.&lt;/p&gt;</comment>
                            <comment id="14090509" author="lirui" created="Fri, 8 Aug 2014 09:15:05 +0000"  >&lt;p&gt;Some change may bypass &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7597&quot; title=&quot;Support analyze table [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7597&quot;&gt;&lt;del&gt;HIVE-7597&lt;/del&gt;&lt;/a&gt;. Remove it.&lt;/p&gt;</comment>
                            <comment id="14090525" author="hiveqa" created="Fri, 8 Aug 2014 09:29:56 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12660582/HIVE-7624.3-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12660582/HIVE-7624.3-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 5843 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_fs_default_name2
org.apache.hadoop.hive.metastore.txn.TestCompactionTxnHandler.testRevokeTimedOutWorkers
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/23/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/23/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/23/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/23/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-23/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-23/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12660582&lt;/p&gt;</comment>
                            <comment id="14090689" author="hiveqa" created="Fri, 8 Aug 2014 12:03:29 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12660590/HIVE-7624.4-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12660590/HIVE-7624.4-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 5828 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_fs_default_name2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/24/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/24/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/24/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/24/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-24/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-24/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12660590&lt;/p&gt;</comment>
                            <comment id="14091198" author="szehon" created="Fri, 8 Aug 2014 19:38:32 +0000"  >&lt;p&gt;Hi Li Rui, I think the patch looks reasonable.  Just had a comment and a question on the RB.  Thanks&lt;/p&gt;</comment>
                            <comment id="14092606" author="hiveqa" created="Mon, 11 Aug 2014 09:26:08 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12660957/HIVE-7624.5-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12660957/HIVE-7624.5-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/28/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/28/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/28/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/28/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-28/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-28/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/lib64/qt-3.3/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/lib64/qt-3.3/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-SPARK-Build-28/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-spark-source ]]
+ [[ ! -d apache-svn-spark-source/.svn ]]
+ [[ ! -d apache-svn-spark-source ]]
+ cd apache-svn-spark-source
+ svn revert -R .
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java&apos;
++ svn status --no-ignore
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/common-secure/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit-hadoop2/target itests/hive-minikdc/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/core/target hcatalog/streaming/target hcatalog/server-extensions/target hcatalog/hcatalog-pig-adapter/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hwi/target common/target common/src/gen contrib/target service/target serde/target beeline/target cli/target odbc/target ql/dependency-reduced-pom.xml ql/target
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1617233.

At revision 1617233.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12660957&lt;/p&gt;</comment>
                            <comment id="14092900" author="brocknoland" created="Mon, 11 Aug 2014 15:37:57 +0000"  >&lt;p&gt;Nice work!!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The patch does not appear to apply with p0, p1, or p2&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Looks like the patch needs to be rebased.&lt;/p&gt;</comment>
                            <comment id="14093614" author="szehon" created="Tue, 12 Aug 2014 01:28:13 +0000"  >&lt;p&gt;+1 for latest version&lt;/p&gt;</comment>
                            <comment id="14093618" author="lirui" created="Tue, 12 Aug 2014 01:32:24 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;brocknoland&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szehon&quot; class=&quot;user-hover&quot; rel=&quot;szehon&quot;&gt;szehon&lt;/a&gt; I&apos;ll rebase the patch.&lt;/p&gt;</comment>
                            <comment id="14093630" author="lirui" created="Tue, 12 Aug 2014 01:38:05 +0000"  >&lt;p&gt;I rebased with latest code.&lt;/p&gt;</comment>
                            <comment id="14093638" author="szehon" created="Tue, 12 Aug 2014 01:47:53 +0000"  >&lt;p&gt;Oh I thought the last version on RB was already rebased.  +1 pending test for latest version.&lt;/p&gt;</comment>
                            <comment id="14093770" author="hiveqa" created="Tue, 12 Aug 2014 05:46:41 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12661110/HIVE-7624.6-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12661110/HIVE-7624.6-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 5844 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_context_ngrams
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_fs_default_name2
org.apache.hadoop.hive.ql.TestDDLWithRemoteMetastoreSecondNamenode.testCreateTableWithIndexAndPartitionsNonDefaultNameNode
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/32/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/32/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/32/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/32/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-32/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-32/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12661110&lt;/p&gt;</comment>
                            <comment id="14093774" author="szehon" created="Tue, 12 Aug 2014 05:55:50 +0000"  >&lt;p&gt;udaf_context_ngrams is a strange failure, never seen it before, but doubt it&apos;s be related to this patch.  &lt;/p&gt;

&lt;p&gt;Will commit this shortly.&lt;/p&gt;</comment>
                            <comment id="14093792" author="szehon" created="Tue, 12 Aug 2014 06:26:37 +0000"  >&lt;p&gt;Committed to spark branch.  Thanks Rui.&lt;/p&gt;</comment>
                            <comment id="14093796" author="lirui" created="Tue, 12 Aug 2014 06:31:29 +0000"  >&lt;p&gt;Thanks for the review : -) &lt;/p&gt;</comment>
                            <comment id="14100307" author="lirui" created="Mon, 18 Aug 2014 05:55:16 +0000"  >&lt;p&gt;Reopen this as we&apos;ve refactored to use SparkRecordHandler instead of ExecMapper and ExecReducer&lt;/p&gt;</comment>
                            <comment id="14100358" author="hiveqa" created="Mon, 18 Aug 2014 06:59:41 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12662431/HIVE-7624.7-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12662431/HIVE-7624.7-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 5915 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_fs_default_name2
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/54/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/54/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/54/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/54/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-54/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-54/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12662431&lt;/p&gt;</comment>
                            <comment id="14100769" author="brocknoland" created="Mon, 18 Aug 2014 16:01:14 +0000"  >&lt;p&gt;Hi Rui,&lt;/p&gt;

&lt;p&gt;Hive generally follows one commit = one jira so I moved your patch over to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7766&quot; title=&quot;Cleanup Reduce operator code [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7766&quot;&gt;&lt;del&gt;HIVE-7766&lt;/del&gt;&lt;/a&gt; and committed it. Thank you!!&lt;/p&gt;</comment>
                            <comment id="14101680" author="lirui" created="Tue, 19 Aug 2014 01:34:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;brocknoland&lt;/a&gt; Got it, thanks!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12731037">HIVE-7569</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12723734">HIVE-7292</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12734784">HIVE-7766</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12660543" name="HIVE-7624.2-spark.patch" size="3990" author="lirui" created="Fri, 8 Aug 2014 03:35:18 +0000"/>
                            <attachment id="12660582" name="HIVE-7624.3-spark.patch" size="4388" author="lirui" created="Fri, 8 Aug 2014 07:59:05 +0000"/>
                            <attachment id="12660590" name="HIVE-7624.4-spark.patch" size="3993" author="lirui" created="Fri, 8 Aug 2014 09:13:01 +0000"/>
                            <attachment id="12660957" name="HIVE-7624.5-spark.patch" size="5190" author="lirui" created="Mon, 11 Aug 2014 09:06:05 +0000"/>
                            <attachment id="12661110" name="HIVE-7624.6-spark.patch" size="5114" author="lirui" created="Tue, 12 Aug 2014 01:38:05 +0000"/>
                            <attachment id="12662431" name="HIVE-7624.7-spark.patch" size="3582" author="lirui" created="Mon, 18 Aug 2014 06:00:47 +0000"/>
                            <attachment id="12660377" name="HIVE-7624.patch" size="4636" author="lirui" created="Thu, 7 Aug 2014 12:35:31 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>410228</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 14 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ykvj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>410220</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>