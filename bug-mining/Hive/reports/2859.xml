<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:27:11 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-8394] HIVE-7803 doesn&apos;t handle Pig MultiQuery, can cause data-loss.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8394</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;We&apos;ve found situations in production where Pig queries using &lt;tt&gt;HCatStorer&lt;/tt&gt;, dynamic partitioning and &lt;tt&gt;opt.multiquery=true&lt;/tt&gt; that produce partitions in the output table, but the corresponding directories have no data files (in spite of Pig reporting non-zero records written to HDFS). I don&apos;t yet have a distilled test-case for this.&lt;/p&gt;

&lt;p&gt;Here&apos;s the code from FileOutputCommitterContainer after &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7803&quot; title=&quot;Enable Hadoop speculative execution may cause corrupt output directory (dynamic partition)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7803&quot;&gt;&lt;del&gt;HIVE-7803&lt;/del&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;background-color: #FFFFCE;border-style: dashed;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: dashed;background-color: #F7D6C1;&quot;&gt;&lt;b&gt;FileOutputCommitterContainer.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot; style=&quot;background-color: #FFFFCE;&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  @Override
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void commitTask(TaskAttemptContext context) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; jobInfoStr = context.getConfiguration().get(FileRecordWriterContainer.DYN_JOBINFO);
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!dynamicPartitioningUsed) {
         &lt;span class=&quot;code-comment&quot;&gt;//See HCATALOG-499
&lt;/span&gt;      FileOutputFormatContainer.setWorkOutputPath(context);
      getBaseOutputCommitter().commitTask(HCatMapRedUtil.createTaskAttemptContext(context));
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (jobInfoStr != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      ArrayList&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; jobInfoList = (ArrayList&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt;)HCatUtil.deserialize(jobInfoStr);
      org.apache.hadoop.mapred.TaskAttemptContext currTaskContext = HCatMapRedUtil.createTaskAttemptContext(context);
      &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; jobStr : jobInfoList) {
    	OutputJobInfo localJobInfo = (OutputJobInfo)HCatUtil.deserialize(jobStr);
    	FileOutputCommitter committer = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FileOutputCommitter(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Path(localJobInfo.getLocation()), currTaskContext);
    	committer.commitTask(currTaskContext);
      }
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The serialized jobInfoList can&apos;t be retrieved, and hence the commit never completes. This is because Pig&apos;s MapReducePOStoreImpl deliberately clones both the TaskAttemptContext and the contained Configuration instance, thus separating the Configuration instances passed to &lt;tt&gt;FileOutputCommitterContainer::commitTask()&lt;/tt&gt; and &lt;tt&gt;FileRecordWriterContainer::close()&lt;/tt&gt;. Anything set by the RecordWriter is unavailable to the Committer.&lt;/p&gt;

&lt;p&gt;One approach would have been to store state in the FileOutputFormatContainer. But that won&apos;t work since this is constructed via reflection in HCatOutputFormat (itself constructed via reflection by PigOutputFormat via HCatStorer). There&apos;s no guarantee that the instance is preserved.&lt;/p&gt;

&lt;p&gt;My only recourse seems to be to use a Singleton to store shared state. I&apos;m loath to indulge in this brand of shenanigans. (Statics and container-reuse in Tez might not play well together, for instance.) It might work if we&apos;re careful about tearing down the singleton.&lt;/p&gt;

&lt;p&gt;Any other ideas? &lt;/p&gt;</description>
                <environment></environment>
        <key id="12746579">HIVE-8394</key>
            <summary>HIVE-7803 doesn&apos;t handle Pig MultiQuery, can cause data-loss.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mithun">Mithun Radhakrishnan</assignee>
                                    <reporter username="mithun">Mithun Radhakrishnan</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Oct 2014 01:17:03 +0000</created>
                <updated>Thu, 13 Nov 2014 19:41:46 +0000</updated>
                            <resolved>Sun, 2 Nov 2014 23:50:05 +0000</resolved>
                                    <version>0.12.0</version>
                    <version>0.13.1</version>
                    <version>0.14.0</version>
                                    <fixVersion>0.14.0</fixVersion>
                                    <component>HCatalog</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="14162902" author="mithun" created="Wed, 8 Oct 2014 01:22:20 +0000"  >&lt;p&gt;I must mention: This breaks only in the case of a multi-query. &lt;/p&gt;

&lt;p&gt;I&apos;ve a silly question: Doesn&apos;t Hive support a multi-query equivalent? For instance:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sql&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;FROM&lt;/span&gt; myth_table
&lt;span class=&quot;code-keyword&quot;&gt;INSERT&lt;/span&gt; OVERWRITE target_table1 &lt;span class=&quot;code-keyword&quot;&gt;SELECT&lt;/span&gt; * &lt;span class=&quot;code-keyword&quot;&gt;WHERE&lt;/span&gt; ...
&lt;span class=&quot;code-keyword&quot;&gt;INSERT&lt;/span&gt; OVERWRITE target_table2 &lt;span class=&quot;code-keyword&quot;&gt;SELECT&lt;/span&gt; ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Isn&apos;t this the Hive equivalent of a Pig multi-output case? How does Hive handle the problem of 2-phase commit?&lt;/p&gt;</comment>
                            <comment id="14168014" author="mithun" created="Sat, 11 Oct 2014 05:42:28 +0000"  >&lt;p&gt;Tentative fix using a singleton to track OutputCommitter calls for TaskAttempt commits/aborts.&lt;br/&gt;
I tried solving this using the configuration, and by storing state in the OutputFormat. It can&apos;t be done. OutputFormats are constructed afresh using Reflection, and hence have no state. Similarly, Pig clones the configurations (and TaskAttemptContext instances) when calling RecordWriter functions, to prevent pollution.&lt;br/&gt;
I even tried storing state in the UDFContext, by modifying &lt;tt&gt;HCatStorer::setLocation()&lt;/tt&gt;, and then transferring the state into the JobConf. No dice.&lt;/p&gt;</comment>
                            <comment id="14168814" author="hiveqa" created="Sun, 12 Oct 2014 22:17:10 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12674344/HIVE-8394.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12674344/HIVE-8394.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4137 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_tez_smb_1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1236/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1236/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1236/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1236/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1236/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1236/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12674344&lt;/p&gt;</comment>
                            <comment id="14168853" author="mithun" created="Sun, 12 Oct 2014 23:58:35 +0000"  >&lt;p&gt;The test-failure is unrelated, IMO. Could I please bother someone for a review?&lt;/p&gt;</comment>
                            <comment id="14170267" author="mithun" created="Tue, 14 Oct 2014 00:01:45 +0000"  >&lt;p&gt;Ok, it looks like this might not work in case the TaskAttempt involves 2 HCatStorers. Since the Singleton uses TaskAttemptID as a key, it&apos;s possible that some OutputJobInfos might be committed twice (because Pig will call commitTask() once per Storer).&lt;/p&gt;</comment>
                            <comment id="14170309" author="mithun" created="Tue, 14 Oct 2014 00:43:13 +0000"  >&lt;p&gt;(Just recording what we discussed in review&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;1. We can get this to work if instead of keying on the TaskAttemptID, we use &amp;lt;attemptId&amp;gt;.&amp;lt;db&amp;gt;.&amp;lt;table&amp;gt; as the key. This will keep it unique and unambiguous.&lt;br/&gt;
2. We&apos;ll also need to add a &lt;tt&gt;finally&lt;/tt&gt; block to discard any cleanup-handler, in &lt;tt&gt;abortTask()&lt;/tt&gt; and &lt;tt&gt;commitTask()&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;This should do the trick for now. But it does feel like a workaround.&lt;/p&gt;</comment>
                            <comment id="14187361" author="sushanth" created="Tue, 28 Oct 2014 20:00:06 +0000"  >&lt;p&gt;I&apos;ll admit to the same distaste to using a Singleton to store state like this - we&apos;ve had similar problems with HCatContext in the past, but I agree with your assertion that that seems to be the only real way to handle this issue.&lt;/p&gt;

&lt;p&gt;Now, that said, the attached file &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8394&quot; title=&quot;HIVE-7803 doesn&amp;#39;t handle Pig MultiQuery, can cause data-loss.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8394&quot;&gt;&lt;del&gt;HIVE-8394&lt;/del&gt;&lt;/a&gt;.1.patch includes a TaskCommitterContextRegistry.discardCleanupFor and does not ever call it. I assume that&apos;s what you mean with your comment on needing to add a finally block? Also, yes, the patch in the current form has an issue with multiple HCatStorers - do you have an updated patch with both these issues resolved?&lt;/p&gt;</comment>
                            <comment id="14187363" author="sushanth" created="Tue, 28 Oct 2014 20:02:09 +0000"  >&lt;p&gt;(Also, slight warning - I&apos;ll likely be applying your patch post &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4329&quot; title=&quot;HCatalog should use getHiveRecordWriter rather than getRecordWriter&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4329&quot;&gt;HIVE-4329&lt;/a&gt;, and that might wind up requiring a rebase - the two should be compatible, I think, but I wanted to point it out if you think it makes a difference)&lt;/p&gt;</comment>
                            <comment id="14187381" author="mithun" created="Tue, 28 Oct 2014 20:21:15 +0000"  >&lt;p&gt;Yes, actually, I do have to update the patch. Will do shortly.&lt;/p&gt;</comment>
                            <comment id="14187382" author="sushanth" created="Tue, 28 Oct 2014 20:21:55 +0000"  >&lt;p&gt;Actually, re-reading &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7803&quot; title=&quot;Enable Hadoop speculative execution may cause corrupt output directory (dynamic partition)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7803&quot;&gt;&lt;del&gt;HIVE-7803&lt;/del&gt;&lt;/a&gt;, there is a problem - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4329&quot; title=&quot;HCatalog should use getHiveRecordWriter rather than getRecordWriter&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4329&quot;&gt;HIVE-4329&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7803&quot; title=&quot;Enable Hadoop speculative execution may cause corrupt output directory (dynamic partition)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7803&quot;&gt;&lt;del&gt;HIVE-7803&lt;/del&gt;&lt;/a&gt; will definitely not merge cleanly, so the pre-requisite for this is itself not going to merge.&lt;/p&gt;</comment>
                            <comment id="14191085" author="mithun" created="Fri, 31 Oct 2014 00:16:26 +0000"  >&lt;p&gt;Here&apos;s the updated patch. It handles the singleton-cleanup more completely. And instead of keying on only the TaskAttemptID, the solution now uses the commit-path as part of the key. This should handle multiple Pig outputs for the same attempt. (Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cdrome&quot; class=&quot;user-hover&quot; rel=&quot;cdrome&quot;&gt;cdrome&lt;/a&gt;.)&lt;/p&gt;</comment>
                            <comment id="14191772" author="hiveqa" created="Fri, 31 Oct 2014 13:00:43 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12678359/HIVE-8394.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12678359/HIVE-8394.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1573/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1573/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1573/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1573/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1573/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1573/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/contrib/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-contrib/0.15.0-SNAPSHOT/hive-contrib-0.15.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HBase Handler 0.15.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hbase-handler ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-hbase-handler ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-hbase-handler ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hbase-handler ---
[INFO] Compiling 37 source files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/classes
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDeParameters.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDeParameters.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- avro-maven-plugin:1.7.6:protocol (default) @ hive-hbase-handler ---
[INFO] 
[INFO] --- build-helper-maven-plugin:1.7:add-test-source (add-test-sources) @ hive-hbase-handler ---
[INFO] Test Source directory: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/gen/avro/gen-java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-hbase-handler ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
     [copy] Copying 8 files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hbase-handler ---
[INFO] Compiling 16 source files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/test-classes
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseKeyFactory2.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseKeyFactory2.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/org/apache/hadoop/hive/hbase/avro/ContactInfo.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/org/apache/hadoop/hive/hbase/avro/ContactInfo.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hbase-handler ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hbase-handler ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-0.15.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-hbase-handler ---
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-hbase-handler ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-0.15.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hbase-handler ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-0.15.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/0.15.0-SNAPSHOT/hive-hbase-handler-0.15.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/0.15.0-SNAPSHOT/hive-hbase-handler-0.15.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-0.15.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/0.15.0-SNAPSHOT/hive-hbase-handler-0.15.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog 0.15.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-hcatalog ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
     [copy] Copying 8 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-hcatalog ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog/0.15.0-SNAPSHOT/hive-hcatalog-0.15.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Core 0.15.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-core ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-hcatalog-core ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-hcatalog-core ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-core ---
[INFO] Compiling 79 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatBaseOutputFormat.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatBaseOutputFormat.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/DynamicPartitionFileRecordWriterContainer.java:[104,44] method register in class org.apache.hive.hcatalog.mapreduce.TaskCommitContextRegistry cannot be applied to given types;
  required: org.apache.hadoop.mapreduce.TaskAttemptContext,org.apache.hive.hcatalog.mapreduce.TaskCommitContextRegistry.TaskCommitterProxy
  found: org.apache.hadoop.mapreduce.TaskAttemptID,&amp;lt;anonymous org.apache.hive.hcatalog.mapreduce.TaskCommitContextRegistry.TaskCommitterProxy&amp;gt;
  reason: actual argument org.apache.hadoop.mapreduce.TaskAttemptID cannot be converted to org.apache.hadoop.mapreduce.TaskAttemptContext by method invocation conversion
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [12.650s]
[INFO] Hive Shims Common ................................. SUCCESS [7.257s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [3.670s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [5.452s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [2.454s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [8.050s]
[INFO] Hive Shims ........................................ SUCCESS [1.852s]
[INFO] Hive Common ....................................... SUCCESS [26.256s]
[INFO] Hive Serde ........................................ SUCCESS [21.837s]
[INFO] Hive Metastore .................................... SUCCESS [37.088s]
[INFO] Hive Ant Utilities ................................ SUCCESS [1.887s]
[INFO] Hive Query Language ............................... SUCCESS [1:37.469s]
[INFO] Hive Service ...................................... SUCCESS [12.555s]
[INFO] Hive Accumulo Handler ............................. SUCCESS [6.831s]
[INFO] Hive JDBC ......................................... SUCCESS [1:28.444s]
[INFO] Hive Beeline ...................................... SUCCESS [1.530s]
[INFO] Hive CLI .......................................... SUCCESS [1.709s]
[INFO] Hive Contrib ...................................... SUCCESS [1.603s]
[INFO] Hive HBase Handler ................................ SUCCESS [8.545s]
[INFO] Hive HCatalog ..................................... SUCCESS [0.600s]
[INFO] Hive HCatalog Core ................................ FAILURE [2.134s]
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 5:52.804s
[INFO] Finished at: Fri Oct 31 09:00:12 EDT 2014
[INFO] Final Memory: 125M/832M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-hcatalog-core: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/DynamicPartitionFileRecordWriterContainer.java:[104,44] method register in class org.apache.hive.hcatalog.mapreduce.TaskCommitContextRegistry cannot be applied to given types;
[ERROR] required: org.apache.hadoop.mapreduce.TaskAttemptContext,org.apache.hive.hcatalog.mapreduce.TaskCommitContextRegistry.TaskCommitterProxy
[ERROR] found: org.apache.hadoop.mapreduce.TaskAttemptID,&amp;lt;anonymous org.apache.hive.hcatalog.mapreduce.TaskCommitContextRegistry.TaskCommitterProxy&amp;gt;
[ERROR] reason: actual argument org.apache.hadoop.mapreduce.TaskAttemptID cannot be converted to org.apache.hadoop.mapreduce.TaskAttemptContext by method invocation conversion
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-hcatalog-core
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12678359 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14192592" author="hiveqa" created="Fri, 31 Oct 2014 22:03:40 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12678513/HIVE-8394.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12678513/HIVE-8394.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6608 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
org.apache.hive.minikdc.TestJdbcWithMiniKdc.testNegativeTokenAuth
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1581/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1581/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1581/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1581/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1581/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1581/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12678513 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14193564" author="mithun" created="Sat, 1 Nov 2014 23:21:08 +0000"  >&lt;p&gt;Ok, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8394&quot; title=&quot;HIVE-7803 doesn&amp;#39;t handle Pig MultiQuery, can cause data-loss.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8394&quot;&gt;&lt;del&gt;HIVE-8394&lt;/del&gt;&lt;/a&gt;.2.patch assumes FileOutputCommitters. Must switch to using the  &lt;tt&gt;baseDynamicCommitters&lt;/tt&gt; list instead.&lt;/p&gt;</comment>
                            <comment id="14193565" author="mithun" created="Sat, 1 Nov 2014 23:22:43 +0000"  >&lt;p&gt;Updated patch.&lt;/p&gt;</comment>
                            <comment id="14193584" author="mithun" created="Sat, 1 Nov 2014 23:40:18 +0000"  >&lt;p&gt;Minor logging adjustment.&lt;/p&gt;</comment>
                            <comment id="14193596" author="mithun" created="Sun, 2 Nov 2014 00:01:48 +0000"  >&lt;p&gt;Now with more logging, and ASF header.&lt;/p&gt;</comment>
                            <comment id="14193601" author="sushanth" created="Sun, 2 Nov 2014 00:08:54 +0000"  >&lt;p&gt;Okay, this .4.patch version looks good to me, +1.&lt;/p&gt;

&lt;p&gt;Awaiting test results now before committing.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hagleitn&quot; class=&quot;user-hover&quot; rel=&quot;hagleitn&quot;&gt;hagleitn&lt;/a&gt;, could we get a +1 on this for 0.14 inclusion as well?&lt;/p&gt;</comment>
                            <comment id="14193607" author="sushanth" created="Sun, 2 Nov 2014 00:10:20 +0000"  >&lt;p&gt;Precommit test link when it gets there : &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1606/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1606/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14193672" author="hiveqa" created="Sun, 2 Nov 2014 03:41:27 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12678738/HIVE-8394.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12678738/HIVE-8394.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6668 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit
org.apache.hive.minikdc.TestJdbcWithMiniKdc.testNegativeTokenAuth
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1606/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1606/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1606/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1606/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1606/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1606/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12678738 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14193696" author="hagleitn" created="Sun, 2 Nov 2014 05:06:38 +0000"  >&lt;p&gt;+1 for hive .14&lt;/p&gt;</comment>
                            <comment id="14193711" author="hagleitn" created="Sun, 2 Nov 2014 05:36:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mithun&quot; class=&quot;user-hover&quot; rel=&quot;mithun&quot;&gt;mithun&lt;/a&gt; - this looks ready, but I hear you&apos;re still testing. Is that complete?&lt;/p&gt;</comment>
                            <comment id="14194077" author="mithun" created="Sun, 2 Nov 2014 23:17:45 +0000"  >&lt;p&gt;Just completed the test with the erstwhile failing case. Success. We&apos;re good to go. &lt;/p&gt;

&lt;p&gt;Sorry for the delay. The commit-code in the end was a little different from what we were using internally, and I needed to be sure this fix was good.&lt;/p&gt;

&lt;p&gt;Thanks for holding on, Gunther.&lt;/p&gt;</comment>
                            <comment id="14194101" author="sushanth" created="Sun, 2 Nov 2014 23:49:10 +0000"  >&lt;p&gt;Good to know - I&apos;ll go ahead and commit it in both branches.&lt;/p&gt;</comment>
                            <comment id="14194102" author="sushanth" created="Sun, 2 Nov 2014 23:50:05 +0000"  >&lt;p&gt;Committed in trunk and in 0.14.&lt;/p&gt;

&lt;p&gt;Thanks, Mithun!&lt;/p&gt;</comment>
                            <comment id="14194109" author="sushanth" created="Sun, 2 Nov 2014 23:57:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;leftylev&lt;/a&gt; : No worries on documentation here, this is a bugfix. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14194153" author="lefty@hortonworks.com" created="Mon, 3 Nov 2014 01:19:58 +0000"  >&lt;p&gt;Thanks for saving me a bit of sleuthing, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;sushanth&lt;/a&gt;!  Maybe you&apos;ll start a trend....&lt;/p&gt;</comment>
                            <comment id="14210625" author="thejas" created="Thu, 13 Nov 2014 19:41:46 +0000"  >&lt;p&gt;This has been fixed in 0.14 release. Please open new jira if you see any issues.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12735500">HIVE-7803</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12674344" name="HIVE-8394.1.patch" size="8361" author="mithun" created="Sat, 11 Oct 2014 05:42:28 +0000"/>
                            <attachment id="12678513" name="HIVE-8394.2.patch" size="9589" author="mithun" created="Fri, 31 Oct 2014 18:26:06 +0000"/>
                            <attachment id="12678736" name="HIVE-8394.3.patch" size="10698" author="mithun" created="Sat, 1 Nov 2014 23:40:18 +0000"/>
                            <attachment id="12678738" name="HIVE-8394.4.patch" size="11643" author="mithun" created="Sun, 2 Nov 2014 00:01:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 1 week, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i20wuf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>