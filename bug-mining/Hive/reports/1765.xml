<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:14:24 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-5936] analyze command failing to collect stats with counter mechanism</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5936</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;With counter mechanism, MR job is successful, but StatsTask on client fails with NPE.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12682583">HIVE-5936</key>
            <summary>analyze command failing to collect stats with counter mechanism</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis Ryu</assignee>
                                    <reporter username="ashutoshc">Ashutosh Chauhan</reporter>
                        <labels>
                    </labels>
                <created>Wed, 4 Dec 2013 00:52:57 +0000</created>
                <updated>Tue, 17 Dec 2013 19:49:31 +0000</updated>
                            <resolved>Tue, 17 Dec 2013 19:49:31 +0000</resolved>
                                    <version>0.13.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                    <component>Statistics</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                <comments>
                            <comment id="13838417" author="ashutoshc" created="Wed, 4 Dec 2013 00:54:49 +0000"  >&lt;p&gt;hive&amp;gt;  analyze table over10k compute statistics;&lt;br/&gt;
Execution completed successfully&lt;br/&gt;
MapredLocal task succeeded&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;Warning&amp;#93;&lt;/span&gt; could not update stats.&lt;/p&gt;

&lt;p&gt;Log shows following exception:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; INFO  exec.Task (SessionState.java:printInfo(431)) - [Warning] could not update stats.Failed with exception &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
java.lang.NullPointerException
        at org.apache.hadoop.hive.ql.stats.CounterStatsAggregator.connect(CounterStatsAggregator.java:49)
        at org.apache.hadoop.hive.ql.exec.StatsTask.aggregateStats(StatsTask.java:194)
        at org.apache.hadoop.hive.ql.exec.StatsTask.execute(StatsTask.java:154)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1470)
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1248)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1076)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:916)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:906)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:268)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:220)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:422)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:790)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:684)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:623)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13838420" author="ashutoshc" created="Wed, 4 Dec 2013 00:56:55 +0000"  >&lt;p&gt;Following modified .q file from original patch also repro this in test case with same stacktrace.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;set hive.stats.autogather=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
set hive.stats.dbclass=counter;

create table dummy as select * from src;

set hive.stats.autogather=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
analyze table dummy compute statistics;
desc formatted dummy;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;navis&lt;/a&gt; Will you be able to take a look at this one, since this is a regression since we switched counter based mechanism as default.&lt;/p&gt;</comment>
                            <comment id="13838470" author="navis" created="Wed, 4 Dec 2013 01:44:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;ashutoshc&lt;/a&gt; Sure. I&apos;ll check this.&lt;/p&gt;</comment>
                            <comment id="13838503" author="ashutoshc" created="Wed, 4 Dec 2013 02:12:51 +0000"  >&lt;p&gt;Thanks for a quick look. Can you also add a testcase which I have above?&lt;/p&gt;</comment>
                            <comment id="13838508" author="ashutoshc" created="Wed, 4 Dec 2013 02:20:01 +0000"  >&lt;p&gt;Also what do you think of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5916&quot; title=&quot;No need to aggregate statistics collected via counter mechanism &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5916&quot;&gt;&lt;del&gt;HIVE-5916&lt;/del&gt;&lt;/a&gt;. Does it make sense ?&lt;/p&gt;</comment>
                            <comment id="13838614" author="navis" created="Wed, 4 Dec 2013 05:32:23 +0000"  >&lt;p&gt;Testing this issue, I&apos;ve confronted a problem related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3750&quot; title=&quot;JDBCStatsPublisher fails when ID length exceeds length of ID column&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3750&quot;&gt;&lt;del&gt;HIVE-3750&lt;/del&gt;&lt;/a&gt;, taking some time to tack. I&apos;ll check &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5916&quot; title=&quot;No need to aggregate statistics collected via counter mechanism &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5916&quot;&gt;&lt;del&gt;HIVE-5916&lt;/del&gt;&lt;/a&gt;, too.&lt;/p&gt;</comment>
                            <comment id="13838651" author="ashutoshc" created="Wed, 4 Dec 2013 06:08:57 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13838661" author="hiveqa" created="Wed, 4 Dec 2013 06:32:50 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12616941/HIVE-5936.2.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12616941/HIVE-5936.2.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 5 failed/errored test(s), 4455 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_udf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats19
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_noscan_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_noscan_2
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_stats3
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/509/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/509/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/509/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/509/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12616941&lt;/p&gt;</comment>
                            <comment id="13838700" author="navis" created="Wed, 4 Dec 2013 07:56:24 +0000"  >&lt;p&gt;Would it better to have -1 for not-calculated stat values? Currently, it&apos;s mixed with 0 and -1.&lt;/p&gt;</comment>
                            <comment id="13838746" author="navis" created="Wed, 4 Dec 2013 08:56:05 +0000"  >&lt;p&gt;Stat works &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5369&quot; title=&quot;Annotate hive operator tree with statistics from metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5369&quot;&gt;&lt;del&gt;HIVE-5369&lt;/del&gt;&lt;/a&gt; is not discerning 0 to -1 and vastly using the concept all over the codes. I think 0 should be mean the emptiness of table or partition and we should revive 0 from minus(invalid) stats. Can I ask your opinion &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasanth_j&quot; class=&quot;user-hover&quot; rel=&quot;prasanth_j&quot;&gt;prasanth_j&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13839029" author="ashutoshc" created="Wed, 4 Dec 2013 16:00:25 +0000"  >&lt;p&gt;Yeah, thats the idea 0 to mean empty table / partition -1 to mean unknown stat. &lt;br/&gt;
I looked at diff of &lt;tt&gt;stats_noscan_1&lt;/tt&gt; and &lt;tt&gt;stats_noscan_2&lt;/tt&gt; because of this patch and it seems what we are getting after patch is correct stats, so for this patch we can just regenerate those .q.out files. &lt;tt&gt;decimal_udf&lt;/tt&gt; failure looks unrelated to this patch.&lt;/p&gt;</comment>
                            <comment id="13839286" author="prasanth_j" created="Wed, 4 Dec 2013 20:01:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;navis&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5369&quot; title=&quot;Annotate hive operator tree with statistics from metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5369&quot;&gt;&lt;del&gt;HIVE-5369&lt;/del&gt;&lt;/a&gt; does not discern 0 to -1. The reason is that I felt even 0 (emptiness) is not very reliable. To make it more reliable in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5369&quot; title=&quot;Annotate hive operator tree with statistics from metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5369&quot;&gt;&lt;del&gt;HIVE-5369&lt;/del&gt;&lt;/a&gt; I am making another call to filesystem to check for the file size which is reliable (if metastore reports 0 then filesystem will report file size as 0). &lt;a href=&quot;https://github.com/apache/hive/blob/trunk/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java#L93&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hive/blob/trunk/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java#L93&lt;/a&gt; here I am getting raw data size from metastore. If it is not reliable I will fallback to total file size from metastore. If total file size is also not reliable then I will query the filesystem to get file size. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5921&quot; title=&quot;Better heuristics for worst case statistics estimates for join, limit and filter operator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5921&quot;&gt;&lt;del&gt;HIVE-5921&lt;/del&gt;&lt;/a&gt; needs some sort of data size (raw data size or file size) to estimate the number of rows in the absence of any statistics (worst case scenario). Since all the statistics rules in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5369&quot; title=&quot;Annotate hive operator tree with statistics from metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5369&quot;&gt;&lt;del&gt;HIVE-5369&lt;/del&gt;&lt;/a&gt; needs atleast the basic statistics (row count and data size), it is better to provide some statistics (accurate or estimated) than providing no statistics at all. &lt;/p&gt;</comment>
                            <comment id="13839635" author="navis" created="Thu, 5 Dec 2013 01:04:56 +0000"  >&lt;p&gt;For the TOTAL_SIZE, it looks fair enough. But for ROW_COUNT and RAW_DATA_SIZE which is calculated by scanning the table, the default value could be -1 returning the meaning of emptiness to &quot;zero&quot;. ie,&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;long nr = getNumRows(dbName, tabName);
long rds = getRawDataSize(dbName, tabName);

 // could be &quot;rds &amp;lt; 0&quot;
if (rds &amp;lt;= 0) {
  rds = getTotalSize(dbName, tabName);
  if (rds &amp;lt;= 0) {
    rds = getFileSizeForTable(conf, table);
  }
}
// this seemed not needed
if (nr &amp;lt; 0) {
  nr = 0;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13839684" author="prasanth_j" created="Thu, 5 Dec 2013 01:59:20 +0000"  >&lt;p&gt;Even ROW_COUNT and RAW_DATA_SIZE is not reliable. Following sequence of operations illustrate it&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;hive&amp;gt; create table test (key string, value string);
OK
Time taken: 0.069 seconds
hive&amp;gt; load data local inpath &lt;span class=&quot;code-quote&quot;&gt;&apos;/work/hive/trunk/hive-git/data/files/kv1.txt&apos;&lt;/span&gt; into table test;
Copying data from file:/work/hive/trunk/hive-git/data/files/kv1.txt
Copying file: file:/work/hive/trunk/hive-git/data/files/kv1.txt
Loading data to table &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.test
Table &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.test stats: [numFiles, numRows, totalSize, rawDataSize]
OK
Time taken: 0.231 seconds
hive&amp;gt; desc formatted test;
OK
# col_name            	data_type           	comment             
	 	 
key                 	string              	None                
value               	string              	None                
	 	 
# Detailed Table Information	 	 
Database:           	&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;             	 
Owner:              	pjayachandran       	 
CreateTime:         	Wed Dec 04 17:31:32 PST 2013	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	file:/tmp/warehouse/test	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;                
	numFiles            	1                   
	numRows             	0                   
	rawDataSize         	0                   
	totalSize           	5812                
	transient_lastDdlTime	1386207121          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
Time taken: 0.094 seconds, Fetched: 32 row(s)
hive&amp;gt; drop table test;
OK
Time taken: 0.423 seconds
hive&amp;gt; set hive.stats.autogather=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
hive&amp;gt; create table test (key string, value string);                                         
OK
Time taken: 0.03 seconds
hive&amp;gt; load data local inpath &lt;span class=&quot;code-quote&quot;&gt;&apos;/work/hive/trunk/hive-git/data/files/kv1.txt&apos;&lt;/span&gt; into table test;
Copying data from file:/work/hive/trunk/hive-git/data/files/kv1.txt
Copying file: file:/work/hive/trunk/hive-git/data/files/kv1.txt
Loading data to table &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.test
OK
Time taken: 0.097 seconds
hive&amp;gt; desc formatted test;                                                                  
OK
# col_name            	data_type           	comment             
	 	 
key                 	string              	None                
value               	string              	None                
	 	 
# Detailed Table Information	 	 
Database:           	&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;             	 
Owner:              	pjayachandran       	 
CreateTime:         	Wed Dec 04 17:32:29 PST 2013	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	file:/tmp/warehouse/test	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;               
	numFiles            	1                   
	numRows             	-1                  
	rawDataSize         	-1                  
	totalSize           	5812                
	transient_lastDdlTime	1386207152          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
Time taken: 0.061 seconds, Fetched: 32 row(s)
hive&amp;gt; set hive.stats.collect.rawdatasize=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;                                             
hive&amp;gt; analyze table test compute statistics;
Total MapReduce jobs = 1
Launching Job 1 out of 1
&lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of reduce tasks is set to 0 since there&apos;s no reduce &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;
Picked up JAVA_TOOL_OPTIONS: -Djava.awt.headless=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
Picked up JAVA_TOOL_OPTIONS: -Djava.awt.headless=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
Listening &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; transport dt_socket at address: 65378
2013-12-04 17:35:55.379 java[81428:1003] Unable to load realm info from SCDynamicStore
Execution log at: /&lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt;/folders/2w/4x52xg597k50_bt27x3_k9tw0000gn/T&lt;span class=&quot;code-comment&quot;&gt;//pjayachandran/pjayachandran_20131204173535_82f7e5c3-0016-4a63-a89c-e07b6ed07ab4.log
&lt;/span&gt;Job running in-process (local Hadoop)
Hadoop job information &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;: number of mappers: 0; number of reducers: 0
2013-12-04 17:35:57,347 &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; map = 0%,  reduce = 0%
2013-12-04 17:36:14,366 &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; map = 100%,  reduce = 0%
Ended Job = job_local124477567_0001
Execution completed successfully
MapredLocal task succeeded
Table &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.test stats: [numFiles, numRows, totalSize, rawDataSize]
OK
Time taken: 36.769 seconds
hive&amp;gt; desc formatted test;                     
OK
# col_name            	data_type           	comment             
	 	 
key                 	string              	None                
value               	string              	None                
	 	 
# Detailed Table Information	 	 
Database:           	&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;             	 
Owner:              	pjayachandran       	 
CreateTime:         	Wed Dec 04 17:32:29 PST 2013	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	file:/tmp/warehouse/test	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;                
	numFiles            	1                   
	numRows             	500                 
	rawDataSize         	0                   
	totalSize           	5812                
	transient_lastDdlTime	1386207374          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
Time taken: 0.064 seconds, Fetched: 32 row(s)
hive&amp;gt; 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As seen above, statistics are different when autostats gathering is enabled vs disabled. Also, not all SerDes support RAW_DATA_SIZE. AFAIK, LazySimpleSerde and ORC supports RAW_DATA_SIZE. LazySimpleSerde supports RAW_DATA_SIZE during INSERT operation and ANALYZE. But ORC supports only during INSERT operation. Since there are multiple codepaths/ways stats can be updated I do not think RAW_DATA_SIZE and ROW_COUNT is reliable always. &lt;/p&gt;

&lt;p&gt;Following code segment is removed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5921&quot; title=&quot;Better heuristics for worst case statistics estimates for join, limit and filter operator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5921&quot;&gt;&lt;del&gt;HIVE-5921&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (nr &amp;lt; 0) {
  nr = 0;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;instead if ROW_COUNT is &amp;lt;=0, the number of rows will be estimated based on average row size computed from schema&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (nr &amp;lt;= 0) {
        nr = 0;
        &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; avgRowSize = estimateRowSizeFromSchema(conf, schema, neededColumns);
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (avgRowSize &amp;gt; 0) {
          nr = ds / avgRowSize;
        }
       }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There is another subtask &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5949&quot; title=&quot;In statistics annotation add flag to say if statistics is estimated or accurate&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5949&quot;&gt;HIVE-5949&lt;/a&gt; which will have a flag to say if the statistics is accurate (all statistics are from metastore) or estimated. &lt;/p&gt;</comment>
                            <comment id="13839799" author="hiveqa" created="Thu, 5 Dec 2013 04:49:14 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12617108/HIVE-5936.3.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12617108/HIVE-5936.3.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 4457 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats19
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_stats3
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/524/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/524/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/524/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/524/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12617108&lt;/p&gt;</comment>
                            <comment id="13839915" author="ashutoshc" created="Thu, 5 Dec 2013 07:41:13 +0000"  >&lt;p&gt;Latest patch looks good to me. +1 Navis, can you rebase it on trunk, now that &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5916&quot; title=&quot;No need to aggregate statistics collected via counter mechanism &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5916&quot;&gt;&lt;del&gt;HIVE-5916&lt;/del&gt;&lt;/a&gt; is committed. Lets get this one in too.&lt;/p&gt;</comment>
                            <comment id="13839933" author="hiveqa" created="Thu, 5 Dec 2013 08:13:15 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12617111/HIVE-5936.4.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12617111/HIVE-5936.4.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4457 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/527/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/527/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/527/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/527/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12617111&lt;/p&gt;</comment>
                            <comment id="13840659" author="ashutoshc" created="Thu, 5 Dec 2013 22:51:00 +0000"  >&lt;p&gt;I tested &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5916&quot; title=&quot;No need to aggregate statistics collected via counter mechanism &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5916&quot;&gt;&lt;del&gt;HIVE-5916&lt;/del&gt;&lt;/a&gt; on a table having 2K partitions. It used to fail earlier because we used to run out of counters earlier. Now analyze command succeeds since we lowered the number of unique counters required. However, as you pointed out in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5916&quot; title=&quot;No need to aggregate statistics collected via counter mechanism &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5916&quot;&gt;&lt;del&gt;HIVE-5916&lt;/del&gt;&lt;/a&gt; review we still potentially can run into counter name limit for which we need to generate unique smaller string which is implemented in this patch. So, it will be good to shorten counter names when needed.&lt;br/&gt;
I also noted that client update the partition object one by one from client to metastore, which is both slow as well as error-prone. We should batch update partitions from client at end of job. Thats should be another jira.&lt;/p&gt;</comment>
                            <comment id="13842913" author="navis" created="Mon, 9 Dec 2013 05:27:42 +0000"  >&lt;p&gt;For running test. Not for a review.&lt;/p&gt;</comment>
                            <comment id="13842936" author="hiveqa" created="Mon, 9 Dec 2013 06:35:18 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12617780/HIVE-5936.5.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12617780/HIVE-5936.5.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4761 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_truncate_column
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/569/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/569/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/569/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/569/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12617780&lt;/p&gt;</comment>
                            <comment id="13843004" author="hiveqa" created="Mon, 9 Dec 2013 09:20:15 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12617792/HIVE-5936.6.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12617792/HIVE-5936.6.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/574/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/574/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/574/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/574/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-cli ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/cli/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-cli ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-cli ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/cli/target/classes
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[74,16] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[75,16] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[371,5] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[372,5] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[377,27] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[378,52] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[378,52] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[383,28] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[378,19] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[439,9] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/RCFileCat.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-cli ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-cli ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-cli ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/cli/target/test-classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/org/apache/hadoop/hive/cli/TestCliDriverMethods.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-cli ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-cli ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/hive-cli-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-cli ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/cli/target/hive-cli-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-cli/0.13.0-SNAPSHOT/hive-cli-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/cli/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-cli/0.13.0-SNAPSHOT/hive-cli-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Contrib 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-contrib ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/contrib (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-contrib ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-contrib ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-contrib ---
[INFO] Compiling 39 source files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleStructPrint.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-contrib ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-contrib ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-contrib ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/test-classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/org/apache/hadoop/hive/contrib/serde2/TestRegexSerDe.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-contrib ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-contrib ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/hive-contrib-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-contrib ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/hive-contrib-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-contrib/0.13.0-SNAPSHOT/hive-contrib-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/contrib/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-contrib/0.13.0-SNAPSHOT/hive-contrib-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HBase Handler 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hbase-handler ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hbase-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hbase-handler ---
[INFO] Compiling 17 source files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 2 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java:[42,8] org.apache.hadoop.hive.hbase.HBaseStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.Task) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [4.806s]
[INFO] Hive Ant Utilities ................................ SUCCESS [6.635s]
[INFO] Hive Shims Common ................................. SUCCESS [3.327s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [2.429s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [2.711s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.370s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [3.017s]
[INFO] Hive Shims ........................................ SUCCESS [4.024s]
[INFO] Hive Common ....................................... SUCCESS [5.472s]
[INFO] Hive Serde ........................................ SUCCESS [12.009s]
[INFO] Hive Metastore .................................... SUCCESS [26.247s]
[INFO] Hive Query Language ............................... SUCCESS [1:00.679s]
[INFO] Hive Service ...................................... SUCCESS [4.591s]
[INFO] Hive JDBC ......................................... SUCCESS [1.866s]
[INFO] Hive Beeline ...................................... SUCCESS [0.979s]
[INFO] Hive CLI .......................................... SUCCESS [1.903s]
[INFO] Hive Contrib ...................................... SUCCESS [0.958s]
[INFO] Hive HBase Handler ................................ FAILURE [1.576s]
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2:27.520s
[INFO] Finished at: Mon Dec 09 04:20:14 EST 2013
[INFO] Final Memory: 68M/506M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-hbase-handler: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java:[42,8] org.apache.hadoop.hive.hbase.HBaseStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.Task) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-hbase-handler
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12617792&lt;/p&gt;</comment>
                            <comment id="13843857" author="hiveqa" created="Tue, 10 Dec 2013 02:28:20 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12617941/HIVE-5936.7.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12617941/HIVE-5936.7.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/587/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/587/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/587/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/587/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
[INFO] Hive Integration - Test Serde
[INFO] Hive Integration - QFile Tests
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Parent 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it/0.13.0-SNAPSHOT/hive-it-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Custom Serde 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-custom-serde ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-it-custom-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-custom-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-custom-serde ---
[INFO] Compiling 8 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-it-custom-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-custom-serde ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-custom-serde ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-custom-serde ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-custom-serde ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/hive-it-custom-serde-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-custom-serde ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/hive-it-custom-serde-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-it-custom-serde/0.13.0-SNAPSHOT/hive-it-custom-serde-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it-custom-serde/0.13.0-SNAPSHOT/hive-it-custom-serde-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - HCatalog Unit Tests 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-it-unit ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-it-unit ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-it-unit ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-it-unit ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-it-unit ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-it-unit ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-it-unit ---
[INFO] Compiling 7 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-it-unit ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hcatalog-it-unit ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-hcatalog-it-unit ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog-it-unit ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/0.13.0-SNAPSHOT/hive-hcatalog-it-unit-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/0.13.0-SNAPSHOT/hive-hcatalog-it-unit-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/0.13.0-SNAPSHOT/hive-hcatalog-it-unit-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Testing Utilities 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-util ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/util (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-it-util ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-util ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-util ---
[INFO] Compiling 41 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/util/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 2 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java:[31,8] org.apache.hadoop.hive.ql.stats.KeyVerifyingStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.Task) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java:[31,8] org.apache.hadoop.hive.ql.stats.DummyStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.Task) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[INFO] 2 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Integration - Parent ......................... SUCCESS [3.689s]
[INFO] Hive Integration - Custom Serde ................... SUCCESS [8.677s]
[INFO] Hive Integration - HCatalog Unit Tests ............ SUCCESS [5.015s]
[INFO] Hive Integration - Testing Utilities .............. FAILURE [3.372s]
[INFO] Hive Integration - Unit Tests ..................... SKIPPED
[INFO] Hive Integration - Test Serde ..................... SKIPPED
[INFO] Hive Integration - QFile Tests .................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 22.338s
[INFO] Finished at: Mon Dec 09 21:28:18 EST 2013
[INFO] Final Memory: 27M/82M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-it-util: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java:[31,8] org.apache.hadoop.hive.ql.stats.KeyVerifyingStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.Task) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java:[31,8] org.apache.hadoop.hive.ql.stats.DummyStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.Task) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-it-util
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12617941&lt;/p&gt;</comment>
                            <comment id="13843876" author="ashutoshc" created="Tue, 10 Dec 2013 02:56:41 +0000"  >&lt;p&gt;Patch looks good. Left some comments on RB.&lt;/p&gt;</comment>
                            <comment id="13843987" author="navis" created="Tue, 10 Dec 2013 06:02:23 +0000"  >&lt;p&gt;Addressed comments&lt;/p&gt;</comment>
                            <comment id="13843991" author="ashutoshc" created="Tue, 10 Dec 2013 06:10:59 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13844094" author="hiveqa" created="Tue, 10 Dec 2013 08:47:13 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12617992/HIVE-5936.8.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12617992/HIVE-5936.8.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/595/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/595/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/595/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/595/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
[INFO] Hive Integration - Test Serde
[INFO] Hive Integration - QFile Tests
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Parent 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it/0.13.0-SNAPSHOT/hive-it-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Custom Serde 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-custom-serde ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-it-custom-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-custom-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-custom-serde ---
[INFO] Compiling 8 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-it-custom-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-custom-serde ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-custom-serde ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-custom-serde ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-custom-serde ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/hive-it-custom-serde-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-custom-serde ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/hive-it-custom-serde-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-it-custom-serde/0.13.0-SNAPSHOT/hive-it-custom-serde-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it-custom-serde/0.13.0-SNAPSHOT/hive-it-custom-serde-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - HCatalog Unit Tests 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-it-unit ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-it-unit ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-it-unit ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-it-unit ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-it-unit ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-it-unit ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-it-unit ---
[INFO] Compiling 7 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-it-unit ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hcatalog-it-unit ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-hcatalog-it-unit ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog-it-unit ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/0.13.0-SNAPSHOT/hive-hcatalog-it-unit-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/0.13.0-SNAPSHOT/hive-hcatalog-it-unit-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/0.13.0-SNAPSHOT/hive-hcatalog-it-unit-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Testing Utilities 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-util ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/util (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-it-util ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-util ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-util ---
[INFO] Compiling 41 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/util/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 2 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java:[31,8] org.apache.hadoop.hive.ql.stats.KeyVerifyingStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.Task) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java:[31,8] org.apache.hadoop.hive.ql.stats.DummyStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.Task) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[INFO] 2 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Integration - Parent ......................... SUCCESS [4.320s]
[INFO] Hive Integration - Custom Serde ................... SUCCESS [11.000s]
[INFO] Hive Integration - HCatalog Unit Tests ............ SUCCESS [6.159s]
[INFO] Hive Integration - Testing Utilities .............. FAILURE [3.449s]
[INFO] Hive Integration - Unit Tests ..................... SKIPPED
[INFO] Hive Integration - Test Serde ..................... SKIPPED
[INFO] Hive Integration - QFile Tests .................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 26.701s
[INFO] Finished at: Tue Dec 10 03:47:12 EST 2013
[INFO] Final Memory: 27M/82M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-it-util: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java:[31,8] org.apache.hadoop.hive.ql.stats.KeyVerifyingStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.Task) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java:[31,8] org.apache.hadoop.hive.ql.stats.DummyStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.Task) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-it-util
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12617992&lt;/p&gt;</comment>
                            <comment id="13845112" author="ashutoshc" created="Wed, 11 Dec 2013 05:58:30 +0000"  >&lt;p&gt;Marking Patch Available to get Hive QA run.&lt;/p&gt;</comment>
                            <comment id="13845307" author="hiveqa" created="Wed, 11 Dec 2013 11:07:54 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12618158/HIVE-5936.9.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12618158/HIVE-5936.9.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 5 failed/errored test(s), 4762 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_aggregator_error_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_publisher_error_1
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_stats_aggregator_error_1
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_stats_aggregator_error_2
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_stats_publisher_error_2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/612/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/612/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/612/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/612/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12618158&lt;/p&gt;</comment>
                            <comment id="13846004" author="navis" created="Thu, 12 Dec 2013 02:16:49 +0000"  >&lt;p&gt;Fixed error message&lt;/p&gt;</comment>
                            <comment id="13846122" author="hiveqa" created="Thu, 12 Dec 2013 07:40:22 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12618345/HIVE-5936.10.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12618345/HIVE-5936.10.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4763 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/620/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/620/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/620/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/620/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12618345&lt;/p&gt;</comment>
                            <comment id="13848768" author="hiveqa" created="Mon, 16 Dec 2013 02:39:07 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12618835/HIVE-5936.11.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12618835/HIVE-5936.11.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4785 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/643/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/643/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/643/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/643/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12618835&lt;/p&gt;</comment>
                            <comment id="13850824" author="ashutoshc" created="Tue, 17 Dec 2013 19:49:31 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12682245">HIVE-5916</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12616925" name="HIVE-5936.1.patch.txt" size="3045" author="navis" created="Wed, 4 Dec 2013 02:09:09 +0000"/>
                            <attachment id="12618345" name="HIVE-5936.10.patch.txt" size="71479" author="navis" created="Thu, 12 Dec 2013 02:16:49 +0000"/>
                            <attachment id="12618835" name="HIVE-5936.11.patch.txt" size="75367" author="navis" created="Mon, 16 Dec 2013 01:25:16 +0000"/>
                            <attachment id="12616941" name="HIVE-5936.2.patch.txt" size="17584" author="navis" created="Wed, 4 Dec 2013 05:30:18 +0000"/>
                            <attachment id="12617108" name="HIVE-5936.3.patch.txt" size="29156" author="navis" created="Thu, 5 Dec 2013 03:38:07 +0000"/>
                            <attachment id="12617111" name="HIVE-5936.4.patch.txt" size="31254" author="navis" created="Thu, 5 Dec 2013 05:05:16 +0000"/>
                            <attachment id="12617780" name="HIVE-5936.5.patch.txt" size="55017" author="navis" created="Mon, 9 Dec 2013 05:27:21 +0000"/>
                            <attachment id="12617792" name="HIVE-5936.6.patch.txt" size="63327" author="navis" created="Mon, 9 Dec 2013 07:46:30 +0000"/>
                            <attachment id="12617941" name="HIVE-5936.7.patch.txt" size="64309" author="navis" created="Tue, 10 Dec 2013 00:33:13 +0000"/>
                            <attachment id="12617992" name="HIVE-5936.8.patch.txt" size="64140" author="navis" created="Tue, 10 Dec 2013 06:02:23 +0000"/>
                            <attachment id="12618158" name="HIVE-5936.9.patch.txt" size="66156" author="navis" created="Wed, 11 Dec 2013 01:50:34 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>361840</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 49 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qdg7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>362137</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>