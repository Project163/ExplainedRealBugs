<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:52:11 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-15997] Resource leaks when query is cancelled </title>
                <link>https://issues.apache.org/jira/browse/HIVE-15997</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;There may some resource leaks when query is cancelled.&lt;br/&gt;
We see following stacks in the log:&lt;/p&gt;

&lt;p&gt;Possible files and folder leak: &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; 
2017-02-02 06:23:25,410 WARN hive.ql.Context: [HiveServer2-Background-Pool: Thread-61]: Error Removing Scratch: java.io.IOException: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: &quot;ychencdh511t-1.vpc.cloudera.com/172.26.11.50&quot;; destination host is: &quot;ychencdh511t-1.vpc.cloudera.com&quot;:8020; 
at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772) 
at org.apache.hadoop.ipc.Client.call(Client.java:1476) 
at org.apache.hadoop.ipc.Client.call(Client.java:1409) 
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230) 
at com.sun.proxy.$Proxy25.delete(Unknown Source) 
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:535)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) 
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) 
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) 
at java.lang.reflect.Method.invoke(Method.java:606) 
at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256) 
at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104) 
at com.sun.proxy.$Proxy26.delete(Unknown Source) 
at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:2059) 
at org.apache.hadoop.hdfs.DistributedFileSystem$13.doCall(DistributedFileSystem.java:675) 
at org.apache.hadoop.hdfs.DistributedFileSystem$13.doCall(DistributedFileSystem.java:671) 
at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) 
at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:671) 
at org.apache.hadoop.hive.ql.Context.removeScratchDir(Context.java:405) 
at org.apache.hadoop.hive.ql.Context.clear(Context.java:541) 
at org.apache.hadoop.hive.ql.Driver.releaseContext(Driver.java:2109) 
at org.apache.hadoop.hive.ql.Driver.closeInProcess(Driver.java:2150) 
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1472) 
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1212) 
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1207) 
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:237) 
at org.apache.hive.service.cli.operation.SQLOperation.access$300(SQLOperation.java:88) 
at org.apache.hive.service.cli.operation.SQLOperation$3$1.run(SQLOperation.java:293) 
at java.security.AccessController.doPrivileged(Native Method) 
at javax.security.auth.Subject.doAs(Subject.java:415) 
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1796) 
at org.apache.hive.service.cli.operation.SQLOperation$3.run(SQLOperation.java:306) 
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) 
at java.util.concurrent.FutureTask.run(FutureTask.java:262) 
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) 
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) 
at java.lang.Thread.run(Thread.java:745) 
Caused by: java.nio.channels.ClosedByInterruptException 
at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202) 
at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:681) 
at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192) 
at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530) 
at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494) 
at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) 
at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:714) 
at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) 
at org.apache.hadoop.ipc.Client.getConnection(Client.java:1525) 
at org.apache.hadoop.ipc.Client.call(Client.java:1448) 
... 35 more 

2017-02-02 12:26:52,706 INFO org.apache.hive.service.cli.operation.OperationManager: [HiveServer2-Background-Pool: Thread-23]: Operation is timed out,operation=OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=2af82100-94cf-4f26-abaa-c4b57c57b23c],state=CANCELED 
{format} 

Possible lock leak:

Locks leak:
{format}
2017-02-02 06:21:05,054 ERROR ZooKeeperHiveLockManager: [HiveServer2-Background-Pool: Thread-61]: Failed to release ZooKeeper lock: 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:503)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:871)
	at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:238)
	at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:233)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230)
	at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:214)
	at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:41)
	at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.unlockPrimitive(ZooKeeperHiveLockManager.java:488)
	at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.unlockWithRetry(ZooKeeperHiveLockManager.java:466)
	at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.unlock(ZooKeeperHiveLockManager.java:454)
	at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.releaseLocks(ZooKeeperHiveLockManager.java:236)
	at org.apache.hadoop.hive.ql.Driver.releaseLocksAndCommitOrRollback(Driver.java:1175)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1432)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1212)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1207)
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:237)
	at org.apache.hive.service.cli.operation.SQLOperation.access$300(SQLOperation.java:88)
	at org.apache.hive.service.cli.operation.SQLOperation$3$1.run(SQLOperation.java:293)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1796)
	at org.apache.hive.service.cli.operation.SQLOperation$3.run(SQLOperation.java:306)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13044888">HIVE-15997</key>
            <summary>Resource leaks when query is cancelled </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ychena">Yongzhi Chen</assignee>
                                    <reporter username="ychena">Yongzhi Chen</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Feb 2017 16:49:46 +0000</created>
                <updated>Fri, 21 Jul 2017 18:36:01 +0000</updated>
                            <resolved>Wed, 8 Mar 2017 17:52:24 +0000</resolved>
                                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15892783" author="ychena" created="Thu, 2 Mar 2017 18:53:14 +0000"  >&lt;p&gt;Reproduce the issue in CDH by canceling a query after compile query and acquire locks and just before the job is really submitted to yarn. &lt;/p&gt;

&lt;p&gt;Fix it by:&lt;br/&gt;
1. Try to cancel query gracefully by removing some interrupting threads code. &lt;br/&gt;
2. When thread is interrupted when releasing locks, it will retry once. &lt;/p&gt;</comment>
                            <comment id="15893510" author="hiveqa" created="Fri, 3 Mar 2017 01:01:54 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12855667/HIVE-15997.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12855667/HIVE-15997.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 10 failed/errored test(s), 10281 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestCommandProcessorFactory - did not produce a TEST-*.xml file (likely timed out) (batchId=272)
TestDbTxnManager - did not produce a TEST-*.xml file (likely timed out) (batchId=272)
TestDummyTxnManager - did not produce a TEST-*.xml file (likely timed out) (batchId=272)
TestHiveInputSplitComparator - did not produce a TEST-*.xml file (likely timed out) (batchId=272)
TestIndexType - did not produce a TEST-*.xml file (likely timed out) (batchId=272)
TestSplitFilter - did not produce a TEST-*.xml file (likely timed out) (batchId=272)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[escape_comments] (batchId=229)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_table] (batchId=147)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_between_in] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver (batchId=231)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/3899/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/3899/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/3899/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/3899/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-3899/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-3899/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 10 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12855667 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15894413" author="ychena" created="Fri, 3 Mar 2017 14:04:48 +0000"  >&lt;p&gt;The failures are not related.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ctang.ma&quot; class=&quot;user-hover&quot; rel=&quot;ctang.ma&quot;&gt;ctang.ma&lt;/a&gt;, could you review the change?  Thanks&lt;/p&gt;</comment>
                            <comment id="15897742" author="ctang.ma" created="Mon, 6 Mar 2017 18:03:03 +0000"  >&lt;p&gt;Will TezTask be affected as well? Also I am not quite sure about this, for the code like this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      
&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
        curatorFramework.delete().forPath(zLock.getPath());
      } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (InterruptedException ie) {
        curatorFramework.delete().forPath(zLock.getPath());
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;catching InterruptedException will guarantee to clear the interrupted flag in the thread and calling the method second time will guarantee to succeed?&lt;/p&gt;</comment>
                            <comment id="15898157" author="ychena" created="Mon, 6 Mar 2017 21:36:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ctang.ma&quot; class=&quot;user-hover&quot; rel=&quot;ctang.ma&quot;&gt;ctang.ma&lt;/a&gt;&lt;br/&gt;
Remove Thread.currentThread().interrupt(); from isInterrupted()  is just to avoid setting the interrupted flag too early and many times. The Tasks will be stopped by DriverContext&apos;s shutdown() method.  The method will call  thread.interrupt();  So TezTask will not affect by the change, and the queries use the TezTask can benefit with the change. &lt;br/&gt;
Other changes in ExecDriver may speed up query response time for cancelling when running with MR. &lt;/p&gt;

&lt;p&gt;For ZooKeeper catch InterruptedException:&lt;br/&gt;
When the InterruptedException is thrown, the thread is already interrupted. It should not be interrupted again. As to my tests, the second time succeed. That mean, when the InterruptedExcetion is thrown for this zookeeper case, the interrupted status is cleared. &lt;/p&gt;


</comment>
                            <comment id="15900049" author="ctang.ma" created="Tue, 7 Mar 2017 20:00:39 +0000"  >&lt;p&gt;LGTM, +1&lt;/p&gt;</comment>
                            <comment id="15901654" author="ychena" created="Wed, 8 Mar 2017 17:52:24 +0000"  >&lt;p&gt;Push the fix into master. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ctang.ma&quot; class=&quot;user-hover&quot; rel=&quot;ctang.ma&quot;&gt;ctang.ma&lt;/a&gt; for reviewing the code. &lt;/p&gt;</comment>
                            <comment id="15987880" author="xuefuz" created="Thu, 27 Apr 2017 23:22:56 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ychena&quot; class=&quot;user-hover&quot; rel=&quot;ychena&quot;&gt;ychena&lt;/a&gt;/&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ctang.ma&quot; class=&quot;user-hover&quot; rel=&quot;ctang.ma&quot;&gt;ctang.ma&lt;/a&gt;, Thanks for looking into this. I&apos;m trying to understand the patch, as I&apos;m reviewing &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-16552&quot; title=&quot;Limit the number of tasks a Spark job may contain&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-16552&quot;&gt;&lt;del&gt;HIVE-16552&lt;/del&gt;&lt;/a&gt;, which refers to this JIRA. Specifically, I don&apos;t quite understand the following code addtion:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;       rj = jc.submitJob(job);
+
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (driverContext.isShutdown()) {
+        LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Task was cancelled&quot;&lt;/span&gt;);
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (rj != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
+          rj.killJob();
+          rj = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
+        }
+        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; 5;
+      }
+
       &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.jobID = rj.getJobID();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I understand we are checking if query is cancelled right after submission. However, my question is whether this check is necessary or complete as right after this check the query can become cancelled, which the check will not capture. If such cancellation is captured later in other code path, then the check here seems not necessary. Otherwise, this check will not capture all scenarios.&lt;/p&gt;

&lt;p&gt;Did I miss anything? Thanks.&lt;/p&gt;</comment>
                            <comment id="15988020" author="ychena" created="Fri, 28 Apr 2017 01:39:41 +0000"  >&lt;p&gt;The shutdown will check the running list and shutdown each task in the list, shutdown on the task will stop the query because of failed task. But there are some chances the task is removed from the list(finished for example) when the shutdown happens. Add the if (driverContext.isShutdown()) may help this scenario. Even if later we can catch the cancel, it is the most prompt one. And if (driverContext.isShutdown()) check is not expensive call, so I think it is OK to have the check. &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; /**
   * Cleans up remaining tasks in case of failure
   */
  public synchronized void shutdown() {
    LOG.debug(&quot;Shutting down query &quot; + ctx.getCmd());
    shutdown = true;
    for (TaskRunner runner : running) {
      if (runner.isRunning()) {
        Task&amp;lt;?&amp;gt; task = runner.getTask();
        LOG.warn(&quot;Shutting down task : &quot; + task);
        try {
          task.shutdown();
        } catch (Exception e) {
          console.printError(&quot;Exception on shutting down task &quot; + task.getId() + &quot;: &quot; + e);
        }
        Thread thread = runner.getRunner();
        if (thread != null) {
          thread.interrupt();
        }
      }
    }
    running.clear();
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15988193" author="xuefuz" created="Fri, 28 Apr 2017 04:46:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ychena&quot; class=&quot;user-hover&quot; rel=&quot;ychena&quot;&gt;ychena&lt;/a&gt;, Thanks for the explanation. I wasn&apos;t questioning the code change. Rather, I was trying to understand whether the solution is complete. That is, is it possible to leak resources with the patch when a query is cancelled. You seemed suggesting the second check is nice to have, but I really like to know what part of code change fixed the root cause of the resource leak problem. Any further thoughts? Thanks.&lt;/p&gt;</comment>
                            <comment id="15991745" author="ychena" created="Mon, 1 May 2017 23:12:14 +0000"  >&lt;p&gt;657	      if (lDrvState.driverState == DriverState.INTERRUPT) {	657	      if (lDrvState.driverState == DriverState.INTERRUPT) {&lt;br/&gt;
658	        Thread.currentThread().interrupt();		&lt;br/&gt;
659	        return true;	658	        return true;&lt;/p&gt;

&lt;p&gt;Remove Thread.currentThread().interrupt();	 // can solve some of the resource leaks (depend on the cancel time), it let the query closed gracefully instead of being interrupted during files clean up. &lt;br/&gt;
And &lt;br/&gt;
The fixes in zookeeper code can fix the lock leaks in my test case. &lt;/p&gt;
</comment>
                            <comment id="15998861" author="xuefuz" created="Fri, 5 May 2017 19:43:47 +0000"  >&lt;p&gt;Thanks for the explanation, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ychena&quot; class=&quot;user-hover&quot; rel=&quot;ychena&quot;&gt;ychena&lt;/a&gt;. One more question: which part of the code was handling the InterruptedException that Thread.currentThread().interrupt() throws? I was wondering if there is any side-effect after the thrower is removed. Thanks.&lt;/p&gt;</comment>
                            <comment id="15998961" author="ychena" created="Fri, 5 May 2017 21:15:21 +0000"  >&lt;p&gt;This interrupt() in our code can cause InterruptedException when the code is doing(or is scheduled to do) hdfs file operations or zookeeper lock operations. For we do not have many long single file operations or long single lock operations, but we do have many fast operations, the performance of cancel operation will not affect by adding checkpoints . I found that the thread interrupt() has no effect for some running operations: for example I tried to interrupt HMS client who is waiting for a response of a long running API (for example ListPartitions), the interrupt can not stop the waiting at all. And the interrupt has some &quot;delay effect&quot;, it causes InterruptedException later (for example when the cleanup folder operations happen.) So we should not put the Thread.currentThread().interrupt() in the heavily used method isInterrupted().  if, in the future, we find the place the interrupt() is really needed, we can just add the code there. &lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12855667" name="HIVE-15997.1.patch" size="6564" author="ychena" created="Thu, 2 Mar 2017 18:53:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 28 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3adxr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>