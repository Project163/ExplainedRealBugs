<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:31:04 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-9934] Vulnerability in LdapAuthenticationProviderImpl enables HiveServer2 client to degrade the authentication mechanism to &quot;none&quot;, allowing authentication without password</title>
                <link>https://issues.apache.org/jira/browse/HIVE-9934</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Vulnerability in LdapAuthenticationProviderImpl enables HiveServer2 client to degrade the authentication mechanism to &quot;none&quot;, allowing authentication without password.&lt;/p&gt;

&lt;p&gt;See: &lt;a href=&quot;http://docs.oracle.com/javase/jndi/tutorial/ldap/security/simple.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://docs.oracle.com/javase/jndi/tutorial/ldap/security/simple.html&lt;/a&gt;&lt;br/&gt;
&#8220;If you supply an empty string, an empty byte/char array, or null to the Context.SECURITY_CREDENTIALS environment property, then the authentication mechanism will be &quot;none&quot;. This is because the LDAP requires the password to be nonempty for simple authentication. The protocol automatically converts the authentication to &quot;none&quot; if a password is not supplied.&#8221;&lt;/p&gt;

&lt;p&gt;Since the LdapAuthenticationProviderImpl.Authenticate method is relying on a NamingException being thrown during creation of initial context, it does not fail when the context result is an &#8220;unauthenticated&#8221; positive response from the LDAP server. The end result is, one can authenticate with HiveServer2 using the LdapAuthenticationProviderImpl with only a user name and an empty password.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12781323">HIVE-9934</key>
            <summary>Vulnerability in LdapAuthenticationProviderImpl enables HiveServer2 client to degrade the authentication mechanism to &quot;none&quot;, allowing authentication without password</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="csun">Chao Sun</assignee>
                                    <reporter username="csun">Chao Sun</reporter>
                        <labels>
                    </labels>
                <created>Wed, 11 Mar 2015 21:11:38 +0000</created>
                <updated>Mon, 18 May 2015 19:50:15 +0000</updated>
                            <resolved>Tue, 17 Mar 2015 22:06:48 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>1.2.0</fixVersion>
                                    <component>Security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="14357669" author="csun" created="Wed, 11 Mar 2015 21:41:56 +0000"  >&lt;p&gt;Check if password is null or blank. If so, throw exception.&lt;/p&gt;</comment>
                            <comment id="14358251" author="hiveqa" created="Thu, 12 Mar 2015 07:58:28 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12704024/HIVE-9934.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12704024/HIVE-9934.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 7762 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3012/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3012/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3012/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3012/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3012/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3012/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12704024 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14363920" author="csun" created="Mon, 16 Mar 2015 20:55:46 +0000"  >&lt;p&gt;(cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;prasadm&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;xuefuz&lt;/a&gt;). I was able to reproduce the issue after disabling JDBC authentication and use the Hadoop provided &lt;tt&gt;SaslPlainServerFactory&lt;/tt&gt;. I need to do the latter because Hive provided Sasl server implementation checks the case when password is empty, therefore the issue could be prevented. However, if the Hadoop version class gets loaded first (which doesn&apos;t check whether password is null or empty), then the issue could still happen.&lt;/p&gt;

&lt;p&gt;In this patch I also included a simple uni test. Desirably we should write an end-to-end test, however that involves non-trivial work. I&apos;ll put that in a follow-up JIRA.&lt;/p&gt;</comment>
                            <comment id="14364092" author="xuefuz" created="Mon, 16 Mar 2015 22:26:41 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14364424" author="hiveqa" created="Tue, 17 Mar 2015 02:09:23 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12704870/HIVE-9934.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12704870/HIVE-9934.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 7769 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestCustomAuthentication - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_percentile_approx_23
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3047/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3047/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3047/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3047/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3047/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3047/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12704870 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14364462" author="csun" created="Tue, 17 Mar 2015 02:47:44 +0000"  >&lt;p&gt;There&apos;s a redundant field &lt;tt&gt;hiveServer2&lt;/tt&gt; in the previous patch. This patch removes it - it shouldn&apos;t affect test results.&lt;/p&gt;</comment>
                            <comment id="14365024" author="hiveqa" created="Tue, 17 Mar 2015 11:55:38 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12704981/HIVE-9934.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12704981/HIVE-9934.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 7770 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3053/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3053/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3053/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3053/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3053/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3053/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12704981 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14365037" author="csun" created="Tue, 17 Mar 2015 12:11:26 +0000"  >&lt;p&gt;Found this in log: &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2015-03-17 04:33:32,728 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 2015-03-17 04:33:32,725 INFO  [pool-1-thread-1] client.RemoteDriver (RemoteDriver.java:call(371)) - Failed to run job 681ccfbe-bf9f-491c-a2e7-ad513f62d1dc
2015-03-17 04:33:32,728 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - java.util.concurrent.ExecutionException: Exception thrown by job
2015-03-17 04:33:32,728 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.JavaFutureActionWrapper.getImpl(FutureAction.scala:311)
2015-03-17 04:33:32,728 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.JavaFutureActionWrapper.get(FutureAction.scala:316)
2015-03-17 04:33:32,728 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.hive.spark.client.RemoteDriver$JobWrapper.call(RemoteDriver.java:364)
2015-03-17 04:33:32,728 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.hive.spark.client.RemoteDriver$JobWrapper.call(RemoteDriver.java:317)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at java.lang.Thread.run(Thread.java:744)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, ip-10-182-56-7.ec2.internal): java.io.FileNotFoundException: http://10.182.56.7:34690/jars/hive-exec-1.2.0-SNAPSHOT.jar
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1624)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:452)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.util.Utils$.fetchFile(Utils.scala:383)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$6.apply(Executor.scala:350)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$6.apply(Executor.scala:347)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
2015-03-17 04:33:32,729 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$updateDependencies(Executor.scala:347)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:177)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at java.lang.Thread.run(Thread.java:744)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - Driver stacktrace:
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1214)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1203)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1202)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1202)
2015-03-17 04:33:32,730 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:696)
2015-03-17 04:33:32,731 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:696)
2015-03-17 04:33:32,731 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at scala.Option.foreach(Option.scala:236)
2015-03-17 04:33:32,731 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:696)
2015-03-17 04:33:32,731 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1420)
2015-03-17 04:33:32,731 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
2015-03-17 04:33:32,731 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(537)) - 	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor.aroundReceive(DAGScheduler.scala:137
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I don&apos;t think this is relevant to my patch.&lt;/p&gt;</comment>
                            <comment id="14365161" author="xuefuz" created="Tue, 17 Mar 2015 14:16:58 +0000"  >&lt;p&gt;Attached the same patch for another test run.&lt;/p&gt;</comment>
                            <comment id="14365402" author="hiveqa" created="Tue, 17 Mar 2015 16:08:09 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12705088/HIVE-9934.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12705088/HIVE-9934.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 7770 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3056/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3056/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3056/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3056/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3056/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3056/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12705088 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14365584" author="prasadm" created="Tue, 17 Mar 2015 17:26:14 +0000"  >&lt;p&gt;Looks fine to me.&lt;br/&gt;
BTW, testLdapEmptyPassword() is missing the Test annotation.&lt;/p&gt;</comment>
                            <comment id="14365832" author="xuefuz" created="Tue, 17 Mar 2015 19:14:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;prasadm&lt;/a&gt;, I think lacking @Test seems fine in this case, as the class is extended from TestCase. I also saw the added test case was run in previous test result. Thus, patch #3 is good as far as I can see. Let me know if you see differently.&lt;/p&gt;
</comment>
                            <comment id="14365839" author="prasadm" created="Tue, 17 Mar 2015 19:18:46 +0000"  >&lt;p&gt;That&apos;s fine. The test did get run in the pre-commit run for patch #3. sorry about the noise.&lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14366184" author="xuefuz" created="Tue, 17 Mar 2015 22:06:48 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Chao.&lt;/p&gt;</comment>
                            <comment id="14369465" author="thejas" created="Thu, 19 Mar 2015 15:02:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;I was able to reproduce the issue after disabling JDBC authentication and use the Hadoop provided SaslPlainServerFactory. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt; Can you please elaborate on what you had do to reproduce this ? What do you mean by disabling JDBC authentication ? (I assume we need to set hive.server2.authentication=LDAP for this scenario). Also, since the SaslPlainServerFactory in hive in a different package, does changing the classpath alone result in the Hadoop provided SaslPlainServerFactory getting used ?&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vgumashta&quot; class=&quot;user-hover&quot; rel=&quot;vgumashta&quot;&gt;vgumashta&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14369918" author="lefty@hortonworks.com" created="Thu, 19 Mar 2015 19:03:09 +0000"  >&lt;p&gt;What documentation does this need?&lt;/p&gt;</comment>
                            <comment id="14369942" author="prasadm" created="Thu, 19 Mar 2015 19:14:57 +0000"  >&lt;p&gt;Hive&apos;s SaslPlainServer actually throws an exception for empty or null password. When Hadoop implemented it&apos;s own plain Sasl server, we are potentially exposed to this LDAP vulnerability. The sasl service registration happens via static code block and hence we can&apos;t guarantee which Sasl server will be used.&lt;br/&gt;
Anycase, since this is LDAP specific behavior, it&apos;s better to guard it in LDAP provider rather than depending on the underlying Sasl implementation.&lt;/p&gt;</comment>
                            <comment id="14370174" author="xuefuz" created="Thu, 19 Mar 2015 21:38:15 +0000"  >&lt;p&gt;Apache has special guidelines regarding security vulnerabilities. Here is the link:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.apache.org/security/committers&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/security/committers&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We are all new to this, so what we have done so far may not comply to this. However, we should try to do so from now on.&lt;/p&gt;

&lt;p&gt;For doc, please also refer to the document.&lt;/p&gt;

&lt;p&gt;AS to the vulnerability, discussion is still ongoing in the community. Thus, we will act based on the conclusions.&lt;/p&gt;</comment>
                            <comment id="14370441" author="csun" created="Fri, 20 Mar 2015 00:29:20 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;thejas&lt;/a&gt;, for JDBC, I need to modify the code. In HiveConnection, when password is empty, it will change it to &quot;anonymous&quot;. Since I&apos;m using JDBC + Beeline to reproduce the issue, I need to change it so that the password will still remain empty.&lt;/p&gt;

&lt;p&gt;For SaslPlainServerFactory, sorry my previous comment wasn&apos;t precise. Here, even though from different packages. they are added via different Providers with the same key (&quot;SaslServerFactory.PLAIN&quot;). Later, when searching for a particular key, it always choose the first Provider that matches. Since the Providers are added in static blocks, the order may not be deterministic. Hence, if the Hadoop one is picked, security issue could happen.&lt;/p&gt;</comment>
                            <comment id="14370602" author="thejas" created="Fri, 20 Mar 2015 02:39:42 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;prasadm&lt;/a&gt; !&lt;br/&gt;
However, looking at the hadoop code, it does not seem to get added via static code blocks (unlike the hive one). It gets initialized through calls to SaslRpcServer.init(). So it looks like the hive one would get added first, and the hadoop one would get added next (when hive functions such as HadoopThriftAuthBridge23.getHadoopSaslProperties are called. This is then getting stored in a HashTable, which means that the second one is what would get used. It seems like the hadoop one would always get used. (I haven&apos;t verified this by testing).&lt;/p&gt;</comment>
                            <comment id="14370664" author="csun" created="Fri, 20 Mar 2015 03:52:01 +0000"  >&lt;p&gt;Yes, hadoop doesn&apos;t use static blocks. But, since Hive class still have it, the order could still vary depending on when the class is loaded, right?&lt;br/&gt;
Looks like SaslRpcServer.init() is called in several places. I debugged it a little, there&apos;s one call site in org.apache.hadoop.ipc.RPC which is surrounded by a conditional stat. It might be called before the static block is called (although in different thread), if the condition is true. The execution didn&apos;t reach HadoopThriftAuthBridge23.getHadoopSaslProperties in my test.&lt;/p&gt;

&lt;p&gt;Looks like new Provider is always added to the end of an ArrayList, and therefore the one added earlier will be used.&lt;/p&gt;</comment>
                            <comment id="14548725" author="sushanth" created="Mon, 18 May 2015 19:50:15 +0000"  >&lt;p&gt;This issue has been fixed and released as part of the 1.2.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12782573">HIVE-9990</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12704024" name="HIVE-9934.1.patch" size="1014" author="csun" created="Wed, 11 Mar 2015 21:41:56 +0000"/>
                            <attachment id="12704870" name="HIVE-9934.2.patch" size="2818" author="csun" created="Mon, 16 Mar 2015 20:55:46 +0000"/>
                            <attachment id="12705088" name="HIVE-9934.3.patch" size="2723" author="xuefuz" created="Tue, 17 Mar 2015 14:16:58 +0000"/>
                            <attachment id="12704981" name="HIVE-9934.3.patch" size="2723" author="csun" created="Tue, 17 Mar 2015 02:47:44 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 27 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i26npr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>