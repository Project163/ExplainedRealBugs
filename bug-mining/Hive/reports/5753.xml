<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:56:07 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-16948] Invalid explain when running dynamic partition pruning query in Hive On Spark</title>
                <link>https://issues.apache.org/jira/browse/HIVE-16948</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;in &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/test/queries/clientpositive/spark_dynamic_partition_pruning.q#L107&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;union_subquery.q&lt;/a&gt; in spark_dynamic_partition_pruning.q&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;set hive.optimize.ppd=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
set hive.ppd.remove.duplicatefilters=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
set hive.spark.dynamic.partition.pruning=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
set hive.optimize.metadataonly=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
set hive.optimize.index.filter=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
set hive.strict.checks.cartesian.product=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
explain select ds from (select distinct(ds) as ds from srcpart union all select distinct(ds) as ds from srcpart) s where s.ds in (select max(srcpart.ds) from srcpart union all select min(srcpart.ds) from srcpart);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;explain &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
      Edges:
        Reducer 11 &amp;lt;- Map 10 (GROUP, 1)
        Reducer 13 &amp;lt;- Map 12 (GROUP, 1)
      DagName: root_20170622231525_20a777e5-e659-4138-b605-65f8395e18e2:2
      Vertices:
        Map 10 
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE
                  Select Operator
                    expressions: ds (type: string)
                    outputColumnNames: ds
                    Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE
                    Group By Operator
                      aggregations: max(ds)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        sort order: 
                        Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: string)
        Map 12 
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE
                  Select Operator
                    expressions: ds (type: string)
                    outputColumnNames: ds
                    Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE
                    Group By Operator
                      aggregations: min(ds)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        sort order: 
                        Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: string)
        Reducer 11 
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: _col0 is not &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; (type: &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;)
                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    keys: _col0 (type: string)
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: string)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                        Spark Partition Pruning Sink Operator
                          partition key expr: ds
                          Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                          target column name: ds
                          target work: Map 1
                    Select Operator
                      expressions: _col0 (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: string)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                        Spark Partition Pruning Sink Operator
                          partition key expr: ds
                          Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                          target column name: ds
                          target work: Map 4
        Reducer 13 
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: _col0 is not &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; (type: &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;)
                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    keys: _col0 (type: string)
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: string)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                        Spark Partition Pruning Sink Operator
                          partition key expr: ds
                          Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                          target column name: ds
                          target work: Map 1
                    Select Operator
                      expressions: _col0 (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: string)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                        Spark Partition Pruning Sink Operator
                          partition key expr: ds
                          Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                          target column name: ds
                          target work: Map 4

  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 &amp;lt;- Map 1 (GROUP, 2)
        Reducer 3 &amp;lt;- Reducer 2 (PARTITION-LEVEL SORT, 2), Reducer 2 (PARTITION-LEVEL SORT, 2), Reducer 7 (PARTITION-LEVEL SORT, 2), Reducer 9 (PARTITION-LEVEL SORT, 2)
        Reducer 7 &amp;lt;- Map 6 (GROUP, 1)
        Reducer 9 &amp;lt;- Map 8 (GROUP, 1)
      DagName: root_20170622231525_20a777e5-e659-4138-b605-65f8395e18e2:1
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  filterExpr: ds is not &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; (type: &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;)
                  Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE
                  Group By Operator
                    keys: ds (type: string)
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 23248 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Map-reduce partition columns: _col0 (type: string)
                      Statistics: Num rows: 1 Data size: 23248 Basic stats: COMPLETE Column stats: NONE
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE
                  Select Operator
                    expressions: ds (type: string)
                    outputColumnNames: ds
                    Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE
                    Group By Operator
                      aggregations: max(ds)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        sort order: 
                        Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: string)
        Map 8 
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE
                  Select Operator
                    expressions: ds (type: string)
                    outputColumnNames: ds
                    Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE
                    Group By Operator
                      aggregations: min(ds)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        sort order: 
                        Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col0 (type: string)
        Reducer 2 
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 23248 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 2 Data size: 46496 Basic stats: COMPLETE Column stats: NONE
        Reducer 3 
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Left Semi Join 0 to 1
                keys:
                  0 _col0 (type: string)
                  1 _col0 (type: string)
                outputColumnNames: _col0
                Statistics: Num rows: 2 Data size: 51145 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
                  Statistics: Num rows: 2 Data size: 51145 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 7 
            Reduce Operator Tree:
              Group By Operator
                aggregations: max(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: _col0 is not &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; (type: &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;)
                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    keys: _col0 (type: string)
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Map-reduce partition columns: _col0 (type: string)
                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
        Reducer 9 
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: _col0 is not &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; (type: &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;)
                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                  Group By Operator
                    keys: _col0 (type: string)
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: string)
                      sort order: +
                      Map-reduce partition columns: _col0 (type: string)
                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;the target work of Reducer11 and Reducer13 is Map4 , but Map4 does not exist in the explain &lt;/p&gt;</description>
                <environment></environment>
        <key id="13081984">HIVE-16948</key>
            <summary>Invalid explain when running dynamic partition pruning query in Hive On Spark</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kellyzly">liyunzhang</assignee>
                                    <reporter username="kellyzly">liyunzhang</reporter>
                        <labels>
                    </labels>
                <created>Fri, 23 Jun 2017 03:23:30 +0000</created>
                <updated>Tue, 22 May 2018 23:59:24 +0000</updated>
                            <resolved>Fri, 18 Aug 2017 07:26:53 +0000</resolved>
                                                    <fixVersion>3.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="16060371" author="pxiong" created="Fri, 23 Jun 2017 03:28:31 +0000"  >&lt;p&gt;HoS? Hive on Spark?&lt;/p&gt;</comment>
                            <comment id="16060374" author="kellyzly" created="Fri, 23 Jun 2017 03:30:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pxiong&quot; class=&quot;user-hover&quot; rel=&quot;pxiong&quot;&gt;pxiong&lt;/a&gt;: i found it in HoS, will modify the description soon.&lt;/p&gt;</comment>
                            <comment id="16060377" author="pxiong" created="Fri, 23 Jun 2017 03:36:03 +0000"  >&lt;p&gt;thanks. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16099424" author="kellyzly" created="Tue, 25 Jul 2017 03:15:12 +0000"  >&lt;p&gt;the reason why Map4 does not exist in the explain is because of &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/CombineEquivalentWorkResolver.java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;CombineEquivalentWorkResolver&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;before CombineEquivalentWorkResolver optimization is enabled,Map4 exists in the explain, after CombineEquivalentWorkResolver which will find and combine equivalent works.  Map4 is deleted because Map4 equals Map1. So we need to remove the spark dynamic pruning sink branch in Reducer 11 and Reducer 13 in Stage-2.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stakiar&quot; class=&quot;user-hover&quot; rel=&quot;stakiar&quot;&gt;stakiar&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt; please help review, thanks!&lt;/p&gt;</comment>
                            <comment id="16099616" author="kellyzly" created="Tue, 25 Jul 2017 07:16:01 +0000"  >&lt;p&gt;One thing need to be mentioned here:&lt;br/&gt;
 why remove dynamic partition pruning sink operator branch directly in CombineEquivalentWorkResolver#dispatch?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;   @Override
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; dispatch(Node nd, Stack&amp;lt;Node&amp;gt; stack, &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;... nodeOutputs) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; SemanticException {
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (nd &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; SparkTask) {
        SparkTask sparkTask = (SparkTask) nd;
        SparkWork sparkWork = sparkTask.getWork();
        Set&amp;lt;BaseWork&amp;gt; roots = sparkWork.getRoots();
        compareWorksRecursively(roots, sparkWork);
        +removeDynamicPartitionPruningSinkBranch(removedMapWorkNames, sparkWork);
      }
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; We found that Map4 equals to Map1 in Stage-1 and remove the dynamic partition pruning sink operator branch in Reducer 11 and Reducer 13 in Stage-2. Stage-1 is the child task of Stage-2. And the traverse order is definite, first Stage-1 then Stage-2 because &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/lib/TaskGraphWalker.java#L184&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;TaskGraphWalker&lt;/a&gt; will first put children task in the front of task queue.&lt;/p&gt;</comment>
                            <comment id="16101050" author="kellyzly" created="Wed, 26 Jul 2017 01:35:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stakiar&quot; class=&quot;user-hover&quot; rel=&quot;stakiar&quot;&gt;stakiar&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt; please help review, thanks!&lt;/p&gt;</comment>
                            <comment id="16102502" author="stakiar" created="Thu, 27 Jul 2017 00:13:00 +0000"  >&lt;p&gt;Overall, the approach LGTM. You may need to re-attach the patch, seem Hive QA hasn&apos;t run yet.&lt;/p&gt;</comment>
                            <comment id="16102563" author="kellyzly" created="Thu, 27 Jul 2017 01:35:19 +0000"  >&lt;p&gt;upload &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-16948&quot; title=&quot;Invalid explain when running dynamic partition pruning query in Hive On Spark&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-16948&quot;&gt;&lt;del&gt;HIVE-16948&lt;/del&gt;&lt;/a&gt;_1.patch to trigger HiveQA.&lt;/p&gt;</comment>
                            <comment id="16102762" author="lirui" created="Thu, 27 Jul 2017 06:04:23 +0000"  >&lt;p&gt;Is it possible that the DPP work doesn&apos;t contain branches, and therefore when the target work is gone, the whole DPP work/task should be removed?&lt;/p&gt;</comment>
                            <comment id="16102849" author="kellyzly" created="Thu, 27 Jul 2017 07:31:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Is it possible that the DPP work doesn&apos;t contain branches, and therefore when the target work is gone, the whole DPP work/task should be removed?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt; There are 3 places to remove spark dynamic partition pruning sink before CombineEquivalentWorkResolver &lt;br/&gt;
1. SparkRemoveDynamicPruningBySize &lt;br/&gt;
2. SparkCompiler#runCycleAnalysisForPartitionPruning&lt;br/&gt;
3. SparkMapJoinOptimizer(&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17087&quot; title=&quot;Remove unnecessary HoS DPP trees during map-join conversion&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-17087&quot;&gt;&lt;del&gt;HIVE-17087&lt;/del&gt;&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;In this jira, there are two dynamic partition pruning sink operators which are target to two same Maps. If we need remove dynamic partition pruning operators in above three conditions. These 2 dynamic partition pruning sink operators will be removed together. In theory, there will not happen the DPP work doesn&apos;t contain branches( remove 1 and remain another).&lt;/p&gt;

&lt;p&gt;if my understanding is not correct, please tell me.&lt;/p&gt;</comment>
                            <comment id="16102900" author="hiveqa" created="Thu, 27 Jul 2017 08:10:51 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12879093/HIVE-16948_1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12879093/HIVE-16948_1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/6145/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/6145/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/6145/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/6145/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-6145/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-6145/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hiveptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-07-27 08:10:44.402
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;MAVEN_OPTS=-Xmx1g &apos;
+ MAVEN_OPTS=&apos;-Xmx1g &apos;
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-6145/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-07-27 08:10:44.405
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 0f7c33d HIVE-17088: HS2 WebUI throws a NullPointerException when opened (Sergio Pena, reviewed by Aihua Xu)
+ git clean -f -d
Removing ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/IfVectorExpression.java
+ git checkout master
Already on &apos;master&apos;
Your branch is up-to-date with &apos;origin/master&apos;.
+ git reset --hard origin/master
HEAD is now at 0f7c33d HIVE-17088: HS2 WebUI throws a NullPointerException when opened (Sergio Pena, reviewed by Aihua Xu)
+ git merge --ff-only origin/master
Already up-to-date.
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-07-27 08:10:51.019
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/CombineEquivalentWorkResolver.java: No such file or directory
error: a/ql/src/test/results/clientpositive/spark/spark_dynamic_partition_pruning.q.out: No such file or directory
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12879093 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16102999" author="lirui" created="Thu, 27 Jul 2017 09:34:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt;, my point is, in your example, both Reducer11 and Reducer13 contain two DPP sinks, and we need to remove one of them in each Reducer. Is it possible the reduce works only contain one DPP sink?&lt;br/&gt;
More specifically, you use &lt;tt&gt;OperatorUtils.removeBranch(pruneSinkOp)&lt;/tt&gt; to remove the DPP sink, which only works if the DPP sink is in a branch. The other 3 places you mentioned can use &lt;tt&gt;OperatorUtils.removeBranch&lt;/tt&gt; because DPP sinks are always in a branch in logical plan. But in physical plan (after &lt;tt&gt;SplitOpTreeForDPP&lt;/tt&gt; has split the tree), I&apos;m not sure whether the assumption will hold.&lt;/p&gt;</comment>
                            <comment id="16104017" author="kellyzly" created="Thu, 27 Jul 2017 22:25:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;: &lt;/p&gt;
&lt;blockquote&gt;

&lt;p&gt; Is it possible the reduce works only contain one DPP sink?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;there are 3 conditions to remove dpp sink:&lt;br/&gt;
1. SparkRemoveDynamicPruningBySize &lt;br/&gt;
2. SparkCompiler#runCycleAnalysisForPartitionPruning&lt;br/&gt;
3. SparkMapJoinOptimizer(&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17087&quot; title=&quot;Remove unnecessary HoS DPP trees during map-join conversion&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-17087&quot;&gt;&lt;del&gt;HIVE-17087&lt;/del&gt;&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;If i use 1 condition to remove dpp sink, can you give one example to show to remove 1 and remain another?&lt;/p&gt;</comment>
                            <comment id="16104374" author="lirui" created="Fri, 28 Jul 2017 03:10:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt;, I&apos;m not talking about the 3 places. Here&apos;s an example:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;set hive.cbo.enable=false;
explain select * from (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.key) a join (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.key) b on a.key=b.key;

STAGE DEPENDENCIES:
  Stage-2 is a root stage
  Stage-1 depends on stages: Stage-2
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-2
    Spark
      DagName: lirui_20170728110559_4c2bc0ba-ab9a-428b-bf09-23f1b19b068f:16
      Vertices:
        Map 8
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: string)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                        Spark Partition Pruning Sink Operator
                          partition key expr: ds
                          Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                          target column name: ds
                          target work: Map 1
            Execution mode: vectorized
        Map 9
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                      Group By Operator
                        keys: _col0 (type: string)
                        mode: hash
                        outputColumnNames: _col0
                        Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                        Spark Partition Pruning Sink Operator
                          partition key expr: ds
                          Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                          target column name: ds
                          target work: Map 5
            Execution mode: vectorized

  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 &amp;lt;- Map 1 (PARTITION-LEVEL SORT, 1), Map 4 (PARTITION-LEVEL SORT, 1)
        Reducer 3 &amp;lt;- Reducer 2 (PARTITION-LEVEL SORT, 1), Reducer 6 (PARTITION-LEVEL SORT, 1)
        Reducer 6 &amp;lt;- Map 1 (PARTITION-LEVEL SORT, 1), Map 4 (PARTITION-LEVEL SORT, 1)
      DagName: lirui_20170728110559_4c2bc0ba-ab9a-428b-bf09-23f1b19b068f:15
      Vertices:
        Map 1
            Map Operator Tree:
                TableScan
                  alias: srcpart
                  Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: ds (type: string)
                      sort order: +
                      Map-reduce partition columns: ds (type: string)
                      Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
                      value expressions: key (type: string)
            Execution mode: vectorized
        Map 4
            Map Operator Tree:
                TableScan
                  alias: src
                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: key is not null (type: boolean)
                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: key (type: string)
                      sort order: +
                      Map-reduce partition columns: key (type: string)
                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized
        Reducer 2
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 ds (type: string)
                  1 key (type: string)
                outputColumnNames: _col0, _col2
                Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col2 (type: string), _col0 (type: string)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col1 (type: string)
                    sort order: +
                    Map-reduce partition columns: _col1 (type: string)
                    Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: string)
        Reducer 3
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col1 (type: string)
                  1 _col1 (type: string)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 2420 Data size: 25709 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 2420 Data size: 25709 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 6
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 ds (type: string)
                  1 key (type: string)
                outputColumnNames: _col0, _col2
                Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col2 (type: string), _col0 (type: string)
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col1 (type: string)
                    sort order: +
                    Map-reduce partition columns: _col1 (type: string)
                    Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col0 (type: string)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Map1 and Map5 are equivalent and Map5 is removed. Therefore the whole Map9 should be removed. But I think your patch won&apos;t work because Map9 doesn&apos;t have branches.&lt;/p&gt;</comment>
                            <comment id="16104380" author="lirui" created="Fri, 28 Jul 2017 03:18:32 +0000"  >&lt;p&gt;Thinking more about this, I find a bug in combing equivalent works. If 2 map works contain same operators, but will be pruned by different DPP sinks, then they can&apos;t be combined. E.g., let&apos;s slightly change the above example into:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;explain select * from (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.key) a join (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.value) b on a.key=b.key;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The two map works for &lt;tt&gt;srcpart&lt;/tt&gt; still get combined. However, they need to be pruned by different values: &lt;tt&gt;src.key&lt;/tt&gt; and &lt;tt&gt;src.value&lt;/tt&gt; respectively. In the current implementation we&apos;ll probably have incorrect results.&lt;/p&gt;</comment>
                            <comment id="16104637" author="kellyzly" created="Fri, 28 Jul 2017 08:24:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;:  thanks for your catch, it needs to remove the whole map work if there is no branch in map work contain spark pruning sink operator.  update &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-16948&quot; title=&quot;Invalid explain when running dynamic partition pruning query in Hive On Spark&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-16948&quot;&gt;&lt;del&gt;HIVE-16948&lt;/del&gt;&lt;/a&gt;.2.patch.&lt;/p&gt;</comment>
                            <comment id="16104700" author="kellyzly" created="Fri, 28 Jul 2017 09:13:27 +0000"  >&lt;blockquote&gt;

&lt;p&gt;Thinking more about this, I find a bug in combing equivalent works. If 2 map works contain same operators, but will be pruned by different DPP sinks, then they can&apos;t be combined. E.g.,&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;CombineEquivalentWorkResolver.EquivalentWorkMatcher#compareCurrentOperator only compare the self property of operator. Will not compare the relationship with other operators. Suggest to have a configuration to enable/disable combine equivalent work so that if users disable combine equivalent to cross above issue.&lt;/p&gt;</comment>
                            <comment id="16105873" author="hiveqa" created="Fri, 28 Jul 2017 23:56:15 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12879315/HIVE-16948.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12879315/HIVE-16948.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 9 failed/errored test(s), 11013 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestPerfCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=240)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=240)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=100)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreStatsMerge.testStatsMerge (batchId=206)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=179)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/6176/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/6176/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/6176/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/6176/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-6176/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-6176/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12879315 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16118025" author="kellyzly" created="Tue, 8 Aug 2017 08:19:12 +0000"  >&lt;p&gt;changes:&lt;br/&gt;
1.	remove the empty sparkWork and sparkTask&lt;br/&gt;
2.	add test in TestSparkTask to test removeEmptySparkTask. Directly copy part code of CombineEquivalentWorkResolver.EquivalentWorkMatcher#removeEmptySparkTask to TestSparkTask to test. It is better to mock some situation to test EquivalentWorkMatcher#removeEmptySparkTask even this situation is rarely occurred. If this is unnecessary, i can remove them.&lt;/p&gt;</comment>
                            <comment id="16118112" author="hiveqa" created="Tue, 8 Aug 2017 09:46:22 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12880794/HIVE-16948.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12880794/HIVE-16948.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/6294/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/6294/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/6294/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/6294/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-6294/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-6294/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hiveptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-08-08 09:46:15.376
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;MAVEN_OPTS=-Xmx1g &apos;
+ MAVEN_OPTS=&apos;-Xmx1g &apos;
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-6294/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-08-08 09:46:15.379
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 6b03a9c HIVE-17247: HoS DPP: UDFs on the partition column side does not evaluate correctly (Sahil Takiar, reviewed by Rui Li)
+ git clean -f -d
+ git checkout master
Already on &apos;master&apos;
Your branch is up-to-date with &apos;origin/master&apos;.
+ git reset --hard origin/master
HEAD is now at 6b03a9c HIVE-17247: HoS DPP: UDFs on the partition column side does not evaluate correctly (Sahil Takiar, reviewed by Rui Li)
+ git merge --ff-only origin/master
Already up-to-date.
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-08-08 09:46:21.472
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: a/ql/src/java/org/apache/hadoop/hive/ql/exec/OperatorUtils.java: No such file or directory
error: a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/CombineEquivalentWorkResolver.java: No such file or directory
error: a/ql/src/test/org/apache/hadoop/hive/ql/exec/spark/TestSparkTask.java: No such file or directory
error: a/ql/src/test/results/clientpositive/spark/spark_dynamic_partition_pruning.q.out: No such file or directory
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12880794 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16125366" author="kellyzly" created="Mon, 14 Aug 2017 08:29:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;: attached is &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-16948&quot; title=&quot;Invalid explain when running dynamic partition pruning query in Hive On Spark&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-16948&quot;&gt;&lt;del&gt;HIVE-16948&lt;/del&gt;&lt;/a&gt;.6.patch. Update code with latest master.  Can you spend some time to review, thanks!&lt;/p&gt;</comment>
                            <comment id="16125474" author="hiveqa" created="Mon, 14 Aug 2017 09:47:42 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12881698/HIVE-16948.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12881698/HIVE-16948.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 13 failed/errored test(s), 11005 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=240)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_dynamic_partitions_merge_move] (batchId=243)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_dynamic_partitions_merge_only] (batchId=243)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_dynamic_partitions_move_only] (batchId=243)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning_mapjoin_only] (batchId=170)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=169)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=99)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=235)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=235)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=180)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=180)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=180)
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testJoinThriftSerializeInTasks (batchId=228)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/6381/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/6381/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/6381/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/6381/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-6381/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-6381/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12881698 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16129993" author="kellyzly" created="Thu, 17 Aug 2017 06:19:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;: Can you spend some time to review &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-16948&quot; title=&quot;Invalid explain when running dynamic partition pruning query in Hive On Spark&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-16948&quot;&gt;&lt;del&gt;HIVE-16948&lt;/del&gt;&lt;/a&gt;.6.patch, thanks!&lt;/p&gt;</comment>
                            <comment id="16130024" author="lirui" created="Thu, 17 Aug 2017 06:56:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt;, sorry about the delay. I&apos;ve left some comments on RB.&lt;/p&gt;</comment>
                            <comment id="16130420" author="pvary" created="Thu, 17 Aug 2017 13:53:58 +0000"  >&lt;p&gt;I do not find my comment on the review board, so I leave a comment here too:&lt;br/&gt;
I think &lt;tt&gt;spark_dynamic_partition_pruning.q.out&lt;/tt&gt; changes are caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17148&quot; title=&quot;Incorrect result for Hive join query with COALESCE in WHERE condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-17148&quot;&gt;&lt;del&gt;HIVE-17148&lt;/del&gt;&lt;/a&gt; - &quot;Incorrect result for Hive join query with COALESCE in WHERE condition&quot;. Created &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17346&quot; title=&quot;TestMiniSparkOnYarnCliDriver[spark_dynamic_partition_pruning] is failing every time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-17346&quot;&gt;&lt;del&gt;HIVE-17346&lt;/del&gt;&lt;/a&gt; to track the progress there&lt;/p&gt;</comment>
                            <comment id="16131675" author="kellyzly" created="Fri, 18 Aug 2017 03:50:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pvary&quot; class=&quot;user-hover&quot; rel=&quot;pvary&quot;&gt;pvary&lt;/a&gt;: I saw your comment on review board.  Thanks for your tracking &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17346&quot; title=&quot;TestMiniSparkOnYarnCliDriver[spark_dynamic_partition_pruning] is failing every time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-17346&quot;&gt;&lt;del&gt;HIVE-17346&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="16131822" author="hiveqa" created="Fri, 18 Aug 2017 07:00:31 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12882506/HIVE-16948.7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12882506/HIVE-16948.7.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 10977 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=169)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=235)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=235)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=180)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=180)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=180)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/6451/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/6451/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/6451/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/6451/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-6451/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-6451/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12882506 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="16131834" author="lirui" created="Fri, 18 Aug 2017 07:14:03 +0000"  >&lt;p&gt;+1. Thanks for the update &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16131842" author="kellyzly" created="Fri, 18 Aug 2017 07:19:49 +0000"  >&lt;p&gt;thanks for your review, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;,&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stakiar&quot; class=&quot;user-hover&quot; rel=&quot;stakiar&quot;&gt;stakiar&lt;/a&gt;,&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pvary&quot; class=&quot;user-hover&quot; rel=&quot;pvary&quot;&gt;pvary&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="16131848" author="lirui" created="Fri, 18 Aug 2017 07:26:53 +0000"  >&lt;p&gt;Pushed to master. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt; for the work.&lt;/p&gt;</comment>
                            <comment id="16486165" author="vgarg" created="Tue, 22 May 2018 23:59:24 +0000"  >&lt;p&gt;Hive 3.0.0 has been released so closing this jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13098676">HIVE-17414</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12893484" name="17193_compare_RS_in_Map_5_1.PNG" size="305955" author="kellyzly" created="Mon, 23 Oct 2017 05:22:24 +0000"/>
                            <attachment id="12879315" name="HIVE-16948.2.patch" size="6955" author="kellyzly" created="Fri, 28 Jul 2017 08:36:10 +0000"/>
                            <attachment id="12880794" name="HIVE-16948.5.patch" size="13540" author="kellyzly" created="Tue, 8 Aug 2017 08:18:37 +0000"/>
                            <attachment id="12881698" name="HIVE-16948.6.patch" size="17038" author="kellyzly" created="Mon, 14 Aug 2017 08:28:42 +0000"/>
                            <attachment id="12882506" name="HIVE-16948.7.patch" size="14336" author="kellyzly" created="Fri, 18 Aug 2017 03:50:38 +0000"/>
                            <attachment id="12878733" name="HIVE-16948.patch" size="6031" author="kellyzly" created="Tue, 25 Jul 2017 03:19:43 +0000"/>
                            <attachment id="12879093" name="HIVE-16948_1.patch" size="6031" author="kellyzly" created="Thu, 27 Jul 2017 01:34:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 26 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3gn4v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>