<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:07:30 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-4730] Join on more than 2^31 records on single reducer failed (wrong results)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4730</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;join on more than 2^31 rows leads to wrong results. for example:&lt;/p&gt;

&lt;p&gt;Create table small_table (p1 string) ROW FORMAT DELIMITED    LINES TERMINATED BY  &apos;\n&apos;;&lt;br/&gt;
Create table big_table (p1 string) ROW FORMAT DELIMITED    LINES TERMINATED BY  &apos;\n&apos;;&lt;/p&gt;

&lt;p&gt;Loading 1 row to small_table (the value 1).&lt;br/&gt;
Loading 2149580800 rows to big_table with the same value (1 on this case).&lt;/p&gt;

&lt;p&gt;create table output as select a.p1 from  big_table a join small_table b on (a.p1=b.p1);&lt;/p&gt;

&lt;p&gt;select count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; from output ; will return only 1 row...&lt;/p&gt;

&lt;p&gt;the reducer syslog:&lt;br/&gt;
...&lt;br/&gt;
2013-06-13 17:20:59,254 INFO ExecReducer: ExecReducer: processing 2147000000 rows: used memory = 32925960&lt;br/&gt;
2013-06-13 17:21:00,745 INFO ExecReducer: ExecReducer: processing 2148000000 rows: used memory = 12815184&lt;br/&gt;
2013-06-13 17:21:02,205 INFO ExecReducer: ExecReducer: processing 2149000000 rows: used memory = 26684552   &amp;lt;-- looks like wrong value..&lt;br/&gt;
...&lt;br/&gt;
2013-06-13 17:21:04,062 INFO ExecReducer: ExecReducer: processed 2149580801 rows: used memory = 17715896&lt;br/&gt;
2013-06-13 17:21:04,062 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: 4 finished. closing...&lt;br/&gt;
2013-06-13 17:21:04,062 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: 4 forwarded 1 rows&lt;br/&gt;
2013-06-13 17:21:05,791 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: SKEWJOINFOLLOWUPJOBS:0&lt;br/&gt;
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 5 finished. closing...&lt;br/&gt;
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 5 forwarded 1 rows&lt;br/&gt;
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 6 finished. closing...&lt;br/&gt;
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 6 forwarded 0 rows&lt;br/&gt;
2013-06-13 17:21:05,946 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: TABLE_ID_1_ROWCOUNT:1&lt;br/&gt;
2013-06-13 17:21:05,946 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 5 Close done&lt;br/&gt;
2013-06-13 17:21:05,946 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: 4 Close done&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12652723">HIVE-4730</key>
            <summary>Join on more than 2^31 records on single reducer failed (wrong results)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis Ryu</assignee>
                                    <reporter username="gabik">Gabi Kazav</reporter>
                        <labels>
                    </labels>
                <created>Thu, 13 Jun 2013 18:36:46 +0000</created>
                <updated>Tue, 15 Oct 2013 23:29:29 +0000</updated>
                            <resolved>Fri, 19 Jul 2013 19:57:29 +0000</resolved>
                                    <version>0.7.1</version>
                    <version>0.8.0</version>
                    <version>0.8.1</version>
                    <version>0.9.0</version>
                    <version>0.10.0</version>
                    <version>0.11.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="13683000" author="navis" created="Fri, 14 Jun 2013 01:49:23 +0000"  >&lt;p&gt;Could you try to change join order something like, &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;select a.p1 from small_table a join big_table b on (a.p1=b.p1);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13683076" author="phabricator@reviews.facebook.net" created="Fri, 14 Jun 2013 04:33:21 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4730&quot; title=&quot;Join on more than 2^31 records on single reducer failed (wrong results)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4730&quot;&gt;&lt;del&gt;HIVE-4730&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Join on more than 2^31 records on single reducer failed (wrong results)&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4730&quot; title=&quot;Join on more than 2^31 records on single reducer failed (wrong results)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4730&quot;&gt;&lt;del&gt;HIVE-4730&lt;/del&gt;&lt;/a&gt; Join on more than 2^31 records on single reducer failed (wrong results)&lt;/p&gt;

&lt;p&gt;join on more than 2^31 rows leads to wrong results. for example:&lt;/p&gt;

&lt;p&gt;Create table small_table (p1 string) ROW FORMAT DELIMITED    LINES TERMINATED BY  &apos;\n&apos;;&lt;br/&gt;
Create table big_table (p1 string) ROW FORMAT DELIMITED    LINES TERMINATED BY  &apos;\n&apos;;&lt;/p&gt;

&lt;p&gt;Loading 1 row to small_table (the value 1).&lt;br/&gt;
Loading 2149580800 rows to big_table with the same value (1 on this case).&lt;/p&gt;

&lt;p&gt;create table output as select a.p1 from  big_table a join small_table b on (a.p1=b.p1);&lt;/p&gt;

&lt;p&gt;select count from output ; will return only 1 row...&lt;/p&gt;

&lt;p&gt;the reducer syslog:&lt;br/&gt;
...&lt;br/&gt;
2013-06-13 17:20:59,254 INFO ExecReducer: ExecReducer: processing 2147000000 rows: used memory = 32925960&lt;br/&gt;
2013-06-13 17:21:00,745 INFO ExecReducer: ExecReducer: processing 2148000000 rows: used memory = 12815184&lt;br/&gt;
2013-06-13 17:21:02,205 INFO ExecReducer: ExecReducer: processing 2149000000 rows: used memory = 26684552   &amp;lt;-- looks like wrong value..&lt;br/&gt;
...&lt;br/&gt;
2013-06-13 17:21:04,062 INFO ExecReducer: ExecReducer: processed 2149580801 rows: used memory = 17715896&lt;br/&gt;
2013-06-13 17:21:04,062 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: 4 finished. closing...&lt;br/&gt;
2013-06-13 17:21:04,062 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: 4 forwarded 1 rows&lt;br/&gt;
2013-06-13 17:21:05,791 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: SKEWJOINFOLLOWUPJOBS:0&lt;br/&gt;
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 5 finished. closing...&lt;br/&gt;
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 5 forwarded 1 rows&lt;br/&gt;
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 6 finished. closing...&lt;br/&gt;
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 6 forwarded 0 rows&lt;br/&gt;
2013-06-13 17:21:05,946 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: TABLE_ID_1_ROWCOUNT:1&lt;br/&gt;
2013-06-13 17:21:05,946 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 5 Close done&lt;br/&gt;
2013-06-13 17:21:05,946 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: 4 Close done&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11283&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D11283&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/AbstractRowContainer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinObjectValue.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinRowContainer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/26817/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/herald/transcript/26817/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13683364" author="gabik" created="Fri, 14 Jun 2013 14:01:45 +0000"  >&lt;p&gt;After patching and compiling, when i run the same join it fail:&lt;/p&gt;

&lt;p&gt;......&lt;br/&gt;
2013-06-14 16:47:14,924 INFO ExecReducer: ExecReducer: processing 2149000000 rows: used memory = 45018992&lt;br/&gt;
2013-06-14 16:47:16,042 FATAL org.apache.hadoop.mapred.TaskTracker: Error running child : java.lang.NoSuchMethodError: org.apache.hadoop.hive.ql.exec.persistence.AbstractRowContainer.size()I&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:802)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.JoinOperator.endGroup(JoinOperator.java:263)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.ExecReducer.close(ExecReducer.java:301)&lt;br/&gt;
        at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:473)&lt;br/&gt;
        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:411)&lt;br/&gt;
        at org.apache.hadoop.mapred.Child.main(Child.java:170)&lt;/p&gt;

&lt;p&gt;2013-06-14 16:47:19,051 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=CLEANUP, sessionId=&lt;br/&gt;
2013-06-14 16:47:19,305 INFO org.apache.hadoop.mapred.TaskRunner: Runnning cleanup for the task&lt;br/&gt;
2013-06-14 16:47:19,305 INFO org.apache.hadoop.mapred.TaskRunner: Task:attempt_201306121727_0032_r_000004_0 is done. And is in the process of commiting&lt;br/&gt;
2013-06-14 16:47:19,311 INFO org.apache.hadoop.mapred.TaskRunner: Task &apos;attempt_201306121727_0032_r_000004_0&apos; done.&lt;/p&gt;
</comment>
                            <comment id="13683409" author="navis" created="Fri, 14 Jun 2013 14:42:18 +0000"  >&lt;p&gt;I think you should do clean build.&lt;/p&gt;</comment>
                            <comment id="13683427" author="gabik" created="Fri, 14 Jun 2013 15:13:49 +0000"  >&lt;p&gt;can you explain me how?&lt;br/&gt;
ant clean ?&lt;/p&gt;

&lt;p&gt;Navis - thank you for your kindly and fast help!&lt;/p&gt;</comment>
                            <comment id="13683436" author="navis" created="Fri, 14 Jun 2013 15:20:30 +0000"  >&lt;p&gt;You can just remove build/ql directory and build, which might be a little faster. &lt;br/&gt;
I wish I could confirm this patch, but my notebook couldn&apos;t handle shuffling of 4G data.&lt;/p&gt;</comment>
                            <comment id="13683439" author="gabik" created="Fri, 14 Jun 2013 15:23:01 +0000"  >&lt;p&gt;ok - i am trying now - building ql from scratch and running the join,&lt;br/&gt;
i will comment here the results.&lt;/p&gt;

&lt;p&gt;Thanks. &lt;/p&gt;</comment>
                            <comment id="13683444" author="gabik" created="Fri, 14 Jun 2013 15:31:38 +0000"  >&lt;p&gt;do i need to copy the hive-exec jar only?  or did the patch changed another jar?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="13683448" author="navis" created="Fri, 14 Jun 2013 15:34:36 +0000"  >&lt;p&gt;exec only&lt;/p&gt;</comment>
                            <comment id="13684192" author="gabik" created="Sat, 15 Jun 2013 13:22:29 +0000"  >&lt;p&gt;Hi Navis - &lt;br/&gt;
on hive 0.7.x is works,&lt;br/&gt;
on hive 0.10.0, i am compiling the exec jar and it build me hive-exec-0.10.0-SNAPSHOT.jar&lt;br/&gt;
when i am running hive on ver 0.10.0, i got the following massage (also after clean build):&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;hdp@hive-1 gabi&amp;#93;&lt;/span&gt;$ hive&lt;br/&gt;
/hive/hive/bin/hive: line 72: [: /hive/hive/lib/hive-exec-0.10.0.jar: binary operator expected&lt;br/&gt;
Logging initialized using configuration in jar:&lt;a href=&quot;file:/hive/hive-0.10.0/lib/hive-common-0.10.0.jar!/hive-log4j.properties&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:/hive/hive-0.10.0/lib/hive-common-0.10.0.jar!/hive-log4j.properties&lt;/a&gt;&lt;br/&gt;
Hive history file=/tmp/hdp/hive_job_log_hdp_201306151610_458251040.txt&lt;br/&gt;
hive&amp;gt; show tables;&lt;br/&gt;
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.hive.metastore.api.MetaException javax.jdo.JDODataStoreException: An exception was thrown while adding/validating class(es) : Constraint &apos;COLUMNS_PK&apos; already exists in Schema &apos;APP&apos;.&lt;br/&gt;
java.sql.SQLException: Constraint &apos;COLUMNS_PK&apos; already exists in Schema &apos;APP&apos;.&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
        at org.apache.commons.dbcp.DelegatingStatement.execute(DelegatingStatement.java:264)&lt;br/&gt;
        at org.apache.commons.dbcp.DelegatingStatement.execute(DelegatingStatement.java:264)&lt;br/&gt;
        at org.datanucleus.store.rdbms.table.AbstractTable.executeDdlStatement(AbstractTable.java:730)&lt;br/&gt;
        at org.datanucleus.store.rdbms.table.AbstractTable.executeDdlStatementList(AbstractTable.java:681)&lt;br/&gt;
        at org.datanucleus.store.rdbms.table.AbstractTable.create(AbstractTable.java:402)&lt;br/&gt;
        at org.datanucleus.store.rdbms.table.AbstractTable.exists(AbstractTable.java:458)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.performTablesValidation(RDBMSStoreManager.java:2689)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.addClassTablesAndValidate(RDBMSStoreManager.java:2503)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.run(RDBMSStoreManager.java:2148)&lt;br/&gt;
        at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:113)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:986)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:952)&lt;br/&gt;
        at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:919)&lt;br/&gt;
        at org.datanucleus.store.mapped.MappedStoreManager.getDatastoreClass(MappedStoreManager.java:356)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.ExtentHelper.getExtent(ExtentHelper.java:48)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager.getExtent(RDBMSStoreManager.java:1332)&lt;br/&gt;
        at org.datanucleus.ObjectManagerImpl.getExtent(ObjectManagerImpl.java:4149)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQueryCompiler.compileCandidates(JDOQLQueryCompiler.java:411)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.QueryCompiler.executionCompile(QueryCompiler.java:312)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQueryCompiler.compile(JDOQLQueryCompiler.java:225)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQuery.compileInternal(JDOQLQuery.java:175)&lt;br/&gt;
        at org.datanucleus.store.query.Query.executeQuery(Query.java:1628)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQuery.executeQuery(JDOQLQuery.java:245)&lt;br/&gt;
        at org.datanucleus.store.query.Query.executeWithArray(Query.java:1499)&lt;br/&gt;
        at org.datanucleus.jdo.JDOQuery.execute(JDOQuery.java:243)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.ObjectStore.getTables(ObjectStore.java:781)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.RetryingRawStore.invoke(RetryingRawStore.java:111)&lt;br/&gt;
        at $Proxy6.getTables(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_tables(HiveMetaStore.java:2327)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:105)&lt;br/&gt;
        at $Proxy7.get_tables(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTables(HiveMetaStoreClient.java:817)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:74)&lt;br/&gt;
        at $Proxy8.getTables(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.metadata.Hive.getTablesByPattern(Hive.java:1009)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.metadata.Hive.getAllTables(Hive.java:983)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.DDLTask.showTables(DDLTask.java:2215)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:334)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:138)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1336)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1122)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:935)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:412)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:755)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:613)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.util.RunJar.main(RunJar.java:156)&lt;br/&gt;
Caused by: java.sql.SQLException: Constraint &apos;COLUMNS_PK&apos; already exists in Schema &apos;APP&apos;.&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)&lt;br/&gt;
        ... 74 more&lt;br/&gt;
Caused by: ERROR X0Y32: Constraint &apos;COLUMNS_PK&apos; already exists in Schema &apos;APP&apos;.&lt;br/&gt;
        at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.duplicateDescriptorException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addDescriptor(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addDescriptor(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addConstraintDescriptor(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.CreateConstraintConstantAction.executeConstantAction(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.AlterTableConstantAction.executeConstantAction(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.MiscResultSet.open(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)&lt;br/&gt;
        ... 68 more&lt;/p&gt;

&lt;p&gt;NestedThrowables:&lt;br/&gt;
java.sql.SQLException: Constraint &apos;COLUMNS_PK&apos; already exists in Schema &apos;APP&apos;.)&lt;br/&gt;
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask&lt;/p&gt;

&lt;p&gt;Do i need to change something on 0.10.0 to get it work?&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Gabi&lt;/p&gt;</comment>
                            <comment id="13684193" author="gabik" created="Sat, 15 Jun 2013 13:26:04 +0000"  >&lt;p&gt;ignore the script error line : /hive/hive/bin/hive: line 72: [: /hive/hive/lib/hive-exec-0.10.0.jar: binary operator expected&lt;br/&gt;
i had 2 jar files (old and new), fixed it, but i still have the exception:&lt;/p&gt;

&lt;p&gt;hive&amp;gt; show tables;&lt;br/&gt;
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.hive.metastore.api.MetaException javax.jdo.JDODataStoreException: An exception was thrown while adding/validating class(es) : Constraint &apos;COLUMNS_PK&apos; already exists in Schema &apos;APP&apos;.&lt;br/&gt;
java.sql.SQLException: Constraint &apos;COLUMNS_PK&apos; already exists in Schema &apos;APP&apos;.&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)&lt;br/&gt;
        at org.apache.commons.dbcp.DelegatingStatement.execute(DelegatingStatement.java:264)&lt;br/&gt;
        at org.apache.commons.dbcp.DelegatingStatement.execute(DelegatingStatement.java:264)&lt;br/&gt;
        at org.datanucleus.store.rdbms.table.AbstractTable.executeDdlStatement(AbstractTable.java:730)&lt;br/&gt;
        at org.datanucleus.store.rdbms.table.AbstractTable.executeDdlStatementList(AbstractTable.java:681)&lt;br/&gt;
        at org.datanucleus.store.rdbms.table.AbstractTable.create(AbstractTable.java:402)&lt;br/&gt;
        at org.datanucleus.store.rdbms.table.AbstractTable.exists(AbstractTable.java:458)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.performTablesValidation(RDBMSStoreManager.java:2689)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.addClassTablesAndValidate(RDBMSStoreManager.java:2503)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.run(RDBMSStoreManager.java:2148)&lt;br/&gt;
        at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:113)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:986)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:952)&lt;br/&gt;
        at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:919)&lt;br/&gt;
        at org.datanucleus.store.mapped.MappedStoreManager.getDatastoreClass(MappedStoreManager.java:356)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.ExtentHelper.getExtent(ExtentHelper.java:48)&lt;br/&gt;
        at org.datanucleus.store.rdbms.RDBMSStoreManager.getExtent(RDBMSStoreManager.java:1332)&lt;br/&gt;
        at org.datanucleus.ObjectManagerImpl.getExtent(ObjectManagerImpl.java:4149)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQueryCompiler.compileCandidates(JDOQLQueryCompiler.java:411)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.QueryCompiler.executionCompile(QueryCompiler.java:312)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQueryCompiler.compile(JDOQLQueryCompiler.java:225)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQuery.compileInternal(JDOQLQuery.java:175)&lt;br/&gt;
        at org.datanucleus.store.query.Query.executeQuery(Query.java:1628)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQuery.executeQuery(JDOQLQuery.java:245)&lt;br/&gt;
        at org.datanucleus.store.query.Query.executeWithArray(Query.java:1499)&lt;br/&gt;
        at org.datanucleus.jdo.JDOQuery.execute(JDOQuery.java:243)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.ObjectStore.getTables(ObjectStore.java:781)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.RetryingRawStore.invoke(RetryingRawStore.java:111)&lt;br/&gt;
        at $Proxy6.getTables(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_tables(HiveMetaStore.java:2327)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:105)&lt;br/&gt;
        at $Proxy7.get_tables(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTables(HiveMetaStoreClient.java:817)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:74)&lt;br/&gt;
        at $Proxy8.getTables(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.metadata.Hive.getTablesByPattern(Hive.java:1009)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.metadata.Hive.getAllTables(Hive.java:983)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.DDLTask.showTables(DDLTask.java:2215)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:334)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:138)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1336)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1122)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:935)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:412)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:755)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:613)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.util.RunJar.main(RunJar.java:156)&lt;br/&gt;
Caused by: java.sql.SQLException: Constraint &apos;COLUMNS_PK&apos; already exists in Schema &apos;APP&apos;.&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)&lt;br/&gt;
        ... 74 more&lt;br/&gt;
Caused by: ERROR X0Y32: Constraint &apos;COLUMNS_PK&apos; already exists in Schema &apos;APP&apos;.&lt;br/&gt;
        at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.duplicateDescriptorException(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addDescriptor(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addDescriptor(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addConstraintDescriptor(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.CreateConstraintConstantAction.executeConstantAction(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.AlterTableConstantAction.executeConstantAction(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.execute.MiscResultSet.open(Unknown Source)&lt;br/&gt;
        at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)&lt;br/&gt;
        ... 68 more&lt;/p&gt;

&lt;p&gt;NestedThrowables:&lt;br/&gt;
java.sql.SQLException: Constraint &apos;COLUMNS_PK&apos; already exists in Schema &apos;APP&apos;.)&lt;br/&gt;
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask&lt;/p&gt;</comment>
                            <comment id="13684558" author="navis" created="Sun, 16 Jun 2013 03:38:11 +0000"  >&lt;p&gt;I think the exception above is from change of metastore schema between 0.7.0 and 0.10.0. You need upgrade metastore via script (I haven&apos;t do that, yet) or make a new metastore.&lt;/p&gt;</comment>
                            <comment id="13684584" author="gabik" created="Sun, 16 Jun 2013 06:22:39 +0000"  >&lt;p&gt;looks like you right, sorry for that.&lt;/p&gt;

&lt;p&gt;will check and update here.&lt;/p&gt;

&lt;p&gt;Thanks again!&lt;/p&gt;</comment>
                            <comment id="13684759" author="gabik" created="Sun, 16 Jun 2013 19:48:20 +0000"  >&lt;p&gt;Looks good, thanks!&lt;/p&gt;</comment>
                            <comment id="13688862" author="gabik" created="Thu, 20 Jun 2013 04:47:01 +0000"  >&lt;p&gt;Hi - i want to add it to git,&lt;br/&gt;
how can i get permissions to push?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13688883" author="gabik" created="Thu, 20 Jun 2013 05:28:30 +0000"  >&lt;p&gt;I have it here:&lt;br/&gt;
&lt;a href=&quot;https://github.com/gabik/hive/tree/HIVE-4730&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/gabik/hive/tree/HIVE-4730&lt;/a&gt;&lt;br/&gt;
and merged into trunk:&lt;br/&gt;
&lt;a href=&quot;https://github.com/gabik/hive/tree/trunk&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/gabik/hive/tree/trunk&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13708691" author="phabricator@reviews.facebook.net" created="Mon, 15 Jul 2013 17:38:46 +0000"  >&lt;p&gt;brock has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4730&quot; title=&quot;Join on more than 2^31 records on single reducer failed (wrong results)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4730&quot;&gt;&lt;del&gt;HIVE-4730&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Join on more than 2^31 records on single reducer failed (wrong results)&quot;.&lt;/p&gt;

&lt;p&gt;  Hi Navis,&lt;/p&gt;

&lt;p&gt;  Thanks for the patch!  I noted a few style nits.  Just curious, how long did the query take to complete?  My guess is far too long to have a q-file test for this.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java:286 Is it possible to move this up near the rest of the member variable definitions?&lt;/p&gt;

&lt;p&gt;  Ideally it&apos;d be nice to change the LHS to be List but it&apos;s possible that something in the class requires ArrayList.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11283&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D11283&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13709442" author="phabricator@reviews.facebook.net" created="Tue, 16 Jul 2013 03:54:47 +0000"  >&lt;p&gt;ashutoshc has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4730&quot; title=&quot;Join on more than 2^31 records on single reducer failed (wrong results)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4730&quot;&gt;&lt;del&gt;HIVE-4730&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Join on more than 2^31 records on single reducer failed (wrong results)&quot;.&lt;/p&gt;

&lt;p&gt;  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11283&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D11283&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4730&quot; title=&quot;Join on more than 2^31 records on single reducer failed (wrong results)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4730&quot;&gt;&lt;del&gt;HIVE-4730&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13710052" author="ashutoshc" created="Tue, 16 Jul 2013 18:28:44 +0000"  >&lt;p&gt;Test &lt;tt&gt;TestCliDriver_skewjoin.q&lt;/tt&gt; failed. All others did pass.&lt;/p&gt;</comment>
                            <comment id="13710717" author="phabricator@reviews.facebook.net" created="Wed, 17 Jul 2013 05:16:48 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4730&quot; title=&quot;Join on more than 2^31 records on single reducer failed (wrong results)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4730&quot;&gt;&lt;del&gt;HIVE-4730&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Join on more than 2^31 records on single reducer failed (wrong results)&quot;.&lt;/p&gt;

&lt;p&gt;  Fixed test failure&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11283&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D11283&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11283?vs=34707&amp;amp;id=35805#toc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D11283?vs=34707&amp;amp;id=35805#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4730&quot; title=&quot;Join on more than 2^31 records on single reducer failed (wrong results)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4730&quot;&gt;&lt;del&gt;HIVE-4730&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/AbstractRowContainer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinObjectValue.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinRowContainer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13710720" author="navis" created="Wed, 17 Jul 2013 05:20:19 +0000"  >&lt;p&gt;I wish I could add a test case for this. But I couldn&apos;t run some query for table with 2G rows (job failed after 40min).&lt;/p&gt;</comment>
                            <comment id="13712157" author="ashutoshc" created="Thu, 18 Jul 2013 09:27:31 +0000"  >&lt;p&gt;skewjoin.q test still fails for me. Canceling patch trying to trigger pre-commit test-patch&lt;/p&gt;</comment>
                            <comment id="13712158" author="ashutoshc" created="Thu, 18 Jul 2013 09:28:28 +0000"  >&lt;p&gt;Marking Patch available to trigger pre-commit script to see if failure reproduces.&lt;/p&gt;</comment>
                            <comment id="13712419" author="hiveqa" created="Thu, 18 Jul 2013 15:38:40 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 build exited with an error&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12592716/HIVE-4730.D11283.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12592716/HIVE-4730.D11283.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 all tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/78/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/78/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/78/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/78/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;br/&gt;
Executing org.apache.hive.ptest.execution.CleanupPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.PrepPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.ExecutionPhase&lt;br/&gt;
Tests failed with: IllegalStateException: Too many bad hosts: 5 bad hosts out of 8 is greater than threshold of 30%&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13712422" author="brocknoland" created="Thu, 18 Jul 2013 15:42:07 +0000"  >&lt;p&gt;OK interesting. Basically 5 of our 8 ec2 hosts went &quot;bad&quot; during testing. We&apos;ll see this from time to time. Uploading the patch again will start a new build, but I kicked off the pre-commit build manually.&lt;/p&gt;</comment>
                            <comment id="13712437" author="hiveqa" created="Thu, 18 Jul 2013 16:02:32 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 build exited with an error&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12592716/HIVE-4730.D11283.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12592716/HIVE-4730.D11283.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 all tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/79/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/79/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/79/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/79/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;br/&gt;
Executing org.apache.hive.ptest.execution.CleanupPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.PrepPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.ExecutionPhase&lt;br/&gt;
Tests failed with: IllegalStateException: Too many bad hosts: 5 bad hosts out of 8 is greater than threshold of 30%&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13712451" author="brocknoland" created="Thu, 18 Jul 2013 16:29:13 +0000"  >&lt;p&gt;And there is a bug we aren&apos;t correctly replacing I created &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4882&quot; title=&quot;PTest2 via the Cloud Provider doesn&amp;#39;t replace bad hosts if an exception occurs during a test&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4882&quot;&gt;&lt;del&gt;HIVE-4882&lt;/del&gt;&lt;/a&gt; for this. I also kicked off the pre-commit job again.&lt;/p&gt;</comment>
                            <comment id="13712903" author="hiveqa" created="Thu, 18 Jul 2013 21:40:25 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12592716/HIVE-4730.D11283.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12592716/HIVE-4730.D11283.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 all tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/81/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/81/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/81/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/81/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;br/&gt;
Executing org.apache.hive.ptest.execution.CleanupPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.PrepPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.ExecutionPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.ReportingPhase&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13712950" author="appodictic" created="Thu, 18 Jul 2013 22:07:03 +0000"  >&lt;p&gt;Q. Why do we cast down to int here?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;       // Different processing for key and value&lt;br/&gt;
       MapJoinRowContainer&amp;lt;Object[]&amp;gt; v = obj;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;out.writeInt(v.size());&lt;br/&gt;
+      out.writeInt((int)v.size());&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;</comment>
                            <comment id="13712984" author="appodictic" created="Thu, 18 Jul 2013 22:23:34 +0000"  >&lt;p&gt;Never mind I see its an array size issue.&lt;/p&gt;</comment>
                            <comment id="13714015" author="ashutoshc" created="Fri, 19 Jul 2013 19:57:29 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis!&lt;/p&gt;</comment>
                            <comment id="13795902" author="ashutoshc" created="Tue, 15 Oct 2013 23:29:29 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12657104">HIVE-4838</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12587771" name="HIVE-4730.D11283.1.patch" size="3730" author="phabricator@reviews.facebook.net" created="Fri, 14 Jun 2013 04:33:21 +0000"/>
                            <attachment id="12592716" name="HIVE-4730.D11283.2.patch" size="3364" author="phabricator@reviews.facebook.net" created="Wed, 17 Jul 2013 05:16:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>333047</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 6 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1lgbr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>333375</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>