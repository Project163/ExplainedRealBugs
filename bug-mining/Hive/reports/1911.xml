<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:16:05 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-6347] ZeroCopy read path for ORC RecordReader</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6347</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;ORC can use the new HDFS Caching APIs and the ZeroCopy readers to avoid extra data copies into memory while scanning files.&lt;/p&gt;

&lt;p&gt;Implement ORC zcr codepath and a hive.orc.zerocopy flag.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692598">HIVE-6347</key>
            <summary>ZeroCopy read path for ORC RecordReader</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gopalv">Gopal Vijayaraghavan</assignee>
                                    <reporter username="gopalv">Gopal Vijayaraghavan</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 Jan 2014 21:34:37 +0000</created>
                <updated>Wed, 20 Jan 2016 21:03:17 +0000</updated>
                            <resolved>Wed, 26 Feb 2014 08:51:32 +0000</resolved>
                                    <version>tez-branch</version>
                                    <fixVersion>tez-branch</fixVersion>
                                    <component>File Formats</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="13888456" author="gopalv" created="Sat, 1 Feb 2014 04:42:23 +0000"  >&lt;p&gt;Patch which applies over &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6346&quot; title=&quot;Add Hadoop-2.4.0 shims to hive-tez&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6346&quot;&gt;&lt;del&gt;HIVE-6346&lt;/del&gt;&lt;/a&gt; on hive/tez branch&lt;/p&gt;</comment>
                            <comment id="13888559" author="lefty@hortonworks.com" created="Sat, 1 Feb 2014 12:46:01 +0000"  >&lt;p&gt;The patch adds &lt;b&gt;hive.orc.zerocopy&lt;/b&gt; to HiveConf.java, so it also needs to document the flag in hive-default.xml.template.&lt;/p&gt;</comment>
                            <comment id="13888587" author="hiveqa" created="Sat, 1 Feb 2014 13:39:13 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12626451/HIVE-6347.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12626451/HIVE-6347.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1151/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1151/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1151/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1151/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:524:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1546 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[21,48] cannot find symbol
symbol  : class DirectDecompressorShim
location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[23,48] cannot find symbol
symbol  : class DirectCompressionType
location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[51,48] cannot find symbol
symbol  : class ByteBufferPoolShim
location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[52,48] cannot find symbol
symbol  : class ZeroCopyReaderShim
location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[100,64] cannot find symbol
symbol  : class ByteBufferPoolShim
location: class org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[96,17] cannot find symbol
symbol  : class ZeroCopyReaderShim
location: class org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[27,48] cannot find symbol
symbol  : class DirectCompressionType
location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[28,48] cannot find symbol
symbol  : class DirectDecompressorShim
location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[82,11] cannot find symbol
symbol  : variable DirectCompressionType
location: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[94,5] cannot find symbol
symbol  : class DirectDecompressorShim
location: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[95,32] cannot find symbol
symbol  : variable DirectCompressionType
location: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[153,5] method does not override or implement a method from a supertype
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[165,5] method does not override or implement a method from a supertype
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[228,45] cannot find symbol
symbol  : method getZeroCopyReader(org.apache.hadoop.fs.FSDataInputStream,org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.ByteBufferAllocatorPool)
location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[95,11] cannot find symbol
symbol  : variable DirectCompressionType
location: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[107,5] cannot find symbol
symbol  : class DirectDecompressorShim
location: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[108,32] cannot find symbol
symbol  : variable DirectCompressionType
location: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec
[INFO] 17 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [4.645s]
[INFO] Hive Ant Utilities ................................ SUCCESS [6.787s]
[INFO] Hive Shims Common ................................. SUCCESS [3.329s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [2.245s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [2.600s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.428s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [3.198s]
[INFO] Hive Shims ........................................ SUCCESS [0.590s]
[INFO] Hive Common ....................................... SUCCESS [7.734s]
[INFO] Hive Serde ........................................ SUCCESS [8.743s]
[INFO] Hive Metastore .................................... SUCCESS [26.982s]
[INFO] Hive Query Language ............................... FAILURE [40.846s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:52.063s
[INFO] Finished at: Sat Feb 01 08:39:12 EST 2014
[INFO] Final Memory: 55M/422M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[21,48] cannot find symbol
[ERROR] symbol  : class DirectDecompressorShim
[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[23,48] cannot find symbol
[ERROR] symbol  : class DirectCompressionType
[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[51,48] cannot find symbol
[ERROR] symbol  : class ByteBufferPoolShim
[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[52,48] cannot find symbol
[ERROR] symbol  : class ZeroCopyReaderShim
[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[100,64] cannot find symbol
[ERROR] symbol  : class ByteBufferPoolShim
[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[96,17] cannot find symbol
[ERROR] symbol  : class ZeroCopyReaderShim
[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[27,48] cannot find symbol
[ERROR] symbol  : class DirectCompressionType
[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[28,48] cannot find symbol
[ERROR] symbol  : class DirectDecompressorShim
[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[82,11] cannot find symbol
[ERROR] symbol  : variable DirectCompressionType
[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[94,5] cannot find symbol
[ERROR] symbol  : class DirectDecompressorShim
[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[95,32] cannot find symbol
[ERROR] symbol  : variable DirectCompressionType
[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[153,5] method does not override or implement a method from a supertype
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[165,5] method does not override or implement a method from a supertype
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[228,45] cannot find symbol
[ERROR] symbol  : method getZeroCopyReader(org.apache.hadoop.fs.FSDataInputStream,org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.ByteBufferAllocatorPool)
[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[95,11] cannot find symbol
[ERROR] symbol  : variable DirectCompressionType
[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[107,5] cannot find symbol
[ERROR] symbol  : class DirectDecompressorShim
[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[108,32] cannot find symbol
[ERROR] symbol  : variable DirectCompressionType
[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12626451&lt;/p&gt;</comment>
                            <comment id="13888658" author="brocknoland" created="Sat, 1 Feb 2014 17:51:05 +0000"  >&lt;p&gt;There are a number of cases there the if contains a negation&lt;br/&gt;
but there is an else condition. Thse should be swapped:&lt;/p&gt;

&lt;p&gt;e.g&lt;/p&gt;

&lt;p&gt;if (!bool) else =&amp;gt; if (bool) else&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+      if(zcr != null) {
+        while(len &amp;gt; 0) {
+          ByteBuffer partial = zcr.readBuffer(len, false);
+          result.add(new BufferChunk(partial, off));
+          int read = partial.remaining();
+          len -= read;
+          off += read;
+        }
+      } else {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+      if (ShimLoader.getHadoopShims().getDirectDecompressor(
+          DirectCompressionType.SNAPPY) != null) {
+        direct = Boolean.valueOf(true);
+      } else {
+        direct = Boolean.valueOf(false);
+      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13892600" author="gopalv" created="Wed, 5 Feb 2014 21:38:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;leftylev&lt;/a&gt;: I will add the docs into the hive-site.xml in the next rev - was waiting for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6346&quot; title=&quot;Add Hadoop-2.4.0 shims to hive-tez&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6346&quot;&gt;&lt;del&gt;HIVE-6346&lt;/del&gt;&lt;/a&gt; to get pushed to branch.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;brocknoland&lt;/a&gt;: a != null is actually positive test, because it implies there exists something (i.e it&apos;s presence). That is how rest of the ORC code deals with optional feature/args (like SARGs).&lt;/p&gt;</comment>
                            <comment id="13902298" author="gopalv" created="Sat, 15 Feb 2014 03:06:48 +0000"  >&lt;p&gt;Address comments on review board (&amp;amp; added docs)&lt;/p&gt;</comment>
                            <comment id="13902800" author="gopalv" created="Sun, 16 Feb 2014 19:55:15 +0000"  >&lt;p&gt;munmap() is async and delayed action&lt;/p&gt;</comment>
                            <comment id="13912652" author="hagleitn" created="Wed, 26 Feb 2014 08:51:32 +0000"  >&lt;p&gt;Committed to branch. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14021861" author="lefty@hortonworks.com" created="Mon, 9 Jun 2014 10:21:51 +0000"  >&lt;p&gt;&lt;b&gt;hive.exec.orc.zerocopy&lt;/b&gt; is documented in hive-default.xml.template as of Hive 0.13.0 with the description &quot;Use zerocopy reads with ORC.&quot; See &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6360&quot; title=&quot;Hadoop 2.3 + Tez 0.3&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6360&quot;&gt;&lt;del&gt;HIVE-6360&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the wiki its description has been expanded to &quot;Use zerocopy reads with ORC. (This requires Hadoop 2.3 or later.)&quot;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.exec.orc.zerocopy&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Configuration Properties: hive.exec.orc.zerocopy &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15108883" author="sztanko" created="Wed, 20 Jan 2016 16:46:14 +0000"  >&lt;p&gt;Hello,&lt;br/&gt;
I am running my cluster on Hadoop 2.7.1 (checksum fc0a1a23fc1868e4d5ee7fa2b28a58a), using Hive 1.2.1 (checksum ab480aca41b24a9c3751b8c023338231) and hive.exec.orc.zerocopy tends to cause failures.&lt;br/&gt;
All my hive queries run fines, but once I enable zerocopy, it seems to have some problems with native libraries:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;set hive.exec.orc.zerocopy = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
&amp;lt;execute my query&amp;gt;
Hadoop job information &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Stage-1: number of mappers: 316; number of reducers: 90
2016-01-20 16:37:54,479 Stage-1 map = 0%,  reduce = 0%
2016-01-20 16:38:21,061 Stage-1 map = 100%,  reduce = 100%
2016-01-20 16:39:21,246 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_1452780282075_23380 with errors
Error during job, obtaining debugging information...
Diagnostic Messages &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; Task:
Error: java.io.IOException: java.lang.reflect.InvocationTargetException
	at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)
	at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:266)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.&amp;lt;init&amp;gt;(HadoopShimsSecure.java:213)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getRecordReader(HadoopShimsSecure.java:333)
	at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getRecordReader(CombineHiveInputFormat.java:719)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.&amp;lt;init&amp;gt;(MapTask.java:169)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:432)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:252)
	... 11 more
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect()I
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method)
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressDirect(SnappyDecompressor.java:305)
	at org.apache.hadoop.io.compress.snappy.SnappyDecompressor$SnappyDirectDecompressor.decompress(SnappyDecompressor.java:341)
	at org.apache.hadoop.hive.shims.ZeroCopyShims$DirectDecompressorAdapter.decompress(ZeroCopyShims.java:101)
	at org.apache.hadoop.hive.ql.io.orc.SnappyCodec.directDecompress(SnappyCodec.java:100)
	at org.apache.hadoop.hive.ql.io.orc.SnappyCodec.decompress(SnappyCodec.java:67)
	at org.apache.hadoop.hive.ql.io.orc.InStream$CompressedStream.readHeader(InStream.java:214)
	at org.apache.hadoop.hive.ql.io.orc.InStream$CompressedStream.read(InStream.java:227)
	at org.apache.hadoop.hive.ql.io.orc.RunLengthIntegerReaderV2.readValues(RunLengthIntegerReaderV2.java:54)
	at org.apache.hadoop.hive.ql.io.orc.RunLengthIntegerReaderV2.next(RunLengthIntegerReaderV2.java:302)
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StringDictionaryTreeReader.readDictionaryLengthStream(TreeReaderFactory.java:1674)
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StringDictionaryTreeReader.startStripe(TreeReaderFactory.java:1654)
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StringTreeReader.startStripe(TreeReaderFactory.java:1382)
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StructTreeReader.startStripe(TreeReaderFactory.java:2040)
	at org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.readStripe(RecordReaderImpl.java:795)
	at org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.advanceStripe(RecordReaderImpl.java:986)
	at org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.advanceToNextRow(RecordReaderImpl.java:1019)
	at org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.&amp;lt;init&amp;gt;(RecordReaderImpl.java:205)
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.rowsOptions(ReaderImpl.java:539)
	at org.apache.hadoop.hive.ql.io.orc.VectorizedOrcInputFormat$VectorizedOrcRecordReader.&amp;lt;init&amp;gt;(VectorizedOrcInputFormat.java:71)
	at org.apache.hadoop.hive.ql.io.orc.VectorizedOrcInputFormat.getRecordReader(VectorizedOrcInputFormat.java:156)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.createVectorizedReader(OrcInputFormat.java:1088)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRecordReader(OrcInputFormat.java:1102)
	at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.&amp;lt;init&amp;gt;(CombineHiveRecordReader.java:67)
	... 16 more

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15109350" author="gopalv" created="Wed, 20 Jan 2016 20:38:06 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect()I
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Does look like the tasks are not able to locate the libhadoop.so binary (&lt;b&gt;or&lt;/b&gt; the hadoop build was done without snappy-dev available).&lt;/p&gt;

&lt;p&gt;Zero copy readers don&apos;t work if libhadoop.so is missing anyway.&lt;/p&gt;

&lt;p&gt;But to fill in some later developments, turning on zerocopy=true needs cluster-wide configs to turn on &lt;a href=&quot;https://issues.apache.org/jira/browse/YARN-1775&quot; title=&quot;Create SMAPBasedProcessTree to get PSS information&quot; class=&quot;issue-link&quot; data-issue-key=&quot;YARN-1775&quot;&gt;&lt;del&gt;YARN-1775&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The YARN memory counting counts memory-mapped files as container memory, so without that change you might see containers being killed for using too much memory as you scale past the terabyte levels.&lt;/p&gt;</comment>
                            <comment id="15109401" author="sztanko" created="Wed, 20 Jan 2016 21:03:17 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt;,&lt;br/&gt;
Seems like tasks are not able to locate the libhadoop, indeed. However, they were able to do that when zerocopy was disabled (I am using snappy compression in my orc tables) and perform well. libhadoop.so and libsnappy are there and I never had any problem with those. This makes me think that there is a correlation between finding native libraries and zerocopy.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12693495">HIVE-6382</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12692595">HIVE-6346</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12673900">HADOOP-10047</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12693000">HIVE-6360</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12655836">HDFS-4949</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12695381">HDFS-5957</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12626451" name="HIVE-6347.1.patch" size="26117" author="gopalv" created="Sat, 1 Feb 2014 04:42:23 +0000"/>
                            <attachment id="12629191" name="HIVE-6347.2-tez.patch" size="27267" author="gopalv" created="Sat, 15 Feb 2014 03:06:48 +0000"/>
                            <attachment id="12629192" name="HIVE-6347.3-tez.patch" size="27186" author="gopalv" created="Sat, 15 Feb 2014 03:12:12 +0000"/>
                            <attachment id="12629484" name="HIVE-6347.4-tez.patch" size="27018" author="gopalv" created="Tue, 18 Feb 2014 06:35:40 +0000"/>
                            <attachment id="12631167" name="HIVE-6347.5-tez.patch" size="24710" author="gopalv" created="Wed, 26 Feb 2014 07:28:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371193</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 43 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1rz1b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371496</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>ZeroCopy readers for the ORC file format</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>