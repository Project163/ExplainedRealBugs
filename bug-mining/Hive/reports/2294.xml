<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:20:02 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-7210] NPE with &quot;No plan file found&quot; when running Driver instances on multiple threads</title>
                <link>https://issues.apache.org/jira/browse/HIVE-7210</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Informatica has a multithreaded application running multiple instances of CLIDriver.  When running concurrent queries they sometimes hit the following error:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2014-05-30 10:24:59 &amp;lt;pool-10-thread-1&amp;gt; INFO: Hadoop_Native_Log :INFO org.apache.hadoop.hive.ql.exec.Utilities: No plan file found: hdfs://ICRHHW21NODE1:8020/tmp/hive-qamercury/hive_2014-05-30_10-24-57_346_890014621821056491-2/-mr-10002/6169987c-3263-4737-b5cb-38daab882afb/map.xml
2014-05-30 10:24:59 &amp;lt;pool-10-thread-1&amp;gt; INFO: Hadoop_Native_Log :INFO org.apache.hadoop.mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/qamercury/.staging/job_1401360353644_0078
2014-05-30 10:24:59 &amp;lt;pool-10-thread-1&amp;gt; INFO: Hadoop_Native_Log :ERROR org.apache.hadoop.hive.ql.exec.Task: Job Submission failed with exception &apos;java.lang.NullPointerException(null)&apos;
java.lang.NullPointerException
                at org.apache.hadoop.hive.ql.io.HiveInputFormat.init(HiveInputFormat.java:255)
                at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:271)
                at org.apache.hadoop.mapreduce.JobSubmitter.writeOldSplits(JobSubmitter.java:520)
                at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:512)
                at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:394)
                at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1285)
                at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1282)
                at java.security.AccessController.doPrivileged(Native Method)
                at javax.security.auth.Subject.doAs(Subject.java:415)
                at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1557)
                at org.apache.hadoop.mapreduce.Job.submit(Job.java:1282)
                at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:562)
                at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:557)
                at java.security.AccessController.doPrivileged(Native Method)
                at javax.security.auth.Subject.doAs(Subject.java:415)
                at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1557)
                at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:557)
                at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:548)
                at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:420)
                at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:136)
                at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
                at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)
                at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1504)
                at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1271)
                at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1089)
                at org.apache.hadoop.hive.ql.Driver.run(Driver.java:912)
                at org.apache.hadoop.hive.ql.Driver.run(Driver.java:902)
                at com.informatica.platform.dtm.executor.hive.impl.AbstractHiveDriverBaseImpl.run(AbstractHiveDriverBaseImpl.java:86)
                at com.informatica.platform.dtm.executor.hive.MHiveDriver.executeQuery(MHiveDriver.java:126)
                at com.informatica.platform.dtm.executor.hive.task.impl.HiveTaskHandlerImpl.executeQuery(HiveTaskHandlerImpl.java:358)
                at com.informatica.platform.dtm.executor.hive.task.impl.HiveTaskHandlerImpl.executeScript(HiveTaskHandlerImpl.java:247)
                at com.informatica.platform.dtm.executor.hive.task.impl.HiveTaskHandlerImpl.executeMainScript(HiveTaskHandlerImpl.java:194)
                at com.informatica.platform.ldtm.executor.common.workflow.taskhandler.impl.BaseTaskHandlerImpl.run(BaseTaskHandlerImpl.java:126)
                at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
                at java.util.concurrent.FutureTask.run(FutureTask.java:262)
                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
                at java.lang.Thread.run(Thread.java:744)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12720483">HIVE-7210</key>
            <summary>NPE with &quot;No plan file found&quot; when running Driver instances on multiple threads</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jdere">Jason Dere</assignee>
                                    <reporter username="jdere">Jason Dere</reporter>
                        <labels>
                    </labels>
                <created>Wed, 11 Jun 2014 00:11:50 +0000</created>
                <updated>Thu, 13 Nov 2014 19:39:36 +0000</updated>
                            <resolved>Wed, 18 Jun 2014 01:30:31 +0000</resolved>
                                                    <fixVersion>0.14.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14027257" author="jdere" created="Wed, 11 Jun 2014 00:26:59 +0000"  >&lt;p&gt;I suspect this problem was introduced by &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6888&quot; title=&quot;Hive leaks MapWork objects via Utilities::gWorkMap&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6888&quot;&gt;&lt;del&gt;HIVE-6888&lt;/del&gt;&lt;/a&gt; - if one of the Driver instances calls CombineHiveInputFormat.getSplits() (and thus HiveInputFormat.getSplits()), the global Utilities.gWorkMap is cleared out, which not only removes the map/reduce work for that query, but for any other queries that are being executed by other threads. If any of these other threads tries to call getSplits(), gWorkMap will no longer have the map/reduce work cached, and the current logic doesn&apos;t look like it allows the client to be able to get the plan if it&apos;s not already cached.&lt;br/&gt;
Possible fixes might be&lt;br/&gt;
1) getSplits() should only remove the map/reduce work for the current query, rather than remove all cached work.&lt;br/&gt;
2) Utilities.getBaseWork() should be modified to allow the map/reduce work to be loaded if it is not already cached.&lt;/p&gt;</comment>
                            <comment id="14030972" author="jdere" created="Fri, 13 Jun 2014 18:36:35 +0000"  >&lt;p&gt;Patch to prevent getSplits() from removing cached plans from other queries. Talked to Gunther and he said he can eliminate the call to clear the cached plan from getSplits() altogether, so this may not be the final fix.&lt;/p&gt;</comment>
                            <comment id="14031059" author="hagleitn" created="Fri, 13 Jun 2014 19:37:40 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jdere&quot; class=&quot;user-hover&quot; rel=&quot;jdere&quot;&gt;jdere&lt;/a&gt;. My plan was to do this purely in HiveSplitGen for Tez. But I think Vikram re-introduced a path that doesn&apos;t go through HiveSplitGen (rather - I broke something, he fixed it by adding that path back in). &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vikram.dixit&quot; class=&quot;user-hover&quot; rel=&quot;vikram.dixit&quot;&gt;vikram.dixit&lt;/a&gt; - can you confirm that?&lt;/p&gt;

&lt;p&gt;If that&apos;s the case the patch you uploaded is probably the best fix.&lt;/p&gt;</comment>
                            <comment id="14031990" author="hiveqa" created="Sun, 15 Jun 2014 18:04:56 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12650358/HIVE-7210.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12650358/HIVE-7210.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 5536 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_columnar
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_root_dir_external_table
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_ctas
org.apache.hadoop.hive.conf.TestHiveConf.testConfProperties
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/474/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/474/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/474/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/474/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-474/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-474/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12650358&lt;/p&gt;</comment>
                            <comment id="14032732" author="jdere" created="Mon, 16 Jun 2014 18:27:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hagleitn&quot; class=&quot;user-hover&quot; rel=&quot;hagleitn&quot;&gt;hagleitn&lt;/a&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vikram.dixit&quot; class=&quot;user-hover&quot; rel=&quot;vikram.dixit&quot;&gt;vikram.dixit&lt;/a&gt; does this fix look ok?&lt;/p&gt;</comment>
                            <comment id="14032756" author="hagleitn" created="Mon, 16 Jun 2014 18:42:09 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14032944" author="vikram.dixit" created="Mon, 16 Jun 2014 21:03:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hagleitn&quot; class=&quot;user-hover&quot; rel=&quot;hagleitn&quot;&gt;hagleitn&lt;/a&gt; In case of bucket map joins in tez, the getSplits is not going to take the SplitGenerator path as in case of other hive queries. We will still need this path for cleaning up.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jdere&quot; class=&quot;user-hover&quot; rel=&quot;jdere&quot;&gt;jdere&lt;/a&gt; As discussed offline, there is another method already in this class that takes a configuration and cleans up cache and plans on HDFS. However, we should not be clearing up the plans on hdfs until the query has completed. You will need a new method for this partial clean up.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vikram.&lt;/p&gt;</comment>
                            <comment id="14032956" author="jdere" created="Mon, 16 Jun 2014 21:15:29 +0000"  >&lt;p&gt;Thanks for the info Vikram. It sounds like the current patch will be fine then, as it adds a new method to clean up the work map entry without removing the plan file from HDFS.&lt;/p&gt;</comment>
                            <comment id="14032969" author="vikram.dixit" created="Mon, 16 Jun 2014 21:27:33 +0000"  >&lt;p&gt;Minor comment. Can you refactor the code used in the method clearWork in the Utilities class to use your method instead.&lt;/p&gt;</comment>
                            <comment id="14033108" author="jdere" created="Mon, 16 Jun 2014 22:21:25 +0000"  >&lt;p&gt;Attaching patch to address comments by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vikram.dixit&quot; class=&quot;user-hover&quot; rel=&quot;vikram.dixit&quot;&gt;vikram.dixit&lt;/a&gt;.&lt;br/&gt;
Additionally, it appears that Utilities.clearWork() has a bug where it will not do any cache or hdfs cleanup if either the map or reduce plan path is null.  The updated patch includes a fix for this. &lt;/p&gt;</comment>
                            <comment id="14033111" author="vikram.dixit" created="Mon, 16 Jun 2014 22:23:21 +0000"  >&lt;p&gt;+1 LGTM. Good catch there Jason.&lt;/p&gt;</comment>
                            <comment id="14034641" author="hiveqa" created="Wed, 18 Jun 2014 00:19:37 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12650673/HIVE-7210.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12650673/HIVE-7210.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 7 failed/errored test(s), 5654 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_columnar
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_optimization
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_root_dir_external_table
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_ctas
org.apache.hadoop.hive.ql.exec.tez.TestTezTask.testSubmit
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/494/testReport&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/494/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/494/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/494/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-494/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-494/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12650673&lt;/p&gt;</comment>
                            <comment id="14034687" author="jdere" created="Wed, 18 Jun 2014 01:05:14 +0000"  >&lt;p&gt;I&apos;ve seen several of these tests failing on previous tests. Ran MiniTez dynpart_sort_optimization.q, TestHCatLoader#testReadDataPrimitiveTypes, TestHiveServer2 locally and these pass for me. Will commit this patch shortly.&lt;/p&gt;</comment>
                            <comment id="14034704" author="jdere" created="Wed, 18 Jun 2014 01:30:31 +0000"  >&lt;p&gt;Committed to trunk. Thanks Gunther/Vikram for the review.&lt;/p&gt;</comment>
                            <comment id="14210209" author="thejas" created="Thu, 13 Nov 2014 19:39:36 +0000"  >&lt;p&gt;This has been fixed in 0.14 release. Please open new jira if you see any issues.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12650358" name="HIVE-7210.1.patch" size="1576" author="jdere" created="Fri, 13 Jun 2014 18:36:35 +0000"/>
                            <attachment id="12650673" name="HIVE-7210.2.patch" size="2334" author="jdere" created="Mon, 16 Jun 2014 22:21:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>398682</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 1 week, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1wmyv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>398806</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>