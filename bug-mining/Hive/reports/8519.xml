<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 19:24:25 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-27441] Iceberg: CTLT with source table as Hive managed table fails with &quot;The table must be stored using an ACID compliant format&quot;</title>
                <link>https://issues.apache.org/jira/browse/HIVE-27441</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Iceberg CTLT with source table as Hive managed table fails with &quot;The table must be stored using an ACID compliant format&quot;&lt;/p&gt;

&lt;p&gt;As part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-26519&quot; title=&quot;Iceberg: Add support for CTLT queries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-26519&quot;&gt;&lt;del&gt;HIVE-26519&lt;/del&gt;&lt;/a&gt; the support for creating Iceberg tables using CTLT was added.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
CREATE TABLE `tpch`.`lineitem`(`l_orderkey` &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,`l_partkey` &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,`l_suppkey` &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,`l_linenumber` &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,`l_quantity` decimal(15,2),`l_extendedprice` decimal(15,2),`l_discount` decimal(15,2),`l_tax` decimal(15,2),`l_returnflag` &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;(1),`l_linestatus` &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;(1),`l_shipdate` date,`l_commitdate` date,`l_receiptdate` date,`l_shipinstruct` &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;(25),`l_shipmode` &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;(10),`l_comment` string)ROW FORMAT SERDE&lt;span class=&quot;code-quote&quot;&gt;&apos;org.apache.hadoop.hive.ql.io.orc.OrcSerde&apos;&lt;/span&gt;STORED AS INPUTFORMAT&lt;span class=&quot;code-quote&quot;&gt;&apos;org.apache.hadoop.hive.ql.io.orc.OrcInputFormat&apos;&lt;/span&gt;OUTPUTFORMAT&lt;span class=&quot;code-quote&quot;&gt;&apos;org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat&apos;&lt;/span&gt;LOCATION&lt;span class=&quot;code-quote&quot;&gt;&apos;s3a:&lt;span class=&quot;code-comment&quot;&gt;//qe-s3-bucket-weekly/cc-dwx-97hupz/warehouse/tablespace/managed/hive/tpch.db/lineitem&apos;&lt;/span&gt;TBLPROPERTIES (&lt;span class=&quot;code-quote&quot;&gt;&apos;bucketing_version&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;2&apos;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&apos;transactional&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&apos;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&apos;transactional_properties&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;&apos;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&apos;transient_lastDdlTime&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;1686741574&apos;&lt;/span&gt;)&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Iceberg query&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
CREATE TABLE lineitem LIKE tpch.lineitem
STORED BY ICEBERG;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Error&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Error &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; compiling statement: FAILED: Execution Error, &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; code 40000 from org.apache.hadoop.hive.ql.ddl.DDLTask. MetaException(message:The table must be stored using an ACID compliant format (such as ORC): tpch_ioytc.lineitem) 


INFO  : Compiling command(queryId=hive_20230614191434_298d5e35-3ac9-4b6b-bf4f-132e8b4ad265): create table line like tpch.lineitem stored by iceberg
INFO  : Semantic Analysis Completed (retrial = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)
INFO  : Created Hive schema: Schema(fieldSchemas:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, properties:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
INFO  : Completed compiling command(queryId=hive_20230614191434_298d5e35-3ac9-4b6b-bf4f-132e8b4ad265); Time taken: 0.03 seconds
INFO  : Executing command(queryId=hive_20230614191434_298d5e35-3ac9-4b6b-bf4f-132e8b4ad265): create table line like tpch.lineitem stored by iceberg
INFO  : Starting task [Stage-0:DDL] in serial mode
ERROR : Failed
org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:The table must be stored using an ACID compliant format (such as ORC): tpch_ioytc.line)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1384) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1389) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.ddl.table.create.like.CreateTableLikeOperation.execute(CreateTableLikeOperation.java:88) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.ddl.DDLTask.execute(DDLTask.java:84) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:213) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:360) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:333) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:250) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:111) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:810) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:547) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:541) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:166) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:235) ~[hive-service-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hive.service.cli.operation.SQLOperation.access$700(SQLOperation.java:92) ~[hive-service-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:340) ~[hive-service-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:?]
	at javax.security.auth.Subject.doAs(Subject.java:423) ~[?:?]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899) ~[hadoop-common-3.1.1.7.2.16.0-287.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360) ~[hive-service-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[?:?]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:829) [?:?]
Caused by: org.apache.hadoop.hive.metastore.api.MetaException: The table must be stored using an ACID compliant format (such as ORC): tpch_ioytc.line
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_req_result$create_table_req_resultStandardScheme.read(ThriftHiveMetastore.java) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_req_result$create_table_req_resultStandardScheme.read(ThriftHiveMetastore.java) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_req_result.read(ThriftHiveMetastore.java) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_table_req(ThriftHiveMetastore.java:2143) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_table_req(ThriftHiveMetastore.java:2130) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.create_table(HiveMetaStoreClient.java:4461) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.create_table(SessionHiveMetaStoreClient.java:180) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1403) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1373) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1364) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at jdk.internal.reflect.GeneratedMethodAccessor299.invoke(Unknown Source) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:216) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at com.sun.proxy.$Proxy56.createTable(Unknown Source) ~[?:?]
	at jdk.internal.reflect.GeneratedMethodAccessor299.invoke(Unknown Source) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:4365) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at com.sun.proxy.$Proxy56.createTable(Unknown Source) ~[?:?]
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1373) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	... 27 more
ERROR : DDLTask failed, DDL Operation: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.hadoop.hive.ql.ddl.table.create.like.CreateTableLikeOperation
org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:The table must be stored using an ACID compliant format (such as ORC): tpch_ioytc.line)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1384) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1389) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.ddl.table.create.like.CreateTableLikeOperation.execute(CreateTableLikeOperation.java:88) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.ddl.DDLTask.execute(DDLTask.java:84) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:213) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:360) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:333) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:250) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:111) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:810) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:547) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:541) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:166) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:235) ~[hive-service-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hive.service.cli.operation.SQLOperation.access$700(SQLOperation.java:92) ~[hive-service-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:340) ~[hive-service-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:?]
	at javax.security.auth.Subject.doAs(Subject.java:423) ~[?:?]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899) ~[hadoop-common-3.1.1.7.2.16.0-287.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360) ~[hive-service-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[?:?]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:829) [?:?]
Caused by: org.apache.hadoop.hive.metastore.api.MetaException: The table must be stored using an ACID compliant format (such as ORC): tpch_ioytc.line
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_req_result$create_table_req_resultStandardScheme.read(ThriftHiveMetastore.java) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_req_result$create_table_req_resultStandardScheme.read(ThriftHiveMetastore.java) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_req_result.read(ThriftHiveMetastore.java) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_table_req(ThriftHiveMetastore.java:2143) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_table_req(ThriftHiveMetastore.java:2130) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.create_table(HiveMetaStoreClient.java:4461) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.create_table(SessionHiveMetaStoreClient.java:180) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1403) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1373) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1364) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at jdk.internal.reflect.GeneratedMethodAccessor299.invoke(Unknown Source) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:216) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at com.sun.proxy.$Proxy56.createTable(Unknown Source) ~[?:?]
	at jdk.internal.reflect.GeneratedMethodAccessor299.invoke(Unknown Source) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:4365) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	at com.sun.proxy.$Proxy56.createTable(Unknown Source) ~[?:?]
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1373) ~[hive-exec-3.1.3000.2023.0.15.0-153.jar:3.1.3000.2023.0.15.0-153]
	... 27 more
ERROR : FAILED: Execution Error, &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; code 40000 from org.apache.hadoop.hive.ql.ddl.DDLTask. MetaException(message:The table must be stored using an ACID compliant format (such as ORC): tpch_ioytc.line)
INFO  : Completed executing command(queryId=hive_20230614191434_298d5e35-3ac9-4b6b-bf4f-132e8b4ad265); Time taken: 0.023 seconds
INFO  : OK&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13540095">HIVE-27441</key>
            <summary>Iceberg: CTLT with source table as Hive managed table fails with &quot;The table must be stored using an ACID compliant format&quot;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ayushtkn">Ayush Saxena</assignee>
                                    <reporter username="dharmikt">Dharmik Thakkar</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Wed, 14 Jun 2023 19:19:39 +0000</created>
                <updated>Tue, 15 Aug 2023 06:33:27 +0000</updated>
                            <resolved>Thu, 22 Jun 2023 04:14:03 +0000</resolved>
                                                    <fixVersion>4.0.0-beta-1</fixVersion>
                                    <component>Iceberg integration</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="17735974" author="ayushtkn" created="Thu, 22 Jun 2023 04:13:54 +0000"  >&lt;p&gt;Committed to master.&lt;/p&gt;

&lt;p&gt;Thanx &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dkuzmenko&quot; class=&quot;user-hover&quot; rel=&quot;dkuzmenko&quot;&gt;dkuzmenko&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aturoczy&quot; class=&quot;user-hover&quot; rel=&quot;aturoczy&quot;&gt;aturoczy&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=simhadri-g&quot; class=&quot;user-hover&quot; rel=&quot;simhadri-g&quot;&gt;simhadri-g&lt;/a&gt; for the review &amp;amp; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dharmikt&quot; class=&quot;user-hover&quot; rel=&quot;dharmikt&quot;&gt;dharmikt&lt;/a&gt; for the report!!!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 20 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1ik4w:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>