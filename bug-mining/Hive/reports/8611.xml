<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 19:25:14 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-27161] MetaException when executing CTAS query in Druid storage handler</title>
                <link>https://issues.apache.org/jira/browse/HIVE-27161</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Any kind of CTAS query targeting the Druid storage handler fails with the following exception:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:LOCATION may not be specified for Druid)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1347) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1352) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.ddl.table.create.CreateTableOperation.createTableNonReplaceMode(CreateTableOperation.java:158) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.ddl.table.create.CreateTableOperation.execute(CreateTableOperation.java:116) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.ddl.DDLTask.execute(DDLTask.java:84) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:214) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:354) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:327) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:244) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:105) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:367) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:205) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:149) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:185) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:228) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:257) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:425) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:356) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.dataset.QTestDatasetHandler.initDataset(QTestDatasetHandler.java:86) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.dataset.QTestDatasetHandler.beforeTest(QTestDatasetHandler.java:190) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.qoption.QTestOptionDispatcher.beforeTest(QTestOptionDispatcher.java:79) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.QTestUtil.cliInit(QTestUtil.java:607) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:112) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.TestMiniDruidCliDriver.testCliDriver(TestMiniDruidCliDriver.java:60) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_261]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_261]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_261]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_261]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.Suite.runChild(Suite.java:128) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.Suite.runChild(Suite.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.MetaException: LOCATION may not be specified for Druid
	at org.apache.hadoop.hive.druid.DruidStorageHandler.preCreateTable(DruidStorageHandler.java:219) ~[hive-druid-handler-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1459) ~[hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1435) ~[hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1426) ~[hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_261]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_261]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_261]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_261]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:218) ~[hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy133.createTable(Unknown Source) ~[?:?]
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1336) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	... 67 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;One way of reproducing the problem is by removing the &lt;tt&gt;@Ignore&lt;/tt&gt; annotation from &lt;tt&gt;TestMiniDruidCliDriver&lt;/tt&gt; and running:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;mvn test -Dtest=TestMiniDruidCliDriver -Dqfile=druidmini_expressions.q
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The druidmini_expressions.q file has &lt;tt&gt;druid_table_alltypesorc&lt;/tt&gt; dataset and the latter is initialized with the CTAS query outlined below:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sql&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;EXTERNAL&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;TABLE&lt;/span&gt; druid_table_alltypesorc
STORED &lt;span class=&quot;code-keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;org.apache.hadoop.hive.druid.DruidStorageHandler&apos;&lt;/span&gt;
TBLPROPERTIES (&lt;span class=&quot;code-quote&quot;&gt;&quot;druid.segment.granularity&quot;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;HOUR&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;druid.query.granularity&quot;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;MINUTE&lt;/span&gt;&quot;&lt;/span&gt;)
&lt;span class=&quot;code-keyword&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; (`ctimestamp1` &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;timestamp&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;zone&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; `__time`,
  cstring1,
  cstring2,
  cdouble,
  cfloat,
  ctinyint,
  csmallint,
  cint,
  cbigint,
  cboolean1,
  cboolean2,
  &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(cint &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;string&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; cintstring,
  &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(cfloat &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;string&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; cfloatstring,
  &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(cdouble &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;string&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; cdoublestring
  &lt;span class=&quot;code-keyword&quot;&gt;FROM&lt;/span&gt; alltypesorc1 &lt;span class=&quot;code-keyword&quot;&gt;where&lt;/span&gt; ctimestamp1 &lt;span class=&quot;code-keyword&quot;&gt;IS&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;NULL&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is a regression caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-26771&quot; title=&quot;Use DDLTask to created Iceberg table when running ctas statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-26771&quot;&gt;&lt;del&gt;HIVE-26771&lt;/del&gt;&lt;/a&gt; that is likely to affect other storage handlers as well.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13529461">HIVE-27161</key>
            <summary>MetaException when executing CTAS query in Druid storage handler</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kkasa">Krisztian Kasa</assignee>
                                    <reporter username="zabetak">Stamatis Zampetakis</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Tue, 21 Mar 2023 14:40:57 +0000</created>
                <updated>Fri, 29 Mar 2024 17:49:50 +0000</updated>
                            <resolved>Thu, 21 Dec 2023 12:42:45 +0000</resolved>
                                    <version>4.0.0-alpha-1</version>
                    <version>4.0.0-alpha-2</version>
                                    <fixVersion>4.0.0</fixVersion>
                                    <component>Druid integration</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="17703237" author="zabetak" created="Tue, 21 Mar 2023 14:43:09 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kkasa&quot; class=&quot;user-hover&quot; rel=&quot;kkasa&quot;&gt;kkasa&lt;/a&gt; since you worked on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-26771&quot; title=&quot;Use DDLTask to created Iceberg table when running ctas statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-26771&quot;&gt;&lt;del&gt;HIVE-26771&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17781743" author="JIRAUSER295887" created="Wed, 1 Nov 2023 14:07:00 +0000"  >&lt;p&gt;I am facing this issue in hive-4.0.0-alpha-1 too.&lt;/p&gt;

&lt;p&gt;Here are the steps to repro.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
1.
CREATE TABLE emp_zlib_3110_2038 (
`__time` TIMESTAMP,
&#160;id &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
&#160;name string,
&#160;age &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
&#160;gender string)
&#160;STORED AS ORC
&#160;TBLPROPERTIES (&lt;span class=&quot;code-quote&quot;&gt;&apos;transactional&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&apos;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;orc.compress&quot;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&quot;ZLIB&quot;&lt;/span&gt;);

2.
insert into emp_zlib_3110_2038 values(CURRENT_TIMESTAMP(),10,&lt;span class=&quot;code-quote&quot;&gt;&apos;basa&apos;&lt;/span&gt;,30,&lt;span class=&quot;code-quote&quot;&gt;&apos;M&apos;&lt;/span&gt;);

3.
CREATE EXTERNAL TABLE druid_table_0111
STORED BY &lt;span class=&quot;code-quote&quot;&gt;&apos;org.apache.hadoop.hive.druid.DruidStorageHandler&apos;&lt;/span&gt;
TBLPROPERTIES (&lt;span class=&quot;code-quote&quot;&gt;&quot;druid.datasource&quot;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&quot;basa_druid_table_01112023&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;orc.compress&quot;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&quot;ZLIB&quot;&lt;/span&gt;)
AS&#160;
select `__time`, id,name,age,gender from emp_zlib_3110_2038;
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Error as followed.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
INFO &#160;: Status: Running (Executing on YARN cluster with App id application_1698753624381_0028)
----------------------------------------------------------------------------------------------
&#160; &#160; &#160; &#160; VERTICES &#160; &#160; &#160;MODE &#160; &#160; &#160; &#160;STATUS &#160;TOTAL &#160;COMPLETED &#160;RUNNING &#160;PENDING &#160;FAILED &#160;KILLED
----------------------------------------------------------------------------------------------
Map 1 .......... container &#160; &#160; SUCCEEDED &#160; &#160; &#160;1 &#160; &#160; &#160; &#160; &#160;1 &#160; &#160; &#160; &#160;0 &#160; &#160; &#160; &#160;0 &#160; &#160; &#160; 0 &#160; &#160; &#160; 0
Reducer 2 ...... container &#160; &#160; SUCCEEDED &#160; &#160; &#160;2 &#160; &#160; &#160; &#160; &#160;2 &#160; &#160; &#160; &#160;0 &#160; &#160; &#160; &#160;0 &#160; &#160; &#160; 0 &#160; &#160; &#160; 0
----------------------------------------------------------------------------------------------
VERTICES: 02/02 &#160;[==========================&amp;gt;&amp;gt;] 100% &#160;ELAPSED TIME: 18.13 s
----------------------------------------------------------------------------------------------
 

INFO&#160; : Starting task [Stage-4:DDL] in serial modeERROR : Failedorg.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:LOCATION may not be specified &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Druid)	
at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1313) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1318) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.ddl.table.create.CreateTableOperation.createTableNonReplaceMode(CreateTableOperation.java:140) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.ddl.table.create.CreateTableOperation.execute(CreateTableOperation.java:98) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.ddl.DDLTask.execute(DDLTask.java:84) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:212) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:361) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:334) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:245) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:106) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:348) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:204) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:148) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:185) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) ~[hive-service-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) ~[hive-service-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) ~[hive-service-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_382]	
at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_382]	
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762) ~[hadoop-common-3.2.3.3.2.2.0-1.jar:?]	
at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) ~[hive-service-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]	
at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]	
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]	
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]	
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:750) [?:1.8.0_382]

Caused by: org.apache.hadoop.hive.metastore.api.MetaException: LOCATION may not be specified &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Druid	
at org.apache.hadoop.hive.druid.DruidStorageHandler.preCreateTable(DruidStorageHandler.java:219) ~[hive-druid-handler-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1402) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1378) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1369) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]	
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]	
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]
at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]
at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:218) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]
at com.sun.proxy.$Proxy33.createTable(Unknown Source) ~[?:?]	
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]	
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]	
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:4342) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
at com.sun.proxy.$Proxy33.createTable(Unknown Source) ~[?:?]	
at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1302) ~[hive-exec-3.1.4.3.2.2.0-1.jar:3.1.4.3.2.2.0-1]	
... 27 moreERROR : 

DDLTask failed, DDL Operation: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.hadoop.hive.ql.ddl.table.create.CreateTableOperation&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Is there any workaround/patch to pass this state.? Appreciated any help on this.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17799414" author="kkasa" created="Thu, 21 Dec 2023 12:42:45 +0000"  >&lt;p&gt;Merged to master. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dkuzmenko&quot; class=&quot;user-hover&quot; rel=&quot;dkuzmenko&quot;&gt;dkuzmenko&lt;/a&gt; for review!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                                                <inwardlinks description="is caused by">
                                        <issuelink>
            <issuekey id="13505538">HIVE-26771</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 46 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1gqv4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>