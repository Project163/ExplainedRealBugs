<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 18:01:57 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HIVE-3275] Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3275</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;autolocal1.q is failing only on hadoop0.23 MR2, due to cluster initialization problem:&lt;/p&gt;

&lt;p&gt;Begin query: autolocal1.q&lt;br/&gt;
diff -a /var/lib/jenkins/workspace/zhenxiao-CDH4-Hive-0.9.0/build/ql/test/logs/clientnegative/autolocal1.q.out /var/lib/jenkins/workspace/zhenxiao-CDH4-Hive-0.9.0/ql/src/test/results/clientnegative/autolocal1.q.out&lt;br/&gt;
5c5&lt;br/&gt;
&amp;lt; Job Submission failed with exception &apos;java.io.IOException(Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.)&apos;&lt;br/&gt;
&#8212;&lt;br/&gt;
&amp;gt; Job Submission failed with exception &apos;java.lang.IllegalArgumentException(Does not contain a valid host:port authority: abracadabra)&apos;&lt;br/&gt;
Exception: Client execution results failed with error code = 1&lt;br/&gt;
See build/ql/tmp/hive.log, or try &quot;ant test ... -Dtest.silent=false&quot; to get more logs.&lt;br/&gt;
Failed query: autolocal1.q&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599389">HIVE-3275</key>
            <summary>Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zhenxiao">Zhenxiao Luo</assignee>
                                    <reporter username="zhenxiao">Zhenxiao Luo</reporter>
                        <labels>
                    </labels>
                <created>Thu, 19 Jul 2012 01:34:18 +0000</created>
                <updated>Thu, 10 Jan 2013 19:53:53 +0000</updated>
                            <resolved>Thu, 26 Jul 2012 05:43:05 +0000</resolved>
                                                    <fixVersion>0.10.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="13417952" author="zhenxiao" created="Thu, 19 Jul 2012 01:36:15 +0000"  >&lt;p&gt;After adding the following to autolocal1.q to initialize MR2 yarn framework:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=%2FCode%2Fhive&quot; class=&quot;user-hover&quot; rel=&quot;/Code/hive&quot;&gt;/Code/hive&lt;/a&gt;git diff ql/src/test/queries/clientnegative/autolocal1.q&lt;br/&gt;
diff --git a/ql/src/test/queries/clientnegative/autolocal1.q b/ql/src/test/queries/clientnegative/autolocal1.q&lt;br/&gt;
index 6bee177..8623eb5 100644&lt;br/&gt;
&amp;#8212; a/ql/src/test/queries/clientnegative/autolocal1.q&lt;br/&gt;
+++ b/ql/src/test/queries/clientnegative/autolocal1.q&lt;br/&gt;
@@ -1,3 +1,4 @@&lt;br/&gt;
+set mapreduce.framework.name=yarn;&lt;br/&gt;
 set mapred.job.tracker=abracadabra;&lt;br/&gt;
 set hive.exec.mode.local.auto.inputbytes.max=1;&lt;br/&gt;
 set hive.exec.mode.local.auto=true;&lt;/p&gt;

&lt;p&gt;Still getting the following diffs:&lt;/p&gt;

&lt;p&gt;diff -a /home/cloudera/Code/hive/build/ql/test/logs/clientnegative/autolocal1.q.out /home/cloudera/Code/hive/ql/src/test/results/clientnegative/autolocal1.q.out&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 5c5&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;lt; Job Submission failed with exception &apos;java.lang.reflect.UndeclaredThrowableException(null)&apos;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &#8212;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; Job Submission failed with exception &apos;java.lang.IllegalArgumentException(Does not contain a valid host:port authority: abracadabra)&apos;&lt;/p&gt;</comment>
                            <comment id="13417965" author="zhenxiao" created="Thu, 19 Jul 2012 01:49:29 +0000"  >&lt;p&gt;The reason is:&lt;/p&gt;

&lt;p&gt;1. On hadoop0.20 or Hadoop0.23 MR1,&lt;/p&gt;

&lt;p&gt;JobClient jc = new JobClient(job);&lt;/p&gt;

&lt;p&gt;this line is throwing exception in ExecDriver.java.&lt;/p&gt;

&lt;p&gt;It calls into JobClient.java:&lt;/p&gt;

&lt;p&gt;public JobClient(JobConf conf) throws IOException &lt;/p&gt;
{
    setConf(conf);
    init(conf);
  }

&lt;p&gt;  /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Connect to the default 
{@link JobTracker}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@param conf the job configuration.&lt;/li&gt;
	&lt;li&gt;@throws IOException&lt;br/&gt;
   */&lt;br/&gt;
  public void init(JobConf conf) throws IOException 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    String tracker = conf.get(&amp;quot;mapred.job.tracker&amp;quot;, &amp;quot;local&amp;quot;);    if (&amp;quot;local&amp;quot;.equals(tracker)) {
      this.jobSubmitClient = new LocalJobRunner(conf);
    } else {
      this.jobSubmitClient = createRPCProxy(JobTracker.getAddress(conf), conf);
    }  }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;When createRPCProxy() is called, jobtracker is trying to getAddress(conf) of the non-existed host(abracadabra), and throws the expected exception:&lt;br/&gt;
java.lang.IllegalArgumentException: Does not contain a valid host:port authority: abracadabra&lt;/p&gt;

&lt;p&gt;Here is the log and stack trace when running in hadoop0.20 to proof the above observation:&lt;/p&gt;

&lt;p&gt;2012-07-18 17:53:38,210 ERROR exec.Task (SessionState.java:printError(400)) - Job Submission failed with exception &apos;java.lang.IllegalArgumentException(Does not contain a valid host:port authority: abracadabra)&apos;&lt;br/&gt;
java.lang.IllegalArgumentException: Does not contain a valid host:port authority: abracadabra     &lt;br/&gt;
    at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:206)&lt;br/&gt;
    at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:158)                         &lt;br/&gt;
    at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:147)                         &lt;br/&gt;
    at org.apache.hadoop.mapred.JobTracker.getAddress(JobTracker.java:2119)                       &lt;br/&gt;
    at org.apache.hadoop.mapred.JobClient.init(JobClient.java:497)&lt;br/&gt;
    at org.apache.hadoop.mapred.JobClient.&amp;lt;init&amp;gt;(JobClient.java:469)                              &lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:418)                     &lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.MapRedTask.execute(MapRedTask.java:136)                     &lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:134)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57)                &lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1324)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1110)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.run(Driver.java:944)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:258)                   &lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:215)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:406)                       &lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:341)                       &lt;br/&gt;
    at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:671)                      &lt;br/&gt;
    at org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_autolocal1(TestNegativeCliDriver.java:117)&lt;br/&gt;
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)              &lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)      &lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:616)&lt;br/&gt;
    at junit.framework.TestCase.runTest(TestCase.java:168)&lt;br/&gt;
    at junit.framework.TestCase.runBare(TestCase.java:134)                                        &lt;br/&gt;
    at junit.framework.TestResult$1.protect(TestResult.java:110)                                  &lt;br/&gt;
    at junit.framework.TestResult.runProtected(TestResult.java:128)                               &lt;br/&gt;
    at junit.framework.TestResult.run(TestResult.java:113)&lt;br/&gt;
    at junit.framework.TestCase.run(TestCase.java:124)&lt;br/&gt;
    at junit.framework.TestSuite.runTest(TestSuite.java:243)                                      &lt;br/&gt;
    at junit.framework.TestSuite.run(TestSuite.java:238)                                          &lt;br/&gt;
    at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420) &lt;br/&gt;
    at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)   &lt;br/&gt;
    at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)&lt;/p&gt;

&lt;p&gt;2012-07-18 17:53:38,215 ERROR ql.Driver (SessionState.java:printError(400)) - FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MapRedTask &lt;/p&gt;

&lt;p&gt;2. When running in hadoop0.23 MR2. MapReduce2 is using Yarn framework,&lt;/p&gt;

&lt;p&gt;JobClient jc = new JobClient(job)&lt;/p&gt;

&lt;p&gt;this line in ExecDriver.java is calling into MR2&apos;s implementation of JobClient:&lt;/p&gt;

&lt;p&gt;public JobClient(Configuration conf) throws IOException &lt;/p&gt;
{
    init(new JobConf(conf));
  }

&lt;p&gt;  /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Connect to the default cluster&lt;/li&gt;
	&lt;li&gt;@param conf the job configuration.&lt;/li&gt;
	&lt;li&gt;@throws IOException&lt;br/&gt;
   */&lt;br/&gt;
  public void init(JobConf conf) throws IOException 
{
    setConf(conf);
    cluster = new Cluster(conf);
    clientUgi = UserGroupInformation.getCurrentUser();
  }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In MR2&apos;s implementation of init(JobConf), it does not try to getAddress(conf) of the non-existed host(abracadabra). It only tries to initialize the cluster. This is working OK with a proof of the following log:&lt;/p&gt;

&lt;p&gt;2012-07-18 17:34:26,539 INFO  exec.ExecDriver (ExecDriver.java:addInputPaths(860)) - Adding input file pfile:/home/cloudera/Code/hive/build/ql/test/data/warehouse/src&lt;br/&gt;
2012-07-18 17:34:26,539 INFO  exec.Utilities (Utilities.java:isEmptyPath(1804)) - Content Summary pfile:/home/cloudera/Code/hive/build/ql/test/data/warehouse/srclength: 5868 num files: 2 num directories: 1&lt;br/&gt;
2012-07-18 17:34:26,877 DEBUG mapreduce.Cluster (Cluster.java:initialize(91)) - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider&lt;br/&gt;
2012-07-18 17:34:26,877 DEBUG mapreduce.Cluster (Cluster.java:initialize(109)) - Cannot pick org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider - returned null protocol&lt;br/&gt;
2012-07-18 17:34:26,879 DEBUG mapreduce.Cluster (Cluster.java:initialize(91)) - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider&lt;br/&gt;
2012-07-18 17:34:26,972 DEBUG ipc.YarnRPC (YarnRPC.java:create(57)) - Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC&lt;br/&gt;
2012-07-18 17:34:27,000 DEBUG mapred.ResourceMgrDelegate (ResourceMgrDelegate.java:&amp;lt;init&amp;gt;(89)) - Connecting to ResourceManager at /0.0.0.0:8032&lt;br/&gt;
2012-07-18 17:34:27,002 DEBUG ipc.HadoopYarnProtoRPC (HadoopYarnProtoRPC.java:getProxy(45)) - Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ClientRMProtocol&lt;br/&gt;
2012-07-18 17:34:27,038 DEBUG ipc.Server (Server.java:registerProtocolEngine(197)) - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWritable, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@1b34cd7b&lt;br/&gt;
2012-07-18 17:34:27,166 DEBUG mapred.ResourceMgrDelegate (ResourceMgrDelegate.java:&amp;lt;init&amp;gt;(93)) - Connected to ResourceManager at /0.0.0.0:8032&lt;br/&gt;
2012-07-18 17:34:27,172 DEBUG security.UserGroupInformation (UserGroupInformation.java:logPrivilegedAction(1254)) - PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:319)&lt;br/&gt;
2012-07-18 17:34:27,186 DEBUG mapreduce.Cluster (Cluster.java:initialize(104)) - Picked org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider&lt;/p&gt;

&lt;p&gt;An exception occurs in ExecDriver.java, when it is submitting the job to yarn:&lt;/p&gt;

&lt;p&gt;rj = jc.submitJob(job);&lt;/p&gt;

&lt;p&gt;Due to the non-existed host(abracadabra), JobClient.submitJob() fails with exception, with a proof of the following log:&lt;/p&gt;

&lt;p&gt;2012-07-18 17:34:27,235 DEBUG mapred.ResourceMgrDelegate (ResourceMgrDelegate.java:getStagingAreaDir(276)) - getStagingAreaDir: dir=/tmp/hadoop-yarn/staging/cloudera/.staging&lt;br/&gt;
2012-07-18 17:34:27,280 DEBUG ipc.Client (Client.java:&amp;lt;init&amp;gt;(262)) - The ping interval is 60000 ms.&lt;br/&gt;
2012-07-18 17:34:27,287 DEBUG ipc.Client (Client.java:&amp;lt;init&amp;gt;(305)) - Use SIMPLE authentication for protocol ClientRMProtocolPB&lt;br/&gt;
2012-07-18 17:34:27,287 DEBUG ipc.Client (Client.java:setupIOstreams(560)) - Connecting to /0.0.0.0:8032&lt;br/&gt;
2012-07-18 17:34:28,295 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s).&lt;br/&gt;
2012-07-18 17:34:29,297 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s).&lt;br/&gt;
2012-07-18 17:34:30,299 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s).&lt;br/&gt;
2012-07-18 17:34:31,301 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s).&lt;br/&gt;
2012-07-18 17:34:32,303 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s).&lt;br/&gt;
2012-07-18 17:34:33,305 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s).&lt;br/&gt;
2012-07-18 17:34:34,306 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s).&lt;br/&gt;
2012-07-18 17:34:35,308 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s).&lt;br/&gt;
2012-07-18 17:34:36,311 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s).&lt;br/&gt;
2012-07-18 17:34:37,312 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s).&lt;br/&gt;
2012-07-18 17:34:37,314 DEBUG ipc.Client (Client.java:close(917)) - closing ipc connection to 0.0.0.0/0.0.0.0:8032: Connection refused&lt;br/&gt;
java.net.ConnectException: Connection refused&lt;br/&gt;
    at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)&lt;br/&gt;
    at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:592)&lt;br/&gt;
    at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)&lt;br/&gt;
    at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:524)&lt;br/&gt;
    at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)&lt;br/&gt;
    at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:472)&lt;br/&gt;
    at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:566)&lt;br/&gt;
    at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:215)&lt;br/&gt;
    at org.apache.hadoop.ipc.Client.getConnection(Client.java:1271)&lt;br/&gt;
    at org.apache.hadoop.ipc.Client.call(Client.java:1141)&lt;br/&gt;
    at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:184)&lt;br/&gt;
    at $Proxy9.getNewApplication(Unknown Source)&lt;br/&gt;
    at org.apache.hadoop.yarn.api.impl.pb.client.ClientRMProtocolPBClientImpl.getNewApplication(ClientRMProtocolPBClientImpl.java:132)&lt;br/&gt;
    at org.apache.hadoop.mapred.ResourceMgrDelegate.getNewJobID(ResourceMgrDelegate.java:181)&lt;br/&gt;
    at org.apache.hadoop.mapred.YARNRunner.getNewJobID(YARNRunner.java:214)&lt;br/&gt;
    at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:338)&lt;br/&gt;
    at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1226)&lt;br/&gt;
    at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1223)&lt;br/&gt;
    at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
    at javax.security.auth.Subject.doAs(Subject.java:416)&lt;br/&gt;
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)&lt;br/&gt;
    at org.apache.hadoop.mapreduce.Job.submit(Job.java:1223)&lt;br/&gt;
    at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:617)&lt;br/&gt;
    at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:612)&lt;br/&gt;
    at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
    at javax.security.auth.Subject.doAs(Subject.java:416)&lt;br/&gt;
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)&lt;br/&gt;
    at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:612)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:435)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.MapRedTask.execute(MapRedTask.java:136)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:134)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1324)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1110)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.run(Driver.java:944)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:258)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:215)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:406)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:341)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:671)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_autolocal1(TestNegativeCliDriver.java:117)&lt;br/&gt;
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:616)&lt;br/&gt;
    at junit.framework.TestCase.runTest(TestCase.java:168)&lt;/p&gt;

</comment>
                            <comment id="13417972" author="zhenxiao" created="Thu, 19 Jul 2012 01:55:35 +0000"  >&lt;p&gt;My plan is to keep autolocal1.q running only in hadoop0.20.&lt;/p&gt;</comment>
                            <comment id="13417990" author="zhenxiao" created="Thu, 19 Jul 2012 02:19:00 +0000"  >&lt;p&gt;review request submitted at:&lt;br/&gt;
&lt;a href=&quot;https://reviews.facebook.net/D4221&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.facebook.net/D4221&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13417998" author="zhenxiao" created="Thu, 19 Jul 2012 02:29:18 +0000"  >&lt;p&gt;In summary,&lt;/p&gt;

&lt;p&gt;In hadoop0.20,&lt;/p&gt;

&lt;p&gt;JobClient initialization would try to get JobTracker&apos;s address, which throws the expected exception.&lt;/p&gt;

&lt;p&gt;While, in hadoop0.23,&lt;/p&gt;

&lt;p&gt;JobClient Initialization would try which protocol to choose.&lt;/p&gt;

&lt;p&gt;If MR1, it would do the same as hadoop0.20.&lt;/p&gt;

&lt;p&gt;If MR2, it does not try to get JobTracker&apos;s address in JobClient initialization. No exception thrown at this time.&lt;/p&gt;

&lt;p&gt;This will be an exception when the jobClient submitJob.&lt;/p&gt;

&lt;p&gt;Since the expected exception on hadoop0.23 diffs for MR1 and MR2, and the execution path has changed for MR1 and MR2, My plan is only running this test on hadoop0.20.&lt;/p&gt;</comment>
                            <comment id="13417999" author="zhenxiao" created="Thu, 19 Jul 2012 02:32:27 +0000"  >&lt;p&gt;@Joydeep:&lt;/p&gt;

&lt;p&gt;Any comments are appreciated. I&apos;d like to know the idea from autolocal1.q&apos;s original author.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Zhenxiao&lt;/p&gt;</comment>
                            <comment id="13418029" author="jsensarma" created="Thu, 19 Jul 2012 03:27:06 +0000"  >&lt;p&gt;that sounds like a reasonable approach. it&apos;s a hive test, not hadoop - so as long as hive is trying to generate a non-local mode job (i am guessing that&apos;s what&apos;s being tested here) and that&apos;s verified against some hadoop tree - we are good.&lt;/p&gt;</comment>
                            <comment id="13422739" author="ashutoshc" created="Wed, 25 Jul 2012 23:50:59 +0000"  >&lt;p&gt;Even between 0.20 and 1.x series, Exception type has changed from RuntimeException to IllegalArgumentTypeException as well as exception message has changed. I don&apos;t see any easy way to keep our testcases to succeed with such changes given our diff based comparisons. I think its fine to just make sure it run against one version and gives desired behavior. +1. will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13422911" author="ashutoshc" created="Thu, 26 Jul 2012 05:43:05 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Zhenxiao!&lt;/p&gt;</comment>
                            <comment id="13423662" author="hudson" created="Fri, 27 Jul 2012 04:21:50 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1569 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1569/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1569/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3275&quot; title=&quot;Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3275&quot;&gt;&lt;del&gt;HIVE-3275&lt;/del&gt;&lt;/a&gt; : Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2 (Zhenxiao Luo via Ashutosh Chauhan) (Revision 1365888)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365888&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365888&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/autolocal1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/autolocal1.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548117" author="hudson" created="Wed, 9 Jan 2013 10:24:27 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3275&quot; title=&quot;Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3275&quot;&gt;&lt;del&gt;HIVE-3275&lt;/del&gt;&lt;/a&gt; : Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2 (Zhenxiao Luo via Ashutosh Chauhan) (Revision 1365888)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365888&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365888&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/autolocal1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/autolocal1.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550230" author="ashutoshc" created="Thu, 10 Jan 2013 19:53:53 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12600246">HIVE-3301</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12537123" name="HIVE-3275.1.patch.txt" size="1853" author="zhenxiao" created="Thu, 19 Jul 2012 02:19:41 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>242371</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 45 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02u67:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14489</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>