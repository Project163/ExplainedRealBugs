diff --git a/ql/src/test/results/clientpositive/convert_enum_to_string.q.out b/ql/src/test/results/clientpositive/convert_enum_to_string.q.out
index ee33631e11..a46857fdac 100644
--- a/ql/src/test/results/clientpositive/convert_enum_to_string.q.out
+++ b/ql/src/test/results/clientpositive/convert_enum_to_string.q.out
@@ -37,16 +37,15 @@ my_binary           	struct<hb:binary,offset:int,isreadonly:boolean,bigendian:bo
 my_string_string_map	map<string,string>  	from deserializer   
 my_string_enum_map  	map<string,string>  	from deserializer   
 my_enum_string_map  	map<string,string>  	from deserializer   
-my_enum_struct_map  	map<string,struct<my_string:string,my_enum:string,optionals:struct<>>>	from deserializer   
+my_enum_struct_map  	map<string,struct<my_string:string,my_enum:string>>	from deserializer   
 my_enum_stringlist_map	map<string,array<string>>	from deserializer   
-my_enum_structlist_map	map<string,array<struct<my_string:string,my_enum:string,optionals:struct<>>>>	from deserializer   
+my_enum_structlist_map	map<string,array<struct<my_string:string,my_enum:string>>>	from deserializer   
 my_stringlist       	array<string>       	from deserializer   
-my_structlist       	array<struct<my_string:string,my_enum:string,optionals:struct<>>>	from deserializer   
+my_structlist       	array<struct<my_string:string,my_enum:string>>	from deserializer   
 my_enumlist         	array<string>       	from deserializer   
 my_stringset        	array<string>       	from deserializer   
 my_enumset          	array<string>       	from deserializer   
-my_structset        	array<struct<my_string:string,my_enum:string,optionals:struct<>>>	from deserializer   
-optionals           	struct<>            	from deserializer   
+my_structset        	array<struct<my_string:string,my_enum:string>>	from deserializer   
 b                   	string              	                    
 	 	 
 # Partition Information	 	 
diff --git a/ql/src/test/results/clientpositive/dynamic_rdd_cache.q.out b/ql/src/test/results/clientpositive/dynamic_rdd_cache.q.out
index 69fe396f45..394af7ec15 100644
--- a/ql/src/test/results/clientpositive/dynamic_rdd_cache.q.out
+++ b/ql/src/test/results/clientpositive/dynamic_rdd_cache.q.out
@@ -1066,19 +1066,23 @@ STAGE PLANS:
           mode: mergepartial
           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
           Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
-          Filter Operator
-            predicate: (CASE (_col5) WHEN (0) THEN (0) ELSE ((_col4 / _col5)) END > 1) (type: boolean)
+          Select Operator
+            expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int), _col4 (type: double), _col5 (type: double)
+            outputColumnNames: _col1, _col2, _col3, _col4, _col5
             Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
-            Select Operator
-              expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int), _col5 (type: double), CASE (_col5) WHEN (0) THEN (null) ELSE ((_col4 / _col5)) END (type: double)
-              outputColumnNames: _col1, _col2, _col3, _col5, _col6
+            Filter Operator
+              predicate: (CASE (_col5) WHEN (0) THEN (0) ELSE ((_col4 / _col5)) END > 1) (type: boolean)
               Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
-              File Output Operator
-                compressed: true
-                table:
-                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
+              Select Operator
+                expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int), _col5 (type: double), CASE (_col5) WHEN (0) THEN (null) ELSE ((_col4 / _col5)) END (type: double)
+                outputColumnNames: _col1, _col2, _col3, _col5, _col6
+                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
+                File Output Operator
+                  compressed: true
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
 
   Stage: Stage-5
     Map Reduce
@@ -1289,19 +1293,23 @@ STAGE PLANS:
           mode: mergepartial
           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
           Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
-          Filter Operator
-            predicate: (CASE (_col5) WHEN (0) THEN (0) ELSE ((_col4 / _col5)) END > 1) (type: boolean)
+          Select Operator
+            expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int), _col4 (type: double), _col5 (type: double)
+            outputColumnNames: _col1, _col2, _col3, _col4, _col5
             Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
-            Select Operator
-              expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int), _col5 (type: double), CASE (_col5) WHEN (0) THEN (null) ELSE ((_col4 / _col5)) END (type: double)
-              outputColumnNames: _col1, _col2, _col3, _col5, _col6
+            Filter Operator
+              predicate: (CASE (_col5) WHEN (0) THEN (0) ELSE ((_col4 / _col5)) END > 1) (type: boolean)
               Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
-              File Output Operator
-                compressed: true
-                table:
-                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
+              Select Operator
+                expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int), _col5 (type: double), CASE (_col5) WHEN (0) THEN (null) ELSE ((_col4 / _col5)) END (type: double)
+                outputColumnNames: _col1, _col2, _col3, _col5, _col6
+                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
+                File Output Operator
+                  compressed: true
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
 
   Stage: Stage-0
     Fetch Operator
