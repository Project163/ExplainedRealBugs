diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index bce2a062ae..5ce31f1991 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -165,6 +165,7 @@
 import org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe;
 import org.apache.hadoop.hive.serde2.SerDeException;
 import org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe;
+import org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
 import org.apache.hadoop.hive.serde2.objectinspector.StructField;
@@ -2479,6 +2480,50 @@ private static GenericUDAFEvaluator.Mode groupByDescModeToUDAFMode(
     }
   }
 
+  /**
+   * Check if the given internalName represents a constant parameter in aggregation parameters
+   * of an aggregation tree.
+   * This method is only invoked when map-side aggregation is not involved. In this case,
+   * every parameter in every aggregation tree should already have a corresponding ColumnInfo,
+   * which is generated when the corresponding ReduceSinkOperator of the GroupByOperator being
+   * generating is generated. If we find that this parameter is a constant parameter,
+   * we will return the corresponding ExprNodeDesc in reduceValues, and we will not need to
+   * use a new ExprNodeColumnDesc, which can not be treated as a constant parameter, for this
+   * parameter (since the writableObjectInspector of a ExprNodeColumnDesc will not be
+   * a instance of ConstantObjectInspector).
+   *
+   * @param reduceValues
+   *          value columns of the corresponding ReduceSinkOperator
+   * @param internalName
+   *          the internal name of this parameter
+   * @return the ExprNodeDesc of the constant parameter if the given internalName represents
+   *         a constant parameter; otherwise, return null
+   */
+  private ExprNodeDesc isConstantParameterInAggregationParameters(String internalName,
+      List<ExprNodeDesc> reduceValues) {
+    // only the pattern of "VALUE._col([0-9]+)" should be handled.
+
+    String[] terms = internalName.split("\\.");
+    if (terms.length != 2 || reduceValues == null) {
+      return null;
+    }
+
+    if (Utilities.ReduceField.VALUE.toString().equals(terms[0])) {
+      int pos = getPositionFromInternalName(terms[1]);
+      if (pos >= 0 && pos < reduceValues.size()) {
+        ExprNodeDesc reduceValue = reduceValues.get(pos);
+        if (reduceValue != null) {
+          if (reduceValue.getWritableObjectInspector() instanceof ConstantObjectInspector) {
+            // this internalName represents a constant parameter in aggregation parameters
+            return reduceValue;
+          }
+        }
+      }
+    }
+
+    return null;
+  }
+
   /**
    * Generate the GroupByOperator for the Query Block (parseInfo.getXXX(dest)).
    * The new GroupByOperator will be a child of the reduceSinkOperatorInfo.
@@ -2528,12 +2573,14 @@ private Operator genGroupByPlanGroupByOperator(QBParseInfo parseInfo,
     // get the last colName for the reduce KEY
     // it represents the column name corresponding to distinct aggr, if any
     String lastKeyColName = null;
+    List<ExprNodeDesc> reduceValues = null;
     if (reduceSinkOperatorInfo.getConf() instanceof ReduceSinkDesc) {
       List<String> inputKeyCols = ((ReduceSinkDesc)
           reduceSinkOperatorInfo.getConf()).getOutputKeyColumnNames();
       if (inputKeyCols.size() > 0) {
         lastKeyColName = inputKeyCols.get(inputKeyCols.size()-1);
       }
+      reduceValues = ((ReduceSinkDesc)reduceSinkOperatorInfo.getConf()).getValueCols();
     }
     int numDistinctUDFs = 0;
     for (Map.Entry<String, ASTNode> entry : aggregationTrees.entrySet()) {
@@ -2565,9 +2612,19 @@ private Operator genGroupByPlanGroupByOperator(QBParseInfo parseInfo,
           getColumnInternalName(i-1);
 
         }
-        aggParameters.add(new ExprNodeColumnDesc(paraExprInfo.getType(),
+
+        ExprNodeDesc expr = new ExprNodeColumnDesc(paraExprInfo.getType(),
             paraExpression, paraExprInfo.getTabAlias(),
-            paraExprInfo.getIsVirtualCol()));
+            paraExprInfo.getIsVirtualCol());
+        ExprNodeDesc reduceValue = isConstantParameterInAggregationParameters(
+            paraExprInfo.getInternalName(), reduceValues);
+
+        if (reduceValue != null) {
+          // this parameter is a constant
+          expr = reduceValue;
+        }
+
+        aggParameters.add(expr);
       }
 
       if (isDistinct) {
@@ -2653,12 +2710,14 @@ private Operator genGroupByPlanGroupByOperator1(QBParseInfo parseInfo,
     // get the last colName for the reduce KEY
     // it represents the column name corresponding to distinct aggr, if any
     String lastKeyColName = null;
+    List<ExprNodeDesc> reduceValues = null;
     if (reduceSinkOperatorInfo.getConf() instanceof ReduceSinkDesc) {
       List<String> inputKeyCols = ((ReduceSinkDesc)
           reduceSinkOperatorInfo.getConf()).getOutputKeyColumnNames();
       if (inputKeyCols.size() > 0) {
         lastKeyColName = inputKeyCols.get(inputKeyCols.size()-1);
       }
+      reduceValues = ((ReduceSinkDesc)reduceSinkOperatorInfo.getConf()).getValueCols();
     }
     int numDistinctUDFs = 0;
     for (Map.Entry<String, ASTNode> entry : aggregationTrees.entrySet()) {
@@ -2699,9 +2758,20 @@ private Operator genGroupByPlanGroupByOperator1(QBParseInfo parseInfo,
             + getColumnInternalName(i-1);
 
           }
-          aggParameters.add(new ExprNodeColumnDesc(paraExprInfo.getType(),
+
+          ExprNodeDesc expr = new ExprNodeColumnDesc(paraExprInfo.getType(),
               paraExpression, paraExprInfo.getTabAlias(),
-              paraExprInfo.getIsVirtualCol()));
+              paraExprInfo.getIsVirtualCol());
+          ExprNodeDesc reduceValue = isConstantParameterInAggregationParameters(
+              paraExprInfo.getInternalName(), reduceValues);
+
+          if (reduceValue != null) {
+            // this parameter is a constant
+            expr = reduceValue;
+          }
+
+          aggParameters.add(expr);
+
         }
       } else {
         ColumnInfo paraExprInfo = groupByInputRowResolver.getExpression(value);
diff --git a/ql/src/test/queries/clientpositive/udaf_percentile_approx.q b/ql/src/test/queries/clientpositive/udaf_percentile_approx.q
index c436a638e2..9ab09de231 100644
--- a/ql/src/test/queries/clientpositive/udaf_percentile_approx.q
+++ b/ql/src/test/queries/clientpositive/udaf_percentile_approx.q
@@ -1,6 +1,26 @@
 
 set mapred.reduce.tasks=4;
 set hive.exec.reducers.max=4;
+set hive.map.aggr=false;
+-- disable map-side aggregation
+SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5) FROM src;
+SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5, 100) FROM src;
+SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5, 1000) FROM src;
+
+SELECT percentile_approx(cast(substr(src.value,5) AS int), 0.5) FROM src;
+SELECT percentile_approx(cast(substr(src.value,5) AS int), 0.5, 100) FROM src;
+SELECT percentile_approx(cast(substr(src.value,5) AS int), 0.5, 1000) FROM src;
+
+SELECT percentile_approx(cast(substr(src.value,5) AS double), array(0.05,0.5,0.95,0.98)) FROM src;
+SELECT percentile_approx(cast(substr(src.value,5) AS double), array(0.05,0.5,0.95,0.98), 100) FROM src;
+SELECT percentile_approx(cast(substr(src.value,5) AS double), array(0.05,0.5,0.95,0.98), 1000) FROM src;
+
+SELECT percentile_approx(cast(substr(src.value,5) AS int), array(0.05,0.5,0.95,0.98)) FROM src;
+SELECT percentile_approx(cast(substr(src.value,5) AS int), array(0.05,0.5,0.95,0.98), 100) FROM src;
+SELECT percentile_approx(cast(substr(src.value,5) AS int), array(0.05,0.5,0.95,0.98), 1000) FROM src;
+
+set hive.map.aggr=true;
+-- enable map-side aggregation
 SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5) FROM src;
 SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5, 100) FROM src;
 SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5, 1000) FROM src;
diff --git a/ql/src/test/results/clientpositive/count.q.out b/ql/src/test/results/clientpositive/count.q.out
index 61e54c72f3..d9c56670f1 100644
--- a/ql/src/test/results/clientpositive/count.q.out
+++ b/ql/src/test/results/clientpositive/count.q.out
@@ -486,7 +486,7 @@ STAGE PLANS:
       Reduce Operator Tree:
         Group By Operator
           aggregations:
-                expr: count(VALUE._col0)
+                expr: count(1)
                 expr: count()
                 expr: count(KEY._col0:14._col0)
                 expr: count(KEY._col0:14._col1)
diff --git a/ql/src/test/results/clientpositive/nullgroup.q.out b/ql/src/test/results/clientpositive/nullgroup.q.out
index 434fa6c3d2..2d8d059359 100644
--- a/ql/src/test/results/clientpositive/nullgroup.q.out
+++ b/ql/src/test/results/clientpositive/nullgroup.q.out
@@ -176,7 +176,7 @@ STAGE PLANS:
       Reduce Operator Tree:
         Group By Operator
           aggregations:
-                expr: count(VALUE._col0)
+                expr: count(1)
           bucketGroup: false
           mode: partial1
           outputColumnNames: _col0
@@ -264,7 +264,7 @@ STAGE PLANS:
       Reduce Operator Tree:
         Group By Operator
           aggregations:
-                expr: count(VALUE._col0)
+                expr: count(1)
           bucketGroup: false
           mode: complete
           outputColumnNames: _col0
diff --git a/ql/src/test/results/clientpositive/nullgroup2.q.out b/ql/src/test/results/clientpositive/nullgroup2.q.out
index aa52d62f9e..9d1d6e9873 100644
--- a/ql/src/test/results/clientpositive/nullgroup2.q.out
+++ b/ql/src/test/results/clientpositive/nullgroup2.q.out
@@ -251,7 +251,7 @@ STAGE PLANS:
       Reduce Operator Tree:
         Group By Operator
           aggregations:
-                expr: count(VALUE._col0)
+                expr: count(1)
           bucketGroup: false
           keys:
                 expr: KEY._col0
@@ -362,7 +362,7 @@ STAGE PLANS:
       Reduce Operator Tree:
         Group By Operator
           aggregations:
-                expr: count(VALUE._col0)
+                expr: count(1)
           bucketGroup: false
           keys:
                 expr: KEY._col0
diff --git a/ql/src/test/results/clientpositive/nullgroup4.q.out b/ql/src/test/results/clientpositive/nullgroup4.q.out
index 3dd3c66a65..2bcc5ec7d5 100644
--- a/ql/src/test/results/clientpositive/nullgroup4.q.out
+++ b/ql/src/test/results/clientpositive/nullgroup4.q.out
@@ -246,7 +246,7 @@ STAGE PLANS:
       Reduce Operator Tree:
         Group By Operator
           aggregations:
-                expr: count(VALUE._col0)
+                expr: count(1)
                 expr: count(DISTINCT KEY._col0:0._col0)
           bucketGroup: false
           mode: partial1
@@ -347,7 +347,7 @@ STAGE PLANS:
       Reduce Operator Tree:
         Group By Operator
           aggregations:
-                expr: count(VALUE._col0)
+                expr: count(1)
                 expr: count(DISTINCT KEY._col0:0._col0)
           bucketGroup: false
           mode: complete
diff --git a/ql/src/test/results/clientpositive/nullgroup4_multi_distinct.q.out b/ql/src/test/results/clientpositive/nullgroup4_multi_distinct.q.out
index 9ac4bbca18..6e479612ed 100644
--- a/ql/src/test/results/clientpositive/nullgroup4_multi_distinct.q.out
+++ b/ql/src/test/results/clientpositive/nullgroup4_multi_distinct.q.out
@@ -137,7 +137,7 @@ STAGE PLANS:
       Reduce Operator Tree:
         Group By Operator
           aggregations:
-                expr: count(VALUE._col0)
+                expr: count(1)
                 expr: count(DISTINCT KEY._col0:0._col0)
                 expr: count(DISTINCT KEY._col0:1._col0)
           bucketGroup: false
diff --git a/ql/src/test/results/clientpositive/udaf_percentile_approx.q.out b/ql/src/test/results/clientpositive/udaf_percentile_approx.q.out
index 4f85a82b72..d871179f6a 100644
--- a/ql/src/test/results/clientpositive/udaf_percentile_approx.q.out
+++ b/ql/src/test/results/clientpositive/udaf_percentile_approx.q.out
@@ -1,8 +1,120 @@
-PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5) FROM src
+PREHOOK: query: -- disable map-side aggregation
+SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5) FROM src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5) FROM src
+POSTHOOK: query: -- disable map-side aggregation
+SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+255.5
+PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5, 100) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5, 100) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+252.77777777777777
+PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5, 1000) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5, 1000) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+255.5
+PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), 0.5) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), 0.5) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+255.5
+PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), 0.5, 100) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), 0.5, 100) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+252.77777777777777
+PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), 0.5, 1000) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), 0.5, 1000) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+255.5
+PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), array(0.05,0.5,0.95,0.98)) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), array(0.05,0.5,0.95,0.98)) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+[26.0,255.5,479.0,491.0]
+PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), array(0.05,0.5,0.95,0.98), 100) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), array(0.05,0.5,0.95,0.98), 100) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+[24.07,252.77777777777777,476.9444444444444,487.82]
+PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), array(0.05,0.5,0.95,0.98), 1000) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS double), array(0.05,0.5,0.95,0.98), 1000) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+[26.0,255.5,479.0,491.0]
+PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), array(0.05,0.5,0.95,0.98)) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), array(0.05,0.5,0.95,0.98)) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+[26.0,255.5,479.0,491.0]
+PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), array(0.05,0.5,0.95,0.98), 100) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), array(0.05,0.5,0.95,0.98), 100) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+[24.07,252.77777777777777,476.9444444444444,487.82]
+PREHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), array(0.05,0.5,0.95,0.98), 1000) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT percentile_approx(cast(substr(src.value,5) AS int), array(0.05,0.5,0.95,0.98), 1000) FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+[26.0,255.5,479.0,491.0]
+PREHOOK: query: -- enable map-side aggregation
+SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5) FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: -- enable map-side aggregation
+SELECT percentile_approx(cast(substr(src.value,5) AS double), 0.5) FROM src
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
