diff --git a/ql/src/java/org/apache/hadoop/hive/ql/ddl/view/materialized/alter/rebuild/AlterMaterializedViewRebuildAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/ddl/view/materialized/alter/rebuild/AlterMaterializedViewRebuildAnalyzer.java
index 05516f7362..53726c93d5 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/ddl/view/materialized/alter/rebuild/AlterMaterializedViewRebuildAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/ddl/view/materialized/alter/rebuild/AlterMaterializedViewRebuildAnalyzer.java
@@ -89,6 +89,8 @@
 public class AlterMaterializedViewRebuildAnalyzer extends CalcitePlanner {
   private static final Logger LOG = LoggerFactory.getLogger(AlterMaterializedViewRebuildAnalyzer.class);
 
+  protected Table mvTable;
+
   public AlterMaterializedViewRebuildAnalyzer(QueryState queryState) throws SemanticException {
     super(queryState);
   }
@@ -110,7 +112,8 @@ public void analyzeInternal(ASTNode root) throws SemanticException {
     }
 
     try {
-      Boolean outdated = db.isOutdatedMaterializedView(getTxnMgr(), tableName);
+      mvTable = db.getTable(tableName.getDb(), tableName.getTable());
+      Boolean outdated = db.isOutdatedMaterializedView(getTxnMgr(), mvTable);
       if (outdated != null && !outdated) {
         String msg = String.format("Materialized view %s.%s is up to date. Skipping rebuild.",
                 tableName.getDb(), tableName.getTable());
@@ -125,8 +128,6 @@ public void analyzeInternal(ASTNode root) throws SemanticException {
     ASTNode rewrittenAST = getRewrittenAST(tableName);
 
     mvRebuildMode = MaterializationRebuildMode.INSERT_OVERWRITE_REBUILD;
-    mvRebuildDbName = tableName.getDb();
-    mvRebuildName = tableName.getTable();
 
     LOG.debug("Rebuilding materialized view " + tableName.getNotEmptyDbTable());
     super.analyzeInternal(rewrittenAST);
@@ -210,7 +211,7 @@ protected RelNode applyMaterializedViewRewriting(RelOptPlanner planner, RelNode
         // we pass 'true' for the forceMVContentsUpToDate parameter, as we cannot allow the
         // materialization contents to be stale for a rebuild if we want to use it.
         materialization = db.getMaterializedViewForRebuild(
-                mvRebuildDbName, mvRebuildName, tablesUsedQuery, getTxnMgr());
+                mvTable.getDbName(), mvTable.getTableName(), tablesUsedQuery, getTxnMgr());
         if (materialization == null) {
           // There is no materialization, we can return the original plan
           return calcitePreMVRewritingPlan;
@@ -293,28 +294,33 @@ private RelNode applyRecordIncrementalRebuildPlan(
       // First we need to check if it is valid to convert to MERGE/INSERT INTO.
       // If we succeed, we modify the plan and afterwards the AST.
       // MV should be an acid table.
-      MaterializedViewRewritingRelVisitor visitor = new MaterializedViewRewritingRelVisitor();
+      boolean fullAcidView = AcidUtils.isFullAcidTable(mvTable.getTTable());
+      MaterializedViewRewritingRelVisitor visitor = new MaterializedViewRewritingRelVisitor(fullAcidView);
       visitor.go(basePlan);
       if (visitor.isRewritingAllowed()) {
-        if (materialization.isSourceTablesUpdateDeleteModified()) {
-          if (visitor.isContainsAggregate()) {
-            if (visitor.getCountIndex() < 0) {
-              // count(*) is necessary for determine which rows should be deleted from the view
-              // if view definition does not have it incremental rebuild can not be performed, bail out
-              return calcitePreMVRewritingPlan;
-            }
-            return applyAggregateInsertDeleteIncremental(basePlan, mdProvider, executorProvider);
-          } else {
-            return applyJoinInsertDeleteIncremental(
-                    basePlan, mdProvider, executorProvider, optCluster, calcitePreMVRewritingPlan);
-          }
-        } else {
+        if (!materialization.isSourceTablesUpdateDeleteModified()) {
           // Trigger rewriting to remove UNION branch with MV
           if (visitor.isContainsAggregate()) {
             return applyAggregateInsertIncremental(basePlan, mdProvider, executorProvider, optCluster, calcitePreMVRewritingPlan);
           } else {
             return applyJoinInsertIncremental(basePlan, mdProvider, executorProvider);
           }
+        } else {
+          if (fullAcidView) {
+            if (visitor.isContainsAggregate()) {
+              if (visitor.getCountIndex() < 0) {
+                // count(*) is necessary for determine which rows should be deleted from the view
+                // if view definition does not have it incremental rebuild can not be performed, bail out
+                return calcitePreMVRewritingPlan;
+              }
+              return applyAggregateInsertDeleteIncremental(basePlan, mdProvider, executorProvider);
+            } else {
+              return applyJoinInsertDeleteIncremental(
+                      basePlan, mdProvider, executorProvider, optCluster, calcitePreMVRewritingPlan);
+            }
+          } else {
+            return calcitePreMVRewritingPlan;
+          }
         }
       } else if (materialization.isSourceTablesUpdateDeleteModified()) {
         // calcitePreMVRewritingPlan is already got the optimizations by applyPreJoinOrderingTransforms prior calling
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
index 1921b65906..9e4cdddab8 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
@@ -2026,9 +2026,7 @@ public Boolean isOutdatedMaterializedView(
    * (false), or it cannot be determined (null). The latest case may happen e.g. when the
    * materialized view definition uses external tables.
    */
-  public Boolean isOutdatedMaterializedView(HiveTxnManager txnManager, TableName tableName) throws HiveException {
-
-    Table table = getTable(tableName.getDb(), tableName.getTable());
+  public Boolean isOutdatedMaterializedView(HiveTxnManager txnManager, Table table) throws HiveException {
 
     String validTxnsList = conf.get(ValidTxnList.VALID_TXNS_KEY);
     if (validTxnsList == null) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/views/MaterializedViewRewritingRelVisitor.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/views/MaterializedViewRewritingRelVisitor.java
index 899b90817f..49a0982828 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/views/MaterializedViewRewritingRelVisitor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/views/MaterializedViewRewritingRelVisitor.java
@@ -26,15 +26,11 @@
 import org.apache.calcite.rel.core.TableScan;
 import org.apache.calcite.rel.core.Union;
 import org.apache.calcite.sql.SqlKind;
-import org.apache.calcite.tools.RelBuilder;
 import org.apache.calcite.util.ControlFlowException;
-import org.apache.hadoop.hive.ql.io.AcidUtils;
 import org.apache.hadoop.hive.ql.optimizer.calcite.RelOptHiveTable;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.util.ArrayList;
-import java.util.List;
 
 /**
  * This class is a helper to check whether a materialized view rebuild
@@ -54,11 +50,13 @@ public class MaterializedViewRewritingRelVisitor extends RelVisitor {
 
 
   private boolean containsAggregate;
+  private boolean fullAcidView;
   private boolean rewritingAllowed;
   private int countIndex;
 
-  public MaterializedViewRewritingRelVisitor() {
+  public MaterializedViewRewritingRelVisitor(boolean fullAcidView) {
     this.containsAggregate = false;
+    this.fullAcidView = fullAcidView;
     this.rewritingAllowed = false;
     this.countIndex = -1;
   }
@@ -127,7 +125,7 @@ public void visit(RelNode node, int ordinal, RelNode parent) {
             // If it is not a materialized view, we do not rewrite it
             throw new ReturnedValue(false);
           }
-          if (containsAggregate && !AcidUtils.isFullAcidTable(hiveTable.getHiveTableMD())) {
+          if (containsAggregate && !fullAcidView) {
             // If it contains an aggregate and it is not a full acid table,
             // we do not rewrite it (we need MERGE support)
             throw new ReturnedValue(false);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index c709209d9d..ad30ef5e1a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -402,8 +402,6 @@ public class SemanticAnalyzer extends BaseSemanticAnalyzer {
 
   // whether this is a mv rebuild rewritten expression
   protected MaterializationRebuildMode mvRebuildMode = MaterializationRebuildMode.NONE;
-  protected String mvRebuildDbName; // Db name for materialization to rebuild
-  protected String mvRebuildName; // Name for materialization to rebuild
 
   protected volatile boolean disableJoinMerge = false;
   protected final boolean defaultJoinMerge;
diff --git a/ql/src/test/queries/clientpositive/materialized_view_create_rewrite_10.q b/ql/src/test/queries/clientpositive/materialized_view_create_rewrite_10.q
new file mode 100644
index 0000000000..417872c272
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/materialized_view_create_rewrite_10.q
@@ -0,0 +1,29 @@
+-- Try to run incremental on a non-transactional MV in presence of delete operations
+-- Compiler should fall back to full rebuild.
+
+set hive.support.concurrency=true;
+set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
+
+set hive.stats.autogather=false;
+
+create table t1 (a int, b int) stored as orc TBLPROPERTIES ('transactional'='true');
+
+insert into t1 values (1,1), (2,1), (3,3);
+
+create materialized view mv1 as
+select a, b from t1 where b = 1;
+
+delete from t1 where a = 2;
+
+explain cbo
+alter materialized view mv1 rebuild;
+
+explain
+alter materialized view mv1 rebuild;
+
+alter materialized view mv1 rebuild;
+
+explain cbo
+select a, b from t1 where b = 1;
+
+select a, b from t1 where b = 1;
diff --git a/ql/src/test/results/clientpositive/llap/materialized_view_create_rewrite_10.q.out b/ql/src/test/results/clientpositive/llap/materialized_view_create_rewrite_10.q.out
new file mode 100644
index 0000000000..7fb9d79d31
--- /dev/null
+++ b/ql/src/test/results/clientpositive/llap/materialized_view_create_rewrite_10.q.out
@@ -0,0 +1,154 @@
+PREHOOK: query: create table t1 (a int, b int) stored as orc TBLPROPERTIES ('transactional'='true')
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t1
+POSTHOOK: query: create table t1 (a int, b int) stored as orc TBLPROPERTIES ('transactional'='true')
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t1
+PREHOOK: query: insert into t1 values (1,1), (2,1), (3,3)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@t1
+POSTHOOK: query: insert into t1 values (1,1), (2,1), (3,3)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@t1
+POSTHOOK: Lineage: t1.a SCRIPT []
+POSTHOOK: Lineage: t1.b SCRIPT []
+PREHOOK: query: create materialized view mv1 as
+select a, b from t1 where b = 1
+PREHOOK: type: CREATE_MATERIALIZED_VIEW
+PREHOOK: Input: default@t1
+PREHOOK: Output: database:default
+PREHOOK: Output: default@mv1
+POSTHOOK: query: create materialized view mv1 as
+select a, b from t1 where b = 1
+POSTHOOK: type: CREATE_MATERIALIZED_VIEW
+POSTHOOK: Input: default@t1
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@mv1
+POSTHOOK: Lineage: mv1.a SIMPLE [(t1)t1.FieldSchema(name:a, type:int, comment:null), ]
+POSTHOOK: Lineage: mv1.b SIMPLE []
+PREHOOK: query: delete from t1 where a = 2
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t1
+PREHOOK: Output: default@t1
+POSTHOOK: query: delete from t1 where a = 2
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t1
+POSTHOOK: Output: default@t1
+PREHOOK: query: explain cbo
+alter materialized view mv1 rebuild
+PREHOOK: type: ALTER_MATERIALIZED_VIEW_REBUILD
+PREHOOK: Input: default@t1
+PREHOOK: Output: default@mv1
+POSTHOOK: query: explain cbo
+alter materialized view mv1 rebuild
+POSTHOOK: type: ALTER_MATERIALIZED_VIEW_REBUILD
+POSTHOOK: Input: default@t1
+POSTHOOK: Output: default@mv1
+CBO PLAN:
+HiveProject(a=[$0], b=[CAST(1):INTEGER])
+  HiveFilter(condition=[=($1, 1)])
+    HiveTableScan(table=[[default, t1]], table:alias=[t1])
+
+PREHOOK: query: explain
+alter materialized view mv1 rebuild
+PREHOOK: type: ALTER_MATERIALIZED_VIEW_REBUILD
+PREHOOK: Input: default@t1
+PREHOOK: Output: default@mv1
+POSTHOOK: query: explain
+alter materialized view mv1 rebuild
+POSTHOOK: type: ALTER_MATERIALIZED_VIEW_REBUILD
+POSTHOOK: Input: default@t1
+POSTHOOK: Output: default@mv1
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-2 depends on stages: Stage-1
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: t1
+                  filterExpr: (b = 1) (type: boolean)
+                  Statistics: Num rows: 69 Data size: 13590 Basic stats: COMPLETE Column stats: NONE
+                  Filter Operator
+                    predicate: (b = 1) (type: boolean)
+                    Statistics: Num rows: 1 Data size: 196 Basic stats: COMPLETE Column stats: NONE
+                    Select Operator
+                      expressions: a (type: int), 1 (type: int)
+                      outputColumnNames: _col0, _col1
+                      Statistics: Num rows: 1 Data size: 196 Basic stats: COMPLETE Column stats: NONE
+                      File Output Operator
+                        compressed: false
+                        Statistics: Num rows: 1 Data size: 196 Basic stats: COMPLETE Column stats: NONE
+                        table:
+                            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
+                            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
+                            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
+                            name: default.mv1
+            Execution mode: vectorized, llap
+            LLAP IO: may be used (ACID table)
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          table:
+              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
+              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
+              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
+              name: default.mv1
+
+  Stage: Stage-3
+    Materialized View Update
+      name: default.mv1
+      update creation metadata: true
+
+PREHOOK: query: alter materialized view mv1 rebuild
+PREHOOK: type: ALTER_MATERIALIZED_VIEW_REBUILD
+PREHOOK: Input: default@t1
+PREHOOK: Output: default@mv1
+POSTHOOK: query: alter materialized view mv1 rebuild
+POSTHOOK: type: ALTER_MATERIALIZED_VIEW_REBUILD
+POSTHOOK: Input: default@t1
+POSTHOOK: Output: default@mv1
+POSTHOOK: Lineage: mv1.a SIMPLE [(t1)t1.FieldSchema(name:a, type:int, comment:null), ]
+POSTHOOK: Lineage: mv1.b SIMPLE []
+PREHOOK: query: explain cbo
+select a, b from t1 where b = 1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@mv1
+PREHOOK: Input: default@t1
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo
+select a, b from t1 where b = 1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@mv1
+POSTHOOK: Input: default@t1
+#### A masked pattern was here ####
+CBO PLAN:
+HiveTableScan(table=[[default, mv1]], table:alias=[default.mv1])
+
+PREHOOK: query: select a, b from t1 where b = 1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@mv1
+PREHOOK: Input: default@t1
+#### A masked pattern was here ####
+POSTHOOK: query: select a, b from t1 where b = 1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@mv1
+POSTHOOK: Input: default@t1
+#### A masked pattern was here ####
+1	1
