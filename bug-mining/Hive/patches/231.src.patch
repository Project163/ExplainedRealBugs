diff --git a/CHANGES.txt b/CHANGES.txt
index 2a9fc29dd8..bfe361b20d 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -34,6 +34,8 @@ Trunk -  Unreleased
 
     HIVE-764. Fixed json.jar. (Raghu Murthy via zshao)
 
+    HIVE-769. Bug in partition pruner checking. (Zheng Shao via namit)
+
 Release 0.4.0 -  Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
index 5638a318a2..39c4f74501 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
@@ -402,8 +402,12 @@ public static void setTaskPlan(String alias_id, Operator<? extends Serializable>
       else {
         partsList = org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner.prune(
                                                     parseCtx.getTopToTable().get(topOp), 
-                                                    parseCtx.getOpToPartPruner().get(topOp));
+                                                    parseCtx.getOpToPartPruner().get(topOp),
+                                                    opProcCtx.getConf(),
+                                                    alias_id);
       }
+    } catch (SemanticException e) {
+      throw e;
     } catch (HiveException e) {
       LOG.error(org.apache.hadoop.util.StringUtils.stringifyException(e));
       throw new SemanticException(e.getMessage(), e);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java
index 0931fc57e4..f992706171 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java
@@ -21,11 +21,12 @@
 import java.util.ArrayList;
 import java.util.LinkedHashMap;
 import java.util.LinkedHashSet;
+import java.util.List;
 import java.util.Map;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.hadoop.hive.metastore.MetaStoreUtils;
+import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.Warehouse;
 import org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator;
 import org.apache.hadoop.hive.ql.exec.ExprNodeEvaluatorFactory;
@@ -42,9 +43,11 @@
 import org.apache.hadoop.hive.ql.metadata.Partition;
 import org.apache.hadoop.hive.ql.metadata.Table;
 import org.apache.hadoop.hive.ql.optimizer.Transform;
+import org.apache.hadoop.hive.ql.parse.ErrorMsg;
 import org.apache.hadoop.hive.ql.parse.ParseContext;
 import org.apache.hadoop.hive.ql.parse.PrunedPartitionList;
 import org.apache.hadoop.hive.ql.parse.SemanticException;
+import org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc;
 import org.apache.hadoop.hive.ql.plan.exprNodeDesc;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
@@ -87,7 +90,19 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {
     return pctx;
   }
 
-  public static PrunedPartitionList prune(Table tab, exprNodeDesc prunerExpr) throws HiveException {
+  /**
+   * Get the partition list for the table that satisfies the partition pruner
+   * condition.
+   * 
+   * @param tab    the table object for the alias
+   * @param prunerExpr  the pruner expression for the alias
+   * @param conf   for checking whether "strict" mode is on.
+   * @param alias  for generating error message only.
+   * @return
+   * @throws HiveException
+   */
+  public static PrunedPartitionList prune(Table tab, exprNodeDesc prunerExpr,
+      HiveConf conf, String alias) throws HiveException {
     LOG.trace("Started pruning partiton");
     LOG.trace("tabname = " + tab.getName());
     LOG.trace("prune Expression = " + prunerExpr);
@@ -121,6 +136,14 @@ public static PrunedPartitionList prune(Table tab, exprNodeDesc prunerExpr) thro
           ois.add(partObjectInspector);
           StructObjectInspector rowWithPartObjectInspector = ObjectInspectorFactory.getUnionStructObjectInspector(ois);
 
+          // If the "strict" mode is on, we have to provide partition pruner for each table.  
+          if ("strict".equalsIgnoreCase(HiveConf.getVar(conf, HiveConf.ConfVars.HIVEMAPREDMODE))) {
+            if (!hasColumnExpr(prunerExpr)) {
+              throw new SemanticException(ErrorMsg.NO_PARTITION_PREDICATE.getMsg( 
+                  "for Alias \"" + alias + "\" Table \"" + tab.getName() + "\""));
+            }
+          }
+          
           // evaluate the expression tree
           if (prunerExpr != null) {
             ExprNodeEvaluator evaluator = ExprNodeEvaluatorFactory.get(prunerExpr);
@@ -152,11 +175,37 @@ public static PrunedPartitionList prune(Table tab, exprNodeDesc prunerExpr) thro
       } else {
         true_parts.addAll(Hive.get().getPartitions(tab));
       }
+    } catch (HiveException e) {
+      throw e;
     } catch (Exception e) {
       throw new HiveException(e);
     }
 
     // Now return the set of partitions
     return new PrunedPartitionList(true_parts, unkn_parts, denied_parts);
-  }  
+  }
+  
+  /**
+   * Whether the expression contains a column node or not.
+   */
+  public static boolean hasColumnExpr(exprNodeDesc desc) {
+    // Return false for null 
+    if (desc == null) {
+      return false;
+    }
+    // Return true for exprNodeColumnDesc
+    if (desc instanceof exprNodeColumnDesc) {
+      return true;
+    }
+    // Return true in case one of the children is column expr.
+    List<exprNodeDesc> children = desc.getChildren();
+    for (int i = 0; i < children.size(); i++) {
+      if (hasColumnExpr(children.get(i))) {
+        return true;
+      }
+    }
+    // Return false otherwise
+    return false;
+  }
+  
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTPartitionPruner.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTPartitionPruner.java
index c28827d77b..a5166b04dc 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTPartitionPruner.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTPartitionPruner.java
@@ -20,6 +20,7 @@
 
 import java.util.*;
 
+import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.exec.FunctionRegistry;
 import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
 import org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException;
@@ -64,6 +65,8 @@ public class ASTPartitionPruner {
 
   private exprNodeDesc prunerExpr;
   
+  private HiveConf conf;
+  
   // is set to true if the expression only contains partitioning columns and not any other column reference.
   // This is used to optimize select * from table where ... scenario, when the where condition only references
   // partitioning columns - the partitions are identified and streamed directly to the client without requiring 
@@ -74,11 +77,12 @@ public ASTPartitionPruner() {
   }
   
   /** Creates a new instance of PartitionPruner */
-  public ASTPartitionPruner(String tableAlias, QBMetaData metaData) {
+  public ASTPartitionPruner(String tableAlias, QBMetaData metaData, HiveConf conf) {
     this.tableAlias = tableAlias;
     this.metaData = metaData;
     this.tab = metaData.getTableForAlias(tableAlias);
     this.prunerExpr = null;
+    this.conf = conf;
     onlyContainsPartCols = true;
   }
 
@@ -413,7 +417,8 @@ public void addJoinOnExpression(ASTNode expr) throws SemanticException {
    */
   @SuppressWarnings("nls")
   public PrunedPartitionList prune() throws HiveException {
-    return org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner.prune(this.tab, this.prunerExpr);
+    return org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner.prune(this.tab,
+        this.prunerExpr, conf, this.tableAlias);
   }
 
   public Table getTable() {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/ErrorMsg.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/ErrorMsg.java
index 4aaa6c11e1..12232045bf 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/ErrorMsg.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/ErrorMsg.java
@@ -132,6 +132,10 @@ String getMsg(Tree tree, String reason) {
     return getMsg((ASTNode)tree, reason);
   }
 
+  public String getMsg(String reason) {
+    return mesg + " " + reason;
+  }
+
   public String getMsg() {
     return mesg;
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 0ece5a06eb..b65b6e26de 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -113,6 +113,7 @@
 import org.apache.hadoop.hive.ql.plan.tableDesc;
 import org.apache.hadoop.hive.ql.plan.tableScanDesc;
 import org.apache.hadoop.hive.ql.plan.unionDesc;
+import org.apache.hadoop.hive.ql.ppd.PredicatePushDown;
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFHash;
@@ -613,7 +614,7 @@ private void genPartitionPruners(QB qb) throws SemanticException {
       String alias_id = (qb.getId() == null ? alias : qb.getId() + ":" + alias);
 
       org.apache.hadoop.hive.ql.parse.ASTPartitionPruner pruner = 
-        new org.apache.hadoop.hive.ql.parse.ASTPartitionPruner(alias, qb.getMetaData());
+        new org.apache.hadoop.hive.ql.parse.ASTPartitionPruner(alias, qb.getMetaData(), conf);
       
       // Pass each where clause to the pruner
       for(String clause: qbp.getClauseNames()) {
@@ -659,21 +660,26 @@ private void genPartitionPruners(QB qb) throws SemanticException {
       }
     }
 
-    for (String alias : qb.getTabAliases()) {
-      String alias_id = (qb.getId() == null ? alias : qb.getId() + ":" + alias);
-      org.apache.hadoop.hive.ql.parse.ASTPartitionPruner pruner = this.aliasToPruner.get(alias_id);
-      if (joinPartnPruner.get(alias_id) == null) {
-        // Pass each where clause to the pruner
-         for(String clause: qbp.getClauseNames()) {
-          
-           ASTNode whexp = (ASTNode)qbp.getWhrForClause(clause);
-           if (pruner.getTable().isPartitioned() &&
-               conf.getVar(HiveConf.ConfVars.HIVEMAPREDMODE).equalsIgnoreCase("strict") &&
-               (whexp == null || !pruner.hasPartitionPredicate((ASTNode)whexp.getChild(0)))) {
-             throw new SemanticException(ErrorMsg.NO_PARTITION_PREDICATE.getMsg(whexp != null ? whexp : qbp.getSelForClause(clause), 
-                                                                                " for Alias " + alias + " Table " + pruner.getTable().getName()));
+    // Do old-style partition pruner check only if the new partition pruner
+    // is not enabled.
+    if (!HiveConf.getBoolVar(conf, HiveConf.ConfVars.HIVEOPTPPD)
+        || !HiveConf.getBoolVar(conf, HiveConf.ConfVars.HIVEOPTPPR)) {
+      for (String alias : qb.getTabAliases()) {
+        String alias_id = (qb.getId() == null ? alias : qb.getId() + ":" + alias);
+        org.apache.hadoop.hive.ql.parse.ASTPartitionPruner pruner = this.aliasToPruner.get(alias_id);
+        if (joinPartnPruner.get(alias_id) == null) {
+          // Pass each where clause to the pruner
+           for(String clause: qbp.getClauseNames()) {
+            
+             ASTNode whexp = (ASTNode)qbp.getWhrForClause(clause);
+             if (pruner.getTable().isPartitioned() &&
+                 conf.getVar(HiveConf.ConfVars.HIVEMAPREDMODE).equalsIgnoreCase("strict") &&
+                 (whexp == null || !pruner.hasPartitionPredicate((ASTNode)whexp.getChild(0)))) {
+               throw new SemanticException(ErrorMsg.NO_PARTITION_PREDICATE.getMsg(whexp != null ? whexp : qbp.getSelForClause(clause), 
+                                                                                  " for Alias " + alias + " Table " + pruner.getTable().getName()));
+             }
            }
-         }
+        }
       }
     }
   }
@@ -4406,7 +4412,7 @@ public void analyzeInternal(ASTNode ast) throws SemanticException {
     init(pCtx);
     qb = pCtx.getQB();
     
-    // Do any partition pruning
+    // Do any partition pruning using ASTPartitionPruner
     genPartitionPruners(qb);
     LOG.info("Completed partition pruning");
     
diff --git a/ql/src/test/results/clientnegative/strict_pruning.q.out b/ql/src/test/results/clientnegative/strict_pruning.q.out
index 29794278cc..3f6ce4938f 100644
--- a/ql/src/test/results/clientnegative/strict_pruning.q.out
+++ b/ql/src/test/results/clientnegative/strict_pruning.q.out
@@ -1 +1 @@
-FAILED: Error in semantic analysis: line 4:7 No Partition Predicate Found 1:  for Alias srcpart Table srcpart
+FAILED: Error in semantic analysis: No Partition Predicate Found for Alias "srcpart" Table "srcpart"
