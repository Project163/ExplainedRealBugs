diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index c4b54588e5..7747cc89d2 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -10768,7 +10768,7 @@ ASTNode analyzeCreateTable(
       }
     }
 
-    addDbAndTabToOutputs(qualifiedTabName);
+    addDbAndTabToOutputs(qualifiedTabName, TableType.MANAGED_TABLE);
 
     if (isTemporary) {
       if (partCols.size() > 0) {
@@ -10868,11 +10868,13 @@ ASTNode analyzeCreateTable(
     return null;
   }
 
-  private void addDbAndTabToOutputs(String[] qualifiedTabName) throws SemanticException {
+  private void addDbAndTabToOutputs(String[] qualifiedTabName, TableType type) throws SemanticException {
     Database database  = getDatabase(qualifiedTabName[0]);
     outputs.add(new WriteEntity(database, WriteEntity.WriteType.DDL_SHARED));
-    outputs.add(new WriteEntity(new Table(qualifiedTabName[0], qualifiedTabName[1]),
-        WriteEntity.WriteType.DDL_NO_LOCK));
+
+    Table t = new Table(qualifiedTabName[0], qualifiedTabName[1]);
+    t.setTableType(type);
+    outputs.add(new WriteEntity(t, WriteEntity.WriteType.DDL_NO_LOCK));
   }
 
   private ASTNode analyzeCreateView(ASTNode ast, QB qb)
@@ -10938,7 +10940,7 @@ private ASTNode analyzeCreateView(ASTNode ast, QB qb)
     rootTasks.add(TaskFactory.get(new DDLWork(getInputs(), getOutputs(),
         createVwDesc), conf));
 
-    addDbAndTabToOutputs(qualTabName);
+    addDbAndTabToOutputs(qualTabName, TableType.VIRTUAL_VIEW);
     return selectStmt;
   }
 
