diff --git a/itests/qtest/pom.xml b/itests/qtest/pom.xml
index 8e5e1eacf2..964fd29f24 100644
--- a/itests/qtest/pom.xml
+++ b/itests/qtest/pom.xml
@@ -38,7 +38,7 @@
     <execute.beeline.tests>false</execute.beeline.tests>
     <minimr.query.files>list_bucket_dml_10.q,input16_cc.q,scriptfile1.q,scriptfile1_win.q,bucket4.q,bucketmapjoin6.q,disable_merge_for_bucketing.q,reduce_deduplicate.q,smb_mapjoin_8.q,join1.q,groupby2.q,bucketizedhiveinputformat.q,bucketmapjoin7.q,optrstat_groupby.q,bucket_num_reducers.q,bucket5.q,load_fs2.q,bucket_num_reducers2.q,infer_bucket_sort_merge.q,infer_bucket_sort_reducers_power_two.q,infer_bucket_sort_dyn_part.q,infer_bucket_sort_bucketed_table.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_num_buckets.q,leftsemijoin_mr.q,schemeAuthority.q,schemeAuthority2.q,truncate_column_buckets.q,remote_script.q,,load_hdfs_file_with_space_in_the_name.q,parallel_orderby.q,import_exported_table.q,stats_counter.q</minimr.query.files>
     <minimr.query.negative.files>cluster_tasklog_retrieval.q,minimr_broken_pipe.q,mapreduce_stack_trace.q,mapreduce_stack_trace_turnoff.q,mapreduce_stack_trace_hadoop20.q,mapreduce_stack_trace_turnoff_hadoop20.q</minimr.query.negative.files>
-    <minitez.query.files>tez_join_tests.q,tez_joins_explain.q,mrr.q,tez_dml.q</minitez.query.files>
+    <minitez.query.files>tez_join_tests.q,tez_joins_explain.q,mrr.q,tez_dml.q,tez_insert_overwrite_local_directory_1.q</minitez.query.files>
     <beeline.positive.exclude>add_part_exist.q,alter1.q,alter2.q,alter4.q,alter5.q,alter_rename_partition.q,alter_rename_partition_authorization.q,archive.q,archive_corrupt.q,archive_multi.q,archive_mr_1806.q,archive_multi_mr_1806.q,authorization_1.q,authorization_2.q,authorization_4.q,authorization_5.q,authorization_6.q,authorization_7.q,ba_table1.q,ba_table2.q,ba_table3.q,ba_table_udfs.q,binary_table_bincolserde.q,binary_table_colserde.q,cluster.q,columnarserde_create_shortcut.q,combine2.q,constant_prop.q,create_nested_type.q,create_or_replace_view.q,create_struct_table.q,create_union_table.q,database.q,database_location.q,database_properties.q,ddltime.q,describe_database_json.q,drop_database_removes_partition_dirs.q,escape1.q,escape2.q,exim_00_nonpart_empty.q,exim_01_nonpart.q,exim_02_00_part_empty.q,exim_02_part.q,exim_03_nonpart_over_compat.q,exim_04_all_part.q,exim_04_evolved_parts.q,exim_05_some_part.q,exim_06_one_part.q,exim_07_all_part_over_nonoverlap.q,exim_08_nonpart_rename.q,exim_09_part_spec_nonoverlap.q,exim_10_external_managed.q,exim_11_managed_external.q,exim_12_external_location.q,exim_13_managed_location.q,exim_14_managed_location_over_existing.q,exim_15_external_part.q,exim_16_part_external.q,exim_17_part_managed.q,exim_18_part_external.q,exim_19_00_part_external_location.q,exim_19_part_external_location.q,exim_20_part_managed_location.q,exim_21_export_authsuccess.q,exim_22_import_exist_authsuccess.q,exim_23_import_part_authsuccess.q,exim_24_import_nonexist_authsuccess.q,global_limit.q,groupby_complex_types.q,groupby_complex_types_multi_single_reducer.q,index_auth.q,index_auto.q,index_auto_empty.q,index_bitmap.q,index_bitmap1.q,index_bitmap2.q,index_bitmap3.q,index_bitmap_auto.q,index_bitmap_rc.q,index_compact.q,index_compact_1.q,index_compact_2.q,index_compact_3.q,index_stale_partitioned.q,init_file.q,input16.q,input16_cc.q,input46.q,input_columnarserde.q,input_dynamicserde.q,input_lazyserde.q,input_testxpath3.q,input_testxpath4.q,insert2_overwrite_partitions.q,insertexternal1.q,join_thrift.q,lateral_view.q,load_binary_data.q,load_exist_part_authsuccess.q,load_nonpart_authsuccess.q,load_part_authsuccess.q,loadpart_err.q,lock1.q,lock2.q,lock3.q,lock4.q,merge_dynamic_partition.q,multi_insert.q,multi_insert_move_tasks_share_dependencies.q,null_column.q,ppd_clusterby.q,query_with_semi.q,rename_column.q,sample6.q,sample_islocalmode_hook.q,set_processor_namespaces.q,show_tables.q,source.q,split_sample.q,str_to_map.q,transform1.q,udaf_collect_set.q,udaf_context_ngrams.q,udaf_histogram_numeric.q,udaf_ngrams.q,udaf_percentile_approx.q,udf_array.q,udf_bitmap_and.q,udf_bitmap_or.q,udf_explode.q,udf_format_number.q,udf_map.q,udf_map_keys.q,udf_map_values.q,udf_max.q,udf_min.q,udf_named_struct.q,udf_percentile.q,udf_printf.q,udf_sentences.q,udf_sort_array.q,udf_split.q,udf_struct.q,udf_substr.q,udf_translate.q,udf_union.q,udf_xpath.q,udtf_stack.q,view.q,virtual_column.q</beeline.positive.exclude>
   </properties>
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezProcessor.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezProcessor.java
index b1e22d5f3e..9c3284b5bb 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezProcessor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezProcessor.java
@@ -17,6 +17,7 @@
  */
 package org.apache.hadoop.hive.ql.exec.tez;
 import java.io.IOException;
+import java.text.NumberFormat;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
@@ -54,6 +55,15 @@ public class TezProcessor implements LogicalIOProcessor {
 
   private TezProcessorContext processorContext;
 
+  protected static final NumberFormat taskIdFormat = NumberFormat.getInstance();
+  protected static final NumberFormat jobIdFormat = NumberFormat.getInstance();
+  static {
+    taskIdFormat.setGroupingUsed(false);
+    taskIdFormat.setMinimumIntegerDigits(6);
+    jobIdFormat.setGroupingUsed(false);
+    jobIdFormat.setMinimumIntegerDigits(4);
+  }
+
   public TezProcessor(boolean isMap) {
     this.isMap = isMap;
   }
@@ -79,9 +89,33 @@ public void initialize(TezProcessorContext processorContext)
     byte[] userPayload = processorContext.getUserPayload();
     Configuration conf = TezUtils.createConfFromUserPayload(userPayload);
     this.jobConf = new JobConf(conf);
+    setupMRLegacyConfigs(processorContext);
     perfLogger.PerfLogEnd(CLASS_NAME, PerfLogger.TEZ_INITIALIZE_PROCESSOR);
   }
 
+  private void setupMRLegacyConfigs(TezProcessorContext processorContext) {
+    // Hive "insert overwrite local directory" uses task id as dir name
+    // Setting the id in jobconf helps to have the similar dir name as MR
+    StringBuilder taskAttemptIdBuilder = new StringBuilder("task");
+    taskAttemptIdBuilder.append(processorContext.getApplicationId().getClusterTimestamp())
+        .append("_")
+        .append(jobIdFormat.format(processorContext.getApplicationId().getId()))
+        .append("_");
+    if (isMap) {
+      taskAttemptIdBuilder.append("m_");
+    } else {
+      taskAttemptIdBuilder.append("r_");
+    }
+    taskAttemptIdBuilder.append(taskIdFormat.format(processorContext.getTaskIndex()))
+      .append("_")
+      .append(processorContext.getTaskAttemptNumber());
+
+    // In MR, mapreduce.task.attempt.id is same as mapred.task.id. Go figure.
+    String taskAttemptIdStr = taskAttemptIdBuilder.toString();
+    this.jobConf.set("mapred.task.id", taskAttemptIdStr);
+    this.jobConf.set("mapreduce.task.attempt.id", taskAttemptIdStr);
+  }
+
   @Override
   public void run(Map<String, LogicalInput> inputs, Map<String, LogicalOutput> outputs)
       throws Exception {
diff --git a/ql/src/test/queries/clientpositive/tez_insert_overwrite_local_directory_1.q b/ql/src/test/queries/clientpositive/tez_insert_overwrite_local_directory_1.q
new file mode 100644
index 0000000000..b465c02fad
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/tez_insert_overwrite_local_directory_1.q
@@ -0,0 +1,7 @@
+set hive.optimize.tez=true;
+
+insert overwrite local directory '${system:test.tmp.dir}/tez_local_src_table_1'
+select * from src order by key limit 10 ;
+dfs -cat file:${system:test.tmp.dir}/tez_local_src_table_1/000000_0 ;
+
+dfs -rmr file:${system:test.tmp.dir}/tez_local_src_table_1/ ;
diff --git a/ql/src/test/results/clientpositive/tez_insert_overwrite_local_directory_1.q.out b/ql/src/test/results/clientpositive/tez_insert_overwrite_local_directory_1.q.out
new file mode 100644
index 0000000000..c42e99dc3f
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez_insert_overwrite_local_directory_1.q.out
@@ -0,0 +1,20 @@
+#### A masked pattern was here ####
+select * from src order by key limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+select * from src order by key limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+0val_0
+0val_0
+0val_0
+10val_10
+100val_100
+100val_100
+103val_103
+103val_103
+104val_104
+104val_104
+#### A masked pattern was here ####
