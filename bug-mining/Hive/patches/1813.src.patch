diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
index a3963a5a46..96a78fcf2c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
@@ -63,14 +63,12 @@
 import org.apache.hadoop.hive.ql.udf.UDFHex;
 import org.apache.hadoop.hive.ql.udf.UDFHour;
 import org.apache.hadoop.hive.ql.udf.UDFJson;
-import org.apache.hadoop.hive.ql.udf.UDFLTrim;
 import org.apache.hadoop.hive.ql.udf.UDFLength;
 import org.apache.hadoop.hive.ql.udf.UDFLike;
 import org.apache.hadoop.hive.ql.udf.UDFLn;
 import org.apache.hadoop.hive.ql.udf.UDFLog;
 import org.apache.hadoop.hive.ql.udf.UDFLog10;
 import org.apache.hadoop.hive.ql.udf.UDFLog2;
-import org.apache.hadoop.hive.ql.udf.UDFLpad;
 import org.apache.hadoop.hive.ql.udf.UDFMinute;
 import org.apache.hadoop.hive.ql.udf.UDFMonth;
 import org.apache.hadoop.hive.ql.udf.UDFOPBitAnd;
@@ -80,7 +78,6 @@
 import org.apache.hadoop.hive.ql.udf.UDFOPLongDivide;
 import org.apache.hadoop.hive.ql.udf.UDFPI;
 import org.apache.hadoop.hive.ql.udf.UDFParseUrl;
-import org.apache.hadoop.hive.ql.udf.UDFRTrim;
 import org.apache.hadoop.hive.ql.udf.UDFRadians;
 import org.apache.hadoop.hive.ql.udf.UDFRand;
 import org.apache.hadoop.hive.ql.udf.UDFRegExp;
@@ -88,7 +85,6 @@
 import org.apache.hadoop.hive.ql.udf.UDFRegExpReplace;
 import org.apache.hadoop.hive.ql.udf.UDFRepeat;
 import org.apache.hadoop.hive.ql.udf.UDFReverse;
-import org.apache.hadoop.hive.ql.udf.UDFRpad;
 import org.apache.hadoop.hive.ql.udf.UDFSecond;
 import org.apache.hadoop.hive.ql.udf.UDFSign;
 import org.apache.hadoop.hive.ql.udf.UDFSin;
@@ -104,7 +100,6 @@
 import org.apache.hadoop.hive.ql.udf.UDFToLong;
 import org.apache.hadoop.hive.ql.udf.UDFToShort;
 import org.apache.hadoop.hive.ql.udf.UDFToString;
-import org.apache.hadoop.hive.ql.udf.UDFTrim;
 import org.apache.hadoop.hive.ql.udf.UDFType;
 import org.apache.hadoop.hive.ql.udf.UDFUnbase64;
 import org.apache.hadoop.hive.ql.udf.UDFUnhex;
@@ -180,8 +175,8 @@ public final class FunctionRegistry {
     registerUDF("space", UDFSpace.class, false);
     registerUDF("repeat", UDFRepeat.class, false);
     registerUDF("ascii", UDFAscii.class, false);
-    registerUDF("lpad", UDFLpad.class, false);
-    registerUDF("rpad", UDFRpad.class, false);
+    registerGenericUDF("lpad", GenericUDFLpad.class);
+    registerGenericUDF("rpad", GenericUDFRpad.class);
 
     registerGenericUDF("size", GenericUDFSize.class);
 
@@ -227,9 +222,9 @@ public final class FunctionRegistry {
     registerGenericUDF("lower", GenericUDFLower.class);
     registerGenericUDF("ucase", GenericUDFUpper.class);
     registerGenericUDF("lcase", GenericUDFLower.class);
-    registerUDF("trim", UDFTrim.class, false);
-    registerUDF("ltrim", UDFLTrim.class, false);
-    registerUDF("rtrim", UDFRTrim.class, false);
+    registerGenericUDF("trim", GenericUDFTrim.class);
+    registerGenericUDF("ltrim", GenericUDFLTrim.class);
+    registerGenericUDF("rtrim", GenericUDFRTrim.class);
     registerUDF("length", UDFLength.class, false);
     registerUDF("reverse", UDFReverse.class, false);
     registerGenericUDF("field", GenericUDFField.class);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java
index a2f050c7de..93cbb59b8f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java
@@ -89,7 +89,6 @@
 import org.apache.hadoop.hive.ql.udf.UDFExp;
 import org.apache.hadoop.hive.ql.udf.UDFHex;
 import org.apache.hadoop.hive.ql.udf.UDFHour;
-import org.apache.hadoop.hive.ql.udf.UDFLTrim;
 import org.apache.hadoop.hive.ql.udf.UDFLength;
 import org.apache.hadoop.hive.ql.udf.UDFLike;
 import org.apache.hadoop.hive.ql.udf.UDFLn;
@@ -98,7 +97,6 @@
 import org.apache.hadoop.hive.ql.udf.UDFLog2;
 import org.apache.hadoop.hive.ql.udf.UDFMinute;
 import org.apache.hadoop.hive.ql.udf.UDFMonth;
-import org.apache.hadoop.hive.ql.udf.UDFRTrim;
 import org.apache.hadoop.hive.ql.udf.UDFRadians;
 import org.apache.hadoop.hive.ql.udf.UDFRand;
 import org.apache.hadoop.hive.ql.udf.UDFRegExp;
@@ -116,7 +114,6 @@
 import org.apache.hadoop.hive.ql.udf.UDFToLong;
 import org.apache.hadoop.hive.ql.udf.UDFToShort;
 import org.apache.hadoop.hive.ql.udf.UDFToString;
-import org.apache.hadoop.hive.ql.udf.UDFTrim;
 import org.apache.hadoop.hive.ql.udf.UDFWeekOfYear;
 import org.apache.hadoop.hive.ql.udf.UDFYear;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDF;
@@ -129,6 +126,7 @@
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFFloor;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFIf;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFIn;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLTrim;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLower;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPAnd;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPDivide;
@@ -151,8 +149,10 @@
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFRound;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPPlus;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFPosMod;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFRTrim;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFTimestamp;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFToUnixTimeStamp;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFTrim;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFUpper;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFWhen;
 
@@ -217,9 +217,9 @@ public Vectorizer() {
     supportedGenericUDFs.add(UDFLike.class);
     supportedGenericUDFs.add(UDFRegExp.class);
     supportedGenericUDFs.add(UDFSubstr.class);
-    supportedGenericUDFs.add(UDFLTrim.class);
-    supportedGenericUDFs.add(UDFRTrim.class);
-    supportedGenericUDFs.add(UDFTrim.class);
+    supportedGenericUDFs.add(GenericUDFLTrim.class);
+    supportedGenericUDFs.add(GenericUDFRTrim.class);
+    supportedGenericUDFs.add(GenericUDFTrim.class);
 
     supportedGenericUDFs.add(UDFSin.class);
     supportedGenericUDFs.add(UDFCos.class);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBasePad.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBasePad.java
new file mode 100644
index 0000000000..d6dab78e9e
--- /dev/null
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBasePad.java
@@ -0,0 +1,122 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.udf.generic;
+
+import org.apache.commons.lang.StringUtils;
+import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
+import org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters;
+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters.Converter;
+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;
+import org.apache.hadoop.io.IntWritable;
+import org.apache.hadoop.io.Text;
+
+public abstract class GenericUDFBasePad extends GenericUDF {
+  private transient Converter converter1;
+  private transient Converter converter2;
+  private transient Converter converter3;
+  private Text result = new Text();
+  private String udfName;
+
+  public GenericUDFBasePad(String _udfName) {
+    this.udfName = _udfName;
+  }
+
+  @Override
+  public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumentException {
+    if (arguments.length != 3) {
+      throw new UDFArgumentException(udfName + " requires three arguments. Found :"
+	  + arguments.length);
+    }
+    converter1 = checkArguments(arguments, 0);
+    converter2 = checkArguments(arguments, 1);
+    converter3 = checkArguments(arguments, 2);
+    return PrimitiveObjectInspectorFactory.writableStringObjectInspector;
+  }
+
+  @Override
+  public Object evaluate(DeferredObject[] arguments) throws HiveException {
+    Object valObject1 = arguments[0].get();
+    Object valObject2 = arguments[1].get();
+    Object valObject3 = arguments[2].get();
+    if (valObject1 == null || valObject2 == null || valObject3 == null) {
+      return null;
+    }
+    Text str = (Text) converter1.convert(valObject1);
+    IntWritable lenW = (IntWritable) converter2.convert(valObject2);
+    Text pad = (Text) converter3.convert(valObject3);
+    if (str == null || pad == null || lenW == null) {
+      return null;
+    }
+    int len = lenW.get();
+
+    byte[] data = result.getBytes();
+    if (data.length < len) {
+      data = new byte[len];
+    }
+
+    byte[] txt = str.getBytes();
+    byte[] padTxt = pad.getBytes();
+
+    performOp(data, txt, padTxt, len, str, pad);
+    result.set(data, 0, len);
+    return result;
+  }
+
+  @Override
+  public String getDisplayString(String[] children) {
+    return udfName + "(" + StringUtils.join(children, ", ") + ")";
+  }
+
+  protected abstract void performOp(byte[] data, byte[] txt, byte[] padTxt, int len, Text str,
+      Text pad);
+
+  private Converter checkArguments(ObjectInspector[] arguments, int i)
+    throws UDFArgumentException {
+    if (arguments[i].getCategory() != ObjectInspector.Category.PRIMITIVE) {
+      throw new UDFArgumentTypeException(i + 1, "Only primitive type arguments are accepted but "
+	  + arguments[i].getTypeName() + " is passed. as  arguments");
+    }
+    PrimitiveCategory inputType = ((PrimitiveObjectInspector) arguments[i]).getPrimitiveCategory();
+    Converter converter;
+    switch (inputType) {
+    case STRING:
+    case CHAR:
+    case VARCHAR:
+      converter = ObjectInspectorConverters.getConverter((PrimitiveObjectInspector) arguments[i],
+	  PrimitiveObjectInspectorFactory.writableStringObjectInspector);
+      break;
+    case INT:
+    case SHORT:
+    case BYTE:
+      converter = ObjectInspectorConverters.getConverter((PrimitiveObjectInspector) arguments[i],
+	  PrimitiveObjectInspectorFactory.writableIntObjectInspector);
+      break;
+    default:
+      throw new UDFArgumentTypeException(i + 1, udfName
+	  + " only takes STRING/CHAR/INT/SHORT/BYTE/VARCHAR types as " + (i + 1) + "-ths argument, got "
+	  + inputType);
+    }
+    return converter;
+  }
+}
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseTrim.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseTrim.java
new file mode 100644
index 0000000000..b3a9e67305
--- /dev/null
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseTrim.java
@@ -0,0 +1,86 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.udf.generic;
+
+import org.apache.commons.lang.StringUtils;
+import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter.TextConverter;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.io.Text;
+
+public abstract class GenericUDFBaseTrim extends GenericUDF {
+  private transient TextConverter converter;
+  private Text result = new Text();
+  private String udfName;
+
+  public GenericUDFBaseTrim(String _udfName) {
+    this.udfName = _udfName;
+  }
+
+  @Override
+  public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumentException {
+    if (arguments.length != 1) {
+      throw new UDFArgumentException(udfName + " requires one value argument. Found :"
+	  + arguments.length);
+    }
+    PrimitiveObjectInspector argumentOI;
+    if(arguments[0] instanceof PrimitiveObjectInspector) {
+      argumentOI = (PrimitiveObjectInspector) arguments[0];
+    } else {
+      throw new UDFArgumentException(udfName + " takes only primitive types. found "
+	  + arguments[0].getTypeName());
+    }
+    switch (argumentOI.getPrimitiveCategory()) {
+    case STRING:
+    case CHAR:
+    case VARCHAR:
+      break;
+    default:
+      throw new UDFArgumentException(udfName + " takes only STRING/CHAR/VARCHAR types. Found "
+	  + argumentOI.getPrimitiveCategory());
+    }
+    converter = new TextConverter(argumentOI);
+    return PrimitiveObjectInspectorFactory.writableStringObjectInspector;
+  }
+
+  @Override
+  public Object evaluate(DeferredObject[] arguments) throws HiveException {
+    Object valObject = arguments[0].get();
+    if (valObject == null) {
+      return null;
+    }
+    String val = ((Text) converter.convert(valObject)).toString();
+    if (val == null) {
+      return null;
+    }
+    result.set(performOp(val.toString()));
+    return result;
+  }
+
+  @Override
+  public String getDisplayString(String[] children) {
+    return udfName + "(" + StringUtils.join(children, ", ") + ")";
+  }
+
+  protected abstract String performOp(String val);
+
+}
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFLTrim.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLTrim.java
old mode 100755
new mode 100644
similarity index 69%
rename from ql/src/java/org/apache/hadoop/hive/ql/udf/UDFLTrim.java
rename to ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLTrim.java
index dc00cf95df..e5764630b8
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFLTrim.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLTrim.java
@@ -16,36 +16,31 @@
  * limitations under the License.
  */
 
-package org.apache.hadoop.hive.ql.udf;
+package org.apache.hadoop.hive.ql.udf.generic;
 
 import org.apache.commons.lang.StringUtils;
 import org.apache.hadoop.hive.ql.exec.Description;
-import org.apache.hadoop.hive.ql.exec.UDF;
 import org.apache.hadoop.hive.ql.exec.vector.VectorizedExpressions;
 import org.apache.hadoop.hive.ql.exec.vector.expressions.StringLTrim;
-import org.apache.hadoop.io.Text;
 
 /**
  * UDFLTrim.
  *
  */
 @Description(name = "ltrim",
-    value = "_FUNC_(str) - Removes the leading space characters from str ",
-    extended = "Example:\n"
+    value = "_FUNC_(str) - Removes the " +
+    "leading space characters from str ", extended = "Example:\n"
     + "  > SELECT _FUNC_('   facebook') FROM src LIMIT 1;\n" + "  'facebook'")
-@VectorizedExpressions({StringLTrim.class})
-public class UDFLTrim extends UDF {
-  private final Text result = new Text();
+@VectorizedExpressions({ StringLTrim.class })
+public class GenericUDFLTrim extends GenericUDFBaseTrim {
 
-  public UDFLTrim() {
+  public GenericUDFLTrim() {
+    super("ltrim");
   }
 
-  public Text evaluate(Text s) {
-    if (s == null) {
-      return null;
-    }
-    result.set(StringUtils.stripStart(s.toString(), " "));
-    return result;
+  @Override
+  protected String performOp(String val) {
+    return StringUtils.stripStart(val, " ");
   }
 
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFLpad.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLpad.java
similarity index 68%
rename from ql/src/java/org/apache/hadoop/hive/ql/udf/UDFLpad.java
rename to ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLpad.java
index d1da19a1ee..76ee94ee45 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFLpad.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLpad.java
@@ -16,11 +16,9 @@
  * limitations under the License.
  */
 
-package org.apache.hadoop.hive.ql.udf;
+package org.apache.hadoop.hive.ql.udf.generic;
 
 import org.apache.hadoop.hive.ql.exec.Description;
-import org.apache.hadoop.hive.ql.exec.UDF;
-import org.apache.hadoop.io.IntWritable;
 import org.apache.hadoop.io.Text;
 
 /**
@@ -35,41 +33,27 @@
     + "  > SELECT _FUNC_('hi', 5, '??') FROM src LIMIT 1;\n"
     + "  '???hi'"
     + "  > SELECT _FUNC_('hi', 1, '??') FROM src LIMIT 1;\n" + "  'h'")
-public class UDFLpad extends UDF {
-
-  private final Text result = new Text();
-
-  public Text evaluate(Text s, IntWritable n, Text pad) {
-    if (s == null || n == null || pad == null) {
-      return null;
-    }
-
-    int len = n.get();
-
-    byte[] data = result.getBytes();
-    if (data.length < len) {
-      data = new byte[len];
-    }
-
-    byte[] txt = s.getBytes();
-    byte[] padTxt = pad.getBytes();
+public class GenericUDFLpad extends GenericUDFBasePad {
+  public GenericUDFLpad() {
+    super("lpad");
+  }
 
+  @Override
+  protected void performOp(byte[] data, byte[] txt, byte[] padTxt, int len, Text str, Text pad) {
     // The length of the padding needed
-    int pos = Math.max(len - s.getLength(), 0);
+    int pos = Math.max(len - str.getLength(), 0);
 
     // Copy the padding
     for (int i = 0; i < pos; i += pad.getLength()) {
       for (int j = 0; j < pad.getLength() && j < pos - i; j++) {
-        data[i + j] = padTxt[j];
+	data[i + j] = padTxt[j];
       }
     }
 
     // Copy the text
-    for (int i = 0; pos + i < len && i < s.getLength(); i++) {
+    for (int i = 0; pos + i < len && i < str.getLength(); i++) {
       data[pos + i] = txt[i];
     }
-
-    result.set(data, 0, len);
-    return result;
   }
+
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFRTrim.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFRTrim.java
old mode 100755
new mode 100644
similarity index 76%
rename from ql/src/java/org/apache/hadoop/hive/ql/udf/UDFRTrim.java
rename to ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFRTrim.java
index 2bcc5fab9c..670927e224
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFRTrim.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFRTrim.java
@@ -16,14 +16,12 @@
  * limitations under the License.
  */
 
-package org.apache.hadoop.hive.ql.udf;
+package org.apache.hadoop.hive.ql.udf.generic;
 
 import org.apache.commons.lang.StringUtils;
 import org.apache.hadoop.hive.ql.exec.Description;
-import org.apache.hadoop.hive.ql.exec.UDF;
 import org.apache.hadoop.hive.ql.exec.vector.VectorizedExpressions;
 import org.apache.hadoop.hive.ql.exec.vector.expressions.StringRTrim;
-import org.apache.hadoop.io.Text;
 
 /**
  * UDFRTrim.
@@ -33,20 +31,15 @@
     value = "_FUNC_(str) - Removes the trailing space characters from str ",
     extended = "Example:\n"
     + "  > SELECT _FUNC_('facebook   ') FROM src LIMIT 1;\n" + "  'facebook'")
-@VectorizedExpressions({StringRTrim.class})
-public class UDFRTrim extends UDF {
-
-  Text result = new Text();
-
-  public UDFRTrim() {
+@VectorizedExpressions({ StringRTrim.class })
+public class GenericUDFRTrim extends GenericUDFBaseTrim {
+  public GenericUDFRTrim() {
+    super("rtrim");
   }
 
-  public Text evaluate(Text s) {
-    if (s == null) {
-      return null;
-    }
-    result.set(StringUtils.stripEnd(s.toString(), " "));
-    return result;
+  @Override
+  protected String performOp(String val) {
+    return StringUtils.stripEnd(val, " ");
   }
 
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFRpad.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFRpad.java
similarity index 60%
rename from ql/src/java/org/apache/hadoop/hive/ql/udf/UDFRpad.java
rename to ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFRpad.java
index 9652ce268d..e436f3a129 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFRpad.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFRpad.java
@@ -16,58 +16,41 @@
  * limitations under the License.
  */
 
-package org.apache.hadoop.hive.ql.udf;
+package org.apache.hadoop.hive.ql.udf.generic;
 
 import org.apache.hadoop.hive.ql.exec.Description;
-import org.apache.hadoop.hive.ql.exec.UDF;
-import org.apache.hadoop.io.IntWritable;
 import org.apache.hadoop.io.Text;
 
 /**
  * UDFRpad.
  *
  */
-@Description(name = "rpad",
-    value = "_FUNC_(str, len, pad) - Returns str, right-padded with pad to a length of len",
+@Description(name = "rpad", value = "_FUNC_(str, len, pad) - " +
+    "Returns str, right-padded with pad to a length of len",
     extended = "If str is longer than len, the return value is shortened to "
     + "len characters.\n"
     + "Example:\n"
     + "  > SELECT _FUNC_('hi', 5, '??') FROM src LIMIT 1;\n"
-    + "  'hi???'"
-    + "  > SELECT _FUNC_('hi', 1, '??') FROM src LIMIT 1;\n" + "  'h'")
-public class UDFRpad extends UDF {
-  private final Text result = new Text();
-
-  public Text evaluate(Text s, IntWritable n, Text pad) {
-    if (s == null || n == null || pad == null) {
-      return null;
-    }
-
-    int len = n.get();
-
-    byte[] data = result.getBytes();
-    if (data.length < len) {
-      data = new byte[len];
-    }
-
-    byte[] txt = s.getBytes();
-    byte[] padTxt = pad.getBytes();
+    + "  'hi???'" + "  > SELECT _FUNC_('hi', 1, '??') FROM src LIMIT 1;\n" + "  'h'")
+public class GenericUDFRpad extends GenericUDFBasePad {
+  public GenericUDFRpad() {
+    super("rpad");
+  }
 
+  @Override
+  protected void performOp(byte[] data, byte[] txt, byte[] padTxt, int len, Text str, Text pad) {
     int pos;
     // Copy the text
-    for (pos = 0; pos < s.getLength() && pos < len; pos++) {
+    for (pos = 0; pos < str.getLength() && pos < len; pos++) {
       data[pos] = txt[pos];
     }
 
     // Copy the padding
     while (pos < len) {
       for (int i = 0; i < pad.getLength() && i < len - pos; i++) {
-        data[pos + i] = padTxt[i];
+	data[pos + i] = padTxt[i];
       }
       pos += pad.getLength();
     }
-
-    result.set(data, 0, len);
-    return result;
   }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFTrim.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTrim.java
old mode 100755
new mode 100644
similarity index 76%
rename from ql/src/java/org/apache/hadoop/hive/ql/udf/UDFTrim.java
rename to ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTrim.java
index 490886dbf6..4e5fe62f7d
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFTrim.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTrim.java
@@ -16,14 +16,12 @@
  * limitations under the License.
  */
 
-package org.apache.hadoop.hive.ql.udf;
+package org.apache.hadoop.hive.ql.udf.generic;
 
 import org.apache.commons.lang.StringUtils;
 import org.apache.hadoop.hive.ql.exec.Description;
-import org.apache.hadoop.hive.ql.exec.UDF;
 import org.apache.hadoop.hive.ql.exec.vector.VectorizedExpressions;
 import org.apache.hadoop.hive.ql.exec.vector.expressions.StringTrim;
-import org.apache.hadoop.io.Text;
 
 /**
  * UDFTrim.
@@ -33,20 +31,15 @@
     value = "_FUNC_(str) - Removes the leading and trailing space characters from str ",
     extended = "Example:\n"
     + "  > SELECT _FUNC_('   facebook  ') FROM src LIMIT 1;\n" + "  'facebook'")
-@VectorizedExpressions({StringTrim.class})
-public class UDFTrim extends UDF {
-
-  Text result = new Text();
-
-  public UDFTrim() {
+@VectorizedExpressions({ StringTrim.class })
+public class GenericUDFTrim extends GenericUDFBaseTrim {
+  public GenericUDFTrim() {
+    super("trim");
   }
 
-  public Text evaluate(Text s) {
-    if (s == null) {
-      return null;
-    }
-    result.set(StringUtils.strip(s.toString(), " "));
-    return result;
+  @Override
+  protected String performOp(String val) {
+    return StringUtils.strip(val, " ");
   }
 
 }
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorizationContext.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorizationContext.java
index eff251f844..454a02dd54 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorizationContext.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorizationContext.java
@@ -99,7 +99,6 @@
 import org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc;
-import org.apache.hadoop.hive.ql.udf.UDFLTrim;
 import org.apache.hadoop.hive.ql.udf.UDFLog;
 import org.apache.hadoop.hive.ql.udf.UDFSin;
 import org.apache.hadoop.hive.ql.udf.UDFYear;
@@ -108,6 +107,7 @@
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFIf;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFIn;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLTrim;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLower;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPAnd;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqual;
@@ -770,7 +770,7 @@ public void testUnaryStringExpressions() throws HiveException {
     List<ExprNodeDesc> children2 = new ArrayList<ExprNodeDesc>();
     children2.add(stringUnary);
     anotherUnary.setChildren(children2);
-    GenericUDFBridge udfbridge = new GenericUDFBridge("ltrim", false, UDFLTrim.class.getName());
+    GenericUDFBridge udfbridge = new GenericUDFBridge("ltrim", false, GenericUDFLTrim.class.getName());
     anotherUnary.setGenericUDF(udfbridge);
 
     ve = vc.getVectorExpression(anotherUnary);
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFLTrim.java b/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFLTrim.java
new file mode 100644
index 0000000000..058dc362fa
--- /dev/null
+++ b/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFLTrim.java
@@ -0,0 +1,53 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.ql.udf;
+
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredJavaObject;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredObject;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLTrim;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.io.Text;
+
+import junit.framework.TestCase;
+
+public class TestGenericUDFLTrim extends TestCase {
+
+  public void testTrim() throws HiveException {
+    GenericUDFLTrim udf = new GenericUDFLTrim();
+    ObjectInspector valueOI = PrimitiveObjectInspectorFactory.writableStringObjectInspector;
+    ObjectInspector[] arguments = { valueOI };
+
+    udf.initialize(arguments);
+    runAndVerify(" Hello World! ", "Hello World! ", udf);
+    runAndVerify("Hello World! ", "Hello World! ", udf);
+    runAndVerify(" Hello World!", "Hello World!", udf);
+    runAndVerify("Hello World!", "Hello World!", udf);
+    runAndVerify("   ", "", udf);
+  }
+
+  private void runAndVerify(String str, String expResult, GenericUDF udf) throws HiveException {
+
+    DeferredObject valueObj = new DeferredJavaObject(new Text(str));
+    DeferredObject[] args = { valueObj };
+    Text output = (Text) udf.evaluate(args);
+    assertEquals("ltrim() test ", expResult, output.toString());
+  }
+}
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFLpad.java b/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFLpad.java
new file mode 100644
index 0000000000..e5a588d83d
--- /dev/null
+++ b/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFLpad.java
@@ -0,0 +1,55 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.ql.udf;
+
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredJavaObject;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredObject;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLpad;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.io.IntWritable;
+import org.apache.hadoop.io.Text;
+
+import junit.framework.TestCase;
+
+public class TestGenericUDFLpad extends TestCase {
+
+  public void testLpad() throws HiveException {
+    GenericUDFLpad udf = new GenericUDFLpad();
+    ObjectInspector valueOI1 = PrimitiveObjectInspectorFactory.writableStringObjectInspector;
+    ObjectInspector valueOI2 = PrimitiveObjectInspectorFactory.writableIntObjectInspector;
+    ObjectInspector valueOI3 = PrimitiveObjectInspectorFactory.writableStringObjectInspector;
+    ObjectInspector[] arguments = { valueOI1, valueOI2, valueOI3 };
+
+    udf.initialize(arguments);
+    runAndVerify("hi", 5, "??", "???hi", udf);
+    runAndVerify("hi", 1, "??", "h", udf);
+  }
+
+  private void runAndVerify(String str, int len, String pad, String expResult, GenericUDF udf)
+      throws HiveException {
+    DeferredObject valueObj1 = new DeferredJavaObject(new Text(str));
+    DeferredObject valueObj2 = new DeferredJavaObject(new IntWritable(len));
+    DeferredObject valueObj3 = new DeferredJavaObject(new Text(pad));
+    DeferredObject[] args = { valueObj1, valueObj2, valueObj3 };
+    Text output = (Text) udf.evaluate(args);
+    assertEquals("lpad() test ", expResult, output.toString());
+  }
+}
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFRTrim.java b/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFRTrim.java
new file mode 100644
index 0000000000..9e1a10a3ad
--- /dev/null
+++ b/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFRTrim.java
@@ -0,0 +1,52 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.ql.udf;
+
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredJavaObject;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredObject;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFRTrim;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.io.Text;
+
+import junit.framework.TestCase;
+
+public class TestGenericUDFRTrim extends TestCase {
+
+  public void testTrim() throws HiveException {
+    GenericUDFRTrim udf = new GenericUDFRTrim();
+    ObjectInspector valueOI = PrimitiveObjectInspectorFactory.writableStringObjectInspector;
+    ObjectInspector[] arguments = { valueOI };
+
+    udf.initialize(arguments);
+    runAndVerify(" Hello World! ", " Hello World!", udf);
+    runAndVerify("Hello World! ", "Hello World!", udf);
+    runAndVerify(" Hello World!", " Hello World!", udf);
+    runAndVerify("Hello World!", "Hello World!", udf);
+    runAndVerify("   ", "", udf);
+  }
+
+  private void runAndVerify(String str, String expResult, GenericUDF udf) throws HiveException {
+    DeferredObject valueObj = new DeferredJavaObject(new Text(str));
+    DeferredObject[] args = { valueObj };
+    Text output = (Text) udf.evaluate(args);
+    assertEquals("ltrim() test ", expResult, output.toString());
+  }
+}
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFRpad.java b/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFRpad.java
new file mode 100644
index 0000000000..239694ca28
--- /dev/null
+++ b/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFRpad.java
@@ -0,0 +1,55 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.ql.udf;
+
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredJavaObject;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredObject;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFLpad;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.io.IntWritable;
+import org.apache.hadoop.io.Text;
+
+import junit.framework.TestCase;
+
+public class TestGenericUDFRpad extends TestCase {
+
+  public void testLpad() throws HiveException {
+    GenericUDFLpad udf = new GenericUDFLpad();
+    ObjectInspector valueOI1 = PrimitiveObjectInspectorFactory.writableStringObjectInspector;
+    ObjectInspector valueOI2 = PrimitiveObjectInspectorFactory.writableIntObjectInspector;
+    ObjectInspector valueOI3 = PrimitiveObjectInspectorFactory.writableStringObjectInspector;
+    ObjectInspector[] arguments = { valueOI1, valueOI2, valueOI3 };
+
+    udf.initialize(arguments);
+    runAndVerify("hi", 5, "??", "???hi", udf);
+    runAndVerify("hi", 1, "??", "h", udf);
+  }
+
+  private void runAndVerify(String str, int len, String pad, String expResult, GenericUDF udf)
+      throws HiveException {
+    DeferredObject valueObj1 = new DeferredJavaObject(new Text(str));
+    DeferredObject valueObj2 = new DeferredJavaObject(new IntWritable(len));
+    DeferredObject valueObj3 = new DeferredJavaObject(new Text(pad));
+    DeferredObject[] args = { valueObj1, valueObj2, valueObj3 };
+    Text output = (Text) udf.evaluate(args);
+    assertEquals("lpad() test ", expResult, output.toString());
+  }
+}
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFTrim.java b/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFTrim.java
new file mode 100644
index 0000000000..59676d50bb
--- /dev/null
+++ b/ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFTrim.java
@@ -0,0 +1,53 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.ql.udf;
+
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredJavaObject;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF.DeferredObject;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFTrim;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.io.Text;
+
+import junit.framework.TestCase;
+
+public class TestGenericUDFTrim extends TestCase {
+
+  public void testTrim() throws HiveException {
+    GenericUDFTrim udf = new GenericUDFTrim();
+    ObjectInspector valueOI = PrimitiveObjectInspectorFactory.writableStringObjectInspector;
+    ObjectInspector[] arguments = { valueOI };
+
+    udf.initialize(arguments);
+    runAndVerify(" Hello World! ", "Hello World!", udf);
+    runAndVerify("Hello World! ", "Hello World!", udf);
+    runAndVerify(" Hello World!", "Hello World!", udf);
+    runAndVerify("Hello World!", "Hello World!", udf);
+    runAndVerify("   ", "", udf);
+  }
+
+  private void runAndVerify(String str, String expResult, GenericUDF udf) throws HiveException {
+
+    DeferredObject valueObj = new DeferredJavaObject(new Text(str));
+    DeferredObject[] args = { valueObj };
+    Text output = (Text) udf.evaluate(args);
+    assertEquals("trim() test ", expResult, output.toString());
+  }
+}
