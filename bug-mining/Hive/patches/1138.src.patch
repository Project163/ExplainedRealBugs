diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
index ef4f6445b5..0cc2ef2ff6 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
@@ -138,7 +138,7 @@ private static boolean[] findIncludedColumns(List<OrcProto.Type> types,
                                                Configuration conf) {
     String includedStr =
         conf.get(ColumnProjectionUtils.READ_COLUMN_IDS_CONF_STR);
-    if (includedStr == null) {
+    if (includedStr == null || includedStr.trim().length() == 0) {
       return null;
     } else {
       int numColumns = types.size();
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java b/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java
index 855856f744..785f0b1113 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java
@@ -169,6 +169,22 @@ public void testInOutFormat() throws Exception {
     }
     assertEquals(3, rowNum);
     reader.close();
+
+    // test the mapping of empty string to all columns
+    conf.set("hive.io.file.readcolumn.ids", "");
+    reader = in.getRecordReader(splits[0], conf, Reporter.NULL);
+    key = reader.createKey();
+    value = (Writable) reader.createValue();
+    rowNum = 0;
+    fields = inspector.getAllStructFieldRefs();
+    while (reader.next(key, value)) {
+      assertEquals(++rowNum, intInspector.get(inspector.
+          getStructFieldData(value, fields.get(0))));
+      assertEquals(2, intInspector.get(inspector.
+          getStructFieldData(serde.deserialize(value), fields.get(1))));
+    }
+    assertEquals(3, rowNum);
+    reader.close();
   }
 
   static class NestedRow implements Writable {
