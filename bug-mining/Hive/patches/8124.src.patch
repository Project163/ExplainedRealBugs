diff --git a/itests/hive-jmh/src/main/java/org/apache/hive/benchmark/serde/HyperLogLogBench.java b/itests/hive-jmh/src/main/java/org/apache/hive/benchmark/serde/HyperLogLogBench.java
new file mode 100644
index 0000000000..1a9ebb1ed8
--- /dev/null
+++ b/itests/hive-jmh/src/main/java/org/apache/hive/benchmark/serde/HyperLogLogBench.java
@@ -0,0 +1,132 @@
+/*
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hive.benchmark.serde;
+
+import java.util.concurrent.TimeUnit;
+
+import org.apache.hadoop.hive.common.ndv.hll.HyperLogLog;
+import org.openjdk.jmh.annotations.Benchmark;
+import org.openjdk.jmh.annotations.BenchmarkMode;
+import org.openjdk.jmh.annotations.Fork;
+import org.openjdk.jmh.annotations.Measurement;
+import org.openjdk.jmh.annotations.Mode;
+import org.openjdk.jmh.annotations.OutputTimeUnit;
+import org.openjdk.jmh.annotations.Scope;
+import org.openjdk.jmh.annotations.Setup;
+import org.openjdk.jmh.annotations.State;
+import org.openjdk.jmh.annotations.Warmup;
+import org.openjdk.jmh.runner.Runner;
+import org.openjdk.jmh.runner.RunnerException;
+import org.openjdk.jmh.runner.options.Options;
+import org.openjdk.jmh.runner.options.OptionsBuilder;
+
+/**
+ * java -cp target/benchmarks.jar org.apache.hive.benchmark.serde.HyperLogLogBench
+ */
+@State(Scope.Benchmark)
+public class HyperLogLogBench {
+  public static final int DEFAULT_ITER_TIME = 1000000;
+
+  @BenchmarkMode(Mode.AverageTime)
+  @Fork(1)
+  @State(Scope.Thread)
+  @OutputTimeUnit(TimeUnit.MILLISECONDS)
+  public static abstract class Abstract {
+
+    @Setup
+    public abstract void setup();
+
+    @Benchmark
+    @Warmup(iterations = 3, time = 2, timeUnit = TimeUnit.MILLISECONDS)
+    @Measurement(iterations = 5, time = 2, timeUnit = TimeUnit.MILLISECONDS)
+    public void bench() {
+
+    }
+  }
+
+
+  public abstract static class SizeOptimizedSparseStressN extends Abstract {
+
+    private HyperLogLog hll;
+    private final int stressN;
+    private final int numIterations;
+
+    public SizeOptimizedSparseStressN(int stressN) {
+      this.stressN = stressN;
+      numIterations = DEFAULT_ITER_TIME / stressN;
+    }
+
+    @Override
+    public void setup() {
+      hll = HyperLogLog.builder().setSizeOptimized().build();
+    }
+
+    @Override
+    public void bench() {
+      for (int i = 0; i < numIterations; i++) {
+        for (int j = 0; j < stressN; j++) {
+          hll.addInt(j);
+        }
+      }
+    }
+
+  }
+
+  public static class SizeOptimizedSparseStress30 extends SizeOptimizedSparseStressN {
+    public SizeOptimizedSparseStress30() {
+      super(30);
+    }
+  }
+
+  public static class SizeOptimizedSparseStress70 extends SizeOptimizedSparseStressN {
+    public SizeOptimizedSparseStress70() {
+      super(70);
+    }
+  }
+
+  public static class SizeOptimizedSparseStressTminus10 extends SizeOptimizedSparseStressN {
+    public SizeOptimizedSparseStressTminus10() {
+      super(HyperLogLog.builder().setSizeOptimized().build().getEncodingSwitchThreshold()-10);
+    }
+  }
+
+  public static class SizeOptimizedSparseStressTminus1 extends SizeOptimizedSparseStressN {
+    public SizeOptimizedSparseStressTminus1() {
+      super(HyperLogLog.builder().setSizeOptimized().build().getEncodingSwitchThreshold() - 1);
+    }
+  }
+
+  public static class SizeOptimizedSparseStressT extends SizeOptimizedSparseStressN {
+    public SizeOptimizedSparseStressT() {
+      super(HyperLogLog.builder().setSizeOptimized().build().getEncodingSwitchThreshold());
+    }
+  }
+
+  public static class SizeOptimizedDenseStress2T extends SizeOptimizedSparseStressN {
+    public SizeOptimizedDenseStress2T() {
+      super(2 * HyperLogLog.builder().setSizeOptimized().build().getEncodingSwitchThreshold());
+    }
+  }
+
+  public static class SizeOptimizedDenseStress8T extends SizeOptimizedSparseStressN {
+    public SizeOptimizedDenseStress8T() {
+      super(8*HyperLogLog.builder().setSizeOptimized().build().getEncodingSwitchThreshold());
+    }
+  }
+
+  public static void main(String[] args) throws RunnerException {
+    Options opt = new OptionsBuilder().include(".*" + HyperLogLogBench.class.getSimpleName() + ".*").build();
+    new Runner(opt).run();
+  }
+}
diff --git a/ql/src/test/results/clientpositive/llap/bucket_map_join_tez2.q.out b/ql/src/test/results/clientpositive/llap/bucket_map_join_tez2.q.out
index 6f0c60c428..4757c32979 100644
--- a/ql/src/test/results/clientpositive/llap/bucket_map_join_tez2.q.out
+++ b/ql/src/test/results/clientpositive/llap/bucket_map_join_tez2.q.out
@@ -1195,13 +1195,13 @@ STAGE PLANS:
                       minReductionHashAggr: 0.4
                       mode: hash
                       outputColumnNames: _col0
-                      Statistics: Num rows: 146 Data size: 584 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 153 Data size: 612 Basic stats: COMPLETE Column stats: COMPLETE
                       Reduce Output Operator
                         key expressions: _col0 (type: int)
                         null sort order: z
                         sort order: +
                         Map-reduce partition columns: _col0 (type: int)
-                        Statistics: Num rows: 146 Data size: 584 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 153 Data size: 612 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: key (type: int)
                       outputColumnNames: _col0
@@ -1221,13 +1221,13 @@ STAGE PLANS:
                 keys: KEY._col0 (type: int)
                 mode: mergepartial
                 outputColumnNames: _col0
-                Statistics: Num rows: 146 Data size: 584 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 153 Data size: 612 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: int)
                   null sort order: z
                   sort order: +
                   Map-reduce partition columns: _col0 (type: int)
-                  Statistics: Num rows: 146 Data size: 584 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 153 Data size: 612 Basic stats: COMPLETE Column stats: COMPLETE
         Reducer 3 
             Execution mode: llap
             Reduce Operator Tree:
@@ -1290,13 +1290,13 @@ STAGE PLANS:
                       minReductionHashAggr: 0.4
                       mode: hash
                       outputColumnNames: _col0
-                      Statistics: Num rows: 146 Data size: 584 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 153 Data size: 612 Basic stats: COMPLETE Column stats: COMPLETE
                       Reduce Output Operator
                         key expressions: _col0 (type: int)
                         null sort order: z
                         sort order: +
                         Map-reduce partition columns: _col0 (type: int)
-                        Statistics: Num rows: 146 Data size: 584 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 153 Data size: 612 Basic stats: COMPLETE Column stats: COMPLETE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 3 
@@ -1304,7 +1304,7 @@ STAGE PLANS:
                 TableScan
                   alias: b
                   filterExpr: key is not null (type: boolean)
-                  probeDecodeDetails: cacheKey:HASH_MAP_MAPJOIN_29_container, bigKeyColName:key, smallTablePos:0, keyRatio:0.6033057851239669
+                  probeDecodeDetails: cacheKey:HASH_MAP_MAPJOIN_29_container, bigKeyColName:key, smallTablePos:0, keyRatio:0.6322314049586777
                   Statistics: Num rows: 242 Data size: 968 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: key is not null (type: boolean)
@@ -1339,13 +1339,13 @@ STAGE PLANS:
                 keys: KEY._col0 (type: int)
                 mode: mergepartial
                 outputColumnNames: _col0
-                Statistics: Num rows: 146 Data size: 584 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 153 Data size: 612 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: int)
                   null sort order: z
                   sort order: +
                   Map-reduce partition columns: _col0 (type: int)
-                  Statistics: Num rows: 146 Data size: 584 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 153 Data size: 612 Basic stats: COMPLETE Column stats: COMPLETE
 
   Stage: Stage-0
     Fetch Operator
diff --git a/ql/src/test/results/clientpositive/llap/compute_bit_vector.q.out b/ql/src/test/results/clientpositive/llap/compute_bit_vector.q.out
index 45d0253a74..f90eb70aec 100644
--- a/ql/src/test/results/clientpositive/llap/compute_bit_vector.q.out
+++ b/ql/src/test/results/clientpositive/llap/compute_bit_vector.q.out
@@ -6,7 +6,7 @@ POSTHOOK: query: select hex(compute_bit_vector_hll(ctinyint)) from alltypesorc
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alltypesorc
 #### A masked pattern was here ####
-484C4CA48201002400000000000010000000000000000030000000010000300020000020000000001010000000000000101000000000000000000000000000010010000000000000000000000000000000202000000000003000000000005010000000100020000100000004001100200000600000000020000001000000000040000101000000000000030000000000000300000000000000010000001004000000000241000001000000002000200000000020000000000101000000000000000000000010000020000030000000000000000000300000000000000000000000000100000332000000000000000000000000000000000001010000000000000000000000000000000010010301000000000000000000000020000000000002000020000000000020210000000000001000020400000000001000000010001000000000100002000000000000300000000000001000000001111010000000000000100000000000000000000000000000000000000000000001010000100000510000000000000300000200000000000020000200200040001001090000020000000000010400000000400001000000000100000020000000000000000210000200110000000000001000000000000000000000000002000000000000003000000000000080000100003100000002000000000000000001000100000004000C400000000002
+484C4CA07F7F829AE8688083800DFF9DBCF404C19597E0FCFFFFFFFF01BFDAB0D90282A7C4A3FDFFFFFFFF01C08D81A704FEC6E59AFEFFFFFFFF01C090B7C2FCFFFFFFFF01C1809DFD03C0F7FFE1FBFFFFFFFF01809DDDFF0481CCA7D5FEFFFFFFFF01FE9FD745C3F5DACBFFFFFFFFFF01FDE5A2D5FBFFFFFFFF0180D4EFCB02C1B485AC01FFBCA2F5FDFFFFFFFF01C3A883E601BDA0FC8EFDFFFFFFFF01C19EBE7780D9DFEFFDFFFFFFFF01BF99E454C1DADCF803809FDFFBFCFFFFFFFF01C0F5EFCAFFFFFFFFFF0180DF8D8603BFAABFB5FDFFFFFFFF01C0FEA4FC03C1F39CB1FAFFFFFFFF01C1C298B303C185AF19FDBD8DFFFDFFFFFFFF0181BD8BFD0581A4B7F4F8FFFFFFFF01C0C2C1B202FFDBB7EBFCFFFFFFFF01BFDABAE806C193A3D7FEFFFFFFFF01FFCBCC9EFEFFFFFFFF0180F6E1F4FFFFFFFFFF01818CE28F04C2B9C890FAFFFFFFFF01BFACB09201BE8DA5C904808FF9C1FAFFFFFFFF01C085E5E803C09598D3FCFFFFFFFF01C1EC9BB603C09BD297FFFFFFFFFF01C0DAF0A90282B2D7AAFAFFFFFFFF01FDACD3CEFEFFFFFFFF0183E6ACE8FFFFFFFFFF01BD95E1F203C1D5E6D50183C995C101BCC6B6E1FDFFFFFFFF01C0F48F0B8097A79EFFFFFFFFFF0180F9C51DC099ABBCFFFFFFFFFF01C0BAA78FFEFFFFFFFF0183A7DAE2FEFFFFFFFF0181DCA18501BC9AB442C2C3BC8DFEFFFFFFFF01808CE030FEDAF9DE0280C5F0A702C39BA557BFF18CD5FBFFFFFFFF01FEC2C6FBFDFFFFFFFF01C0B3B7C20580FFAFFDFFFFFFFFFF01C09DC1870181CDF9CCFEFFFFFFFF018289C8F3FFFFFFFFFF01C8FFA2F4FBFFFFFFFF01F5F7ABA104C0D197D5FAFFFFFFFF01C2C8E9AF06BED0D5D6FDFFFFFFFF01C098A6E0FCFFFFFFFF01C1B3DCD106BFCAFC95FDFFFFFFFF0181A6D5B2FDFFFFFFFF01FFDAECE3FEFFFFFFFF0180E0C6FCFEFFFFFFFF0181E7FCF202C0F2DDC604BFF1CBBEFAFFFFFFFF01C5CDCBB4FFFFFFFFFF01BB99F59C0581FA85A5FEFFFFFFFF01BFBCB384FEFFFFFFFF01C0B897CCFDFFFFFFFF0180FFF7F0FFFFFFFFFF01C1D7F9F604FF898688FCFFFFFFFF01C2ACF4CB01BFC0D688FEFFFFFFFF01869DFAC704B9FDF9FAFFFFFFFFFF0182AAB4CA01FEDD9581FDFFFFFFFF0180B1F4C0FFFFFFFFFF01809DD98AFFFFFFFFFF0188E3ED71BAB98E9AFDFFFFFFFF01BEE4E38C0580C0C880FAFFFFFFFF01C094A6DD07819E95DCFEFFFFFFFF01BFBBDB8DFAFFFFFFFF01C1A9C6A7078088DF9CFFFFFFFFFF01C2E4E9EBF8FFFFFFFF01BDB0D9F40283D2E6B701BEEEE74BFF91AB89FBFFFFFFFF01C0D3C7CA05C0D3F69701C0F5C74280A2A9ECFEFFFFFFFF01
 PREHOOK: query: select hex(compute_bit_vector_hll(csmallint)) from alltypesorc
 PREHOOK: type: QUERY
 PREHOOK: Input: default@alltypesorc
@@ -42,7 +42,7 @@ POSTHOOK: query: select hex(compute_bit_vector_hll(cfloat)) from alltypesorc
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alltypesorc
 #### A masked pattern was here ####
-484C4CA483010000000000000000360000000000000010000001210000041332000100200020000400000000000000000000000000200000000000000000000000000000020000000000000000000022000000000000000000000000000000001000000000000100000000000010000000000000500000020000000000200001000000000000100000003000000001000000010000010040000000000000000000000102000013000001000000001000030000000200000000000010000000000000000000000000020001000002000000011000000000002000000300400000100090000000001000000000000101002000200020000010001000000100030101000003000000000200060000000300100000000000000001000000030000000001100000010001000000000000001000000000001000000010000000000100000000040000000000000000300000002002000001000000000200000000000000020000000000000000100000002000000000201000100000000000000000020000000000000102100000000201000000000010000000000000000004000010002000000100000000000010000000000000000000040010000000000000000020000040000000000020000000300000001000000000000100002000000000000100001001000000100030000000010000300010010000000000000300000000000020200000
+484C4CA08301830182D2E9C906C1B6A8D6F9FFFFFFFF0183FCEFE003FCC4F6AF02BFA7B5A1FDFFFFFFFF0181D99CE502FFBFCBD1F9FFFFFFFF018193F24CC0FC9FF8FFFFFFFFFF01BF8EB545C2F8F3A304FEF2D2BEFBFFFFFFFF0180F4C2B003C1C181C20282F4BAD2FEFFFFFFFF01FDA3AA9C02C0FF9EFEFFFFFFFFFF01C2A7C3EAFCFFFFFFFF01BFF1EAC2FEFFFFFFFF0181FFD68104FFB5D7CBFEFFFFFFFF01FF95DCA7FDFFFFFFFF018087D8CAFFFFFFFFFF0181FC8B2C82F6989502BEB0F7C50281F6F918FEF8AB9EFEFFFFFFFF01C099DEAAFDFFFFFFFF01808397F3FFFFFFFFFF0180A6F964C1B4ADA9FEFFFFFFFF01BFC8C9C303C1FEB5FAFFFFFFFFFF01FFFC90FFFFFFFFFFFF018091F2C3FEFFFFFFFF018086A8FEFBFFFFFFFF01809DFFF30680D080C3FEFFFFFFFF0180F1A8BEFBFFFFFFFF01C0F3A7FAFFFFFFFFFF01C08FE545C387E49904BFAEB2C001FFB6D9A1FFFFFFFFFF01C0899FCCFAFFFFFFFF01FFF3FAB001818795EC02FFB6DBD8FAFFFFFFFF0181CAF3AD05BFEDF439C3BF84EBFAFFFFFFFF01FDB882FB05C0F9F9E9FFFFFFFFFF01C0C1E586FAFFFFFFFF01C3B39CAF02FE938AE7FFFFFFFFFF01BF8384EBFFFFFFFFFF01C4FF90FA03FCC6E4DCF9FFFFFFFF01C2C0EEFA05BFF6F5A1FCFFFFFFFF01BF9CB3F1FEFFFFFFFF018099F1A203C1DADDB601C0868EDBFBFFFFFFFF018294C9A9FFFFFFFFFF01BDCDB4C405C0F6F7ABFCFFFFFFFF0180C184D703C19ED78301BFAE84B7F9FFFFFFFF0182C2C1FA0183DECE8C03BCBADBF1FDFFFFFFFF01818498EBFBFFFFFFFF01FED1DBE80288C3B2F5FDFFFFFFFF01BABC8E9606BE9CBDF8FCFFFFFFFF01C1E8FBDB02C1FBA601FFFA9714C0AAB05A81D8F9DBFAFFFFFFFF01FEFDF1F8FFFFFFFFFF01C0F58950C1B8EBF301BFA4ABF0FCFFFFFFFF01C0ECC9CCFEFFFFFFFF0180C8E79F0681D6D2E2FEFFFFFFFF01FFA0BD90FDFFFFFFFF01C08DFFB40180CEF9FCFDFFFFFFFF0181FCDAE4FFFFFFFFFF0180FEC08904BFE6E38CFBFFFFFFFF0180D0B8A905C092A8B8FDFFFFFFFF01809AA0F601C0868895FCFFFFFFFF01C0A1968A0381BCBAE501C1A6F9A8FBFFFFFFFF01C0AEBFA201FED59CF8FEFFFFFFFF0183B7B3E301BDFBB3BB0381C7B5CFFAFFFFFFFF01C0A3EE8603C0E4F16D82C6B567BFC9D3A6FEFFFFFFFF01FEC7DAA00180CDBEBDFDFFFFFFFF0180ED9AB8FDFFFFFFFF0180EDAC3AC2A3DDE902FE91C3C103C1DDF584F9FFFFFFFF01FFB7948B0281FA8826FFC4CEDE01C0FAD01CC0CABEB1FDFFFFFFFF01C0D087C10181D29CD601FF9BCB88FBFFFFFFFF01C09AC98B0380C5B8ECFDFFFFFFFF01
 PREHOOK: query: select hex(compute_bit_vector_hll(cdouble)) from alltypesorc
 PREHOOK: type: QUERY
 PREHOOK: Input: default@alltypesorc
@@ -78,7 +78,7 @@ POSTHOOK: query: select hex(compute_bit_vector_hll(ctimestamp1)) from alltypesor
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alltypesorc
 #### A masked pattern was here ####
-484C4CA4230000000000000000000000000000000000003000000000000000130000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000010010000000000000000000000000000000000000000000000000000000000000050000000000002000000000000000000000000000000000000000000200000000000000000000000000000000000000000003000000000090000000020070000000001000000000300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000300000000000000000000000000200000000000000000000010000000000000000000002000000000000000000000000000000000010000000000000000020000000000000000000000000000000000010000000000000000000000000000000000000000000000000000100000000000000020000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000200000000000000000000000000000000000000000000000000000001000000000000000006000000000000000000000000020000000000000003000000000000002000000000000000000000040000010000000000100000000000000000000000
+484C4CA02323C4EBE3AC07BED5A5DEFDFFFFFFFF01C581F88E02BAB1CEA6FCFFFFFFFF0181969AF4FCFFFFFFFF01C0C6D1AD048188B8E1FCFFFFFFFF018093C0C701FECEB3C1FFFFFFFFFF0188829A8BFFFFFFFFFF01F8B18EB30380B2D4A802C0C3A0F0FDFFFFFFFF0180838201C1D3A3ADFFFFFFFFFF01C0A591E8FFFFFFFFFF01BFECFA52C1A2A4EBFCFFFFFFFF01BFD8AAE10585FCFDF0FEFFFFFFFF01BCDDA50383E497F7FBFFFFFFFF01FEB190BF0380DB9E8EFEFFFFFFFF01FE82DEFBFFFFFFFFFF01C189FD8903FFC689D8F9FFFFFFFF0180CCF1BB0582E9A9DAFEFFFFFFFF01BF85DAE8FEFFFFFFFF01C1DC87AD03BE9DDA82FEFFFFFFFF01C0B0D0B1FEFFFFFFFF0182829578FFBEF78903
 PREHOOK: query: select hex(compute_bit_vector_hll(cast (ctimestamp2 as date))) from alltypesorc
 PREHOOK: type: QUERY
 PREHOOK: Input: default@alltypesorc
@@ -87,7 +87,7 @@ POSTHOOK: query: select hex(compute_bit_vector_hll(cast (ctimestamp2 as date)))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alltypesorc
 #### A masked pattern was here ####
-484C4CA301000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000C00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
+484C4CA0010186EC80C501
 PREHOOK: query: create table test_compute_bit_vector (val1 string, val2 string)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
diff --git a/ql/src/test/results/clientpositive/llap/compute_stats_date.q.out b/ql/src/test/results/clientpositive/llap/compute_stats_date.q.out
index f28c21c9f1..b33be22d85 100644
--- a/ql/src/test/results/clientpositive/llap/compute_stats_date.q.out
+++ b/ql/src/test/results/clientpositive/llap/compute_stats_date.q.out
@@ -43,7 +43,7 @@ POSTHOOK: query: select compute_stats(fl_date, 'hll') from tab_date
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tab_date
 #### A masked pattern was here ####
-{"columntype":"Date","min":"2000-11-20","max":"2010-10-29","countnulls":0,"numdistinctvalues":19,"ndvbitvector":HLL�Ǫ����!���]����������������Y���T���P��R������W����ĈN������������}
+{"columntype":"Date","min":"2000-11-20","max":"2010-10-29","countnulls":0,"numdistinctvalues":19,"ndvbitvector":HLL������������t������������������������R��ո��������������Y������������������������������������������������犞}
 PREHOOK: query: explain
 analyze table tab_date compute statistics for columns fl_date
 PREHOOK: type: ANALYZE_TABLE
diff --git a/ql/src/test/results/clientpositive/llap/confirm_initial_tbl_stats.q.out b/ql/src/test/results/clientpositive/llap/confirm_initial_tbl_stats.q.out
index cdd934c2fd..a51f25814d 100644
--- a/ql/src/test/results/clientpositive/llap/confirm_initial_tbl_stats.q.out
+++ b/ql/src/test/results/clientpositive/llap/confirm_initial_tbl_stats.q.out
@@ -237,7 +237,7 @@ data_type           	tinyint
 min                 	-64                 
 max                 	62                  
 num_nulls           	3115                
-distinct_count      	130                 
+distinct_count      	127                 
 avg_col_len         	                    
 max_col_len         	                    
 num_trues           	                    
diff --git a/ql/src/test/results/clientpositive/llap/constraints_explain_ddl.q.out b/ql/src/test/results/clientpositive/llap/constraints_explain_ddl.q.out
index cdce79afe9..c38adaa87a 100644
--- a/ql/src/test/results/clientpositive/llap/constraints_explain_ddl.q.out
+++ b/ql/src/test/results/clientpositive/llap/constraints_explain_ddl.q.out
@@ -932,7 +932,7 @@ ALTER TABLE default.dates_removal_n0 UPDATE STATISTICS FOR COLUMN d_dayofweek SE
 ALTER TABLE default.dates_removal_n0 UPDATE STATISTICS FOR COLUMN d_holidayfl SET('lowValue'='0','highValue'='0','numNulls'='2','numDVs'='1' );
 -- BIT VECTORS PRESENT FOR default.dates_removal_n0 FOR COLUMN d_holidayfl BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAEA 
 ALTER TABLE default.dates_removal_n0 UPDATE STATISTICS FOR COLUMN d_id SET('lowValue'='0','highValue'='1','numNulls'='0','numDVs'='2' );
--- BIT VECTORS PRESENT FOR default.dates_removal_n0 FOR COLUMN d_id BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAICwdOOGICgsDA= 
+-- BIT VECTORS PRESENT FOR default.dates_removal_n0 FOR COLUMN d_id BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAICwfO+SIDgz8///////wE= 
 ALTER TABLE default.dates_removal_n0 UPDATE STATISTICS FOR COLUMN d_lastdayinmonthfl SET('lowValue'='0','highValue'='0','numNulls'='2','numDVs'='1' );
 -- BIT VECTORS PRESENT FOR default.dates_removal_n0 FOR COLUMN d_lastdayinmonthfl BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAEA 
 ALTER TABLE default.dates_removal_n0 UPDATE STATISTICS FOR COLUMN d_lastdayinweekfl SET('lowValue'='0','highValue'='0','numNulls'='2','numDVs'='1' );
@@ -1124,7 +1124,7 @@ ALTER TABLE default.dates_removal_n0 UPDATE STATISTICS FOR COLUMN d_dayofweek SE
 ALTER TABLE default.dates_removal_n0 UPDATE STATISTICS FOR COLUMN d_holidayfl SET('lowValue'='0','highValue'='0','numNulls'='2','numDVs'='1' );
 -- BIT VECTORS PRESENT FOR default.dates_removal_n0 FOR COLUMN d_holidayfl BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAEA 
 ALTER TABLE default.dates_removal_n0 UPDATE STATISTICS FOR COLUMN d_id SET('lowValue'='0','highValue'='1','numNulls'='0','numDVs'='2' );
--- BIT VECTORS PRESENT FOR default.dates_removal_n0 FOR COLUMN d_id BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAICwdOOGICgsDA= 
+-- BIT VECTORS PRESENT FOR default.dates_removal_n0 FOR COLUMN d_id BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAICwfO+SIDgz8///////wE= 
 ALTER TABLE default.dates_removal_n0 UPDATE STATISTICS FOR COLUMN d_lastdayinmonthfl SET('lowValue'='0','highValue'='0','numNulls'='2','numDVs'='1' );
 -- BIT VECTORS PRESENT FOR default.dates_removal_n0 FOR COLUMN d_lastdayinmonthfl BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAEA 
 ALTER TABLE default.dates_removal_n0 UPDATE STATISTICS FOR COLUMN d_lastdayinweekfl SET('lowValue'='0','highValue'='0','numNulls'='2','numDVs'='1' );
@@ -1499,9 +1499,9 @@ TBLPROPERTIES (
 ALTER TABLE default.dest_g21 ADD CONSTRAINT #### A masked pattern was here #### PRIMARY KEY (key1) DISABLE NOVALIDATE;
 ALTER TABLE default.dest_g21 UPDATE STATISTICS SET('numRows'='6','rawDataSize'='28' );
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN key1 SET('lowValue'='1','highValue'='6','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwpn6L//ZxBjBu6xiguL3TL2SiwGD3vHAAg== 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwfO+SIGmu+f//////wHC9+jHAf6diLP//////wG/9IJOg97xwAI= 
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN value1 SET('numNulls'='2','numDVs'='3','highValue'='4.0','lowValue'='1.0' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwP/4PQQgsbBowI= 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwOBp7a0Av65vtz9/////wE= 
 
 
 
@@ -1563,9 +1563,9 @@ TBLPROPERTIES (
 ALTER TABLE default.dest_g21 ADD CONSTRAINT #### A masked pattern was here #### PRIMARY KEY (key1) DISABLE NOVALIDATE;
 ALTER TABLE default.dest_g21 UPDATE STATISTICS SET('numRows'='6','rawDataSize'='28' );
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN key1 SET('lowValue'='1','highValue'='6','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwpn6L//ZxBjBu6xiguL3TL2SiwGD3vHAAg== 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwfO+SIGmu+f//////wHC9+jHAf6diLP//////wG/9IJOg97xwAI= 
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN value1 SET('numNulls'='2','numDVs'='3','highValue'='4.0','lowValue'='1.0' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwP/4PQQgsbBowI= 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwOBp7a0Av65vtz9/////wE= 
 
 
 
@@ -1628,9 +1628,9 @@ TBLPROPERTIES (
 ALTER TABLE default.dest_g21 ADD CONSTRAINT #### A masked pattern was here #### PRIMARY KEY (key1) DISABLE NOVALIDATE;
 ALTER TABLE default.dest_g21 UPDATE STATISTICS SET('numRows'='6','rawDataSize'='28' );
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN key1 SET('lowValue'='1','highValue'='6','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwpn6L//ZxBjBu6xiguL3TL2SiwGD3vHAAg== 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwfO+SIGmu+f//////wHC9+jHAf6diLP//////wG/9IJOg97xwAI= 
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN value1 SET('numNulls'='2','numDVs'='3','highValue'='4.0','lowValue'='1.0' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwP/4PQQgsbBowI= 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwOBp7a0Av65vtz9/////wE= 
 
 
 
@@ -1693,9 +1693,9 @@ TBLPROPERTIES (
 ALTER TABLE default.dest_g21 ADD CONSTRAINT #### A masked pattern was here #### PRIMARY KEY (key1) DISABLE NOVALIDATE;
 ALTER TABLE default.dest_g21 UPDATE STATISTICS SET('numRows'='6','rawDataSize'='28' );
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN key1 SET('lowValue'='1','highValue'='6','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwpn6L//ZxBjBu6xiguL3TL2SiwGD3vHAAg== 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwfO+SIGmu+f//////wHC9+jHAf6diLP//////wG/9IJOg97xwAI= 
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN value1 SET('numNulls'='2','numDVs'='3','highValue'='4.0','lowValue'='1.0' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwP/4PQQgsbBowI= 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwOBp7a0Av65vtz9/////wE= 
 
 
 
@@ -1822,9 +1822,9 @@ TBLPROPERTIES (
 ALTER TABLE default.dest_g21 ADD CONSTRAINT #### A masked pattern was here #### PRIMARY KEY (key1) DISABLE NOVALIDATE;
 ALTER TABLE default.dest_g21 UPDATE STATISTICS SET('numRows'='6','rawDataSize'='28' );
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN key1 SET('lowValue'='1','highValue'='6','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwpn6L//ZxBjBu6xiguL3TL2SiwGD3vHAAg== 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwfO+SIGmu+f//////wHC9+jHAf6diLP//////wG/9IJOg97xwAI= 
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN value1 SET('numNulls'='2','numDVs'='3','highValue'='4.0','lowValue'='1.0' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwP/4PQQgsbBowI= 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwOBp7a0Av65vtz9/////wE= 
 
 
 
@@ -1953,9 +1953,9 @@ TBLPROPERTIES (
 ALTER TABLE default.dest_g21 ADD CONSTRAINT #### A masked pattern was here #### PRIMARY KEY (key1) DISABLE NOVALIDATE;
 ALTER TABLE default.dest_g21 UPDATE STATISTICS SET('numRows'='6','rawDataSize'='28' );
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN key1 SET('lowValue'='1','highValue'='6','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwpn6L//ZxBjBu6xiguL3TL2SiwGD3vHAAg== 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwfO+SIGmu+f//////wHC9+jHAf6diLP//////wG/9IJOg97xwAI= 
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN value1 SET('numNulls'='2','numDVs'='3','highValue'='4.0','lowValue'='1.0' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwP/4PQQgsbBowI= 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwOBp7a0Av65vtz9/////wE= 
 
 
 
@@ -2103,9 +2103,9 @@ TBLPROPERTIES (
 ALTER TABLE default.dest_g21 ADD CONSTRAINT #### A masked pattern was here #### PRIMARY KEY (key1) DISABLE NOVALIDATE;
 ALTER TABLE default.dest_g21 UPDATE STATISTICS SET('numRows'='6','rawDataSize'='28' );
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN key1 SET('lowValue'='1','highValue'='6','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwpn6L//ZxBjBu6xiguL3TL2SiwGD3vHAAg== 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwfO+SIGmu+f//////wHC9+jHAf6diLP//////wG/9IJOg97xwAI= 
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN value1 SET('numNulls'='2','numDVs'='3','highValue'='4.0','lowValue'='1.0' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwP/4PQQgsbBowI= 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwOBp7a0Av65vtz9/////wE= 
 
 
 
@@ -2285,9 +2285,9 @@ TBLPROPERTIES (
 ALTER TABLE default.dest_g21 ADD CONSTRAINT #### A masked pattern was here #### PRIMARY KEY (key1) DISABLE NOVALIDATE;
 ALTER TABLE default.dest_g21 UPDATE STATISTICS SET('numRows'='6','rawDataSize'='28' );
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN key1 SET('lowValue'='1','highValue'='6','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwpn6L//ZxBjBu6xiguL3TL2SiwGD3vHAAg== 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwfO+SIGmu+f//////wHC9+jHAf6diLP//////wG/9IJOg97xwAI= 
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN value1 SET('numNulls'='2','numDVs'='3','highValue'='4.0','lowValue'='1.0' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwP/4PQQgsbBowI= 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwOBp7a0Av65vtz9/////wE= 
 
 
 
@@ -2353,9 +2353,9 @@ TBLPROPERTIES (
 ALTER TABLE default.dest_g21 ADD CONSTRAINT #### A masked pattern was here #### PRIMARY KEY (key1) DISABLE NOVALIDATE;
 ALTER TABLE default.dest_g21 UPDATE STATISTICS SET('numRows'='6','rawDataSize'='28' );
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN key1 SET('lowValue'='1','highValue'='6','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwpn6L//ZxBjBu6xiguL3TL2SiwGD3vHAAg== 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN key1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwfO+SIGmu+f//////wHC9+jHAf6diLP//////wG/9IJOg97xwAI= 
 ALTER TABLE default.dest_g21 UPDATE STATISTICS FOR COLUMN value1 SET('numNulls'='2','numDVs'='3','highValue'='4.0','lowValue'='1.0' );
--- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwP/4PQQgsbBowI= 
+-- BIT VECTORS PRESENT FOR default.dest_g21 FOR COLUMN value1 BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwvmagwOBp7a0Av65vtz9/////wE= 
 
 
 
@@ -2510,7 +2510,7 @@ TBLPROPERTIES (
 ALTER TABLE default.tconst UPDATE STATISTICS SET('numRows'='3','rawDataSize'='25' );
 ALTER TABLE default.tconst CHANGE COLUMN i i int CONSTRAINT #### A masked pattern was here #### NOT NULL DISABLE;
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN d_year SET('avgColLen'='4.0','maxColLen'='4','numNulls'='0','numDVs'='3' );
--- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN d_year BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwpepZP/f7ASBwcWJBg== 
+-- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN d_year BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwrjb8gb/vrr2+f////8BgaCT+///////AQ== 
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN i SET('lowValue'='1','highValue'='3','numNulls'='0','numDVs'='3' );
 -- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN i BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwfO+SMG7rGLC0vSOAw== 
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN j SET('lowValue'='1','highValue'='3','numNulls'='1','numDVs'='2' );
@@ -2639,7 +2639,7 @@ TBLPROPERTIES (
 ALTER TABLE default.tconst UPDATE STATISTICS SET('numRows'='3','rawDataSize'='25' );
 ALTER TABLE default.tconst CHANGE COLUMN i i int CONSTRAINT #### A masked pattern was here #### NOT NULL DISABLE;
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN d_year SET('avgColLen'='4.0','maxColLen'='4','numNulls'='0','numDVs'='3' );
--- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN d_year BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwpepZP/f7ASBwcWJBg== 
+-- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN d_year BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwrjb8gb/vrr2+f////8BgaCT+///////AQ== 
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN i SET('lowValue'='1','highValue'='3','numNulls'='0','numDVs'='3' );
 -- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN i BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwfO+SMG7rGLC0vSOAw== 
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN j SET('lowValue'='1','highValue'='3','numNulls'='1','numDVs'='2' );
@@ -2769,7 +2769,7 @@ TBLPROPERTIES (
 ALTER TABLE default.tconst UPDATE STATISTICS SET('numRows'='3','rawDataSize'='25' );
 ALTER TABLE default.tconst CHANGE COLUMN i i int CONSTRAINT #### A masked pattern was here #### NOT NULL DISABLE;
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN d_year SET('avgColLen'='4.0','maxColLen'='4','numNulls'='0','numDVs'='3' );
--- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN d_year BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwpepZP/f7ASBwcWJBg== 
+-- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN d_year BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwrjb8gb/vrr2+f////8BgaCT+///////AQ== 
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN i SET('lowValue'='1','highValue'='3','numNulls'='0','numDVs'='3' );
 -- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN i BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwfO+SMG7rGLC0vSOAw== 
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN j SET('lowValue'='1','highValue'='3','numNulls'='1','numDVs'='2' );
@@ -2898,7 +2898,7 @@ TBLPROPERTIES (
 ALTER TABLE default.tconst UPDATE STATISTICS SET('numRows'='3','rawDataSize'='25' );
 ALTER TABLE default.tconst CHANGE COLUMN i i int CONSTRAINT #### A masked pattern was here #### NOT NULL DISABLE;
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN d_year SET('avgColLen'='4.0','maxColLen'='4','numNulls'='0','numDVs'='3' );
--- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN d_year BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwpepZP/f7ASBwcWJBg== 
+-- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN d_year BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwrjb8gb/vrr2+f////8BgaCT+///////AQ== 
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN i SET('lowValue'='1','highValue'='3','numNulls'='0','numDVs'='3' );
 -- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN i BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwfO+SMG7rGLC0vSOAw== 
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN j SET('lowValue'='1','highValue'='3','numNulls'='1','numDVs'='2' );
@@ -3087,7 +3087,7 @@ TBLPROPERTIES (
 ALTER TABLE default.tconst UPDATE STATISTICS SET('numRows'='3','rawDataSize'='25' );
 ALTER TABLE default.tconst CHANGE COLUMN i i int CONSTRAINT #### A masked pattern was here #### NOT NULL DISABLE;
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN d_year SET('avgColLen'='4.0','maxColLen'='4','numNulls'='0','numDVs'='3' );
--- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN d_year BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwpepZP/f7ASBwcWJBg== 
+-- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN d_year BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwrjb8gb/vrr2+f////8BgaCT+///////AQ== 
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN i SET('lowValue'='1','highValue'='3','numNulls'='0','numDVs'='3' );
 -- BIT VECTORS PRESENT FOR default.tconst FOR COLUMN i BUT THEY ARE NOT SUPPORTED YET. THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAMDwfO+SMG7rGLC0vSOAw== 
 ALTER TABLE default.tconst UPDATE STATISTICS FOR COLUMN j SET('lowValue'='1','highValue'='3','numNulls'='1','numDVs'='2' );
diff --git a/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_2.q.out b/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_2.q.out
index 828f32464b..b74787e35e 100644
--- a/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_2.q.out
+++ b/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_2.q.out
@@ -538,13 +538,13 @@ STAGE PLANS:
                       minReductionHashAggr: 0.4
                       mode: hash
                       outputColumnNames: _col0, _col1
-                      Statistics: Num rows: 146 Data size: 27448 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 153 Data size: 28764 Basic stats: COMPLETE Column stats: COMPLETE
                       Reduce Output Operator
                         key expressions: _col0 (type: int)
                         null sort order: z
                         sort order: +
                         Map-reduce partition columns: _col0 (type: int)
-                        Statistics: Num rows: 146 Data size: 27448 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 153 Data size: 28764 Basic stats: COMPLETE Column stats: COMPLETE
                         value expressions: _col1 (type: string)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -562,13 +562,13 @@ STAGE PLANS:
                       minReductionHashAggr: 0.4
                       mode: hash
                       outputColumnNames: _col0
-                      Statistics: Num rows: 146 Data size: 584 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 153 Data size: 612 Basic stats: COMPLETE Column stats: COMPLETE
                       Reduce Output Operator
                         key expressions: _col0 (type: int)
                         null sort order: z
                         sort order: +
                         Map-reduce partition columns: _col0 (type: int)
-                        Statistics: Num rows: 146 Data size: 584 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 153 Data size: 612 Basic stats: COMPLETE Column stats: COMPLETE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 8 
@@ -598,7 +598,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: int)
                 mode: mergepartial
                 outputColumnNames: _col0
-                Statistics: Num rows: 146 Data size: 584 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 153 Data size: 612 Basic stats: COMPLETE Column stats: COMPLETE
                 Dummy Store
             Execution mode: llap
             Reduce Operator Tree:
@@ -607,10 +607,10 @@ STAGE PLANS:
                 keys: KEY._col0 (type: int)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 146 Data size: 27448 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 153 Data size: 28764 Basic stats: COMPLETE Column stats: COMPLETE
                 Filter Operator
                   predicate: _col1 is not null (type: boolean)
-                  Statistics: Num rows: 146 Data size: 27448 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 153 Data size: 28764 Basic stats: COMPLETE Column stats: COMPLETE
                   Merge Join Operator
                     condition map:
                          Inner Join 0 to 1
@@ -618,19 +618,19 @@ STAGE PLANS:
                       0 _col0 (type: int)
                       1 _col0 (type: int)
                     outputColumnNames: _col1
-                    Statistics: Num rows: 146 Data size: 26864 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 153 Data size: 28152 Basic stats: COMPLETE Column stats: COMPLETE
                     Reduce Output Operator
                       key expressions: _col1 (type: string)
                       null sort order: z
                       sort order: +
                       Map-reduce partition columns: _col1 (type: string)
-                      Statistics: Num rows: 146 Data size: 26864 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 153 Data size: 28152 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col1 (type: string)
                       outputColumnNames: _col1
-                      Statistics: Num rows: 146 Data size: 26864 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 153 Data size: 28152 Basic stats: COMPLETE Column stats: COMPLETE
                       Group By Operator
-                        aggregations: min(_col1), max(_col1), bloom_filter(_col1, expectedEntries=146)
+                        aggregations: min(_col1), max(_col1), bloom_filter(_col1, expectedEntries=153)
                         minReductionHashAggr: 0.99
                         mode: hash
                         outputColumnNames: _col0, _col1, _col2
@@ -680,7 +680,7 @@ STAGE PLANS:
             Execution mode: vectorized, llap
             Reduce Operator Tree:
               Group By Operator
-                aggregations: min(VALUE._col0), max(VALUE._col1), bloom_filter(VALUE._col2, expectedEntries=146)
+                aggregations: min(VALUE._col0), max(VALUE._col1), bloom_filter(VALUE._col2, expectedEntries=153)
                 mode: final
                 outputColumnNames: _col0, _col1, _col2
                 Statistics: Num rows: 1 Data size: 552 Basic stats: COMPLETE Column stats: COMPLETE
diff --git a/ql/src/test/results/clientpositive/llap/estimate_pkfk_fknulls.q.out b/ql/src/test/results/clientpositive/llap/estimate_pkfk_fknulls.q.out
index 8aef47bef5..28f104111f 100644
--- a/ql/src/test/results/clientpositive/llap/estimate_pkfk_fknulls.q.out
+++ b/ql/src/test/results/clientpositive/llap/estimate_pkfk_fknulls.q.out
@@ -91,7 +91,7 @@ data_type           	bigint
 min                 	1                   
 max                 	70                  
 num_nulls           	72                  
-distinct_count      	73                  
+distinct_count      	70                  
 avg_col_len         	                    
 max_col_len         	                    
 num_trues           	                    
@@ -120,7 +120,7 @@ data_type           	bigint
 min                 	1                   
 max                 	70                  
 num_nulls           	72                  
-distinct_count      	73                  
+distinct_count      	70                  
 avg_col_len         	                    
 max_col_len         	                    
 num_trues           	                    
diff --git a/ql/src/test/results/clientpositive/llap/explainanalyze_2.q.out b/ql/src/test/results/clientpositive/llap/explainanalyze_2.q.out
index 9bdfa8caea..4ca869cd77 100644
--- a/ql/src/test/results/clientpositive/llap/explainanalyze_2.q.out
+++ b/ql/src/test/results/clientpositive/llap/explainanalyze_2.q.out
@@ -627,7 +627,7 @@ Stage-0
     Stage-1
       Map 1 llap
       File Output Operator [FS_10]
-        Merge Join Operator [MERGEJOIN_25] (rows=401/480 width=95)
+        Merge Join Operator [MERGEJOIN_25] (rows=382/480 width=95)
           Conds:SEL_2._col0=DUMMY_STORE_26._col0(Inner),Output:["_col0","_col1"]
         <-Dummy Store [DUMMY_STORE_26]
             Select Operator [SEL_5] (rows=242/242 width=4)
@@ -669,47 +669,42 @@ Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
-Reducer 3 <- Map 1 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
 
 Stage-0
   Fetch Operator
     limit:-1
     Stage-1
-      Reducer 3 llap
+      Reducer 2 llap
       File Output Operator [FS_16]
-        Merge Join Operator [MERGEJOIN_46] (rows=633/1166 width=95)
-          Conds:RS_12._col0=RS_13._col0(Inner),Output:["_col0","_col1"]
+        Merge Join Operator [MERGEJOIN_47] (rows=604/1166 width=95)
+          Conds:RS_12._col1=RS_13._col0(Inner),Output:["_col0","_col1"]
         <-Map 1 [SIMPLE_EDGE] llap
-          SHUFFLE [RS_13]
-            PartitionCols:_col0
-            Select Operator [SEL_8] (rows=242/242 width=4)
-              Output:["_col0"]
-              Filter Operator [FIL_24] (rows=242/242 width=4)
-                predicate:key is not null
-                TableScan [TS_0] (rows=242/242 width=95)
-                  default@tab_n6,s1,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
-        <-Reducer 2 [SIMPLE_EDGE] llap
           SHUFFLE [RS_12]
-            PartitionCols:_col0
+            PartitionCols:_col1
             Merge Join Operator [MERGEJOIN_45] (rows=382/480 width=95)
-              Conds:RS_9._col1=RS_10._col0(Inner),Output:["_col0","_col1"]
-            <-Map 1 [SIMPLE_EDGE] llap
-              SHUFFLE [RS_9]
-                PartitionCols:_col1
-                Select Operator [SEL_2] (rows=242/242 width=95)
-                  Output:["_col0","_col1"]
-                  Filter Operator [FIL_22] (rows=242/242 width=95)
-                    predicate:(key is not null and value is not null)
-                     Please refer to the previous TableScan [TS_0]
-            <-Map 4 [SIMPLE_EDGE] llap
-              SHUFFLE [RS_10]
-                PartitionCols:_col0
-                Select Operator [SEL_5] (rows=242/242 width=91)
+              Conds:SEL_2._col0=DUMMY_STORE_46._col0(Inner),Output:["_col0","_col1"]
+            <-Dummy Store [DUMMY_STORE_46]
+                Select Operator [SEL_5] (rows=242/242 width=4)
                   Output:["_col0"]
-                  Filter Operator [FIL_23] (rows=242/242 width=91)
-                    predicate:value is not null
-                    TableScan [TS_3] (rows=242/242 width=91)
-                      default@tab_n6,s2,Tbl:COMPLETE,Col:COMPLETE,Output:["value"]
+                  Filter Operator [FIL_23] (rows=242/242 width=4)
+                    predicate:key is not null
+                    TableScan [TS_3] (rows=242/242 width=4)
+                      default@tab_n6,s3,Tbl:COMPLETE,Col:COMPLETE,Output:["key"]
+            <-Select Operator [SEL_2] (rows=242/242 width=95)
+                Output:["_col0","_col1"]
+                Filter Operator [FIL_22] (rows=242/242 width=95)
+                  predicate:(key is not null and value is not null)
+                  TableScan [TS_0] (rows=242/242 width=95)
+                    default@tab_n6,s1,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
+        <-Map 4 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_13]
+            PartitionCols:_col0
+            Select Operator [SEL_8] (rows=242/242 width=91)
+              Output:["_col0"]
+              Filter Operator [FIL_24] (rows=242/242 width=91)
+                predicate:value is not null
+                TableScan [TS_6] (rows=242/242 width=91)
+                  default@tab_n6,s2,Tbl:COMPLETE,Col:COMPLETE,Output:["value"]
 
 PREHOOK: query: select s1.key as key, s1.value as value from tab_n6 s1 join tab2_n3 s3 on s1.key=s3.key
 PREHOOK: type: QUERY
@@ -749,7 +744,7 @@ Stage-0
     Stage-1
       Map 1 llap
       File Output Operator [FS_10]
-        Merge Join Operator [MERGEJOIN_25] (rows=401/480 width=95)
+        Merge Join Operator [MERGEJOIN_25] (rows=382/480 width=95)
           Conds:SEL_2._col0=DUMMY_STORE_26._col0(Inner),Output:["_col0","_col1"]
         <-Dummy Store [DUMMY_STORE_26]
             Select Operator [SEL_5] (rows=242/242 width=4)
@@ -799,47 +794,42 @@ Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
-Reducer 3 <- Map 4 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
 
 Stage-0
   Fetch Operator
     limit:-1
     Stage-1
-      Reducer 3 llap
+      Reducer 2 llap
       File Output Operator [FS_16]
-        Merge Join Operator [MERGEJOIN_46] (rows=633/1166 width=95)
-          Conds:RS_12._col0=RS_13._col0(Inner),Output:["_col0","_col1"]
+        Merge Join Operator [MERGEJOIN_47] (rows=604/1166 width=95)
+          Conds:RS_12._col1=RS_13._col0(Inner),Output:["_col0","_col1"]
+        <-Map 1 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_12]
+            PartitionCols:_col1
+            Merge Join Operator [MERGEJOIN_45] (rows=382/480 width=95)
+              Conds:SEL_2._col0=DUMMY_STORE_46._col0(Inner),Output:["_col0","_col1"]
+            <-Dummy Store [DUMMY_STORE_46]
+                Select Operator [SEL_5] (rows=242/242 width=4)
+                  Output:["_col0"]
+                  Filter Operator [FIL_23] (rows=242/242 width=4)
+                    predicate:key is not null
+                    TableScan [TS_3] (rows=242/242 width=4)
+                      default@tab2_n3,s3,Tbl:COMPLETE,Col:COMPLETE,Output:["key"]
+            <-Select Operator [SEL_2] (rows=242/242 width=95)
+                Output:["_col0","_col1"]
+                Filter Operator [FIL_22] (rows=242/242 width=95)
+                  predicate:(key is not null and value is not null)
+                  TableScan [TS_0] (rows=242/242 width=95)
+                    default@tab_n6,s1,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
         <-Map 4 [SIMPLE_EDGE] llap
           SHUFFLE [RS_13]
             PartitionCols:_col0
-            Select Operator [SEL_8] (rows=242/242 width=4)
+            Select Operator [SEL_8] (rows=242/242 width=91)
               Output:["_col0"]
-              Filter Operator [FIL_24] (rows=242/242 width=4)
-                predicate:key is not null
-                TableScan [TS_3] (rows=242/242 width=91)
-                  default@tab2_n3,s2,Tbl:COMPLETE,Col:COMPLETE,Output:["value","key"]
-        <-Reducer 2 [SIMPLE_EDGE] llap
-          SHUFFLE [RS_12]
-            PartitionCols:_col0
-            Merge Join Operator [MERGEJOIN_45] (rows=382/480 width=95)
-              Conds:RS_9._col1=RS_10._col0(Inner),Output:["_col0","_col1"]
-            <-Map 4 [SIMPLE_EDGE] llap
-              SHUFFLE [RS_10]
-                PartitionCols:_col0
-                Select Operator [SEL_5] (rows=242/242 width=91)
-                  Output:["_col0"]
-                  Filter Operator [FIL_23] (rows=242/242 width=91)
-                    predicate:value is not null
-                     Please refer to the previous TableScan [TS_3]
-            <-Map 1 [SIMPLE_EDGE] llap
-              SHUFFLE [RS_9]
-                PartitionCols:_col1
-                Select Operator [SEL_2] (rows=242/242 width=95)
-                  Output:["_col0","_col1"]
-                  Filter Operator [FIL_22] (rows=242/242 width=95)
-                    predicate:(key is not null and value is not null)
-                    TableScan [TS_0] (rows=242/242 width=95)
-                      default@tab_n6,s1,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
+              Filter Operator [FIL_24] (rows=242/242 width=91)
+                predicate:value is not null
+                TableScan [TS_6] (rows=242/242 width=91)
+                  default@tab2_n3,s2,Tbl:COMPLETE,Col:COMPLETE,Output:["value"]
 
 PREHOOK: query: select count(*) from (select s1.key as key, s1.value as value from tab_n6 s1 join tab_n6 s3 on s1.key=s3.key
 UNION  ALL
@@ -901,7 +891,7 @@ Stage-0
           Output:["_col0"],aggregations:["count()"]
         <-Reducer 3 [CUSTOM_SIMPLE_EDGE] llap
           PARTITION_ONLY_SHUFFLE [RS_22]
-            Merge Join Operator [MERGEJOIN_60] (rows=1061/1646 width=8)
+            Merge Join Operator [MERGEJOIN_60] (rows=1029/1646 width=8)
               Conds:Union 2._col0=RS_19._col0(Inner)
             <-Map 7 [SIMPLE_EDGE] llap
               SHUFFLE [RS_19]
@@ -916,7 +906,7 @@ Stage-0
               <-Map 1 [CONTAINS] llap
                 Reduce Output Operator [RS_70]
                   PartitionCols:_col0
-                  Merge Join Operator [MERGEJOIN_67] (rows=401/480 width=4)
+                  Merge Join Operator [MERGEJOIN_67] (rows=382/480 width=4)
                     Conds:SEL_65._col0=DUMMY_STORE_59._col0(Inner),Output:["_col0"]
                   <-Dummy Store [DUMMY_STORE_59]
                       Select Operator [SEL_5] (rows=242/242 width=4)
@@ -986,24 +976,23 @@ POSTHOOK: Input: default@tab_part_n7@ds=2008-04-08
 Plan optimized by CBO.
 
 Vertex dependency in root stage
-Map 8 <- Union 4 (CONTAINS)
-Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 7 (SIMPLE_EDGE)
-Reducer 3 <- Map 1 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE), Union 4 (CONTAINS)
-Reducer 5 <- Map 9 (SIMPLE_EDGE), Union 4 (SIMPLE_EDGE)
-Reducer 6 <- Reducer 5 (CUSTOM_SIMPLE_EDGE)
+Map 8 <- Union 3 (CONTAINS)
+Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 7 (SIMPLE_EDGE), Union 3 (CONTAINS)
+Reducer 4 <- Map 9 (SIMPLE_EDGE), Union 3 (SIMPLE_EDGE)
+Reducer 5 <- Reducer 4 (CUSTOM_SIMPLE_EDGE)
 
 Stage-0
   Fetch Operator
     limit:-1
     Stage-1
-      Reducer 6 llap
+      Reducer 5 llap
       File Output Operator [FS_31]
         Group By Operator [GBY_29] (rows=1/1 width=8)
           Output:["_col0"],aggregations:["count()"]
-        <-Reducer 5 [CUSTOM_SIMPLE_EDGE] llap
+        <-Reducer 4 [CUSTOM_SIMPLE_EDGE] llap
           PARTITION_ONLY_SHUFFLE [RS_28]
-            Merge Join Operator [MERGEJOIN_81] (rows=1443/3768 width=8)
-              Conds:Union 4._col0=RS_25._col0(Inner)
+            Merge Join Operator [MERGEJOIN_82] (rows=1396/3768 width=8)
+              Conds:Union 3._col0=RS_25._col0(Inner)
             <-Map 9 [SIMPLE_EDGE] llap
               SHUFFLE [RS_25]
                 PartitionCols:_col0
@@ -1013,52 +1002,48 @@ Stage-0
                     predicate:key is not null
                     TableScan [TS_21] (rows=500/500 width=4)
                       default@tab_part_n7,b_n10,Tbl:COMPLETE,Col:COMPLETE,Output:["key"]
-            <-Union 4 [SIMPLE_EDGE]
+            <-Union 3 [SIMPLE_EDGE]
               <-Map 8 [CONTAINS] llap
-                Reduce Output Operator [RS_89]
+                Reduce Output Operator [RS_90]
                   PartitionCols:_col0
-                  Select Operator [SEL_87] (rows=242/242 width=4)
+                  Select Operator [SEL_88] (rows=242/242 width=4)
                     Output:["_col0"]
-                    Filter Operator [FIL_86] (rows=242/242 width=4)
+                    Filter Operator [FIL_87] (rows=242/242 width=4)
                       predicate:key is not null
-                      TableScan [TS_85] (rows=242/242 width=4)
+                      TableScan [TS_86] (rows=242/242 width=4)
                         default@tab_n6,s2,Tbl:COMPLETE,Col:COMPLETE,Output:["key"]
-              <-Reducer 3 [CONTAINS] llap
-                Reduce Output Operator [RS_84]
+              <-Reducer 2 [CONTAINS] llap
+                Reduce Output Operator [RS_85]
                   PartitionCols:_col0
-                  Merge Join Operator [MERGEJOIN_82] (rows=633/1166 width=4)
-                    Conds:RS_12._col0=RS_13._col0(Inner),Output:["_col0"]
+                  Merge Join Operator [MERGEJOIN_83] (rows=604/1166 width=4)
+                    Conds:RS_12._col1=RS_13._col0(Inner),Output:["_col0"]
                   <-Map 1 [SIMPLE_EDGE] llap
+                    SHUFFLE [RS_12]
+                      PartitionCols:_col1
+                      Merge Join Operator [MERGEJOIN_79] (rows=382/480 width=95)
+                        Conds:SEL_2._col0=DUMMY_STORE_80._col0(Inner),Output:["_col0","_col1"]
+                      <-Dummy Store [DUMMY_STORE_80]
+                          Select Operator [SEL_5] (rows=242/242 width=4)
+                            Output:["_col0"]
+                            Filter Operator [FIL_43] (rows=242/242 width=4)
+                              predicate:key is not null
+                              TableScan [TS_3] (rows=242/242 width=4)
+                                default@tab_n6,s3,Tbl:COMPLETE,Col:COMPLETE,Output:["key"]
+                      <-Select Operator [SEL_2] (rows=242/242 width=95)
+                          Output:["_col0","_col1"]
+                          Filter Operator [FIL_42] (rows=242/242 width=95)
+                            predicate:(key is not null and value is not null)
+                            TableScan [TS_0] (rows=242/242 width=95)
+                              default@tab_n6,s1,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
+                  <-Map 7 [SIMPLE_EDGE] llap
                     SHUFFLE [RS_13]
                       PartitionCols:_col0
-                      Select Operator [SEL_8] (rows=242/242 width=4)
+                      Select Operator [SEL_8] (rows=242/242 width=91)
                         Output:["_col0"]
-                        Filter Operator [FIL_44] (rows=242/242 width=4)
-                          predicate:key is not null
-                          TableScan [TS_0] (rows=242/242 width=95)
-                            default@tab_n6,s1,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
-                  <-Reducer 2 [SIMPLE_EDGE] llap
-                    SHUFFLE [RS_12]
-                      PartitionCols:_col0
-                      Merge Join Operator [MERGEJOIN_79] (rows=382/480 width=4)
-                        Conds:RS_9._col1=RS_10._col0(Inner),Output:["_col0"]
-                      <-Map 1 [SIMPLE_EDGE] llap
-                        SHUFFLE [RS_9]
-                          PartitionCols:_col1
-                          Select Operator [SEL_2] (rows=242/242 width=95)
-                            Output:["_col0","_col1"]
-                            Filter Operator [FIL_42] (rows=242/242 width=95)
-                              predicate:(key is not null and value is not null)
-                               Please refer to the previous TableScan [TS_0]
-                      <-Map 7 [SIMPLE_EDGE] llap
-                        SHUFFLE [RS_10]
-                          PartitionCols:_col0
-                          Select Operator [SEL_5] (rows=242/242 width=91)
-                            Output:["_col0"]
-                            Filter Operator [FIL_43] (rows=242/242 width=91)
-                              predicate:value is not null
-                              TableScan [TS_3] (rows=242/242 width=91)
-                                default@tab_n6,s2,Tbl:COMPLETE,Col:COMPLETE,Output:["value"]
+                        Filter Operator [FIL_44] (rows=242/242 width=91)
+                          predicate:value is not null
+                          TableScan [TS_6] (rows=242/242 width=91)
+                            default@tab_n6,s2,Tbl:COMPLETE,Col:COMPLETE,Output:["value"]
 
 PREHOOK: query: CREATE TABLE a_n14(key STRING, value STRING) STORED AS TEXTFILE
 PREHOOK: type: CREATETABLE
diff --git a/ql/src/test/results/clientpositive/llap/groupby_join_pushdown.q.out b/ql/src/test/results/clientpositive/llap/groupby_join_pushdown.q.out
index a67ac4a71f..1c3f4826cc 100644
--- a/ql/src/test/results/clientpositive/llap/groupby_join_pushdown.q.out
+++ b/ql/src/test/results/clientpositive/llap/groupby_join_pushdown.q.out
@@ -569,7 +569,7 @@ STAGE PLANS:
                 Group By Operator
                   aggregations: sum(_col2)
                   keys: _col0 (type: tinyint), _col3 (type: tinyint)
-                  minReductionHashAggr: 0.8912586
+                  minReductionHashAggr: 0.89495826
                   mode: hash
                   outputColumnNames: _col0, _col1, _col2
                   Statistics: Num rows: 6892 Data size: 100984 Basic stats: COMPLETE Column stats: COMPLETE
@@ -769,16 +769,16 @@ STAGE PLANS:
                       Group By Operator
                         aggregations: min(_col0)
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.98571897
+                        minReductionHashAggr: 0.986046
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 131 Data size: 920 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 920 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: tinyint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -797,16 +797,16 @@ STAGE PLANS:
                       Statistics: Num rows: 9173 Data size: 27396 Basic stats: COMPLETE Column stats: COMPLETE
                       Group By Operator
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.98571897
+                        minReductionHashAggr: 0.986046
                         mode: hash
                         outputColumnNames: _col0
-                        Statistics: Num rows: 131 Data size: 396 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 388 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 396 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 388 Basic stats: COMPLETE Column stats: COMPLETE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -815,7 +815,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0
-                Statistics: Num rows: 131 Data size: 396 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 388 Basic stats: COMPLETE Column stats: COMPLETE
                 Dummy Store
             Execution mode: llap
             Reduce Operator Tree:
@@ -824,7 +824,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 920 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE
                 Merge Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -832,14 +832,14 @@ STAGE PLANS:
                     0 _col0 (type: tinyint)
                     1 _col0 (type: tinyint)
                   outputColumnNames: _col0, _col1, _col2
-                  Statistics: Num rows: 132 Data size: 1328 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 129 Data size: 1300 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col0 (type: tinyint), _col2 (type: tinyint), _col1 (type: tinyint)
                     outputColumnNames: _col0, _col1, _col2
-                    Statistics: Num rows: 132 Data size: 1328 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 129 Data size: 1300 Basic stats: COMPLETE Column stats: COMPLETE
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 132 Data size: 1328 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 129 Data size: 1300 Basic stats: COMPLETE Column stats: COMPLETE
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -893,16 +893,16 @@ STAGE PLANS:
                       Group By Operator
                         aggregations: min(_col1)
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.98571897
+                        minReductionHashAggr: 0.986046
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 131 Data size: 920 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 920 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -921,16 +921,16 @@ STAGE PLANS:
                       Statistics: Num rows: 9173 Data size: 27396 Basic stats: COMPLETE Column stats: COMPLETE
                       Group By Operator
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.98571897
+                        minReductionHashAggr: 0.986046
                         mode: hash
                         outputColumnNames: _col0
-                        Statistics: Num rows: 131 Data size: 396 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 388 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 396 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 388 Basic stats: COMPLETE Column stats: COMPLETE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -939,7 +939,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0
-                Statistics: Num rows: 131 Data size: 396 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 388 Basic stats: COMPLETE Column stats: COMPLETE
                 Dummy Store
             Execution mode: llap
             Reduce Operator Tree:
@@ -948,7 +948,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 920 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE
                 Merge Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -956,14 +956,14 @@ STAGE PLANS:
                     0 _col0 (type: tinyint)
                     1 _col0 (type: tinyint)
                   outputColumnNames: _col1
-                  Statistics: Num rows: 132 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 129 Data size: 516 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col1 (type: int)
                     outputColumnNames: _col0
-                    Statistics: Num rows: 132 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 129 Data size: 516 Basic stats: COMPLETE Column stats: COMPLETE
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 132 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 129 Data size: 516 Basic stats: COMPLETE Column stats: COMPLETE
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1017,16 +1017,16 @@ STAGE PLANS:
                       Group By Operator
                         aggregations: count(_col0)
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.98571897
+                        minReductionHashAggr: 0.986046
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: bigint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -1046,16 +1046,16 @@ STAGE PLANS:
                       Group By Operator
                         aggregations: count()
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.98571897
+                        minReductionHashAggr: 0.986046
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: bigint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -1066,7 +1066,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                 Dummy Store
             Execution mode: llap
             Reduce Operator Tree:
@@ -1075,7 +1075,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                 Merge Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -1083,14 +1083,14 @@ STAGE PLANS:
                     0 _col0 (type: tinyint)
                     1 _col0 (type: tinyint)
                   outputColumnNames: _col1, _col3
-                  Statistics: Num rows: 132 Data size: 2112 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 129 Data size: 2064 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: (_col1 * _col3) (type: bigint)
                     outputColumnNames: _col0
-                    Statistics: Num rows: 132 Data size: 1056 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 129 Data size: 1032 Basic stats: COMPLETE Column stats: COMPLETE
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 132 Data size: 1056 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 129 Data size: 1032 Basic stats: COMPLETE Column stats: COMPLETE
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1144,16 +1144,16 @@ STAGE PLANS:
                       Group By Operator
                         aggregations: count(_col1)
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.98571897
+                        minReductionHashAggr: 0.986046
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: bigint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -1173,16 +1173,16 @@ STAGE PLANS:
                       Group By Operator
                         aggregations: count()
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.98571897
+                        minReductionHashAggr: 0.986046
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: bigint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -1193,7 +1193,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                 Dummy Store
             Execution mode: llap
             Reduce Operator Tree:
@@ -1202,7 +1202,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                 Merge Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -1210,14 +1210,14 @@ STAGE PLANS:
                     0 _col0 (type: tinyint)
                     1 _col0 (type: tinyint)
                   outputColumnNames: _col0, _col1, _col3
-                  Statistics: Num rows: 132 Data size: 2512 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 129 Data size: 2456 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: (_col1 * _col3) (type: bigint), _col0 (type: tinyint)
                     outputColumnNames: _col0, _col1
-                    Statistics: Num rows: 132 Data size: 1456 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 129 Data size: 1424 Basic stats: COMPLETE Column stats: COMPLETE
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 132 Data size: 1456 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 129 Data size: 1424 Basic stats: COMPLETE Column stats: COMPLETE
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1271,16 +1271,16 @@ STAGE PLANS:
                       Group By Operator
                         aggregations: sum(_col1)
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.98571897
+                        minReductionHashAggr: 0.986046
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: bigint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -1300,16 +1300,16 @@ STAGE PLANS:
                       Group By Operator
                         aggregations: count()
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.98571897
+                        minReductionHashAggr: 0.986046
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: bigint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -1320,7 +1320,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                 Dummy Store
             Execution mode: llap
             Reduce Operator Tree:
@@ -1329,7 +1329,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                 Merge Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -1337,14 +1337,14 @@ STAGE PLANS:
                     0 _col0 (type: tinyint)
                     1 _col0 (type: tinyint)
                   outputColumnNames: _col0, _col1, _col3
-                  Statistics: Num rows: 132 Data size: 2512 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 129 Data size: 2456 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: (_col1 * _col3) (type: bigint), _col0 (type: tinyint)
                     outputColumnNames: _col0, _col1
-                    Statistics: Num rows: 132 Data size: 1456 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 129 Data size: 1424 Basic stats: COMPLETE Column stats: COMPLETE
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 132 Data size: 1456 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 129 Data size: 1424 Basic stats: COMPLETE Column stats: COMPLETE
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1458,20 +1458,20 @@ STAGE PLANS:
                   0 _col0 (type: tinyint)
                   1 _col0 (type: tinyint)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 1161499 Data size: 9267080 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 1188936 Data size: 9486576 Basic stats: COMPLETE Column stats: COMPLETE
                 Group By Operator
                   aggregations: sum(_col1)
                   keys: _col0 (type: tinyint)
                   minReductionHashAggr: 0.99
                   mode: hash
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 131 Data size: 1572 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1536 Basic stats: COMPLETE Column stats: COMPLETE
                   Reduce Output Operator
                     key expressions: _col0 (type: tinyint)
                     null sort order: z
                     sort order: +
                     Map-reduce partition columns: _col0 (type: tinyint)
-                    Statistics: Num rows: 131 Data size: 1572 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 1536 Basic stats: COMPLETE Column stats: COMPLETE
                     value expressions: _col1 (type: bigint)
         Reducer 3 
             Execution mode: vectorized, llap
@@ -1481,14 +1481,14 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 130 Data size: 1560 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 127 Data size: 1524 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col1 (type: bigint), _col0 (type: tinyint)
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 130 Data size: 1560 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 127 Data size: 1524 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 130 Data size: 1560 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 127 Data size: 1524 Basic stats: COMPLETE Column stats: COMPLETE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1596,20 +1596,20 @@ STAGE PLANS:
                   0 _col0 (type: tinyint)
                   1 _col0 (type: tinyint)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 647260 Data size: 7739232 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 662550 Data size: 7922712 Basic stats: COMPLETE Column stats: COMPLETE
                 Group By Operator
                   aggregations: sum(_col1)
                   keys: _col0 (type: tinyint), _col2 (type: tinyint)
                   minReductionHashAggr: 0.99
                   mode: hash
                   outputColumnNames: _col0, _col1, _col2
-                  Statistics: Num rows: 17161 Data size: 274088 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 16384 Data size: 261696 Basic stats: COMPLETE Column stats: COMPLETE
                   Reduce Output Operator
                     key expressions: _col0 (type: tinyint), _col1 (type: tinyint)
                     null sort order: zz
                     sort order: ++
                     Map-reduce partition columns: _col0 (type: tinyint), _col1 (type: tinyint)
-                    Statistics: Num rows: 17161 Data size: 274088 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 16384 Data size: 261696 Basic stats: COMPLETE Column stats: COMPLETE
                     value expressions: _col2 (type: bigint)
         Reducer 3 
             Execution mode: vectorized, llap
@@ -1619,14 +1619,14 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint), KEY._col1 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 17161 Data size: 274088 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 16384 Data size: 261696 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col2 (type: bigint), _col0 (type: tinyint)
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 17161 Data size: 205688 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 16384 Data size: 196384 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 17161 Data size: 205688 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 16384 Data size: 196384 Basic stats: COMPLETE Column stats: COMPLETE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/limit_pushdown.q.out b/ql/src/test/results/clientpositive/llap/limit_pushdown.q.out
index 7ce1a04d9b..fc2a53073f 100644
--- a/ql/src/test/results/clientpositive/llap/limit_pushdown.q.out
+++ b/ql/src/test/results/clientpositive/llap/limit_pushdown.q.out
@@ -584,7 +584,7 @@ STAGE PLANS:
                   keys: _col0 (type: tinyint)
                   mode: complete
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col0 (type: tinyint), _col1 (type: bigint)
                     outputColumnNames: _col0, _col1
@@ -697,7 +697,7 @@ STAGE PLANS:
                   keys: _col0 (type: tinyint)
                   mode: complete
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col0 (type: tinyint), _col1 (type: bigint)
                     outputColumnNames: _col0, _col1
@@ -815,7 +815,7 @@ STAGE PLANS:
                     keys: _col2 (type: tinyint)
                     mode: complete
                     outputColumnNames: _col0, _col1, _col2
-                    Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col0 (type: tinyint), _col1 (type: bigint), _col2 (type: bigint)
                       outputColumnNames: _col0, _col1, _col2
diff --git a/ql/src/test/results/clientpositive/llap/limit_pushdown3.q.out b/ql/src/test/results/clientpositive/llap/limit_pushdown3.q.out
index e06de87969..5938fd84ed 100644
--- a/ql/src/test/results/clientpositive/llap/limit_pushdown3.q.out
+++ b/ql/src/test/results/clientpositive/llap/limit_pushdown3.q.out
@@ -620,12 +620,12 @@ STAGE PLANS:
                   keys: _col0 (type: tinyint)
                   mode: complete
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                   Reduce Output Operator
                     key expressions: _col0 (type: tinyint)
                     null sort order: z
                     sort order: +
-                    Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                     value expressions: _col1 (type: bigint)
         Reducer 3 
             Execution mode: vectorized, llap
@@ -633,7 +633,7 @@ STAGE PLANS:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: tinyint), VALUE._col0 (type: bigint)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                 Limit
                   Number of rows: 20
                   Statistics: Num rows: 20 Data size: 204 Basic stats: COMPLETE Column stats: COMPLETE
@@ -744,12 +744,12 @@ STAGE PLANS:
                   keys: _col0 (type: tinyint)
                   mode: complete
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                   Reduce Output Operator
                     key expressions: _col0 (type: tinyint)
                     null sort order: z
                     sort order: +
-                    Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                     value expressions: _col1 (type: bigint)
         Reducer 3 
             Execution mode: vectorized, llap
@@ -757,7 +757,7 @@ STAGE PLANS:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: tinyint), VALUE._col0 (type: bigint)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                 Limit
                   Number of rows: 20
                   Statistics: Num rows: 20 Data size: 204 Basic stats: COMPLETE Column stats: COMPLETE
@@ -873,12 +873,12 @@ STAGE PLANS:
                     keys: _col2 (type: tinyint)
                     mode: complete
                     outputColumnNames: _col0, _col1, _col2
-                    Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                     Reduce Output Operator
                       key expressions: _col0 (type: tinyint)
                       null sort order: z
                       sort order: +
-                      Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                       value expressions: _col1 (type: bigint), _col2 (type: bigint)
         Reducer 3 
             Execution mode: vectorized, llap
@@ -886,7 +886,7 @@ STAGE PLANS:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: tinyint), VALUE._col0 (type: bigint), VALUE._col1 (type: bigint)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                 Limit
                   Number of rows: 20
                   Statistics: Num rows: 20 Data size: 364 Basic stats: COMPLETE Column stats: COMPLETE
diff --git a/ql/src/test/results/clientpositive/llap/mapjoin_decimal.q.out b/ql/src/test/results/clientpositive/llap/mapjoin_decimal.q.out
index 453760754b..8713f38f92 100644
--- a/ql/src/test/results/clientpositive/llap/mapjoin_decimal.q.out
+++ b/ql/src/test/results/clientpositive/llap/mapjoin_decimal.q.out
@@ -102,7 +102,7 @@ STAGE PLANS:
                 TableScan
                   alias: t1_n95
                   filterExpr: dec is not null (type: boolean)
-                  probeDecodeDetails: cacheKey:HASH_MAP_MAPJOIN_27_container, bigKeyColName:dec, smallTablePos:1, keyRatio:0.09532888465204957
+                  probeDecodeDetails: cacheKey:HASH_MAP_MAPJOIN_27_container, bigKeyColName:dec, smallTablePos:1, keyRatio:0.09628217349857007
                   Statistics: Num rows: 1049 Data size: 117488 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: dec is not null (type: boolean)
diff --git a/ql/src/test/results/clientpositive/llap/offset_limit_ppd_optimizer.q.out b/ql/src/test/results/clientpositive/llap/offset_limit_ppd_optimizer.q.out
index d48ef82b07..1646f8219d 100644
--- a/ql/src/test/results/clientpositive/llap/offset_limit_ppd_optimizer.q.out
+++ b/ql/src/test/results/clientpositive/llap/offset_limit_ppd_optimizer.q.out
@@ -589,7 +589,7 @@ STAGE PLANS:
                   keys: _col0 (type: tinyint)
                   mode: complete
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col0 (type: tinyint), _col1 (type: bigint)
                     outputColumnNames: _col0, _col1
@@ -703,7 +703,7 @@ STAGE PLANS:
                   keys: _col0 (type: tinyint)
                   mode: complete
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col0 (type: tinyint), _col1 (type: bigint)
                     outputColumnNames: _col0, _col1
@@ -822,7 +822,7 @@ STAGE PLANS:
                     keys: _col2 (type: tinyint)
                     mode: complete
                     outputColumnNames: _col0, _col1, _col2
-                    Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col0 (type: tinyint), _col1 (type: bigint), _col2 (type: bigint)
                       outputColumnNames: _col0, _col1, _col2
diff --git a/ql/src/test/results/clientpositive/llap/parquet_vectorization_limit.q.out b/ql/src/test/results/clientpositive/llap/parquet_vectorization_limit.q.out
index 4738c6e6b2..83d662fee2 100644
--- a/ql/src/test/results/clientpositive/llap/parquet_vectorization_limit.q.out
+++ b/ql/src/test/results/clientpositive/llap/parquet_vectorization_limit.q.out
@@ -314,10 +314,10 @@ STAGE PLANS:
                             vectorProcessingMode: HASH
                             projectedOutputColumnNums: [0, 1]
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.9893392
+                        minReductionHashAggr: 0.9895833
                         mode: hash
                         outputColumnNames: _col0, _col1, _col2
-                        Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
@@ -327,7 +327,7 @@ STAGE PLANS:
                               className: VectorReduceSinkObjectHashOperator
                               native: true
                               nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                          Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: double), _col2 (type: bigint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs (cache only)
@@ -362,7 +362,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col0 (type: tinyint), (_col1 / _col2) (type: double)
                   outputColumnNames: _col0, _col1
@@ -371,7 +371,7 @@ STAGE PLANS:
                       native: true
                       projectedOutputColumnNums: [0, 3]
                       selectExpressions: DoubleColDivideLongColumn(col 1:double, col 2:bigint) -> 3:double
-                  Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                   Limit
                     Number of rows: 20
                     Limit Vectorization:
@@ -483,10 +483,10 @@ STAGE PLANS:
                             vectorProcessingMode: HASH
                             projectedOutputColumnNums: []
                         keys: ctinyint (type: tinyint)
-                        minReductionHashAggr: 0.9893392
+                        minReductionHashAggr: 0.9895833
                         mode: hash
                         outputColumnNames: _col0
-                        Statistics: Num rows: 131 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 256 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
@@ -496,7 +496,7 @@ STAGE PLANS:
                               className: VectorReduceSinkObjectHashOperator
                               native: true
                               nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                          Statistics: Num rows: 131 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 256 Basic stats: COMPLETE Column stats: COMPLETE
             Execution mode: vectorized, llap
             LLAP IO: all inputs (cache only)
             Map Vectorization:
@@ -528,7 +528,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0
-                Statistics: Num rows: 131 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 256 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col0 (type: tinyint)
                   outputColumnNames: _col0
@@ -706,7 +706,7 @@ STAGE PLANS:
                   keys: _col0 (type: tinyint)
                   mode: complete
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col0 (type: tinyint), _col1 (type: bigint)
                     outputColumnNames: _col0, _col1
diff --git a/ql/src/test/results/clientpositive/llap/partition_explain_ddl.q.out b/ql/src/test/results/clientpositive/llap/partition_explain_ddl.q.out
index 71de63e2b7..83e97eb7d7 100644
--- a/ql/src/test/results/clientpositive/llap/partition_explain_ddl.q.out
+++ b/ql/src/test/results/clientpositive/llap/partition_explain_ddl.q.out
@@ -146,9 +146,9 @@ ALTER TABLE default.add_part_test UPDATE STATISTICS SET('numRows'='0','rawDataSi
 ALTER TABLE default.add_part_test ADD IF NOT EXISTS PARTITION (ds='2010-01-01');
 ALTER TABLE default.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS SET('numRows'='19','rawDataSize'='267' );
 ALTER TABLE default.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS FOR COLUMN key SET('avgColLen'='5.526315789473684','maxColLen'='6','numNulls'='0','numDVs'='19' );
--- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-01' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTgZXdNICf8TvAo4ELgLO2SMXF/BS72uELgOLCnwGAj9Y4wJOCQMKT9CX+vqIBw+fKPr3LlKsBwIHHF8DX2CmF7e4T/JG0AYKY6Bb+o9oQ 
+-- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-01' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTga///AODuuFlwpGjgAL7r+CB+/////8BgPGY2AGB8bqnA8TDyvT6/////wG75PK0BMDg56b6/////wGAn/E7wM3HswOA1rnX/P////8BguujpwOB4qzYAv6j2hD/wYu4+v////8BgIKhwAGAge7KA8Cop9b//////wE= 
 ALTER TABLE default.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS FOR COLUMN value SET('avgColLen'='7.526315789473684','maxColLen'='8','numNulls'='0','numDVs'='19' );
--- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-01' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTgZnEIYCNq4gBgKCIGoD61AHBjs4N/7WjogGBquoE/9ScS4HyxCf/keJOxMnVP4GwwUn7+oEgwNzHBsCeqgOAmb1QguH/Cb7p83LA3Z9B 
+-- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-01' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTwq6o+gLE0trKAvuXwdz6/////wGAp4ikAcCYgKYEgKv42f3/////AcLt7oMD/orRm///////AcDeotcBwOvPh/r/////AYDyz7kGwM+kvvz/////AYD90bn+/////wGBytzd/v////8Bv9fU1v//////AYDRh8UEwf6S/v3/////Ab+aqtIChMGNvP7/////AQ== 
 
 
 
@@ -271,13 +271,13 @@ ALTER TABLE default.add_part_test PARTITION (ds='2010-01-02') UPDATE STATISTICS
 ALTER TABLE default.add_part_test ADD IF NOT EXISTS PARTITION (ds='2010-01-03');
 ALTER TABLE default.add_part_test PARTITION (ds='2010-01-03') UPDATE STATISTICS SET('numRows'='15','rawDataSize'='225' );
 ALTER TABLE default.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS FOR COLUMN value SET('avgColLen'='7.526315789473684','maxColLen'='8','numNulls'='0','numDVs'='19' );
--- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-01' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTgZnEIYCNq4gBgKCIGoD61AHBjs4N/7WjogGBquoE/9ScS4HyxCf/keJOxMnVP4GwwUn7+oEgwNzHBsCeqgOAmb1QguH/Cb7p83LA3Z9B 
+-- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-01' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTwq6o+gLE0trKAvuXwdz6/////wGAp4ikAcCYgKYEgKv42f3/////AcLt7oMD/orRm///////AcDeotcBwOvPh/r/////AYDyz7kGwM+kvvz/////AYD90bn+/////wGBytzd/v////8Bv9fU1v//////AYDRh8UEwf6S/v3/////Ab+aqtIChMGNvP7/////AQ== 
 ALTER TABLE default.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS FOR COLUMN key SET('avgColLen'='5.526315789473684','maxColLen'='6','numNulls'='0','numDVs'='19' );
--- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-01' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTgZXdNICf8TvAo4ELgLO2SMXF/BS72uELgOLCnwGAj9Y4wJOCQMKT9CX+vqIBw+fKPr3LlKsBwIHHF8DX2CmF7e4T/JG0AYKY6Bb+o9oQ 
+-- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-01' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTga///AODuuFlwpGjgAL7r+CB+/////8BgPGY2AGB8bqnA8TDyvT6/////wG75PK0BMDg56b6/////wGAn/E7wM3HswOA1rnX/P////8BguujpwOB4qzYAv6j2hD/wYu4+v////8BgIKhwAGAge7KA8Cop9b//////wE= 
 ALTER TABLE default.add_part_test PARTITION (ds='2010-01-03') UPDATE STATISTICS FOR COLUMN value SET('avgColLen'='8.0','maxColLen'='8','numNulls'='0','numDVs'='15' );
--- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-03' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PxruDCfvd++EBgJbAswHAj9hcgOSPEcGP0Tf/ouVYhPfkDfzUm17AgIcTgOP5KIGsqm3Am/Ii/6epDYDf+AQ= 
+-- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-03' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PgaOnjASAnPDu//////8BwfPgSP+i5ViAxKHO/P////8BgIjfnQTA44A8gJ2G1///////AcSq3Y7//////wH84vzz/f////8BhYzE6vz/////AfyQ+MsH/4aiEoChh/v//////wHBvOTP//////8B 
 ALTER TABLE default.add_part_test PARTITION (ds='2010-01-03') UPDATE STATISTICS FOR COLUMN key SET('avgColLen'='6.0','maxColLen'='6','numNulls'='0','numDVs'='15' );
--- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-03' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8Pwoy4S4DjsC2Cy/cxvYTEDsGjtQqBy7Yi/8DaQb+/pBPAjbjoAYHXgA2/h9yDAcKsjyi+usGNAcHK9T/CzrU/ 
+-- BIT VECTORS PRESENT FOR default.add_part_test PARTITION ds='2010-01-03' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PxLrgqgHA37++Bv2T79H6/////wGAkZX+/v////8BwYzG8AWApP7O+f////8BgdfK4wT/m6bn+/////8B/9jt3wKC8sjC/f////8BvuyTzgPB1Mbz/P////8Bv5KKwgTBi8Ph+f////8BgIaQ5QM= 
 
 
 
@@ -418,9 +418,9 @@ ALTER TABLE add_part_test_db.add_part_test UPDATE STATISTICS SET('numRows'='0','
 ALTER TABLE add_part_test_db.add_part_test ADD IF NOT EXISTS PARTITION (ds='2010-01-01');
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS SET('numRows'='19','rawDataSize'='267' );
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS FOR COLUMN key SET('avgColLen'='5.526315789473684','maxColLen'='6','numNulls'='0','numDVs'='19' );
--- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTgZXdNICf8TvAo4ELgLO2SMXF/BS72uELgOLCnwGAj9Y4wJOCQMKT9CX+vqIBw+fKPr3LlKsBwIHHF8DX2CmF7e4T/JG0AYKY6Bb+o9oQ 
+-- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTga///AODuuFlwpGjgAL7r+CB+/////8BgPGY2AGB8bqnA8TDyvT6/////wG75PK0BMDg56b6/////wGAn/E7wM3HswOA1rnX/P////8BguujpwOB4qzYAv6j2hD/wYu4+v////8BgIKhwAGAge7KA8Cop9b//////wE= 
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS FOR COLUMN value SET('avgColLen'='7.526315789473684','maxColLen'='8','numNulls'='0','numDVs'='19' );
--- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTgZnEIYCNq4gBgKCIGoD61AHBjs4N/7WjogGBquoE/9ScS4HyxCf/keJOxMnVP4GwwUn7+oEgwNzHBsCeqgOAmb1QguH/Cb7p83LA3Z9B 
+-- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTwq6o+gLE0trKAvuXwdz6/////wGAp4ikAcCYgKYEgKv42f3/////AcLt7oMD/orRm///////AcDeotcBwOvPh/r/////AYDyz7kGwM+kvvz/////AYD90bn+/////wGBytzd/v////8Bv9fU1v//////AYDRh8UEwf6S/v3/////Ab+aqtIChMGNvP7/////AQ== 
 
 
 
@@ -543,13 +543,13 @@ ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-02') UPDATE ST
 ALTER TABLE add_part_test_db.add_part_test ADD IF NOT EXISTS PARTITION (ds='2010-01-03');
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-03') UPDATE STATISTICS SET('numRows'='15','rawDataSize'='225' );
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS FOR COLUMN value SET('avgColLen'='7.526315789473684','maxColLen'='8','numNulls'='0','numDVs'='19' );
--- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTgZnEIYCNq4gBgKCIGoD61AHBjs4N/7WjogGBquoE/9ScS4HyxCf/keJOxMnVP4GwwUn7+oEgwNzHBsCeqgOAmb1QguH/Cb7p83LA3Z9B 
+-- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTwq6o+gLE0trKAvuXwdz6/////wGAp4ikAcCYgKYEgKv42f3/////AcLt7oMD/orRm///////AcDeotcBwOvPh/r/////AYDyz7kGwM+kvvz/////AYD90bn+/////wGBytzd/v////8Bv9fU1v//////AYDRh8UEwf6S/v3/////Ab+aqtIChMGNvP7/////AQ== 
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS FOR COLUMN key SET('avgColLen'='5.526315789473684','maxColLen'='6','numNulls'='0','numDVs'='19' );
--- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTgZXdNICf8TvAo4ELgLO2SMXF/BS72uELgOLCnwGAj9Y4wJOCQMKT9CX+vqIBw+fKPr3LlKsBwIHHF8DX2CmF7e4T/JG0AYKY6Bb+o9oQ 
+-- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTga///AODuuFlwpGjgAL7r+CB+/////8BgPGY2AGB8bqnA8TDyvT6/////wG75PK0BMDg56b6/////wGAn/E7wM3HswOA1rnX/P////8BguujpwOB4qzYAv6j2hD/wYu4+v////8BgIKhwAGAge7KA8Cop9b//////wE= 
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-03') UPDATE STATISTICS FOR COLUMN value SET('avgColLen'='8.0','maxColLen'='8','numNulls'='0','numDVs'='15' );
--- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-03' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PxruDCfvd++EBgJbAswHAj9hcgOSPEcGP0Tf/ouVYhPfkDfzUm17AgIcTgOP5KIGsqm3Am/Ii/6epDYDf+AQ= 
+-- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-03' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PgaOnjASAnPDu//////8BwfPgSP+i5ViAxKHO/P////8BgIjfnQTA44A8gJ2G1///////AcSq3Y7//////wH84vzz/f////8BhYzE6vz/////AfyQ+MsH/4aiEoChh/v//////wHBvOTP//////8B 
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-03') UPDATE STATISTICS FOR COLUMN key SET('avgColLen'='6.0','maxColLen'='6','numNulls'='0','numDVs'='15' );
--- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-03' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8Pwoy4S4DjsC2Cy/cxvYTEDsGjtQqBy7Yi/8DaQb+/pBPAjbjoAYHXgA2/h9yDAcKsjyi+usGNAcHK9T/CzrU/ 
+-- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-03' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PxLrgqgHA37++Bv2T79H6/////wGAkZX+/v////8BwYzG8AWApP7O+f////8BgdfK4wT/m6bn+/////8B/9jt3wKC8sjC/f////8BvuyTzgPB1Mbz/P////8Bv5KKwgTBi8Ph+f////8BgIaQ5QM= 
 
 
 
@@ -645,13 +645,13 @@ ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-02') UPDATE ST
 ALTER TABLE add_part_test_db.add_part_test ADD IF NOT EXISTS PARTITION (ds='2010-01-03');
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-03') UPDATE STATISTICS SET('numRows'='15','rawDataSize'='225' );
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS FOR COLUMN value SET('avgColLen'='7.526315789473684','maxColLen'='8','numNulls'='0','numDVs'='19' );
--- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTgZnEIYCNq4gBgKCIGoD61AHBjs4N/7WjogGBquoE/9ScS4HyxCf/keJOxMnVP4GwwUn7+oEgwNzHBsCeqgOAmb1QguH/Cb7p83LA3Z9B 
+-- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTwq6o+gLE0trKAvuXwdz6/////wGAp4ikAcCYgKYEgKv42f3/////AcLt7oMD/orRm///////AcDeotcBwOvPh/r/////AYDyz7kGwM+kvvz/////AYD90bn+/////wGBytzd/v////8Bv9fU1v//////AYDRh8UEwf6S/v3/////Ab+aqtIChMGNvP7/////AQ== 
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-01') UPDATE STATISTICS FOR COLUMN key SET('avgColLen'='5.526315789473684','maxColLen'='6','numNulls'='0','numDVs'='19' );
--- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTgZXdNICf8TvAo4ELgLO2SMXF/BS72uELgOLCnwGAj9Y4wJOCQMKT9CX+vqIBw+fKPr3LlKsBwIHHF8DX2CmF7e4T/JG0AYKY6Bb+o9oQ 
+-- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-01' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBMTga///AODuuFlwpGjgAL7r+CB+/////8BgPGY2AGB8bqnA8TDyvT6/////wG75PK0BMDg56b6/////wGAn/E7wM3HswOA1rnX/P////8BguujpwOB4qzYAv6j2hD/wYu4+v////8BgIKhwAGAge7KA8Cop9b//////wE= 
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-03') UPDATE STATISTICS FOR COLUMN value SET('avgColLen'='8.0','maxColLen'='8','numNulls'='0','numDVs'='15' );
--- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-03' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PxruDCfvd++EBgJbAswHAj9hcgOSPEcGP0Tf/ouVYhPfkDfzUm17AgIcTgOP5KIGsqm3Am/Ii/6epDYDf+AQ= 
+-- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-03' FOR COLUMN value BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PgaOnjASAnPDu//////8BwfPgSP+i5ViAxKHO/P////8BgIjfnQTA44A8gJ2G1///////AcSq3Y7//////wH84vzz/f////8BhYzE6vz/////AfyQ+MsH/4aiEoChh/v//////wHBvOTP//////8B 
 ALTER TABLE add_part_test_db.add_part_test PARTITION (ds='2010-01-03') UPDATE STATISTICS FOR COLUMN key SET('avgColLen'='6.0','maxColLen'='6','numNulls'='0','numDVs'='15' );
--- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-03' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8Pwoy4S4DjsC2Cy/cxvYTEDsGjtQqBy7Yi/8DaQb+/pBPAjbjoAYHXgA2/h9yDAcKsjyi+usGNAcHK9T/CzrU/ 
+-- BIT VECTORS PRESENT FOR add_part_test_db.add_part_test PARTITION ds='2010-01-03' FOR COLUMN key BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PxLrgqgHA37++Bv2T79H6/////wGAkZX+/v////8BwYzG8AWApP7O+f////8BgdfK4wT/m6bn+/////8B/9jt3wKC8sjC/f////8BvuyTzgPB1Mbz/P////8Bv5KKwgTBi8Ph+f////8BgIaQ5QM= 
 
 
 
@@ -899,65 +899,65 @@ ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Tennis') UPDATE
 -- ALTER TABLE db_bdpbase.default_partition_test ADD IF NOT EXISTS PARTITION (sports='__HIVE_DEFAULT_PARTITION__');
 -- ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='__HIVE_DEFAULT_PARTITION__') UPDATE STATISTICS SET('numRows'='6','rawDataSize'='247' );
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Tennis') UPDATE STATISTICS FOR COLUMN lastname SET('avgColLen'='6.625','maxColLen'='10','numNulls'='0','numDVs'='16' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Tennis' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBAQwqCZNL+hzCfCq8sS//G4Z//Igh+Av5g6g5jedr2g+gbE5OIS/ZXolwHB4+gmgdGQUb3CjB6Cx8R2/vCZUcaC9hQ= 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Tennis' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBAQw9jy4wbApZ6a/v////8B/sPU3fv/////AcCHp9kGgN/fv/r/////AYLFxPn+/////wGBkrK3Av2Ry8cCgc676Pv/////Ab/A89YBxOTiEvzixO/+/////wHD55ygA77R9+T6/////wHFq+mVB7vOpY39/////wE= 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Tennis') UPDATE STATISTICS FOR COLUMN id SET('lowValue'='1007','highValue'='1086','numNulls'='0','numDVs'='16' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Tennis' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBAQgsirL7/48YUBwInYJYLsnAq+rqJAwuW8X77azDPAtbA6wI+oAsSgqUz8v41KwIuXPIGM9zK/tfErgbSuJv/R0gg= 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Tennis' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBAQgsirL7+NuZgFgJSyrf7/////AcDw1/3//////wGAw9/iAoGurff//////wH//tG+/v////8BhMDytf//////Abya/vb+/////wHCpbPM//////8B/v+D1v7/////AcD2p9r//////wGApJdwwLKYgQTByo7U//////8BwdS26vv/////AQ== 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Tennis') UPDATE STATISTICS FOR COLUMN firstname SET('avgColLen'='5.875','maxColLen'='10','numNulls'='0','numDVs'='16' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Tennis' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBAQgs6IDMDD0h/Avf/gAYHX+Bz+5Kk6w7ikD/2kzCGBw4ol/8ulC4LylJoBvpSVecDR9AXAj+MDhpLjD/rmkgKBx/W+AQ== 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Tennis' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBAQgp+Lswf/6/Gw+/////8BgM2YkAPB0+LF/f////8B/8ulC8DngZ0CgJ+o9v//////AcDR9AWBwp7N+v////8BwZT4/QH/qIfj//////8BgP+t//3/////Ab+a5YgDxoiV3QK8+K/t/v////8Bgdruk/7/////AQ== 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Tennis') UPDATE STATISTICS FOR COLUMN country SET('avgColLen'='9.5625','maxColLen'='27','numNulls'='0','numDVs'='16' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Tennis' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBAQgZe0VsP97SW+mrkRxManffz0xjvAi6/iAb/L3gaA9d4BgKrvFcPQvQH9lawjwMHuIYLolCr+3eM+wMr+kwHBp+Ri 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Tennis' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBAQweClxwTAto6P/P////8Bg5qv8gO9nZOuAYWnjJT8/////wH7y9SkAoD13gGBtJOV/v////8BgqrYtf7/////Af3z25EEgbjb3wK/2Jud//////8BgZbmgvr/////Af+XtN4Dga/pvP//////AcH6mY8B 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Tennis') UPDATE STATISTICS FOR COLUMN city SET('avgColLen'='9.5625','maxColLen'='18','numNulls'='0','numDVs'='16' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Tennis' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBAQweyPIYCenSjA+bAFwJzvJICSgjyB2vovv+e98gHBg6FVv4+kJsC21wuAtsEYgITSacL2+CL/gYsyv6zyA4C7hoUB 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Tennis' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBAQgfSH0gPAg7CJAoCl9ljC0YLK//////8B/picz/7/////AcDlwtP7/////wHAl84twIbP+v//////AYCoomaApeWJBoG1lab6/////wH/sNr5AoDjqJr8/////wHBz+68BcCH7fb9/////wH/+7xK 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Basketball') UPDATE STATISTICS FOR COLUMN lastname SET('avgColLen'='6.2','maxColLen'='8','numNulls'='0','numDVs'='15' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Basketball' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PwtzJS4HWiIcBvubhfcG5hga/gIwlg5ObZsHx3x+8x6s9wOOwfMGM2jq/pMwLgN+XIcDKw1uAmZYhwN6AEQ== 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Basketball' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PgZ/tvgSA18jgAoGZwtb+/////wH/zaeIAcDWpIP//////wGC/43R+/////8B/5/ogwGDhYerAfz89K4DgL6l8v7/////AYDwwZj//////wHAlpaV/f////8BgLqSK8GJg9D9/////wHCiZiWAw== 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Basketball') UPDATE STATISTICS FOR COLUMN id SET('lowValue'='1001','highValue'='1097','numNulls'='0','numDVs'='15' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Basketball' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PgdqlYcDMpyaAzclyhImqVPydRcDlhnaB4u0Zv/vMLIC25x2GqtMQvsDAWrzYkyaApdafAcKXpUfAxuFQ 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Basketball' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PgYCNxQOA2pic/f////8BxuPc2AP8m7G4A7+Ix+z7/////wG/xNKo/f////8BgLCJswSAxK+U/f////8BgPmo2gHE6pNr/pSPjQK+4MTY+v////8BgIiW4ASEgZT0+/////8B/OCGvQE= 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Basketball') UPDATE STATISTICS FOR COLUMN firstname SET('avgColLen'='6.466666666666667','maxColLen'='9','numNulls'='0','numDVs'='15' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Basketball' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PwYD+FsDL+AOC+7wFvvyplwHAydEMgJnvHIGU3CeApeAWw8foVvyik4cCwI6wAoC/34cBwO+2mAHAsYgEgu/rLA== 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Basketball' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PgbilpAeC7+ssvtnsxfj/////AcCW6PAFwLLw9f7/////AcHwo4v9/////wH/nYz3AoGH1J/9/////wH/7Jv7/f////8BxNrM2wK85uvN/v////8BgJnvHMCdv9b//////wGAw7/oBcLAloD5/////wE= 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Basketball') UPDATE STATISTICS FOR COLUMN country SET('avgColLen'='8.666666666666666','maxColLen'='16','numNulls'='0','numDVs'='14' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Basketball' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4OwbKHJIDWpA/AicoqgdXDIf/81IYBgPnGIoT/7Au98aUnwOqQK//QmzHEwKwWvJG0TIDT8XGAvOBg 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Basketball' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4OhdzCtAL8jYW5A8Ce5MX6/////wHAicoqgNKYqAGA+cYigKy/jwGB3qTH/f////8BgNG/hwLDkchH/YOnjf//////Af/knsj9/////wHA+9/oBICtjo7//////wE= 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Basketball') UPDATE STATISTICS FOR COLUMN city SET('avgColLen'='9.733333333333333','maxColLen'='26','numNulls'='0','numDVs'='15' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Basketball' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8Pg4qShgHAnsES/vPoZ8GR/Uq/35UjgN3eiwHA/9AbgLalKMXU3Qb8xrmYAb/cmUPAiv9nwMjAVsHUtQmCz5UO 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Basketball' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA8PgZjVoAbAiv9ng+yLbv3bzYP8/////wGFitRK/MrIowP/zYSG+/////8BwvzCl/7/////Af+jp8UBv+6Ctf//////AYGf/9wDv6/ZgQLCvb65+f////8BvsGr/QKAtqUo 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Football') UPDATE STATISTICS FOR COLUMN lastname SET('avgColLen'='5.6521739130434785','maxColLen'='8','numNulls'='0','numDVs'='23' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Football' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBcXgbeNBsGzzAa/6L3KAYDEvBrAkZgDw660G/2CxwiB4qEh/+PjJMHGy23/2K0IwLLuBoCvmBHDqrYlvtmWBf/R1F3B4asm/9PccYDm5UCB0gvBl4oVv8joB//GohE= 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Football' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBcXgqW6lwS/7cK2AsGpjOz7/////wGCm5fW//////8BvbT96wTA5rbf/P////8Bgoq+hwO/6qXp/P////8B/8GzqP7/////AcCqq+L//////wGA5PWu/v////8Bwa37xwa/u+SQ/P////8Bwcrsrf3/////Ab+2k+ADgNahiAHAyNff/v////8BwNftnP7/////AYDDkyfB/tKCA4DswM8Bgoeop/3/////Af3g8/oB 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Football') UPDATE STATISTICS FOR COLUMN id SET('lowValue'='1006','highValue'='1100','numNulls'='0','numDVs'='23' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Football' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBcXwaGOJcCG/geAndhQwOWwJoKHvAL+pZRUgJ2xH8P2iwn9oMwKgK7oGYC3z0iAl6UNwdOdQYL29i69zrZ5wJ+NIMHylbkBgIivKcSpmBO9wrAGv7r5DL+c8TXAzbEZ 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Football' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBcXgaCXhwXA1P+S/f////8Bg93J8wG91quf/P////8Bg8OW9gG9v/KA//////8Bhbns+AW7mZtJwM2xGcCm2JD7/////wHAzv2WAsDMyob9/////wHCpeL4/v////8Bv4iY4wW/56Sb+f////8BgLbX1QHB2tTlBP+Sqp36/////wGA9fLJAcGhkpcBgIXC0QPBxYbz//////8B/uGZ+vv/////AQ== 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Football') UPDATE STATISTICS FOR COLUMN firstname SET('avgColLen'='5.782608695652174','maxColLen'='9','numNulls'='0','numDVs'='23' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Football' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBcXwoOrLcDDvzrA+50D/5e3LoKK0Qb+55RWwI+gCYGexA2/g6MVgLChRIPl00v9/5sHwYqsEL+X0gnCvtZEvt7xI4D5icoBwO+PJoL28SWA+oIkwOT+P7635A+AwpUc 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Football' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBcXwbS80wPA08+OBMDEmZT6/////wHA7fi1BMLU84kBvs2zyfr/////AcDRiGfCgsLrA4DDgsb9/////wG+ipqK/v////8BwMjJowWC5Jyw//////8Bv5j19Pn/////AYDBosL//////wHA9t7fAb/QhPkDgJCxk/v/////AYKK0Qb+ra2ZAoOA5Pj//////wH9vuKJAcH15av8/////wGA1v/hAg== 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Football') UPDATE STATISTICS FOR COLUMN country SET('avgColLen'='10.826086956521738','maxColLen'='33','numNulls'='0','numDVs'='22' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Football' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBYWwfrFBoOK2xH/nPAQ/ui8kAGAr99HwIqwCMHyiwH/t5scgMfIP4GP/FGDhfgVvOntAYKIgxTA2t8Gwd6PL76d9zrAttBiweapRv6JlEOB+JIDwZKZGf7280Q= 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Football' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBYWw66T/gX/gadGwYr4n/3/////AYG57zXAkP/9+/////8BvbWmigfB/KHo+v////8BwYzq0gS/zsX3/f////8B//i05Pz/////AcG9m/4D//vz0fz/////AcCqpx3AxKqpAcCF+PACgIGGwPv/////AYSQlM0B/fqH6v//////Af+1/M38/////wGCp8si/pO8vQKC4MSEAQ== 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Football') UPDATE STATISTICS FOR COLUMN city SET('avgColLen'='8.782608695652174','maxColLen'='20','numNulls'='0','numDVs'='23' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Football' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBcXgYTdXcGyu2v/iN4PguGcML7L4wmBi8UFgIXPVr/M2RqA9tANgbekGsGM9gf+p+8OgOf1TcDusYMBgsCKJb7Pw0zA34ATgeWSToHExzb+p8w9wOY6wdGkBMCF3Qo= 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Football' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBcXw7/xvgW/vaexAoD6oqj6/////wHBqdfw//////8BvuPJ1P7/////AYCN2LgDwaXjsv3/////Af+IxJcGwbyujvv/////Af+ttFnBqYmkA7+Yrqb7/////wHAgr+LBIGHpJP9/////wH/iY3oAYDAj7/8/////wGAie6wAYD20A3Cw5oi/ozl0QKAl+LVAcHRpASBoNS9//////8B 
 -- ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='__HIVE_DEFAULT_PARTITION__') UPDATE STATISTICS FOR COLUMN lastname SET('avgColLen'='6.333333333333333','maxColLen'='8','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='__HIVE_DEFAULT_PARTITION__' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwq3YGf+6xOABgNDxgwHBtvulAYOcuZgB/KvM/AE= 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='__HIVE_DEFAULT_PARTITION__' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGgbePuQfB9sjg+P////8Bw93qogW83dm9/P////8BwYbtqQK/yYTa/v////8B 
 -- ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='__HIVE_DEFAULT_PARTITION__') UPDATE STATISTICS FOR COLUMN id SET('lowValue'='1005','highValue'='1098','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='__HIVE_DEFAULT_PARTITION__' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwpjJWP/R3EDA+qZ5gKng4AHAzIc9wIH6KQ== 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='__HIVE_DEFAULT_PARTITION__' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGgeXMkgKAqeDgAYDOgWfAjve+/P////8Bga6jv///////Af/B69cD 
 -- ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='__HIVE_DEFAULT_PARTITION__') UPDATE STATISTICS FOR COLUMN firstname SET('avgColLen'='7.0','maxColLen'='9','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='__HIVE_DEFAULT_PARTITION__' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwe3GFoDQpwXB2quPAYCG7znBtecs/6up+gQ= 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='__HIVE_DEFAULT_PARTITION__' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwe3GFsGq05QBv6XU8P7/////AYHCq/AGwJ7v2Pr/////AcG15yw= 
 -- ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='__HIVE_DEFAULT_PARTITION__') UPDATE STATISTICS FOR COLUMN country SET('avgColLen'='9.333333333333334','maxColLen'='15','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='__HIVE_DEFAULT_PARTITION__' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwYisM4HBvsACv7+qRMKE/Eu/ucfmAr/e9Qs= 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='__HIVE_DEFAULT_PARTITION__' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwaXO9gaA4928+f////8BgoXl0AP/u9nv/v////8BwP3t9gP/wbzN/P////8B 
 -- ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='__HIVE_DEFAULT_PARTITION__') UPDATE STATISTICS FOR COLUMN city SET('avgColLen'='10.5','maxColLen'='17','numNulls'='0','numDVs'='6' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='__HIVE_DEFAULT_PARTITION__' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGgb7shwHA47jBAcLU7Xu+9fE7gKzqhAHBrpp+ 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='__HIVE_DEFAULT_PARTITION__' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoAYGwaGlyQKAyt+3AYCs6oQBwt6jv/7/////Af/P9r4C//fig/v/////AQ== 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Cricket') UPDATE STATISTICS FOR COLUMN lastname SET('avgColLen'='6.642857142857143','maxColLen'='10','numNulls'='0','numDVs'='14' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Cricket' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4OgoXoAv+tv2eBvOFvhYj5A/3fnjL97PUrgLHfJYD5+VGC9uAv/9aawwH/5cE2wdyMHoG1tsEBvtWbJQ== 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Cricket' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4Oh/eB3gH6kIqEBoDm49H7/////wGBzfvyAcDCzlTC2eaU/P////8B/q3H8v3/////Af+bxdoFgJL6jPv/////AYG84W//1I1igqC6pwH+kKX+/v////8Bwr362gQ= 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Cricket') UPDATE STATISTICS FOR COLUMN id SET('lowValue'='1002','highValue'='1099','numNulls'='0','numDVs'='14' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Cricket' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4OgqC6QMDhgB6/5MkWgaCkT8Gl6hHBqJC3Af3zgdcBgOWQKcHygjGAqr9J/7b9BYCB5gaA81HAr65J 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Cricket' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4Owp+5vgXAgIGC+/////8B/6frowTArIixAcCvrknA3Jmv//////8BgIHmBoGA38n6/////wHAhO5lgs76yAG+9dT6Ar+cjO36/////wGAx7GYBML+3Mj8/////wE= 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Cricket') UPDATE STATISTICS FOR COLUMN firstname SET('avgColLen'='5.285714285714286','maxColLen'='9','numNulls'='0','numDVs'='14' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Cricket' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4Og/GxPb+shzmAgJIEgezEjwGCibMXvP6rWYDq0AjAufxPgPGQDIHw+lGB28gmwumyTLziu2XAmYe4AQ== 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Cricket' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4OwbS80wOB6fyi/f////8B/4eU6QKB+P2a/f////8Bw7z4qQT8+8KdAsKaipb9/////wH/pLfZ//////8Bg/367/3/////Af72zOj//////wG+8a95gvbxuf3/////Ab7LzcwFwNTv8Pz/////AQ== 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Cricket') UPDATE STATISTICS FOR COLUMN country SET('avgColLen'='9.714285714285714','maxColLen'='18','numNulls'='0','numDVs'='14' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Cricket' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4Oge6eEYK1syL+v+RxxZLMZb/mvymC+cA1/N6NMr+Dxxa/zeUbgKag1gGBnYsTv4aNP4Db2KsBgIfwCQ== 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Cricket' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4OwanPogfEsvOR+/////8B/M6b8AKCibP3/f////8Bvprl2gLB+fLA//////8B/7zUlv7/////AcXwxLz+/////wG7+JuG/v////8BgPWXlAHB1KGNAv/45vkDwvKSh/n/////AYSysbYC 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Cricket') UPDATE STATISTICS FOR COLUMN city SET('avgColLen'='9.5','maxColLen'='18','numNulls'='0','numDVs'='14' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Cricket' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4OxNGgLP2X9QOB3uU3gPqsI//H7A2B7vRqv/idFoCrxB6A1JnuAcC/kS2Bz/PeAoC/vjm/u+0DxPKMBg== 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Cricket' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoA4Owv2KsweAxJ3Y+f////8Bv7aO5QaAo7XI+v////8BwM6p9/3/////AcCGkuoBwYfi6f//////Ab/3+6ICxPu9zwP90YX2//////8BgpXXv/j/////Af3c9qcEgZnkk/z/////Af/BmTE= 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Badminton') UPDATE STATISTICS FOR COLUMN lastname SET('avgColLen'='6.269230769230769','maxColLen'='9','numNulls'='0','numDVs'='26' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Badminton' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBoaw7/TBb7IiwLAqpc1guT6HYH+7wT+1/gIg6DoW7zrmyXAqbZFgMO4LMLuhGa+3oQmwLWoCIL8kQXAhuE9wPf/T77a3V3A6cYGwP2mAsCRpxmA6fgigMvYBIG7lRG/1okGgOiHJsGA/YsB 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Badminton' FOR COLUMN lastname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBoaw5bxWsDKgKgE/pbs5vz/////AYDw18AEguubl/3/////AcHBj579/////wH9pu6ABYKuotL+/////wH+x+S0//////8BgMj+2QLAjorG+f////8BwJm1pwLBgbeMBL/BgaD8/////wHAuJDKA4CXh93//////wHBuPXl+v////8B//SC/wWAweCB//////8BwMTBhv7/////AYC+l/cBwI3g1fr/////AYTay4cBvtbOsAL//sj+A8Hd+ZH4/////wE= 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Badminton') UPDATE STATISTICS FOR COLUMN id SET('lowValue'='1004','highValue'='1094','numNulls'='0','numDVs'='26' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Badminton' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBoawr/bO7+AhAiEneMx/PeySYK5/AmAnf4mwOW/Q/7Z9AvA9phvgPvRGoDSpBmA9PAPgYHVL7/QhBPAhbctgJXQFYDTmASAyqgkgL2uL4GK9Rq/mcwugLSoHMDChBWA54k2gKmhGoHCmzg= 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Badminton' FOR COLUMN id BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBoahd3Cdf32590G/6SLj/3/////AYCykT7Av92e/f////8BwYfGqwP/9oKWAYD4z638/////wGBwrxzv+i89wHA0Niv/f////8BgLL2rgGAstnL+/////8BguuQrAH+1vPaBMG99/D5/////wH//4P6BcDSr2WAnKXH/P////8BgKfB3P3/////AYCTgJEEgqb8+Pv/////AcCCvmq+0O7IAoDBhvb+/////wHA0dlC 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Badminton') UPDATE STATISTICS FOR COLUMN firstname SET('avgColLen'='5.615384615384615','maxColLen'='8','numNulls'='0','numDVs'='25' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Badminton' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBkZwYydOMGjqzT/gJUCge/NAcDH7X2GqedV/IGibr2RqwaBs44DwrPHF/20wwGAkOg0gNLgRICg/y/A6tgJgPGmJYDLzxODvuIivbrfDIDWr07A9qYBgPrdVIDQmQmAwuEFwMLuOg== 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Badminton' FOR COLUMN firstname BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBkZyJCAxAK5lvTQBMDlqKP5/////wHAl7CAA8CbmRzA8faZ/f////8Bgf/q/f//////Ab/LlfIGgNTwqvz/////AcDcuH6Ay4aWAoDC4QXA6L+q/f////8BwPv+XoDLzxPAzvF9waDs/Pz/////AcCQvbL+/////wHAuJKC//////8Bv8CUgAXAzNZPw+WL8vz/////AYD4gCH9tourAcPksWU= 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Badminton') UPDATE STATISTICS FOR COLUMN country SET('avgColLen'='10.038461538461538','maxColLen'='44','numNulls'='0','numDVs'='26' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Badminton' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBoahOSiAr6LiUe/p4gNgNayTcDNpQ2B6J1Iv8HkDMD3xgLAuL8/wLrZaMTj0hvAl4ACwI6CMf/Yn0m9mgSAlOY/gK2HH4DlgQzAv5UshI3VFv6v8B3B6O8nv+DxDL6vuSiB5osW/8wt 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Badminton' FOR COLUMN country BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBoahbLBzAP85PKJ/f////8BwLe62gLD4vSXAYGN3q0B/6Xhi/r/////Ab2osqUFwqq+oQH+tdPa+v////8BgPenYoCwhkKAndeXA4Sn15/+/////wH+le6UAr/epnP/7bOp+v////8BgKHJV4DwkcACg4u68wGB85+S/f////8B/JyLowOAs7kWgYmk8fr/////Af/OrLoDgO721P//////AYGQ3sD7/////wE= 
 ALTER TABLE db_bdpbase.default_partition_test PARTITION (sports='Badminton') UPDATE STATISTICS FOR COLUMN city SET('avgColLen'='7.961538461538462','maxColLen'='15','numNulls'='0','numDVs'='26' );
--- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Badminton' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBoagrWZAv/9s07Bs+0B//2kJsD8PIKP1SP+2PIEgfG2EoDcziH/jeLHAcD+zy2Bw8wOgLrAXL+8myOA1LEOwfzSIIK3mAO9rYMCwY+1R4PVp1CB3L4ngfaAFfqJzAHA/JA/wZrqAb/2q0E= 
+-- BIT VECTORS PRESENT FOR db_bdpbase.default_partition_test PARTITION sports='Badminton' FOR COLUMN city BUT THEY ARE NOT SUPPORTED YET.THE BASE64 VALUE FOR THE BITVECTOR IS SExMoBoagcnkoQHDmv3pA/6E55gChOm3qP//////AbzE6Yj7/////wH/jeLHAYC7qMgEgO/pvP//////AYDl7q35/////wHAnoCTBsDeqIT+/////wGArM7x//////8BwdCEL//10sL+/////wGB/Yxrv/G7V8HV1cT7/////wGA/62HA4C7sfsBwJT/rPr/////AYCFgrIBgbbW6P//////Ab707dv//////wGEkeKsBYLSvzy6mZuX+v////8B 
 
 
 
diff --git a/ql/src/test/results/clientpositive/llap/prepare_plan.q.out b/ql/src/test/results/clientpositive/llap/prepare_plan.q.out
index 41bc2c59c8..ec38f3f00b 100644
--- a/ql/src/test/results/clientpositive/llap/prepare_plan.q.out
+++ b/ql/src/test/results/clientpositive/llap/prepare_plan.q.out
@@ -412,16 +412,16 @@ STAGE PLANS:
                       Group By Operator
                         aggregations: avg(ctinyint)
                         keys: ctinyint (type: tinyint)
-                        minReductionHashAggr: 0.9040293
+                        minReductionHashAggr: 0.9062271
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 131 Data size: 10352 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 10116 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 10352 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 10116 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: struct<count:bigint,sum:double,input:tinyint>)
             Execution mode: llap
             LLAP IO: all inputs
@@ -433,21 +433,21 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col1 (type: double)
                   outputColumnNames: _col1
-                  Statistics: Num rows: 131 Data size: 1048 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1024 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: (_col1 < $4) (type: boolean)
-                    Statistics: Num rows: 43 Data size: 344 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 42 Data size: 336 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col1 (type: double)
                       outputColumnNames: _col0
-                      Statistics: Num rows: 43 Data size: 344 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 42 Data size: 336 Basic stats: COMPLETE Column stats: COMPLETE
                       File Output Operator
                         compressed: false
-                        Statistics: Num rows: 43 Data size: 344 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 42 Data size: 336 Basic stats: COMPLETE Column stats: COMPLETE
                         table:
                             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -497,16 +497,16 @@ STAGE PLANS:
                       Group By Operator
                         aggregations: avg(ctinyint)
                         keys: ctinyint (type: tinyint)
-                        minReductionHashAggr: 0.95746756
+                        minReductionHashAggr: 0.95844156
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 131 Data size: 10352 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 10116 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 10352 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 10116 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: struct<count:bigint,sum:double,input:tinyint>)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -518,21 +518,21 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 131 Data size: 1444 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1412 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col1 (type: double)
                   outputColumnNames: _col1
-                  Statistics: Num rows: 131 Data size: 1048 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1024 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: (_col1 < 0) (type: boolean)
-                    Statistics: Num rows: 43 Data size: 344 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 42 Data size: 336 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col1 (type: double)
                       outputColumnNames: _col0
-                      Statistics: Num rows: 43 Data size: 344 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 42 Data size: 336 Basic stats: COMPLETE Column stats: COMPLETE
                       File Output Operator
                         compressed: false
-                        Statistics: Num rows: 43 Data size: 344 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 42 Data size: 336 Basic stats: COMPLETE Column stats: COMPLETE
                         table:
                             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1111,16 +1111,16 @@ STAGE PLANS:
                       Group By Operator
                         aggregations: min(ctinyint), max(cbigint)
                         keys: ctinyint (type: tinyint)
-                        minReductionHashAggr: 0.9680176
+                        minReductionHashAggr: 0.96875
                         mode: hash
                         outputColumnNames: _col0, _col1, _col2
-                        Statistics: Num rows: 131 Data size: 1968 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 1924 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: tinyint)
-                          Statistics: Num rows: 131 Data size: 1968 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 1924 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: tinyint), _col2 (type: bigint)
             Execution mode: llap
             LLAP IO: all inputs
@@ -1132,14 +1132,14 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 131 Data size: 1968 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1924 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col1 (type: tinyint), _col2 (type: bigint)
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 131 Data size: 1572 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1536 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 131 Data size: 1572 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 1536 Basic stats: COMPLETE Column stats: COMPLETE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/vector_left_outer_join.q.out b/ql/src/test/results/clientpositive/llap/vector_left_outer_join.q.out
index fcb46479de..e538862bda 100644
--- a/ql/src/test/results/clientpositive/llap/vector_left_outer_join.q.out
+++ b/ql/src/test/results/clientpositive/llap/vector_left_outer_join.q.out
@@ -65,7 +65,7 @@ STAGE PLANS:
                           1 _col0 (type: tinyint)
                         input vertices:
                           1 Reducer 4
-                        Statistics: Num rows: 1302989 Data size: 10423912 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 1333768 Data size: 10670144 Basic stats: COMPLETE Column stats: COMPLETE
                         Group By Operator
                           aggregations: count()
                           minReductionHashAggr: 0.99
diff --git a/ql/src/test/results/clientpositive/llap/vector_llap_text_1.q.out b/ql/src/test/results/clientpositive/llap/vector_llap_text_1.q.out
index 2159f0dc29..bcb679745c 100644
--- a/ql/src/test/results/clientpositive/llap/vector_llap_text_1.q.out
+++ b/ql/src/test/results/clientpositive/llap/vector_llap_text_1.q.out
@@ -208,7 +208,7 @@ STAGE PLANS:
                 TableScan
                   alias: b
                   filterExpr: key is not null (type: boolean)
-                  probeDecodeDetails: cacheKey:HASH_MAP_MAPJOIN_29_container, bigKeyColName:key, smallTablePos:0, keyRatio:0.292
+                  probeDecodeDetails: cacheKey:HASH_MAP_MAPJOIN_29_container, bigKeyColName:key, smallTablePos:0, keyRatio:0.306
                   Statistics: Num rows: 500 Data size: 47500 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
diff --git a/ql/src/test/results/clientpositive/llap/vectorization_div0.q.out b/ql/src/test/results/clientpositive/llap/vectorization_div0.q.out
index c5cdb49ea8..cf04ee0fc8 100644
--- a/ql/src/test/results/clientpositive/llap/vectorization_div0.q.out
+++ b/ql/src/test/results/clientpositive/llap/vectorization_div0.q.out
@@ -736,12 +736,12 @@ STAGE PLANS:
                         native: true
                         predicateExpression: FilterExprOrExpr(children: FilterLongColGreaterLongScalar(col 2:int, val 500000000), FilterDoubleColGreaterDoubleScalar(col 5:double, val 1.0E9), FilterLongColEqualLongScalar(col 0:tinyint, val 0))
                     predicate: ((cint > 500000000) or (cdouble > 1.0E9D) or (ctinyint = 0Y)) (type: boolean)
-                    Statistics: Num rows: 3378 Data size: 60552 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 3380 Data size: 60576 Basic stats: COMPLETE Column stats: COMPLETE
                     Top N Key Operator
                       sort order: +++++++++
                       keys: cint (type: int), cbigint (type: bigint), ctinyint (type: tinyint), (UDFToDouble(cint) / UDFToDouble((cint - 528534767))) (type: double), (UDFToDouble(cbigint) / UDFToDouble((cbigint - 1018195815L))) (type: double), (UDFToDouble(ctinyint) / UDFToDouble(ctinyint)) (type: double), (cint % (cint - 528534767)) (type: int), (cbigint % (cbigint - 1018195815L)) (type: bigint), (ctinyint % ctinyint) (type: tinyint)
                       null sort order: zzzzzzzzz
-                      Statistics: Num rows: 3378 Data size: 60552 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 3380 Data size: 60576 Basic stats: COMPLETE Column stats: COMPLETE
                       top n: 100
                       Top N Key Vectorization:
                           className: VectorTopNKeyOperator
@@ -755,7 +755,7 @@ STAGE PLANS:
                             native: true
                             projectedOutputColumnNums: [2, 3, 0, 18, 20, 22, 19, 25, 15]
                             selectExpressions: DoubleColDivideDoubleColumn(col 14:double, col 16:double)(children: CastLongToDouble(col 2:int) -> 14:double, CastLongToDouble(col 15:int)(children: LongColSubtractLongScalar(col 2:int, val 528534767) -> 15:int) -> 16:double) -> 18:double, DoubleColDivideDoubleColumn(col 14:double, col 16:double)(children: CastLongToDouble(col 3:bigint) -> 14:double, CastLongToDouble(col 15:bigint)(children: LongColSubtractLongScalar(col 3:bigint, val 1018195815) -> 15:bigint) -> 16:double) -> 20:double, DoubleColDivideDoubleColumn(col 14:double, col 16:double)(children: CastLongToDouble(col 0:tinyint) -> 14:double, CastLongToDouble(col 0:tinyint) -> 16:double) -> 22:double, LongColModuloLongColumn(col 2:int, col 15:int)(children: LongColSubtractLongScalar(col 2:int, val 528534767) -> 15:int) -> 19:int, LongColModuloLongColumn(col 3:bigint, col 15:bigint)(children: LongColSubtractLongScalar(col 3:bigint, val 1018195815) -> 15:bigint) -> 25:bigint, LongColModuloLongColumn(col 0:tinyint, col 0:tinyint) -> 15:tinyint
-                        Statistics: Num rows: 3378 Data size: 161792 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 3380 Data size: 161872 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: int), _col1 (type: bigint), _col2 (type: tinyint), _col3 (type: double), _col4 (type: double), _col5 (type: double), _col6 (type: int), _col7 (type: bigint), _col8 (type: tinyint)
                           null sort order: zzzzzzzzz
@@ -764,7 +764,7 @@ STAGE PLANS:
                               className: VectorReduceSinkObjectHashOperator
                               native: true
                               nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                          Statistics: Num rows: 3378 Data size: 161792 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 3380 Data size: 161872 Basic stats: COMPLETE Column stats: COMPLETE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -792,7 +792,7 @@ STAGE PLANS:
                     className: VectorSelectOperator
                     native: true
                     projectedOutputColumnNums: [0, 1, 2, 3, 4, 5, 6, 7, 8]
-                Statistics: Num rows: 3378 Data size: 161792 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 3380 Data size: 161872 Basic stats: COMPLETE Column stats: COMPLETE
                 Limit
                   Number of rows: 100
                   Limit Vectorization:
diff --git a/ql/src/test/results/clientpositive/llap/vectorization_input_format_excludes.q.out b/ql/src/test/results/clientpositive/llap/vectorization_input_format_excludes.q.out
index fbfb7c3857..b3b14ad8d2 100644
--- a/ql/src/test/results/clientpositive/llap/vectorization_input_format_excludes.q.out
+++ b/ql/src/test/results/clientpositive/llap/vectorization_input_format_excludes.q.out
@@ -188,16 +188,16 @@ STAGE PLANS:
                     Group By Operator
                       aggregations: max(_col1), min(_col2), count(_col3), sum(_col4), count(_col4), sum(_col6), sum(_col5), count(_col5)
                       keys: _col0 (type: tinyint)
-                      minReductionHashAggr: 0.9893392
+                      minReductionHashAggr: 0.9895833
                       mode: hash
                       outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                      Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                       Reduce Output Operator
                         key expressions: _col0 (type: tinyint)
                         null sort order: z
                         sort order: +
                         Map-reduce partition columns: _col0 (type: tinyint)
-                        Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                         value expressions: _col1 (type: int), _col2 (type: smallint), _col3 (type: bigint), _col4 (type: double), _col5 (type: bigint), _col6 (type: double), _col7 (type: double), _col8 (type: bigint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs (cache only)
@@ -224,14 +224,14 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col0 (type: tinyint), _col1 (type: int), _col2 (type: smallint), _col3 (type: bigint), (_col4 / _col5) (type: double), power(((_col6 - ((_col7 * _col7) / _col8)) / _col8), 0.5) (type: double)
                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                  Statistics: Num rows: 131 Data size: 4588 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 4484 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 131 Data size: 4588 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 4484 Basic stats: COMPLETE Column stats: COMPLETE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -530,16 +530,16 @@ STAGE PLANS:
                     Group By Operator
                       aggregations: max(_col1), min(_col2), count(_col3), sum(_col4), count(_col4), sum(_col6), sum(_col5), count(_col5)
                       keys: _col0 (type: tinyint)
-                      minReductionHashAggr: 0.9893392
+                      minReductionHashAggr: 0.9895833
                       mode: hash
                       outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                      Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                       Reduce Output Operator
                         key expressions: _col0 (type: tinyint)
                         null sort order: z
                         sort order: +
                         Map-reduce partition columns: _col0 (type: tinyint)
-                        Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                         value expressions: _col1 (type: int), _col2 (type: smallint), _col3 (type: bigint), _col4 (type: double), _col5 (type: bigint), _col6 (type: double), _col7 (type: double), _col8 (type: bigint)
             Execution mode: llap
             LLAP IO: all inputs (cache only)
@@ -561,14 +561,14 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col0 (type: tinyint), _col1 (type: int), _col2 (type: smallint), _col3 (type: bigint), (_col4 / _col5) (type: double), power(((_col6 - ((_col7 * _col7) / _col8)) / _col8), 0.5) (type: double)
                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                  Statistics: Num rows: 131 Data size: 4588 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 4484 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 131 Data size: 4588 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 4484 Basic stats: COMPLETE Column stats: COMPLETE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -872,16 +872,16 @@ STAGE PLANS:
                     Group By Operator
                       aggregations: max(_col1), min(_col2), count(_col3), sum(_col4), count(_col4), sum(_col6), sum(_col5), count(_col5)
                       keys: _col0 (type: tinyint)
-                      minReductionHashAggr: 0.9893392
+                      minReductionHashAggr: 0.9895833
                       mode: hash
                       outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                      Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                       Reduce Output Operator
                         key expressions: _col0 (type: tinyint)
                         null sort order: z
                         sort order: +
                         Map-reduce partition columns: _col0 (type: tinyint)
-                        Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                         value expressions: _col1 (type: int), _col2 (type: smallint), _col3 (type: bigint), _col4 (type: double), _col5 (type: bigint), _col6 (type: double), _col7 (type: double), _col8 (type: bigint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs (cache only)
@@ -908,14 +908,14 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col0 (type: tinyint), _col1 (type: int), _col2 (type: smallint), _col3 (type: bigint), (_col4 / _col5) (type: double), power(((_col6 - ((_col7 * _col7) / _col8)) / _col8), 0.5) (type: double)
                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                  Statistics: Num rows: 131 Data size: 4588 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 4484 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 131 Data size: 4588 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 4484 Basic stats: COMPLETE Column stats: COMPLETE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1262,16 +1262,16 @@ STAGE PLANS:
                     Group By Operator
                       aggregations: max(_col1), min(_col2), count(_col3), sum(_col4), count(_col4), sum(_col6), sum(_col5), count(_col5)
                       keys: _col0 (type: tinyint)
-                      minReductionHashAggr: 0.9893392
+                      minReductionHashAggr: 0.9895833
                       mode: hash
                       outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                      Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                       Reduce Output Operator
                         key expressions: _col0 (type: tinyint)
                         null sort order: z
                         sort order: +
                         Map-reduce partition columns: _col0 (type: tinyint)
-                        Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                         value expressions: _col1 (type: int), _col2 (type: smallint), _col3 (type: bigint), _col4 (type: double), _col5 (type: bigint), _col6 (type: double), _col7 (type: double), _col8 (type: bigint)
             Execution mode: llap
             LLAP IO: all inputs
@@ -1293,14 +1293,14 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col0 (type: tinyint), _col1 (type: int), _col2 (type: smallint), _col3 (type: bigint), (_col4 / _col5) (type: double), power(((_col6 - ((_col7 * _col7) / _col8)) / _col8), 0.5) (type: double)
                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                  Statistics: Num rows: 131 Data size: 4588 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 4484 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 131 Data size: 4588 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 4484 Basic stats: COMPLETE Column stats: COMPLETE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/vectorization_limit.q.out b/ql/src/test/results/clientpositive/llap/vectorization_limit.q.out
index 3b874f750e..675f499b65 100644
--- a/ql/src/test/results/clientpositive/llap/vectorization_limit.q.out
+++ b/ql/src/test/results/clientpositive/llap/vectorization_limit.q.out
@@ -333,10 +333,10 @@ STAGE PLANS:
                             vectorProcessingMode: HASH
                             projectedOutputColumnNums: [0, 1]
                         keys: _col0 (type: tinyint)
-                        minReductionHashAggr: 0.9893392
+                        minReductionHashAggr: 0.9895833
                         mode: hash
                         outputColumnNames: _col0, _col1, _col2
-                        Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
@@ -348,7 +348,7 @@ STAGE PLANS:
                               native: true
                               nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                               valueColumns: 1:double, 2:bigint
-                          Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                           value expressions: _col1 (type: double), _col2 (type: bigint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -396,12 +396,12 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                 Top N Key Operator
                   sort order: ++
                   keys: _col0 (type: tinyint), (_col1 / _col2) (type: double)
                   null sort order: zz
-                  Statistics: Num rows: 131 Data size: 2360 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 2304 Basic stats: COMPLETE Column stats: COMPLETE
                   top n: 20
                   Top N Key Vectorization:
                       className: VectorTopNKeyOperator
@@ -415,7 +415,7 @@ STAGE PLANS:
                         native: true
                         projectedOutputColumnNums: [0, 4]
                         selectExpressions: DoubleColDivideLongColumn(col 1:double, col 2:bigint) -> 4:double
-                    Statistics: Num rows: 131 Data size: 1048 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 1020 Basic stats: COMPLETE Column stats: COMPLETE
                     Reduce Output Operator
                       key expressions: _col0 (type: tinyint), _col1 (type: double)
                       null sort order: zz
@@ -425,7 +425,7 @@ STAGE PLANS:
                           keyColumns: 0:tinyint, 4:double
                           native: true
                           nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                      Statistics: Num rows: 131 Data size: 1048 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 128 Data size: 1020 Basic stats: COMPLETE Column stats: COMPLETE
         Reducer 3 
             Execution mode: vectorized, llap
             Reduce Vectorization:
@@ -449,7 +449,7 @@ STAGE PLANS:
                     className: VectorSelectOperator
                     native: true
                     projectedOutputColumnNums: [0, 1]
-                Statistics: Num rows: 131 Data size: 1048 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1020 Basic stats: COMPLETE Column stats: COMPLETE
                 Limit
                   Number of rows: 20
                   Limit Vectorization:
@@ -562,10 +562,10 @@ STAGE PLANS:
                             vectorProcessingMode: HASH
                             projectedOutputColumnNums: []
                         keys: ctinyint (type: tinyint)
-                        minReductionHashAggr: 0.9893392
+                        minReductionHashAggr: 0.9895833
                         mode: hash
                         outputColumnNames: _col0
-                        Statistics: Num rows: 131 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 256 Basic stats: COMPLETE Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: tinyint)
                           null sort order: z
@@ -577,7 +577,7 @@ STAGE PLANS:
                               native: true
                               nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                               partitionColumns: 0:tinyint
-                          Statistics: Num rows: 131 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 128 Data size: 256 Basic stats: COMPLETE Column stats: COMPLETE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -622,7 +622,7 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0
-                Statistics: Num rows: 131 Data size: 264 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 256 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col0 (type: tinyint)
                   outputColumnNames: _col0
@@ -817,12 +817,12 @@ STAGE PLANS:
                   keys: _col0 (type: tinyint)
                   mode: complete
                   outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                   Top N Key Operator
                     sort order: ++
                     keys: _col0 (type: tinyint), _col1 (type: bigint)
                     null sort order: zz
-                    Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
                     top n: 20
                     Top N Key Vectorization:
                         className: VectorTopNKeyOperator
@@ -837,7 +837,7 @@ STAGE PLANS:
                           keyColumns: 0:tinyint, 1:bigint
                           native: true
                           nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                      Statistics: Num rows: 131 Data size: 1312 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 128 Data size: 1280 Basic stats: COMPLETE Column stats: COMPLETE
         Reducer 3 
             Execution mode: vectorized, llap
             Reduce Vectorization:
@@ -861,7 +861,7 @@ STAGE PLANS:
                     className: VectorSelectOperator
                     native: true
                     projectedOutputColumnNums: [0, 1]
-                Statistics: Num rows: 131 Data size: 1048 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 1020 Basic stats: COMPLETE Column stats: COMPLETE
                 Limit
                   Number of rows: 20
                   Limit Vectorization:
diff --git a/ql/src/test/results/clientpositive/llap/vectorized_distinct_gby.q.out b/ql/src/test/results/clientpositive/llap/vectorized_distinct_gby.q.out
index 7be6c7a659..7e968d085b 100644
--- a/ql/src/test/results/clientpositive/llap/vectorized_distinct_gby.q.out
+++ b/ql/src/test/results/clientpositive/llap/vectorized_distinct_gby.q.out
@@ -477,10 +477,10 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2, _col3
-                Statistics: Num rows: 131 Data size: 26596 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 25988 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 131 Data size: 26596 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 25988 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/vectorized_nested_mapjoin.q.out b/ql/src/test/results/clientpositive/llap/vectorized_nested_mapjoin.q.out
index bed3845548..1c136371c3 100644
--- a/ql/src/test/results/clientpositive/llap/vectorized_nested_mapjoin.q.out
+++ b/ql/src/test/results/clientpositive/llap/vectorized_nested_mapjoin.q.out
@@ -29,7 +29,7 @@ STAGE PLANS:
                 TableScan
                   alias: v3
                   filterExpr: csmallint is not null (type: boolean)
-                  probeDecodeDetails: cacheKey:HASH_MAP_MAPJOIN_49_container, bigKeyColName:csmallint, smallTablePos:1, keyRatio:0.010579427083333334
+                  probeDecodeDetails: cacheKey:HASH_MAP_MAPJOIN_49_container, bigKeyColName:csmallint, smallTablePos:1, keyRatio:0.010335286458333334
                   Statistics: Num rows: 12288 Data size: 36700 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: csmallint is not null (type: boolean)
@@ -57,7 +57,7 @@ STAGE PLANS:
                           outputColumnNames: _col3
                           input vertices:
                             1 Map 3
-                          Statistics: Num rows: 782315 Data size: 6244648 Basic stats: COMPLETE Column stats: COMPLETE
+                          Statistics: Num rows: 800795 Data size: 6392488 Basic stats: COMPLETE Column stats: COMPLETE
                           Group By Operator
                             aggregations: sum(_col3)
                             minReductionHashAggr: 0.99
diff --git a/ql/src/test/results/clientpositive/llap/vectorized_parquet.q.out b/ql/src/test/results/clientpositive/llap/vectorized_parquet.q.out
index 90e9e7d47b..8f98380b58 100644
--- a/ql/src/test/results/clientpositive/llap/vectorized_parquet.q.out
+++ b/ql/src/test/results/clientpositive/llap/vectorized_parquet.q.out
@@ -158,16 +158,16 @@ STAGE PLANS:
                     Group By Operator
                       aggregations: max(_col1), min(_col2), count(_col3), sum(_col4), count(_col4), sum(_col6), sum(_col5), count(_col5)
                       keys: _col0 (type: tinyint)
-                      minReductionHashAggr: 0.9893392
+                      minReductionHashAggr: 0.9895833
                       mode: hash
                       outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                      Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                       Reduce Output Operator
                         key expressions: _col0 (type: tinyint)
                         null sort order: z
                         sort order: +
                         Map-reduce partition columns: _col0 (type: tinyint)
-                        Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                         value expressions: _col1 (type: int), _col2 (type: smallint), _col3 (type: bigint), _col4 (type: double), _col5 (type: bigint), _col6 (type: double), _col7 (type: double), _col8 (type: bigint)
             Execution mode: vectorized, llap
             LLAP IO: all inputs (cache only)
@@ -194,14 +194,14 @@ STAGE PLANS:
                 keys: KEY._col0 (type: tinyint)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                Statistics: Num rows: 131 Data size: 7732 Basic stats: COMPLETE Column stats: COMPLETE
+                Statistics: Num rows: 128 Data size: 7556 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col0 (type: tinyint), _col1 (type: int), _col2 (type: smallint), _col3 (type: bigint), (_col4 / _col5) (type: double), power(((_col6 - ((_col7 * _col7) / _col8)) / _col8), 0.5) (type: double)
                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                  Statistics: Num rows: 131 Data size: 4588 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 128 Data size: 4484 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 131 Data size: 4588 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 128 Data size: 4484 Basic stats: COMPLETE Column stats: COMPLETE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/tez/tez_tag.q.out b/ql/src/test/results/clientpositive/tez/tez_tag.q.out
index ecbac7a206..a78eaa1bf6 100644
--- a/ql/src/test/results/clientpositive/tez/tez_tag.q.out
+++ b/ql/src/test/results/clientpositive/tez/tez_tag.q.out
@@ -309,19 +309,19 @@ Stage-0
               <-Reducer 2 [SIMPLE_EDGE]
                 SHUFFLE [RS_21]
                   PartitionCols:_col1
-                  Merge Join Operator [MERGEJOIN_39] (rows=146 width=184)
+                  Merge Join Operator [MERGEJOIN_39] (rows=153 width=184)
                     Conds:FIL_35._col0=DUMMY_STORE_40._col0(Inner),Output:["_col1"]
                   <-Dummy Store [DUMMY_STORE_40]
-                      Group By Operator [GBY_13] (rows=146 width=4)
+                      Group By Operator [GBY_13] (rows=153 width=4)
                         Output:["_col0"],keys:KEY._col0
-                  <-Filter Operator [FIL_35] (rows=146 width=188)
+                  <-Filter Operator [FIL_35] (rows=153 width=188)
                       predicate:_col1 is not null
-                      Group By Operator [GBY_5] (rows=146 width=188)
+                      Group By Operator [GBY_5] (rows=153 width=188)
                         Output:["_col0","_col1"],aggregations:["min(VALUE._col0)"],keys:KEY._col0
                       <-Map 1 [SIMPLE_EDGE]
                         SHUFFLE [RS_4]
                           PartitionCols:_col0
-                          Group By Operator [GBY_3] (rows=146 width=188)
+                          Group By Operator [GBY_3] (rows=153 width=188)
                             Output:["_col0","_col1"],aggregations:["min(value)"],keys:key
                             Filter Operator [FIL_36] (rows=242 width=95)
                               predicate:key is not null
@@ -330,7 +330,7 @@ Stage-0
                       <-Map 5 [SIMPLE_EDGE]
                         SHUFFLE [RS_12]
                           PartitionCols:_col0
-                          Group By Operator [GBY_11] (rows=146 width=4)
+                          Group By Operator [GBY_11] (rows=153 width=4)
                             Output:["_col0"],keys:key
                             Filter Operator [FIL_37] (rows=242 width=4)
                               predicate:key is not null
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HLLConstants.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HLLConstants.java
index 3a1d0761a7..7a726aa298 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HLLConstants.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HLLConstants.java
@@ -26,9 +26,6 @@ public class HLLConstants {
   public static final int MIN_P_VALUE = 4;
   public static final int MAX_P_VALUE = 16;
 
-  // number of entries to store before being merged to sparse map
-  public static final int TEMP_LIST_DEFAULT_SIZE = 1024;
-
   // constants for SPARSE encoding
   public static final int P_PRIME_VALUE = 25;
   public static final int Q_PRIME_VALUE = 6;
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HLLSparseRegister.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HLLSparseRegister.java
index d5ac54ab52..d53c614c97 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HLLSparseRegister.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HLLSparseRegister.java
@@ -20,16 +20,12 @@
 
 import java.util.Map;
 import java.util.Map.Entry;
-import java.util.TreeMap;
 
-public class HLLSparseRegister implements HLLRegister {
+import java.util.HashMap;
 
-  private TreeMap<Integer,Byte> sparseMap;
+public class HLLSparseRegister implements HLLRegister {
 
-  // for a better insertion performance values are added to temporary unsorted
-  // list which will be merged to sparse map after a threshold
-  private int[] tempList;
-  private int tempListIdx;
+  private Map<Integer, Byte> sparseMap;
 
   // number of register bits
   private final int p;
@@ -47,9 +43,7 @@ public class HLLSparseRegister implements HLLRegister {
 
   public HLLSparseRegister(int p, int pp, int qp) {
     this.p = p;
-    this.sparseMap = new TreeMap<>();
-    this.tempList = new int[HLLConstants.TEMP_LIST_DEFAULT_SIZE];
-    this.tempListIdx = 0;
+    this.sparseMap = new HashMap<>();
     this.pPrime = pp;
     this.qPrime = qp;
     this.mask = ((1 << pPrime) - 1) ^ ((1 << p) - 1);
@@ -60,65 +54,43 @@ public HLLSparseRegister(int p, int pp, int qp) {
   public boolean add(long hashcode) {
     boolean updated = false;
 
-    // fill the temp list before merging to sparse map
-    if (tempListIdx < tempList.length) {
-      int encodedHash = encodeHash(hashcode);
-      tempList[tempListIdx++] = encodedHash;
-      updated = true;
+    int encodedHash = encodeHash(hashcode);
+
+    int key = encodedHash & pPrimeMask;
+    byte value = (byte) (encodedHash >>> pPrime);
+    byte nr = 0;
+    // if MSB is set to 1 then next qPrime MSB bits contains the value of
+    // number of zeroes.
+    // if MSB is set to 0 then number of zeroes is contained within pPrime - p
+    // bits.
+    if (encodedHash < 0) {
+      nr = (byte) (value & qPrimeMask);
     } else {
-      updated = mergeTempListToSparseMap();
-    }
-
-    return updated;
-  }
-
-  /**
-   * Adds temp list to sparse map. The key for sparse map entry is the register
-   * index determined by pPrime and value is the number of trailing zeroes.
-   * @return
-   */
-  private boolean mergeTempListToSparseMap() {
-    boolean updated = false;
-    for (int i = 0; i < tempListIdx; i++) {
-      int encodedHash = tempList[i];
-      int key = encodedHash & pPrimeMask;
-      byte value = (byte) (encodedHash >>> pPrime);
-      byte nr = 0;
-      // if MSB is set to 1 then next qPrime MSB bits contains the value of
-      // number of zeroes.
-      // if MSB is set to 0 then number of zeroes is contained within pPrime - p
-      // bits.
-      if (encodedHash < 0) {
-        nr = (byte) (value & qPrimeMask);
-      } else {
-        nr = (byte) (Integer.numberOfTrailingZeros(encodedHash >>> p) + 1);
-      }
-      updated = set(key, nr);
+      nr = (byte) (Integer.numberOfTrailingZeros(encodedHash >>> p) + 1);
     }
+    updated = set(key, nr);
 
-    // reset temp list index
-    tempListIdx = 0;
     return updated;
   }
 
   /**
    * <pre>
    * <b>Input:</b> 64 bit hashcode
-   * 
+   *
    * |---------w-------------| |------------p'----------|
    * 10101101.......1010101010 10101010101 01010101010101
    *                                       |------p-----|
-   *                                       
+   *
    * <b>Output:</b> 32 bit int
-   * 
+   *
    * |b| |-q'-|  |------------p'----------|
    *  1  010101  01010101010 10101010101010
    *                         |------p-----|
-   *                    
-   * 
+   *
+   *
    * The default values of p', q' and b are 25, 6, 1 (total 32 bits) respectively.
    * This function will return an int encoded in the following format
-   * 
+   *
    * p  - LSB p bits represent the register index
    * p' - LSB p' bits are used for increased accuracy in estimation
    * q' - q' bits after p' are left as such from the hashcode if b = 0 else
@@ -148,8 +120,8 @@ public int encodeHash(long hashcode) {
     }
   }
 
-  public int getSize() {
-    return sparseMap.size() + tempListIdx;
+  public boolean isSizeGreaterThan(int s) {
+    return sparseMap.size() > s;
   }
 
   public void merge(HLLRegister hllRegister) {
@@ -177,14 +149,7 @@ public boolean set(int key, byte value) {
     return false;
   }
 
-  public TreeMap<Integer,Byte> getSparseMap() {
-    return getMergedSparseMap();
-  }
-
-  private TreeMap<Integer,Byte> getMergedSparseMap() {
-    if (tempListIdx != 0) {
-      mergeTempListToSparseMap();
-    }
+  public Map<Integer, Byte> getSparseMap() {
     return sparseMap;
   }
 
@@ -195,7 +160,7 @@ public void extractLowBitsTo(HLLRegister dest) {
       byte lr = entry.getValue(); // this can be a max of 65, never > 127
       if (lr != 0) {
         // should be a no-op for sparse
-        dest.add((long) ((1 << (p + lr - 1)) | idx));
+        dest.add((1L << (p + lr - 1)) | idx);
       }
     }
   }
@@ -231,15 +196,8 @@ public boolean equals(Object obj) {
       return false;
     }
     HLLSparseRegister other = (HLLSparseRegister) obj;
-    boolean result = p == other.p && pPrime == other.pPrime && qPrime == other.qPrime
-        && tempListIdx == other.tempListIdx;
+    boolean result = p == other.p && pPrime == other.pPrime && qPrime == other.qPrime;
     if (result) {
-      for (int i = 0; i < tempListIdx; i++) {
-        if (tempList[i] != other.tempList[i]) {
-          return false;
-        }
-      }
-
       result = result && sparseMap.equals(other.sparseMap);
     }
     return result;
@@ -251,9 +209,6 @@ public int hashCode() {
     hashcode += 31 * p;
     hashcode += 31 * pPrime;
     hashcode += 31 * qPrime;
-    for (int i = 0; i < tempListIdx; i++) {
-      hashcode += 31 * tempList[tempListIdx];
-    }
     hashcode += sparseMap.hashCode();
     return hashcode;
   }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HyperLogLog.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HyperLogLog.java
index b23ebc3f71..8295bba662 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HyperLogLog.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HyperLogLog.java
@@ -20,7 +20,6 @@
 
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
-import java.nio.ByteBuffer;
 import java.nio.charset.Charset;
 import java.util.Map;
 import java.util.TreeMap;
@@ -30,17 +29,19 @@
 import org.apache.hadoop.hive.ql.util.JavaDataModel;
 import org.apache.hive.common.util.Murmur3;
 
+import com.google.common.annotations.VisibleForTesting;
+
 /**
  * <pre>
  * This is an implementation of the following variants of hyperloglog (HLL)
- * algorithm 
+ * algorithm
  * Original  - Original HLL algorithm from Flajolet et. al from
  *             http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf
  * HLLNoBias - Google's implementation of bias correction based on lookup table
  *             http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40671.pdf
  * HLL++     - Google's implementation of HLL++ algorithm that uses SPARSE registers
  *             http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40671.pdf
- * 
+ *
  * Following are the constructor parameters that determines which algorithm is
  * used
  * <b>numRegisterIndexBits</b> - number of LSB hashcode bits to be used as register index.
@@ -194,7 +195,7 @@ private void initializeAlpha(final int hashBits) {
     } else if (hashBits <= 64) {
       alphaMM = 0.709f;
     } else {
-      alphaMM = 0.7213f / (float) (1 + 1.079f / m);
+      alphaMM = 0.7213f / (1 + 1.079f / m);
     }
 
     // For efficiency alpha is multiplied by m^2
@@ -262,7 +263,7 @@ public void add(long hashcode) {
 
       // if size of sparse map excess the threshold convert the sparse map to
       // dense register and switch to DENSE encoding
-      if (sparseRegister.getSize() > encodingSwitchThreshold) {
+      if (sparseRegister.isSizeGreaterThan(encodingSwitchThreshold)) {
         encoding = EncodingType.DENSE;
         denseRegister = sparseToDenseRegister(sparseRegister);
         sparseRegister = null;
@@ -390,7 +391,7 @@ public void setCount(long count) {
   }
 
   private long linearCount(int mVal, long numZeros) {
-    return (long) (Math.round(mVal * Math.log(mVal / ((double) numZeros))));
+    return (Math.round(mVal * Math.log(mVal / ((double) numZeros))));
   }
 
   // refer paper
@@ -463,7 +464,7 @@ public void merge(HyperLogLog hll) {
       sparseRegister.merge(hll.getHLLSparseRegister());
       // if after merge the sparse switching threshold is exceeded then change
       // to dense encoding
-      if (sparseRegister.getSize() > encodingSwitchThreshold) {
+      if (sparseRegister.isSizeGreaterThan(encodingSwitchThreshold)) {
         encoding = EncodingType.DENSE;
         denseRegister = sparseToDenseRegister(sparseRegister);
         sparseRegister = null;
@@ -485,7 +486,7 @@ public void merge(HyperLogLog hll) {
 
   /**
    * Reduces the accuracy of the HLL provided to a smaller size
-   * @param p0 
+   * @param p0
    *         - new p size for the new HyperLogLog (smaller or no change)
    * @return reduced (or same) HyperLogLog instance
    */
@@ -670,4 +671,9 @@ public boolean canMerge(NumDistinctValueEstimator o) {
     return o instanceof HyperLogLog;
   }
 
+  @VisibleForTesting
+  public int getEncodingSwitchThreshold() {
+    return encodingSwitchThreshold;
+  }
+
 }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HyperLogLogUtils.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HyperLogLogUtils.java
index a50d085fbc..78507372cb 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HyperLogLogUtils.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/common/ndv/hll/HyperLogLogUtils.java
@@ -25,8 +25,6 @@
 import java.io.OutputStream;
 import java.util.Arrays;
 import java.util.Map;
-import java.util.TreeMap;
-
 import org.apache.hadoop.hive.common.ndv.hll.HyperLogLog.EncodingType;
 
 /**
@@ -38,24 +36,24 @@ public class HyperLogLogUtils {
 
   /**
    * HyperLogLog is serialized using the following format
-   * 
+   *
    * <pre>
-   * |-4 byte-|------varlong----|varint (optional)|----------|  
+   * |-4 byte-|------varlong----|varint (optional)|----------|
    * ---------------------------------------------------------
    * | header | estimated-count | register-length | register |
    * ---------------------------------------------------------
-   * 
+   *
    * <b>4 byte header</b> is encoded like below
    * 3 bytes - HLL magic string to identify serialized stream
    * 4 bits  - p (number of bits to be used as register index)
    * 1       - spare bit (not used)
    * 3 bits  - encoding (000 - sparse, 001..110 - n bit packing, 111 - no bit packing)
-   * 
+   *
    * Followed by header are 3 fields that are required for reconstruction
    * of hyperloglog
    * Estimated count - variable length long to store last computed estimated count.
    *                   This is just for quick lookup without deserializing registers
-   * Register length - number of entries in the register (required only for 
+   * Register length - number of entries in the register (required only for
    *                   for sparse representation. For bit-packing, the register
    *                   length can be found from p)
    * </pre>
@@ -104,7 +102,7 @@ public static void serializeHLL(OutputStream out, HyperLogLog hll) throws IOExce
       byte[] register = hll.getHLLDenseRegister().getRegister();
       bitpackHLLRegister(out, register, bitWidth);
     } else if (enc.equals(EncodingType.SPARSE)) {
-      TreeMap<Integer, Byte> sparseMap = hll.getHLLSparseRegister().getSparseMap();
+      Map<Integer, Byte> sparseMap = hll.getHLLSparseRegister().getSparseMap();
 
       // write the number of elements in sparse map (required for
       // reconstruction)
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/common/ndv/hll/TestHyperLogLog.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/common/ndv/hll/TestHyperLogLog.java
index e014fb5e09..bed550a9d8 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/common/ndv/hll/TestHyperLogLog.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/common/ndv/hll/TestHyperLogLog.java
@@ -18,6 +18,7 @@
 package org.apache.hadoop.hive.common.ndv.hll;
 
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
 
 import org.apache.hadoop.hive.common.ndv.hll.HyperLogLog.EncodingType;
 import org.apache.hadoop.hive.metastore.annotation.MetastoreUnitTest;
@@ -49,27 +50,27 @@ public void testHLLDenseMerge() {
     double threshold = size > 40000 ? longRangeTolerance : shortRangeTolerance;
     double delta = threshold * size / 100;
     double delta4 = threshold * (4*size) / 100;
-    assertEquals((double) size, (double) hll.count(), delta);
-    assertEquals((double) size, (double) hll2.count(), delta);
+    assertEquals(size, hll.count(), delta);
+    assertEquals(size, hll2.count(), delta);
 
     // merge
     hll.merge(hll2);
-    assertEquals((double) 2 * size, (double) hll.count(), delta);
+    assertEquals((double) 2 * size, hll.count(), delta);
     assertEquals(EncodingType.DENSE, hll.getEncoding());
 
     // merge should update registers and hence the count
     hll.merge(hll2);
-    assertEquals((double) 2 * size, (double) hll.count(), delta);
+    assertEquals((double) 2 * size, hll.count(), delta);
     assertEquals(EncodingType.DENSE, hll.getEncoding());
 
     // new merge
     hll.merge(hll3);
-    assertEquals((double) 3 * size, (double) hll.count(), delta);
+    assertEquals((double) 3 * size, hll.count(), delta);
     assertEquals(EncodingType.DENSE, hll.getEncoding());
 
-    // valid merge -- register set size gets bigger (also 4k items 
+    // valid merge -- register set size gets bigger (also 4k items
     hll.merge(hll4);
-    assertEquals((double) 4 * size, (double) hll.count(), delta4);
+    assertEquals((double) 4 * size, hll.count(), delta4);
     assertEquals(EncodingType.DENSE, hll.getEncoding());
 
     // invalid merge -- smaller register merge to bigger
@@ -95,27 +96,27 @@ public void testHLLSparseMerge() {
     double threshold = size > 40000 ? longRangeTolerance : shortRangeTolerance;
     double delta = threshold * size / 100;
     double delta4 = threshold * (4*size) / 100;
-    assertEquals((double) size, (double) hll.count(), delta);
-    assertEquals((double) size, (double) hll2.count(), delta);
+    assertEquals(size, hll.count(), delta);
+    assertEquals(size, hll2.count(), delta);
 
     // merge
     hll.merge(hll2);
-    assertEquals((double) 2 * size, (double) hll.count(), delta);
+    assertEquals((double) 2 * size, hll.count(), delta);
     assertEquals(EncodingType.SPARSE, hll.getEncoding());
 
     // merge should update registers and hence the count
     hll.merge(hll2);
-    assertEquals((double) 2 * size, (double) hll.count(), delta);
+    assertEquals((double) 2 * size, hll.count(), delta);
     assertEquals(EncodingType.SPARSE, hll.getEncoding());
 
     // new merge
     hll.merge(hll3);
-    assertEquals((double) 3 * size, (double) hll.count(), delta);
+    assertEquals((double) 3 * size, hll.count(), delta);
     assertEquals(EncodingType.SPARSE, hll.getEncoding());
 
     // valid merge -- register set size gets bigger & dense automatically
     hll.merge(hll4);
-    assertEquals((double) 4 * size, (double) hll.count(), delta4);
+    assertEquals((double) 4 * size, hll.count(), delta4);
     assertEquals(EncodingType.DENSE, hll.getEncoding());
 
     // invalid merge -- smaller register merge to bigger
@@ -140,27 +141,27 @@ public void testHLLSparseDenseMerge() {
     }
     double threshold = size > 40000 ? longRangeTolerance : shortRangeTolerance;
     double delta = threshold * size / 100;
-    assertEquals((double) size, (double) hll.count(), delta);
-    assertEquals((double) size, (double) hll2.count(), delta);
+    assertEquals(size, hll.count(), delta);
+    assertEquals(size, hll2.count(), delta);
 
     // sparse-sparse merge
     hll.merge(hll2);
-    assertEquals((double) 2 * size, (double) hll.count(), delta);
+    assertEquals((double) 2 * size, hll.count(), delta);
     assertEquals(EncodingType.SPARSE, hll.getEncoding());
 
     // merge should update registers and hence the count
     hll.merge(hll2);
-    assertEquals((double) 2 * size, (double) hll.count(), delta);
+    assertEquals((double) 2 * size, hll.count(), delta);
     assertEquals(EncodingType.SPARSE, hll.getEncoding());
 
     // sparse-dense merge
     hll.merge(hll3);
-    assertEquals((double) 3 * size, (double) hll.count(), delta);
+    assertEquals((double) 3 * size, hll.count(), delta);
     assertEquals(EncodingType.DENSE, hll.getEncoding());
 
     // merge should convert hll2 to DENSE
     hll2.merge(hll4);
-    assertEquals((double) 2 * size, (double) hll2.count(), delta);
+    assertEquals((double) 2 * size, hll2.count(), delta);
     assertEquals(EncodingType.DENSE, hll2.getEncoding());
 
     // invalid merge -- smaller register merge to bigger
@@ -185,27 +186,27 @@ public void testHLLDenseSparseMerge() {
     }
     double threshold = size > 40000 ? longRangeTolerance : shortRangeTolerance;
     double delta = threshold * size / 100;
-    assertEquals((double) size, (double) hll.count(), delta);
-    assertEquals((double) size, (double) hll2.count(), delta);
+    assertEquals(size, hll.count(), delta);
+    assertEquals(size, hll2.count(), delta);
 
     // sparse-sparse merge
     hll.merge(hll2);
-    assertEquals((double) 2 * size, (double) hll.count(), delta);
+    assertEquals((double) 2 * size, hll.count(), delta);
     assertEquals(EncodingType.DENSE, hll.getEncoding());
 
     // merge should update registers and hence the count
     hll.merge(hll2);
-    assertEquals((double) 2 * size, (double) hll.count(), delta);
+    assertEquals((double) 2 * size, hll.count(), delta);
     assertEquals(EncodingType.DENSE, hll.getEncoding());
 
     // sparse-dense merge
     hll.merge(hll3);
-    assertEquals((double) 3 * size, (double) hll.count(), delta);
+    assertEquals((double) 3 * size, hll.count(), delta);
     assertEquals(EncodingType.DENSE, hll.getEncoding());
 
     // merge should convert hll3 to DENSE
     hll3.merge(hll4);
-    assertEquals((double) 2 * size, (double) hll3.count(), delta);
+    assertEquals((double) 2 * size, hll3.count(), delta);
     assertEquals(EncodingType.DENSE, hll3.getEncoding());
 
     // invalid merge -- smaller register merge to bigger
@@ -231,27 +232,27 @@ public void testHLLSparseOverflowMerge() {
     }
     double threshold = size > 40000 ? longRangeTolerance : shortRangeTolerance;
     double delta = threshold * size / 100;
-    assertEquals((double) size, (double) hll.count(), delta);
-    assertEquals((double) size, (double) hll2.count(), delta);
+    assertEquals(size, hll.count(), delta);
+    assertEquals(size, hll2.count(), delta);
 
     // sparse-sparse merge
     hll.merge(hll2);
-    assertEquals((double) 2 * size, (double) hll.count(), delta);
+    assertEquals((double) 2 * size, hll.count(), delta);
     assertEquals(EncodingType.SPARSE, hll.getEncoding());
 
     // merge should update registers and hence the count
     hll.merge(hll2);
-    assertEquals((double) 2 * size, (double) hll.count(), delta);
+    assertEquals((double) 2 * size, hll.count(), delta);
     assertEquals(EncodingType.SPARSE, hll.getEncoding());
 
     // sparse-sparse overload to dense
     hll.merge(hll3);
-    assertEquals((double) 3 * size, (double) hll.count(), delta);
+    assertEquals((double) 3 * size, hll.count(), delta);
     assertEquals(EncodingType.DENSE, hll.getEncoding());
 
     // merge should convert hll2 to DENSE
     hll2.merge(hll4);
-    assertEquals((double) 2 * size, (double) hll2.count(), delta);
+    assertEquals((double) 2 * size, hll2.count(), delta);
     assertEquals(EncodingType.DENSE, hll2.getEncoding());
 
     // invalid merge -- smaller register merge to bigger
@@ -268,7 +269,7 @@ public void testHLLSparseMoreRegisterBits() {
     }
     double threshold = size > 40000 ? longRangeTolerance : shortRangeTolerance;
     double delta = threshold * size / 100;
-    assertEquals((double) size, (double) hll.count(), delta);
+    assertEquals(size, hll.count(), delta);
   }
 
   @Test
@@ -296,7 +297,7 @@ public void testHLLSquash() {
               .squash(small.getNumRegisterIndexBits());
           assertEquals(small.count(), mush.count(), 0);
           double delta = Math.ceil(small.getStandardError()*size);
-          assertEquals((double) size, (double) mush.count(), delta);
+          assertEquals(size, mush.count(), delta);
         }
       }
     }
@@ -316,7 +317,7 @@ public void testHLLDenseDenseSquash() {
     }
 
     p14HLL.squash(p10HLL.getNumRegisterIndexBits());
-    assertEquals((double) size, p14HLL.count(), longRangeTolerance * size / 100.0);
+    assertEquals(size, p14HLL.count(), longRangeTolerance * size / 100.0);
   }
 
   @Test
@@ -333,6 +334,35 @@ public void testHLLSparseDenseSquash() {
     }
 
     p14HLL.squash(p10HLL.getNumRegisterIndexBits());
-    assertEquals((double) size, p14HLL.count(), longRangeTolerance * size / 100.0);
+    assertEquals(size, p14HLL.count(), longRangeTolerance * size / 100.0);
   }
+
+  @Test
+  public void testAbletoRetainAccuracyUpToSwitchThreshold70() {
+    testRetainAccuracy(70);
+  }
+
+  @Test
+  public void testAbletoRetainAccuracyUpToSwitchThresholdMaxPer2() {
+    int maxThreshold = HyperLogLog.builder().setSizeOptimized().build().getEncodingSwitchThreshold();
+    testRetainAccuracy(maxThreshold / 2);
+  }
+
+  @Test
+  public void testAbletoRetainAccuracyUpToSwitchThresholdMax() {
+    int maxThreshold = HyperLogLog.builder().setSizeOptimized().build().getEncodingSwitchThreshold();
+    testRetainAccuracy(maxThreshold);
+  }
+
+  private void testRetainAccuracy(int numElements) {
+    HyperLogLog h = HyperLogLog.builder().setSizeOptimized().build();
+    assertTrue(numElements <= h.getEncodingSwitchThreshold());
+    for (int ia = 0; ia <= 10; ia++) {
+      for (int i = 1; i <= numElements; i++) {
+        h.addLong(i);
+      }
+    }
+    assertEquals(numElements, h.estimateNumDistinctValues());
+  }
+
 }
