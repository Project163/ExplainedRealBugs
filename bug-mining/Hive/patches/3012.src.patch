diff --git a/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java b/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java
index d6067e7a23..e26031cd3a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java
@@ -134,7 +134,7 @@ public ResultSet run(PreparedStatement stmt) throws SQLException {
       }
     };
 
-    fileID = JDBCStatsUtils.truncateRowId(fileID);
+    JDBCStatsUtils.validateRowId(fileID);
     String keyPrefix = Utilities.escapeSqlLike(fileID) + "%";
     for (int failures = 0;; failures++) {
       try {
@@ -218,7 +218,7 @@ public Void run(PreparedStatement stmt) throws SQLException {
     };
     try {
 
-      rowID = JDBCStatsUtils.truncateRowId(rowID);
+      JDBCStatsUtils.validateRowId(rowID);
       String keyPrefix = Utilities.escapeSqlLike(rowID) + "%";
 
       PreparedStatement delStmt = Utilities.prepareWithRetry(conn,
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsPublisher.java b/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsPublisher.java
index c1621e029b..32826e740f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsPublisher.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsPublisher.java
@@ -139,10 +139,9 @@ public boolean publishStat(String fileID, Map<String, String> stats) {
           + " stats: " + JDBCStatsUtils.getSupportedStatistics());
       return false;
     }
-    String rowId = JDBCStatsUtils.truncateRowId(fileID);
+    JDBCStatsUtils.validateRowId(fileID);
     if (LOG.isInfoEnabled()) {
-      String truncateSuffix = (rowId != fileID) ? " (from " + fileID + ")" : ""; // object equality
-      LOG.info("Stats publishing for key " + rowId + truncateSuffix);
+      LOG.info("Stats publishing for key " + fileID);
     }
 
     Utilities.SQLCommand<Void> execUpdate = new Utilities.SQLCommand<Void>() {
@@ -157,7 +156,7 @@ public Void run(PreparedStatement stmt) throws SQLException {
 
     for (int failures = 0;; failures++) {
       try {
-        insStmt.setString(1, rowId);
+        insStmt.setString(1, fileID);
         for (int i = 0; i < JDBCStatsUtils.getSupportedStatistics().size(); i++) {
           insStmt.setString(i + 2, stats.get(supportedStatistics.get(i)));
         }
@@ -176,10 +175,10 @@ public Void run(PreparedStatement stmt) throws SQLException {
             for (i = 0; i < JDBCStatsUtils.getSupportedStatistics().size(); i++) {
               updStmt.setString(i + 1, stats.get(supportedStatistics.get(i)));
             }
-            updStmt.setString(supportedStatistics.size() + 1, rowId);
+            updStmt.setString(supportedStatistics.size() + 1, fileID);
             updStmt.setString(supportedStatistics.size() + 2,
                 stats.get(JDBCStatsUtils.getBasicStat()));
-            updStmt.setString(supportedStatistics.size() + 3, rowId);
+            updStmt.setString(supportedStatistics.size() + 3, fileID);
             Utilities.executeWithRetry(execUpdate, updStmt, waitWindow, maxRetries);
             return true;
           } catch (SQLRecoverableException ue) {
@@ -281,14 +280,36 @@ public boolean init(Configuration hconf) {
         stmt = conn.createStatement();
         stmt.setQueryTimeout(timeout);
 
+        // TODO: why is this not done using Hive db scripts?
         // Check if the table exists
         DatabaseMetaData dbm = conn.getMetaData();
-        rs = dbm.getTables(null, null, JDBCStatsUtils.getStatTableName(), null);
+        String tableName = JDBCStatsUtils.getStatTableName();
+        rs = dbm.getTables(null, null, tableName, null);
         boolean tblExists = rs.next();
         if (!tblExists) { // Table does not exist, create it
           String createTable = JDBCStatsUtils.getCreate("");
-          stmt.executeUpdate(createTable);          
-        }      
+          stmt.executeUpdate(createTable);
+        } else {
+          // Upgrade column name to allow for longer paths.
+          String idColName = JDBCStatsUtils.getIdColumnName();
+          int colSize = -1;
+          try {
+            rs.close();
+            rs = dbm.getColumns(null, null, tableName, idColName);
+            if (rs.next()) {
+              colSize = rs.getInt("COLUMN_SIZE");
+              if (colSize < JDBCStatsSetupConstants.ID_COLUMN_VARCHAR_SIZE) {
+                String alterTable = JDBCStatsUtils.getAlterIdColumn();
+                  stmt.executeUpdate(alterTable);
+              }
+            } else {
+              LOG.warn("Failed to update " + idColName + " - column not found");
+            }
+          } catch (Throwable t) {
+            LOG.warn("Failed to update " + idColName + " (size "
+                + (colSize == -1 ? "unknown" : colSize) + ")", t);
+          }
+        }
       }
     } catch (Exception e) {
       LOG.error("Error during JDBC initialization. ", e);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsSetupConstants.java b/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsSetupConstants.java
index b999f8ae99..17e109a23e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsSetupConstants.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsSetupConstants.java
@@ -34,7 +34,6 @@ public final class JDBCStatsSetupConstants {
 
   public static final String PART_STAT_RAW_DATA_SIZE_COLUMN_NAME = "RAW_DATA_SIZE";
 
-  // 255 is an old value that we will keep for now; it can be increased to 4000; limits are
   // MySQL - 65535, SQL Server - 8000, Oracle - 4000, Derby - 32762, Postgres - large.
-  public static final int ID_COLUMN_VARCHAR_SIZE = 255;
+  public static final int ID_COLUMN_VARCHAR_SIZE = 4000;
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsUtils.java
index 383314bdd9..59d94d5343 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsUtils.java
@@ -24,7 +24,6 @@
 import java.util.Map;
 
 import org.apache.hadoop.hive.common.StatsSetupConst;
-import org.apache.hadoop.util.hash.MurmurHash;
 
 public class JDBCStatsUtils {
 
@@ -136,6 +135,15 @@ public static String getCreate(String comment) {
     return create;
   }
 
+  /**
+   * Prepares ALTER TABLE query
+   */
+  public static String getAlterIdColumn() {
+    return "ALTER TABLE " + JDBCStatsUtils.getStatTableName() + " ALTER COLUMN "
+        + JDBCStatsUtils.getIdColumnName() + " VARCHAR("
+        + JDBCStatsSetupConstants.ID_COLUMN_VARCHAR_SIZE + ")";
+  }
+
   /**
    * Prepares UPDATE statement issued when updating existing statistics
    */
@@ -195,11 +203,10 @@ public static String getDeleteAggr(String rowID, String comment) {
 
   /**
    * Make sure the row ID fits into the row ID column in the table.
-   * @param rowId Row ID.
-   * @return Resulting row ID truncated to correct length, if necessary.
    */
-  public static String truncateRowId(String rowId) {
-    return (rowId.length() <= JDBCStatsSetupConstants.ID_COLUMN_VARCHAR_SIZE)
-        ? rowId : Integer.toHexString(MurmurHash.getInstance().hash(rowId.getBytes()));
+  public static void validateRowId(String rowId) {
+    if (rowId.length() > JDBCStatsSetupConstants.ID_COLUMN_VARCHAR_SIZE) {
+      throw new RuntimeException("ID is too big, client should have truncated it: " + rowId);
+    }
   }
 }
