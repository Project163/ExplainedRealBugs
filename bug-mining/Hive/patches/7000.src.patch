diff --git a/common/src/java/org/apache/hadoop/hive/common/type/TimestampTZ.java b/common/src/java/org/apache/hadoop/hive/common/type/TimestampTZ.java
index b5bd80bda8..af181ba124 100644
--- a/common/src/java/org/apache/hadoop/hive/common/type/TimestampTZ.java
+++ b/common/src/java/org/apache/hadoop/hive/common/type/TimestampTZ.java
@@ -92,6 +92,10 @@ public long getEpochSecond() {
     return zonedDateTime.toInstant().getEpochSecond();
   }
 
+  public long toEpochMilli() {
+    return zonedDateTime.toInstant().toEpochMilli();
+  }
+
   public int getNanos() {
     return zonedDateTime.toInstant().getNano();
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 1cd8008177..5126a7915d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -14979,7 +14979,7 @@ private void useCachedResult(QueryResultsCache.CacheEntry cacheEntry, boolean ne
   }
 
   private QueryResultsCache.QueryInfo createCacheQueryInfoForQuery(QueryResultsCache.LookupInfo lookupInfo) {
-    long queryTime = SessionState.get().getQueryCurrentTimestamp().getTime();
+    long queryTime = SessionState.get().getQueryCurrentTimestamp().toEpochMilli();
     return new QueryResultsCache.QueryInfo(queryTime, lookupInfo, queryState.getHiveOperation(),
         resultSchema, getTableAccessInfo(), getColumnAccessInfo(), inputs);
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java b/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
index ff523cc686..e406060642 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
@@ -28,7 +28,7 @@
 import java.net.URI;
 import java.net.URISyntaxException;
 import java.net.URLClassLoader;
-import java.sql.Timestamp;
+import java.time.Instant;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
@@ -56,6 +56,9 @@
 import org.apache.hadoop.hive.common.FileUtils;
 import org.apache.hadoop.hive.common.JavaUtils;
 import org.apache.hadoop.hive.common.log.ProgressMonitor;
+import org.apache.hadoop.hive.common.type.Timestamp;
+import org.apache.hadoop.hive.common.type.TimestampTZ;
+import org.apache.hadoop.hive.common.type.TimestampTZUtil;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
 import org.apache.hadoop.hive.conf.HiveConfUtil;
@@ -305,7 +308,7 @@ public enum AuthorizationMode{V1, V2};
   /**
    * CURRENT_TIMESTAMP value for query
    */
-  private Timestamp queryCurrentTimestamp;
+  private Instant queryCurrentTimestamp;
 
   private final ResourceMaps resourceMaps;
 
@@ -1960,14 +1963,16 @@ public String getNextValuesTempTableSuffix() {
    * Initialize current timestamp, other necessary query initialization.
    */
   public void setupQueryCurrentTimestamp() {
-    queryCurrentTimestamp = new Timestamp(System.currentTimeMillis());
+    queryCurrentTimestamp = Instant.now();
 
     // Provide a facility to set current timestamp during tests
     if (sessionConf.getBoolVar(ConfVars.HIVE_IN_TEST)) {
       String overrideTimestampString =
           HiveConf.getVar(sessionConf, HiveConf.ConfVars.HIVETESTCURRENTTIMESTAMP, (String)null);
       if (overrideTimestampString != null && overrideTimestampString.length() > 0) {
-        queryCurrentTimestamp = Timestamp.valueOf(overrideTimestampString);
+        TimestampTZ zonedDateTime = TimestampTZUtil.convert(
+            Timestamp.valueOf(overrideTimestampString), sessionConf.getLocalTimeZone());
+        queryCurrentTimestamp = zonedDateTime.getZonedDateTime().toInstant();
       }
     }
   }
@@ -1976,7 +1981,7 @@ public void setupQueryCurrentTimestamp() {
    * Get query current timestamp
    * @return
    */
-  public Timestamp getQueryCurrentTimestamp() {
+  public Instant getQueryCurrentTimestamp() {
     return queryCurrentTimestamp;
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java
index cffd10beee..0e58dd0d08 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java
@@ -17,6 +17,7 @@
  */
 package org.apache.hadoop.hive.ql.udf.generic;
 
+import java.time.ZonedDateTime;
 import org.apache.hadoop.hive.common.type.Date;
 import org.apache.hadoop.hive.ql.exec.Description;
 import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
@@ -49,8 +50,11 @@ public ObjectInspector initialize(ObjectInspector[] arguments)
     }
 
     if (currentDate == null) {
-      Date dateVal =
-          Date.valueOf(SessionState.get().getQueryCurrentTimestamp().toString().substring(0, 10));
+      SessionState ss = SessionState.get();
+      ZonedDateTime dateTime = ss.getQueryCurrentTimestamp().atZone(
+          ss.getConf().getLocalTimeZone());
+      Date dateVal = Date.valueOf(
+          dateTime.toString().substring(0, 10));
       currentDate = new DateWritableV2(dateVal);
     }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java
index d9447f126b..281294c6d7 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java
@@ -17,6 +17,7 @@
  */
 package org.apache.hadoop.hive.ql.udf.generic;
 
+import java.time.ZonedDateTime;
 import org.apache.hadoop.hive.common.type.Timestamp;
 import org.apache.hadoop.hive.ql.exec.Description;
 import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
@@ -49,9 +50,11 @@ public ObjectInspector initialize(ObjectInspector[] arguments)
     }
 
     if (currentTimestamp == null) {
-      java.sql.Timestamp ts = SessionState.get().getQueryCurrentTimestamp();
+      SessionState ss = SessionState.get();
+      ZonedDateTime dateTime = ss.getQueryCurrentTimestamp().atZone(
+          ss.getConf().getLocalTimeZone());
       currentTimestamp = new TimestampWritableV2(
-          Timestamp.ofEpochMilli(ts.getTime(), ts.getNanos()));
+          Timestamp.valueOf(dateTime.toLocalDateTime().toString()));
     }
 
     return PrimitiveObjectInspectorFactory.writableTimestampObjectInspector;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java
index 557ab792ea..d560c62adb 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java
@@ -45,7 +45,7 @@ protected void initializeInput(ObjectInspector[] arguments) throws UDFArgumentEx
     } else {
       if (currentTimestamp == null) {
         currentTimestamp = new LongWritable(0);
-        setValueFromTs(currentTimestamp, Timestamp.ofEpochMilli(SessionState.get().getQueryCurrentTimestamp().getTime()));
+        setValueFromTs(currentTimestamp, Timestamp.ofEpochMilli(SessionState.get().getQueryCurrentTimestamp().toEpochMilli()));
         String msg = "unix_timestamp(void) is deprecated. Use current_timestamp instead.";
         SessionState.getConsole().printInfo(msg, false);
       }
diff --git a/ql/src/test/results/clientpositive/llap/current_date_timestamp.q.out b/ql/src/test/results/clientpositive/llap/current_date_timestamp.q.out
index afed94891b..280ffb07e1 100644
--- a/ql/src/test/results/clientpositive/llap/current_date_timestamp.q.out
+++ b/ql/src/test/results/clientpositive/llap/current_date_timestamp.q.out
@@ -61,7 +61,7 @@ STAGE PLANS:
           alias: alltypesorc
           GatherStats: false
           Select Operator
-            expressions: TIMESTAMP'2012-01-01 09:02:03' (type: timestamp)
+            expressions: TIMESTAMP'2012-01-01 01:02:03' (type: timestamp)
             outputColumnNames: _col0
             ListSink
 
@@ -234,11 +234,11 @@ POSTHOOK: query: select unix_timestamp(current_timestamp()),
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alltypesorc
 #### A masked pattern was here ####
-1325408523	9	2	3
-1325408523	9	2	3
-1325408523	9	2	3
-1325408523	9	2	3
-1325408523	9	2	3
+1325379723	1	2	3
+1325379723	1	2	3
+1325379723	1	2	3
+1325379723	1	2	3
+1325379723	1	2	3
 PREHOOK: query: select to_date(current_timestamp()),
                            year(current_timestamp()),
                            month(current_timestamp()),
@@ -321,7 +321,7 @@ POSTHOOK: query: select current_timestamp() - current_timestamp(),
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alltypesorc
 #### A masked pattern was here ####
-0 00:00:00.000000000	0 09:02:03.000000000	-0 09:02:03.000000000	0 00:00:00.000000000
+0 00:00:00.000000000	0 01:02:03.000000000	-0 01:02:03.000000000	0 00:00:00.000000000
 PREHOOK: query: select ctimestamp1 - current_date(),
         ctimestamp1- ctimestamp2,
         current_date() - current_date(),
@@ -357,11 +357,11 @@ POSTHOOK: query: select current_date, current_timestamp from src limit 5
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
-2012-01-01	2012-01-01 09:02:03
-2012-01-01	2012-01-01 09:02:03
-2012-01-01	2012-01-01 09:02:03
-2012-01-01	2012-01-01 09:02:03
-2012-01-01	2012-01-01 09:02:03
+2012-01-01	2012-01-01 01:02:03
+2012-01-01	2012-01-01 01:02:03
+2012-01-01	2012-01-01 01:02:03
+2012-01-01	2012-01-01 01:02:03
+2012-01-01	2012-01-01 01:02:03
 PREHOOK: query: select `[kv]+.+` from srcpart order by key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart
diff --git a/ql/src/test/results/clientpositive/llap/results_cache_2.q.out b/ql/src/test/results/clientpositive/llap/results_cache_2.q.out
index 11dbacf3d1..a042a68e74 100644
--- a/ql/src/test/results/clientpositive/llap/results_cache_2.q.out
+++ b/ql/src/test/results/clientpositive/llap/results_cache_2.q.out
@@ -115,7 +115,7 @@ group by c1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
-2012-01-01 09:02:03	10
+2012-01-01 01:02:03	10
 test.comment=Queries using non-deterministic functions should not use results cache
 PREHOOK: query: explain
 select c1, count(*)
@@ -178,7 +178,7 @@ STAGE PLANS:
                 outputColumnNames: _col0, _col1
                 Statistics: Num rows: 1 Data size: 12 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
-                  expressions: TIMESTAMP'2012-01-01 09:02:03' (type: timestamp), _col1 (type: bigint)
+                  expressions: TIMESTAMP'2012-01-01 01:02:03' (type: timestamp), _col1 (type: bigint)
                   outputColumnNames: _col0, _col1
                   Statistics: Num rows: 1 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
