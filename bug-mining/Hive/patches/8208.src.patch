diff --git a/ql/src/java/org/apache/hadoop/hive/ql/log/HushableRandomAccessFileAppender.java b/ql/src/java/org/apache/hadoop/hive/ql/log/HushableRandomAccessFileAppender.java
index 7e60435b1a..0ff66df441 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/log/HushableRandomAccessFileAppender.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/log/HushableRandomAccessFileAppender.java
@@ -20,11 +20,7 @@
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Map;
-import java.util.concurrent.TimeUnit;
 
-import com.google.common.cache.CacheBuilder;
-import com.google.common.cache.CacheLoader;
-import com.google.common.cache.LoadingCache;
 import org.apache.logging.log4j.core.Filter;
 import org.apache.logging.log4j.core.Layout;
 import org.apache.logging.log4j.core.LogEvent;
@@ -51,17 +47,6 @@
 public final class HushableRandomAccessFileAppender extends
     AbstractOutputStreamAppender<RandomAccessFileManager> {
 
-  private static final LoadingCache<String, String> CLOSED_FILES =
-      CacheBuilder.newBuilder().maximumSize(1000)
-          .expireAfterWrite(1, TimeUnit.SECONDS)
-          .build(new CacheLoader<String, String>() {
-            @Override
-            public String load(String key) throws Exception {
-              return key;
-            }
-          });
-
-
   private final String fileName;
   private Object advertisement;
   private final Advertiser advertiser;
@@ -86,7 +71,6 @@ private HushableRandomAccessFileAppender(final String name, final Layout<? exten
   @Override
   public void stop() {
     super.stop();
-    CLOSED_FILES.put(fileName, fileName);
     if (advertiser != null) {
       advertiser.unadvertise(advertisement);
     }
@@ -188,22 +172,6 @@ public static HushableRandomAccessFileAppender createAppender(
           + name);
       return null;
     }
-
-    /**
-     * In corner cases (e.g exceptions), there seem to be some race between
-     * com.lmax.disruptor.BatchEventProcessor and HS2 thread which is actually
-     * stopping the logs. Because of this, same filename is recreated and
-     * stop() would never be invoked on that instance, causing a mem leak.
-     * To prevent same file being recreated within very short time,
-     * CLOSED_FILES are tracked in cache with TTL of 1 second. This
-     * also helps in avoiding the stale directories created.
-     */
-    if (CLOSED_FILES.getIfPresent(fileName) != null) {
-      // Do not create another file, which got closed in last 5 seconds
-      LOGGER.error(fileName + " was closed recently.");
-      return null;
-    }
-
     if (layout == null) {
       layout = PatternLayout.createDefaultLayout();
     }
