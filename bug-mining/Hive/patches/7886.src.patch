diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/BaseReplicationAcrossInstances.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/BaseReplicationAcrossInstances.java
index 8265a7a2a5..e03efd80fc 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/BaseReplicationAcrossInstances.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/BaseReplicationAcrossInstances.java
@@ -57,6 +57,7 @@ static void internalBeforeClassSetup(Map<String, String> overrides, Class clazz)
     conf.set("dfs.client.use.datanode.hostname", "true");
     conf.set("hadoop.proxyuser." + Utils.getUGI().getShortUserName() + ".hosts", "*");
     conf.set("hive.repl.cmrootdir", "/tmp/");
+    conf.set("dfs.namenode.acls.enabled", "true");
     MiniDFSCluster miniDFSCluster =
         new MiniDFSCluster.Builder(conf).numDataNodes(1).format(true).build();
     Map<String, String> localOverrides = new HashMap<String, String>() {{
diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenariosExternalTables.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenariosExternalTables.java
index 2b04ba66db..d33ec4ba1c 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenariosExternalTables.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenariosExternalTables.java
@@ -21,6 +21,10 @@
 import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.permission.AclEntry;
+import org.apache.hadoop.fs.permission.AclEntryScope;
+import org.apache.hadoop.fs.permission.AclEntryType;
+import org.apache.hadoop.fs.permission.FsAction;
 import org.apache.hadoop.fs.permission.FsPermission;
 import org.apache.hadoop.hdfs.DistributedFileSystem;
 import org.apache.hadoop.hive.conf.HiveConf;
@@ -44,11 +48,9 @@
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.metadata.Partition;
 import org.apache.hadoop.hive.ql.metadata.Hive;
-import org.apache.hadoop.hive.ql.parse.TestReplicationScenarios;
 import org.apache.hadoop.hive.ql.parse.repl.dump.Utils;
 import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe;
-import org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe;
 import org.apache.hadoop.security.UserGroupInformation;
 import org.junit.After;
 import org.junit.Assert;
@@ -340,6 +342,73 @@ public void externalTableReplicationWithCustomPathsLazyCopy() throws Throwable {
     assertTablePartitionLocation(primaryDbName + ".a", replicatedDbName + ".a");
   }
 
+  @Test
+  public void testExternalTableLocationACLPreserved() throws Throwable {
+
+    // Create data file with data for external table.
+    Path externalTableLocation = new Path(
+        "/" + testName.getMethodName() + "/" + primaryDbName + "/" + "a/");
+    DistributedFileSystem fs = primary.miniDFSCluster.getFileSystem();
+    fs.mkdirs(externalTableLocation, new FsPermission("777"));
+
+    Path externalFileLoc = new Path(externalTableLocation, "file1.txt");
+    try (FSDataOutputStream outputStream = fs.create(externalFileLoc)) {
+      outputStream.write("1,2\n".getBytes());
+      outputStream.write("13,21\n".getBytes());
+    }
+
+    // Set some ACL's on the table directory and the data file.
+    List<AclEntry> aclEntries = new ArrayList<>();
+    AclEntry aeUser =
+        new AclEntry.Builder().setName("user").setScope(AclEntryScope.ACCESS)
+            .setType(AclEntryType.USER).setPermission(FsAction.ALL).build();
+    AclEntry aeGroup =
+        new AclEntry.Builder().setName("group").setScope(AclEntryScope.ACCESS)
+            .setType(AclEntryType.GROUP).setPermission(FsAction.ALL).build();
+    AclEntry aeOther = new AclEntry.Builder().setScope(AclEntryScope.ACCESS)
+        .setType(AclEntryType.OTHER).setPermission(FsAction.ALL).build();
+
+    aclEntries.add(aeUser);
+    aclEntries.add(aeGroup);
+    aclEntries.add(aeOther);
+
+    fs.modifyAclEntries(externalTableLocation, aclEntries);
+    fs.modifyAclEntries(externalFileLoc, aclEntries);
+
+    // Run bootstrap with distcp options to preserve ACL.
+    List<String> withClause = Arrays
+        .asList("'distcp.options.update'=''", "'distcp.options.puga'=''",
+            "'" + HiveConf.ConfVars.REPL_RUN_DATA_COPY_TASKS_ON_TARGET.varname
+                + "'='true'");
+
+    primary.run("use " + primaryDbName).run(
+        "create external table a (i int, j int) "
+            + "row format delimited fields terminated by ',' " + "location '"
+            + externalTableLocation.toUri() + "'")
+        .dump(primaryDbName, withClause);
+
+    // Verify load is success and has the appropriate data.
+    replica.load(replicatedDbName, primaryDbName, withClause)
+        .run("use " + replicatedDbName).run("select i From a")
+        .verifyResults(new String[] {"1", "13"}).run("select j from a")
+        .verifyResults(new String[] {"2", "21"});
+
+    // Verify the ACL's of the destination table directory and data file are
+    // same as that of source.
+    Hive hiveForReplica = Hive.get(replica.hiveConf);
+    org.apache.hadoop.hive.ql.metadata.Table replicaTable =
+        hiveForReplica.getTable(replicatedDbName + ".a");
+    Path dataLocation = replicaTable.getDataLocation();
+
+    assertEquals("ACL entries are not same for the data file.",
+        fs.getAclStatus(externalFileLoc).getEntries().size(),
+        fs.getAclStatus(new Path(dataLocation, "file1.txt")).getEntries()
+            .size());
+    assertEquals("ACL entries are not same for the table directory.",
+        fs.getAclStatus(externalTableLocation).getEntries().size(),
+        fs.getAclStatus(dataLocation).getEntries().size());
+  }
+
   /**
    * @param sourceTableName  -- Provide the fully qualified table name
    * @param replicaTableName -- Provide the fully qualified table name
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/DirCopyTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/DirCopyTask.java
index 43d45a95b2..f5346dacad 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/DirCopyTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/DirCopyTask.java
@@ -18,6 +18,9 @@
 package org.apache.hadoop.hive.ql.exec.repl;
 
 import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.permission.AclEntry;
+import org.apache.hadoop.fs.permission.AclStatus;
+import org.apache.hadoop.fs.permission.AclUtil;
 import org.apache.hadoop.hive.common.FileUtils;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.ErrorMsg;
@@ -39,6 +42,9 @@
 import java.io.IOException;
 import java.net.URI;
 import java.util.Collections;
+import java.util.List;
+
+import static org.apache.hadoop.hive.metastore.utils.HdfsUtils.constructDistCpOptions;
 
 /**
  * DirCopyTask, mainly to be used to copy External table data.
@@ -70,9 +76,40 @@ private boolean createAndSetPathOwner(Path destPath, Path sourcePath) throws IOE
             destPath, sourcePath, status.getOwner(), status.getGroup(), status.getPermission());
     destPath.getFileSystem(conf).setOwner(destPath, status.getOwner(), status.getGroup());
     destPath.getFileSystem(conf).setPermission(destPath, status.getPermission());
+    setAclsToTarget(status, sourcePath, destPath);
     return createdDir;
   }
 
+  private void setAclsToTarget(FileStatus sourceStatus, Path sourcePath,
+      Path destPath) throws IOException {
+    // Check if distCp options contains preserve ACL.
+    if (isPreserveAcl()) {
+      AclStatus sourceAcls =
+          sourcePath.getFileSystem(conf).getAclStatus(sourcePath);
+      if (sourceAcls != null && sourceAcls.getEntries().size() > 0) {
+        destPath.getFileSystem(conf).removeAcl(destPath);
+        List<AclEntry> effectiveAclEntries = AclUtil
+            .getAclFromPermAndEntries(sourceStatus.getPermission(),
+                sourceAcls.getEntries());
+        destPath.getFileSystem(conf).setAcl(destPath, effectiveAclEntries);
+      }
+    }
+  }
+
+  private boolean isPreserveAcl() {
+    List<String> distCpOptions = constructDistCpOptions(conf);
+    for (String option : distCpOptions) {
+      if (option.startsWith("-p")) {
+        if (option.contains("a")) {
+          return true;
+        } else {
+          return false;
+        }
+      }
+    }
+    return false;
+  }
+
   private boolean setTargetPathOwner(Path targetPath, Path sourcePath, UserGroupInformation proxyUser)
             throws IOException, InterruptedException {
     if (proxyUser == null) {
diff --git a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/HdfsUtils.java b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/HdfsUtils.java
index 37d42a19e9..4f03e919bc 100644
--- a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/HdfsUtils.java
+++ b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/HdfsUtils.java
@@ -193,15 +193,7 @@ public static boolean runDistCp(List<Path> srcPaths, Path dst, Configuration con
 
   private static List<String> constructDistCpParams(List<Path> srcPaths, Path dst,
                                                     Configuration conf) {
-    List<String> params = new ArrayList<>();
-    for (Map.Entry<String,String> entry : conf.getPropsWithPrefix(DISTCP_OPTIONS_PREFIX).entrySet()){
-      String distCpOption = entry.getKey();
-      String distCpVal = entry.getValue();
-      params.add("-" + distCpOption);
-      if ((distCpVal != null) && (!distCpVal.isEmpty())){
-        params.add(distCpVal);
-      }
-    }
+    List<String> params = constructDistCpOptions(conf);
     if (params.size() == 0){
       // if no entries were added via conf, we initiate our defaults
       params.add("-update");
@@ -214,6 +206,21 @@ private static List<String> constructDistCpParams(List<Path> srcPaths, Path dst,
     return params;
   }
 
+  public static List<String> constructDistCpOptions(Configuration conf) {
+    List<String> options = new ArrayList<>();
+    for (Map.Entry<String, String> entry : conf
+        .getPropsWithPrefix(DISTCP_OPTIONS_PREFIX).entrySet()) {
+      String distCpOption = entry.getKey();
+      String distCpVal = entry.getValue();
+      options.add("-" + distCpOption);
+      if ((distCpVal != null) && (!distCpVal.isEmpty())) {
+        options.add(distCpVal);
+      }
+    }
+    return options;
+  }
+
+
   public static Path getFileIdPath(
       FileSystem fileSystem, Path path, long fileId) {
     return (fileSystem instanceof DistributedFileSystem)
