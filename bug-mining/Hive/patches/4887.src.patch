diff --git a/ql/src/java/org/apache/hadoop/hive/ql/processors/ResetProcessor.java b/ql/src/java/org/apache/hadoop/hive/ql/processors/ResetProcessor.java
index e67422b0a9..bbd45010ea 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/processors/ResetProcessor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/processors/ResetProcessor.java
@@ -18,41 +18,134 @@
 
 package org.apache.hadoop.hive.ql.processors;
 
+import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.List;
+import java.util.Map;
 
+import org.apache.commons.lang3.StringUtils;
 import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.conf.HiveVariableSource;
+import org.apache.hadoop.hive.conf.SystemVariables;
+import org.apache.hadoop.hive.conf.VariableSubstitution;
 import org.apache.hadoop.hive.ql.CommandNeedRetryException;
+import org.apache.hadoop.hive.ql.metadata.Hive;
 import org.apache.hadoop.hive.ql.security.authorization.plugin.HiveOperationType;
 import org.apache.hadoop.hive.ql.session.SessionState;
 
+import com.google.common.collect.Lists;
+
 public class ResetProcessor implements CommandProcessor {
 
   @Override
   public void init() {
   }
 
+  private final static String DEFAULT_ARG = "-d";
+
   @Override
   public CommandProcessorResponse run(String command) throws CommandNeedRetryException {
     SessionState ss = SessionState.get();
 
     CommandProcessorResponse authErrResp =
         CommandUtil.authorizeCommand(ss, HiveOperationType.RESET, Arrays.asList(command));
-    if(authErrResp != null){
+    if (authErrResp != null) {
       // there was an authorization issue
       return authErrResp;
     }
-
-    if (ss.getOverriddenConfigurations().isEmpty()) {
+    command = command.trim();
+    if (StringUtils.isBlank(command)) {
+      resetOverridesOnly(ss);
       return new CommandProcessorResponse(0);
     }
+    String[] parts = command.split("\\s+");
+    boolean isDefault = false;
+    List<String> varnames = new ArrayList<>(parts.length);
+    for (String part : parts) {
+      if (part.isEmpty()) continue;
+      if (DEFAULT_ARG.equals(part)) {
+        isDefault = true;
+      } else {
+        varnames.add(part);
+      }
+    }
+    if (varnames.isEmpty()) {
+      return new CommandProcessorResponse(1, "No variable names specified", "42000");
+    }
+    String message = "";
+    for (String varname : varnames) {
+      if (isDefault) {
+        if (!message.isEmpty()) {
+          message += ", ";
+        }
+        message += varname;
+        resetToDefault(ss, varname);
+      } else {
+        resetOverrideOnly(ss, varname);
+      }
+    }
+    return new CommandProcessorResponse(0, isDefault
+        ? Lists.newArrayList("Resetting " + message + " to default values") : null);
+  }
+
+  private void resetOverridesOnly(SessionState ss) {
+    if (ss.getOverriddenConfigurations().isEmpty()) return;
     HiveConf conf = new HiveConf();
     for (String key : ss.getOverriddenConfigurations().keySet()) {
-      String value = conf.get(key);
-      if (value != null) {
-        ss.getConf().set(key, value);
-      }
+      setSessionVariableFromConf(ss, key, conf);
     }
     ss.getOverriddenConfigurations().clear();
-    return new CommandProcessorResponse(0);
+  }
+
+  private void resetOverrideOnly(SessionState ss, String varname) {
+    if (!ss.getOverriddenConfigurations().containsKey(varname)) return;
+    setSessionVariableFromConf(ss, varname, new HiveConf());
+    ss.getOverriddenConfigurations().remove(varname);
+  }
+
+  private void setSessionVariableFromConf(SessionState ss, String varname,
+      HiveConf conf) {
+    String value = conf.get(varname);
+    if (value != null) {
+      ss.getConf().set(varname, value);
+    }
+  }
+
+  private CommandProcessorResponse resetToDefault(SessionState ss, String varname) {
+    varname = varname.trim();
+    try {
+      String nonErrorMessage = null;
+      if (varname.startsWith(SystemVariables.HIVECONF_PREFIX)){
+        String propName = varname.substring(SystemVariables.HIVECONF_PREFIX.length());
+        nonErrorMessage = SetProcessor.setConf(
+            varname, propName, getConfVar(propName).getDefaultValue(), false);
+      } else if (varname.startsWith(SystemVariables.METACONF_PREFIX)) {
+        String propName = varname.substring(SystemVariables.METACONF_PREFIX.length());
+        HiveConf.ConfVars confVars = getConfVar(propName);
+        Hive.get(ss.getConf()).setMetaConf(propName, new VariableSubstitution(new HiveVariableSource() {
+          @Override
+          public Map<String, String> getHiveVariable() {
+            return SessionState.get().getHiveVariables();
+          }
+        }).substitute(ss.getConf(), confVars.getDefaultValue()));
+      } else {
+        String defaultVal = getConfVar(varname).getDefaultValue();
+        nonErrorMessage = SetProcessor.setConf(varname, varname, defaultVal, true);
+        if (varname.equals(HiveConf.ConfVars.HIVE_SESSION_HISTORY_ENABLED.toString())) {
+          SessionState.get().updateHistory(Boolean.parseBoolean(defaultVal), ss);
+        }
+      }
+      return nonErrorMessage == null ? new CommandProcessorResponse(0)
+        : new CommandProcessorResponse(0, Lists.newArrayList(nonErrorMessage));
+    } catch (Exception e) {
+      return new CommandProcessorResponse(1, e.getMessage(), "42000",
+          e instanceof IllegalArgumentException ? null : e);
+    }
+  }
+
+  private static HiveConf.ConfVars getConfVar(String propName) {
+    HiveConf.ConfVars confVars = HiveConf.getConfVars(propName);
+    if (confVars == null) throw new IllegalArgumentException(propName + " not found");
+    return confVars;
   }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java b/ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java
index 2e13dab934..c9d06ba33d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java
@@ -24,7 +24,6 @@
 
 import static org.apache.hadoop.hive.conf.SystemVariables.*;
 
-import java.util.HashSet;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
@@ -179,7 +178,7 @@ public Map<String, String> getHiveVariable() {
   /**
    * @return A console message that is not strong enough to fail the command (e.g. deprecation).
    */
-  private static String setConf(String varname, String key, String varvalue, boolean register)
+  static String setConf(String varname, String key, String varvalue, boolean register)
         throws IllegalArgumentException {
     String result = null;
     HiveConf conf = SessionState.get().getConf();
diff --git a/ql/src/test/queries/clientpositive/reset_conf.q b/ql/src/test/queries/clientpositive/reset_conf.q
index 8ddde23645..8420d0225b 100644
--- a/ql/src/test/queries/clientpositive/reset_conf.q
+++ b/ql/src/test/queries/clientpositive/reset_conf.q
@@ -9,3 +9,21 @@ reset;
 
 set hive.skewjoin.key;
 set hive.skewjoin.mapjoin.min.split;
+
+set hive.skewjoin.key=300000;
+set hive.skewjoin.mapjoin.min.split=256000000;
+select 'After setting hive.skewjoin.key and hive.skewjoin.mapjoin.min.split';
+set hive.skewjoin.key;
+
+reset -d hive.skewjoin.key;
+select 'After resetting hive.skewjoin.key to default';
+set hive.skewjoin.key;
+set hive.skewjoin.mapjoin.min.split;
+
+set hive.skewjoin.key=300000;
+
+reset -d hive.skewjoin.key hive.skewjoin.mapjoin.min.split;
+select 'After resetting both to default';
+set hive.skewjoin.key;
+set hive.skewjoin.mapjoin.min.split;
+
diff --git a/ql/src/test/queries/clientpositive/set_metaconf.q b/ql/src/test/queries/clientpositive/set_metaconf.q
index a679489146..6186122aec 100644
--- a/ql/src/test/queries/clientpositive/set_metaconf.q
+++ b/ql/src/test/queries/clientpositive/set_metaconf.q
@@ -4,3 +4,7 @@ set metaconf:hive.metastore.try.direct.sql;
 set metaconf:hive.metastore.try.direct.sql=false;
 set metaconf:hive.metastore.try.direct.sql;
 set hive.metastore.try.direct.sql;
+
+reset -d metaconf:hive.metastore.try.direct.sql;
+set metaconf:hive.metastore.try.direct.sql;
+set hive.metastore.try.direct.sql;
diff --git a/ql/src/test/results/clientpositive/reset_conf.q.out b/ql/src/test/results/clientpositive/reset_conf.q.out
index e4e15be028..12f2555f27 100644
--- a/ql/src/test/results/clientpositive/reset_conf.q.out
+++ b/ql/src/test/results/clientpositive/reset_conf.q.out
@@ -4,3 +4,35 @@ hive.skewjoin.key=300000
 hive.skewjoin.mapjoin.min.split=256000000
 hive.skewjoin.key=100000
 hive.skewjoin.mapjoin.min.split=33554432
+PREHOOK: query: select 'After setting hive.skewjoin.key and hive.skewjoin.mapjoin.min.split'
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+#### A masked pattern was here ####
+POSTHOOK: query: select 'After setting hive.skewjoin.key and hive.skewjoin.mapjoin.min.split'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+#### A masked pattern was here ####
+After setting hive.skewjoin.key and hive.skewjoin.mapjoin.min.split
+hive.skewjoin.key=300000
+PREHOOK: query: select 'After resetting hive.skewjoin.key to default'
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+#### A masked pattern was here ####
+POSTHOOK: query: select 'After resetting hive.skewjoin.key to default'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+#### A masked pattern was here ####
+After resetting hive.skewjoin.key to default
+hive.skewjoin.key=100000
+hive.skewjoin.mapjoin.min.split=256000000
+PREHOOK: query: select 'After resetting both to default'
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+#### A masked pattern was here ####
+POSTHOOK: query: select 'After resetting both to default'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+#### A masked pattern was here ####
+After resetting both to default
+hive.skewjoin.key=100000
+hive.skewjoin.mapjoin.min.split=33554432
diff --git a/ql/src/test/results/clientpositive/set_metaconf.q.out b/ql/src/test/results/clientpositive/set_metaconf.q.out
index ec33e59cca..41b8957e00 100644
--- a/ql/src/test/results/clientpositive/set_metaconf.q.out
+++ b/ql/src/test/results/clientpositive/set_metaconf.q.out
@@ -1,3 +1,5 @@
 metaconf:hive.metastore.try.direct.sql=true
 metaconf:hive.metastore.try.direct.sql=false
 hive.metastore.try.direct.sql=true
+metaconf:hive.metastore.try.direct.sql=true
+hive.metastore.try.direct.sql=true
