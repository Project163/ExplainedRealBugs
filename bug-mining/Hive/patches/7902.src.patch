diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/BasePartitionEvaluator.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/BasePartitionEvaluator.java
index 77ddca95a3..4dfb34daec 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/BasePartitionEvaluator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/BasePartitionEvaluator.java
@@ -65,26 +65,28 @@ public class BasePartitionEvaluator {
    * Internal class to represent a window range in a partition by searching the
    * relative position (ROWS) or relative value (RANGE) of the current row
    */
-  protected class Range
+  protected static class Range
   {
     int start;
     int end;
     PTFPartition p;
+    /**
+     * When there are no parameters specified, partition iterator can be made faster;
+     * In such cases, it need not materialize the ROW from RowContainer. This saves lots of IO.
+     */
+    private final boolean optimized;
 
-    public Range(int start, int end, PTFPartition p)
+    public Range(int start, int end, PTFPartition p, boolean optimized)
     {
       this.start = start;
       this.end = end;
       this.p = p;
+      this.optimized = optimized;
     }
 
     public PTFPartitionIterator<Object> iterator()
     {
-      /**
-       * When there are no parameters specified, partition iterator can be made faster;
-       * In such cases, it need not materialize the ROW from RowContainer. This saves lots of IO.
-       */
-      return p.range(start, end, (parameters == null || parameters.isEmpty()));
+      return p.range(start, end, optimized);
     }
 
     public int getDiff(Range prevRange) {
@@ -108,13 +110,17 @@ private static abstract class TypeOperationBase<ResultType> {
   private static class TypeOperationLongWritable extends TypeOperationBase<LongWritable> {
     @Override
     public LongWritable add(LongWritable t1, LongWritable t2) {
-      if (t1 == null && t2 == null) return null;
+      if (t1 == null && t2 == null) {
+        return null;
+      }
       return new LongWritable((t1 == null ? 0 : t1.get()) + (t2 == null ? 0 : t2.get()));
     }
 
     @Override
     public LongWritable minus(LongWritable t1, LongWritable t2) {
-      if (t1 == null && t2 == null) return null;
+      if (t1 == null && t2 == null) {
+        return null;
+      }
       return new LongWritable((t1 == null ? 0 : t1.get()) - (t2 == null ? 0 : t2.get()));
     }
 
@@ -127,27 +133,35 @@ public LongWritable div(LongWritable sum, long numRows) {
   private static class TypeOperationDoubleWritable extends TypeOperationBase<DoubleWritable> {
     @Override
     public DoubleWritable add(DoubleWritable t1, DoubleWritable t2) {
-      if (t1 == null && t2 == null) return null;
+      if (t1 == null && t2 == null) {
+        return null;
+      }
       return new DoubleWritable((t1 == null ? 0 : t1.get()) + (t2 == null ? 0 : t2.get()));
     }
 
     public DoubleWritable minus(DoubleWritable t1, DoubleWritable t2) {
-      if (t1 == null && t2 == null) return null;
+      if (t1 == null && t2 == null) {
+        return null;
+      }
       return new DoubleWritable((t1 == null ? 0 : t1.get()) - (t2 == null ? 0 : t2.get()));
     }
 
     @Override
     public DoubleWritable div(DoubleWritable sum, long numRows) {
-      if (sum == null || numRows == 0) return null;
+      if (sum == null || numRows == 0) {
+        return null;
+      }
 
-      return new DoubleWritable(sum.get() / (double)numRows);
+      return new DoubleWritable(sum.get() / numRows);
     }
   }
 
   private static class TypeOperationHiveDecimalWritable extends TypeOperationBase<HiveDecimalWritable> {
     @Override
     public HiveDecimalWritable div(HiveDecimalWritable sum, long numRows) {
-      if (sum == null || numRows == 0) return null;
+      if (sum == null || numRows == 0) {
+        return null;
+      }
 
       HiveDecimalWritable result = new HiveDecimalWritable(sum);
       result.mutateDivide(HiveDecimal.create(numRows));
@@ -156,7 +170,9 @@ public HiveDecimalWritable div(HiveDecimalWritable sum, long numRows) {
 
     @Override
     public HiveDecimalWritable add(HiveDecimalWritable t1, HiveDecimalWritable t2) {
-      if (t1 == null && t2 == null) return null;
+      if (t1 == null && t2 == null) {
+        return null;
+      }
 
       if (t1 == null) {
         return new HiveDecimalWritable(t2);
@@ -171,7 +187,9 @@ public HiveDecimalWritable add(HiveDecimalWritable t1, HiveDecimalWritable t2) {
 
     @Override
     public HiveDecimalWritable minus(HiveDecimalWritable t1, HiveDecimalWritable t2) {
-      if (t1 == null && t2 == null) return null;
+      if (t1 == null && t2 == null) {
+        return null;
+      }
 
       if (t2 == null) {
         return new HiveDecimalWritable(t1);
@@ -262,6 +280,14 @@ protected Object calcFunctionValue(PTFPartitionIterator<Object> pItr, LeadLagInf
     return ObjectInspectorUtils.copyToStandardObject(wrappedEvaluator.evaluate(aggBuffer), outputOI);
   }
 
+  /**
+   * When there are no parameters specified, partition iterator can be made faster;
+   * In such cases, it need not materialize the ROW from RowContainer. This saves lots of IO.
+   */
+  protected Range newRange(int end, int end2, PTFPartition partition) {
+    return new Range(end, end2, partition, (parameters == null || parameters.isEmpty()));
+  }
+
   protected Range getRange(WindowFrameDef winFrame, int currRow, PTFPartition p,
       boolean nullsLast) throws HiveException {
     BoundaryDef startB = winFrame.getStart();
@@ -279,7 +305,7 @@ protected Range getRange(WindowFrameDef winFrame, int currRow, PTFPartition p,
     }
     start = start < 0 ? 0 : start;
     end = end > p.size() ? p.size() : end;
-    return new Range(start, end, p);
+    return newRange(start, end, p);
   }
 
   private static int getRowBoundaryStart(BoundaryDef b, int currRow) throws HiveException {
@@ -370,8 +396,8 @@ public Object iterate(int currentRow, LeadLagInfo leadLagInfo) throws HiveExcept
       } else {
         // Given the previous range and the current range, calculate the new sum
         // from the previous sum and the difference to save the computation.
-        Range r1 = new Range(sumAgg.prevRange.start, currentRange.start, partition);
-        Range r2 = new Range(sumAgg.prevRange.end, currentRange.end, partition);
+        Range r1 = newRange(sumAgg.prevRange.start, currentRange.start, partition);
+        Range r2 = newRange(sumAgg.prevRange.end, currentRange.end, partition);
         ResultType sum1 = (ResultType)calcFunctionValue(r1.iterator(), leadLagInfo);
         ResultType sum2 = (ResultType)calcFunctionValue(r2.iterator(), leadLagInfo);
         result = typeOperation.add(typeOperation.minus(sumAgg.prevSum, sum1), sum2);
@@ -480,7 +506,7 @@ public Object iterate(int currentRow, LeadLagInfo leadLagInfo) throws HiveExcept
       if (currentRow == 0 ||  // Reset for the new partition
           avgAgg.prevRange == null ||
           currentRange.getSize() <= currentRange.getDiff(avgAgg.prevRange)) {
-        Object[] partial = (Object[])calcPartialResult(currentRange.iterator(), leadLagInfo);
+        Object[] partial = calcPartialResult(currentRange.iterator(), leadLagInfo);
         avgAgg.prevRange = currentRange;
         avgAgg.empty = false;
         avgAgg.prevSum = (ResultType)partial[1];
@@ -488,10 +514,10 @@ public Object iterate(int currentRow, LeadLagInfo leadLagInfo) throws HiveExcept
       } else {
         // Given the previous range and the current range, calculate the new sum
         // from the previous sum and the difference to save the computation.
-        Range r1 = new Range(avgAgg.prevRange.start, currentRange.start, partition);
-        Range r2 = new Range(avgAgg.prevRange.end, currentRange.end, partition);
-        Object[] partial1 = (Object[])calcPartialResult(r1.iterator(), leadLagInfo);
-        Object[] partial2 = (Object[])calcPartialResult(r2.iterator(), leadLagInfo);
+        Range r1 = newRange(avgAgg.prevRange.start, currentRange.start, partition);
+        Range r2 = newRange(avgAgg.prevRange.end, currentRange.end, partition);
+        Object[] partial1 = calcPartialResult(r1.iterator(), leadLagInfo);
+        Object[] partial2 = calcPartialResult(r2.iterator(), leadLagInfo);
         ResultType sum = typeOperation.add(typeOperation.minus(avgAgg.prevSum, (ResultType)partial1[1]), (ResultType)partial2[1]);
         long count = avgAgg.prevCount - (long)partial1[0]+ (long)partial2[0];
 
@@ -502,6 +528,7 @@ public Object iterate(int currentRow, LeadLagInfo leadLagInfo) throws HiveExcept
 
       return typeOperation.div(avgAgg.prevSum, avgAgg.prevCount);
     }
+
   }
 
   public static class AvgPartitionDoubleEvaluator extends AvgPartitionEvaluator<DoubleWritable> {
