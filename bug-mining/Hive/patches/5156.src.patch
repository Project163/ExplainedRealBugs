diff --git a/ql/src/test/results/clientpositive/bucket_num_reducers.q.out b/ql/src/test/results/clientpositive/bucket_num_reducers.q.out
index a760592b71..9f317816c2 100644
--- a/ql/src/test/results/clientpositive/bucket_num_reducers.q.out
+++ b/ql/src/test/results/clientpositive/bucket_num_reducers.q.out
@@ -1,14 +1,8 @@
-PREHOOK: query: -- This test sets number of mapred tasks to 10 for a database with 50 buckets, 
--- and uses a post-hook to confirm that 10 tasks were created
-
-CREATE TABLE bucket_nr(key int, value string) CLUSTERED BY (key) INTO 50 BUCKETS
+PREHOOK: query: CREATE TABLE bucket_nr(key int, value string) CLUSTERED BY (key) INTO 50 BUCKETS
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@bucket_nr
-POSTHOOK: query: -- This test sets number of mapred tasks to 10 for a database with 50 buckets, 
--- and uses a post-hook to confirm that 10 tasks were created
-
-CREATE TABLE bucket_nr(key int, value string) CLUSTERED BY (key) INTO 50 BUCKETS
+POSTHOOK: query: CREATE TABLE bucket_nr(key int, value string) CLUSTERED BY (key) INTO 50 BUCKETS
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@bucket_nr
diff --git a/ql/src/test/results/clientpositive/bucket_num_reducers2.q.out b/ql/src/test/results/clientpositive/bucket_num_reducers2.q.out
index a16a50239a..c7eeda0cde 100644
--- a/ql/src/test/results/clientpositive/bucket_num_reducers2.q.out
+++ b/ql/src/test/results/clientpositive/bucket_num_reducers2.q.out
@@ -1,14 +1,8 @@
-PREHOOK: query: -- This test sets the maximum number of reduce tasks to 2 for overwriting a
--- table with 3 buckets, and uses a post-hook to confirm that 1 reducer was used
-
-CREATE TABLE test_table(key int, value string) CLUSTERED BY (key) INTO 3 BUCKETS
+PREHOOK: query: CREATE TABLE test_table(key int, value string) CLUSTERED BY (key) INTO 3 BUCKETS
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@test_table
-POSTHOOK: query: -- This test sets the maximum number of reduce tasks to 2 for overwriting a
--- table with 3 buckets, and uses a post-hook to confirm that 1 reducer was used
-
-CREATE TABLE test_table(key int, value string) CLUSTERED BY (key) INTO 3 BUCKETS
+POSTHOOK: query: CREATE TABLE test_table(key int, value string) CLUSTERED BY (key) INTO 3 BUCKETS
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@test_table
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_dynamic.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_dynamic.q.out
index dbc7473b93..c4a04b24f4 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_dynamic.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_dynamic.q.out
@@ -1,12 +1,6 @@
-PREHOOK: query: -- SORT_QUERY_RESULTS
-
--- init
-drop table IF EXISTS encryptedTable PURGE
+PREHOOK: query: drop table IF EXISTS encryptedTable PURGE
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- SORT_QUERY_RESULTS
-
--- init
-drop table IF EXISTS encryptedTable PURGE
+POSTHOOK: query: drop table IF EXISTS encryptedTable PURGE
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: drop table IF EXISTS unencryptedTable PURGE
 PREHOOK: type: DROPTABLE
@@ -38,14 +32,12 @@ POSTHOOK: query: create table unencryptedTable(value string)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@unencryptedTable
-PREHOOK: query: -- insert encrypted table from values
-insert into table encryptedTable partition (key) values
+PREHOOK: query: insert into table encryptedTable partition (key) values
     ('val_501', '501'),
     ('val_502', '502')
 PREHOOK: type: QUERY
 PREHOOK: Output: default@encryptedtable
-POSTHOOK: query: -- insert encrypted table from values
-insert into table encryptedTable partition (key) values
+POSTHOOK: query: insert into table encryptedTable partition (key) values
     ('val_501', '501'),
     ('val_502', '502')
 POSTHOOK: type: QUERY
@@ -67,15 +59,13 @@ POSTHOOK: Input: default@encryptedtable@key=502
 #### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
 val_501	501
 val_502	502
-PREHOOK: query: -- insert encrypted table from unencrypted source
-from src
+PREHOOK: query: from src
 insert into table encryptedTable partition (key)
     select value, key limit 2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@encryptedtable
-POSTHOOK: query: -- insert encrypted table from unencrypted source
-from src
+POSTHOOK: query: from src
 insert into table encryptedTable partition (key)
     select value, key limit 2
 POSTHOOK: type: QUERY
@@ -104,8 +94,7 @@ val_238	238
 val_501	501
 val_502	502
 val_86	86
-PREHOOK: query: -- insert unencrypted table from encrypted source
-from encryptedTable
+PREHOOK: query: from encryptedTable
 insert into table unencryptedTable partition (key)
     select value, key
 PREHOOK: type: QUERY
@@ -115,8 +104,7 @@ PREHOOK: Input: default@encryptedtable@key=501
 PREHOOK: Input: default@encryptedtable@key=502
 PREHOOK: Input: default@encryptedtable@key=86
 PREHOOK: Output: default@unencryptedtable
-POSTHOOK: query: -- insert unencrypted table from encrypted source
-from encryptedTable
+POSTHOOK: query: from encryptedTable
 insert into table unencryptedTable partition (key)
     select value, key
 POSTHOOK: type: QUERY
@@ -153,13 +141,11 @@ val_238	238
 val_501	501
 val_502	502
 val_86	86
-PREHOOK: query: -- clean up
-drop table encryptedTable PURGE
+PREHOOK: query: drop table encryptedTable PURGE
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@encryptedtable
 PREHOOK: Output: default@encryptedtable
-POSTHOOK: query: -- clean up
-drop table encryptedTable PURGE
+POSTHOOK: query: drop table encryptedTable PURGE
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@encryptedtable
 POSTHOOK: Output: default@encryptedtable
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_static.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_static.q.out
index 53ef34cc48..cd35148f98 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_static.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_insert_partition_static.q.out
@@ -1,12 +1,6 @@
-PREHOOK: query: -- SORT_QUERY_RESULTS
-
--- init
-drop table IF EXISTS encryptedTable PURGE
+PREHOOK: query: drop table IF EXISTS encryptedTable PURGE
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- SORT_QUERY_RESULTS
-
--- init
-drop table IF EXISTS encryptedTable PURGE
+POSTHOOK: query: drop table IF EXISTS encryptedTable PURGE
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: drop table IF EXISTS unencryptedTable PURGE
 PREHOOK: type: DROPTABLE
@@ -38,15 +32,13 @@ POSTHOOK: query: create table unencryptedTable(key string,
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@unencryptedTable
-PREHOOK: query: -- insert encrypted table from values
-insert into table encryptedTable partition
+PREHOOK: query: insert into table encryptedTable partition
     (ds='today') values
     ('501', 'val_501'),
     ('502', 'val_502')
 PREHOOK: type: QUERY
 PREHOOK: Output: default@encryptedtable@ds=today
-POSTHOOK: query: -- insert encrypted table from values
-insert into table encryptedTable partition
+POSTHOOK: query: insert into table encryptedTable partition
     (ds='today') values
     ('501', 'val_501'),
     ('502', 'val_502')
@@ -66,14 +58,12 @@ POSTHOOK: Input: default@encryptedtable@ds=today
 #### A PARTIAL masked pattern was here #### data/warehouse/encryptedTable/.hive-staging
 501	val_501	today
 502	val_502	today
-PREHOOK: query: -- insert encrypted table from unencrypted source
-insert into table encryptedTable partition (ds='yesterday')
+PREHOOK: query: insert into table encryptedTable partition (ds='yesterday')
 select * from src where key in ('238', '86')
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@encryptedtable@ds=yesterday
-POSTHOOK: query: -- insert encrypted table from unencrypted source
-insert into table encryptedTable partition (ds='yesterday')
+POSTHOOK: query: insert into table encryptedTable partition (ds='yesterday')
 select * from src where key in ('238', '86')
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
@@ -97,15 +87,13 @@ POSTHOOK: Input: default@encryptedtable@ds=yesterday
 501	val_501	today
 502	val_502	today
 86	val_86	yesterday
-PREHOOK: query: -- insert unencrypted table from encrypted source
-insert into table unencryptedTable partition (ds='today')
+PREHOOK: query: insert into table unencryptedTable partition (ds='today')
 select key, value from encryptedTable where ds='today'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@encryptedtable
 PREHOOK: Input: default@encryptedtable@ds=today
 PREHOOK: Output: default@unencryptedtable@ds=today
-POSTHOOK: query: -- insert unencrypted table from encrypted source
-insert into table unencryptedTable partition (ds='today')
+POSTHOOK: query: insert into table unencryptedTable partition (ds='today')
 select key, value from encryptedTable where ds='today'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@encryptedtable
@@ -144,13 +132,11 @@ POSTHOOK: Input: default@unencryptedtable@ds=yesterday
 501	val_501	today
 502	val_502	today
 86	val_86	yesterday
-PREHOOK: query: -- clean up
-drop table encryptedTable PURGE
+PREHOOK: query: drop table encryptedTable PURGE
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@encryptedtable
 PREHOOK: Output: default@encryptedtable
-POSTHOOK: query: -- clean up
-drop table encryptedTable PURGE
+POSTHOOK: query: drop table encryptedTable PURGE
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@encryptedtable
 POSTHOOK: Output: default@encryptedtable
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_insert_values.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_insert_values.q.out
index 80f37a7e99..e8645883b7 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_insert_values.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_insert_values.q.out
@@ -1,10 +1,6 @@
-PREHOOK: query: -- SORT_QUERY_RESULTS;
-
-DROP TABLE IF EXISTS encrypted_table PURGE
+PREHOOK: query: DROP TABLE IF EXISTS encrypted_table PURGE
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- SORT_QUERY_RESULTS;
-
-DROP TABLE IF EXISTS encrypted_table PURGE
+POSTHOOK: query: DROP TABLE IF EXISTS encrypted_table PURGE
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
@@ -36,12 +32,10 @@ POSTHOOK: Input: default@encrypted_table
 #### A PARTIAL masked pattern was here #### data/warehouse/default/encrypted_table/.hive-staging
 1	foo
 2	bar
-PREHOOK: query: -- this checks that we've actually created temp table data under encrypted_table folder 
-describe formatted values__tmp__table__1
+PREHOOK: query: describe formatted values__tmp__table__1
 PREHOOK: type: DESCTABLE
 PREHOOK: Input: default@values__tmp__table__1
-POSTHOOK: query: -- this checks that we've actually created temp table data under encrypted_table folder 
-describe formatted values__tmp__table__1
+POSTHOOK: query: describe formatted values__tmp__table__1
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Input: default@values__tmp__table__1
 # col_name            	data_type           	comment             
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_join_unencrypted_tbl.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_join_unencrypted_tbl.q.out
index 32ade9cd29..9a2ca9df97 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_join_unencrypted_tbl.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_join_unencrypted_tbl.q.out
@@ -1,10 +1,6 @@
-PREHOOK: query: --SORT_QUERY_RESULTS
-
-DROP TABLE IF EXISTS encrypted_table PURGE
+PREHOOK: query: DROP TABLE IF EXISTS encrypted_table PURGE
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: --SORT_QUERY_RESULTS
-
-DROP TABLE IF EXISTS encrypted_table PURGE
+POSTHOOK: query: DROP TABLE IF EXISTS encrypted_table PURGE
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_load_data_to_encrypted_tables.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_load_data_to_encrypted_tables.q.out
index 35de14ff87..0d1ae19286 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_load_data_to_encrypted_tables.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_load_data_to_encrypted_tables.q.out
@@ -14,13 +14,11 @@ POSTHOOK: Output: database:default
 POSTHOOK: Output: default@encrypted_table
 Encryption key created: 'key1'
 Encryption zone created: '/build/ql/test/data/warehouse/encrypted_table' using key: 'key1'
-PREHOOK: query: -- Test loading data from the local filesystem;
-LOAD DATA LOCAL INPATH '../../data/files/kv1.txt' OVERWRITE INTO TABLE encrypted_table
+PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv1.txt' OVERWRITE INTO TABLE encrypted_table
 PREHOOK: type: LOAD
 #### A masked pattern was here ####
 PREHOOK: Output: default@encrypted_table
-POSTHOOK: query: -- Test loading data from the local filesystem;
-LOAD DATA LOCAL INPATH '../../data/files/kv1.txt' OVERWRITE INTO TABLE encrypted_table
+POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv1.txt' OVERWRITE INTO TABLE encrypted_table
 POSTHOOK: type: LOAD
 #### A masked pattern was here ####
 POSTHOOK: Output: default@encrypted_table
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_move_tbl.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_move_tbl.q.out
index 26396b2e24..cc363ac289 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_move_tbl.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_move_tbl.q.out
@@ -18,13 +18,10 @@ POSTHOOK: Output: database:default
 POSTHOOK: Output: default@encrypted_table
 Encryption key created: 'key_128'
 Encryption zone created: '/build/ql/test/data/warehouse/encrypted_table' using key: 'key_128'
-PREHOOK: query: -- create database encrypted_db in its default warehouse location {hiveconf:hive.metastore.warehouse.dir}/encrypted_db.db
 #### A masked pattern was here ####
 PREHOOK: type: CREATEDATABASE
 PREHOOK: Output: database:encrypted_db
 #### A masked pattern was here ####
-POSTHOOK: query: -- create database encrypted_db in its default warehouse location {hiveconf:hive.metastore.warehouse.dir}/encrypted_db.db
-#### A masked pattern was here ####
 POSTHOOK: type: CREATEDATABASE
 POSTHOOK: Output: database:encrypted_db
 #### A masked pattern was here ####
@@ -48,8 +45,7 @@ POSTHOOK: type: SHOWTABLES
 POSTHOOK: Input: database:default
 encrypted_table
 src
-PREHOOK: query: -- should fail, since they are in different encryption zones
-ALTER TABLE default.encrypted_table RENAME TO encrypted_db.encrypted_table_2
+PREHOOK: query: ALTER TABLE default.encrypted_table RENAME TO encrypted_db.encrypted_table_2
 PREHOOK: type: ALTERTABLE_RENAME
 PREHOOK: Input: default@encrypted_table
 PREHOOK: Output: default@encrypted_table
@@ -62,13 +58,11 @@ POSTHOOK: type: SHOWTABLES
 POSTHOOK: Input: database:default
 encrypted_table
 src
-PREHOOK: query: -- should succeed in Hadoop 2.7 but fail in 2.6  (HDFS-7530)
-ALTER TABLE default.encrypted_table RENAME TO default.plain_table
+PREHOOK: query: ALTER TABLE default.encrypted_table RENAME TO default.plain_table
 PREHOOK: type: ALTERTABLE_RENAME
 PREHOOK: Input: default@encrypted_table
 PREHOOK: Output: default@encrypted_table
-POSTHOOK: query: -- should succeed in Hadoop 2.7 but fail in 2.6  (HDFS-7530)
-ALTER TABLE default.encrypted_table RENAME TO default.plain_table
+POSTHOOK: query: ALTER TABLE default.encrypted_table RENAME TO default.plain_table
 POSTHOOK: type: ALTERTABLE_RENAME
 POSTHOOK: Input: default@encrypted_table
 POSTHOOK: Output: default@encrypted_table
@@ -81,15 +75,11 @@ POSTHOOK: type: SHOWTABLES
 POSTHOOK: Input: database:default
 plain_table
 src
-PREHOOK: query: -- create table encrypted_table_outloc under default database but in a specified location other than the default db location in the warehouse
--- rename should succeed since it does not need to move data (HIVE-14909), otherwise, it would fail.
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
 #### A masked pattern was here ####
 PREHOOK: Output: database:default
 PREHOOK: Output: default@encrypted_table_outloc
-POSTHOOK: query: -- create table encrypted_table_outloc under default database but in a specified location other than the default db location in the warehouse
--- rename should succeed since it does not need to move data (HIVE-14909), otherwise, it would fail.
 #### A masked pattern was here ####
 POSTHOOK: type: CREATETABLE
 #### A masked pattern was here ####
@@ -115,13 +105,10 @@ POSTHOOK: Input: database:default
 plain_table
 renamed_encrypted_table_outloc
 src
-PREHOOK: query: -- create database encrypted_db_outloc in a specified location other than its default in warehouse
 #### A masked pattern was here ####
 PREHOOK: type: CREATEDATABASE
 PREHOOK: Output: database:encrypted_db_outloc
 #### A masked pattern was here ####
-POSTHOOK: query: -- create database encrypted_db_outloc in a specified location other than its default in warehouse
-#### A masked pattern was here ####
 POSTHOOK: type: CREATEDATABASE
 POSTHOOK: Output: database:encrypted_db_outloc
 #### A masked pattern was here ####
@@ -160,17 +147,14 @@ POSTHOOK: type: ALTERTABLE_RENAME
 POSTHOOK: Input: encrypted_db_outloc@encrypted_table
 POSTHOOK: Output: encrypted_db_outloc@encrypted_table
 POSTHOOK: Output: encrypted_db_outloc@renamed_encrypted_table
-PREHOOK: query: -- should succeed since data moves within specified_db_location
-SHOW TABLES
+PREHOOK: query: SHOW TABLES
 PREHOOK: type: SHOWTABLES
 PREHOOK: Input: database:encrypted_db_outloc
-POSTHOOK: query: -- should succeed since data moves within specified_db_location
-SHOW TABLES
+POSTHOOK: query: SHOW TABLES
 POSTHOOK: type: SHOWTABLES
 POSTHOOK: Input: database:encrypted_db_outloc
 renamed_encrypted_table
-PREHOOK: query: -- should fail, since they are in different encryption zones
-ALTER TABLE encrypted_db_outloc.renamed_encrypted_table RENAME TO default.plain_table_2
+PREHOOK: query: ALTER TABLE encrypted_db_outloc.renamed_encrypted_table RENAME TO default.plain_table_2
 PREHOOK: type: ALTERTABLE_RENAME
 PREHOOK: Input: encrypted_db_outloc@renamed_encrypted_table
 PREHOOK: Output: encrypted_db_outloc@renamed_encrypted_table
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_select_read_only_encrypted_tbl.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_select_read_only_encrypted_tbl.q.out
index c57a5ad86d..758a8fa63e 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_select_read_only_encrypted_tbl.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_select_read_only_encrypted_tbl.q.out
@@ -1,10 +1,6 @@
-PREHOOK: query: -- SORT_QUERY_RESULTS
-
-DROP TABLE IF EXISTS encrypted_table PURGE
+PREHOOK: query: DROP TABLE IF EXISTS encrypted_table PURGE
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- SORT_QUERY_RESULTS
-
-DROP TABLE IF EXISTS encrypted_table PURGE
+POSTHOOK: query: DROP TABLE IF EXISTS encrypted_table PURGE
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_select_read_only_unencrypted_tbl.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_select_read_only_unencrypted_tbl.q.out
index 34c152f1ae..4c3b853c60 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_select_read_only_unencrypted_tbl.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_select_read_only_unencrypted_tbl.q.out
@@ -1,10 +1,6 @@
-PREHOOK: query: -- SORT_QUERY_RESULTS
-
-DROP TABLE IF EXISTS unencrypted_table
+PREHOOK: query: DROP TABLE IF EXISTS unencrypted_table
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- SORT_QUERY_RESULTS
-
-DROP TABLE IF EXISTS unencrypted_table
+POSTHOOK: query: DROP TABLE IF EXISTS unencrypted_table
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
diff --git a/ql/src/test/results/clientpositive/encrypted/encryption_unencrypted_nonhdfs_external_tables.q.out b/ql/src/test/results/clientpositive/encrypted/encryption_unencrypted_nonhdfs_external_tables.q.out
index 2d81d887e8..966f06e5e3 100644
--- a/ql/src/test/results/clientpositive/encrypted/encryption_unencrypted_nonhdfs_external_tables.q.out
+++ b/ql/src/test/results/clientpositive/encrypted/encryption_unencrypted_nonhdfs_external_tables.q.out
@@ -1,12 +1,6 @@
-PREHOOK: query: -- This test does not test encrypted data, but it makes sure that external tables out of HDFS can
--- be queried due to internal encryption functions;
-
-DROP TABLE mydata
+PREHOOK: query: DROP TABLE mydata
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- This test does not test encrypted data, but it makes sure that external tables out of HDFS can
--- be queried due to internal encryption functions;
-
-DROP TABLE mydata
+POSTHOOK: query: DROP TABLE mydata
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: CREATE EXTERNAL TABLE mydata (key STRING, value STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ' '
 #### A masked pattern was here ####
diff --git a/ql/src/test/results/clientpositive/index_bitmap3.q.out b/ql/src/test/results/clientpositive/index_bitmap3.q.out
index dc51c77a8e..bd5a48496f 100644
--- a/ql/src/test/results/clientpositive/index_bitmap3.q.out
+++ b/ql/src/test/results/clientpositive/index_bitmap3.q.out
@@ -1,11 +1,7 @@
-PREHOOK: query: -- SORT_QUERY_RESULTS
-
-EXPLAIN
+PREHOOK: query: EXPLAIN
 CREATE INDEX src1_index ON TABLE src(key) as 'BITMAP' WITH DEFERRED REBUILD
 PREHOOK: type: CREATEINDEX
-POSTHOOK: query: -- SORT_QUERY_RESULTS
-
-EXPLAIN
+POSTHOOK: query: EXPLAIN
 CREATE INDEX src1_index ON TABLE src(key) as 'BITMAP' WITH DEFERRED REBUILD
 POSTHOOK: type: CREATEINDEX
 STAGE DEPENDENCIES:
diff --git a/ql/src/test/results/clientpositive/infer_bucket_sort_dyn_part.q.out b/ql/src/test/results/clientpositive/infer_bucket_sort_dyn_part.q.out
index 6d2ca0c14e..d62d0b8d2f 100644
--- a/ql/src/test/results/clientpositive/infer_bucket_sort_dyn_part.q.out
+++ b/ql/src/test/results/clientpositive/infer_bucket_sort_dyn_part.q.out
@@ -1,16 +1,8 @@
-PREHOOK: query: -- This tests inferring how data is bucketed/sorted from the operators in the reducer
--- and populating that information in partitions' metadata.  In particular, those cases
--- where dynamic partitioning is used.
-
-CREATE TABLE test_table LIKE srcpart
+PREHOOK: query: CREATE TABLE test_table LIKE srcpart
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@test_table
-POSTHOOK: query: -- This tests inferring how data is bucketed/sorted from the operators in the reducer
--- and populating that information in partitions' metadata.  In particular, those cases
--- where dynamic partitioning is used.
-
-CREATE TABLE test_table LIKE srcpart
+POSTHOOK: query: CREATE TABLE test_table LIKE srcpart
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@test_table
@@ -22,9 +14,7 @@ POSTHOOK: query: ALTER TABLE test_table SET FILEFORMAT RCFILE
 POSTHOOK: type: ALTERTABLE_FILEFORMAT
 POSTHOOK: Input: default@test_table
 POSTHOOK: Output: default@test_table
-PREHOOK: query: -- Simple case, this should not be bucketed or sorted
-
-INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
+PREHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
 SELECT key, value, ds, hr FROM srcpart
 WHERE ds = '2008-04-08'
 PREHOOK: type: QUERY
@@ -32,9 +22,7 @@ PREHOOK: Input: default@srcpart
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Output: default@test_table
-POSTHOOK: query: -- Simple case, this should not be bucketed or sorted
-
-INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
+POSTHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
 SELECT key, value, ds, hr FROM srcpart
 WHERE ds = '2008-04-08'
 POSTHOOK: type: QUERY
@@ -127,10 +115,7 @@ Bucket Columns:     	[]
 Sort Columns:       	[]                  	 
 Storage Desc Params:	 	 
 	serialization.format	1                   
-PREHOOK: query: -- This should not be bucketed or sorted since the partition keys are in the set of bucketed
--- and sorted columns for the output 
-
-INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
+PREHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
 SELECT key, COUNT(*), ds, hr FROM srcpart
 WHERE ds = '2008-04-08'
 GROUP BY key, ds, hr
@@ -139,10 +124,7 @@ PREHOOK: Input: default@srcpart
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Output: default@test_table
-POSTHOOK: query: -- This should not be bucketed or sorted since the partition keys are in the set of bucketed
--- and sorted columns for the output 
-
-INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
+POSTHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
 SELECT key, COUNT(*), ds, hr FROM srcpart
 WHERE ds = '2008-04-08'
 GROUP BY key, ds, hr
@@ -236,9 +218,7 @@ Bucket Columns:     	[]
 Sort Columns:       	[]                  	 
 Storage Desc Params:	 	 
 	serialization.format	1                   
-PREHOOK: query: -- Both partitions should be bucketed and sorted by key
-
-INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
+PREHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
 SELECT key, value, '2008-04-08', IF (key % 2 == 0, '11', '12') FROM
 (SELECT key, COUNT(*) AS value FROM srcpart
 WHERE ds = '2008-04-08'
@@ -248,9 +228,7 @@ PREHOOK: Input: default@srcpart
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Output: default@test_table
-POSTHOOK: query: -- Both partitions should be bucketed and sorted by key
-
-INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
+POSTHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (ds, hr)
 SELECT key, value, '2008-04-08', IF (key % 2 == 0, '11', '12') FROM
 (SELECT key, COUNT(*) AS value FROM srcpart
 WHERE ds = '2008-04-08'
@@ -430,24 +408,14 @@ POSTHOOK: Lineage: srcpart_merge_dp_rc PARTITION(ds=2008-04-08,hr=11).key SIMPLE
 POSTHOOK: Lineage: srcpart_merge_dp_rc PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart_merge_dp)srcpart_merge_dp.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: srcpart_merge_dp_rc PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart_merge_dp)srcpart_merge_dp.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: srcpart_merge_dp_rc PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart_merge_dp)srcpart_merge_dp.FieldSchema(name:value, type:string, comment:default), ]
-PREHOOK: query: -- Tests dynamic partitions where bucketing/sorting can be inferred, but some partitions are
--- merged and some are moved.  Currently neither should be bucketed or sorted, in the future,
--- (ds='2008-04-08', hr='12') may be bucketed and sorted, (ds='2008-04-08', hr='11') should
--- definitely not be.
-
-EXPLAIN
+PREHOOK: query: EXPLAIN
 INSERT OVERWRITE TABLE test_table PARTITION (ds = '2008-04-08', hr)
 SELECT key, value, IF (key % 100 == 0, '11', '12') FROM
 (SELECT key, COUNT(*) AS value FROM srcpart
 WHERE ds = '2008-04-08'
 GROUP BY key) a
 PREHOOK: type: QUERY
-POSTHOOK: query: -- Tests dynamic partitions where bucketing/sorting can be inferred, but some partitions are
--- merged and some are moved.  Currently neither should be bucketed or sorted, in the future,
--- (ds='2008-04-08', hr='12') may be bucketed and sorted, (ds='2008-04-08', hr='11') should
--- definitely not be.
-
-EXPLAIN
+POSTHOOK: query: EXPLAIN
 INSERT OVERWRITE TABLE test_table PARTITION (ds = '2008-04-08', hr)
 SELECT key, value, IF (key % 100 == 0, '11', '12') FROM
 (SELECT key, COUNT(*) AS value FROM srcpart
diff --git a/ql/src/test/results/clientpositive/infer_bucket_sort_map_operators.q.out b/ql/src/test/results/clientpositive/infer_bucket_sort_map_operators.q.out
index 3f7ae9108e..05e1c66664 100644
--- a/ql/src/test/results/clientpositive/infer_bucket_sort_map_operators.q.out
+++ b/ql/src/test/results/clientpositive/infer_bucket_sort_map_operators.q.out
@@ -1,17 +1,9 @@
-PREHOOK: query: -- This tests inferring how data is bucketed/sorted from the operators in the reducer
--- and populating that information in partitions' metadata, in particular, this tests
--- that operators in the mapper have no effect
-
-CREATE TABLE test_table1 (key STRING, value STRING)
+PREHOOK: query: CREATE TABLE test_table1 (key STRING, value STRING)
 CLUSTERED BY (key) SORTED BY (key DESC) INTO 2 BUCKETS
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@test_table1
-POSTHOOK: query: -- This tests inferring how data is bucketed/sorted from the operators in the reducer
--- and populating that information in partitions' metadata, in particular, this tests
--- that operators in the mapper have no effect
-
-CREATE TABLE test_table1 (key STRING, value STRING)
+POSTHOOK: query: CREATE TABLE test_table1 (key STRING, value STRING)
 CLUSTERED BY (key) SORTED BY (key DESC) INTO 2 BUCKETS
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
@@ -54,12 +46,10 @@ POSTHOOK: query: CREATE TABLE test_table_out (key STRING, value STRING) PARTITIO
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@test_table_out
-PREHOOK: query: -- Test map group by doesn't affect inference, should not be bucketed or sorted
-EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1') 
+PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1') 
 SELECT key, count(*) FROM test_table1 GROUP BY key
 PREHOOK: type: QUERY
-POSTHOOK: query: -- Test map group by doesn't affect inference, should not be bucketed or sorted
-EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1') 
+POSTHOOK: query: EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1') 
 SELECT key, count(*) FROM test_table1 GROUP BY key
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
@@ -204,8 +194,7 @@ Sort Columns:       	[]
 Storage Desc Params:	 	 
 	serialization.format	1                   
 WARNING: Comparing a bigint and a string may result in a loss of precision.
-PREHOOK: query: -- Test map group by doesn't affect inference, should be bucketed and sorted by value
-EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1') 
+PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1') 
 SELECT a.key, a.value FROM (
 	SELECT key, count(*) AS value FROM test_table1 GROUP BY key
 ) a JOIN (
@@ -213,8 +202,7 @@ SELECT a.key, a.value FROM (
 ) b
 ON (a.value = b.value)
 PREHOOK: type: QUERY
-POSTHOOK: query: -- Test map group by doesn't affect inference, should be bucketed and sorted by value
-EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1') 
+POSTHOOK: query: EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1') 
 SELECT a.key, a.value FROM (
 	SELECT key, count(*) AS value FROM test_table1 GROUP BY key
 ) a JOIN (
@@ -364,12 +352,10 @@ Bucket Columns:     	[value]
 Sort Columns:       	[Order(col:value, order:1)]	 
 Storage Desc Params:	 	 
 	serialization.format	1                   
-PREHOOK: query: -- Test SMB join doesn't affect inference, should not be bucketed or sorted
-EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1')
+PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1')
 SELECT /*+ MAPJOIN(a) */ a.key, b.value FROM test_table1 a JOIN test_table2 b ON a.key = b.key
 PREHOOK: type: QUERY
-POSTHOOK: query: -- Test SMB join doesn't affect inference, should not be bucketed or sorted
-EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1')
+POSTHOOK: query: EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1')
 SELECT /*+ MAPJOIN(a) */ a.key, b.value FROM test_table1 a JOIN test_table2 b ON a.key = b.key
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
@@ -517,13 +503,11 @@ Bucket Columns:     	[]
 Sort Columns:       	[]                  	 
 Storage Desc Params:	 	 
 	serialization.format	1                   
-PREHOOK: query: -- Test SMB join doesn't affect inference, should be bucketed and sorted by key
-EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1')
+PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1')
 SELECT /*+ MAPJOIN(a) */ b.value, count(*) FROM test_table1 a JOIN test_table2 b ON a.key = b.key
 GROUP BY b.value
 PREHOOK: type: QUERY
-POSTHOOK: query: -- Test SMB join doesn't affect inference, should be bucketed and sorted by key
-EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1')
+POSTHOOK: query: EXPLAIN INSERT OVERWRITE TABLE test_table_out PARTITION (part = '1')
 SELECT /*+ MAPJOIN(a) */ b.value, count(*) FROM test_table1 a JOIN test_table2 b ON a.key = b.key
 GROUP BY b.value
 POSTHOOK: type: QUERY
diff --git a/ql/src/test/results/clientpositive/infer_bucket_sort_merge.q.out b/ql/src/test/results/clientpositive/infer_bucket_sort_merge.q.out
index 9eb7bbf8b2..bf77d4ce5a 100644
--- a/ql/src/test/results/clientpositive/infer_bucket_sort_merge.q.out
+++ b/ql/src/test/results/clientpositive/infer_bucket_sort_merge.q.out
@@ -1,27 +1,17 @@
-PREHOOK: query: -- This tests inferring how data is bucketed/sorted from the operators in the reducer
--- and populating that information in partitions' metadata.  In particular, those cases
--- where where merging may or may not be used.
-
-CREATE TABLE test_table (key STRING, value STRING) PARTITIONED BY (part STRING)
+PREHOOK: query: CREATE TABLE test_table (key STRING, value STRING) PARTITIONED BY (part STRING)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@test_table
-POSTHOOK: query: -- This tests inferring how data is bucketed/sorted from the operators in the reducer
--- and populating that information in partitions' metadata.  In particular, those cases
--- where where merging may or may not be used.
-
-CREATE TABLE test_table (key STRING, value STRING) PARTITIONED BY (part STRING)
+POSTHOOK: query: CREATE TABLE test_table (key STRING, value STRING) PARTITIONED BY (part STRING)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@test_table
-PREHOOK: query: -- Tests a reduce task followed by a merge.  The output should be neither bucketed nor sorted.
-INSERT OVERWRITE TABLE test_table PARTITION (part = '1') 
+PREHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (part = '1') 
 SELECT a.key, b.value FROM src a JOIN src b ON a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@test_table@part=1
-POSTHOOK: query: -- Tests a reduce task followed by a merge.  The output should be neither bucketed nor sorted.
-INSERT OVERWRITE TABLE test_table PARTITION (part = '1') 
+POSTHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (part = '1') 
 SELECT a.key, b.value FROM src a JOIN src b ON a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
@@ -67,14 +57,12 @@ Bucket Columns:     	[]
 Sort Columns:       	[]                  	 
 Storage Desc Params:	 	 
 	serialization.format	1                   
-PREHOOK: query: -- Tests a reduce task followed by a move. The output should be bucketed and sorted.
-INSERT OVERWRITE TABLE test_table PARTITION (part = '1') 
+PREHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (part = '1') 
 SELECT a.key, b.value FROM src a JOIN src b ON a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@test_table@part=1
-POSTHOOK: query: -- Tests a reduce task followed by a move. The output should be bucketed and sorted.
-INSERT OVERWRITE TABLE test_table PARTITION (part = '1') 
+POSTHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (part = '1') 
 SELECT a.key, b.value FROM src a JOIN src b ON a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
diff --git a/ql/src/test/results/clientpositive/infer_bucket_sort_num_buckets.q.out b/ql/src/test/results/clientpositive/infer_bucket_sort_num_buckets.q.out
index f467168869..0c61fe0212 100644
--- a/ql/src/test/results/clientpositive/infer_bucket_sort_num_buckets.q.out
+++ b/ql/src/test/results/clientpositive/infer_bucket_sort_num_buckets.q.out
@@ -6,20 +6,7 @@ POSTHOOK: query: CREATE TABLE test_table (key INT, value STRING) PARTITIONED BY
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@test_table
-PREHOOK: query: -- Tests dynamic partitions where bucketing/sorting can be inferred, but not all reducers write
--- all partitions.  The subquery produces rows as follows
--- key = 0:
---    0, <value>, 0
--- key = 1:
---    0, <value>, 1
--- key = 2:
---    1, <value>, 0
--- This means that by distributing by the first column into two reducers, and using the third
--- columns as a dynamic partition, the dynamic partition for 0 will get written in both reducers
--- and the partition for 1 will get written in one reducer.  So hr=0 should be bucketed by key
--- and hr=1 should not.
-
-EXPLAIN
+PREHOOK: query: EXPLAIN
 INSERT OVERWRITE TABLE test_table PARTITION (ds = '2008-04-08', hr)
 SELECT key2, value, cast(hr as int) FROM
 (SELECT if ((key % 3) < 2, 0, 1) as key2, value, (key % 2) as hr
@@ -27,20 +14,7 @@ FROM srcpart
 WHERE ds = '2008-04-08') a
 DISTRIBUTE BY key2
 PREHOOK: type: QUERY
-POSTHOOK: query: -- Tests dynamic partitions where bucketing/sorting can be inferred, but not all reducers write
--- all partitions.  The subquery produces rows as follows
--- key = 0:
---    0, <value>, 0
--- key = 1:
---    0, <value>, 1
--- key = 2:
---    1, <value>, 0
--- This means that by distributing by the first column into two reducers, and using the third
--- columns as a dynamic partition, the dynamic partition for 0 will get written in both reducers
--- and the partition for 1 will get written in one reducer.  So hr=0 should be bucketed by key
--- and hr=1 should not.
-
-EXPLAIN
+POSTHOOK: query: EXPLAIN
 INSERT OVERWRITE TABLE test_table PARTITION (ds = '2008-04-08', hr)
 SELECT key2, value, cast(hr as int) FROM
 (SELECT if ((key % 3) < 2, 0, 1) as key2, value, (key % 2) as hr
diff --git a/ql/src/test/results/clientpositive/parallel_orderby.q.out b/ql/src/test/results/clientpositive/parallel_orderby.q.out
index 2991122822..8249a7baad 100644
--- a/ql/src/test/results/clientpositive/parallel_orderby.q.out
+++ b/ql/src/test/results/clientpositive/parallel_orderby.q.out
@@ -184,15 +184,11 @@ POSTHOOK: Input: default@total_ordered
 86	val_86
 98	val_98
 98	val_98
-PREHOOK: query: -- rolling back to single task in case that the number of sample is not enough
-
-drop table total_ordered
+PREHOOK: query: drop table total_ordered
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@total_ordered
 PREHOOK: Output: default@total_ordered
-POSTHOOK: query: -- rolling back to single task in case that the number of sample is not enough
-
-drop table total_ordered
+POSTHOOK: query: drop table total_ordered
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@total_ordered
 POSTHOOK: Output: default@total_ordered
diff --git a/ql/src/test/results/clientpositive/scriptfile1.q.out b/ql/src/test/results/clientpositive/scriptfile1.q.out
index bf202f9b18..cf718ccc03 100644
--- a/ql/src/test/results/clientpositive/scriptfile1.q.out
+++ b/ql/src/test/results/clientpositive/scriptfile1.q.out
@@ -1,20 +1,8 @@
-PREHOOK: query: -- SORT_QUERY_RESULTS
-
--- EXCLUDE_OS_WINDOWS
-
--- NO_SESSION_REUSE
-
-CREATE TABLE dest1(key INT, value STRING)
+PREHOOK: query: CREATE TABLE dest1(key INT, value STRING)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@dest1
-POSTHOOK: query: -- SORT_QUERY_RESULTS
-
--- EXCLUDE_OS_WINDOWS
-
--- NO_SESSION_REUSE
-
-CREATE TABLE dest1(key INT, value STRING)
+POSTHOOK: query: CREATE TABLE dest1(key INT, value STRING)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@dest1
