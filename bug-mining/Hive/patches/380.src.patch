diff --git a/CHANGES.txt b/CHANGES.txt
index 264f14dc2b..10af48c791 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -381,6 +381,9 @@ Trunk -  Unreleased
     HIVE-1260. from_unixtime should accept bigints
     (Ning Zhang via namit)
 
+    HIVE-1315. Bug in sort-merge join
+    (Ning Zhang via namit)
+
 Release 0.5.0 -  Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/data/conf/hive-site.xml b/data/conf/hive-site.xml
index 0db0487b5d..92c069ccb8 100644
--- a/data/conf/hive-site.xml
+++ b/data/conf/hive-site.xml
@@ -16,6 +16,14 @@
   <description>A base for other temporary directories.</description>
 </property>
 
+<!--
+<property>
+  <name>hive.exec.reducers.max</name>
+  <value>1</value>
+  <description>maximum number of reducers</description>
+</property>
+-->
+
 <property>
   <name>hive.exec.scratchdir</name>
   <value>${build.dir}/scratchdir</value>
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
index 841ab3aed9..7a672b3bbf 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
@@ -316,7 +316,7 @@ protected void initializeOp(Configuration hconf) throws HiveException {
 
       	// Create all the files - this is required because empty files need to be created for
       	// empty buckets
-      	createBucketFiles(fsp);
+      	// createBucketFiles(fsp);
       	valToPaths.put("", fsp); // special entry for non-DP case
       }
 
diff --git a/ql/src/test/queries/clientpositive/bucketmapjoin6.q b/ql/src/test/queries/clientpositive/bucketmapjoin6.q
index 829b06ade3..2ff07d2655 100644
--- a/ql/src/test/queries/clientpositive/bucketmapjoin6.q
+++ b/ql/src/test/queries/clientpositive/bucketmapjoin6.q
@@ -7,6 +7,7 @@ create table tmp2 (a string, b string) clustered by (a) sorted by (a) into 10 bu
 
 set hive.enforce.bucketing = true;
 set hive.enforce.sorting = true;
+set hive.exec.reducers.max=1;
 
 
 insert overwrite table tmp1 select * from src where key < 50;
@@ -25,7 +26,7 @@ insert overwrite table tmp3
   select /*+ MAPJOIN(l) */ i.a, i.b, l.b
   from tmp1 i join tmp2 l ON i.a = l.a;
 
-select * from tmp3;
+select * from tmp3 order by a, b, c;
 
 drop table tmp1;
 drop table tmp2;
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin6.q.out b/ql/src/test/results/clientpositive/bucketmapjoin6.q.out
index ad00a65226..db41bc8b46 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin6.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin6.q.out
@@ -76,14 +76,14 @@ POSTHOOK: Lineage: tmp2.b SIMPLE [(src)src.FieldSchema(name:value, type:string,
 POSTHOOK: Lineage: tmp3.a SIMPLE [(tmp1)i.FieldSchema(name:a, type:string, comment:null), ]
 POSTHOOK: Lineage: tmp3.b SIMPLE [(tmp1)i.FieldSchema(name:b, type:string, comment:null), ]
 POSTHOOK: Lineage: tmp3.c SIMPLE [(tmp2)l.FieldSchema(name:b, type:string, comment:null), ]
-PREHOOK: query: select * from tmp3
+PREHOOK: query: select * from tmp3 order by a, b, c
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmp3
-PREHOOK: Output: file:/data/users/njain/hive_commit1/hive_commit1/build/ql/scratchdir/hive_2010-04-06_13-16-17_519_5426148572496063749/10000
-POSTHOOK: query: select * from tmp3
+PREHOOK: Output: file:/data/users/nzhang/work/999/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-20_11-17-38_126_6207291158988738744/10000
+POSTHOOK: query: select * from tmp3 order by a, b, c
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmp3
-POSTHOOK: Output: file:/data/users/njain/hive_commit1/hive_commit1/build/ql/scratchdir/hive_2010-04-06_13-16-17_519_5426148572496063749/10000
+POSTHOOK: Output: file:/data/users/nzhang/work/999/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-20_11-17-38_126_6207291158988738744/10000
 POSTHOOK: Lineage: tmp1.a SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: tmp1.b SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: tmp2.a SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
