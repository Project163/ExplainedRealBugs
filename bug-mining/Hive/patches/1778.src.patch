diff --git a/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java b/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
index 7444294018..b36a4ca6cc 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
@@ -366,9 +366,9 @@ public enum ErrorMsg {
   UNSUPPORTED_SUBQUERY_EXPRESSION(10249, "Unsupported SubQuery Expression"),
   INVALID_SUBQUERY_EXPRESSION(10250, "Invalid SubQuery expression"),
 
-  INVALID_HDFS_URI(10248, "{0} is not a hdfs uri", true),
-  INVALID_DIR(10249, "{0} is not a directory", true),
-  NO_VALID_LOCATIONS(10250, "Could not find any valid location to place the jars. " +
+  INVALID_HDFS_URI(10251, "{0} is not a hdfs uri", true),
+  INVALID_DIR(10252, "{0} is not a directory", true),
+  NO_VALID_LOCATIONS(10253, "Could not find any valid location to place the jars. " +
   "Please update hive.jar.directory or hive.user.install.directory with a valid location", false),
 
   SCRIPT_INIT_ERROR(20000, "Unable to initialize custom script."),
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
index b36767c408..bbde09c0ff 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
@@ -29,6 +29,7 @@
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.ql.io.IOContext;
 import org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory;
 import org.apache.hadoop.hive.ql.plan.CollectDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc;
@@ -313,6 +314,7 @@ public void testMapOperator() throws Throwable {
       Configuration hconf = new JobConf(TestOperators.class);
       HiveConf.setVar(hconf, HiveConf.ConfVars.HADOOPMAPFILENAME,
           "hdfs:///testDir/testFile");
+      IOContext.get().setInputPath(new Path("hdfs:///testDir/testFile"));
 
       // initialize pathToAliases
       ArrayList<String> aliases = new ArrayList<String>();
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java b/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java
index 1a7288d1bd..93b50c6006 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java
@@ -19,6 +19,7 @@
 
 import static org.junit.Assert.assertArrayEquals;
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
 
 import java.io.DataInput;
 import java.io.DataOutput;
@@ -562,7 +563,6 @@ public void testInOutFormat() throws Exception {
     IntObjectInspector intInspector =
         (IntObjectInspector) fields.get(0).getFieldObjectInspector();
     assertEquals(0.0, reader.getProgress(), 0.00001);
-    assertEquals(3, reader.getPos());
     while (reader.next(key, value)) {
       assertEquals(++rowNum, intInspector.get(inspector.
           getStructFieldData(serde.deserialize(value), fields.get(0))));
@@ -697,7 +697,7 @@ public void testEmptyFile() throws Exception {
     InputFormat<?,?> in = new OrcInputFormat();
     FileInputFormat.setInputPaths(conf, testFilePath.toString());
     InputSplit[] splits = in.getSplits(conf, 1);
-    assertEquals(0, splits.length);
+    assertTrue(1 == splits.length);
     assertEquals(null, serde.getSerDeStats());
   }
 
