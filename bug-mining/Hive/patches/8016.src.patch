diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java
index 2874108973..d0ae8d5c01 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java
@@ -135,6 +135,7 @@ public abstract class BaseSemanticAnalyzer {
   protected Context ctx;
   protected Map<String, String> idToTableNameMap;
   protected QueryProperties queryProperties;
+  ParseContext pCtx = null;
 
   /**
    * A set of FileSinkOperators being written to in an ACID compliant way.  We need to remember
@@ -1924,4 +1925,8 @@ public void endAnalysis() {
     // Nothing to do
   }
 
+  public ParseContext getParseContext() {
+    return pCtx;
+  }
+
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/ExplainSemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/ExplainSemanticAnalyzer.java
index 9f1bcd9982..a144839fa9 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/ExplainSemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/ExplainSemanticAnalyzer.java
@@ -189,9 +189,8 @@ public void analyzeInternal(ASTNode ast) throws SemanticException {
       fetchTask.getWork().initializeForFetch(ctx.getOpContext());
     }
 
-    ParseContext pCtx = null;
     if (sem instanceof SemanticAnalyzer) {
-      pCtx = ((SemanticAnalyzer)sem).getParseContext();
+      pCtx = sem.getParseContext();
     }
 
     config.setUserLevelExplain(!config.isExtended()
@@ -289,5 +288,4 @@ public boolean skipAuthorization() {
     }
     return super.skipAuthorization();
   }
-
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/command/CommandAuthorizerV1.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/command/CommandAuthorizerV1.java
index e14e73bfb8..b43a958f36 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/command/CommandAuthorizerV1.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/command/CommandAuthorizerV1.java
@@ -194,10 +194,9 @@ private static void getTablePartitionUsedColumns(HiveOperation op, BaseSemanticA
     // for a select or create-as-select query, populate the partition to column (par2Cols) or
     // table to columns mapping (tab2Cols)
     if (op.equals(HiveOperation.CREATETABLE_AS_SELECT) || op.equals(HiveOperation.QUERY)) {
-      SemanticAnalyzer querySem = (SemanticAnalyzer) sem;
-      ParseContext parseCtx = querySem.getParseContext();
+      ParseContext parseCtx = sem.getParseContext();
 
-      for (Map.Entry<String, TableScanOperator> topOpMap : querySem.getParseContext().getTopOps().entrySet()) {
+      for (Map.Entry<String, TableScanOperator> topOpMap : parseCtx.getTopOps().entrySet()) {
         TableScanOperator tableScanOp = topOpMap.getValue();
         if (!tableScanOp.isInsideView()) {
           Table tbl = tableScanOp.getConf().getTableMetadata();
diff --git a/ql/src/test/queries/clientpositive/explain_defaultauthorizer.q b/ql/src/test/queries/clientpositive/explain_defaultauthorizer.q
new file mode 100644
index 0000000000..dc21fc44f0
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/explain_defaultauthorizer.q
@@ -0,0 +1,5 @@
+--! qt:dataset:src
+
+set hive.security.authorization.enabled=true;
+set hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.DefaultHiveAuthorizationProvider;
+EXPLAIN SELECT * FROM src;
diff --git a/ql/src/test/results/clientpositive/llap/explain_defaultauthorizer.q.out b/ql/src/test/results/clientpositive/llap/explain_defaultauthorizer.q.out
new file mode 100644
index 0000000000..e2c5a5e598
--- /dev/null
+++ b/ql/src/test/results/clientpositive/llap/explain_defaultauthorizer.q.out
@@ -0,0 +1,23 @@
+PREHOOK: query: EXPLAIN SELECT * FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: EXPLAIN SELECT * FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: src
+          Select Operator
+            expressions: key (type: string), value (type: string)
+            outputColumnNames: _col0, _col1
+            ListSink
+
