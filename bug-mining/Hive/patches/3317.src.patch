diff --git a/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java b/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
index 541531ca6b..f97d462a13 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
@@ -444,6 +444,9 @@ public enum ErrorMsg {
       "is controlled by hive.exec.max.dynamic.partitions and hive.exec.max.dynamic.partitions.pernode. "),
   PARTITION_SCAN_LIMIT_EXCEEDED(20005, "Number of partitions scanned (={0}) on table {1} exceeds limit" +
       " (={2}). This is controlled by hive.limit.query.max.table.partition.", true),
+  OP_NOT_ALLOWED_IN_AUTOCOMMIT(20006, "Operation {0} is not allowed when autoCommit=true.", true),//todo: better SQLState?
+  OP_NOT_ALLOWED_IN_TXN(20007, "Operation {0} is not allowed in a transaction.  TransactionID={1}.", true),
+  OP_NOT_ALLOWED_WITHOUT_TXN(2008, "Operation {0} is not allowed since autoCommit=false and there is no active transaction", true),
 
   //========================== 30000 range starts here ========================//
   STATSPUBLISHER_NOT_OBTAINED(30000, "StatsPublisher cannot be obtained. " +
@@ -509,7 +512,7 @@ public enum ErrorMsg {
   static {
     for (ErrorMsg errorMsg : values()) {
       if (errorMsg.format != null) {
-        String pattern = errorMsg.mesg.replaceAll("\\{.*\\}", ".*");
+        String pattern = errorMsg.mesg.replaceAll("\\{[0-9]+\\}", ".*");
         formatToErrorMsgMap.put(Pattern.compile("^" + pattern + "$"), errorMsg);
       } else {
         mesgToErrorMsgMap.put(errorMsg.getMsg().trim(), errorMsg);
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestErrorMsg.java b/ql/src/test/org/apache/hadoop/hive/ql/TestErrorMsg.java
index 0654a0a8af..c5b658fc27 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/TestErrorMsg.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestErrorMsg.java
@@ -23,9 +23,11 @@
 
 import junit.framework.Assert;
 import junit.framework.TestCase;
+import org.junit.Test;
 
-public class TestErrorMsg extends TestCase {
+public class TestErrorMsg {
 
+  @Test
   public void testUniqueErrorCode() {
     Set<Integer> numbers = new HashSet<Integer>();
     for (ErrorMsg err : ErrorMsg.values()) {
@@ -33,4 +35,15 @@ public void testUniqueErrorCode() {
       Assert.assertTrue("duplicated error number " + code, numbers.add(code));
     }
   }
+  @Test
+  public void testReverseMatch() {
+    testReverseMatch(ErrorMsg.OP_NOT_ALLOWED_IN_AUTOCOMMIT, "COMMIT");
+    testReverseMatch(ErrorMsg.OP_NOT_ALLOWED_IN_TXN, "ALTER TABLE", "1");
+    testReverseMatch(ErrorMsg.OP_NOT_ALLOWED_WITHOUT_TXN, "ROLLBACK");
+  }
+  private void testReverseMatch(ErrorMsg errorMsg, String... args) {
+    String parametrizedMsg = errorMsg.format(args);
+    ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(parametrizedMsg);
+    Assert.assertEquals("Didn't find expected msg", errorMsg.getErrorCode(), canonicalMsg.getErrorCode());
+  }
 }
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/parse/TestUpdateDeleteSemanticAnalyzer.java b/ql/src/test/org/apache/hadoop/hive/ql/parse/TestUpdateDeleteSemanticAnalyzer.java
index b9f2edeb1e..e1cab7901e 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/parse/TestUpdateDeleteSemanticAnalyzer.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/parse/TestUpdateDeleteSemanticAnalyzer.java
@@ -17,15 +17,12 @@
  */
 package org.apache.hadoop.hive.ql.parse;
 
-import static org.junit.Assert.*;
-
 import java.io.File;
 import java.io.IOException;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Map;
 
-import junit.framework.Assert;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.fs.FSDataInputStream;
@@ -44,7 +41,6 @@
 import org.apache.hadoop.hive.ql.plan.ExplainWork;
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.junit.Before;
-import org.junit.Ignore;
 import org.junit.Test;
 
 public class TestUpdateDeleteSemanticAnalyzer {
