diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index 7932a3db5d..bfe08a0d41 100644
--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -182,6 +182,7 @@ public static enum ConfVars {
     LOCALSCRATCHDIR("hive.exec.local.scratchdir", System.getProperty("java.io.tmpdir") + File.separator + System.getProperty("user.name")),
     SCRATCHDIRPERMISSION("hive.scratch.dir.permission", "700"),
     SUBMITVIACHILD("hive.exec.submitviachild", false),
+    SUBMITLOCALTASKVIACHILD("hive.exec.submit.local.task.via.child", true),
     SCRIPTERRORLIMIT("hive.exec.script.maxerrsize", 100000),
     ALLOWPARTIALCONSUMP("hive.exec.script.allow.partial.consumption", false),
     STREAMREPORTERPERFIX("stream.stderr.reporter.prefix", "reporter:"),
diff --git a/contrib/src/test/queries/clientnegative/case_with_row_sequence.q b/contrib/src/test/queries/clientnegative/case_with_row_sequence.q
index b51dc6e70b..910ffdaa40 100644
--- a/contrib/src/test/queries/clientnegative/case_with_row_sequence.q
+++ b/contrib/src/test/queries/clientnegative/case_with_row_sequence.q
@@ -1,3 +1,6 @@
+set hive.exec.submitviachild=true;
+set hive.exec.submit.local.task.via.child=true;
+
 drop temporary function row_sequence;
 
 add jar ${system:maven.local.repository}/org/apache/hive/hive-contrib/${system:hive.version}/hive-contrib-${system:hive.version}.jar;
diff --git a/contrib/src/test/queries/clientpositive/dboutput.q b/contrib/src/test/queries/clientpositive/dboutput.q
index 28f17108f2..4c4f5d5897 100644
--- a/contrib/src/test/queries/clientpositive/dboutput.q
+++ b/contrib/src/test/queries/clientpositive/dboutput.q
@@ -6,6 +6,8 @@ set mapred.map.tasks.speculative.execution=false;
 set mapred.reduce.tasks.speculative.execution=false;
 set mapred.map.tasks=1;
 set mapred.reduce.tasks=1;
+set hive.exec.submitviachild=true;
+set hive.exec.submit.local.task.via.child=true;
 
 ADD JAR ${system:maven.local.repository}/org/apache/derby/derby/${system:derby.version}/derby-${system:derby.version}.jar;
 
diff --git a/data/conf/hive-site.xml b/data/conf/hive-site.xml
index 7931d6a712..1c9c59866c 100644
--- a/data/conf/hive-site.xml
+++ b/data/conf/hive-site.xml
@@ -216,4 +216,9 @@
   <description>Using dummy config value above because you cannot override config with empty value</description>
 </property>
 
+<property>
+  <name>hive.exec.submit.local.task.via.child</name>
+  <value>false</value>
+</property>
+
 </configuration>
diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/TestMTQueries.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/TestMTQueries.java
index 337c50b91d..8a5bb1d034 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/TestMTQueries.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/TestMTQueries.java
@@ -41,6 +41,8 @@ public void testMTQueries1() throws Exception {
     QTestUtil[] qts = QTestUtil.queryListRunnerSetup(qfiles, resDir, logDir);
     for (QTestUtil util : qts) {
       // derby fails creating multiple stats aggregator concurrently
+      util.getConf().setBoolean("hive.exec.submitviachild", true);
+      util.getConf().setBoolean("hive.exec.submit.local.task.via.child", true);
       util.getConf().set("hive.stats.dbclass", "custom");
       util.getConf().set("hive.stats.default.aggregator", "org.apache.hadoop.hive.ql.stats.DummyStatsAggregator");
       util.getConf().set("hive.stats.default.publisher", "org.apache.hadoop.hive.ql.stats.DummyStatsPublisher");
diff --git a/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java b/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
index 2974327d4f..39375bb3b7 100644
--- a/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
+++ b/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
@@ -827,6 +827,7 @@ public String cliInit(String tname, boolean recreate) throws Exception {
 
     HiveConf.setVar(conf, HiveConf.ConfVars.HIVE_AUTHENTICATOR_MANAGER,
     "org.apache.hadoop.hive.ql.security.DummyAuthenticator");
+    Utilities.clearWorkMap();
     CliSessionState ss = new CliSessionState(conf);
     assert ss != null;
     ss.in = System.in;
@@ -1264,7 +1265,8 @@ private void maskPatterns(Pattern[] patterns, String fname) throws Exception {
       "^Deleted.*",
       ".*DagName:.*",
       ".*Input:.*/data/files/.*",
-      ".*Output:.*/data/files/.*"
+      ".*Output:.*/data/files/.*",
+      ".*total number of created files now is.*"
   });
 
   public int checkCliDriverResults(String tname) throws Exception {
diff --git a/pom.xml b/pom.xml
index 99fe9d6934..b5a5697e6a 100644
--- a/pom.xml
+++ b/pom.xml
@@ -729,7 +729,7 @@
           <redirectTestOutputToFile>true</redirectTestOutputToFile>
           <reuseForks>false</reuseForks>
           <failIfNoTests>false</failIfNoTests>
-          <argLine>-Xmx1024m -XX:MaxPermSize=256m</argLine>
+          <argLine>-Xmx2048m -XX:MaxPermSize=512m</argLine>
           <additionalClasspathElements>
             <additionalClasspathElement>${test.tmp.dir}/conf</additionalClasspathElement>
             <additionalClasspathElement>${basedir}/${hive.path.to.root}/conf</additionalClasspathElement>
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
index 179ad29b22..5d88c5a3fd 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
@@ -732,7 +732,7 @@ public static void main(String[] args) throws IOException, HiveException {
       memoryMXBean = ManagementFactory.getMemoryMXBean();
       MapredLocalWork plan = Utilities.deserializePlan(pathData, MapredLocalWork.class, conf);
       MapredLocalTask ed = new MapredLocalTask(plan, conf, isSilent);
-      ret = ed.executeFromChildJVM(new DriverContext());
+      ret = ed.executeInProcess(new DriverContext());
 
     } else {
       MapredWork plan = Utilities.deserializePlan(pathData, MapredWork.class, conf);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapRedTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapRedTask.java
index 2ce4dbd8a2..a9869f72b4 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapRedTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapRedTask.java
@@ -127,8 +127,7 @@ public int execute(DriverContext driverContext) {
         }
       }
 
-      runningViaChild = ShimLoader.getHadoopShims().isLocalMode(conf) ||
-        conf.getBoolVar(HiveConf.ConfVars.SUBMITVIACHILD);
+      runningViaChild = conf.getBoolVar(HiveConf.ConfVars.SUBMITVIACHILD);
 
       if(!runningViaChild) {
         // we are not running this mapred task via child jvm
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
index d2e122d80a..ff44cb1dc0 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
@@ -130,6 +130,17 @@ public boolean requireLock() {
 
   @Override
   public int execute(DriverContext driverContext) {
+    if (conf.getBoolVar(HiveConf.ConfVars.SUBMITLOCALTASKVIACHILD)) {
+      // send task off to another jvm
+      return executeInChildVM(driverContext);
+    } else {
+      // execute in process
+      return executeInProcess(driverContext);
+    }
+  }
+
+  public int executeInChildVM(DriverContext driverContext) {
+    // execute in child jvm
     try {
       // generate the cmd line to run in the child jvm
       Context ctx = driverContext.getCtx();
@@ -285,9 +296,7 @@ public int execute(DriverContext driverContext) {
     }
   }
 
-
-
-  public int executeFromChildJVM(DriverContext driverContext) {
+  public int executeInProcess(DriverContext driverContext) {
     // check the local work
     if (work == null) {
       return -1;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCount.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCount.java
index 89bc1a7015..54aa987e94 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCount.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCount.java
@@ -130,7 +130,6 @@ public void iterate(AggregationBuffer agg, Object[] parameters)
         assert parameters.length == 0;
         ((CountAgg) agg).value++;
       } else {
-        assert parameters.length > 0;
         boolean countThisRow = true;
         for (Object nextParam : parameters) {
           if (nextParam == null) {
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
index ef978e37e9..63ecb8d125 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
@@ -80,6 +80,9 @@ public class TestExecDriver extends TestCase {
   static {
     try {
       conf = new HiveConf(ExecDriver.class);
+      conf.setBoolVar(HiveConf.ConfVars.SUBMITVIACHILD, true);
+      conf.setBoolVar(HiveConf.ConfVars.SUBMITLOCALTASKVIACHILD, true);
+
       SessionState.start(conf);
 
       //convert possible incompatible Windows path in config
diff --git a/ql/src/test/queries/clientpositive/archive_excludeHadoop20.q b/ql/src/test/queries/clientpositive/archive_excludeHadoop20.q
index 50c0faa5e4..90757f2c6a 100644
--- a/ql/src/test/queries/clientpositive/archive_excludeHadoop20.q
+++ b/ql/src/test/queries/clientpositive/archive_excludeHadoop20.q
@@ -1,5 +1,7 @@
 set hive.archive.enabled = true;
 set hive.enforce.bucketing = true;
+set hive.exec.submitviachild=true;
+set hive.exec.submit.local.task.via.child=true;
 
 -- EXCLUDE_HADOOP_MAJOR_VERSIONS(0.20)
 
diff --git a/ql/src/test/queries/clientpositive/dynpart_sort_opt_vectorization.q b/ql/src/test/queries/clientpositive/dynpart_sort_opt_vectorization.q
index 5f1a5ce809..814f1007fa 100644
--- a/ql/src/test/queries/clientpositive/dynpart_sort_opt_vectorization.q
+++ b/ql/src/test/queries/clientpositive/dynpart_sort_opt_vectorization.q
@@ -6,6 +6,8 @@ set hive.exec.dynamic.partition.mode=nonstrict;
 set hive.vectorized.execution.enabled=true;
 set hive.enforce.bucketing=false;
 set hive.enforce.sorting=false;
+set hive.exec.submitviachild=true;
+set hive.exec.submit.local.task.via.child=true;
 
 create table over1k(
            t tinyint,
diff --git a/ql/src/test/queries/clientpositive/dynpart_sort_optimization.q b/ql/src/test/queries/clientpositive/dynpart_sort_optimization.q
index 52b5d1e0c1..8c3c68f83a 100644
--- a/ql/src/test/queries/clientpositive/dynpart_sort_optimization.q
+++ b/ql/src/test/queries/clientpositive/dynpart_sort_optimization.q
@@ -5,6 +5,8 @@ set hive.exec.max.dynamic.partitions.pernode=1000;
 set hive.exec.dynamic.partition.mode=nonstrict;
 set hive.enforce.bucketing=false;
 set hive.enforce.sorting=false;
+set hive.exec.submitviachild=true;
+set hive.exec.submit.local.task.via.child=true;
 
 create table over1k(
            t tinyint,
diff --git a/ql/src/test/queries/clientpositive/fetch_aggregation.q b/ql/src/test/queries/clientpositive/fetch_aggregation.q
index 618fea158a..a56b6c8197 100644
--- a/ql/src/test/queries/clientpositive/fetch_aggregation.q
+++ b/ql/src/test/queries/clientpositive/fetch_aggregation.q
@@ -1,4 +1,6 @@
 set hive.fetch.task.aggr=true;
+set hive.exec.submitviachild=true;
+set hive.exec.submit.local.task.via.child=true;
 
 explain
 select count(key),sum(key),avg(key),min(key),max(key),std(key),variance(key) from src;
diff --git a/ql/src/test/queries/clientpositive/nonmr_fetch.q b/ql/src/test/queries/clientpositive/nonmr_fetch.q
index e961e93a18..2a92d175a3 100644
--- a/ql/src/test/queries/clientpositive/nonmr_fetch.q
+++ b/ql/src/test/queries/clientpositive/nonmr_fetch.q
@@ -1,4 +1,6 @@
 set hive.fetch.task.conversion=minimal;
+set hive.exec.submitviachild=true;
+set hive.exec.submit.local.task.via.child=true;
 
 -- backward compatible (minimal)
 explain select * from src limit 10;
diff --git a/ql/src/test/queries/clientpositive/orc_analyze.q b/ql/src/test/queries/clientpositive/orc_analyze.q
index 915f4f0d71..3621c7a4d8 100644
--- a/ql/src/test/queries/clientpositive/orc_analyze.q
+++ b/ql/src/test/queries/clientpositive/orc_analyze.q
@@ -1,3 +1,6 @@
+set hive.exec.submitviachild=true;
+set hive.exec.submit.local.task.via.child=true;
+
 CREATE TABLE orc_create_people_staging (
   id int,
   first_name string,
diff --git a/ql/src/test/queries/clientpositive/sample10.q b/ql/src/test/queries/clientpositive/sample10.q
index 1c6695c541..d9fe744f44 100644
--- a/ql/src/test/queries/clientpositive/sample10.q
+++ b/ql/src/test/queries/clientpositive/sample10.q
@@ -1,4 +1,5 @@
-
+set hive.exec.submitviachild=true;
+set hive.exec.submit.local.task.via.child=true;
 set hive.exec.dynamic.partition=true;
 set hive.exec.dynamic.partition.mode=nonstrict;
 set hive.enforce.bucketing=true;
diff --git a/ql/src/test/queries/clientpositive/sample_islocalmode_hook.q b/ql/src/test/queries/clientpositive/sample_islocalmode_hook.q
index 12f2bcd46e..0c8424b406 100644
--- a/ql/src/test/queries/clientpositive/sample_islocalmode_hook.q
+++ b/ql/src/test/queries/clientpositive/sample_islocalmode_hook.q
@@ -1,3 +1,5 @@
+set hive.exec.submitviachild=true;
+set hive.exec.submit.local.task.via.child=true;
 set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
 set mapred.max.split.size=300;
 set mapred.min.split.size=300;
diff --git a/ql/src/test/queries/clientpositive/vectorized_parquet.q b/ql/src/test/queries/clientpositive/vectorized_parquet.q
index 5ce1cf0965..4b14628712 100644
--- a/ql/src/test/queries/clientpositive/vectorized_parquet.q
+++ b/ql/src/test/queries/clientpositive/vectorized_parquet.q
@@ -1,3 +1,6 @@
+set hive.exec.submitviachild=true;
+set hive.exec.submit.local.task.via.child=true;
+
 create table if not exists alltypes_parquet (
   cint int, 
   ctinyint tinyint, 
diff --git a/ql/src/test/results/clientnegative/cachingprintstream.q.out b/ql/src/test/results/clientnegative/cachingprintstream.q.out
index d231136ef6..0acb77265f 100644
--- a/ql/src/test/results/clientnegative/cachingprintstream.q.out
+++ b/ql/src/test/results/clientnegative/cachingprintstream.q.out
@@ -7,31 +7,11 @@ TEST, this should only appear once in the log.
 PREHOOK: query: FROM src SELECT TRANSFORM (key, value) USING 'FAKE_SCRIPT_SHOULD_NOT_EXIST' AS key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 Begin cached logs.
 PREHOOK: query: FROM src SELECT TRANSFORM (key, value) USING 'FAKE_SCRIPT_SHOULD_NOT_EXIST' AS key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 End cached logs.
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/compute_stats_long.q.out b/ql/src/test/results/clientnegative/compute_stats_long.q.out
index c1373bed59..3be6320fab 100644
--- a/ql/src/test/results/clientnegative/compute_stats_long.q.out
+++ b/ql/src/test/results/clientnegative/compute_stats_long.q.out
@@ -19,15 +19,5 @@ PREHOOK: query: -- compute stats should raise an error since the number of bit v
 select compute_stats(a, 10000) from tab_int
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tab_int
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/dyn_part3.q.out b/ql/src/test/results/clientnegative/dyn_part3.q.out
index 4de5005f40..658ce5f2fe 100644
--- a/ql/src/test/results/clientnegative/dyn_part3.q.out
+++ b/ql/src/test/results/clientnegative/dyn_part3.q.out
@@ -9,14 +9,5 @@ PREHOOK: query: insert overwrite table nzhang_part partition(value) select key,
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@nzhang_part
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/dyn_part_max_per_node.q.out b/ql/src/test/results/clientnegative/dyn_part_max_per_node.q.out
index c7ed8ca2e9..4a463543d2 100644
--- a/ql/src/test/results/clientnegative/dyn_part_max_per_node.q.out
+++ b/ql/src/test/results/clientnegative/dyn_part_max_per_node.q.out
@@ -20,14 +20,5 @@ LIMIT 50
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@max_parts
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-2
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/index_compact_entry_limit.q.out b/ql/src/test/results/clientnegative/index_compact_entry_limit.q.out
index 2b4dfacdd1..85614ca2ce 100644
--- a/ql/src/test/results/clientnegative/index_compact_entry_limit.q.out
+++ b/ql/src/test/results/clientnegative/index_compact_entry_limit.q.out
@@ -29,14 +29,5 @@ PREHOOK: query: SELECT key, value FROM src WHERE key=100 ORDER BY key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 #### A masked pattern was here ####
-Execution failed with exit status: 1
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
-#### A masked pattern was here ####
+Job Submission failed with exception 'java.io.IOException(org.apache.hadoop.hive.ql.metadata.HiveException: Number of compact index entries loaded during the query exceeded the maximum of 5 set in hive.index.compact.query.max.entries)'
 FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/index_compact_size_limit.q.out b/ql/src/test/results/clientnegative/index_compact_size_limit.q.out
index 2b4dfacdd1..7c6bb0ae36 100644
--- a/ql/src/test/results/clientnegative/index_compact_size_limit.q.out
+++ b/ql/src/test/results/clientnegative/index_compact_size_limit.q.out
@@ -29,14 +29,5 @@ PREHOOK: query: SELECT key, value FROM src WHERE key=100 ORDER BY key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 #### A masked pattern was here ####
-Execution failed with exit status: 1
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
-#### A masked pattern was here ####
+Job Submission failed with exception 'java.io.IOException(Size of data to read during a compact-index-based query exceeded the maximum of 1024 set in hive.index.compact.query.max.size)'
 FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/local_mapred_error_cache.q.out b/ql/src/test/results/clientnegative/local_mapred_error_cache.q.out
index 60df1cd465..f5cf1eace2 100644
--- a/ql/src/test/results/clientnegative/local_mapred_error_cache.q.out
+++ b/ql/src/test/results/clientnegative/local_mapred_error_cache.q.out
@@ -2,22 +2,4 @@ PREHOOK: query: FROM src SELECT TRANSFORM(key, value) USING 'python ../../data/s
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 #### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
-#### A masked pattern was here ####
-ID: Stage-1
-org.apache.hadoop.hive.ql.metadata.HiveException: [Error 20003]: An error occurred when trying to close the Operator running your custom script.
-#### A masked pattern was here ####
-org.apache.hadoop.hive.ql.metadata.HiveException: [Error 20003]: An error occurred when trying to close the Operator running your custom script.
-#### A masked pattern was here ####
-org.apache.hadoop.hive.ql.metadata.HiveException: [Error 20003]: An error occurred when trying to close the Operator running your custom script.
-#### A masked pattern was here ####
-Error during job, obtaining debugging information...
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/script_broken_pipe2.q.out b/ql/src/test/results/clientnegative/script_broken_pipe2.q.out
index e29e115ae2..7e186a0bf6 100644
--- a/ql/src/test/results/clientnegative/script_broken_pipe2.q.out
+++ b/ql/src/test/results/clientnegative/script_broken_pipe2.q.out
@@ -2,15 +2,5 @@ PREHOOK: query: -- Tests exception in ScriptOperator.processOp() by passing extr
 SELECT TRANSFORM(key, value, key, value, key, value, key, value, key, value, key, value, key, value, key, value, key, value, key, value, key, value, key, value) USING 'true' as a,b,c,d FROM src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/script_broken_pipe3.q.out b/ql/src/test/results/clientnegative/script_broken_pipe3.q.out
index 1bf4fb287a..575b8f2a58 100644
--- a/ql/src/test/results/clientnegative/script_broken_pipe3.q.out
+++ b/ql/src/test/results/clientnegative/script_broken_pipe3.q.out
@@ -2,15 +2,5 @@ PREHOOK: query: -- Test to ensure that a script with a bad error code still fail
 SELECT TRANSFORM(*) USING 'false' AS a, b FROM (SELECT TRANSFORM(*) USING 'echo' AS a, b FROM src LIMIT 1) tmp
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/script_error.q.out b/ql/src/test/results/clientnegative/script_error.q.out
index c932d41685..47acc55a8b 100644
--- a/ql/src/test/results/clientnegative/script_error.q.out
+++ b/ql/src/test/results/clientnegative/script_error.q.out
@@ -46,15 +46,5 @@ PREHOOK: query: SELECT TRANSFORM(src.key, src.value) USING '../../data/scripts/e
 FROM src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/serde_regex2.q.out b/ql/src/test/results/clientnegative/serde_regex2.q.out
index c68f075ec9..8ed0bee0e7 100644
--- a/ql/src/test/results/clientnegative/serde_regex2.q.out
+++ b/ql/src/test/results/clientnegative/serde_regex2.q.out
@@ -59,15 +59,5 @@ PREHOOK: query: -- raise an exception
 SELECT * FROM serde_regex ORDER BY time
 PREHOOK: type: QUERY
 PREHOOK: Input: default@serde_regex
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/stats_aggregator_error_2.q.out b/ql/src/test/results/clientnegative/stats_aggregator_error_2.q.out
index 5727cfe277..d9c5c06277 100644
--- a/ql/src/test/results/clientnegative/stats_aggregator_error_2.q.out
+++ b/ql/src/test/results/clientnegative/stats_aggregator_error_2.q.out
@@ -30,14 +30,5 @@ PREHOOK: query: INSERT OVERWRITE TABLE tmptable select * from src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@tmptable
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/stats_publisher_error_1.q.out b/ql/src/test/results/clientnegative/stats_publisher_error_1.q.out
index f0bbc2fa24..ae898609af 100644
--- a/ql/src/test/results/clientnegative/stats_publisher_error_1.q.out
+++ b/ql/src/test/results/clientnegative/stats_publisher_error_1.q.out
@@ -31,14 +31,5 @@ PREHOOK: query: INSERT OVERWRITE TABLE tmptable select * from src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@tmptable
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/stats_publisher_error_2.q.out b/ql/src/test/results/clientnegative/stats_publisher_error_2.q.out
index 2ff15ebc72..5cec747477 100644
--- a/ql/src/test/results/clientnegative/stats_publisher_error_2.q.out
+++ b/ql/src/test/results/clientnegative/stats_publisher_error_2.q.out
@@ -30,14 +30,5 @@ PREHOOK: query: INSERT OVERWRITE TABLE tmptable select * from src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@tmptable
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/udf_assert_true.q.out b/ql/src/test/results/clientnegative/udf_assert_true.q.out
index 0e17231d79..6f180112a0 100644
--- a/ql/src/test/results/clientnegative/udf_assert_true.q.out
+++ b/ql/src/test/results/clientnegative/udf_assert_true.q.out
@@ -150,15 +150,5 @@ STAGE PLANS:
 PREHOOK: query: SELECT ASSERT_TRUE(x < 2) FROM src LATERAL VIEW EXPLODE(ARRAY(1, 2)) a AS x LIMIT 2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/udf_assert_true2.q.out b/ql/src/test/results/clientnegative/udf_assert_true2.q.out
index 0506970c4f..abc721e94a 100644
--- a/ql/src/test/results/clientnegative/udf_assert_true2.q.out
+++ b/ql/src/test/results/clientnegative/udf_assert_true2.q.out
@@ -68,15 +68,5 @@ STAGE PLANS:
 PREHOOK: query: SELECT 1 + ASSERT_TRUE(x < 2) FROM src LATERAL VIEW EXPLODE(ARRAY(1, 2)) a AS x LIMIT 2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/udf_reflect_neg.q.out b/ql/src/test/results/clientnegative/udf_reflect_neg.q.out
index d65acadb0d..7ae91b5eef 100644
--- a/ql/src/test/results/clientnegative/udf_reflect_neg.q.out
+++ b/ql/src/test/results/clientnegative/udf_reflect_neg.q.out
@@ -8,15 +8,5 @@ PREHOOK: query: SELECT reflect("java.lang.StringClassThatDoesNotExist", "valueOf
 FROM src LIMIT 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/udf_test_error.q.out b/ql/src/test/results/clientnegative/udf_test_error.q.out
index fae8c3cbd5..3146652404 100644
--- a/ql/src/test/results/clientnegative/udf_test_error.q.out
+++ b/ql/src/test/results/clientnegative/udf_test_error.q.out
@@ -7,15 +7,5 @@ POSTHOOK: Output: database:default
 PREHOOK: query: SELECT test_error(key < 125 OR key > 130) FROM src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientnegative/udf_test_error_reduce.q.out b/ql/src/test/results/clientnegative/udf_test_error_reduce.q.out
index 2c4642a858..c83c50309d 100644
--- a/ql/src/test/results/clientnegative/udf_test_error_reduce.q.out
+++ b/ql/src/test/results/clientnegative/udf_test_error_reduce.q.out
@@ -12,15 +12,5 @@ FROM (
 ) map_output
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-#### A masked pattern was here ####
-Execution failed with exit status: 2
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-1
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
diff --git a/ql/src/test/results/clientpositive/auto_join25.q.out b/ql/src/test/results/clientpositive/auto_join25.q.out
index 927f898022..21188f89c9 100644
--- a/ql/src/test/results/clientpositive/auto_join25.q.out
+++ b/ql/src/test/results/clientpositive/auto_join25.q.out
@@ -19,16 +19,6 @@ PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 PREHOOK: Output: default@dest1
-Execution failed with exit status: 3
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-7
-
-Logs:
-
-#### A masked pattern was here ####
 FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
 ATTEMPT: Execute BackupTask: org.apache.hadoop.hive.ql.exec.mr.MapRedTask
 POSTHOOK: query: FROM srcpart src1 JOIN src src2 ON (src1.key = src2.key)
@@ -72,28 +62,8 @@ INSERT OVERWRITE TABLE dest_j2 SELECT src1.key, src3.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@dest_j2
-Execution failed with exit status: 3
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-14
-
-Logs:
-
-#### A masked pattern was here ####
 FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
 ATTEMPT: Execute BackupTask: org.apache.hadoop.hive.ql.exec.mr.MapRedTask
-Execution failed with exit status: 3
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-12
-
-Logs:
-
-#### A masked pattern was here ####
 FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
 ATTEMPT: Execute BackupTask: org.apache.hadoop.hive.ql.exec.mr.MapRedTask
 POSTHOOK: query: FROM src src1 JOIN src src2 ON (src1.key = src2.key) JOIN src src3 ON (src1.key + src2.key = src3.key)
@@ -134,16 +104,6 @@ INSERT OVERWRITE TABLE dest_j1 SELECT src1.key, src2.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@dest_j1
-Execution failed with exit status: 3
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-7
-
-Logs:
-
-#### A masked pattern was here ####
 FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
 ATTEMPT: Execute BackupTask: org.apache.hadoop.hive.ql.exec.mr.MapRedTask
 POSTHOOK: query: FROM src src1 JOIN src src2 ON (src1.key = src2.key)
diff --git a/ql/src/test/results/clientpositive/auto_join_without_localtask.q.out b/ql/src/test/results/clientpositive/auto_join_without_localtask.q.out
index d2efd8f831..e4db2df3e9 100644
--- a/ql/src/test/results/clientpositive/auto_join_without_localtask.q.out
+++ b/ql/src/test/results/clientpositive/auto_join_without_localtask.q.out
@@ -934,29 +934,9 @@ PREHOOK: query: -- fallback to common join
 select a.* from src a join src b on a.key=b.key join src c on a.value=c.value where a.key>100 limit 40
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-#### A masked pattern was here ####
-Execution failed with exit status: 3
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-14
-
-Logs:
-
 #### A masked pattern was here ####
 FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
 ATTEMPT: Execute BackupTask: org.apache.hadoop.hive.ql.exec.mr.MapRedTask
-Execution failed with exit status: 3
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-11
-
-Logs:
-
-#### A masked pattern was here ####
 FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
 ATTEMPT: Execute BackupTask: org.apache.hadoop.hive.ql.exec.mr.MapRedTask
 POSTHOOK: query: -- fallback to common join
diff --git a/ql/src/test/results/clientpositive/infer_bucket_sort_convert_join.q.out b/ql/src/test/results/clientpositive/infer_bucket_sort_convert_join.q.out
index 01195d6999..1508d0e648 100644
--- a/ql/src/test/results/clientpositive/infer_bucket_sort_convert_join.q.out
+++ b/ql/src/test/results/clientpositive/infer_bucket_sort_convert_join.q.out
@@ -76,16 +76,6 @@ SELECT a.key, b.value FROM src a JOIN src b ON a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@test_table@part=1
-Execution failed with exit status: 3
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-7
-
-Logs:
-
-#### A masked pattern was here ####
 FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
 ATTEMPT: Execute BackupTask: org.apache.hadoop.hive.ql.exec.mr.MapRedTask
 POSTHOOK: query: -- This test tests the scenario when the mapper dies. So, create a conditional task for the mapjoin.
diff --git a/ql/src/test/results/clientpositive/mapjoin_hook.q.out b/ql/src/test/results/clientpositive/mapjoin_hook.q.out
index b7ab45e7ed..815e4d5d59 100644
--- a/ql/src/test/results/clientpositive/mapjoin_hook.q.out
+++ b/ql/src/test/results/clientpositive/mapjoin_hook.q.out
@@ -37,16 +37,6 @@ PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 PREHOOK: Output: default@dest1
-Execution failed with exit status: 3
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-7
-
-Logs:
-
-#### A masked pattern was here ####
 FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
 ATTEMPT: Execute BackupTask: org.apache.hadoop.hive.ql.exec.mr.MapRedTask
 [MapJoinCounter PostHook] COMMON_JOIN: 0 HINTED_MAPJOIN: 0 HINTED_MAPJOIN_LOCAL: 0 CONVERTED_MAPJOIN: 0 CONVERTED_MAPJOIN_LOCAL: 1 BACKUP_COMMON_JOIN: 1
@@ -60,28 +50,8 @@ INSERT OVERWRITE TABLE dest1 SELECT src1.key, src3.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@dest1
-Execution failed with exit status: 3
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-14
-
-Logs:
-
-#### A masked pattern was here ####
 FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
 ATTEMPT: Execute BackupTask: org.apache.hadoop.hive.ql.exec.mr.MapRedTask
-Execution failed with exit status: 3
-Obtaining error information
-
-Task failed!
-Task ID:
-  Stage-12
-
-Logs:
-
-#### A masked pattern was here ####
 FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
 ATTEMPT: Execute BackupTask: org.apache.hadoop.hive.ql.exec.mr.MapRedTask
 [MapJoinCounter PostHook] COMMON_JOIN: 0 HINTED_MAPJOIN: 0 HINTED_MAPJOIN_LOCAL: 0 CONVERTED_MAPJOIN: 0 CONVERTED_MAPJOIN_LOCAL: 2 BACKUP_COMMON_JOIN: 2
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/StandardStructObjectInspector.java b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/StandardStructObjectInspector.java
index 077c3711ae..c96fc2dee3 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/StandardStructObjectInspector.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/StandardStructObjectInspector.java
@@ -112,9 +112,6 @@ protected StandardStructObjectInspector(List<String> structFieldNames,
   protected void init(List<String> structFieldNames,
       List<ObjectInspector> structFieldObjectInspectors,
       List<String> structFieldComments) {
-    assert (structFieldNames.size() == structFieldObjectInspectors.size());
-    assert (structFieldComments == null ||
-            (structFieldNames.size() == structFieldComments.size()));
 
     fields = new ArrayList<MyField>(structFieldNames.size());
     for (int i = 0; i < structFieldNames.size(); i++) {
@@ -182,7 +179,6 @@ public Object getStructFieldData(Object data, StructField fieldRef) {
       LOG.warn("ignoring similar errors.");
     }
     int fieldID = f.getFieldID();
-    assert (fieldID >= 0 && fieldID < fields.size());
 
     if (fieldID >= listSize) {
       return null;
@@ -205,7 +201,6 @@ public List<Object> getStructFieldsDataAsList(Object data) {
       data = java.util.Arrays.asList((Object[]) data);
     }
     List<Object> list = (List<Object>) data;
-    assert (list.size() == fields.size());
     return list;
   }
 
