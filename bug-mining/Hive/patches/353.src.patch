diff --git a/CHANGES.txt b/CHANGES.txt
index cbd640e564..bc4976b28a 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -216,6 +216,9 @@ Trunk -  Unreleased
     HIVE-1185. Fix RCFile resource leak when opening a non-RCFile.
     (He Yongqiang via zshao)
 
+    HIVE-1184. Fix Expression Not In Group By Key error.
+    (Paul Yang via zshao)
+
 Release 0.5.0 -  Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckCtx.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckCtx.java
index 13225fd9c9..afa0b4782e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckCtx.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckCtx.java
@@ -42,9 +42,14 @@ public class TypeCheckCtx implements NodeProcessorCtx {
    */
   private String error;
 
+  /**
+   * The node that generated the potential typecheck error
+   */
+  private ASTNode errorSrcNode;
+
   /**
    * Constructor.
-   * 
+   *
    * @param inputRR
    *          The input row resolver of the previous operator.
    */
@@ -86,9 +91,11 @@ public UnparseTranslator getUnparseTranslator() {
   /**
    * @param error
    *          the error to set
+   *
    */
-  public void setError(String error) {
+  public void setError(String error, ASTNode errorSrcNode) {
     this.error = error;
+    this.errorSrcNode = errorSrcNode;
   }
 
   /**
@@ -98,4 +105,8 @@ public String getError() {
     return error;
   }
 
+  public ASTNode getErrorSrcNode() {
+    return errorSrcNode;
+  }
+
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java
index 5a0a479a82..9525d6351a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java
@@ -75,12 +75,12 @@ private TypeCheckProcFactory() {
    * by operators key, so we substitute a+b in the select list with the internal
    * column name of the a+b expression that appears in the in input row
    * resolver.
-   * 
+   *
    * @param nd
    *          The node that is being inspected.
    * @param procCtx
    *          The processor context.
-   * 
+   *
    * @return exprNodeColumnDesc.
    */
   public static ExprNodeDesc processGByExpr(Node nd, Object procCtx)
@@ -137,7 +137,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
 
   /**
    * Factory method to get NullExprProcessor.
-   * 
+   *
    * @return NullExprProcessor.
    */
   public static NullExprProcessor getNullExprProcessor() {
@@ -186,7 +186,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
 
   /**
    * Factory method to get NumExprProcessor.
-   * 
+   *
    * @return NumExprProcessor.
    */
   public static NumExprProcessor getNumExprProcessor() {
@@ -236,7 +236,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
 
   /**
    * Factory method to get StrExprProcessor.
-   * 
+   *
    * @return StrExprProcessor.
    */
   public static StrExprProcessor getStrExprProcessor() {
@@ -282,7 +282,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
 
   /**
    * Factory method to get BoolExprProcessor.
-   * 
+   *
    * @return BoolExprProcessor.
    */
   public static BoolExprProcessor getBoolExprProcessor() {
@@ -312,7 +312,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
       RowResolver input = ctx.getInputRR();
 
       if (expr.getType() != HiveParser.TOK_TABLE_OR_COL) {
-        ctx.setError(ErrorMsg.INVALID_COLUMN.getMsg(expr));
+        ctx.setError(ErrorMsg.INVALID_COLUMN.getMsg(expr), expr);
         return null;
       }
 
@@ -326,7 +326,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
       if (isTableAlias) {
         if (colInfo != null) {
           // it's a table alias, and also a column
-          ctx.setError(ErrorMsg.AMBIGUOUS_TABLE_OR_COLUMN.getMsg(expr));
+          ctx.setError(ErrorMsg.AMBIGUOUS_TABLE_OR_COLUMN.getMsg(expr), expr);
           return null;
         } else {
           // It's a table alias.
@@ -337,11 +337,11 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
         if (colInfo == null) {
           // It's not a column or a table alias.
           if (input.getIsExprResolver()) {
-            ctx.setError(ErrorMsg.NON_KEY_EXPR_IN_GROUPBY.getMsg(expr));
+            ctx.setError(ErrorMsg.NON_KEY_EXPR_IN_GROUPBY.getMsg(expr), expr);
             return null;
           } else {
             ctx.setError(ErrorMsg.INVALID_TABLE_OR_COLUMN.getMsg(expr
-                .getChild(0)));
+                .getChild(0)), expr);
             LOG.debug(ErrorMsg.INVALID_TABLE_OR_COLUMN.toString() + ":"
                 + input.toString());
             return null;
@@ -360,7 +360,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
 
   /**
    * Factory method to get ColumnExprProcessor.
-   * 
+   *
    * @return ColumnExprProcessor.
    */
   public static ColumnExprProcessor getColumnExprProcessor() {
@@ -455,7 +455,7 @@ public static String getFunctionText(ASTNode expr, boolean isFunction) {
 
     /**
      * Get the exprNodeDesc.
-     * 
+     *
      * @param name
      * @param children
      * @return The expression node descriptor
@@ -476,7 +476,7 @@ public static ExprNodeDesc getFuncExprNodeDesc(String name,
      * This function create an ExprNodeDesc for a UDF function given the
      * children (arguments). It will insert implicit type conversion functions
      * if necessary.
-     * 
+     *
      * @throws UDFArgumentException
      */
     public static ExprNodeDesc getFuncExprNodeDesc(String udfName,
@@ -636,16 +636,54 @@ static ExprNodeDesc getXpathOrFuncExprNodeDesc(ASTNode expr,
       return desc;
     }
 
+    /**
+     * Returns true if des is a descendant of ans (ancestor)
+     */
+    private boolean isDescendant(Node ans, Node des) {
+      if (ans.getChildren() == null) {
+        return false;
+      }
+      for (Node c : ans.getChildren()) {
+        if (c == des) {
+          return true;
+        }
+        if (isDescendant(c, des)) {
+          return true;
+        }
+      }
+      return false;
+    }
+
     @Override
     public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
         Object... nodeOutputs) throws SemanticException {
 
       TypeCheckCtx ctx = (TypeCheckCtx) procCtx;
 
-      // If this is a GroupBy expression, clear error and continue
       ExprNodeDesc desc = TypeCheckProcFactory.processGByExpr(nd, procCtx);
       if (desc != null) {
-        ctx.setError(null);
+        // Here we know nd represents a group by expression.
+
+        // During the DFS traversal of the AST, a descendant of nd likely set an
+        // error because a sub-tree of nd is unlikely to also be a group by
+        // expression. For example, in a query such as
+        // SELECT *concat(key)* FROM src GROUP BY concat(key), 'key' will be
+        // processed before 'concat(key)' and since 'key' is not a group by
+        // expression, an error will be set in ctx by ColumnExprProcessor.
+
+        // We can clear the global error when we see that it was set in a
+        // descendant node of a group by expression because
+        // processGByExpr() returns a ExprNodeDesc that effectively ignores
+        // its children. Although the error can be set multiple times by
+        // descendant nodes, DFS traversal ensures that the error only needs to
+        // be cleared once. Also, for a case like
+        // SELECT concat(value, concat(value))... the logic still works as the
+        // error is only set with the first 'value'; all node pocessors quit
+        // early if the global error is set.
+
+        if (isDescendant(nd, ctx.getErrorSrcNode())) {
+          ctx.setError(null, null);
+        }
         return desc;
       }
 
@@ -670,7 +708,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
             ((ExprNodeConstantDesc) nodeOutputs[1]).getValue().toString());
 
         if (colInfo == null) {
-          ctx.setError(ErrorMsg.INVALID_COLUMN.getMsg(expr.getChild(1)));
+          ctx.setError(ErrorMsg.INVALID_COLUMN.getMsg(expr.getChild(1)), expr);
           return null;
         }
         return new ExprNodeColumnDesc(colInfo.getType(), colInfo
@@ -722,7 +760,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
 
   /**
    * Factory method to get DefaultExprProcessor.
-   * 
+   *
    * @return DefaultExprProcessor.
    */
   public static DefaultExprProcessor getDefaultExprProcessor() {
diff --git a/ql/src/test/queries/clientnegative/groupby_key.q b/ql/src/test/queries/clientnegative/groupby_key.q
new file mode 100644
index 0000000000..20970152c3
--- /dev/null
+++ b/ql/src/test/queries/clientnegative/groupby_key.q
@@ -0,0 +1 @@
+SELECT concat(value, concat(value)) FROM src GROUP BY concat(value);
diff --git a/ql/src/test/results/clientnegative/groupby_key.q.out b/ql/src/test/results/clientnegative/groupby_key.q.out
new file mode 100644
index 0000000000..8c30cc40da
--- /dev/null
+++ b/ql/src/test/results/clientnegative/groupby_key.q.out
@@ -0,0 +1 @@
+FAILED: Error in semantic analysis: line 1:14 Expression Not In Group By Key value
