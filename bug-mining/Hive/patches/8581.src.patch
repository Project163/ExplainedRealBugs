diff --git a/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/DummyRawStoreFailEvent.java b/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/DummyRawStoreFailEvent.java
index 5c7db6c948..31569d6793 100644
--- a/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/DummyRawStoreFailEvent.java
+++ b/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/DummyRawStoreFailEvent.java
@@ -117,6 +117,7 @@
 import org.apache.hadoop.hive.metastore.api.WriteEventInfo;
 import org.apache.hadoop.hive.metastore.api.ReplicationMetricList;
 import org.apache.hadoop.hive.metastore.api.GetReplicationMetricsRequest;
+import org.apache.hadoop.hive.metastore.client.builder.GetPartitionsArgs;
 import org.apache.hadoop.hive.metastore.model.MTable;
 import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;
 import org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils.ColStatsObjWithSourceInfo;
@@ -1615,46 +1616,34 @@ public Map<String, Map<String, String>> updatePartitionColumnStatisticsInBatch(
   }
 
   @Override
-  public List<Partition> getPartitions(String catName, String dbName, String tableName, int max, boolean skipColSchemaForPartitions)
+  public List<Partition> getPartitions(String catName, String dbName, String tableName, GetPartitionsArgs args)
           throws MetaException, NoSuchObjectException {
-    return objectStore.getPartitions(catName, dbName, tableName, max, skipColSchemaForPartitions);
+    return objectStore.getPartitions(catName, dbName, tableName, args);
   }
 
   @Override
   public List<Partition> getPartitionsByNames(String catName, String dbName, String tblName,
-                                              List<String> partNames, boolean skipColSchemaForPartitions)
+                                              GetPartitionsArgs args)
           throws MetaException, NoSuchObjectException {
-    return objectStore.getPartitionsByNames(
-            catName, dbName, tblName, partNames, skipColSchemaForPartitions);
+    return objectStore.getPartitionsByNames(catName, dbName, tblName, args);
   }
 
   @Override
-  public boolean getPartitionsByExpr(String catName, String dbName, String tblName, byte[] expr,
-                                     String defaultPartitionName, short maxParts, List<Partition> result, boolean skipColSchemaForPartitions) throws TException {
-    return objectStore.getPartitionsByExpr(catName,
-            dbName, tblName, expr, defaultPartitionName, maxParts, result, skipColSchemaForPartitions);
-  }
-
-  @Override
-  public List<Partition> getPartitionsWithAuth(String catName, String dbName, String tblName,
-                                               short maxParts, String userName, List<String> groupNames, boolean skipColSchemaForPartitions)
-          throws MetaException, NoSuchObjectException, InvalidObjectException {
-    return objectStore.getPartitionsWithAuth(catName, dbName, tblName, maxParts, userName,
-            groupNames, skipColSchemaForPartitions);
+  public boolean getPartitionsByExpr(String catName, String dbName, String tblName,
+                                     List<Partition> result, GetPartitionsArgs args) throws TException {
+    return objectStore.getPartitionsByExpr(catName, dbName, tblName, result, args);
   }
 
   @Override
   public List<Partition> listPartitionsPsWithAuth(String catName, String dbName, String tblName,
-                                                  List<String> partVals, short maxParts, String userName, List<String> groupNames,
-                                                  boolean skipColSchemaForPartitions) throws MetaException, InvalidObjectException, NoSuchObjectException {
-    return objectStore.listPartitionsPsWithAuth(catName, dbName, tblName, partVals, maxParts,
-            userName, groupNames, skipColSchemaForPartitions);
+                                                  GetPartitionsArgs args) throws MetaException, InvalidObjectException, NoSuchObjectException {
+    return objectStore.listPartitionsPsWithAuth(catName, dbName, tblName, args);
   }
 
 
   @Override
   public List<Partition> getPartitionsByFilter(String catName, String dbName, String tblName,
-                                               String filter, short maxParts, boolean skipColSchemaForPartitions) throws MetaException, NoSuchObjectException {
-    return objectStore.getPartitionsByFilter(catName, dbName, tblName, filter, maxParts, skipColSchemaForPartitions);
+                                               GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
+    return objectStore.getPartitionsByFilter(catName, dbName, tblName, args);
   }
 }
diff --git a/itests/qtest/src/test/java/org/apache/hadoop/hive/udf/example/AlterPartitionParamsExample.java b/itests/qtest/src/test/java/org/apache/hadoop/hive/udf/example/AlterPartitionParamsExample.java
new file mode 100644
index 0000000000..f69dca9085
--- /dev/null
+++ b/itests/qtest/src/test/java/org/apache/hadoop/hive/udf/example/AlterPartitionParamsExample.java
@@ -0,0 +1,113 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.udf.example;
+
+import java.util.Arrays;
+import java.util.List;
+
+import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
+import org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException;
+import org.apache.hadoop.hive.ql.metadata.Hive;
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.metadata.Partition;
+import org.apache.hadoop.hive.ql.metadata.Table;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDF;
+import org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.io.BooleanWritable;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * This class is for testing only, will try to alter the partition's parameters with the input key value pairs.
+ */
+public class AlterPartitionParamsExample extends GenericUDF {
+
+  private static final Logger LOG = LoggerFactory.getLogger(AlterPartitionParamsExample.class);
+
+  private transient ObjectInspectorConverters.Converter[] converters;
+  private transient BooleanWritable ret = new BooleanWritable(false);
+  private transient Table table;
+
+  // table, partition name, param_key, param_value
+  @Override
+  public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumentException {
+    if (arguments.length != 4) {
+      throw new UDFArgumentLengthException(
+          "Requires 4 argument, got " + arguments.length);
+    }
+    if (!(arguments[0] instanceof ConstantObjectInspector)) {
+      throw new UDFArgumentException(
+          "The first argument should be a string constant, got " + arguments[0].getTypeName());
+    }
+    converters = new ObjectInspectorConverters.Converter[arguments.length];
+    for (int i = 1; i < arguments.length; i++) {
+      converters[i] = ObjectInspectorConverters.getConverter(arguments[i],
+          PrimitiveObjectInspectorFactory.writableStringObjectInspector);
+    }
+    String tableName = ((ConstantObjectInspector) arguments[0]).getWritableConstantValue().toString();
+    try {
+      table = Hive.get().getTable(tableName);
+      if (!table.isPartitioned()) {
+        throw new UDFArgumentException("The input table: " + table + " isn't a partitioned table!");
+      }
+    } catch (Exception e) {
+      if (e instanceof UDFArgumentException) {
+        throw (UDFArgumentException) e;
+      }
+      throw new UDFArgumentException(e);
+    }
+    return PrimitiveObjectInspectorFactory.writableBooleanObjectInspector;
+  }
+
+  @Override
+  public Object evaluate(DeferredObject[] arguments) throws HiveException {
+    ret.set(false);
+    if (arguments[1].get() == null || arguments[2].get() == null ||
+        arguments[3].get() == null) {
+      return ret;
+    }
+    String partName   = converters[1].convert(arguments[1].get()).toString();
+    String paramKey   = converters[2].convert(arguments[2].get()).toString();
+    String paramValue = converters[3].convert(arguments[3].get()).toString();
+    try {
+      List<Partition> partitionList = Hive.get()
+          .getPartitionsByNames(table, Arrays.asList(partName));
+      if (partitionList == null || partitionList.isEmpty()) {
+        return ret;
+      }
+      Partition partition = partitionList.get(0);
+      partition.getParameters().put(paramKey, paramValue);
+      Hive.get()
+          .alterPartition(table.getCatName(), table.getDbName(), table.getTableName(), partition, null, true);
+      ret.set(true);
+    } catch (Exception e) {
+      LOG.debug("Error while altering the partition's parameters", e);
+    }
+    return ret;
+  }
+
+  @Override
+  public String getDisplayString(String[] children) {
+    return getStandardDisplayString("alter_partition_params", children);
+  }
+
+}
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
index d6189b1fa6..51133a3636 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
@@ -4132,6 +4132,8 @@ public List<Partition> getPartitions(Table tbl) throws HiveException {
           GetPartitionsPsWithAuthResponse res = getMSC().listPartitionsWithAuthInfoRequest(req);
           tParts = res.getPartitions();
 
+        } catch (NoSuchObjectException nsoe) {
+          return Lists.newArrayList();
         } catch (Exception e) {
           LOG.error("Failed getPartitions", e);
           throw new HiveException(e);
diff --git a/ql/src/test/org/apache/hadoop/hive/metastore/TestListPartitionsWithXIncludeParams.java b/ql/src/test/org/apache/hadoop/hive/metastore/TestListPartitionsWithXIncludeParams.java
new file mode 100644
index 0000000000..f0acbc67ee
--- /dev/null
+++ b/ql/src/test/org/apache/hadoop/hive/metastore/TestListPartitionsWithXIncludeParams.java
@@ -0,0 +1,234 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.metastore;
+
+import com.google.common.collect.Lists;
+
+import java.nio.ByteBuffer;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hive.metastore.annotation.MetastoreCheckinTest;
+import org.apache.hadoop.hive.metastore.api.GetPartitionsByNamesRequest;
+import org.apache.hadoop.hive.metastore.api.GetPartitionsFilterSpec;
+import org.apache.hadoop.hive.metastore.api.GetPartitionsRequest;
+import org.apache.hadoop.hive.metastore.api.GetProjectionsSpec;
+import org.apache.hadoop.hive.metastore.api.Partition;
+import org.apache.hadoop.hive.metastore.api.PartitionFilterMode;
+import org.apache.hadoop.hive.metastore.api.PartitionWithoutSD;
+import org.apache.hadoop.hive.metastore.api.PartitionsByExprRequest;
+import org.apache.hadoop.hive.metastore.api.Table;
+import org.apache.hadoop.hive.metastore.client.TestListPartitions;
+import org.apache.hadoop.hive.metastore.client.builder.PartitionBuilder;
+import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
+import org.apache.hadoop.hive.metastore.minihms.AbstractMetaStoreService;
+import org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils;
+import org.apache.hadoop.hive.metastore.utils.MetaStoreUtils;
+import org.apache.hadoop.hive.ql.exec.SerializationUtilities;
+import org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore;
+import org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc;
+import org.apache.thrift.TException;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+
+import static junit.framework.TestCase.assertTrue;
+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.convertToGetPartitionsByNamesRequest;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+
+/**
+ * Test class for list partitions with configurable include/exclude pattern on parameters.
+ * Embedded Metastore uses JDO, Remote Metastore uses direct SQL to query the partitions:
+ * MetaStoreFactoryForTests.getMetaStores()
+ */
+@RunWith(Parameterized.class)
+@Category(MetastoreCheckinTest.class)
+public class TestListPartitionsWithXIncludeParams
+    extends TestListPartitions {
+
+  private Configuration hiveConf;
+  private Set<String> includeKeys = new HashSet<>();
+  private Set<String> excludeKeys = new HashSet<>();
+  private Map<String, String> partParams = new HashMap<>();
+
+  public static class PartitionExpressionForMetastoreTest extends PartitionExpressionForMetastore {
+    // MetaStoreTestUtils.setConfForStandloneMode will change the default PartitionExpressionForMetastore
+    // to DefaultPartitionExpressionProxy, which doesn't support deserializing the Hive filter from a byte array.
+    // As this test sits inside the hive-exec module, it's safe to set the hive.metastore.expression.proxy to
+    // PartitionExpressionForMetastoreTest.
+  }
+
+  public TestListPartitionsWithXIncludeParams(String name,
+      AbstractMetaStoreService metaStore) {
+    super(name, metaStore);
+    partParams.put("key1", "value1");
+    partParams.put("akey1", "avalue1");
+    partParams.put("akey10", "avalue10");
+    partParams.put("excludekey1", "value1");
+    partParams.put("excludekey2", "value1");
+    includeKeys.add("key1");
+    includeKeys.add("akey1");
+    excludeKeys.add("excludekey1");
+    excludeKeys.add("excludekey2");
+    hiveConf = metaStore.getConf();
+    MetastoreConf.setVar(hiveConf, MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS,
+        PartitionExpressionForMetastoreTest.class.getName());
+    MetastoreConf.setVar(hiveConf,
+        MetastoreConf.ConfVars.METASTORE_PARTITIONS_PARAMETERS_INCLUDE_PATTERN, "%k_y_");
+    MetastoreConf.setVar(hiveConf,
+        MetastoreConf.ConfVars.METASTORE_PARTITIONS_PARAMETERS_EXCLUDE_PATTERN, "%exclu%");
+  }
+
+  @Override
+  protected void addPartition(IMetaStoreClient client, Table table,
+      List<String> values) throws TException {
+    PartitionBuilder partitionBuilder = new PartitionBuilder().inTable(table);
+    values.forEach(val -> partitionBuilder.addValue(val));
+    partParams.forEach((k, v) -> partitionBuilder.addPartParam(k, v));
+    client.add_partition(partitionBuilder.build(getMetaStore().getConf()));
+  }
+
+  @Override
+  protected void addPartitions(IMetaStoreClient client, List<Partition> partitions)
+      throws TException {
+    partitions.stream().forEach(partition -> partition.setParameters(partParams));
+    super.addPartitions(client, partitions);
+  }
+
+  @Override
+  protected void assertPartitionsHaveCorrectParams(List<Partition> partitions) {
+    for (int i = 0; i < partitions.size(); i++) {
+      Map<String, String> parameters = partitions.get(i).getParameters();
+      assertTrue("included parameter key is not found in the partition",
+          parameters.keySet().containsAll(includeKeys));
+      assertFalse("excluded parameter key is found in the partition",
+          parameters.keySet().stream().anyMatch(key -> excludeKeys.contains(key)));
+      assertEquals(includeKeys.size(), parameters.size());
+    }
+  }
+
+  @Test
+  public void testGetPartitionsByNames() throws Exception {
+    Table t = createTable4PartColsParts(getClient()).table;
+    List<String> part_names = Arrays.asList("yyyy=1999/mm=01/dd=02",
+        "yyyy=2009/mm=02/dd=10", "yyyy=1999/mm=03/dd=02");
+    GetPartitionsByNamesRequest request = convertToGetPartitionsByNamesRequest(
+        MetaStoreUtils.prependCatalogToDbName(t.getCatName(), t.getDbName(), hiveConf), t.getTableName(),
+        part_names);
+    List<Partition> partitions = getClient().getPartitionsByNames(request).getPartitions();
+    List<List<String>> values = partitions.stream().map(partition -> partition.getValues()).collect(Collectors.toList());
+    assertCorrectPartitionNames(part_names.subList(0, 2), values, Lists.newArrayList("yyyy", "mm", "dd"));
+    assertPartitionsHaveCorrectParams(partitions);
+
+    // empty
+    part_names = Arrays.asList("yyyy=1999/mm=03/dd=02", "yyyy=2017/mm=02/dd=13");
+    request = convertToGetPartitionsByNamesRequest(
+        MetaStoreUtils.prependCatalogToDbName(t.getCatName(), t.getDbName(), hiveConf), t.getTableName(),
+        part_names);
+    partitions = getClient().getPartitionsByNames(request).getPartitions();
+    assertTrue(partitions.isEmpty());
+  }
+
+  @Test
+  public void testGetPartitionsRequest() throws Exception {
+    ReturnTable returnTable = createTable4PartColsParts(getClient());
+    Table t = returnTable.table;
+    GetPartitionsRequest request = new GetPartitionsRequest(t.getDbName(), t.getTableName(),
+        new GetProjectionsSpec(), new GetPartitionsFilterSpec());
+    request.setCatName(t.getCatName());
+
+    List<Partition> partitions = MetaStoreServerUtils.getPartitionsByProjectSpec(getClient(), request);
+    assertPartitionsHaveCorrectParams(partitions);
+    List<List<String>> values = partitions.stream().map(partition -> partition.getValues()).collect(Collectors.toList());
+    assertEquals(returnTable.testValues, values);
+
+    request.getProjectionSpec()
+        .setFieldList(Arrays.asList("dbName", "tableName", "catName", "parameters", "values"));
+    partitions = MetaStoreServerUtils.getPartitionsByProjectSpec(getClient(), request);
+    assertPartitionsHaveCorrectParams(partitions);
+    values = partitions.stream().map(partition -> partition.getValues()).collect(Collectors.toList());
+    assertEquals(returnTable.testValues, values);
+
+    request.getFilterSpec().setFilterMode(PartitionFilterMode.BY_VALUES);
+    request.getFilterSpec().setFilters(Arrays.asList("2017"));
+    partitions = MetaStoreServerUtils.getPartitionsByProjectSpec(getClient(), request);
+    assertPartitionsHaveCorrectParams(partitions);
+    values = partitions.stream().map(partition -> partition.getValues()).collect(Collectors.toList());
+    assertEquals("Two partitions expected", 2, values.size());
+    assertEquals(Arrays.asList(Arrays.asList("2017", "10", "26"),
+        Arrays.asList("2017", "11", "27")), returnTable.testValues.subList(2, 4));
+  }
+
+  @Test
+  public void testListPartitionsByExr() throws Exception {
+    createTable4PartColsParts(getClient());
+    TestMetastoreExpr.ExprBuilder e = new TestMetastoreExpr.ExprBuilder(TABLE_NAME);
+    checkExpr(2, e.strCol("yyyy").val("2017").pred("=", 2).build());
+    checkExpr(3, e.strCol("mm").val("11").pred(">", 2).build());
+    checkExpr(4, e.strCol("dd").val("29").pred(">=", 2).build());
+    checkExpr(2, e.strCol("yyyy").val("2017").pred("!=", 2).build());
+    checkExpr(1, e.strCol("yyyy").val("2017").pred("=", 2).strCol("mm").val("10")
+        .pred(">=", 2).pred("and", 2).build());
+    checkExpr(3, e.strCol("dd").val("10").pred("<", 2).strCol("yyyy").val("2009")
+        .pred("!=", 2).pred("or", 2).build());
+    checkExpr(0, e.strCol("yyyy").val("2019").pred("=", 2).build());
+  }
+
+  private void checkExpr(int numParts, ExprNodeGenericFuncDesc expr) throws Exception {
+    List<Partition> partitions = new ArrayList<>();
+    byte[] exprBytes = SerializationUtilities.serializeObjectWithTypeInformation(expr);
+    getClient().listPartitionsByExpr(DB_NAME, TABLE_NAME, exprBytes,
+        null, (short) -1, partitions);
+    assertEquals("Partition check failed: " + expr.getExprString(), numParts, partitions.size());
+    assertPartitionsHaveCorrectParams(partitions);
+
+    PartitionsByExprRequest req = new PartitionsByExprRequest(DB_NAME, TABLE_NAME,
+        ByteBuffer.wrap(exprBytes));
+    List<org.apache.hadoop.hive.metastore.api.PartitionSpec> msParts =
+        new ArrayList<>();
+    getClient().listPartitionsSpecByExpr(req, msParts);
+
+    int numPartitions = 0;
+    for (org.apache.hadoop.hive.metastore.api.PartitionSpec partitionSpec : msParts) {
+      assertTrue(partitionSpec.getPartitionList() == null ||
+          partitionSpec.getPartitionList().getPartitions() == null ||
+          partitionSpec.getPartitionList().getPartitions().isEmpty());
+      for (PartitionWithoutSD partitionWithoutSD: partitionSpec.getSharedSDPartitionSpec().getPartitions()) {
+        numPartitions ++;
+        Map<String, String> parameters = partitionWithoutSD.getParameters();
+        assertTrue("included parameter key is not found in the partition",
+            parameters.keySet().containsAll(includeKeys));
+        assertFalse("excluded parameter key is found in the partition",
+            parameters.keySet().stream().anyMatch(key -> excludeKeys.contains(key)));
+        assertEquals(includeKeys.size(), parameters.size());
+      }
+    }
+    assertEquals("Partition check failed: " + expr.getExprString(), numParts, numPartitions);
+  }
+
+}
diff --git a/ql/src/test/queries/clientpositive/partition_params_xinclude.q b/ql/src/test/queries/clientpositive/partition_params_xinclude.q
new file mode 100644
index 0000000000..10d1230172
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/partition_params_xinclude.q
@@ -0,0 +1,23 @@
+create table part_params_xin (customer int) partitioned by (dt string);
+insert into part_params_xin partition(dt='2001-01-01') values(1);
+insert into part_params_xin partition(dt='2001-01-03') values(3);
+
+set hive.optimize.metadata.query.cache.enabled=false;
+
+create table params(key string, value string);
+insert into table params values('key1', 'value1'), ('akey1', 'avalue1'), ('akey10', 'avalue10'), ('excludekey1', 'value1'),('excludekey2', 'value1');
+
+add jar ${system:maven.local.repository}/org/apache/hive/hive-it-qfile/${system:hive.version}/hive-it-qfile-${system:hive.version}.jar;
+
+create temporary function alter_partition_params as 'org.apache.hadoop.hive.udf.example.AlterPartitionParamsExample';
+
+select alter_partition_params('part_params_xin', 'dt=2001-01-01', key, value) from params;
+
+explain extended select * from part_params_xin where nvl(dt='2001-01-01' and customer=1, false);
+
+set metastore.partitions.parameters.include.pattern=%k_y_;
+set metastore.partitions.parameters.exclude.pattern=%exclu%;
+explain extended select * from part_params_xin where nvl(dt='2001-01-01' and customer=1, false);
+
+set metastore.partitions.parameters.exclude.pattern=;
+explain extended select * from part_params_xin where nvl(dt='2001-01-01' and customer=1, false);
diff --git a/ql/src/test/results/clientpositive/llap/partition_params_xinclude.q.out b/ql/src/test/results/clientpositive/llap/partition_params_xinclude.q.out
new file mode 100644
index 0000000000..32588d0443
--- /dev/null
+++ b/ql/src/test/results/clientpositive/llap/partition_params_xinclude.q.out
@@ -0,0 +1,281 @@
+PREHOOK: query: create table part_params_xin (customer int) partitioned by (dt string)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@part_params_xin
+POSTHOOK: query: create table part_params_xin (customer int) partitioned by (dt string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@part_params_xin
+PREHOOK: query: insert into part_params_xin partition(dt='2001-01-01') values(1)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@part_params_xin@dt=2001-01-01
+POSTHOOK: query: insert into part_params_xin partition(dt='2001-01-01') values(1)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@part_params_xin@dt=2001-01-01
+POSTHOOK: Lineage: part_params_xin PARTITION(dt=2001-01-01).customer SCRIPT []
+PREHOOK: query: insert into part_params_xin partition(dt='2001-01-03') values(3)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@part_params_xin@dt=2001-01-03
+POSTHOOK: query: insert into part_params_xin partition(dt='2001-01-03') values(3)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@part_params_xin@dt=2001-01-03
+POSTHOOK: Lineage: part_params_xin PARTITION(dt=2001-01-03).customer SCRIPT []
+PREHOOK: query: create table params(key string, value string)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@params
+POSTHOOK: query: create table params(key string, value string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@params
+PREHOOK: query: insert into table params values('key1', 'value1'), ('akey1', 'avalue1'), ('akey10', 'avalue10'), ('excludekey1', 'value1'),('excludekey2', 'value1')
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@params
+POSTHOOK: query: insert into table params values('key1', 'value1'), ('akey1', 'avalue1'), ('akey10', 'avalue10'), ('excludekey1', 'value1'),('excludekey2', 'value1')
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@params
+POSTHOOK: Lineage: params.key SCRIPT []
+POSTHOOK: Lineage: params.value SCRIPT []
+PREHOOK: query: create temporary function alter_partition_params as 'org.apache.hadoop.hive.udf.example.AlterPartitionParamsExample'
+PREHOOK: type: CREATEFUNCTION
+PREHOOK: Output: alter_partition_params
+POSTHOOK: query: create temporary function alter_partition_params as 'org.apache.hadoop.hive.udf.example.AlterPartitionParamsExample'
+POSTHOOK: type: CREATEFUNCTION
+POSTHOOK: Output: alter_partition_params
+PREHOOK: query: select alter_partition_params('part_params_xin', 'dt=2001-01-01', key, value) from params
+PREHOOK: type: QUERY
+PREHOOK: Input: default@params
+#### A masked pattern was here ####
+POSTHOOK: query: select alter_partition_params('part_params_xin', 'dt=2001-01-01', key, value) from params
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@params
+#### A masked pattern was here ####
+true
+true
+true
+true
+true
+PREHOOK: query: explain extended select * from part_params_xin where nvl(dt='2001-01-01' and customer=1, false)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@part_params_xin
+PREHOOK: Input: default@part_params_xin@dt=2001-01-01
+#### A masked pattern was here ####
+POSTHOOK: query: explain extended select * from part_params_xin where nvl(dt='2001-01-01' and customer=1, false)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@part_params_xin
+POSTHOOK: Input: default@part_params_xin@dt=2001-01-01
+#### A masked pattern was here ####
+OPTIMIZED SQL: SELECT `customer`, `dt`
+FROM `default`.`part_params_xin`
+WHERE NVL(`dt` = '2001-01-01' AND `customer` = 1, FALSE)
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Partition Description:
+          Partition
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              dt 2001-01-01
+            properties:
+              akey1 avalue1
+              akey10 avalue10
+              column.name.delimiter ,
+              columns customer
+              columns.types int
+              excludekey1 value1
+              excludekey2 value1
+#### A masked pattern was here ####
+              key1 value1
+#### A masked pattern was here ####
+              name default.part_params_xin
+              partition_columns dt
+              partition_columns.types string
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucketing_version 2
+                column.name.delimiter ,
+                columns customer
+                columns.comments 
+                columns.types int
+#### A masked pattern was here ####
+                name default.part_params_xin
+                partition_columns dt
+                partition_columns.types string
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.part_params_xin
+            name: default.part_params_xin
+      Processor Tree:
+        TableScan
+          alias: part_params_xin
+          filterExpr: COALESCE((customer = 1),false) (type: boolean)
+          GatherStats: false
+          Filter Operator
+            isSamplingPred: false
+            predicate: COALESCE((customer = 1),false) (type: boolean)
+            Select Operator
+              expressions: customer (type: int), dt (type: string)
+              outputColumnNames: _col0, _col1
+              ListSink
+
+PREHOOK: query: explain extended select * from part_params_xin where nvl(dt='2001-01-01' and customer=1, false)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@part_params_xin
+PREHOOK: Input: default@part_params_xin@dt=2001-01-01
+#### A masked pattern was here ####
+POSTHOOK: query: explain extended select * from part_params_xin where nvl(dt='2001-01-01' and customer=1, false)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@part_params_xin
+POSTHOOK: Input: default@part_params_xin@dt=2001-01-01
+#### A masked pattern was here ####
+OPTIMIZED SQL: SELECT `customer`, `dt`
+FROM `default`.`part_params_xin`
+WHERE NVL(`dt` = '2001-01-01' AND `customer` = 1, FALSE)
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Partition Description:
+          Partition
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              dt 2001-01-01
+            properties:
+              akey1 avalue1
+              column.name.delimiter ,
+              columns customer
+              columns.types int
+#### A masked pattern was here ####
+              key1 value1
+#### A masked pattern was here ####
+              name default.part_params_xin
+              partition_columns dt
+              partition_columns.types string
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucketing_version 2
+                column.name.delimiter ,
+                columns customer
+                columns.comments 
+                columns.types int
+#### A masked pattern was here ####
+                name default.part_params_xin
+                partition_columns dt
+                partition_columns.types string
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.part_params_xin
+            name: default.part_params_xin
+      Processor Tree:
+        TableScan
+          alias: part_params_xin
+          filterExpr: COALESCE((customer = 1),false) (type: boolean)
+          GatherStats: false
+          Filter Operator
+            isSamplingPred: false
+            predicate: COALESCE((customer = 1),false) (type: boolean)
+            Select Operator
+              expressions: customer (type: int), dt (type: string)
+              outputColumnNames: _col0, _col1
+              ListSink
+
+PREHOOK: query: explain extended select * from part_params_xin where nvl(dt='2001-01-01' and customer=1, false)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@part_params_xin
+PREHOOK: Input: default@part_params_xin@dt=2001-01-01
+#### A masked pattern was here ####
+POSTHOOK: query: explain extended select * from part_params_xin where nvl(dt='2001-01-01' and customer=1, false)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@part_params_xin
+POSTHOOK: Input: default@part_params_xin@dt=2001-01-01
+#### A masked pattern was here ####
+OPTIMIZED SQL: SELECT `customer`, `dt`
+FROM `default`.`part_params_xin`
+WHERE NVL(`dt` = '2001-01-01' AND `customer` = 1, FALSE)
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Partition Description:
+          Partition
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              dt 2001-01-01
+            properties:
+              akey1 avalue1
+              column.name.delimiter ,
+              columns customer
+              columns.types int
+              excludekey1 value1
+              excludekey2 value1
+#### A masked pattern was here ####
+              key1 value1
+#### A masked pattern was here ####
+              name default.part_params_xin
+              partition_columns dt
+              partition_columns.types string
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucketing_version 2
+                column.name.delimiter ,
+                columns customer
+                columns.comments 
+                columns.types int
+#### A masked pattern was here ####
+                name default.part_params_xin
+                partition_columns dt
+                partition_columns.types string
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.part_params_xin
+            name: default.part_params_xin
+      Processor Tree:
+        TableScan
+          alias: part_params_xin
+          filterExpr: COALESCE((customer = 1),false) (type: boolean)
+          GatherStats: false
+          Filter Operator
+            isSamplingPred: false
+            predicate: COALESCE((customer = 1),false) (type: boolean)
+            Select Operator
+              expressions: customer (type: int), dt (type: string)
+              outputColumnNames: _col0, _col1
+              ListSink
+
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-cpp/hive_metastore_types.cpp b/standalone-metastore/metastore-common/src/gen/thrift/gen-cpp/hive_metastore_types.cpp
index a0b3bc5ad8..401d63df93 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-cpp/hive_metastore_types.cpp
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-cpp/hive_metastore_types.cpp
@@ -17606,6 +17606,16 @@ void PartitionsByExprRequest::__set_skipColumnSchemaForPartition(const bool val)
   this->skipColumnSchemaForPartition = val;
 __isset.skipColumnSchemaForPartition = true;
 }
+
+void PartitionsByExprRequest::__set_includeParamKeyPattern(const std::string& val) {
+  this->includeParamKeyPattern = val;
+__isset.includeParamKeyPattern = true;
+}
+
+void PartitionsByExprRequest::__set_excludeParamKeyPattern(const std::string& val) {
+  this->excludeParamKeyPattern = val;
+__isset.excludeParamKeyPattern = true;
+}
 std::ostream& operator<<(std::ostream& out, const PartitionsByExprRequest& obj)
 {
   obj.printTo(out);
@@ -17717,6 +17727,22 @@ uint32_t PartitionsByExprRequest::read(::apache::thrift::protocol::TProtocol* ip
           xfer += iprot->skip(ftype);
         }
         break;
+      case 11:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->includeParamKeyPattern);
+          this->__isset.includeParamKeyPattern = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 12:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->excludeParamKeyPattern);
+          this->__isset.excludeParamKeyPattern = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
       default:
         xfer += iprot->skip(ftype);
         break;
@@ -17787,6 +17813,16 @@ uint32_t PartitionsByExprRequest::write(::apache::thrift::protocol::TProtocol* o
     xfer += oprot->writeBool(this->skipColumnSchemaForPartition);
     xfer += oprot->writeFieldEnd();
   }
+  if (this->__isset.includeParamKeyPattern) {
+    xfer += oprot->writeFieldBegin("includeParamKeyPattern", ::apache::thrift::protocol::T_STRING, 11);
+    xfer += oprot->writeString(this->includeParamKeyPattern);
+    xfer += oprot->writeFieldEnd();
+  }
+  if (this->__isset.excludeParamKeyPattern) {
+    xfer += oprot->writeFieldBegin("excludeParamKeyPattern", ::apache::thrift::protocol::T_STRING, 12);
+    xfer += oprot->writeString(this->excludeParamKeyPattern);
+    xfer += oprot->writeFieldEnd();
+  }
   xfer += oprot->writeFieldStop();
   xfer += oprot->writeStructEnd();
   return xfer;
@@ -17804,6 +17840,8 @@ void swap(PartitionsByExprRequest &a, PartitionsByExprRequest &b) {
   swap(a.validWriteIdList, b.validWriteIdList);
   swap(a.id, b.id);
   swap(a.skipColumnSchemaForPartition, b.skipColumnSchemaForPartition);
+  swap(a.includeParamKeyPattern, b.includeParamKeyPattern);
+  swap(a.excludeParamKeyPattern, b.excludeParamKeyPattern);
   swap(a.__isset, b.__isset);
 }
 
@@ -17818,6 +17856,8 @@ PartitionsByExprRequest::PartitionsByExprRequest(const PartitionsByExprRequest&
   validWriteIdList = other651.validWriteIdList;
   id = other651.id;
   skipColumnSchemaForPartition = other651.skipColumnSchemaForPartition;
+  includeParamKeyPattern = other651.includeParamKeyPattern;
+  excludeParamKeyPattern = other651.excludeParamKeyPattern;
   __isset = other651.__isset;
 }
 PartitionsByExprRequest& PartitionsByExprRequest::operator=(const PartitionsByExprRequest& other652) {
@@ -17831,6 +17871,8 @@ PartitionsByExprRequest& PartitionsByExprRequest::operator=(const PartitionsByEx
   validWriteIdList = other652.validWriteIdList;
   id = other652.id;
   skipColumnSchemaForPartition = other652.skipColumnSchemaForPartition;
+  includeParamKeyPattern = other652.includeParamKeyPattern;
+  excludeParamKeyPattern = other652.excludeParamKeyPattern;
   __isset = other652.__isset;
   return *this;
 }
@@ -17847,6 +17889,8 @@ void PartitionsByExprRequest::printTo(std::ostream& out) const {
   out << ", " << "validWriteIdList="; (__isset.validWriteIdList ? (out << to_string(validWriteIdList)) : (out << "<null>"));
   out << ", " << "id="; (__isset.id ? (out << to_string(id)) : (out << "<null>"));
   out << ", " << "skipColumnSchemaForPartition="; (__isset.skipColumnSchemaForPartition ? (out << to_string(skipColumnSchemaForPartition)) : (out << "<null>"));
+  out << ", " << "includeParamKeyPattern="; (__isset.includeParamKeyPattern ? (out << to_string(includeParamKeyPattern)) : (out << "<null>"));
+  out << ", " << "excludeParamKeyPattern="; (__isset.excludeParamKeyPattern ? (out << to_string(excludeParamKeyPattern)) : (out << "<null>"));
   out << ")";
 }
 
@@ -20459,6 +20503,16 @@ void GetPartitionsByNamesRequest::__set_skipColumnSchemaForPartition(const bool
   this->skipColumnSchemaForPartition = val;
 __isset.skipColumnSchemaForPartition = true;
 }
+
+void GetPartitionsByNamesRequest::__set_includeParamKeyPattern(const std::string& val) {
+  this->includeParamKeyPattern = val;
+__isset.includeParamKeyPattern = true;
+}
+
+void GetPartitionsByNamesRequest::__set_excludeParamKeyPattern(const std::string& val) {
+  this->excludeParamKeyPattern = val;
+__isset.excludeParamKeyPattern = true;
+}
 std::ostream& operator<<(std::ostream& out, const GetPartitionsByNamesRequest& obj)
 {
   obj.printTo(out);
@@ -20601,6 +20655,22 @@ uint32_t GetPartitionsByNamesRequest::read(::apache::thrift::protocol::TProtocol
           xfer += iprot->skip(ftype);
         }
         break;
+      case 12:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->includeParamKeyPattern);
+          this->__isset.includeParamKeyPattern = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 13:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->excludeParamKeyPattern);
+          this->__isset.excludeParamKeyPattern = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
       default:
         xfer += iprot->skip(ftype);
         break;
@@ -20691,6 +20761,16 @@ uint32_t GetPartitionsByNamesRequest::write(::apache::thrift::protocol::TProtoco
     xfer += oprot->writeBool(this->skipColumnSchemaForPartition);
     xfer += oprot->writeFieldEnd();
   }
+  if (this->__isset.includeParamKeyPattern) {
+    xfer += oprot->writeFieldBegin("includeParamKeyPattern", ::apache::thrift::protocol::T_STRING, 12);
+    xfer += oprot->writeString(this->includeParamKeyPattern);
+    xfer += oprot->writeFieldEnd();
+  }
+  if (this->__isset.excludeParamKeyPattern) {
+    xfer += oprot->writeFieldBegin("excludeParamKeyPattern", ::apache::thrift::protocol::T_STRING, 13);
+    xfer += oprot->writeString(this->excludeParamKeyPattern);
+    xfer += oprot->writeFieldEnd();
+  }
   xfer += oprot->writeFieldStop();
   xfer += oprot->writeStructEnd();
   return xfer;
@@ -20709,6 +20789,8 @@ void swap(GetPartitionsByNamesRequest &a, GetPartitionsByNamesRequest &b) {
   swap(a.getFileMetadata, b.getFileMetadata);
   swap(a.id, b.id);
   swap(a.skipColumnSchemaForPartition, b.skipColumnSchemaForPartition);
+  swap(a.includeParamKeyPattern, b.includeParamKeyPattern);
+  swap(a.excludeParamKeyPattern, b.excludeParamKeyPattern);
   swap(a.__isset, b.__isset);
 }
 
@@ -20724,6 +20806,8 @@ GetPartitionsByNamesRequest::GetPartitionsByNamesRequest(const GetPartitionsByNa
   getFileMetadata = other795.getFileMetadata;
   id = other795.id;
   skipColumnSchemaForPartition = other795.skipColumnSchemaForPartition;
+  includeParamKeyPattern = other795.includeParamKeyPattern;
+  excludeParamKeyPattern = other795.excludeParamKeyPattern;
   __isset = other795.__isset;
 }
 GetPartitionsByNamesRequest& GetPartitionsByNamesRequest::operator=(const GetPartitionsByNamesRequest& other796) {
@@ -20738,6 +20822,8 @@ GetPartitionsByNamesRequest& GetPartitionsByNamesRequest::operator=(const GetPar
   getFileMetadata = other796.getFileMetadata;
   id = other796.id;
   skipColumnSchemaForPartition = other796.skipColumnSchemaForPartition;
+  includeParamKeyPattern = other796.includeParamKeyPattern;
+  excludeParamKeyPattern = other796.excludeParamKeyPattern;
   __isset = other796.__isset;
   return *this;
 }
@@ -20755,6 +20841,8 @@ void GetPartitionsByNamesRequest::printTo(std::ostream& out) const {
   out << ", " << "getFileMetadata="; (__isset.getFileMetadata ? (out << to_string(getFileMetadata)) : (out << "<null>"));
   out << ", " << "id="; (__isset.id ? (out << to_string(id)) : (out << "<null>"));
   out << ", " << "skipColumnSchemaForPartition="; (__isset.skipColumnSchemaForPartition ? (out << to_string(skipColumnSchemaForPartition)) : (out << "<null>"));
+  out << ", " << "includeParamKeyPattern="; (__isset.includeParamKeyPattern ? (out << to_string(includeParamKeyPattern)) : (out << "<null>"));
+  out << ", " << "excludeParamKeyPattern="; (__isset.excludeParamKeyPattern ? (out << to_string(excludeParamKeyPattern)) : (out << "<null>"));
   out << ")";
 }
 
@@ -49068,6 +49156,16 @@ void PartitionsRequest::__set_skipColumnSchemaForPartition(const bool val) {
   this->skipColumnSchemaForPartition = val;
 __isset.skipColumnSchemaForPartition = true;
 }
+
+void PartitionsRequest::__set_includeParamKeyPattern(const std::string& val) {
+  this->includeParamKeyPattern = val;
+__isset.includeParamKeyPattern = true;
+}
+
+void PartitionsRequest::__set_excludeParamKeyPattern(const std::string& val) {
+  this->excludeParamKeyPattern = val;
+__isset.excludeParamKeyPattern = true;
+}
 std::ostream& operator<<(std::ostream& out, const PartitionsRequest& obj)
 {
   obj.printTo(out);
@@ -49154,6 +49252,22 @@ uint32_t PartitionsRequest::read(::apache::thrift::protocol::TProtocol* iprot) {
           xfer += iprot->skip(ftype);
         }
         break;
+      case 8:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->includeParamKeyPattern);
+          this->__isset.includeParamKeyPattern = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 9:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->excludeParamKeyPattern);
+          this->__isset.excludeParamKeyPattern = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
       default:
         xfer += iprot->skip(ftype);
         break;
@@ -49208,6 +49322,16 @@ uint32_t PartitionsRequest::write(::apache::thrift::protocol::TProtocol* oprot)
     xfer += oprot->writeBool(this->skipColumnSchemaForPartition);
     xfer += oprot->writeFieldEnd();
   }
+  if (this->__isset.includeParamKeyPattern) {
+    xfer += oprot->writeFieldBegin("includeParamKeyPattern", ::apache::thrift::protocol::T_STRING, 8);
+    xfer += oprot->writeString(this->includeParamKeyPattern);
+    xfer += oprot->writeFieldEnd();
+  }
+  if (this->__isset.excludeParamKeyPattern) {
+    xfer += oprot->writeFieldBegin("excludeParamKeyPattern", ::apache::thrift::protocol::T_STRING, 9);
+    xfer += oprot->writeString(this->excludeParamKeyPattern);
+    xfer += oprot->writeFieldEnd();
+  }
   xfer += oprot->writeFieldStop();
   xfer += oprot->writeStructEnd();
   return xfer;
@@ -49222,6 +49346,8 @@ void swap(PartitionsRequest &a, PartitionsRequest &b) {
   swap(a.validWriteIdList, b.validWriteIdList);
   swap(a.id, b.id);
   swap(a.skipColumnSchemaForPartition, b.skipColumnSchemaForPartition);
+  swap(a.includeParamKeyPattern, b.includeParamKeyPattern);
+  swap(a.excludeParamKeyPattern, b.excludeParamKeyPattern);
   swap(a.__isset, b.__isset);
 }
 
@@ -49233,6 +49359,8 @@ PartitionsRequest::PartitionsRequest(const PartitionsRequest& other1733) {
   validWriteIdList = other1733.validWriteIdList;
   id = other1733.id;
   skipColumnSchemaForPartition = other1733.skipColumnSchemaForPartition;
+  includeParamKeyPattern = other1733.includeParamKeyPattern;
+  excludeParamKeyPattern = other1733.excludeParamKeyPattern;
   __isset = other1733.__isset;
 }
 PartitionsRequest& PartitionsRequest::operator=(const PartitionsRequest& other1734) {
@@ -49243,6 +49371,8 @@ PartitionsRequest& PartitionsRequest::operator=(const PartitionsRequest& other17
   validWriteIdList = other1734.validWriteIdList;
   id = other1734.id;
   skipColumnSchemaForPartition = other1734.skipColumnSchemaForPartition;
+  includeParamKeyPattern = other1734.includeParamKeyPattern;
+  excludeParamKeyPattern = other1734.excludeParamKeyPattern;
   __isset = other1734.__isset;
   return *this;
 }
@@ -49256,6 +49386,8 @@ void PartitionsRequest::printTo(std::ostream& out) const {
   out << ", " << "validWriteIdList="; (__isset.validWriteIdList ? (out << to_string(validWriteIdList)) : (out << "<null>"));
   out << ", " << "id="; (__isset.id ? (out << to_string(id)) : (out << "<null>"));
   out << ", " << "skipColumnSchemaForPartition="; (__isset.skipColumnSchemaForPartition ? (out << to_string(skipColumnSchemaForPartition)) : (out << "<null>"));
+  out << ", " << "includeParamKeyPattern="; (__isset.includeParamKeyPattern ? (out << to_string(includeParamKeyPattern)) : (out << "<null>"));
+  out << ", " << "excludeParamKeyPattern="; (__isset.excludeParamKeyPattern ? (out << to_string(excludeParamKeyPattern)) : (out << "<null>"));
   out << ")";
 }
 
@@ -49402,6 +49534,16 @@ void GetPartitionsByFilterRequest::__set_skipColumnSchemaForPartition(const bool
   this->skipColumnSchemaForPartition = val;
 __isset.skipColumnSchemaForPartition = true;
 }
+
+void GetPartitionsByFilterRequest::__set_includeParamKeyPattern(const std::string& val) {
+  this->includeParamKeyPattern = val;
+__isset.includeParamKeyPattern = true;
+}
+
+void GetPartitionsByFilterRequest::__set_excludeParamKeyPattern(const std::string& val) {
+  this->excludeParamKeyPattern = val;
+__isset.excludeParamKeyPattern = true;
+}
 std::ostream& operator<<(std::ostream& out, const GetPartitionsByFilterRequest& obj)
 {
   obj.printTo(out);
@@ -49478,6 +49620,22 @@ uint32_t GetPartitionsByFilterRequest::read(::apache::thrift::protocol::TProtoco
           xfer += iprot->skip(ftype);
         }
         break;
+      case 7:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->includeParamKeyPattern);
+          this->__isset.includeParamKeyPattern = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 8:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->excludeParamKeyPattern);
+          this->__isset.excludeParamKeyPattern = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
       default:
         xfer += iprot->skip(ftype);
         break;
@@ -49522,6 +49680,16 @@ uint32_t GetPartitionsByFilterRequest::write(::apache::thrift::protocol::TProtoc
     xfer += oprot->writeBool(this->skipColumnSchemaForPartition);
     xfer += oprot->writeFieldEnd();
   }
+  if (this->__isset.includeParamKeyPattern) {
+    xfer += oprot->writeFieldBegin("includeParamKeyPattern", ::apache::thrift::protocol::T_STRING, 7);
+    xfer += oprot->writeString(this->includeParamKeyPattern);
+    xfer += oprot->writeFieldEnd();
+  }
+  if (this->__isset.excludeParamKeyPattern) {
+    xfer += oprot->writeFieldBegin("excludeParamKeyPattern", ::apache::thrift::protocol::T_STRING, 8);
+    xfer += oprot->writeString(this->excludeParamKeyPattern);
+    xfer += oprot->writeFieldEnd();
+  }
   xfer += oprot->writeFieldStop();
   xfer += oprot->writeStructEnd();
   return xfer;
@@ -49535,6 +49703,8 @@ void swap(GetPartitionsByFilterRequest &a, GetPartitionsByFilterRequest &b) {
   swap(a.filter, b.filter);
   swap(a.maxParts, b.maxParts);
   swap(a.skipColumnSchemaForPartition, b.skipColumnSchemaForPartition);
+  swap(a.includeParamKeyPattern, b.includeParamKeyPattern);
+  swap(a.excludeParamKeyPattern, b.excludeParamKeyPattern);
   swap(a.__isset, b.__isset);
 }
 
@@ -49545,6 +49715,8 @@ GetPartitionsByFilterRequest::GetPartitionsByFilterRequest(const GetPartitionsBy
   filter = other1743.filter;
   maxParts = other1743.maxParts;
   skipColumnSchemaForPartition = other1743.skipColumnSchemaForPartition;
+  includeParamKeyPattern = other1743.includeParamKeyPattern;
+  excludeParamKeyPattern = other1743.excludeParamKeyPattern;
   __isset = other1743.__isset;
 }
 GetPartitionsByFilterRequest& GetPartitionsByFilterRequest::operator=(const GetPartitionsByFilterRequest& other1744) {
@@ -49554,6 +49726,8 @@ GetPartitionsByFilterRequest& GetPartitionsByFilterRequest::operator=(const GetP
   filter = other1744.filter;
   maxParts = other1744.maxParts;
   skipColumnSchemaForPartition = other1744.skipColumnSchemaForPartition;
+  includeParamKeyPattern = other1744.includeParamKeyPattern;
+  excludeParamKeyPattern = other1744.excludeParamKeyPattern;
   __isset = other1744.__isset;
   return *this;
 }
@@ -49566,6 +49740,8 @@ void GetPartitionsByFilterRequest::printTo(std::ostream& out) const {
   out << ", " << "filter=" << to_string(filter);
   out << ", " << "maxParts="; (__isset.maxParts ? (out << to_string(maxParts)) : (out << "<null>"));
   out << ", " << "skipColumnSchemaForPartition="; (__isset.skipColumnSchemaForPartition ? (out << to_string(skipColumnSchemaForPartition)) : (out << "<null>"));
+  out << ", " << "includeParamKeyPattern="; (__isset.includeParamKeyPattern ? (out << to_string(includeParamKeyPattern)) : (out << "<null>"));
+  out << ", " << "excludeParamKeyPattern="; (__isset.excludeParamKeyPattern ? (out << to_string(excludeParamKeyPattern)) : (out << "<null>"));
   out << ")";
 }
 
@@ -49981,6 +50157,16 @@ void GetPartitionsPsWithAuthRequest::__set_skipColumnSchemaForPartition(const bo
   this->skipColumnSchemaForPartition = val;
 __isset.skipColumnSchemaForPartition = true;
 }
+
+void GetPartitionsPsWithAuthRequest::__set_includeParamKeyPattern(const std::string& val) {
+  this->includeParamKeyPattern = val;
+__isset.includeParamKeyPattern = true;
+}
+
+void GetPartitionsPsWithAuthRequest::__set_excludeParamKeyPattern(const std::string& val) {
+  this->excludeParamKeyPattern = val;
+__isset.excludeParamKeyPattern = true;
+}
 std::ostream& operator<<(std::ostream& out, const GetPartitionsPsWithAuthRequest& obj)
 {
   obj.printTo(out);
@@ -50115,6 +50301,22 @@ uint32_t GetPartitionsPsWithAuthRequest::read(::apache::thrift::protocol::TProto
           xfer += iprot->skip(ftype);
         }
         break;
+      case 11:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->includeParamKeyPattern);
+          this->__isset.includeParamKeyPattern = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 12:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->excludeParamKeyPattern);
+          this->__isset.excludeParamKeyPattern = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
       default:
         xfer += iprot->skip(ftype);
         break;
@@ -50200,6 +50402,16 @@ uint32_t GetPartitionsPsWithAuthRequest::write(::apache::thrift::protocol::TProt
     xfer += oprot->writeBool(this->skipColumnSchemaForPartition);
     xfer += oprot->writeFieldEnd();
   }
+  if (this->__isset.includeParamKeyPattern) {
+    xfer += oprot->writeFieldBegin("includeParamKeyPattern", ::apache::thrift::protocol::T_STRING, 11);
+    xfer += oprot->writeString(this->includeParamKeyPattern);
+    xfer += oprot->writeFieldEnd();
+  }
+  if (this->__isset.excludeParamKeyPattern) {
+    xfer += oprot->writeFieldBegin("excludeParamKeyPattern", ::apache::thrift::protocol::T_STRING, 12);
+    xfer += oprot->writeString(this->excludeParamKeyPattern);
+    xfer += oprot->writeFieldEnd();
+  }
   xfer += oprot->writeFieldStop();
   xfer += oprot->writeStructEnd();
   return xfer;
@@ -50217,6 +50429,8 @@ void swap(GetPartitionsPsWithAuthRequest &a, GetPartitionsPsWithAuthRequest &b)
   swap(a.validWriteIdList, b.validWriteIdList);
   swap(a.id, b.id);
   swap(a.skipColumnSchemaForPartition, b.skipColumnSchemaForPartition);
+  swap(a.includeParamKeyPattern, b.includeParamKeyPattern);
+  swap(a.excludeParamKeyPattern, b.excludeParamKeyPattern);
   swap(a.__isset, b.__isset);
 }
 
@@ -50231,6 +50445,8 @@ GetPartitionsPsWithAuthRequest::GetPartitionsPsWithAuthRequest(const GetPartitio
   validWriteIdList = other1773.validWriteIdList;
   id = other1773.id;
   skipColumnSchemaForPartition = other1773.skipColumnSchemaForPartition;
+  includeParamKeyPattern = other1773.includeParamKeyPattern;
+  excludeParamKeyPattern = other1773.excludeParamKeyPattern;
   __isset = other1773.__isset;
 }
 GetPartitionsPsWithAuthRequest& GetPartitionsPsWithAuthRequest::operator=(const GetPartitionsPsWithAuthRequest& other1774) {
@@ -50244,6 +50460,8 @@ GetPartitionsPsWithAuthRequest& GetPartitionsPsWithAuthRequest::operator=(const
   validWriteIdList = other1774.validWriteIdList;
   id = other1774.id;
   skipColumnSchemaForPartition = other1774.skipColumnSchemaForPartition;
+  includeParamKeyPattern = other1774.includeParamKeyPattern;
+  excludeParamKeyPattern = other1774.excludeParamKeyPattern;
   __isset = other1774.__isset;
   return *this;
 }
@@ -50260,6 +50478,8 @@ void GetPartitionsPsWithAuthRequest::printTo(std::ostream& out) const {
   out << ", " << "validWriteIdList="; (__isset.validWriteIdList ? (out << to_string(validWriteIdList)) : (out << "<null>"));
   out << ", " << "id="; (__isset.id ? (out << to_string(id)) : (out << "<null>"));
   out << ", " << "skipColumnSchemaForPartition="; (__isset.skipColumnSchemaForPartition ? (out << to_string(skipColumnSchemaForPartition)) : (out << "<null>"));
+  out << ", " << "includeParamKeyPattern="; (__isset.includeParamKeyPattern ? (out << to_string(includeParamKeyPattern)) : (out << "<null>"));
+  out << ", " << "excludeParamKeyPattern="; (__isset.excludeParamKeyPattern ? (out << to_string(excludeParamKeyPattern)) : (out << "<null>"));
   out << ")";
 }
 
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-cpp/hive_metastore_types.h b/standalone-metastore/metastore-common/src/gen/thrift/gen-cpp/hive_metastore_types.h
index 09238fa5e6..47d79d6ae0 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-cpp/hive_metastore_types.h
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-cpp/hive_metastore_types.h
@@ -7238,7 +7238,7 @@ void swap(PartitionsSpecByExprResult &a, PartitionsSpecByExprResult &b);
 std::ostream& operator<<(std::ostream& out, const PartitionsSpecByExprResult& obj);
 
 typedef struct _PartitionsByExprRequest__isset {
-  _PartitionsByExprRequest__isset() : defaultPartitionName(false), maxParts(true), catName(false), order(false), validWriteIdList(false), id(true), skipColumnSchemaForPartition(false) {}
+  _PartitionsByExprRequest__isset() : defaultPartitionName(false), maxParts(true), catName(false), order(false), validWriteIdList(false), id(true), skipColumnSchemaForPartition(false), includeParamKeyPattern(false), excludeParamKeyPattern(false) {}
   bool defaultPartitionName :1;
   bool maxParts :1;
   bool catName :1;
@@ -7246,6 +7246,8 @@ typedef struct _PartitionsByExprRequest__isset {
   bool validWriteIdList :1;
   bool id :1;
   bool skipColumnSchemaForPartition :1;
+  bool includeParamKeyPattern :1;
+  bool excludeParamKeyPattern :1;
 } _PartitionsByExprRequest__isset;
 
 class PartitionsByExprRequest : public virtual ::apache::thrift::TBase {
@@ -7263,7 +7265,9 @@ class PartitionsByExprRequest : public virtual ::apache::thrift::TBase {
                             order(),
                             validWriteIdList(),
                             id(-1LL),
-                            skipColumnSchemaForPartition(0) {
+                            skipColumnSchemaForPartition(0),
+                            includeParamKeyPattern(),
+                            excludeParamKeyPattern() {
   }
 
   virtual ~PartitionsByExprRequest() noexcept;
@@ -7277,6 +7281,8 @@ class PartitionsByExprRequest : public virtual ::apache::thrift::TBase {
   std::string validWriteIdList;
   int64_t id;
   bool skipColumnSchemaForPartition;
+  std::string includeParamKeyPattern;
+  std::string excludeParamKeyPattern;
 
   _PartitionsByExprRequest__isset __isset;
 
@@ -7300,6 +7306,10 @@ class PartitionsByExprRequest : public virtual ::apache::thrift::TBase {
 
   void __set_skipColumnSchemaForPartition(const bool val);
 
+  void __set_includeParamKeyPattern(const std::string& val);
+
+  void __set_excludeParamKeyPattern(const std::string& val);
+
   bool operator == (const PartitionsByExprRequest & rhs) const
   {
     if (!(dbName == rhs.dbName))
@@ -7336,6 +7346,14 @@ class PartitionsByExprRequest : public virtual ::apache::thrift::TBase {
       return false;
     else if (__isset.skipColumnSchemaForPartition && !(skipColumnSchemaForPartition == rhs.skipColumnSchemaForPartition))
       return false;
+    if (__isset.includeParamKeyPattern != rhs.__isset.includeParamKeyPattern)
+      return false;
+    else if (__isset.includeParamKeyPattern && !(includeParamKeyPattern == rhs.includeParamKeyPattern))
+      return false;
+    if (__isset.excludeParamKeyPattern != rhs.__isset.excludeParamKeyPattern)
+      return false;
+    else if (__isset.excludeParamKeyPattern && !(excludeParamKeyPattern == rhs.excludeParamKeyPattern))
+      return false;
     return true;
   }
   bool operator != (const PartitionsByExprRequest &rhs) const {
@@ -8236,7 +8254,7 @@ void swap(PartitionValuesResponse &a, PartitionValuesResponse &b);
 std::ostream& operator<<(std::ostream& out, const PartitionValuesResponse& obj);
 
 typedef struct _GetPartitionsByNamesRequest__isset {
-  _GetPartitionsByNamesRequest__isset() : names(false), get_col_stats(false), processorCapabilities(false), processorIdentifier(false), engine(false), validWriteIdList(false), getFileMetadata(false), id(true), skipColumnSchemaForPartition(false) {}
+  _GetPartitionsByNamesRequest__isset() : names(false), get_col_stats(false), processorCapabilities(false), processorIdentifier(false), engine(false), validWriteIdList(false), getFileMetadata(false), id(true), skipColumnSchemaForPartition(false), includeParamKeyPattern(false), excludeParamKeyPattern(false) {}
   bool names :1;
   bool get_col_stats :1;
   bool processorCapabilities :1;
@@ -8246,6 +8264,8 @@ typedef struct _GetPartitionsByNamesRequest__isset {
   bool getFileMetadata :1;
   bool id :1;
   bool skipColumnSchemaForPartition :1;
+  bool includeParamKeyPattern :1;
+  bool excludeParamKeyPattern :1;
 } _GetPartitionsByNamesRequest__isset;
 
 class GetPartitionsByNamesRequest : public virtual ::apache::thrift::TBase {
@@ -8262,7 +8282,9 @@ class GetPartitionsByNamesRequest : public virtual ::apache::thrift::TBase {
                                 validWriteIdList(),
                                 getFileMetadata(0),
                                 id(-1LL),
-                                skipColumnSchemaForPartition(0) {
+                                skipColumnSchemaForPartition(0),
+                                includeParamKeyPattern(),
+                                excludeParamKeyPattern() {
   }
 
   virtual ~GetPartitionsByNamesRequest() noexcept;
@@ -8277,6 +8299,8 @@ class GetPartitionsByNamesRequest : public virtual ::apache::thrift::TBase {
   bool getFileMetadata;
   int64_t id;
   bool skipColumnSchemaForPartition;
+  std::string includeParamKeyPattern;
+  std::string excludeParamKeyPattern;
 
   _GetPartitionsByNamesRequest__isset __isset;
 
@@ -8302,6 +8326,10 @@ class GetPartitionsByNamesRequest : public virtual ::apache::thrift::TBase {
 
   void __set_skipColumnSchemaForPartition(const bool val);
 
+  void __set_includeParamKeyPattern(const std::string& val);
+
+  void __set_excludeParamKeyPattern(const std::string& val);
+
   bool operator == (const GetPartitionsByNamesRequest & rhs) const
   {
     if (!(db_name == rhs.db_name))
@@ -8344,6 +8372,14 @@ class GetPartitionsByNamesRequest : public virtual ::apache::thrift::TBase {
       return false;
     else if (__isset.skipColumnSchemaForPartition && !(skipColumnSchemaForPartition == rhs.skipColumnSchemaForPartition))
       return false;
+    if (__isset.includeParamKeyPattern != rhs.__isset.includeParamKeyPattern)
+      return false;
+    else if (__isset.includeParamKeyPattern && !(includeParamKeyPattern == rhs.includeParamKeyPattern))
+      return false;
+    if (__isset.excludeParamKeyPattern != rhs.__isset.excludeParamKeyPattern)
+      return false;
+    else if (__isset.excludeParamKeyPattern && !(excludeParamKeyPattern == rhs.excludeParamKeyPattern))
+      return false;
     return true;
   }
   bool operator != (const GetPartitionsByNamesRequest &rhs) const {
@@ -19307,12 +19343,14 @@ void swap(GetPartitionResponse &a, GetPartitionResponse &b);
 std::ostream& operator<<(std::ostream& out, const GetPartitionResponse& obj);
 
 typedef struct _PartitionsRequest__isset {
-  _PartitionsRequest__isset() : catName(false), maxParts(true), validWriteIdList(false), id(true), skipColumnSchemaForPartition(false) {}
+  _PartitionsRequest__isset() : catName(false), maxParts(true), validWriteIdList(false), id(true), skipColumnSchemaForPartition(false), includeParamKeyPattern(false), excludeParamKeyPattern(false) {}
   bool catName :1;
   bool maxParts :1;
   bool validWriteIdList :1;
   bool id :1;
   bool skipColumnSchemaForPartition :1;
+  bool includeParamKeyPattern :1;
+  bool excludeParamKeyPattern :1;
 } _PartitionsRequest__isset;
 
 class PartitionsRequest : public virtual ::apache::thrift::TBase {
@@ -19327,7 +19365,9 @@ class PartitionsRequest : public virtual ::apache::thrift::TBase {
                       maxParts(-1),
                       validWriteIdList(),
                       id(-1LL),
-                      skipColumnSchemaForPartition(0) {
+                      skipColumnSchemaForPartition(0),
+                      includeParamKeyPattern(),
+                      excludeParamKeyPattern() {
   }
 
   virtual ~PartitionsRequest() noexcept;
@@ -19338,6 +19378,8 @@ class PartitionsRequest : public virtual ::apache::thrift::TBase {
   std::string validWriteIdList;
   int64_t id;
   bool skipColumnSchemaForPartition;
+  std::string includeParamKeyPattern;
+  std::string excludeParamKeyPattern;
 
   _PartitionsRequest__isset __isset;
 
@@ -19355,6 +19397,10 @@ class PartitionsRequest : public virtual ::apache::thrift::TBase {
 
   void __set_skipColumnSchemaForPartition(const bool val);
 
+  void __set_includeParamKeyPattern(const std::string& val);
+
+  void __set_excludeParamKeyPattern(const std::string& val);
+
   bool operator == (const PartitionsRequest & rhs) const
   {
     if (__isset.catName != rhs.__isset.catName)
@@ -19381,6 +19427,14 @@ class PartitionsRequest : public virtual ::apache::thrift::TBase {
       return false;
     else if (__isset.skipColumnSchemaForPartition && !(skipColumnSchemaForPartition == rhs.skipColumnSchemaForPartition))
       return false;
+    if (__isset.includeParamKeyPattern != rhs.__isset.includeParamKeyPattern)
+      return false;
+    else if (__isset.includeParamKeyPattern && !(includeParamKeyPattern == rhs.includeParamKeyPattern))
+      return false;
+    if (__isset.excludeParamKeyPattern != rhs.__isset.excludeParamKeyPattern)
+      return false;
+    else if (__isset.excludeParamKeyPattern && !(excludeParamKeyPattern == rhs.excludeParamKeyPattern))
+      return false;
     return true;
   }
   bool operator != (const PartitionsRequest &rhs) const {
@@ -19436,13 +19490,15 @@ void swap(PartitionsResponse &a, PartitionsResponse &b);
 std::ostream& operator<<(std::ostream& out, const PartitionsResponse& obj);
 
 typedef struct _GetPartitionsByFilterRequest__isset {
-  _GetPartitionsByFilterRequest__isset() : catName(false), dbName(false), tblName(false), filter(false), maxParts(true), skipColumnSchemaForPartition(false) {}
+  _GetPartitionsByFilterRequest__isset() : catName(false), dbName(false), tblName(false), filter(false), maxParts(true), skipColumnSchemaForPartition(false), includeParamKeyPattern(false), excludeParamKeyPattern(false) {}
   bool catName :1;
   bool dbName :1;
   bool tblName :1;
   bool filter :1;
   bool maxParts :1;
   bool skipColumnSchemaForPartition :1;
+  bool includeParamKeyPattern :1;
+  bool excludeParamKeyPattern :1;
 } _GetPartitionsByFilterRequest__isset;
 
 class GetPartitionsByFilterRequest : public virtual ::apache::thrift::TBase {
@@ -19456,7 +19512,9 @@ class GetPartitionsByFilterRequest : public virtual ::apache::thrift::TBase {
                                  tblName(),
                                  filter(),
                                  maxParts(-1),
-                                 skipColumnSchemaForPartition(0) {
+                                 skipColumnSchemaForPartition(0),
+                                 includeParamKeyPattern(),
+                                 excludeParamKeyPattern() {
   }
 
   virtual ~GetPartitionsByFilterRequest() noexcept;
@@ -19466,6 +19524,8 @@ class GetPartitionsByFilterRequest : public virtual ::apache::thrift::TBase {
   std::string filter;
   int16_t maxParts;
   bool skipColumnSchemaForPartition;
+  std::string includeParamKeyPattern;
+  std::string excludeParamKeyPattern;
 
   _GetPartitionsByFilterRequest__isset __isset;
 
@@ -19481,6 +19541,10 @@ class GetPartitionsByFilterRequest : public virtual ::apache::thrift::TBase {
 
   void __set_skipColumnSchemaForPartition(const bool val);
 
+  void __set_includeParamKeyPattern(const std::string& val);
+
+  void __set_excludeParamKeyPattern(const std::string& val);
+
   bool operator == (const GetPartitionsByFilterRequest & rhs) const
   {
     if (__isset.catName != rhs.__isset.catName)
@@ -19501,6 +19565,14 @@ class GetPartitionsByFilterRequest : public virtual ::apache::thrift::TBase {
       return false;
     else if (__isset.skipColumnSchemaForPartition && !(skipColumnSchemaForPartition == rhs.skipColumnSchemaForPartition))
       return false;
+    if (__isset.includeParamKeyPattern != rhs.__isset.includeParamKeyPattern)
+      return false;
+    else if (__isset.includeParamKeyPattern && !(includeParamKeyPattern == rhs.includeParamKeyPattern))
+      return false;
+    if (__isset.excludeParamKeyPattern != rhs.__isset.excludeParamKeyPattern)
+      return false;
+    else if (__isset.excludeParamKeyPattern && !(excludeParamKeyPattern == rhs.excludeParamKeyPattern))
+      return false;
     return true;
   }
   bool operator != (const GetPartitionsByFilterRequest &rhs) const {
@@ -19648,7 +19720,7 @@ void swap(GetPartitionNamesPsResponse &a, GetPartitionNamesPsResponse &b);
 std::ostream& operator<<(std::ostream& out, const GetPartitionNamesPsResponse& obj);
 
 typedef struct _GetPartitionsPsWithAuthRequest__isset {
-  _GetPartitionsPsWithAuthRequest__isset() : catName(false), partVals(false), maxParts(true), userName(false), groupNames(false), validWriteIdList(false), id(true), skipColumnSchemaForPartition(false) {}
+  _GetPartitionsPsWithAuthRequest__isset() : catName(false), partVals(false), maxParts(true), userName(false), groupNames(false), validWriteIdList(false), id(true), skipColumnSchemaForPartition(false), includeParamKeyPattern(false), excludeParamKeyPattern(false) {}
   bool catName :1;
   bool partVals :1;
   bool maxParts :1;
@@ -19657,6 +19729,8 @@ typedef struct _GetPartitionsPsWithAuthRequest__isset {
   bool validWriteIdList :1;
   bool id :1;
   bool skipColumnSchemaForPartition :1;
+  bool includeParamKeyPattern :1;
+  bool excludeParamKeyPattern :1;
 } _GetPartitionsPsWithAuthRequest__isset;
 
 class GetPartitionsPsWithAuthRequest : public virtual ::apache::thrift::TBase {
@@ -19672,7 +19746,9 @@ class GetPartitionsPsWithAuthRequest : public virtual ::apache::thrift::TBase {
                                    userName(),
                                    validWriteIdList(),
                                    id(-1LL),
-                                   skipColumnSchemaForPartition(0) {
+                                   skipColumnSchemaForPartition(0),
+                                   includeParamKeyPattern(),
+                                   excludeParamKeyPattern() {
   }
 
   virtual ~GetPartitionsPsWithAuthRequest() noexcept;
@@ -19686,6 +19762,8 @@ class GetPartitionsPsWithAuthRequest : public virtual ::apache::thrift::TBase {
   std::string validWriteIdList;
   int64_t id;
   bool skipColumnSchemaForPartition;
+  std::string includeParamKeyPattern;
+  std::string excludeParamKeyPattern;
 
   _GetPartitionsPsWithAuthRequest__isset __isset;
 
@@ -19709,6 +19787,10 @@ class GetPartitionsPsWithAuthRequest : public virtual ::apache::thrift::TBase {
 
   void __set_skipColumnSchemaForPartition(const bool val);
 
+  void __set_includeParamKeyPattern(const std::string& val);
+
+  void __set_excludeParamKeyPattern(const std::string& val);
+
   bool operator == (const GetPartitionsPsWithAuthRequest & rhs) const
   {
     if (__isset.catName != rhs.__isset.catName)
@@ -19747,6 +19829,14 @@ class GetPartitionsPsWithAuthRequest : public virtual ::apache::thrift::TBase {
       return false;
     else if (__isset.skipColumnSchemaForPartition && !(skipColumnSchemaForPartition == rhs.skipColumnSchemaForPartition))
       return false;
+    if (__isset.includeParamKeyPattern != rhs.__isset.includeParamKeyPattern)
+      return false;
+    else if (__isset.includeParamKeyPattern && !(includeParamKeyPattern == rhs.includeParamKeyPattern))
+      return false;
+    if (__isset.excludeParamKeyPattern != rhs.__isset.excludeParamKeyPattern)
+      return false;
+    else if (__isset.excludeParamKeyPattern && !(excludeParamKeyPattern == rhs.excludeParamKeyPattern))
+      return false;
     return true;
   }
   bool operator != (const GetPartitionsPsWithAuthRequest &rhs) const {
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsByFilterRequest.java b/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsByFilterRequest.java
index 88491fb7d0..2042e78886 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsByFilterRequest.java
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsByFilterRequest.java
@@ -17,6 +17,8 @@
   private static final org.apache.thrift.protocol.TField FILTER_FIELD_DESC = new org.apache.thrift.protocol.TField("filter", org.apache.thrift.protocol.TType.STRING, (short)4);
   private static final org.apache.thrift.protocol.TField MAX_PARTS_FIELD_DESC = new org.apache.thrift.protocol.TField("maxParts", org.apache.thrift.protocol.TType.I16, (short)5);
   private static final org.apache.thrift.protocol.TField SKIP_COLUMN_SCHEMA_FOR_PARTITION_FIELD_DESC = new org.apache.thrift.protocol.TField("skipColumnSchemaForPartition", org.apache.thrift.protocol.TType.BOOL, (short)6);
+  private static final org.apache.thrift.protocol.TField INCLUDE_PARAM_KEY_PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField("includeParamKeyPattern", org.apache.thrift.protocol.TType.STRING, (short)7);
+  private static final org.apache.thrift.protocol.TField EXCLUDE_PARAM_KEY_PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField("excludeParamKeyPattern", org.apache.thrift.protocol.TType.STRING, (short)8);
 
   private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new GetPartitionsByFilterRequestStandardSchemeFactory();
   private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new GetPartitionsByFilterRequestTupleSchemeFactory();
@@ -27,6 +29,8 @@
   private @org.apache.thrift.annotation.Nullable java.lang.String filter; // required
   private short maxParts; // optional
   private boolean skipColumnSchemaForPartition; // optional
+  private @org.apache.thrift.annotation.Nullable java.lang.String includeParamKeyPattern; // optional
+  private @org.apache.thrift.annotation.Nullable java.lang.String excludeParamKeyPattern; // optional
 
   /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
   public enum _Fields implements org.apache.thrift.TFieldIdEnum {
@@ -35,7 +39,9 @@ public enum _Fields implements org.apache.thrift.TFieldIdEnum {
     TBL_NAME((short)3, "tblName"),
     FILTER((short)4, "filter"),
     MAX_PARTS((short)5, "maxParts"),
-    SKIP_COLUMN_SCHEMA_FOR_PARTITION((short)6, "skipColumnSchemaForPartition");
+    SKIP_COLUMN_SCHEMA_FOR_PARTITION((short)6, "skipColumnSchemaForPartition"),
+    INCLUDE_PARAM_KEY_PATTERN((short)7, "includeParamKeyPattern"),
+    EXCLUDE_PARAM_KEY_PATTERN((short)8, "excludeParamKeyPattern");
 
     private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();
 
@@ -63,6 +69,10 @@ public static _Fields findByThriftId(int fieldId) {
           return MAX_PARTS;
         case 6: // SKIP_COLUMN_SCHEMA_FOR_PARTITION
           return SKIP_COLUMN_SCHEMA_FOR_PARTITION;
+        case 7: // INCLUDE_PARAM_KEY_PATTERN
+          return INCLUDE_PARAM_KEY_PATTERN;
+        case 8: // EXCLUDE_PARAM_KEY_PATTERN
+          return EXCLUDE_PARAM_KEY_PATTERN;
         default:
           return null;
       }
@@ -107,7 +117,7 @@ public java.lang.String getFieldName() {
   private static final int __MAXPARTS_ISSET_ID = 0;
   private static final int __SKIPCOLUMNSCHEMAFORPARTITION_ISSET_ID = 1;
   private byte __isset_bitfield = 0;
-  private static final _Fields optionals[] = {_Fields.CAT_NAME,_Fields.MAX_PARTS,_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION};
+  private static final _Fields optionals[] = {_Fields.CAT_NAME,_Fields.MAX_PARTS,_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION,_Fields.INCLUDE_PARAM_KEY_PATTERN,_Fields.EXCLUDE_PARAM_KEY_PATTERN};
   public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
   static {
     java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
@@ -123,6 +133,10 @@ public java.lang.String getFieldName() {
         new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I16)));
     tmpMap.put(_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION, new org.apache.thrift.meta_data.FieldMetaData("skipColumnSchemaForPartition", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
         new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.BOOL)));
+    tmpMap.put(_Fields.INCLUDE_PARAM_KEY_PATTERN, new org.apache.thrift.meta_data.FieldMetaData("includeParamKeyPattern", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
+    tmpMap.put(_Fields.EXCLUDE_PARAM_KEY_PATTERN, new org.apache.thrift.meta_data.FieldMetaData("excludeParamKeyPattern", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
     metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
     org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(GetPartitionsByFilterRequest.class, metaDataMap);
   }
@@ -162,6 +176,12 @@ public GetPartitionsByFilterRequest(GetPartitionsByFilterRequest other) {
     }
     this.maxParts = other.maxParts;
     this.skipColumnSchemaForPartition = other.skipColumnSchemaForPartition;
+    if (other.isSetIncludeParamKeyPattern()) {
+      this.includeParamKeyPattern = other.includeParamKeyPattern;
+    }
+    if (other.isSetExcludeParamKeyPattern()) {
+      this.excludeParamKeyPattern = other.excludeParamKeyPattern;
+    }
   }
 
   public GetPartitionsByFilterRequest deepCopy() {
@@ -178,6 +198,8 @@ public void clear() {
 
     setSkipColumnSchemaForPartitionIsSet(false);
     this.skipColumnSchemaForPartition = false;
+    this.includeParamKeyPattern = null;
+    this.excludeParamKeyPattern = null;
   }
 
   @org.apache.thrift.annotation.Nullable
@@ -320,6 +342,54 @@ public void setSkipColumnSchemaForPartitionIsSet(boolean value) {
     __isset_bitfield = org.apache.thrift.EncodingUtils.setBit(__isset_bitfield, __SKIPCOLUMNSCHEMAFORPARTITION_ISSET_ID, value);
   }
 
+  @org.apache.thrift.annotation.Nullable
+  public java.lang.String getIncludeParamKeyPattern() {
+    return this.includeParamKeyPattern;
+  }
+
+  public void setIncludeParamKeyPattern(@org.apache.thrift.annotation.Nullable java.lang.String includeParamKeyPattern) {
+    this.includeParamKeyPattern = includeParamKeyPattern;
+  }
+
+  public void unsetIncludeParamKeyPattern() {
+    this.includeParamKeyPattern = null;
+  }
+
+  /** Returns true if field includeParamKeyPattern is set (has been assigned a value) and false otherwise */
+  public boolean isSetIncludeParamKeyPattern() {
+    return this.includeParamKeyPattern != null;
+  }
+
+  public void setIncludeParamKeyPatternIsSet(boolean value) {
+    if (!value) {
+      this.includeParamKeyPattern = null;
+    }
+  }
+
+  @org.apache.thrift.annotation.Nullable
+  public java.lang.String getExcludeParamKeyPattern() {
+    return this.excludeParamKeyPattern;
+  }
+
+  public void setExcludeParamKeyPattern(@org.apache.thrift.annotation.Nullable java.lang.String excludeParamKeyPattern) {
+    this.excludeParamKeyPattern = excludeParamKeyPattern;
+  }
+
+  public void unsetExcludeParamKeyPattern() {
+    this.excludeParamKeyPattern = null;
+  }
+
+  /** Returns true if field excludeParamKeyPattern is set (has been assigned a value) and false otherwise */
+  public boolean isSetExcludeParamKeyPattern() {
+    return this.excludeParamKeyPattern != null;
+  }
+
+  public void setExcludeParamKeyPatternIsSet(boolean value) {
+    if (!value) {
+      this.excludeParamKeyPattern = null;
+    }
+  }
+
   public void setFieldValue(_Fields field, @org.apache.thrift.annotation.Nullable java.lang.Object value) {
     switch (field) {
     case CAT_NAME:
@@ -370,6 +440,22 @@ public void setFieldValue(_Fields field, @org.apache.thrift.annotation.Nullable
       }
       break;
 
+    case INCLUDE_PARAM_KEY_PATTERN:
+      if (value == null) {
+        unsetIncludeParamKeyPattern();
+      } else {
+        setIncludeParamKeyPattern((java.lang.String)value);
+      }
+      break;
+
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      if (value == null) {
+        unsetExcludeParamKeyPattern();
+      } else {
+        setExcludeParamKeyPattern((java.lang.String)value);
+      }
+      break;
+
     }
   }
 
@@ -394,6 +480,12 @@ public java.lang.Object getFieldValue(_Fields field) {
     case SKIP_COLUMN_SCHEMA_FOR_PARTITION:
       return isSkipColumnSchemaForPartition();
 
+    case INCLUDE_PARAM_KEY_PATTERN:
+      return getIncludeParamKeyPattern();
+
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      return getExcludeParamKeyPattern();
+
     }
     throw new java.lang.IllegalStateException();
   }
@@ -417,6 +509,10 @@ public boolean isSet(_Fields field) {
       return isSetMaxParts();
     case SKIP_COLUMN_SCHEMA_FOR_PARTITION:
       return isSetSkipColumnSchemaForPartition();
+    case INCLUDE_PARAM_KEY_PATTERN:
+      return isSetIncludeParamKeyPattern();
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      return isSetExcludeParamKeyPattern();
     }
     throw new java.lang.IllegalStateException();
   }
@@ -488,6 +584,24 @@ public boolean equals(GetPartitionsByFilterRequest that) {
         return false;
     }
 
+    boolean this_present_includeParamKeyPattern = true && this.isSetIncludeParamKeyPattern();
+    boolean that_present_includeParamKeyPattern = true && that.isSetIncludeParamKeyPattern();
+    if (this_present_includeParamKeyPattern || that_present_includeParamKeyPattern) {
+      if (!(this_present_includeParamKeyPattern && that_present_includeParamKeyPattern))
+        return false;
+      if (!this.includeParamKeyPattern.equals(that.includeParamKeyPattern))
+        return false;
+    }
+
+    boolean this_present_excludeParamKeyPattern = true && this.isSetExcludeParamKeyPattern();
+    boolean that_present_excludeParamKeyPattern = true && that.isSetExcludeParamKeyPattern();
+    if (this_present_excludeParamKeyPattern || that_present_excludeParamKeyPattern) {
+      if (!(this_present_excludeParamKeyPattern && that_present_excludeParamKeyPattern))
+        return false;
+      if (!this.excludeParamKeyPattern.equals(that.excludeParamKeyPattern))
+        return false;
+    }
+
     return true;
   }
 
@@ -519,6 +633,14 @@ public int hashCode() {
     if (isSetSkipColumnSchemaForPartition())
       hashCode = hashCode * 8191 + ((skipColumnSchemaForPartition) ? 131071 : 524287);
 
+    hashCode = hashCode * 8191 + ((isSetIncludeParamKeyPattern()) ? 131071 : 524287);
+    if (isSetIncludeParamKeyPattern())
+      hashCode = hashCode * 8191 + includeParamKeyPattern.hashCode();
+
+    hashCode = hashCode * 8191 + ((isSetExcludeParamKeyPattern()) ? 131071 : 524287);
+    if (isSetExcludeParamKeyPattern())
+      hashCode = hashCode * 8191 + excludeParamKeyPattern.hashCode();
+
     return hashCode;
   }
 
@@ -590,6 +712,26 @@ public int compareTo(GetPartitionsByFilterRequest other) {
         return lastComparison;
       }
     }
+    lastComparison = java.lang.Boolean.compare(isSetIncludeParamKeyPattern(), other.isSetIncludeParamKeyPattern());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetIncludeParamKeyPattern()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.includeParamKeyPattern, other.includeParamKeyPattern);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    lastComparison = java.lang.Boolean.compare(isSetExcludeParamKeyPattern(), other.isSetExcludeParamKeyPattern());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetExcludeParamKeyPattern()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.excludeParamKeyPattern, other.excludeParamKeyPattern);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
     return 0;
   }
 
@@ -656,6 +798,26 @@ public java.lang.String toString() {
       sb.append(this.skipColumnSchemaForPartition);
       first = false;
     }
+    if (isSetIncludeParamKeyPattern()) {
+      if (!first) sb.append(", ");
+      sb.append("includeParamKeyPattern:");
+      if (this.includeParamKeyPattern == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.includeParamKeyPattern);
+      }
+      first = false;
+    }
+    if (isSetExcludeParamKeyPattern()) {
+      if (!first) sb.append(", ");
+      sb.append("excludeParamKeyPattern:");
+      if (this.excludeParamKeyPattern == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.excludeParamKeyPattern);
+      }
+      first = false;
+    }
     sb.append(")");
     return sb.toString();
   }
@@ -749,6 +911,22 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, GetPartitionsByFilt
               org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
             }
             break;
+          case 7: // INCLUDE_PARAM_KEY_PATTERN
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
+              struct.includeParamKeyPattern = iprot.readString();
+              struct.setIncludeParamKeyPatternIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
+          case 8: // EXCLUDE_PARAM_KEY_PATTERN
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
+              struct.excludeParamKeyPattern = iprot.readString();
+              struct.setExcludeParamKeyPatternIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
           default:
             org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
         }
@@ -794,6 +972,20 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, GetPartitionsByFil
         oprot.writeBool(struct.skipColumnSchemaForPartition);
         oprot.writeFieldEnd();
       }
+      if (struct.includeParamKeyPattern != null) {
+        if (struct.isSetIncludeParamKeyPattern()) {
+          oprot.writeFieldBegin(INCLUDE_PARAM_KEY_PATTERN_FIELD_DESC);
+          oprot.writeString(struct.includeParamKeyPattern);
+          oprot.writeFieldEnd();
+        }
+      }
+      if (struct.excludeParamKeyPattern != null) {
+        if (struct.isSetExcludeParamKeyPattern()) {
+          oprot.writeFieldBegin(EXCLUDE_PARAM_KEY_PATTERN_FIELD_DESC);
+          oprot.writeString(struct.excludeParamKeyPattern);
+          oprot.writeFieldEnd();
+        }
+      }
       oprot.writeFieldStop();
       oprot.writeStructEnd();
     }
@@ -830,7 +1022,13 @@ public void write(org.apache.thrift.protocol.TProtocol prot, GetPartitionsByFilt
       if (struct.isSetSkipColumnSchemaForPartition()) {
         optionals.set(5);
       }
-      oprot.writeBitSet(optionals, 6);
+      if (struct.isSetIncludeParamKeyPattern()) {
+        optionals.set(6);
+      }
+      if (struct.isSetExcludeParamKeyPattern()) {
+        optionals.set(7);
+      }
+      oprot.writeBitSet(optionals, 8);
       if (struct.isSetCatName()) {
         oprot.writeString(struct.catName);
       }
@@ -849,12 +1047,18 @@ public void write(org.apache.thrift.protocol.TProtocol prot, GetPartitionsByFilt
       if (struct.isSetSkipColumnSchemaForPartition()) {
         oprot.writeBool(struct.skipColumnSchemaForPartition);
       }
+      if (struct.isSetIncludeParamKeyPattern()) {
+        oprot.writeString(struct.includeParamKeyPattern);
+      }
+      if (struct.isSetExcludeParamKeyPattern()) {
+        oprot.writeString(struct.excludeParamKeyPattern);
+      }
     }
 
     @Override
     public void read(org.apache.thrift.protocol.TProtocol prot, GetPartitionsByFilterRequest struct) throws org.apache.thrift.TException {
       org.apache.thrift.protocol.TTupleProtocol iprot = (org.apache.thrift.protocol.TTupleProtocol) prot;
-      java.util.BitSet incoming = iprot.readBitSet(6);
+      java.util.BitSet incoming = iprot.readBitSet(8);
       if (incoming.get(0)) {
         struct.catName = iprot.readString();
         struct.setCatNameIsSet(true);
@@ -879,6 +1083,14 @@ public void read(org.apache.thrift.protocol.TProtocol prot, GetPartitionsByFilte
         struct.skipColumnSchemaForPartition = iprot.readBool();
         struct.setSkipColumnSchemaForPartitionIsSet(true);
       }
+      if (incoming.get(6)) {
+        struct.includeParamKeyPattern = iprot.readString();
+        struct.setIncludeParamKeyPatternIsSet(true);
+      }
+      if (incoming.get(7)) {
+        struct.excludeParamKeyPattern = iprot.readString();
+        struct.setExcludeParamKeyPatternIsSet(true);
+      }
     }
   }
 
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsByNamesRequest.java b/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsByNamesRequest.java
index 4f91e2e10c..2ecd9aa0c1 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsByNamesRequest.java
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsByNamesRequest.java
@@ -22,6 +22,8 @@
   private static final org.apache.thrift.protocol.TField GET_FILE_METADATA_FIELD_DESC = new org.apache.thrift.protocol.TField("getFileMetadata", org.apache.thrift.protocol.TType.BOOL, (short)9);
   private static final org.apache.thrift.protocol.TField ID_FIELD_DESC = new org.apache.thrift.protocol.TField("id", org.apache.thrift.protocol.TType.I64, (short)10);
   private static final org.apache.thrift.protocol.TField SKIP_COLUMN_SCHEMA_FOR_PARTITION_FIELD_DESC = new org.apache.thrift.protocol.TField("skipColumnSchemaForPartition", org.apache.thrift.protocol.TType.BOOL, (short)11);
+  private static final org.apache.thrift.protocol.TField INCLUDE_PARAM_KEY_PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField("includeParamKeyPattern", org.apache.thrift.protocol.TType.STRING, (short)12);
+  private static final org.apache.thrift.protocol.TField EXCLUDE_PARAM_KEY_PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField("excludeParamKeyPattern", org.apache.thrift.protocol.TType.STRING, (short)13);
 
   private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new GetPartitionsByNamesRequestStandardSchemeFactory();
   private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new GetPartitionsByNamesRequestTupleSchemeFactory();
@@ -37,6 +39,8 @@
   private boolean getFileMetadata; // optional
   private long id; // optional
   private boolean skipColumnSchemaForPartition; // optional
+  private @org.apache.thrift.annotation.Nullable java.lang.String includeParamKeyPattern; // optional
+  private @org.apache.thrift.annotation.Nullable java.lang.String excludeParamKeyPattern; // optional
 
   /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
   public enum _Fields implements org.apache.thrift.TFieldIdEnum {
@@ -50,7 +54,9 @@ public enum _Fields implements org.apache.thrift.TFieldIdEnum {
     VALID_WRITE_ID_LIST((short)8, "validWriteIdList"),
     GET_FILE_METADATA((short)9, "getFileMetadata"),
     ID((short)10, "id"),
-    SKIP_COLUMN_SCHEMA_FOR_PARTITION((short)11, "skipColumnSchemaForPartition");
+    SKIP_COLUMN_SCHEMA_FOR_PARTITION((short)11, "skipColumnSchemaForPartition"),
+    INCLUDE_PARAM_KEY_PATTERN((short)12, "includeParamKeyPattern"),
+    EXCLUDE_PARAM_KEY_PATTERN((short)13, "excludeParamKeyPattern");
 
     private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();
 
@@ -88,6 +94,10 @@ public static _Fields findByThriftId(int fieldId) {
           return ID;
         case 11: // SKIP_COLUMN_SCHEMA_FOR_PARTITION
           return SKIP_COLUMN_SCHEMA_FOR_PARTITION;
+        case 12: // INCLUDE_PARAM_KEY_PATTERN
+          return INCLUDE_PARAM_KEY_PATTERN;
+        case 13: // EXCLUDE_PARAM_KEY_PATTERN
+          return EXCLUDE_PARAM_KEY_PATTERN;
         default:
           return null;
       }
@@ -134,7 +144,7 @@ public java.lang.String getFieldName() {
   private static final int __ID_ISSET_ID = 2;
   private static final int __SKIPCOLUMNSCHEMAFORPARTITION_ISSET_ID = 3;
   private byte __isset_bitfield = 0;
-  private static final _Fields optionals[] = {_Fields.NAMES,_Fields.GET_COL_STATS,_Fields.PROCESSOR_CAPABILITIES,_Fields.PROCESSOR_IDENTIFIER,_Fields.ENGINE,_Fields.VALID_WRITE_ID_LIST,_Fields.GET_FILE_METADATA,_Fields.ID,_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION};
+  private static final _Fields optionals[] = {_Fields.NAMES,_Fields.GET_COL_STATS,_Fields.PROCESSOR_CAPABILITIES,_Fields.PROCESSOR_IDENTIFIER,_Fields.ENGINE,_Fields.VALID_WRITE_ID_LIST,_Fields.GET_FILE_METADATA,_Fields.ID,_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION,_Fields.INCLUDE_PARAM_KEY_PATTERN,_Fields.EXCLUDE_PARAM_KEY_PATTERN};
   public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
   static {
     java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
@@ -162,6 +172,10 @@ public java.lang.String getFieldName() {
         new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I64)));
     tmpMap.put(_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION, new org.apache.thrift.meta_data.FieldMetaData("skipColumnSchemaForPartition", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
         new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.BOOL)));
+    tmpMap.put(_Fields.INCLUDE_PARAM_KEY_PATTERN, new org.apache.thrift.meta_data.FieldMetaData("includeParamKeyPattern", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
+    tmpMap.put(_Fields.EXCLUDE_PARAM_KEY_PATTERN, new org.apache.thrift.meta_data.FieldMetaData("excludeParamKeyPattern", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
     metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
     org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(GetPartitionsByNamesRequest.class, metaDataMap);
   }
@@ -212,6 +226,12 @@ public GetPartitionsByNamesRequest(GetPartitionsByNamesRequest other) {
     this.getFileMetadata = other.getFileMetadata;
     this.id = other.id;
     this.skipColumnSchemaForPartition = other.skipColumnSchemaForPartition;
+    if (other.isSetIncludeParamKeyPattern()) {
+      this.includeParamKeyPattern = other.includeParamKeyPattern;
+    }
+    if (other.isSetExcludeParamKeyPattern()) {
+      this.excludeParamKeyPattern = other.excludeParamKeyPattern;
+    }
   }
 
   public GetPartitionsByNamesRequest deepCopy() {
@@ -235,6 +255,8 @@ public void clear() {
 
     setSkipColumnSchemaForPartitionIsSet(false);
     this.skipColumnSchemaForPartition = false;
+    this.includeParamKeyPattern = null;
+    this.excludeParamKeyPattern = null;
   }
 
   @org.apache.thrift.annotation.Nullable
@@ -525,6 +547,54 @@ public void setSkipColumnSchemaForPartitionIsSet(boolean value) {
     __isset_bitfield = org.apache.thrift.EncodingUtils.setBit(__isset_bitfield, __SKIPCOLUMNSCHEMAFORPARTITION_ISSET_ID, value);
   }
 
+  @org.apache.thrift.annotation.Nullable
+  public java.lang.String getIncludeParamKeyPattern() {
+    return this.includeParamKeyPattern;
+  }
+
+  public void setIncludeParamKeyPattern(@org.apache.thrift.annotation.Nullable java.lang.String includeParamKeyPattern) {
+    this.includeParamKeyPattern = includeParamKeyPattern;
+  }
+
+  public void unsetIncludeParamKeyPattern() {
+    this.includeParamKeyPattern = null;
+  }
+
+  /** Returns true if field includeParamKeyPattern is set (has been assigned a value) and false otherwise */
+  public boolean isSetIncludeParamKeyPattern() {
+    return this.includeParamKeyPattern != null;
+  }
+
+  public void setIncludeParamKeyPatternIsSet(boolean value) {
+    if (!value) {
+      this.includeParamKeyPattern = null;
+    }
+  }
+
+  @org.apache.thrift.annotation.Nullable
+  public java.lang.String getExcludeParamKeyPattern() {
+    return this.excludeParamKeyPattern;
+  }
+
+  public void setExcludeParamKeyPattern(@org.apache.thrift.annotation.Nullable java.lang.String excludeParamKeyPattern) {
+    this.excludeParamKeyPattern = excludeParamKeyPattern;
+  }
+
+  public void unsetExcludeParamKeyPattern() {
+    this.excludeParamKeyPattern = null;
+  }
+
+  /** Returns true if field excludeParamKeyPattern is set (has been assigned a value) and false otherwise */
+  public boolean isSetExcludeParamKeyPattern() {
+    return this.excludeParamKeyPattern != null;
+  }
+
+  public void setExcludeParamKeyPatternIsSet(boolean value) {
+    if (!value) {
+      this.excludeParamKeyPattern = null;
+    }
+  }
+
   public void setFieldValue(_Fields field, @org.apache.thrift.annotation.Nullable java.lang.Object value) {
     switch (field) {
     case DB_NAME:
@@ -615,6 +685,22 @@ public void setFieldValue(_Fields field, @org.apache.thrift.annotation.Nullable
       }
       break;
 
+    case INCLUDE_PARAM_KEY_PATTERN:
+      if (value == null) {
+        unsetIncludeParamKeyPattern();
+      } else {
+        setIncludeParamKeyPattern((java.lang.String)value);
+      }
+      break;
+
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      if (value == null) {
+        unsetExcludeParamKeyPattern();
+      } else {
+        setExcludeParamKeyPattern((java.lang.String)value);
+      }
+      break;
+
     }
   }
 
@@ -654,6 +740,12 @@ public java.lang.Object getFieldValue(_Fields field) {
     case SKIP_COLUMN_SCHEMA_FOR_PARTITION:
       return isSkipColumnSchemaForPartition();
 
+    case INCLUDE_PARAM_KEY_PATTERN:
+      return getIncludeParamKeyPattern();
+
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      return getExcludeParamKeyPattern();
+
     }
     throw new java.lang.IllegalStateException();
   }
@@ -687,6 +779,10 @@ public boolean isSet(_Fields field) {
       return isSetId();
     case SKIP_COLUMN_SCHEMA_FOR_PARTITION:
       return isSetSkipColumnSchemaForPartition();
+    case INCLUDE_PARAM_KEY_PATTERN:
+      return isSetIncludeParamKeyPattern();
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      return isSetExcludeParamKeyPattern();
     }
     throw new java.lang.IllegalStateException();
   }
@@ -803,6 +899,24 @@ public boolean equals(GetPartitionsByNamesRequest that) {
         return false;
     }
 
+    boolean this_present_includeParamKeyPattern = true && this.isSetIncludeParamKeyPattern();
+    boolean that_present_includeParamKeyPattern = true && that.isSetIncludeParamKeyPattern();
+    if (this_present_includeParamKeyPattern || that_present_includeParamKeyPattern) {
+      if (!(this_present_includeParamKeyPattern && that_present_includeParamKeyPattern))
+        return false;
+      if (!this.includeParamKeyPattern.equals(that.includeParamKeyPattern))
+        return false;
+    }
+
+    boolean this_present_excludeParamKeyPattern = true && this.isSetExcludeParamKeyPattern();
+    boolean that_present_excludeParamKeyPattern = true && that.isSetExcludeParamKeyPattern();
+    if (this_present_excludeParamKeyPattern || that_present_excludeParamKeyPattern) {
+      if (!(this_present_excludeParamKeyPattern && that_present_excludeParamKeyPattern))
+        return false;
+      if (!this.excludeParamKeyPattern.equals(that.excludeParamKeyPattern))
+        return false;
+    }
+
     return true;
   }
 
@@ -854,6 +968,14 @@ public int hashCode() {
     if (isSetSkipColumnSchemaForPartition())
       hashCode = hashCode * 8191 + ((skipColumnSchemaForPartition) ? 131071 : 524287);
 
+    hashCode = hashCode * 8191 + ((isSetIncludeParamKeyPattern()) ? 131071 : 524287);
+    if (isSetIncludeParamKeyPattern())
+      hashCode = hashCode * 8191 + includeParamKeyPattern.hashCode();
+
+    hashCode = hashCode * 8191 + ((isSetExcludeParamKeyPattern()) ? 131071 : 524287);
+    if (isSetExcludeParamKeyPattern())
+      hashCode = hashCode * 8191 + excludeParamKeyPattern.hashCode();
+
     return hashCode;
   }
 
@@ -975,6 +1097,26 @@ public int compareTo(GetPartitionsByNamesRequest other) {
         return lastComparison;
       }
     }
+    lastComparison = java.lang.Boolean.compare(isSetIncludeParamKeyPattern(), other.isSetIncludeParamKeyPattern());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetIncludeParamKeyPattern()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.includeParamKeyPattern, other.includeParamKeyPattern);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    lastComparison = java.lang.Boolean.compare(isSetExcludeParamKeyPattern(), other.isSetExcludeParamKeyPattern());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetExcludeParamKeyPattern()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.excludeParamKeyPattern, other.excludeParamKeyPattern);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
     return 0;
   }
 
@@ -1085,6 +1227,26 @@ public java.lang.String toString() {
       sb.append(this.skipColumnSchemaForPartition);
       first = false;
     }
+    if (isSetIncludeParamKeyPattern()) {
+      if (!first) sb.append(", ");
+      sb.append("includeParamKeyPattern:");
+      if (this.includeParamKeyPattern == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.includeParamKeyPattern);
+      }
+      first = false;
+    }
+    if (isSetExcludeParamKeyPattern()) {
+      if (!first) sb.append(", ");
+      sb.append("excludeParamKeyPattern:");
+      if (this.excludeParamKeyPattern == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.excludeParamKeyPattern);
+      }
+      first = false;
+    }
     sb.append(")");
     return sb.toString();
   }
@@ -1246,6 +1408,22 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, GetPartitionsByName
               org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
             }
             break;
+          case 12: // INCLUDE_PARAM_KEY_PATTERN
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
+              struct.includeParamKeyPattern = iprot.readString();
+              struct.setIncludeParamKeyPatternIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
+          case 13: // EXCLUDE_PARAM_KEY_PATTERN
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
+              struct.excludeParamKeyPattern = iprot.readString();
+              struct.setExcludeParamKeyPatternIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
           default:
             org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
         }
@@ -1338,6 +1516,20 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, GetPartitionsByNam
         oprot.writeBool(struct.skipColumnSchemaForPartition);
         oprot.writeFieldEnd();
       }
+      if (struct.includeParamKeyPattern != null) {
+        if (struct.isSetIncludeParamKeyPattern()) {
+          oprot.writeFieldBegin(INCLUDE_PARAM_KEY_PATTERN_FIELD_DESC);
+          oprot.writeString(struct.includeParamKeyPattern);
+          oprot.writeFieldEnd();
+        }
+      }
+      if (struct.excludeParamKeyPattern != null) {
+        if (struct.isSetExcludeParamKeyPattern()) {
+          oprot.writeFieldBegin(EXCLUDE_PARAM_KEY_PATTERN_FIELD_DESC);
+          oprot.writeString(struct.excludeParamKeyPattern);
+          oprot.writeFieldEnd();
+        }
+      }
       oprot.writeFieldStop();
       oprot.writeStructEnd();
     }
@@ -1385,7 +1577,13 @@ public void write(org.apache.thrift.protocol.TProtocol prot, GetPartitionsByName
       if (struct.isSetSkipColumnSchemaForPartition()) {
         optionals.set(8);
       }
-      oprot.writeBitSet(optionals, 9);
+      if (struct.isSetIncludeParamKeyPattern()) {
+        optionals.set(9);
+      }
+      if (struct.isSetExcludeParamKeyPattern()) {
+        optionals.set(10);
+      }
+      oprot.writeBitSet(optionals, 11);
       if (struct.isSetNames()) {
         {
           oprot.writeI32(struct.names.size());
@@ -1425,6 +1623,12 @@ public void write(org.apache.thrift.protocol.TProtocol prot, GetPartitionsByName
       if (struct.isSetSkipColumnSchemaForPartition()) {
         oprot.writeBool(struct.skipColumnSchemaForPartition);
       }
+      if (struct.isSetIncludeParamKeyPattern()) {
+        oprot.writeString(struct.includeParamKeyPattern);
+      }
+      if (struct.isSetExcludeParamKeyPattern()) {
+        oprot.writeString(struct.excludeParamKeyPattern);
+      }
     }
 
     @Override
@@ -1434,7 +1638,7 @@ public void read(org.apache.thrift.protocol.TProtocol prot, GetPartitionsByNames
       struct.setDb_nameIsSet(true);
       struct.tbl_name = iprot.readString();
       struct.setTbl_nameIsSet(true);
-      java.util.BitSet incoming = iprot.readBitSet(9);
+      java.util.BitSet incoming = iprot.readBitSet(11);
       if (incoming.get(0)) {
         {
           org.apache.thrift.protocol.TList _list732 = iprot.readListBegin(org.apache.thrift.protocol.TType.STRING);
@@ -1489,6 +1693,14 @@ public void read(org.apache.thrift.protocol.TProtocol prot, GetPartitionsByNames
         struct.skipColumnSchemaForPartition = iprot.readBool();
         struct.setSkipColumnSchemaForPartitionIsSet(true);
       }
+      if (incoming.get(9)) {
+        struct.includeParamKeyPattern = iprot.readString();
+        struct.setIncludeParamKeyPatternIsSet(true);
+      }
+      if (incoming.get(10)) {
+        struct.excludeParamKeyPattern = iprot.readString();
+        struct.setExcludeParamKeyPatternIsSet(true);
+      }
     }
   }
 
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsPsWithAuthRequest.java b/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsPsWithAuthRequest.java
index 865f3fe366..8cd28971b2 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsPsWithAuthRequest.java
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetPartitionsPsWithAuthRequest.java
@@ -21,6 +21,8 @@
   private static final org.apache.thrift.protocol.TField VALID_WRITE_ID_LIST_FIELD_DESC = new org.apache.thrift.protocol.TField("validWriteIdList", org.apache.thrift.protocol.TType.STRING, (short)8);
   private static final org.apache.thrift.protocol.TField ID_FIELD_DESC = new org.apache.thrift.protocol.TField("id", org.apache.thrift.protocol.TType.I64, (short)9);
   private static final org.apache.thrift.protocol.TField SKIP_COLUMN_SCHEMA_FOR_PARTITION_FIELD_DESC = new org.apache.thrift.protocol.TField("skipColumnSchemaForPartition", org.apache.thrift.protocol.TType.BOOL, (short)10);
+  private static final org.apache.thrift.protocol.TField INCLUDE_PARAM_KEY_PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField("includeParamKeyPattern", org.apache.thrift.protocol.TType.STRING, (short)11);
+  private static final org.apache.thrift.protocol.TField EXCLUDE_PARAM_KEY_PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField("excludeParamKeyPattern", org.apache.thrift.protocol.TType.STRING, (short)12);
 
   private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new GetPartitionsPsWithAuthRequestStandardSchemeFactory();
   private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new GetPartitionsPsWithAuthRequestTupleSchemeFactory();
@@ -35,6 +37,8 @@
   private @org.apache.thrift.annotation.Nullable java.lang.String validWriteIdList; // optional
   private long id; // optional
   private boolean skipColumnSchemaForPartition; // optional
+  private @org.apache.thrift.annotation.Nullable java.lang.String includeParamKeyPattern; // optional
+  private @org.apache.thrift.annotation.Nullable java.lang.String excludeParamKeyPattern; // optional
 
   /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
   public enum _Fields implements org.apache.thrift.TFieldIdEnum {
@@ -47,7 +51,9 @@ public enum _Fields implements org.apache.thrift.TFieldIdEnum {
     GROUP_NAMES((short)7, "groupNames"),
     VALID_WRITE_ID_LIST((short)8, "validWriteIdList"),
     ID((short)9, "id"),
-    SKIP_COLUMN_SCHEMA_FOR_PARTITION((short)10, "skipColumnSchemaForPartition");
+    SKIP_COLUMN_SCHEMA_FOR_PARTITION((short)10, "skipColumnSchemaForPartition"),
+    INCLUDE_PARAM_KEY_PATTERN((short)11, "includeParamKeyPattern"),
+    EXCLUDE_PARAM_KEY_PATTERN((short)12, "excludeParamKeyPattern");
 
     private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();
 
@@ -83,6 +89,10 @@ public static _Fields findByThriftId(int fieldId) {
           return ID;
         case 10: // SKIP_COLUMN_SCHEMA_FOR_PARTITION
           return SKIP_COLUMN_SCHEMA_FOR_PARTITION;
+        case 11: // INCLUDE_PARAM_KEY_PATTERN
+          return INCLUDE_PARAM_KEY_PATTERN;
+        case 12: // EXCLUDE_PARAM_KEY_PATTERN
+          return EXCLUDE_PARAM_KEY_PATTERN;
         default:
           return null;
       }
@@ -128,7 +138,7 @@ public java.lang.String getFieldName() {
   private static final int __ID_ISSET_ID = 1;
   private static final int __SKIPCOLUMNSCHEMAFORPARTITION_ISSET_ID = 2;
   private byte __isset_bitfield = 0;
-  private static final _Fields optionals[] = {_Fields.CAT_NAME,_Fields.PART_VALS,_Fields.MAX_PARTS,_Fields.USER_NAME,_Fields.GROUP_NAMES,_Fields.VALID_WRITE_ID_LIST,_Fields.ID,_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION};
+  private static final _Fields optionals[] = {_Fields.CAT_NAME,_Fields.PART_VALS,_Fields.MAX_PARTS,_Fields.USER_NAME,_Fields.GROUP_NAMES,_Fields.VALID_WRITE_ID_LIST,_Fields.ID,_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION,_Fields.INCLUDE_PARAM_KEY_PATTERN,_Fields.EXCLUDE_PARAM_KEY_PATTERN};
   public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
   static {
     java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
@@ -154,6 +164,10 @@ public java.lang.String getFieldName() {
         new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I64)));
     tmpMap.put(_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION, new org.apache.thrift.meta_data.FieldMetaData("skipColumnSchemaForPartition", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
         new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.BOOL)));
+    tmpMap.put(_Fields.INCLUDE_PARAM_KEY_PATTERN, new org.apache.thrift.meta_data.FieldMetaData("includeParamKeyPattern", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
+    tmpMap.put(_Fields.EXCLUDE_PARAM_KEY_PATTERN, new org.apache.thrift.meta_data.FieldMetaData("excludeParamKeyPattern", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
     metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
     org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(GetPartitionsPsWithAuthRequest.class, metaDataMap);
   }
@@ -205,6 +219,12 @@ public GetPartitionsPsWithAuthRequest(GetPartitionsPsWithAuthRequest other) {
     }
     this.id = other.id;
     this.skipColumnSchemaForPartition = other.skipColumnSchemaForPartition;
+    if (other.isSetIncludeParamKeyPattern()) {
+      this.includeParamKeyPattern = other.includeParamKeyPattern;
+    }
+    if (other.isSetExcludeParamKeyPattern()) {
+      this.excludeParamKeyPattern = other.excludeParamKeyPattern;
+    }
   }
 
   public GetPartitionsPsWithAuthRequest deepCopy() {
@@ -226,6 +246,8 @@ public void clear() {
 
     setSkipColumnSchemaForPartitionIsSet(false);
     this.skipColumnSchemaForPartition = false;
+    this.includeParamKeyPattern = null;
+    this.excludeParamKeyPattern = null;
   }
 
   @org.apache.thrift.annotation.Nullable
@@ -494,6 +516,54 @@ public void setSkipColumnSchemaForPartitionIsSet(boolean value) {
     __isset_bitfield = org.apache.thrift.EncodingUtils.setBit(__isset_bitfield, __SKIPCOLUMNSCHEMAFORPARTITION_ISSET_ID, value);
   }
 
+  @org.apache.thrift.annotation.Nullable
+  public java.lang.String getIncludeParamKeyPattern() {
+    return this.includeParamKeyPattern;
+  }
+
+  public void setIncludeParamKeyPattern(@org.apache.thrift.annotation.Nullable java.lang.String includeParamKeyPattern) {
+    this.includeParamKeyPattern = includeParamKeyPattern;
+  }
+
+  public void unsetIncludeParamKeyPattern() {
+    this.includeParamKeyPattern = null;
+  }
+
+  /** Returns true if field includeParamKeyPattern is set (has been assigned a value) and false otherwise */
+  public boolean isSetIncludeParamKeyPattern() {
+    return this.includeParamKeyPattern != null;
+  }
+
+  public void setIncludeParamKeyPatternIsSet(boolean value) {
+    if (!value) {
+      this.includeParamKeyPattern = null;
+    }
+  }
+
+  @org.apache.thrift.annotation.Nullable
+  public java.lang.String getExcludeParamKeyPattern() {
+    return this.excludeParamKeyPattern;
+  }
+
+  public void setExcludeParamKeyPattern(@org.apache.thrift.annotation.Nullable java.lang.String excludeParamKeyPattern) {
+    this.excludeParamKeyPattern = excludeParamKeyPattern;
+  }
+
+  public void unsetExcludeParamKeyPattern() {
+    this.excludeParamKeyPattern = null;
+  }
+
+  /** Returns true if field excludeParamKeyPattern is set (has been assigned a value) and false otherwise */
+  public boolean isSetExcludeParamKeyPattern() {
+    return this.excludeParamKeyPattern != null;
+  }
+
+  public void setExcludeParamKeyPatternIsSet(boolean value) {
+    if (!value) {
+      this.excludeParamKeyPattern = null;
+    }
+  }
+
   public void setFieldValue(_Fields field, @org.apache.thrift.annotation.Nullable java.lang.Object value) {
     switch (field) {
     case CAT_NAME:
@@ -576,6 +646,22 @@ public void setFieldValue(_Fields field, @org.apache.thrift.annotation.Nullable
       }
       break;
 
+    case INCLUDE_PARAM_KEY_PATTERN:
+      if (value == null) {
+        unsetIncludeParamKeyPattern();
+      } else {
+        setIncludeParamKeyPattern((java.lang.String)value);
+      }
+      break;
+
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      if (value == null) {
+        unsetExcludeParamKeyPattern();
+      } else {
+        setExcludeParamKeyPattern((java.lang.String)value);
+      }
+      break;
+
     }
   }
 
@@ -612,6 +698,12 @@ public java.lang.Object getFieldValue(_Fields field) {
     case SKIP_COLUMN_SCHEMA_FOR_PARTITION:
       return isSkipColumnSchemaForPartition();
 
+    case INCLUDE_PARAM_KEY_PATTERN:
+      return getIncludeParamKeyPattern();
+
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      return getExcludeParamKeyPattern();
+
     }
     throw new java.lang.IllegalStateException();
   }
@@ -643,6 +735,10 @@ public boolean isSet(_Fields field) {
       return isSetId();
     case SKIP_COLUMN_SCHEMA_FOR_PARTITION:
       return isSetSkipColumnSchemaForPartition();
+    case INCLUDE_PARAM_KEY_PATTERN:
+      return isSetIncludeParamKeyPattern();
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      return isSetExcludeParamKeyPattern();
     }
     throw new java.lang.IllegalStateException();
   }
@@ -750,6 +846,24 @@ public boolean equals(GetPartitionsPsWithAuthRequest that) {
         return false;
     }
 
+    boolean this_present_includeParamKeyPattern = true && this.isSetIncludeParamKeyPattern();
+    boolean that_present_includeParamKeyPattern = true && that.isSetIncludeParamKeyPattern();
+    if (this_present_includeParamKeyPattern || that_present_includeParamKeyPattern) {
+      if (!(this_present_includeParamKeyPattern && that_present_includeParamKeyPattern))
+        return false;
+      if (!this.includeParamKeyPattern.equals(that.includeParamKeyPattern))
+        return false;
+    }
+
+    boolean this_present_excludeParamKeyPattern = true && this.isSetExcludeParamKeyPattern();
+    boolean that_present_excludeParamKeyPattern = true && that.isSetExcludeParamKeyPattern();
+    if (this_present_excludeParamKeyPattern || that_present_excludeParamKeyPattern) {
+      if (!(this_present_excludeParamKeyPattern && that_present_excludeParamKeyPattern))
+        return false;
+      if (!this.excludeParamKeyPattern.equals(that.excludeParamKeyPattern))
+        return false;
+    }
+
     return true;
   }
 
@@ -797,6 +911,14 @@ public int hashCode() {
     if (isSetSkipColumnSchemaForPartition())
       hashCode = hashCode * 8191 + ((skipColumnSchemaForPartition) ? 131071 : 524287);
 
+    hashCode = hashCode * 8191 + ((isSetIncludeParamKeyPattern()) ? 131071 : 524287);
+    if (isSetIncludeParamKeyPattern())
+      hashCode = hashCode * 8191 + includeParamKeyPattern.hashCode();
+
+    hashCode = hashCode * 8191 + ((isSetExcludeParamKeyPattern()) ? 131071 : 524287);
+    if (isSetExcludeParamKeyPattern())
+      hashCode = hashCode * 8191 + excludeParamKeyPattern.hashCode();
+
     return hashCode;
   }
 
@@ -908,6 +1030,26 @@ public int compareTo(GetPartitionsPsWithAuthRequest other) {
         return lastComparison;
       }
     }
+    lastComparison = java.lang.Boolean.compare(isSetIncludeParamKeyPattern(), other.isSetIncludeParamKeyPattern());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetIncludeParamKeyPattern()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.includeParamKeyPattern, other.includeParamKeyPattern);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    lastComparison = java.lang.Boolean.compare(isSetExcludeParamKeyPattern(), other.isSetExcludeParamKeyPattern());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetExcludeParamKeyPattern()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.excludeParamKeyPattern, other.excludeParamKeyPattern);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
     return 0;
   }
 
@@ -1012,6 +1154,26 @@ public java.lang.String toString() {
       sb.append(this.skipColumnSchemaForPartition);
       first = false;
     }
+    if (isSetIncludeParamKeyPattern()) {
+      if (!first) sb.append(", ");
+      sb.append("includeParamKeyPattern:");
+      if (this.includeParamKeyPattern == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.includeParamKeyPattern);
+      }
+      first = false;
+    }
+    if (isSetExcludeParamKeyPattern()) {
+      if (!first) sb.append(", ");
+      sb.append("excludeParamKeyPattern:");
+      if (this.excludeParamKeyPattern == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.excludeParamKeyPattern);
+      }
+      first = false;
+    }
     sb.append(")");
     return sb.toString();
   }
@@ -1165,6 +1327,22 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, GetPartitionsPsWith
               org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
             }
             break;
+          case 11: // INCLUDE_PARAM_KEY_PATTERN
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
+              struct.includeParamKeyPattern = iprot.readString();
+              struct.setIncludeParamKeyPatternIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
+          case 12: // EXCLUDE_PARAM_KEY_PATTERN
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
+              struct.excludeParamKeyPattern = iprot.readString();
+              struct.setExcludeParamKeyPatternIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
           default:
             org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
         }
@@ -1252,6 +1430,20 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, GetPartitionsPsWit
         oprot.writeBool(struct.skipColumnSchemaForPartition);
         oprot.writeFieldEnd();
       }
+      if (struct.includeParamKeyPattern != null) {
+        if (struct.isSetIncludeParamKeyPattern()) {
+          oprot.writeFieldBegin(INCLUDE_PARAM_KEY_PATTERN_FIELD_DESC);
+          oprot.writeString(struct.includeParamKeyPattern);
+          oprot.writeFieldEnd();
+        }
+      }
+      if (struct.excludeParamKeyPattern != null) {
+        if (struct.isSetExcludeParamKeyPattern()) {
+          oprot.writeFieldBegin(EXCLUDE_PARAM_KEY_PATTERN_FIELD_DESC);
+          oprot.writeString(struct.excludeParamKeyPattern);
+          oprot.writeFieldEnd();
+        }
+      }
       oprot.writeFieldStop();
       oprot.writeStructEnd();
     }
@@ -1296,7 +1488,13 @@ public void write(org.apache.thrift.protocol.TProtocol prot, GetPartitionsPsWith
       if (struct.isSetSkipColumnSchemaForPartition()) {
         optionals.set(7);
       }
-      oprot.writeBitSet(optionals, 8);
+      if (struct.isSetIncludeParamKeyPattern()) {
+        optionals.set(8);
+      }
+      if (struct.isSetExcludeParamKeyPattern()) {
+        optionals.set(9);
+      }
+      oprot.writeBitSet(optionals, 10);
       if (struct.isSetCatName()) {
         oprot.writeString(struct.catName);
       }
@@ -1333,6 +1531,12 @@ public void write(org.apache.thrift.protocol.TProtocol prot, GetPartitionsPsWith
       if (struct.isSetSkipColumnSchemaForPartition()) {
         oprot.writeBool(struct.skipColumnSchemaForPartition);
       }
+      if (struct.isSetIncludeParamKeyPattern()) {
+        oprot.writeString(struct.includeParamKeyPattern);
+      }
+      if (struct.isSetExcludeParamKeyPattern()) {
+        oprot.writeString(struct.excludeParamKeyPattern);
+      }
     }
 
     @Override
@@ -1342,7 +1546,7 @@ public void read(org.apache.thrift.protocol.TProtocol prot, GetPartitionsPsWithA
       struct.setDbNameIsSet(true);
       struct.tblName = iprot.readString();
       struct.setTblNameIsSet(true);
-      java.util.BitSet incoming = iprot.readBitSet(8);
+      java.util.BitSet incoming = iprot.readBitSet(10);
       if (incoming.get(0)) {
         struct.catName = iprot.readString();
         struct.setCatNameIsSet(true);
@@ -1393,6 +1597,14 @@ public void read(org.apache.thrift.protocol.TProtocol prot, GetPartitionsPsWithA
         struct.skipColumnSchemaForPartition = iprot.readBool();
         struct.setSkipColumnSchemaForPartitionIsSet(true);
       }
+      if (incoming.get(8)) {
+        struct.includeParamKeyPattern = iprot.readString();
+        struct.setIncludeParamKeyPatternIsSet(true);
+      }
+      if (incoming.get(9)) {
+        struct.excludeParamKeyPattern = iprot.readString();
+        struct.setExcludeParamKeyPatternIsSet(true);
+      }
     }
   }
 
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/PartitionsByExprRequest.java b/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/PartitionsByExprRequest.java
index 70894d3639..7ae789bf46 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/PartitionsByExprRequest.java
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/PartitionsByExprRequest.java
@@ -21,6 +21,8 @@
   private static final org.apache.thrift.protocol.TField VALID_WRITE_ID_LIST_FIELD_DESC = new org.apache.thrift.protocol.TField("validWriteIdList", org.apache.thrift.protocol.TType.STRING, (short)8);
   private static final org.apache.thrift.protocol.TField ID_FIELD_DESC = new org.apache.thrift.protocol.TField("id", org.apache.thrift.protocol.TType.I64, (short)9);
   private static final org.apache.thrift.protocol.TField SKIP_COLUMN_SCHEMA_FOR_PARTITION_FIELD_DESC = new org.apache.thrift.protocol.TField("skipColumnSchemaForPartition", org.apache.thrift.protocol.TType.BOOL, (short)10);
+  private static final org.apache.thrift.protocol.TField INCLUDE_PARAM_KEY_PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField("includeParamKeyPattern", org.apache.thrift.protocol.TType.STRING, (short)11);
+  private static final org.apache.thrift.protocol.TField EXCLUDE_PARAM_KEY_PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField("excludeParamKeyPattern", org.apache.thrift.protocol.TType.STRING, (short)12);
 
   private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new PartitionsByExprRequestStandardSchemeFactory();
   private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new PartitionsByExprRequestTupleSchemeFactory();
@@ -35,6 +37,8 @@
   private @org.apache.thrift.annotation.Nullable java.lang.String validWriteIdList; // optional
   private long id; // optional
   private boolean skipColumnSchemaForPartition; // optional
+  private @org.apache.thrift.annotation.Nullable java.lang.String includeParamKeyPattern; // optional
+  private @org.apache.thrift.annotation.Nullable java.lang.String excludeParamKeyPattern; // optional
 
   /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
   public enum _Fields implements org.apache.thrift.TFieldIdEnum {
@@ -47,7 +51,9 @@ public enum _Fields implements org.apache.thrift.TFieldIdEnum {
     ORDER((short)7, "order"),
     VALID_WRITE_ID_LIST((short)8, "validWriteIdList"),
     ID((short)9, "id"),
-    SKIP_COLUMN_SCHEMA_FOR_PARTITION((short)10, "skipColumnSchemaForPartition");
+    SKIP_COLUMN_SCHEMA_FOR_PARTITION((short)10, "skipColumnSchemaForPartition"),
+    INCLUDE_PARAM_KEY_PATTERN((short)11, "includeParamKeyPattern"),
+    EXCLUDE_PARAM_KEY_PATTERN((short)12, "excludeParamKeyPattern");
 
     private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();
 
@@ -83,6 +89,10 @@ public static _Fields findByThriftId(int fieldId) {
           return ID;
         case 10: // SKIP_COLUMN_SCHEMA_FOR_PARTITION
           return SKIP_COLUMN_SCHEMA_FOR_PARTITION;
+        case 11: // INCLUDE_PARAM_KEY_PATTERN
+          return INCLUDE_PARAM_KEY_PATTERN;
+        case 12: // EXCLUDE_PARAM_KEY_PATTERN
+          return EXCLUDE_PARAM_KEY_PATTERN;
         default:
           return null;
       }
@@ -128,7 +138,7 @@ public java.lang.String getFieldName() {
   private static final int __ID_ISSET_ID = 1;
   private static final int __SKIPCOLUMNSCHEMAFORPARTITION_ISSET_ID = 2;
   private byte __isset_bitfield = 0;
-  private static final _Fields optionals[] = {_Fields.DEFAULT_PARTITION_NAME,_Fields.MAX_PARTS,_Fields.CAT_NAME,_Fields.ORDER,_Fields.VALID_WRITE_ID_LIST,_Fields.ID,_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION};
+  private static final _Fields optionals[] = {_Fields.DEFAULT_PARTITION_NAME,_Fields.MAX_PARTS,_Fields.CAT_NAME,_Fields.ORDER,_Fields.VALID_WRITE_ID_LIST,_Fields.ID,_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION,_Fields.INCLUDE_PARAM_KEY_PATTERN,_Fields.EXCLUDE_PARAM_KEY_PATTERN};
   public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
   static {
     java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
@@ -152,6 +162,10 @@ public java.lang.String getFieldName() {
         new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I64)));
     tmpMap.put(_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION, new org.apache.thrift.meta_data.FieldMetaData("skipColumnSchemaForPartition", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
         new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.BOOL)));
+    tmpMap.put(_Fields.INCLUDE_PARAM_KEY_PATTERN, new org.apache.thrift.meta_data.FieldMetaData("includeParamKeyPattern", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
+    tmpMap.put(_Fields.EXCLUDE_PARAM_KEY_PATTERN, new org.apache.thrift.meta_data.FieldMetaData("excludeParamKeyPattern", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
     metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
     org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(PartitionsByExprRequest.class, metaDataMap);
   }
@@ -203,6 +217,12 @@ public PartitionsByExprRequest(PartitionsByExprRequest other) {
     }
     this.id = other.id;
     this.skipColumnSchemaForPartition = other.skipColumnSchemaForPartition;
+    if (other.isSetIncludeParamKeyPattern()) {
+      this.includeParamKeyPattern = other.includeParamKeyPattern;
+    }
+    if (other.isSetExcludeParamKeyPattern()) {
+      this.excludeParamKeyPattern = other.excludeParamKeyPattern;
+    }
   }
 
   public PartitionsByExprRequest deepCopy() {
@@ -224,6 +244,8 @@ public void clear() {
 
     setSkipColumnSchemaForPartitionIsSet(false);
     this.skipColumnSchemaForPartition = false;
+    this.includeParamKeyPattern = null;
+    this.excludeParamKeyPattern = null;
   }
 
   @org.apache.thrift.annotation.Nullable
@@ -468,6 +490,54 @@ public void setSkipColumnSchemaForPartitionIsSet(boolean value) {
     __isset_bitfield = org.apache.thrift.EncodingUtils.setBit(__isset_bitfield, __SKIPCOLUMNSCHEMAFORPARTITION_ISSET_ID, value);
   }
 
+  @org.apache.thrift.annotation.Nullable
+  public java.lang.String getIncludeParamKeyPattern() {
+    return this.includeParamKeyPattern;
+  }
+
+  public void setIncludeParamKeyPattern(@org.apache.thrift.annotation.Nullable java.lang.String includeParamKeyPattern) {
+    this.includeParamKeyPattern = includeParamKeyPattern;
+  }
+
+  public void unsetIncludeParamKeyPattern() {
+    this.includeParamKeyPattern = null;
+  }
+
+  /** Returns true if field includeParamKeyPattern is set (has been assigned a value) and false otherwise */
+  public boolean isSetIncludeParamKeyPattern() {
+    return this.includeParamKeyPattern != null;
+  }
+
+  public void setIncludeParamKeyPatternIsSet(boolean value) {
+    if (!value) {
+      this.includeParamKeyPattern = null;
+    }
+  }
+
+  @org.apache.thrift.annotation.Nullable
+  public java.lang.String getExcludeParamKeyPattern() {
+    return this.excludeParamKeyPattern;
+  }
+
+  public void setExcludeParamKeyPattern(@org.apache.thrift.annotation.Nullable java.lang.String excludeParamKeyPattern) {
+    this.excludeParamKeyPattern = excludeParamKeyPattern;
+  }
+
+  public void unsetExcludeParamKeyPattern() {
+    this.excludeParamKeyPattern = null;
+  }
+
+  /** Returns true if field excludeParamKeyPattern is set (has been assigned a value) and false otherwise */
+  public boolean isSetExcludeParamKeyPattern() {
+    return this.excludeParamKeyPattern != null;
+  }
+
+  public void setExcludeParamKeyPatternIsSet(boolean value) {
+    if (!value) {
+      this.excludeParamKeyPattern = null;
+    }
+  }
+
   public void setFieldValue(_Fields field, @org.apache.thrift.annotation.Nullable java.lang.Object value) {
     switch (field) {
     case DB_NAME:
@@ -554,6 +624,22 @@ public void setFieldValue(_Fields field, @org.apache.thrift.annotation.Nullable
       }
       break;
 
+    case INCLUDE_PARAM_KEY_PATTERN:
+      if (value == null) {
+        unsetIncludeParamKeyPattern();
+      } else {
+        setIncludeParamKeyPattern((java.lang.String)value);
+      }
+      break;
+
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      if (value == null) {
+        unsetExcludeParamKeyPattern();
+      } else {
+        setExcludeParamKeyPattern((java.lang.String)value);
+      }
+      break;
+
     }
   }
 
@@ -590,6 +676,12 @@ public java.lang.Object getFieldValue(_Fields field) {
     case SKIP_COLUMN_SCHEMA_FOR_PARTITION:
       return isSkipColumnSchemaForPartition();
 
+    case INCLUDE_PARAM_KEY_PATTERN:
+      return getIncludeParamKeyPattern();
+
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      return getExcludeParamKeyPattern();
+
     }
     throw new java.lang.IllegalStateException();
   }
@@ -621,6 +713,10 @@ public boolean isSet(_Fields field) {
       return isSetId();
     case SKIP_COLUMN_SCHEMA_FOR_PARTITION:
       return isSetSkipColumnSchemaForPartition();
+    case INCLUDE_PARAM_KEY_PATTERN:
+      return isSetIncludeParamKeyPattern();
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      return isSetExcludeParamKeyPattern();
     }
     throw new java.lang.IllegalStateException();
   }
@@ -728,6 +824,24 @@ public boolean equals(PartitionsByExprRequest that) {
         return false;
     }
 
+    boolean this_present_includeParamKeyPattern = true && this.isSetIncludeParamKeyPattern();
+    boolean that_present_includeParamKeyPattern = true && that.isSetIncludeParamKeyPattern();
+    if (this_present_includeParamKeyPattern || that_present_includeParamKeyPattern) {
+      if (!(this_present_includeParamKeyPattern && that_present_includeParamKeyPattern))
+        return false;
+      if (!this.includeParamKeyPattern.equals(that.includeParamKeyPattern))
+        return false;
+    }
+
+    boolean this_present_excludeParamKeyPattern = true && this.isSetExcludeParamKeyPattern();
+    boolean that_present_excludeParamKeyPattern = true && that.isSetExcludeParamKeyPattern();
+    if (this_present_excludeParamKeyPattern || that_present_excludeParamKeyPattern) {
+      if (!(this_present_excludeParamKeyPattern && that_present_excludeParamKeyPattern))
+        return false;
+      if (!this.excludeParamKeyPattern.equals(that.excludeParamKeyPattern))
+        return false;
+    }
+
     return true;
   }
 
@@ -775,6 +889,14 @@ public int hashCode() {
     if (isSetSkipColumnSchemaForPartition())
       hashCode = hashCode * 8191 + ((skipColumnSchemaForPartition) ? 131071 : 524287);
 
+    hashCode = hashCode * 8191 + ((isSetIncludeParamKeyPattern()) ? 131071 : 524287);
+    if (isSetIncludeParamKeyPattern())
+      hashCode = hashCode * 8191 + includeParamKeyPattern.hashCode();
+
+    hashCode = hashCode * 8191 + ((isSetExcludeParamKeyPattern()) ? 131071 : 524287);
+    if (isSetExcludeParamKeyPattern())
+      hashCode = hashCode * 8191 + excludeParamKeyPattern.hashCode();
+
     return hashCode;
   }
 
@@ -886,6 +1008,26 @@ public int compareTo(PartitionsByExprRequest other) {
         return lastComparison;
       }
     }
+    lastComparison = java.lang.Boolean.compare(isSetIncludeParamKeyPattern(), other.isSetIncludeParamKeyPattern());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetIncludeParamKeyPattern()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.includeParamKeyPattern, other.includeParamKeyPattern);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    lastComparison = java.lang.Boolean.compare(isSetExcludeParamKeyPattern(), other.isSetExcludeParamKeyPattern());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetExcludeParamKeyPattern()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.excludeParamKeyPattern, other.excludeParamKeyPattern);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
     return 0;
   }
 
@@ -988,6 +1130,26 @@ public java.lang.String toString() {
       sb.append(this.skipColumnSchemaForPartition);
       first = false;
     }
+    if (isSetIncludeParamKeyPattern()) {
+      if (!first) sb.append(", ");
+      sb.append("includeParamKeyPattern:");
+      if (this.includeParamKeyPattern == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.includeParamKeyPattern);
+      }
+      first = false;
+    }
+    if (isSetExcludeParamKeyPattern()) {
+      if (!first) sb.append(", ");
+      sb.append("excludeParamKeyPattern:");
+      if (this.excludeParamKeyPattern == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.excludeParamKeyPattern);
+      }
+      first = false;
+    }
     sb.append(")");
     return sb.toString();
   }
@@ -1125,6 +1287,22 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, PartitionsByExprReq
               org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
             }
             break;
+          case 11: // INCLUDE_PARAM_KEY_PATTERN
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
+              struct.includeParamKeyPattern = iprot.readString();
+              struct.setIncludeParamKeyPatternIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
+          case 12: // EXCLUDE_PARAM_KEY_PATTERN
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
+              struct.excludeParamKeyPattern = iprot.readString();
+              struct.setExcludeParamKeyPatternIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
           default:
             org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
         }
@@ -1196,6 +1374,20 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, PartitionsByExprRe
         oprot.writeBool(struct.skipColumnSchemaForPartition);
         oprot.writeFieldEnd();
       }
+      if (struct.includeParamKeyPattern != null) {
+        if (struct.isSetIncludeParamKeyPattern()) {
+          oprot.writeFieldBegin(INCLUDE_PARAM_KEY_PATTERN_FIELD_DESC);
+          oprot.writeString(struct.includeParamKeyPattern);
+          oprot.writeFieldEnd();
+        }
+      }
+      if (struct.excludeParamKeyPattern != null) {
+        if (struct.isSetExcludeParamKeyPattern()) {
+          oprot.writeFieldBegin(EXCLUDE_PARAM_KEY_PATTERN_FIELD_DESC);
+          oprot.writeString(struct.excludeParamKeyPattern);
+          oprot.writeFieldEnd();
+        }
+      }
       oprot.writeFieldStop();
       oprot.writeStructEnd();
     }
@@ -1238,7 +1430,13 @@ public void write(org.apache.thrift.protocol.TProtocol prot, PartitionsByExprReq
       if (struct.isSetSkipColumnSchemaForPartition()) {
         optionals.set(6);
       }
-      oprot.writeBitSet(optionals, 7);
+      if (struct.isSetIncludeParamKeyPattern()) {
+        optionals.set(7);
+      }
+      if (struct.isSetExcludeParamKeyPattern()) {
+        optionals.set(8);
+      }
+      oprot.writeBitSet(optionals, 9);
       if (struct.isSetDefaultPartitionName()) {
         oprot.writeString(struct.defaultPartitionName);
       }
@@ -1260,6 +1458,12 @@ public void write(org.apache.thrift.protocol.TProtocol prot, PartitionsByExprReq
       if (struct.isSetSkipColumnSchemaForPartition()) {
         oprot.writeBool(struct.skipColumnSchemaForPartition);
       }
+      if (struct.isSetIncludeParamKeyPattern()) {
+        oprot.writeString(struct.includeParamKeyPattern);
+      }
+      if (struct.isSetExcludeParamKeyPattern()) {
+        oprot.writeString(struct.excludeParamKeyPattern);
+      }
     }
 
     @Override
@@ -1271,7 +1475,7 @@ public void read(org.apache.thrift.protocol.TProtocol prot, PartitionsByExprRequ
       struct.setTblNameIsSet(true);
       struct.expr = iprot.readBinary();
       struct.setExprIsSet(true);
-      java.util.BitSet incoming = iprot.readBitSet(7);
+      java.util.BitSet incoming = iprot.readBitSet(9);
       if (incoming.get(0)) {
         struct.defaultPartitionName = iprot.readString();
         struct.setDefaultPartitionNameIsSet(true);
@@ -1300,6 +1504,14 @@ public void read(org.apache.thrift.protocol.TProtocol prot, PartitionsByExprRequ
         struct.skipColumnSchemaForPartition = iprot.readBool();
         struct.setSkipColumnSchemaForPartitionIsSet(true);
       }
+      if (incoming.get(7)) {
+        struct.includeParamKeyPattern = iprot.readString();
+        struct.setIncludeParamKeyPatternIsSet(true);
+      }
+      if (incoming.get(8)) {
+        struct.excludeParamKeyPattern = iprot.readString();
+        struct.setExcludeParamKeyPatternIsSet(true);
+      }
     }
   }
 
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/PartitionsRequest.java b/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/PartitionsRequest.java
index 52e2ec0d01..69c241ccad 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/PartitionsRequest.java
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/PartitionsRequest.java
@@ -18,6 +18,8 @@
   private static final org.apache.thrift.protocol.TField VALID_WRITE_ID_LIST_FIELD_DESC = new org.apache.thrift.protocol.TField("validWriteIdList", org.apache.thrift.protocol.TType.STRING, (short)5);
   private static final org.apache.thrift.protocol.TField ID_FIELD_DESC = new org.apache.thrift.protocol.TField("id", org.apache.thrift.protocol.TType.I64, (short)6);
   private static final org.apache.thrift.protocol.TField SKIP_COLUMN_SCHEMA_FOR_PARTITION_FIELD_DESC = new org.apache.thrift.protocol.TField("skipColumnSchemaForPartition", org.apache.thrift.protocol.TType.BOOL, (short)7);
+  private static final org.apache.thrift.protocol.TField INCLUDE_PARAM_KEY_PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField("includeParamKeyPattern", org.apache.thrift.protocol.TType.STRING, (short)8);
+  private static final org.apache.thrift.protocol.TField EXCLUDE_PARAM_KEY_PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField("excludeParamKeyPattern", org.apache.thrift.protocol.TType.STRING, (short)9);
 
   private static final org.apache.thrift.scheme.SchemeFactory STANDARD_SCHEME_FACTORY = new PartitionsRequestStandardSchemeFactory();
   private static final org.apache.thrift.scheme.SchemeFactory TUPLE_SCHEME_FACTORY = new PartitionsRequestTupleSchemeFactory();
@@ -29,6 +31,8 @@
   private @org.apache.thrift.annotation.Nullable java.lang.String validWriteIdList; // optional
   private long id; // optional
   private boolean skipColumnSchemaForPartition; // optional
+  private @org.apache.thrift.annotation.Nullable java.lang.String includeParamKeyPattern; // optional
+  private @org.apache.thrift.annotation.Nullable java.lang.String excludeParamKeyPattern; // optional
 
   /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
   public enum _Fields implements org.apache.thrift.TFieldIdEnum {
@@ -38,7 +42,9 @@ public enum _Fields implements org.apache.thrift.TFieldIdEnum {
     MAX_PARTS((short)4, "maxParts"),
     VALID_WRITE_ID_LIST((short)5, "validWriteIdList"),
     ID((short)6, "id"),
-    SKIP_COLUMN_SCHEMA_FOR_PARTITION((short)7, "skipColumnSchemaForPartition");
+    SKIP_COLUMN_SCHEMA_FOR_PARTITION((short)7, "skipColumnSchemaForPartition"),
+    INCLUDE_PARAM_KEY_PATTERN((short)8, "includeParamKeyPattern"),
+    EXCLUDE_PARAM_KEY_PATTERN((short)9, "excludeParamKeyPattern");
 
     private static final java.util.Map<java.lang.String, _Fields> byName = new java.util.HashMap<java.lang.String, _Fields>();
 
@@ -68,6 +74,10 @@ public static _Fields findByThriftId(int fieldId) {
           return ID;
         case 7: // SKIP_COLUMN_SCHEMA_FOR_PARTITION
           return SKIP_COLUMN_SCHEMA_FOR_PARTITION;
+        case 8: // INCLUDE_PARAM_KEY_PATTERN
+          return INCLUDE_PARAM_KEY_PATTERN;
+        case 9: // EXCLUDE_PARAM_KEY_PATTERN
+          return EXCLUDE_PARAM_KEY_PATTERN;
         default:
           return null;
       }
@@ -113,7 +123,7 @@ public java.lang.String getFieldName() {
   private static final int __ID_ISSET_ID = 1;
   private static final int __SKIPCOLUMNSCHEMAFORPARTITION_ISSET_ID = 2;
   private byte __isset_bitfield = 0;
-  private static final _Fields optionals[] = {_Fields.CAT_NAME,_Fields.MAX_PARTS,_Fields.VALID_WRITE_ID_LIST,_Fields.ID,_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION};
+  private static final _Fields optionals[] = {_Fields.CAT_NAME,_Fields.MAX_PARTS,_Fields.VALID_WRITE_ID_LIST,_Fields.ID,_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION,_Fields.INCLUDE_PARAM_KEY_PATTERN,_Fields.EXCLUDE_PARAM_KEY_PATTERN};
   public static final java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
   static {
     java.util.Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new java.util.EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
@@ -131,6 +141,10 @@ public java.lang.String getFieldName() {
         new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I64)));
     tmpMap.put(_Fields.SKIP_COLUMN_SCHEMA_FOR_PARTITION, new org.apache.thrift.meta_data.FieldMetaData("skipColumnSchemaForPartition", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
         new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.BOOL)));
+    tmpMap.put(_Fields.INCLUDE_PARAM_KEY_PATTERN, new org.apache.thrift.meta_data.FieldMetaData("includeParamKeyPattern", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
+    tmpMap.put(_Fields.EXCLUDE_PARAM_KEY_PATTERN, new org.apache.thrift.meta_data.FieldMetaData("excludeParamKeyPattern", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
     metaDataMap = java.util.Collections.unmodifiableMap(tmpMap);
     org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(PartitionsRequest.class, metaDataMap);
   }
@@ -171,6 +185,12 @@ public PartitionsRequest(PartitionsRequest other) {
     }
     this.id = other.id;
     this.skipColumnSchemaForPartition = other.skipColumnSchemaForPartition;
+    if (other.isSetIncludeParamKeyPattern()) {
+      this.includeParamKeyPattern = other.includeParamKeyPattern;
+    }
+    if (other.isSetExcludeParamKeyPattern()) {
+      this.excludeParamKeyPattern = other.excludeParamKeyPattern;
+    }
   }
 
   public PartitionsRequest deepCopy() {
@@ -189,6 +209,8 @@ public void clear() {
 
     setSkipColumnSchemaForPartitionIsSet(false);
     this.skipColumnSchemaForPartition = false;
+    this.includeParamKeyPattern = null;
+    this.excludeParamKeyPattern = null;
   }
 
   @org.apache.thrift.annotation.Nullable
@@ -353,6 +375,54 @@ public void setSkipColumnSchemaForPartitionIsSet(boolean value) {
     __isset_bitfield = org.apache.thrift.EncodingUtils.setBit(__isset_bitfield, __SKIPCOLUMNSCHEMAFORPARTITION_ISSET_ID, value);
   }
 
+  @org.apache.thrift.annotation.Nullable
+  public java.lang.String getIncludeParamKeyPattern() {
+    return this.includeParamKeyPattern;
+  }
+
+  public void setIncludeParamKeyPattern(@org.apache.thrift.annotation.Nullable java.lang.String includeParamKeyPattern) {
+    this.includeParamKeyPattern = includeParamKeyPattern;
+  }
+
+  public void unsetIncludeParamKeyPattern() {
+    this.includeParamKeyPattern = null;
+  }
+
+  /** Returns true if field includeParamKeyPattern is set (has been assigned a value) and false otherwise */
+  public boolean isSetIncludeParamKeyPattern() {
+    return this.includeParamKeyPattern != null;
+  }
+
+  public void setIncludeParamKeyPatternIsSet(boolean value) {
+    if (!value) {
+      this.includeParamKeyPattern = null;
+    }
+  }
+
+  @org.apache.thrift.annotation.Nullable
+  public java.lang.String getExcludeParamKeyPattern() {
+    return this.excludeParamKeyPattern;
+  }
+
+  public void setExcludeParamKeyPattern(@org.apache.thrift.annotation.Nullable java.lang.String excludeParamKeyPattern) {
+    this.excludeParamKeyPattern = excludeParamKeyPattern;
+  }
+
+  public void unsetExcludeParamKeyPattern() {
+    this.excludeParamKeyPattern = null;
+  }
+
+  /** Returns true if field excludeParamKeyPattern is set (has been assigned a value) and false otherwise */
+  public boolean isSetExcludeParamKeyPattern() {
+    return this.excludeParamKeyPattern != null;
+  }
+
+  public void setExcludeParamKeyPatternIsSet(boolean value) {
+    if (!value) {
+      this.excludeParamKeyPattern = null;
+    }
+  }
+
   public void setFieldValue(_Fields field, @org.apache.thrift.annotation.Nullable java.lang.Object value) {
     switch (field) {
     case CAT_NAME:
@@ -411,6 +481,22 @@ public void setFieldValue(_Fields field, @org.apache.thrift.annotation.Nullable
       }
       break;
 
+    case INCLUDE_PARAM_KEY_PATTERN:
+      if (value == null) {
+        unsetIncludeParamKeyPattern();
+      } else {
+        setIncludeParamKeyPattern((java.lang.String)value);
+      }
+      break;
+
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      if (value == null) {
+        unsetExcludeParamKeyPattern();
+      } else {
+        setExcludeParamKeyPattern((java.lang.String)value);
+      }
+      break;
+
     }
   }
 
@@ -438,6 +524,12 @@ public java.lang.Object getFieldValue(_Fields field) {
     case SKIP_COLUMN_SCHEMA_FOR_PARTITION:
       return isSkipColumnSchemaForPartition();
 
+    case INCLUDE_PARAM_KEY_PATTERN:
+      return getIncludeParamKeyPattern();
+
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      return getExcludeParamKeyPattern();
+
     }
     throw new java.lang.IllegalStateException();
   }
@@ -463,6 +555,10 @@ public boolean isSet(_Fields field) {
       return isSetId();
     case SKIP_COLUMN_SCHEMA_FOR_PARTITION:
       return isSetSkipColumnSchemaForPartition();
+    case INCLUDE_PARAM_KEY_PATTERN:
+      return isSetIncludeParamKeyPattern();
+    case EXCLUDE_PARAM_KEY_PATTERN:
+      return isSetExcludeParamKeyPattern();
     }
     throw new java.lang.IllegalStateException();
   }
@@ -543,6 +639,24 @@ public boolean equals(PartitionsRequest that) {
         return false;
     }
 
+    boolean this_present_includeParamKeyPattern = true && this.isSetIncludeParamKeyPattern();
+    boolean that_present_includeParamKeyPattern = true && that.isSetIncludeParamKeyPattern();
+    if (this_present_includeParamKeyPattern || that_present_includeParamKeyPattern) {
+      if (!(this_present_includeParamKeyPattern && that_present_includeParamKeyPattern))
+        return false;
+      if (!this.includeParamKeyPattern.equals(that.includeParamKeyPattern))
+        return false;
+    }
+
+    boolean this_present_excludeParamKeyPattern = true && this.isSetExcludeParamKeyPattern();
+    boolean that_present_excludeParamKeyPattern = true && that.isSetExcludeParamKeyPattern();
+    if (this_present_excludeParamKeyPattern || that_present_excludeParamKeyPattern) {
+      if (!(this_present_excludeParamKeyPattern && that_present_excludeParamKeyPattern))
+        return false;
+      if (!this.excludeParamKeyPattern.equals(that.excludeParamKeyPattern))
+        return false;
+    }
+
     return true;
   }
 
@@ -578,6 +692,14 @@ public int hashCode() {
     if (isSetSkipColumnSchemaForPartition())
       hashCode = hashCode * 8191 + ((skipColumnSchemaForPartition) ? 131071 : 524287);
 
+    hashCode = hashCode * 8191 + ((isSetIncludeParamKeyPattern()) ? 131071 : 524287);
+    if (isSetIncludeParamKeyPattern())
+      hashCode = hashCode * 8191 + includeParamKeyPattern.hashCode();
+
+    hashCode = hashCode * 8191 + ((isSetExcludeParamKeyPattern()) ? 131071 : 524287);
+    if (isSetExcludeParamKeyPattern())
+      hashCode = hashCode * 8191 + excludeParamKeyPattern.hashCode();
+
     return hashCode;
   }
 
@@ -659,6 +781,26 @@ public int compareTo(PartitionsRequest other) {
         return lastComparison;
       }
     }
+    lastComparison = java.lang.Boolean.compare(isSetIncludeParamKeyPattern(), other.isSetIncludeParamKeyPattern());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetIncludeParamKeyPattern()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.includeParamKeyPattern, other.includeParamKeyPattern);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    lastComparison = java.lang.Boolean.compare(isSetExcludeParamKeyPattern(), other.isSetExcludeParamKeyPattern());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetExcludeParamKeyPattern()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.excludeParamKeyPattern, other.excludeParamKeyPattern);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
     return 0;
   }
 
@@ -733,6 +875,26 @@ public java.lang.String toString() {
       sb.append(this.skipColumnSchemaForPartition);
       first = false;
     }
+    if (isSetIncludeParamKeyPattern()) {
+      if (!first) sb.append(", ");
+      sb.append("includeParamKeyPattern:");
+      if (this.includeParamKeyPattern == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.includeParamKeyPattern);
+      }
+      first = false;
+    }
+    if (isSetExcludeParamKeyPattern()) {
+      if (!first) sb.append(", ");
+      sb.append("excludeParamKeyPattern:");
+      if (this.excludeParamKeyPattern == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.excludeParamKeyPattern);
+      }
+      first = false;
+    }
     sb.append(")");
     return sb.toString();
   }
@@ -842,6 +1004,22 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, PartitionsRequest s
               org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
             }
             break;
+          case 8: // INCLUDE_PARAM_KEY_PATTERN
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
+              struct.includeParamKeyPattern = iprot.readString();
+              struct.setIncludeParamKeyPatternIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
+          case 9: // EXCLUDE_PARAM_KEY_PATTERN
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
+              struct.excludeParamKeyPattern = iprot.readString();
+              struct.setExcludeParamKeyPatternIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
           default:
             org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
         }
@@ -894,6 +1072,20 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, PartitionsRequest
         oprot.writeBool(struct.skipColumnSchemaForPartition);
         oprot.writeFieldEnd();
       }
+      if (struct.includeParamKeyPattern != null) {
+        if (struct.isSetIncludeParamKeyPattern()) {
+          oprot.writeFieldBegin(INCLUDE_PARAM_KEY_PATTERN_FIELD_DESC);
+          oprot.writeString(struct.includeParamKeyPattern);
+          oprot.writeFieldEnd();
+        }
+      }
+      if (struct.excludeParamKeyPattern != null) {
+        if (struct.isSetExcludeParamKeyPattern()) {
+          oprot.writeFieldBegin(EXCLUDE_PARAM_KEY_PATTERN_FIELD_DESC);
+          oprot.writeString(struct.excludeParamKeyPattern);
+          oprot.writeFieldEnd();
+        }
+      }
       oprot.writeFieldStop();
       oprot.writeStructEnd();
     }
@@ -929,7 +1121,13 @@ public void write(org.apache.thrift.protocol.TProtocol prot, PartitionsRequest s
       if (struct.isSetSkipColumnSchemaForPartition()) {
         optionals.set(4);
       }
-      oprot.writeBitSet(optionals, 5);
+      if (struct.isSetIncludeParamKeyPattern()) {
+        optionals.set(5);
+      }
+      if (struct.isSetExcludeParamKeyPattern()) {
+        optionals.set(6);
+      }
+      oprot.writeBitSet(optionals, 7);
       if (struct.isSetCatName()) {
         oprot.writeString(struct.catName);
       }
@@ -945,6 +1143,12 @@ public void write(org.apache.thrift.protocol.TProtocol prot, PartitionsRequest s
       if (struct.isSetSkipColumnSchemaForPartition()) {
         oprot.writeBool(struct.skipColumnSchemaForPartition);
       }
+      if (struct.isSetIncludeParamKeyPattern()) {
+        oprot.writeString(struct.includeParamKeyPattern);
+      }
+      if (struct.isSetExcludeParamKeyPattern()) {
+        oprot.writeString(struct.excludeParamKeyPattern);
+      }
     }
 
     @Override
@@ -954,7 +1158,7 @@ public void read(org.apache.thrift.protocol.TProtocol prot, PartitionsRequest st
       struct.setDbNameIsSet(true);
       struct.tblName = iprot.readString();
       struct.setTblNameIsSet(true);
-      java.util.BitSet incoming = iprot.readBitSet(5);
+      java.util.BitSet incoming = iprot.readBitSet(7);
       if (incoming.get(0)) {
         struct.catName = iprot.readString();
         struct.setCatNameIsSet(true);
@@ -975,6 +1179,14 @@ public void read(org.apache.thrift.protocol.TProtocol prot, PartitionsRequest st
         struct.skipColumnSchemaForPartition = iprot.readBool();
         struct.setSkipColumnSchemaForPartitionIsSet(true);
       }
+      if (incoming.get(5)) {
+        struct.includeParamKeyPattern = iprot.readString();
+        struct.setIncludeParamKeyPatternIsSet(true);
+      }
+      if (incoming.get(6)) {
+        struct.excludeParamKeyPattern = iprot.readString();
+        struct.setExcludeParamKeyPatternIsSet(true);
+      }
     }
   }
 
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsByFilterRequest.php b/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsByFilterRequest.php
index 549e4c908d..348ae509ff 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsByFilterRequest.php
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsByFilterRequest.php
@@ -51,6 +51,16 @@ class GetPartitionsByFilterRequest
             'isRequired' => false,
             'type' => TType::BOOL,
         ),
+        7 => array(
+            'var' => 'includeParamKeyPattern',
+            'isRequired' => false,
+            'type' => TType::STRING,
+        ),
+        8 => array(
+            'var' => 'excludeParamKeyPattern',
+            'isRequired' => false,
+            'type' => TType::STRING,
+        ),
     );
 
     /**
@@ -77,6 +87,14 @@ class GetPartitionsByFilterRequest
      * @var bool
      */
     public $skipColumnSchemaForPartition = null;
+    /**
+     * @var string
+     */
+    public $includeParamKeyPattern = null;
+    /**
+     * @var string
+     */
+    public $excludeParamKeyPattern = null;
 
     public function __construct($vals = null)
     {
@@ -99,6 +117,12 @@ class GetPartitionsByFilterRequest
             if (isset($vals['skipColumnSchemaForPartition'])) {
                 $this->skipColumnSchemaForPartition = $vals['skipColumnSchemaForPartition'];
             }
+            if (isset($vals['includeParamKeyPattern'])) {
+                $this->includeParamKeyPattern = $vals['includeParamKeyPattern'];
+            }
+            if (isset($vals['excludeParamKeyPattern'])) {
+                $this->excludeParamKeyPattern = $vals['excludeParamKeyPattern'];
+            }
         }
     }
 
@@ -163,6 +187,20 @@ class GetPartitionsByFilterRequest
                         $xfer += $input->skip($ftype);
                     }
                     break;
+                case 7:
+                    if ($ftype == TType::STRING) {
+                        $xfer += $input->readString($this->includeParamKeyPattern);
+                    } else {
+                        $xfer += $input->skip($ftype);
+                    }
+                    break;
+                case 8:
+                    if ($ftype == TType::STRING) {
+                        $xfer += $input->readString($this->excludeParamKeyPattern);
+                    } else {
+                        $xfer += $input->skip($ftype);
+                    }
+                    break;
                 default:
                     $xfer += $input->skip($ftype);
                     break;
@@ -207,6 +245,16 @@ class GetPartitionsByFilterRequest
             $xfer += $output->writeBool($this->skipColumnSchemaForPartition);
             $xfer += $output->writeFieldEnd();
         }
+        if ($this->includeParamKeyPattern !== null) {
+            $xfer += $output->writeFieldBegin('includeParamKeyPattern', TType::STRING, 7);
+            $xfer += $output->writeString($this->includeParamKeyPattern);
+            $xfer += $output->writeFieldEnd();
+        }
+        if ($this->excludeParamKeyPattern !== null) {
+            $xfer += $output->writeFieldBegin('excludeParamKeyPattern', TType::STRING, 8);
+            $xfer += $output->writeString($this->excludeParamKeyPattern);
+            $xfer += $output->writeFieldEnd();
+        }
         $xfer += $output->writeFieldStop();
         $xfer += $output->writeStructEnd();
         return $xfer;
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsByNamesRequest.php b/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsByNamesRequest.php
index d0b4aa7152..c06aa5ac27 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsByNamesRequest.php
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsByNamesRequest.php
@@ -84,6 +84,16 @@ class GetPartitionsByNamesRequest
             'isRequired' => false,
             'type' => TType::BOOL,
         ),
+        12 => array(
+            'var' => 'includeParamKeyPattern',
+            'isRequired' => false,
+            'type' => TType::STRING,
+        ),
+        13 => array(
+            'var' => 'excludeParamKeyPattern',
+            'isRequired' => false,
+            'type' => TType::STRING,
+        ),
     );
 
     /**
@@ -130,6 +140,14 @@ class GetPartitionsByNamesRequest
      * @var bool
      */
     public $skipColumnSchemaForPartition = null;
+    /**
+     * @var string
+     */
+    public $includeParamKeyPattern = null;
+    /**
+     * @var string
+     */
+    public $excludeParamKeyPattern = null;
 
     public function __construct($vals = null)
     {
@@ -167,6 +185,12 @@ class GetPartitionsByNamesRequest
             if (isset($vals['skipColumnSchemaForPartition'])) {
                 $this->skipColumnSchemaForPartition = $vals['skipColumnSchemaForPartition'];
             }
+            if (isset($vals['includeParamKeyPattern'])) {
+                $this->includeParamKeyPattern = $vals['includeParamKeyPattern'];
+            }
+            if (isset($vals['excludeParamKeyPattern'])) {
+                $this->excludeParamKeyPattern = $vals['excludeParamKeyPattern'];
+            }
         }
     }
 
@@ -284,6 +308,20 @@ class GetPartitionsByNamesRequest
                         $xfer += $input->skip($ftype);
                     }
                     break;
+                case 12:
+                    if ($ftype == TType::STRING) {
+                        $xfer += $input->readString($this->includeParamKeyPattern);
+                    } else {
+                        $xfer += $input->skip($ftype);
+                    }
+                    break;
+                case 13:
+                    if ($ftype == TType::STRING) {
+                        $xfer += $input->readString($this->excludeParamKeyPattern);
+                    } else {
+                        $xfer += $input->skip($ftype);
+                    }
+                    break;
                 default:
                     $xfer += $input->skip($ftype);
                     break;
@@ -367,6 +405,16 @@ class GetPartitionsByNamesRequest
             $xfer += $output->writeBool($this->skipColumnSchemaForPartition);
             $xfer += $output->writeFieldEnd();
         }
+        if ($this->includeParamKeyPattern !== null) {
+            $xfer += $output->writeFieldBegin('includeParamKeyPattern', TType::STRING, 12);
+            $xfer += $output->writeString($this->includeParamKeyPattern);
+            $xfer += $output->writeFieldEnd();
+        }
+        if ($this->excludeParamKeyPattern !== null) {
+            $xfer += $output->writeFieldBegin('excludeParamKeyPattern', TType::STRING, 13);
+            $xfer += $output->writeString($this->excludeParamKeyPattern);
+            $xfer += $output->writeFieldEnd();
+        }
         $xfer += $output->writeFieldStop();
         $xfer += $output->writeStructEnd();
         return $xfer;
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsPsWithAuthRequest.php b/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsPsWithAuthRequest.php
index 0eecd2f5ad..19c6836862 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsPsWithAuthRequest.php
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/GetPartitionsPsWithAuthRequest.php
@@ -79,6 +79,16 @@ class GetPartitionsPsWithAuthRequest
             'isRequired' => false,
             'type' => TType::BOOL,
         ),
+        11 => array(
+            'var' => 'includeParamKeyPattern',
+            'isRequired' => false,
+            'type' => TType::STRING,
+        ),
+        12 => array(
+            'var' => 'excludeParamKeyPattern',
+            'isRequired' => false,
+            'type' => TType::STRING,
+        ),
     );
 
     /**
@@ -121,6 +131,14 @@ class GetPartitionsPsWithAuthRequest
      * @var bool
      */
     public $skipColumnSchemaForPartition = null;
+    /**
+     * @var string
+     */
+    public $includeParamKeyPattern = null;
+    /**
+     * @var string
+     */
+    public $excludeParamKeyPattern = null;
 
     public function __construct($vals = null)
     {
@@ -155,6 +173,12 @@ class GetPartitionsPsWithAuthRequest
             if (isset($vals['skipColumnSchemaForPartition'])) {
                 $this->skipColumnSchemaForPartition = $vals['skipColumnSchemaForPartition'];
             }
+            if (isset($vals['includeParamKeyPattern'])) {
+                $this->includeParamKeyPattern = $vals['includeParamKeyPattern'];
+            }
+            if (isset($vals['excludeParamKeyPattern'])) {
+                $this->excludeParamKeyPattern = $vals['excludeParamKeyPattern'];
+            }
         }
     }
 
@@ -265,6 +289,20 @@ class GetPartitionsPsWithAuthRequest
                         $xfer += $input->skip($ftype);
                     }
                     break;
+                case 11:
+                    if ($ftype == TType::STRING) {
+                        $xfer += $input->readString($this->includeParamKeyPattern);
+                    } else {
+                        $xfer += $input->skip($ftype);
+                    }
+                    break;
+                case 12:
+                    if ($ftype == TType::STRING) {
+                        $xfer += $input->readString($this->excludeParamKeyPattern);
+                    } else {
+                        $xfer += $input->skip($ftype);
+                    }
+                    break;
                 default:
                     $xfer += $input->skip($ftype);
                     break;
@@ -343,6 +381,16 @@ class GetPartitionsPsWithAuthRequest
             $xfer += $output->writeBool($this->skipColumnSchemaForPartition);
             $xfer += $output->writeFieldEnd();
         }
+        if ($this->includeParamKeyPattern !== null) {
+            $xfer += $output->writeFieldBegin('includeParamKeyPattern', TType::STRING, 11);
+            $xfer += $output->writeString($this->includeParamKeyPattern);
+            $xfer += $output->writeFieldEnd();
+        }
+        if ($this->excludeParamKeyPattern !== null) {
+            $xfer += $output->writeFieldBegin('excludeParamKeyPattern', TType::STRING, 12);
+            $xfer += $output->writeString($this->excludeParamKeyPattern);
+            $xfer += $output->writeFieldEnd();
+        }
         $xfer += $output->writeFieldStop();
         $xfer += $output->writeStructEnd();
         return $xfer;
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/PartitionsByExprRequest.php b/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/PartitionsByExprRequest.php
index 175fa5c3d5..23c31bfd8a 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/PartitionsByExprRequest.php
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/PartitionsByExprRequest.php
@@ -71,6 +71,16 @@ class PartitionsByExprRequest
             'isRequired' => false,
             'type' => TType::BOOL,
         ),
+        11 => array(
+            'var' => 'includeParamKeyPattern',
+            'isRequired' => false,
+            'type' => TType::STRING,
+        ),
+        12 => array(
+            'var' => 'excludeParamKeyPattern',
+            'isRequired' => false,
+            'type' => TType::STRING,
+        ),
     );
 
     /**
@@ -113,6 +123,14 @@ class PartitionsByExprRequest
      * @var bool
      */
     public $skipColumnSchemaForPartition = null;
+    /**
+     * @var string
+     */
+    public $includeParamKeyPattern = null;
+    /**
+     * @var string
+     */
+    public $excludeParamKeyPattern = null;
 
     public function __construct($vals = null)
     {
@@ -147,6 +165,12 @@ class PartitionsByExprRequest
             if (isset($vals['skipColumnSchemaForPartition'])) {
                 $this->skipColumnSchemaForPartition = $vals['skipColumnSchemaForPartition'];
             }
+            if (isset($vals['includeParamKeyPattern'])) {
+                $this->includeParamKeyPattern = $vals['includeParamKeyPattern'];
+            }
+            if (isset($vals['excludeParamKeyPattern'])) {
+                $this->excludeParamKeyPattern = $vals['excludeParamKeyPattern'];
+            }
         }
     }
 
@@ -239,6 +263,20 @@ class PartitionsByExprRequest
                         $xfer += $input->skip($ftype);
                     }
                     break;
+                case 11:
+                    if ($ftype == TType::STRING) {
+                        $xfer += $input->readString($this->includeParamKeyPattern);
+                    } else {
+                        $xfer += $input->skip($ftype);
+                    }
+                    break;
+                case 12:
+                    if ($ftype == TType::STRING) {
+                        $xfer += $input->readString($this->excludeParamKeyPattern);
+                    } else {
+                        $xfer += $input->skip($ftype);
+                    }
+                    break;
                 default:
                     $xfer += $input->skip($ftype);
                     break;
@@ -303,6 +341,16 @@ class PartitionsByExprRequest
             $xfer += $output->writeBool($this->skipColumnSchemaForPartition);
             $xfer += $output->writeFieldEnd();
         }
+        if ($this->includeParamKeyPattern !== null) {
+            $xfer += $output->writeFieldBegin('includeParamKeyPattern', TType::STRING, 11);
+            $xfer += $output->writeString($this->includeParamKeyPattern);
+            $xfer += $output->writeFieldEnd();
+        }
+        if ($this->excludeParamKeyPattern !== null) {
+            $xfer += $output->writeFieldBegin('excludeParamKeyPattern', TType::STRING, 12);
+            $xfer += $output->writeString($this->excludeParamKeyPattern);
+            $xfer += $output->writeFieldEnd();
+        }
         $xfer += $output->writeFieldStop();
         $xfer += $output->writeStructEnd();
         return $xfer;
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/PartitionsRequest.php b/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/PartitionsRequest.php
index 7bf93c4034..a616788764 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/PartitionsRequest.php
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-php/metastore/PartitionsRequest.php
@@ -56,6 +56,16 @@ class PartitionsRequest
             'isRequired' => false,
             'type' => TType::BOOL,
         ),
+        8 => array(
+            'var' => 'includeParamKeyPattern',
+            'isRequired' => false,
+            'type' => TType::STRING,
+        ),
+        9 => array(
+            'var' => 'excludeParamKeyPattern',
+            'isRequired' => false,
+            'type' => TType::STRING,
+        ),
     );
 
     /**
@@ -86,6 +96,14 @@ class PartitionsRequest
      * @var bool
      */
     public $skipColumnSchemaForPartition = null;
+    /**
+     * @var string
+     */
+    public $includeParamKeyPattern = null;
+    /**
+     * @var string
+     */
+    public $excludeParamKeyPattern = null;
 
     public function __construct($vals = null)
     {
@@ -111,6 +129,12 @@ class PartitionsRequest
             if (isset($vals['skipColumnSchemaForPartition'])) {
                 $this->skipColumnSchemaForPartition = $vals['skipColumnSchemaForPartition'];
             }
+            if (isset($vals['includeParamKeyPattern'])) {
+                $this->includeParamKeyPattern = $vals['includeParamKeyPattern'];
+            }
+            if (isset($vals['excludeParamKeyPattern'])) {
+                $this->excludeParamKeyPattern = $vals['excludeParamKeyPattern'];
+            }
         }
     }
 
@@ -182,6 +206,20 @@ class PartitionsRequest
                         $xfer += $input->skip($ftype);
                     }
                     break;
+                case 8:
+                    if ($ftype == TType::STRING) {
+                        $xfer += $input->readString($this->includeParamKeyPattern);
+                    } else {
+                        $xfer += $input->skip($ftype);
+                    }
+                    break;
+                case 9:
+                    if ($ftype == TType::STRING) {
+                        $xfer += $input->readString($this->excludeParamKeyPattern);
+                    } else {
+                        $xfer += $input->skip($ftype);
+                    }
+                    break;
                 default:
                     $xfer += $input->skip($ftype);
                     break;
@@ -231,6 +269,16 @@ class PartitionsRequest
             $xfer += $output->writeBool($this->skipColumnSchemaForPartition);
             $xfer += $output->writeFieldEnd();
         }
+        if ($this->includeParamKeyPattern !== null) {
+            $xfer += $output->writeFieldBegin('includeParamKeyPattern', TType::STRING, 8);
+            $xfer += $output->writeString($this->includeParamKeyPattern);
+            $xfer += $output->writeFieldEnd();
+        }
+        if ($this->excludeParamKeyPattern !== null) {
+            $xfer += $output->writeFieldBegin('excludeParamKeyPattern', TType::STRING, 9);
+            $xfer += $output->writeString($this->excludeParamKeyPattern);
+            $xfer += $output->writeFieldEnd();
+        }
         $xfer += $output->writeFieldStop();
         $xfer += $output->writeStructEnd();
         return $xfer;
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-py/hive_metastore/ttypes.py b/standalone-metastore/metastore-common/src/gen/thrift/gen-py/hive_metastore/ttypes.py
index a06a33c405..7b8052771a 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-py/hive_metastore/ttypes.py
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-py/hive_metastore/ttypes.py
@@ -10113,11 +10113,13 @@ class PartitionsByExprRequest(object):
      - validWriteIdList
      - id
      - skipColumnSchemaForPartition
+     - includeParamKeyPattern
+     - excludeParamKeyPattern
 
     """
 
 
-    def __init__(self, dbName=None, tblName=None, expr=None, defaultPartitionName=None, maxParts=-1, catName=None, order=None, validWriteIdList=None, id=-1, skipColumnSchemaForPartition=None,):
+    def __init__(self, dbName=None, tblName=None, expr=None, defaultPartitionName=None, maxParts=-1, catName=None, order=None, validWriteIdList=None, id=-1, skipColumnSchemaForPartition=None, includeParamKeyPattern=None, excludeParamKeyPattern=None,):
         self.dbName = dbName
         self.tblName = tblName
         self.expr = expr
@@ -10128,6 +10130,8 @@ def __init__(self, dbName=None, tblName=None, expr=None, defaultPartitionName=No
         self.validWriteIdList = validWriteIdList
         self.id = id
         self.skipColumnSchemaForPartition = skipColumnSchemaForPartition
+        self.includeParamKeyPattern = includeParamKeyPattern
+        self.excludeParamKeyPattern = excludeParamKeyPattern
 
     def read(self, iprot):
         if iprot._fast_decode is not None and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None:
@@ -10188,6 +10192,16 @@ def read(self, iprot):
                     self.skipColumnSchemaForPartition = iprot.readBool()
                 else:
                     iprot.skip(ftype)
+            elif fid == 11:
+                if ftype == TType.STRING:
+                    self.includeParamKeyPattern = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
+                else:
+                    iprot.skip(ftype)
+            elif fid == 12:
+                if ftype == TType.STRING:
+                    self.excludeParamKeyPattern = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
+                else:
+                    iprot.skip(ftype)
             else:
                 iprot.skip(ftype)
             iprot.readFieldEnd()
@@ -10238,6 +10252,14 @@ def write(self, oprot):
             oprot.writeFieldBegin('skipColumnSchemaForPartition', TType.BOOL, 10)
             oprot.writeBool(self.skipColumnSchemaForPartition)
             oprot.writeFieldEnd()
+        if self.includeParamKeyPattern is not None:
+            oprot.writeFieldBegin('includeParamKeyPattern', TType.STRING, 11)
+            oprot.writeString(self.includeParamKeyPattern.encode('utf-8') if sys.version_info[0] == 2 else self.includeParamKeyPattern)
+            oprot.writeFieldEnd()
+        if self.excludeParamKeyPattern is not None:
+            oprot.writeFieldBegin('excludeParamKeyPattern', TType.STRING, 12)
+            oprot.writeString(self.excludeParamKeyPattern.encode('utf-8') if sys.version_info[0] == 2 else self.excludeParamKeyPattern)
+            oprot.writeFieldEnd()
         oprot.writeFieldStop()
         oprot.writeStructEnd()
 
@@ -11700,11 +11722,13 @@ class GetPartitionsByNamesRequest(object):
      - getFileMetadata
      - id
      - skipColumnSchemaForPartition
+     - includeParamKeyPattern
+     - excludeParamKeyPattern
 
     """
 
 
-    def __init__(self, db_name=None, tbl_name=None, names=None, get_col_stats=None, processorCapabilities=None, processorIdentifier=None, engine=None, validWriteIdList=None, getFileMetadata=None, id=-1, skipColumnSchemaForPartition=None,):
+    def __init__(self, db_name=None, tbl_name=None, names=None, get_col_stats=None, processorCapabilities=None, processorIdentifier=None, engine=None, validWriteIdList=None, getFileMetadata=None, id=-1, skipColumnSchemaForPartition=None, includeParamKeyPattern=None, excludeParamKeyPattern=None,):
         self.db_name = db_name
         self.tbl_name = tbl_name
         self.names = names
@@ -11716,6 +11740,8 @@ def __init__(self, db_name=None, tbl_name=None, names=None, get_col_stats=None,
         self.getFileMetadata = getFileMetadata
         self.id = id
         self.skipColumnSchemaForPartition = skipColumnSchemaForPartition
+        self.includeParamKeyPattern = includeParamKeyPattern
+        self.excludeParamKeyPattern = excludeParamKeyPattern
 
     def read(self, iprot):
         if iprot._fast_decode is not None and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None:
@@ -11791,6 +11817,16 @@ def read(self, iprot):
                     self.skipColumnSchemaForPartition = iprot.readBool()
                 else:
                     iprot.skip(ftype)
+            elif fid == 12:
+                if ftype == TType.STRING:
+                    self.includeParamKeyPattern = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
+                else:
+                    iprot.skip(ftype)
+            elif fid == 13:
+                if ftype == TType.STRING:
+                    self.excludeParamKeyPattern = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
+                else:
+                    iprot.skip(ftype)
             else:
                 iprot.skip(ftype)
             iprot.readFieldEnd()
@@ -11851,6 +11887,14 @@ def write(self, oprot):
             oprot.writeFieldBegin('skipColumnSchemaForPartition', TType.BOOL, 11)
             oprot.writeBool(self.skipColumnSchemaForPartition)
             oprot.writeFieldEnd()
+        if self.includeParamKeyPattern is not None:
+            oprot.writeFieldBegin('includeParamKeyPattern', TType.STRING, 12)
+            oprot.writeString(self.includeParamKeyPattern.encode('utf-8') if sys.version_info[0] == 2 else self.includeParamKeyPattern)
+            oprot.writeFieldEnd()
+        if self.excludeParamKeyPattern is not None:
+            oprot.writeFieldBegin('excludeParamKeyPattern', TType.STRING, 13)
+            oprot.writeString(self.excludeParamKeyPattern.encode('utf-8') if sys.version_info[0] == 2 else self.excludeParamKeyPattern)
+            oprot.writeFieldEnd()
         oprot.writeFieldStop()
         oprot.writeStructEnd()
 
@@ -27993,11 +28037,13 @@ class PartitionsRequest(object):
      - validWriteIdList
      - id
      - skipColumnSchemaForPartition
+     - includeParamKeyPattern
+     - excludeParamKeyPattern
 
     """
 
 
-    def __init__(self, catName=None, dbName=None, tblName=None, maxParts=-1, validWriteIdList=None, id=-1, skipColumnSchemaForPartition=None,):
+    def __init__(self, catName=None, dbName=None, tblName=None, maxParts=-1, validWriteIdList=None, id=-1, skipColumnSchemaForPartition=None, includeParamKeyPattern=None, excludeParamKeyPattern=None,):
         self.catName = catName
         self.dbName = dbName
         self.tblName = tblName
@@ -28005,6 +28051,8 @@ def __init__(self, catName=None, dbName=None, tblName=None, maxParts=-1, validWr
         self.validWriteIdList = validWriteIdList
         self.id = id
         self.skipColumnSchemaForPartition = skipColumnSchemaForPartition
+        self.includeParamKeyPattern = includeParamKeyPattern
+        self.excludeParamKeyPattern = excludeParamKeyPattern
 
     def read(self, iprot):
         if iprot._fast_decode is not None and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None:
@@ -28050,6 +28098,16 @@ def read(self, iprot):
                     self.skipColumnSchemaForPartition = iprot.readBool()
                 else:
                     iprot.skip(ftype)
+            elif fid == 8:
+                if ftype == TType.STRING:
+                    self.includeParamKeyPattern = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
+                else:
+                    iprot.skip(ftype)
+            elif fid == 9:
+                if ftype == TType.STRING:
+                    self.excludeParamKeyPattern = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
+                else:
+                    iprot.skip(ftype)
             else:
                 iprot.skip(ftype)
             iprot.readFieldEnd()
@@ -28088,6 +28146,14 @@ def write(self, oprot):
             oprot.writeFieldBegin('skipColumnSchemaForPartition', TType.BOOL, 7)
             oprot.writeBool(self.skipColumnSchemaForPartition)
             oprot.writeFieldEnd()
+        if self.includeParamKeyPattern is not None:
+            oprot.writeFieldBegin('includeParamKeyPattern', TType.STRING, 8)
+            oprot.writeString(self.includeParamKeyPattern.encode('utf-8') if sys.version_info[0] == 2 else self.includeParamKeyPattern)
+            oprot.writeFieldEnd()
+        if self.excludeParamKeyPattern is not None:
+            oprot.writeFieldBegin('excludeParamKeyPattern', TType.STRING, 9)
+            oprot.writeString(self.excludeParamKeyPattern.encode('utf-8') if sys.version_info[0] == 2 else self.excludeParamKeyPattern)
+            oprot.writeFieldEnd()
         oprot.writeFieldStop()
         oprot.writeStructEnd()
 
@@ -28187,17 +28253,21 @@ class GetPartitionsByFilterRequest(object):
      - filter
      - maxParts
      - skipColumnSchemaForPartition
+     - includeParamKeyPattern
+     - excludeParamKeyPattern
 
     """
 
 
-    def __init__(self, catName=None, dbName=None, tblName=None, filter=None, maxParts=-1, skipColumnSchemaForPartition=None,):
+    def __init__(self, catName=None, dbName=None, tblName=None, filter=None, maxParts=-1, skipColumnSchemaForPartition=None, includeParamKeyPattern=None, excludeParamKeyPattern=None,):
         self.catName = catName
         self.dbName = dbName
         self.tblName = tblName
         self.filter = filter
         self.maxParts = maxParts
         self.skipColumnSchemaForPartition = skipColumnSchemaForPartition
+        self.includeParamKeyPattern = includeParamKeyPattern
+        self.excludeParamKeyPattern = excludeParamKeyPattern
 
     def read(self, iprot):
         if iprot._fast_decode is not None and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None:
@@ -28238,6 +28308,16 @@ def read(self, iprot):
                     self.skipColumnSchemaForPartition = iprot.readBool()
                 else:
                     iprot.skip(ftype)
+            elif fid == 7:
+                if ftype == TType.STRING:
+                    self.includeParamKeyPattern = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
+                else:
+                    iprot.skip(ftype)
+            elif fid == 8:
+                if ftype == TType.STRING:
+                    self.excludeParamKeyPattern = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
+                else:
+                    iprot.skip(ftype)
             else:
                 iprot.skip(ftype)
             iprot.readFieldEnd()
@@ -28272,6 +28352,14 @@ def write(self, oprot):
             oprot.writeFieldBegin('skipColumnSchemaForPartition', TType.BOOL, 6)
             oprot.writeBool(self.skipColumnSchemaForPartition)
             oprot.writeFieldEnd()
+        if self.includeParamKeyPattern is not None:
+            oprot.writeFieldBegin('includeParamKeyPattern', TType.STRING, 7)
+            oprot.writeString(self.includeParamKeyPattern.encode('utf-8') if sys.version_info[0] == 2 else self.includeParamKeyPattern)
+            oprot.writeFieldEnd()
+        if self.excludeParamKeyPattern is not None:
+            oprot.writeFieldBegin('excludeParamKeyPattern', TType.STRING, 8)
+            oprot.writeString(self.excludeParamKeyPattern.encode('utf-8') if sys.version_info[0] == 2 else self.excludeParamKeyPattern)
+            oprot.writeFieldEnd()
         oprot.writeFieldStop()
         oprot.writeStructEnd()
 
@@ -28505,11 +28593,13 @@ class GetPartitionsPsWithAuthRequest(object):
      - validWriteIdList
      - id
      - skipColumnSchemaForPartition
+     - includeParamKeyPattern
+     - excludeParamKeyPattern
 
     """
 
 
-    def __init__(self, catName=None, dbName=None, tblName=None, partVals=None, maxParts=-1, userName=None, groupNames=None, validWriteIdList=None, id=-1, skipColumnSchemaForPartition=None,):
+    def __init__(self, catName=None, dbName=None, tblName=None, partVals=None, maxParts=-1, userName=None, groupNames=None, validWriteIdList=None, id=-1, skipColumnSchemaForPartition=None, includeParamKeyPattern=None, excludeParamKeyPattern=None,):
         self.catName = catName
         self.dbName = dbName
         self.tblName = tblName
@@ -28520,6 +28610,8 @@ def __init__(self, catName=None, dbName=None, tblName=None, partVals=None, maxPa
         self.validWriteIdList = validWriteIdList
         self.id = id
         self.skipColumnSchemaForPartition = skipColumnSchemaForPartition
+        self.includeParamKeyPattern = includeParamKeyPattern
+        self.excludeParamKeyPattern = excludeParamKeyPattern
 
     def read(self, iprot):
         if iprot._fast_decode is not None and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None:
@@ -28590,6 +28682,16 @@ def read(self, iprot):
                     self.skipColumnSchemaForPartition = iprot.readBool()
                 else:
                     iprot.skip(ftype)
+            elif fid == 11:
+                if ftype == TType.STRING:
+                    self.includeParamKeyPattern = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
+                else:
+                    iprot.skip(ftype)
+            elif fid == 12:
+                if ftype == TType.STRING:
+                    self.excludeParamKeyPattern = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
+                else:
+                    iprot.skip(ftype)
             else:
                 iprot.skip(ftype)
             iprot.readFieldEnd()
@@ -28646,6 +28748,14 @@ def write(self, oprot):
             oprot.writeFieldBegin('skipColumnSchemaForPartition', TType.BOOL, 10)
             oprot.writeBool(self.skipColumnSchemaForPartition)
             oprot.writeFieldEnd()
+        if self.includeParamKeyPattern is not None:
+            oprot.writeFieldBegin('includeParamKeyPattern', TType.STRING, 11)
+            oprot.writeString(self.includeParamKeyPattern.encode('utf-8') if sys.version_info[0] == 2 else self.includeParamKeyPattern)
+            oprot.writeFieldEnd()
+        if self.excludeParamKeyPattern is not None:
+            oprot.writeFieldBegin('excludeParamKeyPattern', TType.STRING, 12)
+            oprot.writeString(self.excludeParamKeyPattern.encode('utf-8') if sys.version_info[0] == 2 else self.excludeParamKeyPattern)
+            oprot.writeFieldEnd()
         oprot.writeFieldStop()
         oprot.writeStructEnd()
 
@@ -31892,6 +32002,8 @@ def __ne__(self, other):
     (8, TType.STRING, 'validWriteIdList', 'UTF8', None, ),  # 8
     (9, TType.I64, 'id', None, -1, ),  # 9
     (10, TType.BOOL, 'skipColumnSchemaForPartition', None, None, ),  # 10
+    (11, TType.STRING, 'includeParamKeyPattern', 'UTF8', None, ),  # 11
+    (12, TType.STRING, 'excludeParamKeyPattern', 'UTF8', None, ),  # 12
 )
 all_structs.append(TableStatsResult)
 TableStatsResult.thrift_spec = (
@@ -32016,6 +32128,8 @@ def __ne__(self, other):
     (9, TType.BOOL, 'getFileMetadata', None, None, ),  # 9
     (10, TType.I64, 'id', None, -1, ),  # 10
     (11, TType.BOOL, 'skipColumnSchemaForPartition', None, None, ),  # 11
+    (12, TType.STRING, 'includeParamKeyPattern', 'UTF8', None, ),  # 12
+    (13, TType.STRING, 'excludeParamKeyPattern', 'UTF8', None, ),  # 13
 )
 all_structs.append(GetPartitionsByNamesResult)
 GetPartitionsByNamesResult.thrift_spec = (
@@ -33348,6 +33462,8 @@ def __ne__(self, other):
     (5, TType.STRING, 'validWriteIdList', 'UTF8', None, ),  # 5
     (6, TType.I64, 'id', None, -1, ),  # 6
     (7, TType.BOOL, 'skipColumnSchemaForPartition', None, None, ),  # 7
+    (8, TType.STRING, 'includeParamKeyPattern', 'UTF8', None, ),  # 8
+    (9, TType.STRING, 'excludeParamKeyPattern', 'UTF8', None, ),  # 9
 )
 all_structs.append(PartitionsResponse)
 PartitionsResponse.thrift_spec = (
@@ -33363,6 +33479,8 @@ def __ne__(self, other):
     (4, TType.STRING, 'filter', 'UTF8', None, ),  # 4
     (5, TType.I16, 'maxParts', None, -1, ),  # 5
     (6, TType.BOOL, 'skipColumnSchemaForPartition', None, None, ),  # 6
+    (7, TType.STRING, 'includeParamKeyPattern', 'UTF8', None, ),  # 7
+    (8, TType.STRING, 'excludeParamKeyPattern', 'UTF8', None, ),  # 8
 )
 all_structs.append(GetPartitionNamesPsRequest)
 GetPartitionNamesPsRequest.thrift_spec = (
@@ -33393,6 +33511,8 @@ def __ne__(self, other):
     (8, TType.STRING, 'validWriteIdList', 'UTF8', None, ),  # 8
     (9, TType.I64, 'id', None, -1, ),  # 9
     (10, TType.BOOL, 'skipColumnSchemaForPartition', None, None, ),  # 10
+    (11, TType.STRING, 'includeParamKeyPattern', 'UTF8', None, ),  # 11
+    (12, TType.STRING, 'excludeParamKeyPattern', 'UTF8', None, ),  # 12
 )
 all_structs.append(GetPartitionsPsWithAuthResponse)
 GetPartitionsPsWithAuthResponse.thrift_spec = (
diff --git a/standalone-metastore/metastore-common/src/gen/thrift/gen-rb/hive_metastore_types.rb b/standalone-metastore/metastore-common/src/gen/thrift/gen-rb/hive_metastore_types.rb
index 72595ed426..ab4c608d8e 100644
--- a/standalone-metastore/metastore-common/src/gen/thrift/gen-rb/hive_metastore_types.rb
+++ b/standalone-metastore/metastore-common/src/gen/thrift/gen-rb/hive_metastore_types.rb
@@ -3191,6 +3191,8 @@ class PartitionsByExprRequest
   VALIDWRITEIDLIST = 8
   ID = 9
   SKIPCOLUMNSCHEMAFORPARTITION = 10
+  INCLUDEPARAMKEYPATTERN = 11
+  EXCLUDEPARAMKEYPATTERN = 12
 
   FIELDS = {
     DBNAME => {:type => ::Thrift::Types::STRING, :name => 'dbName'},
@@ -3202,7 +3204,9 @@ class PartitionsByExprRequest
     ORDER => {:type => ::Thrift::Types::STRING, :name => 'order', :optional => true},
     VALIDWRITEIDLIST => {:type => ::Thrift::Types::STRING, :name => 'validWriteIdList', :optional => true},
     ID => {:type => ::Thrift::Types::I64, :name => 'id', :default => -1, :optional => true},
-    SKIPCOLUMNSCHEMAFORPARTITION => {:type => ::Thrift::Types::BOOL, :name => 'skipColumnSchemaForPartition', :optional => true}
+    SKIPCOLUMNSCHEMAFORPARTITION => {:type => ::Thrift::Types::BOOL, :name => 'skipColumnSchemaForPartition', :optional => true},
+    INCLUDEPARAMKEYPATTERN => {:type => ::Thrift::Types::STRING, :name => 'includeParamKeyPattern', :optional => true},
+    EXCLUDEPARAMKEYPATTERN => {:type => ::Thrift::Types::STRING, :name => 'excludeParamKeyPattern', :optional => true}
   }
 
   def struct_fields; FIELDS; end
@@ -3560,6 +3564,8 @@ class GetPartitionsByNamesRequest
   GETFILEMETADATA = 9
   ID = 10
   SKIPCOLUMNSCHEMAFORPARTITION = 11
+  INCLUDEPARAMKEYPATTERN = 12
+  EXCLUDEPARAMKEYPATTERN = 13
 
   FIELDS = {
     DB_NAME => {:type => ::Thrift::Types::STRING, :name => 'db_name'},
@@ -3572,7 +3578,9 @@ class GetPartitionsByNamesRequest
     VALIDWRITEIDLIST => {:type => ::Thrift::Types::STRING, :name => 'validWriteIdList', :optional => true},
     GETFILEMETADATA => {:type => ::Thrift::Types::BOOL, :name => 'getFileMetadata', :optional => true},
     ID => {:type => ::Thrift::Types::I64, :name => 'id', :default => -1, :optional => true},
-    SKIPCOLUMNSCHEMAFORPARTITION => {:type => ::Thrift::Types::BOOL, :name => 'skipColumnSchemaForPartition', :optional => true}
+    SKIPCOLUMNSCHEMAFORPARTITION => {:type => ::Thrift::Types::BOOL, :name => 'skipColumnSchemaForPartition', :optional => true},
+    INCLUDEPARAMKEYPATTERN => {:type => ::Thrift::Types::STRING, :name => 'includeParamKeyPattern', :optional => true},
+    EXCLUDEPARAMKEYPATTERN => {:type => ::Thrift::Types::STRING, :name => 'excludeParamKeyPattern', :optional => true}
   }
 
   def struct_fields; FIELDS; end
@@ -7660,6 +7668,8 @@ class PartitionsRequest
   VALIDWRITEIDLIST = 5
   ID = 6
   SKIPCOLUMNSCHEMAFORPARTITION = 7
+  INCLUDEPARAMKEYPATTERN = 8
+  EXCLUDEPARAMKEYPATTERN = 9
 
   FIELDS = {
     CATNAME => {:type => ::Thrift::Types::STRING, :name => 'catName', :optional => true},
@@ -7668,7 +7678,9 @@ class PartitionsRequest
     MAXPARTS => {:type => ::Thrift::Types::I16, :name => 'maxParts', :default => -1, :optional => true},
     VALIDWRITEIDLIST => {:type => ::Thrift::Types::STRING, :name => 'validWriteIdList', :optional => true},
     ID => {:type => ::Thrift::Types::I64, :name => 'id', :default => -1, :optional => true},
-    SKIPCOLUMNSCHEMAFORPARTITION => {:type => ::Thrift::Types::BOOL, :name => 'skipColumnSchemaForPartition', :optional => true}
+    SKIPCOLUMNSCHEMAFORPARTITION => {:type => ::Thrift::Types::BOOL, :name => 'skipColumnSchemaForPartition', :optional => true},
+    INCLUDEPARAMKEYPATTERN => {:type => ::Thrift::Types::STRING, :name => 'includeParamKeyPattern', :optional => true},
+    EXCLUDEPARAMKEYPATTERN => {:type => ::Thrift::Types::STRING, :name => 'excludeParamKeyPattern', :optional => true}
   }
 
   def struct_fields; FIELDS; end
@@ -7706,6 +7718,8 @@ class GetPartitionsByFilterRequest
   FILTER = 4
   MAXPARTS = 5
   SKIPCOLUMNSCHEMAFORPARTITION = 6
+  INCLUDEPARAMKEYPATTERN = 7
+  EXCLUDEPARAMKEYPATTERN = 8
 
   FIELDS = {
     CATNAME => {:type => ::Thrift::Types::STRING, :name => 'catName', :optional => true},
@@ -7713,7 +7727,9 @@ class GetPartitionsByFilterRequest
     TBLNAME => {:type => ::Thrift::Types::STRING, :name => 'tblName'},
     FILTER => {:type => ::Thrift::Types::STRING, :name => 'filter'},
     MAXPARTS => {:type => ::Thrift::Types::I16, :name => 'maxParts', :default => -1, :optional => true},
-    SKIPCOLUMNSCHEMAFORPARTITION => {:type => ::Thrift::Types::BOOL, :name => 'skipColumnSchemaForPartition', :optional => true}
+    SKIPCOLUMNSCHEMAFORPARTITION => {:type => ::Thrift::Types::BOOL, :name => 'skipColumnSchemaForPartition', :optional => true},
+    INCLUDEPARAMKEYPATTERN => {:type => ::Thrift::Types::STRING, :name => 'includeParamKeyPattern', :optional => true},
+    EXCLUDEPARAMKEYPATTERN => {:type => ::Thrift::Types::STRING, :name => 'excludeParamKeyPattern', :optional => true}
   }
 
   def struct_fields; FIELDS; end
@@ -7783,6 +7799,8 @@ class GetPartitionsPsWithAuthRequest
   VALIDWRITEIDLIST = 8
   ID = 9
   SKIPCOLUMNSCHEMAFORPARTITION = 10
+  INCLUDEPARAMKEYPATTERN = 11
+  EXCLUDEPARAMKEYPATTERN = 12
 
   FIELDS = {
     CATNAME => {:type => ::Thrift::Types::STRING, :name => 'catName', :optional => true},
@@ -7794,7 +7812,9 @@ class GetPartitionsPsWithAuthRequest
     GROUPNAMES => {:type => ::Thrift::Types::LIST, :name => 'groupNames', :element => {:type => ::Thrift::Types::STRING}, :optional => true},
     VALIDWRITEIDLIST => {:type => ::Thrift::Types::STRING, :name => 'validWriteIdList', :optional => true},
     ID => {:type => ::Thrift::Types::I64, :name => 'id', :default => -1, :optional => true},
-    SKIPCOLUMNSCHEMAFORPARTITION => {:type => ::Thrift::Types::BOOL, :name => 'skipColumnSchemaForPartition', :optional => true}
+    SKIPCOLUMNSCHEMAFORPARTITION => {:type => ::Thrift::Types::BOOL, :name => 'skipColumnSchemaForPartition', :optional => true},
+    INCLUDEPARAMKEYPATTERN => {:type => ::Thrift::Types::STRING, :name => 'includeParamKeyPattern', :optional => true},
+    EXCLUDEPARAMKEYPATTERN => {:type => ::Thrift::Types::STRING, :name => 'excludeParamKeyPattern', :optional => true}
   }
 
   def struct_fields; FIELDS; end
diff --git a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
index 228baed81a..71a8dfb620 100644
--- a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
+++ b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
@@ -21,6 +21,7 @@
 import static org.apache.hadoop.hive.common.AcidConstants.SOFT_DELETE_TABLE;
 import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;
 import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.convertToGetPartitionsByNamesRequest;
+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.createThriftPartitionsReq;
 import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.getDefaultCatalog;
 import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependCatalogToDbName;
 
@@ -1731,10 +1732,7 @@ public void dropDatabase(DropDatabaseRequest req)
    * server side when the client invokes drop_database.
    * Note that this is 'less transactional' than dropDatabaseCascadePerDb since we're dropping
    * table level objects, so the overall outcome of this method might result in a halfly dropped DB.
-   * @param catName
-   * @param dbName
    * @param tableList
-   * @param deleteData
    * @param maxBatchSize
    * @throws TException
    */
@@ -2188,12 +2186,12 @@ public List<Partition> listPartitions(String catName, String db_name, String tbl
     if (db_name == null || tbl_name == null) {
       throw new MetaException("Database name/Table name should not be null");
     }
-    boolean skipColumnSchemaForPartition = MetastoreConf.getBoolVar(conf, ConfVars.METASTORE_CLIENT_FIELD_SCHEMA_FOR_PARTITIONS);
     // TODO should we add capabilities here as well as it returns Partition objects
-    PartitionsRequest req = new PartitionsRequest(db_name, tbl_name);
+    PartitionsRequest req = createThriftPartitionsReq(PartitionsRequest.class, conf);
+    req.setDbName(db_name);
+    req.setTblName(tbl_name);
     req.setCatName(catName);
     req.setMaxParts(shrinkMaxtoShort(max_parts));
-    req.setSkipColumnSchemaForPartition(skipColumnSchemaForPartition);
     List<Partition> parts = client.get_partitions_req(req).getPartitions();
     return deepCopyPartitions(
         FilterUtils.filterPartitionsIfEnabled(isClientFilterEnabled, filterHook, parts));
@@ -2227,12 +2225,12 @@ public List<Partition> listPartitions(String catName, String db_name, String tbl
     if (db_name == null || tbl_name == null || part_vals == null) {
       throw new MetaException("Database name/Table name/partition values should not be null");
     }
-    boolean skipColumnSchemaForPartition = MetastoreConf.getBoolVar(conf, ConfVars.METASTORE_CLIENT_FIELD_SCHEMA_FOR_PARTITIONS);
-    GetPartitionsPsWithAuthRequest req = new GetPartitionsPsWithAuthRequest(db_name, tbl_name);
+    GetPartitionsPsWithAuthRequest req = createThriftPartitionsReq(GetPartitionsPsWithAuthRequest.class, conf);
+    req.setDbName(db_name);
+    req.setTblName(tbl_name);
     req.setCatName(catName);
     req.setPartVals(part_vals);
     req.setMaxParts(shrinkMaxtoShort(max_parts));
-    req.setSkipColumnSchemaForPartition(skipColumnSchemaForPartition);
     List<Partition> parts = client.get_partitions_ps_with_auth_req(req).getPartitions();
     return deepCopyPartitions(FilterUtils.filterPartitionsIfEnabled(isClientFilterEnabled, filterHook, parts));
   }
@@ -2265,9 +2263,8 @@ public GetPartitionsPsWithAuthResponse listPartitionsWithAuthInfoRequest(GetPart
 
   protected GetPartitionsPsWithAuthResponse listPartitionsWithAuthInfoRequestInternal(GetPartitionsPsWithAuthRequest req)
       throws TException {
-    boolean skipColumnSchemaForPartition = MetastoreConf.getBoolVar(conf, ConfVars.METASTORE_CLIENT_FIELD_SCHEMA_FOR_PARTITIONS);
-    req.setSkipColumnSchemaForPartition(skipColumnSchemaForPartition);
-    return client.get_partitions_ps_with_auth_req(req);
+    return client.get_partitions_ps_with_auth_req(
+        createThriftPartitionsReq(GetPartitionsPsWithAuthRequest.class, conf, req));
   }
 
   @Override
@@ -2295,13 +2292,13 @@ protected List<Partition> listPartitionsWithAuthInfoInternal(String catName, Str
     if (dbName == null || tableName == null) {
       throw new MetaException("Database name/Table name should not be null");
     }
-    boolean skipColumnSchemaForPartition = MetastoreConf.getBoolVar(conf, ConfVars.METASTORE_CLIENT_FIELD_SCHEMA_FOR_PARTITIONS);
-    GetPartitionsPsWithAuthRequest req = new GetPartitionsPsWithAuthRequest(dbName, tableName);
+    GetPartitionsPsWithAuthRequest req = createThriftPartitionsReq(GetPartitionsPsWithAuthRequest.class, conf);
+    req.setTblName(tableName);
+    req.setDbName(dbName);
     req.setCatName(catName);
     req.setMaxParts(shrinkMaxtoShort(maxParts));
     req.setUserName(userName);
     req.setGroupNames(groupNames);
-    req.setSkipColumnSchemaForPartition(skipColumnSchemaForPartition);
     List<Partition> partsList = client.get_partitions_ps_with_auth_req(req).getPartitions();
     return partsList;
   }
@@ -2344,14 +2341,14 @@ protected List<Partition> listPartitionsWithAuthInfoInternal(String catName, Str
     if (dbName == null || tableName == null || partialPvals == null) {
       throw new MetaException("Database name/Table name/partition values should not be null");
     }
-    boolean skipColumnSchemaForPartition = MetastoreConf.getBoolVar(conf, ConfVars.METASTORE_CLIENT_FIELD_SCHEMA_FOR_PARTITIONS);
-    GetPartitionsPsWithAuthRequest req = new GetPartitionsPsWithAuthRequest(dbName, tableName);
+    GetPartitionsPsWithAuthRequest req = createThriftPartitionsReq(GetPartitionsPsWithAuthRequest.class, conf);
+    req.setTblName(tableName);
+    req.setDbName(dbName);
     req.setCatName(catName);
     req.setPartVals(partialPvals);
     req.setMaxParts(shrinkMaxtoShort(maxParts));
     req.setUserName(userName);
     req.setGroupNames(groupNames);
-    req.setSkipColumnSchemaForPartition(skipColumnSchemaForPartition);
     return client.get_partitions_ps_with_auth_req(req).getPartitions();
   }
 
@@ -2364,9 +2361,14 @@ public List<Partition> listPartitionsByFilter(String db_name, String tbl_name,
   @Override
   public List<Partition> listPartitionsByFilter(String catName, String db_name, String tbl_name,
                                                 String filter, int max_parts) throws TException {
+    GetPartitionsByFilterRequest req = createThriftPartitionsReq(GetPartitionsByFilterRequest.class, conf);
+    req.setTblName(tbl_name);
+    req.setDbName(db_name);
+    req.setCatName(catName);
+    req.setFilter(filter);
+    req.setMaxParts(shrinkMaxtoShort(max_parts));
     // TODO should we add capabilities here as well as it returns Partition objects
-    List<Partition> parts = client.get_partitions_by_filter(prependCatalogToDbName(
-        catName, db_name, conf), tbl_name, filter, shrinkMaxtoShort(max_parts));
+    List<Partition> parts = client.get_partitions_by_filter_req(req);
     return deepCopyPartitions(FilterUtils.filterPartitionsIfEnabled(isClientFilterEnabled, filterHook, parts));
   }
 
@@ -2417,9 +2419,7 @@ protected PartitionsByExprRequest buildPartitionsByExprRequest(String catName, S
   }
 
   protected PartitionsByExprResult getPartitionsByExprInternal(PartitionsByExprRequest req) throws TException {
-    boolean skipColumnSchemaForPartition = MetastoreConf.getBoolVar(conf, ConfVars.METASTORE_CLIENT_FIELD_SCHEMA_FOR_PARTITIONS);
-    req.setSkipColumnSchemaForPartition(skipColumnSchemaForPartition);
-    return client.get_partitions_by_expr(req);
+    return client.get_partitions_by_expr(createThriftPartitionsReq(PartitionsByExprRequest.class, conf, req));
   }
 
   @Override
@@ -2469,7 +2469,7 @@ private void rethrowException(TApplicationException te) throws TException{
   }
 
   protected PartitionsSpecByExprResult getPartitionsSpecByExprInternal(PartitionsByExprRequest req) throws TException {
-    return client.get_partitions_spec_by_expr(req);
+    return client.get_partitions_spec_by_expr(createThriftPartitionsReq(PartitionsByExprRequest.class, conf, req));
   }
 
   @Override
@@ -2574,13 +2574,10 @@ public List<Partition> getPartitionsByNames(String db_name, String tbl_name,
   @Override
   public PartitionsResponse getPartitionsRequest(PartitionsRequest req)
       throws NoSuchObjectException, MetaException, TException {
-
     if (req.getValidWriteIdList() == null) {
       req.setValidWriteIdList(getValidWriteIdList(req.getDbName(), req.getTblName()));
     }
-    boolean skipColumnSchemaForPartition = MetastoreConf.getBoolVar(conf, ConfVars.METASTORE_CLIENT_FIELD_SCHEMA_FOR_PARTITIONS);
-    req.setSkipColumnSchemaForPartition(skipColumnSchemaForPartition);
-    PartitionsResponse res = client.get_partitions_req(req);
+    PartitionsResponse res = client.get_partitions_req(createThriftPartitionsReq(PartitionsRequest.class, conf, req));
     List<Partition> parts = deepCopyPartitions(
             FilterUtils.filterPartitionsIfEnabled(isClientFilterEnabled, filterHook, res.getPartitions()));
     res.setPartitions(parts);
@@ -2607,8 +2604,6 @@ public GetPartitionsByNamesResult getPartitionsByNames(GetPartitionsByNamesReque
       req.setProcessorCapabilities(new ArrayList<>(Arrays.asList(processorCapabilities)));
     if (processorIdentifier != null)
       req.setProcessorIdentifier(processorIdentifier);
-    boolean skipColumnSchemaForPartition = MetastoreConf.getBoolVar(conf, ConfVars.METASTORE_CLIENT_FIELD_SCHEMA_FOR_PARTITIONS);
-    req.setSkipColumnSchemaForPartition(skipColumnSchemaForPartition);
     List<Partition> parts = getPartitionsByNamesInternal(req).getPartitions();
     GetPartitionsByNamesResult res = new GetPartitionsByNamesResult();
     res.setPartitions(deepCopyPartitions(FilterUtils.filterPartitionsIfEnabled(
@@ -2618,7 +2613,7 @@ public GetPartitionsByNamesResult getPartitionsByNames(GetPartitionsByNamesReque
 
   protected GetPartitionsByNamesResult getPartitionsByNamesInternal(GetPartitionsByNamesRequest gpbnr)
       throws TException {
-    return client.get_partitions_by_names_req(gpbnr);
+    return client.get_partitions_by_names_req(createThriftPartitionsReq(GetPartitionsByNamesRequest.class, conf, gpbnr));
   }
 
   @Override
@@ -5119,6 +5114,16 @@ public GetPartitionsResponse getPartitionsWithSpecs(GetPartitionsRequest request
       request.setProcessorCapabilities(new ArrayList<String>(Arrays.asList(processorCapabilities)));
     if (processorIdentifier != null)
       request.setProcessorIdentifier(processorIdentifier);
+    if (request.isSetProjectionSpec()) {
+      if (!request.getProjectionSpec().isSetExcludeParamKeyPattern()) {
+        request.getProjectionSpec().setExcludeParamKeyPattern(MetastoreConf.getAsString(conf,
+            MetastoreConf.ConfVars.METASTORE_PARTITIONS_PARAMETERS_EXCLUDE_PATTERN));
+      }
+      if (!request.getProjectionSpec().isSetIncludeParamKeyPattern()) {
+        request.getProjectionSpec().setIncludeParamKeyPattern(MetastoreConf.getAsString(conf,
+            MetastoreConf.ConfVars.METASTORE_PARTITIONS_PARAMETERS_INCLUDE_PATTERN));
+      }
+    }
     return client.get_partitions_with_specs(request);
   }
 
diff --git a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java
index f8814a6838..7208867eaa 100644
--- a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java
+++ b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java
@@ -240,7 +240,9 @@ public String toString() {
       ConfVars.DISALLOW_INCOMPATIBLE_COL_TYPE_CHANGES,
       ConfVars.FILE_METADATA_THREADS,
       ConfVars.METASTORE_CLIENT_FILTER_ENABLED,
-      ConfVars.METASTORE_SERVER_FILTER_ENABLED
+      ConfVars.METASTORE_SERVER_FILTER_ENABLED,
+      ConfVars.METASTORE_PARTITIONS_PARAMETERS_INCLUDE_PATTERN,
+      ConfVars.METASTORE_PARTITIONS_PARAMETERS_EXCLUDE_PATTERN
   };
 
   /**
@@ -1127,6 +1129,16 @@ public enum ConfVars {
                     + "table carries the field schema that is same as that of table schema. For a table with \n"
                     + "wider partitions fetching duplicated field schema in every partition increases memory footprint\n"
                     + "and thrift communication timeout errors. Set this config to 'true' to ignore column schema in partitions."),
+    METASTORE_PARTITIONS_PARAMETERS_EXCLUDE_PATTERN("metastore.partitions.parameters.exclude.pattern",
+        "hive.metastore.partitions.parameters.exclude.pattern", "",
+        "SQL pattern used to exclude the matched parameters for get-partitions APIs.\n"
+            + "Any key-value pair from parameters whose key matches with the pattern will be excluded from the partitions.\n"
+            + "This property doesn't work for the temporary table."),
+    METASTORE_PARTITIONS_PARAMETERS_INCLUDE_PATTERN("metastore.partitions.parameters.include.pattern",
+        "hive.metastore.partitions.parameters.include.pattern", "",
+        "SQL pattern used to select the matched parameters for get-partitions APIs.\n"
+            + "Any key-value pair from parameters whose key matches with the pattern will be included in the partitions.\n"
+            + "This property doesn't work for the temporary table."),
     METASTORE_CLIENT_FILTER_ENABLED("metastore.client.filter.enabled", "hive.metastore.client.filter.enabled", true,
         "Enable filtering the metadata read results at HMS client. Default is true."),
     METASTORE_SERVER_FILTER_ENABLED("metastore.server.filter.enabled", "hive.metastore.server.filter.enabled", false,
diff --git a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/JavaUtils.java b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/JavaUtils.java
index 503345d043..d00c8f0501 100644
--- a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/JavaUtils.java
+++ b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/JavaUtils.java
@@ -23,6 +23,7 @@
 import org.slf4j.LoggerFactory;
 
 import java.lang.reflect.Constructor;
+import java.lang.reflect.Method;
 import java.net.InetAddress;
 import java.net.UnknownHostException;
 
@@ -115,6 +116,18 @@ public static String hostname() {
     }
   }
 
+  public static <T> void setField(T req, String methodName, Class[] argsCls, Object... args) {
+    try {
+      Method method = req.getClass().getDeclaredMethod(methodName, argsCls);
+      method.setAccessible(true);
+      method.invoke(req, args);
+    } catch (Exception e) {
+      LOG.error("Unable to invoke the underlying method: {} of the instance: {}, message: {}",
+          methodName, req, e.getMessage());
+      throw new RuntimeException(e);
+    }
+  }
+
   /**
    * Utility method for ACID to normalize logging info.  Matches
    * org.apache.hadoop.hive.metastore.api.LockRequest#toString
diff --git a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreUtils.java b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreUtils.java
index a95c4c1d19..1491b45a35 100644
--- a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreUtils.java
+++ b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreUtils.java
@@ -1261,6 +1261,23 @@ public static GetPartitionsByNamesRequest convertToGetPartitionsByNamesRequest(S
     return result;
   }
 
+  public static <T> T createThriftPartitionsReq(Class<T> clazz, Configuration conf, T... deepCopy) {
+    final T req;
+    if (deepCopy != null && deepCopy.length == 1) {
+      assert clazz.isAssignableFrom(deepCopy[0].getClass());
+      req = JavaUtils.newInstance(clazz, new Class[]{clazz}, deepCopy);
+    } else {
+      req = JavaUtils.newInstance(clazz);
+    }
+    JavaUtils.setField(req, "setSkipColumnSchemaForPartition", new Class[]{boolean.class},
+        MetastoreConf.getBoolVar(conf, MetastoreConf.ConfVars.METASTORE_CLIENT_FIELD_SCHEMA_FOR_PARTITIONS));
+    JavaUtils.setField(req, "setIncludeParamKeyPattern", new Class[]{String.class},
+        MetastoreConf.getAsString(conf, MetastoreConf.ConfVars.METASTORE_PARTITIONS_PARAMETERS_INCLUDE_PATTERN));
+    JavaUtils.setField(req, "setExcludeParamKeyPattern", new Class[]{String.class},
+        MetastoreConf.getAsString(conf, MetastoreConf.ConfVars.METASTORE_PARTITIONS_PARAMETERS_EXCLUDE_PATTERN));
+    return req;
+  }
+
   /**
    * The config parameter can be like "path", "/path", "/path/", "path/*", "/path1/path2/*" and so on.
    * httpPath should end up as "/*", "/path/*" or "/path1/../pathN/*"
diff --git a/standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift b/standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift
index 935e286c85..e586973640 100644
--- a/standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift
+++ b/standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift
@@ -880,7 +880,9 @@ struct PartitionsByExprRequest {
   7: optional string order
   8: optional string validWriteIdList,
   9: optional i64 id=-1, // table id
-  10: optional bool skipColumnSchemaForPartition
+  10: optional bool skipColumnSchemaForPartition,
+  11: optional string includeParamKeyPattern,
+  12: optional string excludeParamKeyPattern
 }
 
 struct TableStatsResult {
@@ -995,7 +997,9 @@ struct GetPartitionsByNamesRequest {
   8: optional string validWriteIdList,
   9: optional bool getFileMetadata,
   10: optional i64 id=-1,  // table id
-  11: optional bool skipColumnSchemaForPartition
+  11: optional bool skipColumnSchemaForPartition,
+  12: optional string includeParamKeyPattern,
+  13: optional string excludeParamKeyPattern
 }
 
 struct GetPartitionsByNamesResult {
@@ -2310,7 +2314,9 @@ struct PartitionsRequest { // Not using Get prefix as that name is already used
    4: optional i16 maxParts=-1,
    5: optional string validWriteIdList,
    6: optional i64 id=-1, // table id
-   7: optional bool skipColumnSchemaForPartition
+   7: optional bool skipColumnSchemaForPartition,
+   8: optional string includeParamKeyPattern,
+   9: optional string excludeParamKeyPattern
 }
 
 struct PartitionsResponse { // Not using Get prefix as that name is already used for a different method
@@ -2323,7 +2329,9 @@ struct GetPartitionsByFilterRequest {
    3: string tblName,
    4: string filter,
    5: optional i16 maxParts=-1,
-   6: optional bool skipColumnSchemaForPartition
+   6: optional bool skipColumnSchemaForPartition,
+   7: optional string includeParamKeyPattern,
+   8: optional string excludeParamKeyPattern
 }
 
 struct GetPartitionNamesPsRequest {
@@ -2350,7 +2358,9 @@ struct GetPartitionsPsWithAuthRequest {
    7: optional list<string> groupNames,
    8: optional string validWriteIdList,
    9: optional i64 id=-1 // table id
-   10: optional bool skipColumnSchemaForPartition
+   10: optional bool skipColumnSchemaForPartition,
+   11: optional string includeParamKeyPattern,
+   12: optional string excludeParamKeyPattern
 }
 
 struct GetPartitionsPsWithAuthResponse {
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
index c908028bea..feb9701fac 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
@@ -43,6 +43,7 @@
 import org.apache.hadoop.hive.common.repl.ReplConst;
 import org.apache.hadoop.hive.metastore.api.*;
 import org.apache.hadoop.hive.metastore.api.Package;
+import org.apache.hadoop.hive.metastore.client.builder.GetPartitionsArgs;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf.ConfVars;
 import org.apache.hadoop.hive.metastore.dataconnector.DataConnectorProviderFactory;
@@ -2320,9 +2321,10 @@ private void create_table_core(final RawStore ms, final CreateTableRequest req)
       if (!TableType.VIRTUAL_VIEW.toString().equals(tbl.getTableType())) {
         if (tbl.getSd().getLocation() == null
             || tbl.getSd().getLocation().isEmpty()) {
-          tblPath = wh.getDefaultTablePath(db, tbl.getTableName() + getTableSuffix(tbl), isExternal(tbl));
+          tblPath = wh.getDefaultTablePath(db, tbl.getTableName() + getTableSuffix(tbl),
+              MetaStoreUtils.isExternalTable(tbl));
         } else {
-          if (!isExternal(tbl) && !MetaStoreUtils.isNonNativeTable(tbl)) {
+          if (!MetaStoreUtils.isExternalTable(tbl) && !MetaStoreUtils.isNonNativeTable(tbl)) {
             LOG.warn("Location: " + tbl.getSd().getLocation()
                 + " specified for non-external table:" + tbl.getTableName());
           }
@@ -2970,9 +2972,9 @@ private boolean drop_table_core(final RawStore ms, final String catName, final S
   }
 
   private boolean checkTableDataShouldBeDeleted(Table tbl, boolean deleteData) {
-    if (deleteData && isExternal(tbl)) {
+    if (deleteData && MetaStoreUtils.isExternalTable(tbl)) {
       // External table data can be deleted if EXTERNAL_TABLE_PURGE is true
-      return isExternalTablePurge(tbl);
+      return MetaStoreUtils.isExternalTablePurge(tbl);
     }
     return deleteData;
   }
@@ -3413,21 +3415,6 @@ private void truncateDataFiles(Path location, boolean isSkipTrash, boolean needC
     }
   }
 
-  /**
-   * Is this an external table?
-   *
-   * @param table
-   *          Check if this table is external.
-   * @return True if the table is external, otherwise false.
-   */
-  private boolean isExternal(Table table) {
-    return MetaStoreUtils.isExternalTable(table);
-  }
-
-  private boolean isExternalTablePurge(Table table) {
-    return MetaStoreUtils.isExternalTablePurge(table);
-  }
-
   @Override
   @Deprecated
   public Table get_table(final String dbname, final String name) throws MetaException,
@@ -5151,9 +5138,10 @@ public DropPartitionsResult drop_partitions_req(
         for (DropPartitionsExpr expr : spec.getExprs()) {
           ++minCount; // At least one partition per expression, if not ifExists
           List<Partition> result = new ArrayList<>();
-          boolean hasUnknown = ms.getPartitionsByExpr(
-              catName, dbName, tblName, expr.getExpr(), null,
-              (short)-1, result, request.isSkipColumnSchemaForPartition());
+          boolean hasUnknown = ms.getPartitionsByExpr(catName, dbName, tblName, result,
+              new GetPartitionsArgs.GetPartitionsArgsBuilder()
+                  .expr(expr.getExpr()).skipColumnSchemaForPartition(request.isSkipColumnSchemaForPartition())
+                  .build());
           if (hasUnknown) {
             // Expr is built by DDLSA, it should only contain part cols and simple ops
             throw new MetaException("Unexpected unknown partitions to drop");
@@ -5174,8 +5162,10 @@ public DropPartitionsResult drop_partitions_req(
       } else if (spec.isSetNames()) {
         partNames = spec.getNames();
         minCount = partNames.size();
-        parts = ms.getPartitionsByNames(catName, dbName, tblName, partNames,
-                request.isSkipColumnSchemaForPartition());
+        parts = ms.getPartitionsByNames(catName, dbName, tblName,
+            new GetPartitionsArgs.GetPartitionsArgsBuilder()
+                .partNames(partNames).skipColumnSchemaForPartition(request.isSkipColumnSchemaForPartition())
+                .build());
       } else {
         throw new MetaException("Partition spec is not set");
       }
@@ -5491,12 +5481,12 @@ public Partition get_partition_with_auth(final String db_name,
   @Deprecated
   public List<Partition> get_partitions(final String db_name, final String tbl_name,
                                         final short max_parts) throws NoSuchObjectException, MetaException {
-    return get_partitions(db_name, tbl_name, max_parts, false);
-
+    return get_partitions(db_name, tbl_name,
+        new GetPartitionsArgs.GetPartitionsArgsBuilder().max(max_parts).build());
   }
 
   private List<Partition> get_partitions(final String db_name, final String tbl_name,
-    final short max_parts, boolean skipColumnSchemaForPartition) throws NoSuchObjectException, MetaException {
+    GetPartitionsArgs args) throws NoSuchObjectException, MetaException {
     String[] parsedDbName = parseDbName(db_name, conf);
     startTableFunction("get_partitions", parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tbl_name);
     fireReadTablePreEvent(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tbl_name);
@@ -5504,12 +5494,11 @@ private List<Partition> get_partitions(final String db_name, final String tbl_na
     Exception ex = null;
     try {
       checkLimitNumberOfPartitionsByFilter(parsedDbName[CAT_NAME], parsedDbName[DB_NAME],
-          tbl_name, NO_FILTER_STRING, max_parts);
+          tbl_name, NO_FILTER_STRING, args.getMax());
 
       authorizeTableForPartitionMetadata(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tbl_name);
 
-      ret = getMS().getPartitions(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tbl_name,
-          max_parts, skipColumnSchemaForPartition);
+      ret = getMS().getPartitions(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tbl_name, args);
       ret = FilterUtils.filterPartitionsIfEnabled(isServerFilterEnabled, filterHook, ret);
     } catch (Exception e) {
       ex = e;
@@ -5525,8 +5514,13 @@ private List<Partition> get_partitions(final String db_name, final String tbl_na
   public PartitionsResponse get_partitions_req(PartitionsRequest req)
       throws NoSuchObjectException, MetaException, TException {
     String dbName = MetaStoreUtils.prependCatalogToDbName(req.getCatName(), req.getDbName(), conf);
-    List<Partition> partitions = get_partitions(dbName, req.getTblName(), req.getMaxParts(),
-            req.isSkipColumnSchemaForPartition());
+    List<Partition> partitions = get_partitions(dbName, req.getTblName(),
+        new GetPartitionsArgs.GetPartitionsArgsBuilder()
+            .max(req.getMaxParts())
+            .includeParamKeyPattern(req.getIncludeParamKeyPattern())
+            .excludeParamKeyPattern(req.getExcludeParamKeyPattern())
+            .skipColumnSchemaForPartition(req.isSkipColumnSchemaForPartition())
+            .build());
     PartitionsResponse res = new PartitionsResponse();
     res.setPartitions(partitions);
     return res;
@@ -5537,36 +5531,10 @@ public PartitionsResponse get_partitions_req(PartitionsRequest req)
   public List<Partition> get_partitions_with_auth(final String dbName,
       final String tblName, final short maxParts, final String userName,
       final List<String> groupNames) throws TException {
-    return get_partitions_with_auth_optional_schema(dbName, tblName, maxParts, userName, groupNames , false);
-
-  }
-
-  private List<Partition> get_partitions_with_auth_optional_schema(final String dbName,
-      final String tblName, final short maxParts, final String userName,
-      final List<String> groupNames, boolean skipColSchemaForPartitions) throws TException {
-    String[] parsedDbName = parseDbName(dbName, conf);
-    startTableFunction("get_partitions_with_auth", parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tblName);
-
-    List<Partition> ret = null;
-    Exception ex = null;
-    try {
-      checkLimitNumberOfPartitionsByFilter(parsedDbName[CAT_NAME], parsedDbName[DB_NAME],
-          tblName, NO_FILTER_STRING, maxParts);
-
-      authorizeTableForPartitionMetadata(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tblName);
-
-      ret = getMS().getPartitionsWithAuth(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tblName,
-          maxParts, userName, groupNames, skipColSchemaForPartitions);
-      ret = FilterUtils.filterPartitionsIfEnabled(isServerFilterEnabled, filterHook, ret);
-    } catch (Exception e) {
-      ex = e;
-      handleException(e).convertIfInstance(InvalidObjectException.class, NoSuchObjectException.class)
-          .rethrowException(e);
-    } finally {
-      endFunction("get_partitions_with_auth", ret != null, ex, tblName);
-    }
-    return ret;
-
+    return get_partitions_ps_with_auth(dbName, tblName,
+        new GetPartitionsArgs.GetPartitionsArgsBuilder()
+            .max(maxParts).userName(userName).groupNames(groupNames)
+            .build());
   }
 
   private void checkLimitNumberOfPartitionsByFilter(String catName, String dbName,
@@ -6601,8 +6569,9 @@ public List<Partition> get_partitions_ps(final String db_name,
     try {
       authorizeTableForPartitionMetadata(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tbl_name);
       // Don't send the parsedDbName, as this method will parse itself.
-      ret = get_partitions_ps_with_auth(db_name, tbl_name, part_vals,
-          max_parts, null, null);
+      ret = get_partitions_ps_with_auth(db_name, tbl_name, new GetPartitionsArgs.GetPartitionsArgsBuilder()
+          .part_vals(part_vals).max(max_parts)
+          .build());
       ret = FilterUtils.filterPartitionsIfEnabled(isServerFilterEnabled, filterHook, ret);
     } catch (Exception e) {
       ex = e;
@@ -6624,25 +6593,30 @@ public List<Partition> get_partitions_ps_with_auth(final String db_name,
       final String tbl_name, final List<String> part_vals,
       final short max_parts, final String userName,
       final List<String> groupNames) throws TException {
-    return get_partitions_ps_with_auth(db_name, tbl_name, part_vals, max_parts, userName, groupNames, false);
+    return get_partitions_ps_with_auth(db_name, tbl_name, new GetPartitionsArgs.GetPartitionsArgsBuilder()
+            .part_vals(part_vals).max(max_parts).userName(userName).groupNames(groupNames)
+            .build());
   }
 
   private List<Partition> get_partitions_ps_with_auth(final String db_name,
-      final String tbl_name, final List<String> part_vals,
-      final short max_parts, final String userName,
-      final List<String> groupNames, boolean skipColSchemaForPartitions) throws TException {
+      final String tbl_name, GetPartitionsArgs args) throws TException {
     String[] parsedDbName = parseDbName(db_name, conf);
     startPartitionFunction("get_partitions_ps_with_auth", parsedDbName[CAT_NAME],
-        parsedDbName[DB_NAME], tbl_name, part_vals);
+        parsedDbName[DB_NAME], tbl_name, args.getPart_vals());
     fireReadTablePreEvent(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tbl_name);
     List<Partition> ret = null;
     Exception ex = null;
     try {
-      checkLimitNumberOfPartitionsByPs(parsedDbName[CAT_NAME], parsedDbName[DB_NAME],
-              tbl_name, part_vals, max_parts);
+      if (args.getPart_vals() != null) {
+        checkLimitNumberOfPartitionsByPs(parsedDbName[CAT_NAME], parsedDbName[DB_NAME],
+            tbl_name, args.getPart_vals(), args.getMax());
+      } else {
+        checkLimitNumberOfPartitionsByFilter(parsedDbName[CAT_NAME], parsedDbName[DB_NAME],
+            tbl_name, NO_FILTER_STRING, args.getMax());
+      }
       authorizeTableForPartitionMetadata(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tbl_name);
       ret = getMS().listPartitionsPsWithAuth(parsedDbName[CAT_NAME], parsedDbName[DB_NAME],
-          tbl_name, part_vals, max_parts, userName, groupNames, skipColSchemaForPartitions);
+          tbl_name, args);
       ret = FilterUtils.filterPartitionsIfEnabled(isServerFilterEnabled, filterHook, ret);
     } catch (Exception e) {
       ex = e;
@@ -6657,15 +6631,14 @@ private List<Partition> get_partitions_ps_with_auth(final String db_name,
   public GetPartitionsPsWithAuthResponse get_partitions_ps_with_auth_req(GetPartitionsPsWithAuthRequest req)
       throws MetaException, NoSuchObjectException, TException {
     String dbName = MetaStoreUtils.prependCatalogToDbName(req.getCatName(), req.getDbName(), conf);
-    List<Partition> partitions = null;
-    if (req.getPartVals() == null) {
-      partitions = get_partitions_with_auth_optional_schema(dbName, req.getTblName(), req.getMaxParts(), req.getUserName(),
-          req.getGroupNames(), req.isSkipColumnSchemaForPartition());
-    } else {
-      partitions =
-          get_partitions_ps_with_auth(dbName, req.getTblName(), req.getPartVals(), req.getMaxParts(),
-              req.getUserName(), req.getGroupNames(), req.isSkipColumnSchemaForPartition());
-    }
+    List<Partition> partitions =
+        get_partitions_ps_with_auth(dbName, req.getTblName(), new GetPartitionsArgs.GetPartitionsArgsBuilder()
+            .part_vals(req.getPartVals()).max(req.getMaxParts())
+            .userName(req.getUserName()).groupNames(req.getGroupNames())
+            .skipColumnSchemaForPartition(req.isSkipColumnSchemaForPartition())
+            .includeParamKeyPattern(req.getIncludeParamKeyPattern())
+            .excludeParamKeyPattern(req.getExcludeParamKeyPattern())
+            .build());
     GetPartitionsPsWithAuthResponse res = new GetPartitionsPsWithAuthResponse();
     res.setPartitions(partitions);
     return res;
@@ -7245,12 +7218,12 @@ public List<Partition> get_partitions_by_filter(final String dbName, final Strin
                                                   final String filter, final short maxParts)
       throws TException {
     String[] parsedDbName = parseDbName(dbName, conf);
-    return get_partitions_by_filter_internal(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tblName, filter, maxParts, false);
+    return get_partitions_by_filter_internal(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], tblName,
+        new GetPartitionsArgs.GetPartitionsArgsBuilder().filter(filter).max(maxParts).build());
   }
 
   private List<Partition> get_partitions_by_filter_internal(final String catName,
-      final String dbName, final String tblName, final String filter, final short maxParts,
-      boolean skipColSchemaForPartitions) throws TException {
+      final String dbName, final String tblName, GetPartitionsArgs args) throws TException {
     startTableFunction("get_partitions_by_filter", catName, dbName,
         tblName);
     fireReadTablePreEvent(catName, dbName, tblName);
@@ -7258,12 +7231,11 @@ private List<Partition> get_partitions_by_filter_internal(final String catName,
     Exception ex = null;
     try {
       checkLimitNumberOfPartitionsByFilter(catName, dbName,
-          tblName, filter, maxParts);
+          tblName, args.getFilter(), args.getMax());
 
       authorizeTableForPartitionMetadata(catName, dbName, tblName);
 
-      ret = getMS().getPartitionsByFilter(catName, dbName, tblName,
-          filter, maxParts, skipColSchemaForPartitions);
+      ret = getMS().getPartitionsByFilter(catName, dbName, tblName, args);
       ret = FilterUtils.filterPartitionsIfEnabled(isServerFilterEnabled, filterHook, ret);
     } catch (Exception e) {
       ex = e;
@@ -7275,8 +7247,13 @@ private List<Partition> get_partitions_by_filter_internal(final String catName,
   }
 
   public List<Partition> get_partitions_by_filter_req(GetPartitionsByFilterRequest req) throws TException {
-    return get_partitions_by_filter_internal(req.getCatName(), req.getDbName(), req.getTblName(), req.getFilter(),
-            req.getMaxParts(), req.isSkipColumnSchemaForPartition());
+    return get_partitions_by_filter_internal(req.getCatName(), req.getDbName(), req.getTblName(),
+        new GetPartitionsArgs.GetPartitionsArgsBuilder()
+            .filter(req.getFilter()).max(req.getMaxParts())
+            .skipColumnSchemaForPartition(req.isSkipColumnSchemaForPartition())
+            .excludeParamKeyPattern(req.getExcludeParamKeyPattern())
+            .includeParamKeyPattern(req.getIncludeParamKeyPattern())
+            .build());
   }
 
   @Override
@@ -7327,8 +7304,13 @@ public PartitionsSpecByExprResult get_partitions_spec_by_expr(
     try {
       checkLimitNumberOfPartitionsByExpr(catName, dbName, tblName, req.getExpr(), UNLIMITED_MAX_PARTITIONS);
       List<Partition> partitions = new LinkedList<>();
-      boolean hasUnknownPartitions = getMS().getPartitionsByExpr(catName, dbName, tblName,
-          req.getExpr(), req.getDefaultPartitionName(), req.getMaxParts(), partitions);
+      boolean hasUnknownPartitions = getMS().getPartitionsByExpr(catName, dbName, tblName, partitions,
+          new GetPartitionsArgs.GetPartitionsArgsBuilder()
+              .expr(req.getExpr()).max(req.getMaxParts()).defaultPartName(req.getDefaultPartitionName())
+              .skipColumnSchemaForPartition(req.isSkipColumnSchemaForPartition())
+              .includeParamKeyPattern(req.getIncludeParamKeyPattern())
+              .excludeParamKeyPattern(req.getExcludeParamKeyPattern())
+              .build());
       Table table = get_table_core(catName, dbName, tblName);
       List<PartitionSpec> partitionSpecs =
           MetaStoreServerUtils.getPartitionspecsGroupedByStorageDescriptor(table, partitions);
@@ -7354,9 +7336,13 @@ public PartitionsByExprResult get_partitions_by_expr(
     try {
       checkLimitNumberOfPartitionsByExpr(catName, dbName, tblName, req.getExpr(), UNLIMITED_MAX_PARTITIONS);
       List<Partition> partitions = new LinkedList<>();
-      boolean hasUnknownPartitions = getMS().getPartitionsByExpr(catName, dbName, tblName,
-          req.getExpr(), req.getDefaultPartitionName(), req.getMaxParts(), partitions,
-          req.isSkipColumnSchemaForPartition());
+      boolean hasUnknownPartitions = getMS().getPartitionsByExpr(catName, dbName, tblName, partitions,
+          new GetPartitionsArgs.GetPartitionsArgsBuilder()
+              .expr(req.getExpr()).defaultPartName(req.getDefaultPartitionName()).max(req.getMaxParts())
+              .skipColumnSchemaForPartition(req.isSkipColumnSchemaForPartition())
+              .excludeParamKeyPattern(req.getExcludeParamKeyPattern())
+              .includeParamKeyPattern(req.getIncludeParamKeyPattern())
+              .build());
       ret = new PartitionsByExprResult(partitions, hasUnknownPartitions);
     } catch (Exception e) {
       ex = e;
@@ -7434,31 +7420,30 @@ private int getNumPartitionsByPs(final String catName, final String dbName,
   public List<Partition> get_partitions_by_names(final String dbName, final String tblName,
                                                  final List<String> partNames)
       throws TException {
-    return get_partitions_by_names(dbName, tblName, partNames, false, null, null, false);
+    return get_partitions_by_names(dbName, tblName, false, null, null, null,
+        new GetPartitionsArgs.GetPartitionsArgsBuilder().partNames(partNames).build());
   }
 
   @Override
   public GetPartitionsByNamesResult get_partitions_by_names_req(GetPartitionsByNamesRequest gpbnr)
       throws TException {
     List<Partition> partitions = get_partitions_by_names(gpbnr.getDb_name(),
-        gpbnr.getTbl_name(), gpbnr.getNames(),
+        gpbnr.getTbl_name(),
         gpbnr.isSetGet_col_stats() && gpbnr.isGet_col_stats(), gpbnr.getEngine(),
-        gpbnr.getProcessorCapabilities(), gpbnr.getProcessorIdentifier(), gpbnr.isSkipColumnSchemaForPartition());
+        gpbnr.getProcessorCapabilities(), gpbnr.getProcessorIdentifier(),
+        new GetPartitionsArgs.GetPartitionsArgsBuilder()
+            .partNames(gpbnr.getNames()).skipColumnSchemaForPartition(gpbnr.isSkipColumnSchemaForPartition())
+            .excludeParamKeyPattern(gpbnr.getExcludeParamKeyPattern())
+            .includeParamKeyPattern(gpbnr.getIncludeParamKeyPattern())
+            .build());
     GetPartitionsByNamesResult result = new GetPartitionsByNamesResult(partitions);
     return result;
   }
 
   public List<Partition> get_partitions_by_names(final String dbName, final String tblName,
-      final List<String> partNames, boolean getColStats, String engine, String validWriteIdList,
-      boolean skipColSchemaForPartitions) throws TException {
-    return get_partitions_by_names(
-        dbName, tblName, partNames, getColStats, engine, null, null, skipColSchemaForPartitions);
-  }
-
-  public List<Partition> get_partitions_by_names(final String dbName, final String tblName,
-      final List<String> partNames, boolean getColStats, String engine,
+      boolean getColStats, String engine,
       List<String> processorCapabilities, String processorId,
-      boolean skipColSchemaForPartitions) throws TException {
+      GetPartitionsArgs args) throws TException {
 
     String[] dbNameParts = parseDbName(dbName, conf);
     String parsedCatName = dbNameParts[CAT_NAME];
@@ -7475,7 +7460,7 @@ public List<Partition> get_partitions_by_names(final String dbName, final String
 
       fireReadTablePreEvent(parsedCatName, parsedDbName, tblName);
 
-      ret = getMS().getPartitionsByNames(parsedCatName, parsedDbName, tblName, partNames, skipColSchemaForPartitions);
+      ret = getMS().getPartitionsByNames(parsedCatName, parsedDbName, tblName, args);
       ret = FilterUtils.filterPartitionsIfEnabled(isServerFilterEnabled, filterHook, ret);
       table = getTable(parsedCatName, parsedDbName, tblName);
 
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java
index 6f04fd0372..9795666079 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java
@@ -89,6 +89,7 @@
 import org.apache.hadoop.hive.metastore.api.SkewedInfo;
 import org.apache.hadoop.hive.metastore.api.StorageDescriptor;
 import org.apache.hadoop.hive.metastore.api.Table;
+import org.apache.hadoop.hive.metastore.client.builder.GetPartitionsArgs;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf.ConfVars;
 import org.apache.hadoop.hive.metastore.model.MConstraint;
@@ -388,7 +389,7 @@ public Database getDatabase(String catName, String dbName) throws MetaException{
     String queryTextDbSelector= "select "
         + "\"DB_ID\", \"NAME\", \"DB_LOCATION_URI\", \"DESC\", "
         + "\"OWNER_NAME\", \"OWNER_TYPE\", \"CTLG_NAME\" , \"CREATE_TIME\", \"DB_MANAGED_LOCATION_URI\", "
-        + "\"TYPE\", \"DATACONNECTOR_NAME\", \"REMOTE_DBNAME\""
+        + "\"TYPE\", \"DATACONNECTOR_NAME\", \"REMOTE_DBNAME\" "
         + "FROM "+ DBS
         + " where \"NAME\" = ? and \"CTLG_NAME\" = ? ";
     String queryTextDbParams = "select \"PARAM_KEY\", \"PARAM_VALUE\" "
@@ -661,13 +662,13 @@ public List<String> getPartitionNamesViaSql(SqlFilterForPushdown filter, List<Fi
    * @param catName Metastore catalog name.
    * @param dbName Metastore db name.
    * @param tblName Metastore table name.
-   * @param partNames Partition names to get.
-   * @param skipColSchemaForPartitions skip column schema for partitions
+   * @param args additional arguments for getting partitions
    * @return List of partitions.
    */
-  public List<Partition> getPartitionsViaSqlFilter(final String catName, final String dbName,
-      final String tblName, List<String> partNames, boolean skipColSchemaForPartitions)
+  public List<Partition> getPartitionsViaPartNames(final String catName, final String dbName,
+      final String tblName, GetPartitionsArgs args)
       throws MetaException {
+    List<String> partNames = args.getPartNames();
     if (partNames.isEmpty()) {
       return Collections.emptyList();
     }
@@ -681,7 +682,7 @@ public List<Partition> run(List<String> input) throws MetaException {
           return Collections.emptyList(); // no partitions, bail early.
         }
         return getPartitionsFromPartitionIds(catName, dbName, tblName, null,
-                partitionIds, Collections.emptyList(), skipColSchemaForPartitions);
+                partitionIds, Collections.emptyList(), false, args);
       }
     });
   }
@@ -689,17 +690,16 @@ public List<Partition> run(List<String> input) throws MetaException {
   /**
    * Gets partitions by using direct SQL queries.
    * @param filter The filter.
-   * @param max The maximum number of partitions to return.
    * @param isAcidTable True if the table is ACID
-   * @param skipColSchemaForPartitions skip column schema for partitions
+   * @param args additional arguments for getting partitions
    * @return List of partitions.
    */
   public List<Partition> getPartitionsViaSqlFilter(String catName, String dbName, String tableName,
-      SqlFilterForPushdown filter, Integer max, boolean isAcidTable,
-      boolean skipColSchemaForPartitions) throws MetaException {
+      SqlFilterForPushdown filter, boolean isAcidTable,
+      GetPartitionsArgs args) throws MetaException {
     List<Long> partitionIds = getPartitionIdsViaSqlFilter(catName,
         dbName, tableName, filter.filter, filter.params,
-        filter.joins, max);
+        filter.joins, args.getMax());
     if (partitionIds.isEmpty()) {
       return Collections.emptyList(); // no partitions, bail early.
     }
@@ -707,7 +707,7 @@ public List<Partition> getPartitionsViaSqlFilter(String catName, String dbName,
       @Override
       public List<Partition> run(List<Long> input) throws MetaException {
         return getPartitionsFromPartitionIds(catName, dbName,
-            tableName, null, input, Collections.emptyList(), isAcidTable, skipColSchemaForPartitions);
+            tableName, null, input, Collections.emptyList(), isAcidTable, args);
       }
     });
   }
@@ -846,14 +846,13 @@ public boolean generateSqlFilterForPushdown(String catName, String dbName, Strin
    * @param catName Metastore catalog name.
    * @param dbName Metastore db name.
    * @param tblName Metastore table name.
-   * @param max The maximum number of partitions to return.
-   * @param skipColumnSchemaForPartition skip column schema for partitions
+   * @param args additional arguments for getting partitions
    * @return List of partitions.
    */
   public List<Partition> getPartitions(String catName,
-      String dbName, String tblName, Integer max, boolean skipColumnSchemaForPartition) throws MetaException {
+      String dbName, String tblName, GetPartitionsArgs args) throws MetaException {
     List<Long> partitionIds = getPartitionIdsViaSqlFilter(catName, dbName,
-        tblName, null, Collections.<String>emptyList(), Collections.<String>emptyList(), max);
+        tblName, null, Collections.<String>emptyList(), Collections.<String>emptyList(), args.getMax());
     if (partitionIds.isEmpty()) {
       return Collections.emptyList(); // no partitions, bail early.
     }
@@ -862,8 +861,7 @@ public List<Partition> getPartitions(String catName,
     List<Partition> result = Batchable.runBatched(batchSize, partitionIds, new Batchable<Long, Partition>() {
       @Override
       public List<Partition> run(List<Long> input) throws MetaException {
-        return getPartitionsFromPartitionIds(catName, dbName, tblName, null, input, Collections.emptyList(),
-                skipColumnSchemaForPartition);
+        return getPartitionsFromPartitionIds(catName, dbName, tblName, null, input, Collections.emptyList(), false, args);
       }
     });
     return result;
@@ -947,17 +945,10 @@ private List<Long> getPartitionIdsViaSqlFilter(
     }
   }
 
-  /** Should be called with the list short enough to not trip up Oracle/etc. */
-  private List<Partition> getPartitionsFromPartitionIds(String catName, String dbName, String tblName,
-      Boolean isView, List<Long> partIdList, List<String> projectionFields, boolean skipColumnSchemaForPartition) throws MetaException {
-    return getPartitionsFromPartitionIds(catName, dbName, tblName, isView, partIdList,
-            projectionFields, false, skipColumnSchemaForPartition);
-  }
-
   /** Should be called with the list short enough to not trip up Oracle/etc. */
   private List<Partition> getPartitionsFromPartitionIds(String catName, String dbName, String tblName,
       Boolean isView, List<Long> partIdList, List<String> projectionFields,
-      boolean isAcidTable, boolean skipColumnSchemaForPartition) throws MetaException {
+      boolean isAcidTable, GetPartitionsArgs args) throws MetaException {
 
     boolean doTrace = LOG.isDebugEnabled();
 
@@ -1093,7 +1084,8 @@ private List<Partition> getPartitionsFromPartitionIds(String catName, String dbN
     }
     // Now get all the one-to-many things. Start with partitions.
     MetastoreDirectSqlUtils
-        .setPartitionParameters(PARTITION_PARAMS, convertMapNullsToEmptyStrings, pm, partIds, partitions);
+        .setPartitionParametersWithFilter(PARTITION_PARAMS, convertMapNullsToEmptyStrings, pm,
+            partIds, partitions, args.getIncludeParamKeyPattern(), args.getExcludeParamKeyPattern());
 
     MetastoreDirectSqlUtils.setPartitionValues(PARTITION_KEY_VALS, pm, partIds, partitions);
 
@@ -1136,7 +1128,7 @@ private List<Partition> getPartitionsFromPartitionIds(String catName, String dbN
     } // if (hasSkewedColumns)
 
     // Get FieldSchema stuff if any.
-    if (!colss.isEmpty() && !skipColumnSchemaForPartition) {
+    if (!colss.isEmpty() && !args.isSkipColumnSchemaForPartition()) {
       // We are skipping the CDS table here, as it seems to be totally useless.
       MetastoreDirectSqlUtils.setSDCols(COLUMNS_V2, pm, colss, colIds);
     }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDirectSqlUtils.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDirectSqlUtils.java
index b309997731..067e415d72 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDirectSqlUtils.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDirectSqlUtils.java
@@ -167,24 +167,6 @@ static <T> int loopJoinOrderedResult(PersistenceManager pm, TreeMap<Long, T> tre
     return rv;
   }
 
-  static void setPartitionParameters(String PARTITION_PARAMS, boolean convertMapNullsToEmptyStrings,
-      PersistenceManager pm, String partIds, TreeMap<Long, Partition> partitions)
-      throws MetaException {
-    String queryText;
-    queryText = "select \"PART_ID\", \"PARAM_KEY\", \"PARAM_VALUE\" from " + PARTITION_PARAMS + ""
-        + " where \"PART_ID\" in (" + partIds + ") and \"PARAM_KEY\" is not null"
-        + " order by \"PART_ID\" asc";
-    loopJoinOrderedResult(pm, partitions, queryText, 0, new ApplyFunc<Partition>() {
-      @Override
-      public void apply(Partition t, Object[] fields) {
-        t.putToParameters(extractSqlClob(fields[1]), extractSqlClob(fields[2]));
-      }});
-    // Perform conversion of null map values
-    for (Partition t : partitions.values()) {
-      t.setParameters(MetaStoreServerUtils.trimMapNulls(t.getParameters(), convertMapNullsToEmptyStrings));
-    }
-  }
-
   static void setPartitionParametersWithFilter(String PARTITION_PARAMS,
       boolean convertMapNullsToEmptyStrings, PersistenceManager pm, String partIds,
       TreeMap<Long, Partition> partitions, String includeParamKeyPattern, String excludeParamKeyPattern)
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java
index 05a421e93f..fa13262993 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java
@@ -58,6 +58,7 @@
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.locks.Lock;
 import java.util.regex.Pattern;
+import java.util.stream.Collectors;
 
 import javax.jdo.JDODataStoreException;
 import javax.jdo.JDOException;
@@ -192,6 +193,7 @@
 import org.apache.hadoop.hive.metastore.api.WMTrigger;
 import org.apache.hadoop.hive.metastore.api.WMValidateResourcePlanResponse;
 import org.apache.hadoop.hive.metastore.api.WriteEventInfo;
+import org.apache.hadoop.hive.metastore.client.builder.GetPartitionsArgs;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf.ConfVars;
 import org.apache.hadoop.hive.metastore.metrics.Metrics;
@@ -2262,9 +2264,38 @@ private <T> List<T> convertList(List<T> dnList) {
   }
 
   /** Makes shallow copy of a map to avoid DataNucleus mucking with our objects. */
-  private Map<String, String> convertMap(Map<String, String> dnMap) {
-    return MetaStoreServerUtils.trimMapNulls(dnMap,
+  private Map<String, String> convertMap(Map<String, String> dnMap, GetPartitionsArgs... args) {
+    Map<String, String> parameters = MetaStoreServerUtils.trimMapNulls(dnMap,
         MetastoreConf.getBoolVar(getConf(), ConfVars.ORM_RETRIEVE_MAPNULLS_AS_EMPTY_STRINGS));
+    if (parameters != null && args != null && args.length == 1) {
+      // Pattern matching in Java might be different from the one used by the metastore backends,
+      // An underscore (_) in pattern stands for (matches) any single character;
+      // a percent sign (%) matches any sequence of zero or more characters.
+      // See TestGetPartitionsUsingProjectionAndFilterSpecs#testPartitionProjectionEmptySpec.
+      Pattern includePatt = null;
+      if (StringUtils.isNotBlank(args[0].getIncludeParamKeyPattern())) {
+        includePatt = Optional.of(args[0].getIncludeParamKeyPattern()).map(regex ->
+            Pattern.compile(regex.replaceAll("%", ".*").replaceAll("_", "."))).get();
+      }
+      Pattern excludePatt = null;
+      if (StringUtils.isNotBlank(args[0].getExcludeParamKeyPattern())) {
+        excludePatt = Optional.of(args[0].getExcludeParamKeyPattern()).map(regex ->
+            Pattern.compile(regex.replaceAll("%", ".*").replaceAll("_", "."))).get();;
+      }
+      final Pattern includePattern = includePatt;
+      final Pattern excludePattern = excludePatt;
+      return parameters.entrySet().stream().filter(entry -> {
+        boolean matches = true;
+        if (includePattern != null) {
+          matches &= includePattern.matcher(entry.getKey()).matches();
+        }
+        if (excludePattern != null) {
+          matches &= !excludePattern.matcher(entry.getKey()).matches();
+        }
+        return matches;
+      }).collect(Collectors.toMap(x -> x.getKey(), x -> x.getValue()));
+    }
+    return parameters;
   }
 
   private Table convertToTable(MTable mtbl) throws MetaException {
@@ -2866,7 +2897,8 @@ public Partition getPartition(String catName, String dbName, String tableName,
             " does not exist");
       }
       MPartition mpart = getMPartition(catName, dbName, tableName, part_vals, table);
-      part = convertToPart(mpart, false);
+      part = convertToPart(catName, dbName, tableName, mpart,
+          TxnUtils.isAcidTable(table.getParameters()));
       committed = commitTransaction();
       if (part == null) {
         throw new NoSuchObjectException("partition values="
@@ -3031,45 +3063,20 @@ private MPartition convertToMPart(Partition part, MTable mt, boolean useTableCD)
         msd, part.getParameters());
   }
 
-  private Partition convertToPart(MPartition mpart, boolean isAcidTable) throws MetaException {
-    return convertToPart(mpart, isAcidTable, false);
-  }
-
-  private Partition convertToPart(MPartition mpart, boolean isAcidTable,
-      boolean skipColSchemaForPartitions) throws MetaException {
-    if (mpart == null) {
-      return null;
-    }
-    //its possible that MPartition is partially filled, do null checks to avoid NPE
-    MTable table = mpart.getTable();
-    String dbName =
-        table == null ? null : table.getDatabase() == null ? null : table.getDatabase().getName();
-    String tableName = table == null ? null : table.getTableName();
-    String catName = table == null ? null :
-        table.getDatabase() == null ? null : table.getDatabase().getCatalogName();
-    Map<String,String> params = convertMap(mpart.getParameters());
-    Partition p = new Partition(convertList(mpart.getValues()), dbName, tableName, mpart.getCreateTime(),
-        mpart.getLastAccessTime(), convertToStorageDescriptor(mpart.getSd(), skipColSchemaForPartitions, isAcidTable),
-        params);
-    p.setCatName(catName);
-    if(mpart.getWriteId()>0) {
-      p.setWriteId(mpart.getWriteId());
-    }else {
-      p.setWriteId(-1L);
-    }
-    return p;
-  }
-
   private Partition convertToPart(String catName, String dbName, String tblName,
-      MPartition mpart, boolean isAcidTable, boolean skipColSchemaForPartitions)
+      MPartition mpart, boolean isAcidTable, GetPartitionsArgs... args)
       throws MetaException {
     if (mpart == null) {
       return null;
     }
-    Map<String,String> params = convertMap(mpart.getParameters());
+    catName = normalizeIdentifier(catName);
+    dbName = normalizeIdentifier(dbName);
+    tblName = normalizeIdentifier(tblName);
+    Map<String,String> params = convertMap(mpart.getParameters(), args);
+    boolean noFS = args != null && args.length == 1 ? args[0].isSkipColumnSchemaForPartition() : false;
     Partition p = new Partition(convertList(mpart.getValues()), dbName, tblName,
         mpart.getCreateTime(), mpart.getLastAccessTime(),
-        convertToStorageDescriptor(mpart.getSd(), skipColSchemaForPartitions, isAcidTable), params);
+        convertToStorageDescriptor(mpart.getSd(), noFS, isAcidTable), params);
     p.setCatName(catName);
     if(mpart.getWriteId()>0) {
       p.setWriteId(mpart.getWriteId());
@@ -3238,7 +3245,7 @@ private boolean dropPartitionCommon(MPartition part) throws MetaException,
 
   @Override
   public List<Partition> getPartitions(String catName, String dbName, String tableName,
-      int maxParts, boolean skipColumnSchemaForPartition) throws MetaException, NoSuchObjectException {
+      GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
     List<Partition> results = Collections.emptyList();
     boolean success = false;
 
@@ -3246,7 +3253,7 @@ public List<Partition> getPartitions(String catName, String dbName, String table
 
     try {
       openTransaction();
-      results = getPartitionsInternal(catName, dbName, tableName, maxParts, true, true, skipColumnSchemaForPartition);
+      results = getPartitionsInternal(catName, dbName, tableName, true, true, args);
       success = commitTransaction();
     } finally {
       if (!success) {
@@ -3297,23 +3304,19 @@ public Map<String, String> getPartitionLocations(String catName, String dbName,
     return partLocations;
   }
 
-  protected List<Partition> getPartitionsInternal(String catName, String dbName, String tblName, final int maxParts,
-      boolean allowSql, boolean allowJdo) throws MetaException, NoSuchObjectException {
-    return getPartitionsInternal(catName, dbName, tblName, maxParts, allowSql, allowJdo, false);
-  }
-
-  private List<Partition> getPartitionsInternal(String catName, String dbName, String tblName, final int maxParts,
-      boolean allowSql, boolean allowJdo, boolean skipColumnSchemaForPartition)
+  protected List<Partition> getPartitionsInternal(String catName, String dbName, String tblName,
+      boolean allowSql, boolean allowJdo, GetPartitionsArgs args)
       throws MetaException, NoSuchObjectException {
     return new GetListHelper<Partition>(catName, dbName, tblName, allowSql, allowJdo) {
       @Override
       protected List<Partition> getSqlResult(GetHelper<List<Partition>> ctx) throws MetaException {
-        return directSql.getPartitions(catName, dbName, tblName, maxParts, skipColumnSchemaForPartition);
+        return directSql.getPartitions(catName, dbName, tblName, args);
       }
       @Override
       protected List<Partition> getJdoResult(GetHelper<List<Partition>> ctx) throws MetaException {
         try {
-          return convertToParts(listMPartitions(catName, dbName, tblName, maxParts), skipColumnSchemaForPartition);
+          return convertToParts(catName, dbName, tblName,
+              listMPartitions(catName, dbName, tblName, args.getMax()), false, args);
         } catch (Exception e) {
           LOG.error("Failed to convert to parts", e);
           throw new MetaException(e.getMessage());
@@ -3322,40 +3325,6 @@ protected List<Partition> getJdoResult(GetHelper<List<Partition>> ctx) throws Me
     }.run(false);
   }
 
-  @Override
-  public List<Partition> getPartitionsWithAuth(String catName, String dbName, String tblName,
-      short max, String userName, List<String> groupNames, boolean skipColumnSchemaForPartition)
-          throws MetaException, InvalidObjectException {
-    boolean success = false;
-
-    try {
-      openTransaction();
-      List<MPartition> mparts = listMPartitions(catName, dbName, tblName, max);
-      List<Partition> parts = new ArrayList<>(mparts.size());
-      if (CollectionUtils.isNotEmpty(mparts)) {
-        for (MPartition mpart : mparts) {
-          MTable mtbl = mpart.getTable();
-          Partition part = convertToPart(mpart, false, skipColumnSchemaForPartition);
-          parts.add(part);
-
-          if ("TRUE".equalsIgnoreCase(mtbl.getParameters().get("PARTITION_LEVEL_PRIVILEGE"))) {
-            String partName = Warehouse.makePartName(this.convertToFieldSchemas(mtbl
-                .getPartitionKeys()), part.getValues());
-            PrincipalPrivilegeSet partAuth = this.getPartitionPrivilegeSet(catName, dbName,
-                tblName, partName, userName, groupNames);
-            part.setPrivileges(partAuth);
-          }
-        }
-      }
-      success =  commitTransaction();
-      return parts;
-    } catch (Exception e) {
-      throw new MetaException(e.getMessage());
-    } finally {
-      rollbackAndCleanup(success, null);
-    }
-  }
-
   @Override
   public Partition getPartitionWithAuth(String catName, String dbName, String tblName,
       List<String> partVals, String user_name, List<String> group_names)
@@ -3370,7 +3339,8 @@ public Partition getPartitionWithAuth(String catName, String dbName, String tblN
             + partVals.toString());
       }
       MTable mtbl = mpart.getTable();
-      Partition part = convertToPart(mpart, false);
+
+      Partition part = convertToPart(catName, dbName, tblName, mpart, TxnUtils.isAcidTable(mtbl.getParameters()));
       if ("TRUE".equalsIgnoreCase(mtbl.getParameters().get("PARTITION_LEVEL_PRIVILEGE"))) {
         String partName = Warehouse.makePartName(this.convertToFieldSchemas(mtbl
             .getPartitionKeys()), partVals);
@@ -3388,32 +3358,12 @@ public Partition getPartitionWithAuth(String catName, String dbName, String tblN
     }
   }
 
-  private List<Partition> convertToParts(List<MPartition> mparts,
-      boolean skipColumnSchemaForPartition) throws MetaException {
-    return convertToParts(mparts, null, skipColumnSchemaForPartition);
-  }
-
-  private List<Partition> convertToParts(List<MPartition> src, List<Partition> dest,
-      boolean skipColumnSchemaForPartition) throws MetaException {
-    if (src == null) {
-      return dest;
-    }
-    if (dest == null) {
-      dest = new ArrayList<>(src.size());
-    }
-    for (MPartition mp : src) {
-      dest.add(convertToPart(mp, false, skipColumnSchemaForPartition));
-      Deadline.checkTimeout();
-    }
-    return dest;
-  }
-
   private List<Partition> convertToParts(String catName, String dbName, String tblName,
-      List<MPartition> mparts, boolean isAcidTable, boolean skipColumnSchemaForPartition)
+      List<MPartition> mparts, boolean isAcidTable, GetPartitionsArgs args)
       throws MetaException {
     List<Partition> parts = new ArrayList<>(mparts.size());
     for (MPartition mp : mparts) {
-      parts.add(convertToPart(catName, dbName, tblName, mp, isAcidTable, skipColumnSchemaForPartition));
+      parts.add(convertToPart(catName, dbName, tblName, mp, isAcidTable, args));
       Deadline.checkTimeout();
     }
     return parts;
@@ -3862,7 +3812,7 @@ public int getNumPartitionsByPs(String catName, String dbName, String tblName, L
    *          has types of String, and if resultsCol is null, the types are MPartition.
    */
   private Collection<String> getPartitionPsQueryResults(String catName, String dbName, String tableName, List<String> part_vals,
-      short max_parts, String resultsCol) throws Exception {
+      int max_parts, String resultsCol) throws Exception {
 
     Preconditions.checkState(this.currentTransaction.isActive());
 
@@ -3904,8 +3854,8 @@ private Collection<String> getPartitionPsQueryResults(String catName, String dbN
    * doesn't support partition privileges.
    */
   private boolean canTryDirectSQL(List<String> partVals) {
-    if (partVals.isEmpty()) {
-      return false;
+    if (partVals == null || partVals.isEmpty()) {
+      return true;
     }
     for (String val : partVals) {
       if (val != null && !val.isEmpty()) {
@@ -3917,42 +3867,48 @@ private boolean canTryDirectSQL(List<String> partVals) {
 
   @Override
   public List<Partition> listPartitionsPsWithAuth(String catName, String db_name, String tbl_name,
-      List<String> part_vals, short max_parts, String userName, List<String> groupNames,
-      boolean skipColSchemaForPartitions) throws MetaException, InvalidObjectException, NoSuchObjectException {
+      GetPartitionsArgs args) throws MetaException, InvalidObjectException, NoSuchObjectException {
     List<Partition> partitions = new ArrayList<>();
     boolean success = false;
 
     try {
       openTransaction();
-
+      LOG.debug("executing listPartitionNamesPsWithAuth");
       MTable mtbl = getMTable(catName, db_name, tbl_name);
       if (mtbl == null) {
         throw new NoSuchObjectException(
             TableName.getQualified(catName, db_name, tbl_name) + " table not found");
       }
+      int max_parts = args.getMax();
+      String userName = args.getUserName();
+      List<String> groupNames = args.getGroupNames();
+      List<String> part_vals = args.getPart_vals();
       boolean getauth = null != userName && null != groupNames &&
           "TRUE".equalsIgnoreCase(
               mtbl.getParameters().get("PARTITION_LEVEL_PRIVILEGE"));
-      if (!getauth && canTryDirectSQL(part_vals)) {
+
+      if (canTryDirectSQL(part_vals)) {
         LOG.info(
             "Redirecting to directSQL enabled API: db: {} tbl: {} partVals: {}",
-            db_name, tbl_name, Joiner.on(',').join(part_vals));
-        return getPartitions(catName, db_name, tbl_name, max_parts, skipColSchemaForPartitions);
+            db_name, tbl_name, part_vals);
+        partitions = getPartitions(catName, db_name, tbl_name, args);
+      } else {
+        Collection parts = getPartitionPsQueryResults(catName, db_name, tbl_name,
+            part_vals, max_parts, null);
+        boolean isAcidTable = TxnUtils.isAcidTable(mtbl.getParameters());
+        for (Object o : parts) {
+          Partition part = convertToPart(catName, db_name, tbl_name, (MPartition) o, isAcidTable, args);
+          partitions.add(part);
+        }
       }
-      LOG.debug("executing listPartitionNamesPsWithAuth");
-      Collection parts = getPartitionPsQueryResults(catName, db_name, tbl_name,
-          part_vals, max_parts, null);
-      for (Object o : parts) {
-        Partition part = convertToPart((MPartition) o, false, skipColSchemaForPartitions);
-        //set auth privileges
-        if (getauth) {
+      if (getauth) {
+        for (Partition part : partitions) {
           String partName = Warehouse.makePartName(this.convertToFieldSchemas(mtbl
               .getPartitionKeys()), part.getValues());
           PrincipalPrivilegeSet partAuth = getPartitionPrivilegeSet(catName, db_name,
               tbl_name, partName, userName, groupNames);
           part.setPrivileges(partAuth);
         }
-        partitions.add(part);
       }
       success = commitTransaction();
     } catch (InvalidObjectException | NoSuchObjectException | MetaException e) {
@@ -4074,41 +4030,39 @@ private List<MPartition> listMPartitionsWithProjection(List<String> fieldNames,
 
   @Override
   public List<Partition> getPartitionsByNames(String catName, String dbName, String tblName,
-      List<String> partNames, boolean skipColSchemaForPartitions) throws MetaException, NoSuchObjectException {
-    return getPartitionsByNamesInternal(catName, dbName, tblName, partNames, true, true, skipColSchemaForPartitions);
+      GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
+    return getPartitionsByNamesInternal(catName, dbName, tblName, true, true, args);
   }
 
   protected List<Partition> getPartitionsByNamesInternal(String catName, String dbName,
-      String tblName, final List<String> partNames, boolean allowSql, boolean allowJdo,
-      boolean skipColSchemaForPartitions) throws MetaException, NoSuchObjectException {
+      String tblName, boolean allowSql, boolean allowJdo,
+      GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
     return new GetListHelper<Partition>(catName, dbName, tblName, allowSql, allowJdo) {
       @Override
       protected List<Partition> getSqlResult(GetHelper<List<Partition>> ctx) throws MetaException {
-        return directSql.getPartitionsViaSqlFilter(catName, dbName, tblName, partNames, skipColSchemaForPartitions);
+        return directSql.getPartitionsViaPartNames(catName, dbName, tblName, args);
       }
       @Override
       protected List<Partition> getJdoResult(
           GetHelper<List<Partition>> ctx) throws MetaException, NoSuchObjectException {
-        return getPartitionsViaOrmFilter(catName, dbName, tblName, partNames, false, skipColSchemaForPartitions);
+        return getPartitionsViaOrmFilter(catName, dbName, tblName, false, args);
       }
     }.run(false);
   }
 
   @Override
-  public boolean getPartitionsByExpr(String catName, String dbName, String tblName, byte[] expr,
-      String defaultPartitionName, short maxParts, List<Partition> result,
-      boolean skipColSchemaForPartitions) throws TException {
-    return getPartitionsByExprInternal(catName, dbName, tblName, expr, defaultPartitionName, maxParts,
-            result, true, true, skipColSchemaForPartitions);
+  public boolean getPartitionsByExpr(String catName, String dbName, String tblName,
+     List<Partition> result, GetPartitionsArgs args) throws TException {
+    return getPartitionsByExprInternal(catName, dbName, tblName, result, true, true, args);
   }
 
-  protected boolean getPartitionsByExprInternal(String catName, String dbName, String tblName, final byte[] expr,
-      final String defaultPartitionName, final  short maxParts, List<Partition> result,
-      boolean allowSql, boolean allowJdo, boolean skipColSchemaForPartitions) throws TException {
+  protected boolean getPartitionsByExprInternal(String catName, String dbName, String tblName,
+      List<Partition> result, boolean allowSql, boolean allowJdo, GetPartitionsArgs args) throws TException {
     assert result != null;
 
+    byte[] expr = args.getExpr();
     final ExpressionTree exprTree = expr.length != 0 ? PartFilterExprUtil.makeExpressionTree(
-          expressionProxy, expr, getDefaultPartitionName(defaultPartitionName), conf) : ExpressionTree.EMPTY_TREE;
+          expressionProxy, expr, getDefaultPartitionName(args.getDefaultPartName()), conf) : ExpressionTree.EMPTY_TREE;
     final AtomicBoolean hasUnknownPartitions = new AtomicBoolean(false);
 
     catName = normalizeIdentifier(catName);
@@ -4125,17 +4079,18 @@ protected List<Partition> getSqlResult(GetHelper<List<Partition>> ctx) throws Me
         if (exprTree != null) {
           SqlFilterForPushdown filter = new SqlFilterForPushdown();
           if (directSql.generateSqlFilterForPushdown(catName, dbName, tblName, partitionKeys,
-              exprTree, defaultPartitionName, filter)) {
+              exprTree, args.getDefaultPartName(), filter)) {
             String catalogName = (catName != null) ? catName : getDefaultCatalog(conf);
-            return directSql.getPartitionsViaSqlFilter(catalogName, dbName, tblName, filter, null,
-                    isAcidTable, skipColSchemaForPartitions);
+            return directSql.getPartitionsViaSqlFilter(catalogName, dbName, tblName, filter,
+                    isAcidTable, args);
           }
         }
         // We couldn't do SQL filter pushdown. Get names via normal means.
         List<String> partNames = new LinkedList<>();
         hasUnknownPartitions.set(getPartitionNamesPrunedByExprNoTxn(
-                catName, dbName, tblName, partitionKeys, expr, defaultPartitionName, maxParts, partNames));
-        return directSql.getPartitionsViaSqlFilter(catName, dbName, tblName, partNames, skipColSchemaForPartitions);
+                catName, dbName, tblName, partitionKeys, expr, args.getDefaultPartName(), (short) args.getMax(), partNames));
+        GetPartitionsArgs newArgs = new GetPartitionsArgs.GetPartitionsArgsBuilder(args).partNames(partNames).build();
+        return directSql.getPartitionsViaPartNames(catName, dbName, tblName, newArgs);
       }
 
       @Override
@@ -4145,15 +4100,15 @@ protected List<Partition> getJdoResult(
         List<Partition> result = null;
         if (exprTree != null) {
           result = getPartitionsViaOrmFilter(catName, dbName, tblName, exprTree,
-                  maxParts, false, partitionKeys, skipColSchemaForPartitions);
+              false, partitionKeys, isAcidTable, args);
         }
         if (result == null) {
           // We couldn't do JDOQL filter pushdown. Get names via normal means.
           List<String> partNames = new ArrayList<>();
           hasUnknownPartitions.set(getPartitionNamesPrunedByExprNoTxn(
-                  catName, dbName, tblName, partitionKeys, expr, defaultPartitionName, maxParts, partNames));
-          result = getPartitionsViaOrmFilter(catName, dbName, tblName, partNames,
-                  isAcidTable, skipColSchemaForPartitions);
+                  catName, dbName, tblName, partitionKeys, expr, args.getDefaultPartName(), (short) args.getMax(), partNames));
+          GetPartitionsArgs newArgs = new GetPartitionsArgs.GetPartitionsArgsBuilder(args).partNames(partNames).build();
+          result = getPartitionsViaOrmFilter(catName, dbName, tblName, isAcidTable, newArgs);
         }
         return result;
       }
@@ -4201,16 +4156,15 @@ private boolean getPartitionNamesPrunedByExprNoTxn(String catName, String dbName
    * Gets partition names from the table via ORM (JDOQL) filter pushdown.
    * @param tblName The table.
    * @param tree The expression tree from which JDOQL filter will be made.
-   * @param maxParts Maximum number of partitions to return.
    * @param isValidatedFilter Whether the filter was pre-validated for JDOQL pushdown by a client
    *   (old hive client or non-hive one); if it was and we fail to create a filter, we will throw.
-   * @param skipColSchemaForPartitions skip column schema for partitions
+   * @param args additional arguments for getting partitions
    * @return Resulting partitions. Can be null if isValidatedFilter is false, and
    *         there was error deriving the JDO filter.
    */
   private List<Partition> getPartitionsViaOrmFilter(String catName, String dbName, String tblName, ExpressionTree tree,
-      short maxParts, boolean isValidatedFilter, List<FieldSchema> partitionKeys,
-      boolean skipColSchemaForPartitions) throws MetaException {
+      boolean isValidatedFilter, List<FieldSchema> partitionKeys, boolean isAcidTable,
+      GetPartitionsArgs args) throws MetaException {
     Map<String, Object> params = new HashMap<>();
     String jdoFilter =
         makeQueryFilterString(catName, dbName, tblName, tree, params, isValidatedFilter, partitionKeys);
@@ -4219,9 +4173,9 @@ private List<Partition> getPartitionsViaOrmFilter(String catName, String dbName,
       return null;
     }
     try (QueryWrapper query = new QueryWrapper(pm.newQuery(MPartition.class, jdoFilter))) {
-      if (maxParts >= 0) {
+      if (args.getMax() >= 0) {
         // User specified a row limit, set it on the Query
-        query.setRange(0, maxParts);
+        query.setRange(0, args.getMax());
       }
       String parameterDeclaration = makeParameterDeclarationStringObj(params);
       query.declareParameters(parameterDeclaration);
@@ -4230,7 +4184,8 @@ private List<Partition> getPartitionsViaOrmFilter(String catName, String dbName,
       LOG.debug("Done executing query for getPartitionsViaOrmFilter");
       pm.retrieveAll(mparts); // TODO: why is this inconsistent with what we get by names?
       LOG.debug("Done retrieving all objects for getPartitionsViaOrmFilter");
-      List<Partition> results = convertToParts(mparts, skipColSchemaForPartitions);
+      List<Partition> results =
+          convertToParts(catName, dbName, tblName, mparts, isAcidTable, args);
       return results;
     }
   }
@@ -4259,14 +4214,13 @@ private Integer getNumPartitionsViaOrmFilter(String catName, String dbName, Stri
    * Gets partition names from the table via ORM (JDOQL) name filter.
    * @param dbName Database name.
    * @param tblName Table name.
-   * @param partNames Partition names to get the objects for.
    * @param isAcidTable True if the table is ACID
-   * @param skipColSchemaForPartitions skip column schema for partitions
+   * @param args additional arguments for getting partitions
    * @return Resulting partitions.
    */
   private List<Partition> getPartitionsViaOrmFilter(String catName, String dbName, String tblName,
-      List<String> partNames, boolean isAcidTable, boolean skipColSchemaForPartitions) throws MetaException {
-
+      boolean isAcidTable, GetPartitionsArgs args) throws MetaException {
+    List<String> partNames = args.getPartNames();
     if (partNames.isEmpty()) {
       return Collections.emptyList();
     }
@@ -4283,7 +4237,7 @@ public List<Partition> run(List<String> input) throws MetaException {
 
           List<MPartition> mparts = (List<MPartition>) query.executeWithMap(queryWithParams.getRight());
           List<Partition> partitions = convertToParts(catName, dbName, tblName, mparts,
-                  isAcidTable, skipColSchemaForPartitions);
+                  isAcidTable, args);
 
           return partitions;
         }
@@ -4372,9 +4326,8 @@ private Pair<Query, Map<String, String>> getPartQueryWithParams(
 
   @Override
   public List<Partition> getPartitionsByFilter(String catName, String dbName, String tblName,
-      String filter, short maxParts, boolean skipColSchemaForPartitions) throws MetaException, NoSuchObjectException {
-    return getPartitionsByFilterInternal(catName, dbName, tblName, filter, maxParts,
-            true, true, skipColSchemaForPartitions);
+      GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
+    return getPartitionsByFilterInternal(catName, dbName, tblName, true, true, args);
   }
 
   /** Helper class for getting stuff w/transaction, direct SQL, perf logging, etc. */
@@ -4719,8 +4672,8 @@ protected Integer getJdoResult(
   }
 
   protected List<Partition> getPartitionsByFilterInternal(
-      String catName, String dbName, String tblName, String filter, final short maxParts,
-      boolean allowSql, boolean allowJdo, boolean skipColSchemaForPartitions)
+      String catName, String dbName, String tblName,
+      boolean allowSql, boolean allowJdo, GetPartitionsArgs args)
       throws MetaException, NoSuchObjectException {
 
     catName = normalizeIdentifier(catName);
@@ -4730,6 +4683,7 @@ protected List<Partition> getPartitionsByFilterInternal(
     MTable mTable = ensureGetMTable(catName, dbName, tblName);
     List<FieldSchema> partitionKeys = convertToFieldSchemas(mTable.getPartitionKeys());
     boolean isAcidTable = TxnUtils.isAcidTable(mTable.getParameters());
+    String filter = args.getFilter();
     final ExpressionTree tree = (filter != null && !filter.isEmpty())
         ? PartFilterExprUtil.parseFilterTree(filter) : ExpressionTree.EMPTY_TREE;
     return new GetListHelper<Partition>(catName, dbName, tblName, allowSql, allowJdo) {
@@ -4742,15 +4696,14 @@ protected boolean canUseDirectSql(GetHelper<List<Partition>> ctx) throws MetaExc
 
       @Override
       protected List<Partition> getSqlResult(GetHelper<List<Partition>> ctx) throws MetaException {
-        return directSql.getPartitionsViaSqlFilter(catName, dbName, tblName, filter,
-                (maxParts < 0) ? null : (int)maxParts, isAcidTable, skipColSchemaForPartitions);
+        return directSql.getPartitionsViaSqlFilter(catName, dbName, tblName, filter, isAcidTable, args);
       }
 
       @Override
       protected List<Partition> getJdoResult(
           GetHelper<List<Partition>> ctx) throws MetaException, NoSuchObjectException {
-        return getPartitionsViaOrmFilter(catName, dbName, tblName, tree, maxParts, true,
-                partitionKeys, skipColSchemaForPartitions);
+        return getPartitionsViaOrmFilter(catName, dbName, tblName, tree, true,
+                partitionKeys, isAcidTable, args);
       }
     }.run(false);
   }
@@ -4773,8 +4726,11 @@ public List<Partition> getPartitionSpecsByFilterAndProjection(final Table table,
     }
     if (fieldList == null || fieldList.isEmpty()) {
       // no fields are requested. Fallback to regular getPartitions implementation to return all the fields
-      return getPartitionsInternal(table.getCatName(), table.getDbName(), table.getTableName(), -1,
-          true, true);
+      GetPartitionsArgs.GetPartitionsArgsBuilder argsBuilder = new GetPartitionsArgs.GetPartitionsArgsBuilder()
+          .excludeParamKeyPattern(inputExcludePattern)
+          .includeParamKeyPattern(inputIncludePattern);
+      return getPartitionsInternal(table.getCatName(), table.getDbName(), table.getTableName(),
+          true, true, argsBuilder.build());
     }
 
     // anonymous class below requires final String objects
@@ -4864,7 +4820,11 @@ protected List<Partition> getJdoResult(
             params.put("t3", normalizeIdentifier(catName));
           }
         try {
-          return convertToParts(listMPartitionsWithProjection(fieldNames, jdoFilter, params), false);
+          List<MPartition> mparts = listMPartitionsWithProjection(fieldNames, jdoFilter, params);
+          return convertToParts(catName, dbName, tblName, mparts, false, new GetPartitionsArgs.GetPartitionsArgsBuilder()
+              .excludeParamKeyPattern(excludeParamKeyPattern)
+              .includeParamKeyPattern(includeParamKeyPattern)
+              .build());
         } catch (MetaException me) {
           throw me;
         } catch (Exception e) {
@@ -5251,7 +5211,7 @@ private Partition alterPartitionNoTxn(String catName, String dbname,
     }
 
     oldCd.t = oldCD;
-    return convertToPart(oldp, false);
+    return convertToPart(catName, dbname, name, oldp, TxnUtils.isAcidTable(table.getParameters()));
   }
 
   @Override
@@ -10127,8 +10087,8 @@ public Map<String, String> updatePartitionColumnStatistics(Table table, MTable m
       List<ColumnStatisticsObj> statsObjs = colStats.getStatsObj();
       ColumnStatisticsDesc statsDesc = colStats.getStatsDesc();
       String catName = statsDesc.isSetCatName() ? statsDesc.getCatName() : getDefaultCatalog(conf);
-      Partition partition = convertToPart(getMPartition(
-          catName, statsDesc.getDbName(), statsDesc.getTableName(), partVals, mTable), false);
+      Partition partition = convertToPart(catName, statsDesc.getDbName(), statsDesc.getTableName(), getMPartition(
+          catName, statsDesc.getDbName(), statsDesc.getTableName(), partVals, mTable), TxnUtils.isAcidTable(table));
       List<String> colNames = new ArrayList<>();
 
       for(ColumnStatisticsObj statsObj : statsObjs) {
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/RawStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/RawStore.java
index 23d0187d10..5dead2d425 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/RawStore.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/RawStore.java
@@ -113,8 +113,8 @@
 import org.apache.hadoop.hive.metastore.api.WMTrigger;
 import org.apache.hadoop.hive.metastore.api.WMValidateResourcePlanResponse;
 import org.apache.hadoop.hive.metastore.api.WriteEventInfo;
+import org.apache.hadoop.hive.metastore.client.builder.GetPartitionsArgs;
 import org.apache.hadoop.hive.metastore.model.MTable;
-import org.apache.hadoop.hive.metastore.model.MMetastoreDBProperties;
 import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;
 import org.apache.hadoop.hive.metastore.properties.PropertyStore;
 import org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils.ColStatsObjWithSourceInfo;
@@ -500,9 +500,11 @@ boolean dropPartition(String catName, String dbName, String tableName, String pa
    * @throws MetaException error access the RDBMS.
    * @throws NoSuchObjectException no such table exists
    */
+  @Deprecated
   default List<Partition> getPartitions(String catName, String dbName,
       String tableName, int max) throws MetaException, NoSuchObjectException {
-    return getPartitions(catName, dbName, tableName, max, false);
+    return getPartitions(catName, dbName, tableName, new GetPartitionsArgs
+        .GetPartitionsArgsBuilder().max(max).build());
   }
 
   /**
@@ -510,14 +512,13 @@ default List<Partition> getPartitions(String catName, String dbName,
    * @param catName catalog name.
    * @param dbName database name.
    * @param tableName table name
-   * @param max maximum number of partitions, or -1 to get all partitions.
-   * @param skipColumnSchemaForPartition boolean flag to skip column schema for partition
+   * @param args additional arguments for getting partitions
    * @return list of partitions
    * @throws MetaException error access the RDBMS.
    * @throws NoSuchObjectException no such table exists
    */
-  List<Partition> getPartitions(String catName, String dbName,
-      String tableName, int max, boolean skipColumnSchemaForPartition) throws MetaException, NoSuchObjectException;
+  List<Partition> getPartitions(String catName, String dbName, String tableName,
+      GetPartitionsArgs args) throws MetaException, NoSuchObjectException;
 
   /**
    * Get the location for every partition of a given table. If a partition location is a child of
@@ -764,10 +765,14 @@ List<Partition> alterPartitions(String catName, String db_name, String tbl_name,
    * @throws MetaException Error accessing the RDBMS or processing the filter.
    * @throws NoSuchObjectException no such table.
    */
+  @Deprecated
   default List<Partition> getPartitionsByFilter(
      String catName, String dbName, String tblName, String filter, short maxParts)
      throws MetaException, NoSuchObjectException {
-    return getPartitionsByFilter(catName, dbName, tblName, filter, maxParts, false);
+    return getPartitionsByFilter(catName, dbName, tblName, new GetPartitionsArgs
+        .GetPartitionsArgsBuilder()
+        .filter(filter).max(maxParts)
+        .build());
   }
 
   /**
@@ -775,15 +780,13 @@ default List<Partition> getPartitionsByFilter(
    * @param catName catalog name
    * @param dbName database name
    * @param tblName table name
-   * @param filter SQL where clause filter
-   * @param maxParts maximum number of partitions to return, or -1 for all.
-   * @param skipColSchemaForPartitions skips the column schema for partition
+   * @param args additional arguments for getting partitions
    * @return list of partition objects matching the criteria
    * @throws MetaException Error accessing the RDBMS or processing the filter.
    * @throws NoSuchObjectException no such table.
    */
   List<Partition> getPartitionsByFilter(
-      String catName, String dbName, String tblName, String filter, short maxParts, boolean skipColSchemaForPartitions)
+      String catName, String dbName, String tblName, GetPartitionsArgs args)
       throws MetaException, NoSuchObjectException;
 
   /**
@@ -829,11 +832,14 @@ List<Partition> getPartitionSpecsByFilterAndProjection(Table table,
    * @return true if the result contains unknown partitions.
    * @throws TException error executing the expression
    */
+  @Deprecated
   default boolean getPartitionsByExpr(String catName, String dbName, String tblName,
        byte[] expr, String defaultPartitionName, short maxParts, List<Partition> result)
        throws TException {
-    return getPartitionsByExpr(catName, dbName, tblName, expr, defaultPartitionName,
-            maxParts, result, false);
+    return getPartitionsByExpr(catName, dbName, tblName, result, new GetPartitionsArgs
+        .GetPartitionsArgsBuilder()
+        .expr(expr).defaultPartName(defaultPartitionName).max(maxParts)
+        .build());
   }
 
   /**
@@ -841,16 +847,12 @@ default boolean getPartitionsByExpr(String catName, String dbName, String tblNam
    * @param catName catalog name.
    * @param dbName database name
    * @param tblName table name
-   * @param expr an already parsed Hive expression
-   * @param defaultPartitionName default name of a partition
-   * @param maxParts maximum number of partitions to return, or -1 for all
-   * @param result list to place resulting partitions in
-   * @param skipColSchemaForPartitions skip column schema for partitions
+   * @param args additional arguments for getting partitions
    * @return true if the result contains unknown partitions.
    * @throws TException error executing the expression
    */
   boolean getPartitionsByExpr(String catName, String dbName, String tblName,
-      byte[] expr, String defaultPartitionName, short maxParts, List<Partition> result, boolean skipColSchemaForPartitions)
+      List<Partition> result, GetPartitionsArgs args)
       throws TException;
 
   /**
@@ -906,7 +908,8 @@ int getNumPartitionsByPs(String catName, String dbName, String tblName, List<Str
    */
   default List<Partition> getPartitionsByNames(String catName, String dbName, String tblName,
       List<String> partNames) throws MetaException, NoSuchObjectException {
-    return getPartitionsByNames(catName, dbName, tblName, partNames, false);
+    return getPartitionsByNames(catName, dbName, tblName, new GetPartitionsArgs
+        .GetPartitionsArgsBuilder().partNames(partNames).build());
   }
 
   /**
@@ -914,15 +917,13 @@ default List<Partition> getPartitionsByNames(String catName, String dbName, Stri
    * @param catName catalog name.
    * @param dbName database name.
    * @param tblName table name.
-   * @param partNames list of partition names.  These are names not values, so they will include
-   *                  both the key and the value.
-   * @param skipColumnSchemaForPartition boolean flag to skip column schema for partition
+   * @param args additional arguments for getting partitions
    * @return list of matching partitions
    * @throws MetaException error accessing the RDBMS.
    * @throws NoSuchObjectException No such table.
    */
   List<Partition> getPartitionsByNames(String catName, String dbName, String tblName,
-      List<String> partNames, boolean skipColumnSchemaForPartition) throws MetaException, NoSuchObjectException;
+      GetPartitionsArgs args) throws MetaException, NoSuchObjectException;
 
   Table markPartitionForEvent(String catName, String dbName, String tblName, Map<String,String> partVals, PartitionEventType evtType) throws MetaException, UnknownTableException, InvalidPartitionException, UnknownPartitionException;
 
@@ -1154,30 +1155,16 @@ Partition getPartitionWithAuth(String catName, String dbName, String tblName,
    * @throws NoSuchObjectException no such table exists
    * @throws InvalidObjectException error fetching privilege information.
    */
+  @Deprecated
   default List<Partition> getPartitionsWithAuth(String catName, String dbName,
        String tblName, short maxParts, String userName, List<String> groupNames)
        throws MetaException, NoSuchObjectException, InvalidObjectException {
-    return getPartitionsWithAuth(catName, dbName, tblName, maxParts, userName, groupNames, false);
+    return listPartitionsPsWithAuth(catName, dbName, tblName,
+        new GetPartitionsArgs.GetPartitionsArgsBuilder()
+            .max(maxParts).userName(userName).groupNames(groupNames)
+            .build());
   }
 
-  /**
-   * Fetch some or all partitions for a table, along with privilege information for a particular
-   * user.
-   * @param catName catalog name.
-   * @param dbName database name.
-   * @param tblName table name.
-   * @param maxParts maximum number of partitions to fetch, -1 for all partitions.
-   * @param userName user to get privilege information for.
-   * @param groupNames groups to get privilege information for.
-   * @return list of partitions.
-   * @throws MetaException error access the RDBMS.
-   * @throws NoSuchObjectException no such table exists
-   * @throws InvalidObjectException error fetching privilege information.
-   */
-  List<Partition> getPartitionsWithAuth(String catName, String dbName,
-      String tblName, short maxParts, String userName, List<String> groupNames, boolean isColSchemaRequired)
-      throws MetaException, NoSuchObjectException, InvalidObjectException;
-
   /**
    * Lists partition names that match a given partial specification
    * @param catName catalog name.
@@ -1220,11 +1207,14 @@ List<String> listPartitionNamesPs(String catName, String db_name, String tbl_nam
    * @throws NoSuchObjectException No such table exists
    * @throws InvalidObjectException error access privilege information
    */
+  @Deprecated
   default List<Partition> listPartitionsPsWithAuth(String catName, String db_name, String tbl_name,
       List<String> part_vals, short max_parts, String userName, List<String> groupNames)
       throws MetaException, InvalidObjectException, NoSuchObjectException {
-    return listPartitionsPsWithAuth(catName, db_name, tbl_name, part_vals, max_parts,
-            userName, groupNames, false);
+    return listPartitionsPsWithAuth(catName, db_name, tbl_name, new GetPartitionsArgs
+        .GetPartitionsArgsBuilder()
+        .part_vals(part_vals).max(max_parts).userName(userName).groupNames(groupNames)
+        .build());
   }
 
   /**
@@ -1235,23 +1225,14 @@ default List<Partition> listPartitionsPsWithAuth(String catName, String db_name,
    *          The name of the database which has the partitions
    * @param tbl_name
    *          The name of the table which has the partitions
-   * @param part_vals
-   *          A partial list of values for partitions in order of the table's partition keys
-   *          Entries can be empty if you need to specify latter partitions.
-   * @param max_parts
-   *          The maximum number of partitions to return
-   * @param userName
-   *          The user name for the partition for authentication privileges
-   * @param groupNames
-   *          The groupNames for the partition for authentication privileges
+   * @param args additional arguments for getting partitions
    * @return A list of partitions that match the partial spec.
    * @throws MetaException error access RDBMS
    * @throws NoSuchObjectException No such table exists
    * @throws InvalidObjectException error access privilege information
    */
   List<Partition> listPartitionsPsWithAuth(String catName, String db_name, String tbl_name,
-      List<String> part_vals, short max_parts, String userName, List<String> groupNames,
-      boolean skipColSchemaForPartitions) throws MetaException, InvalidObjectException, NoSuchObjectException;
+      GetPartitionsArgs args) throws MetaException, InvalidObjectException, NoSuchObjectException;
 
   /** Persists the given column statistics object to the metastore
    * @param colStats object to persist
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java
index c589fd7ba2..876f8ff272 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java
@@ -60,6 +60,7 @@
 import org.apache.hadoop.hive.metastore.api.*;
 import org.apache.hadoop.hive.metastore.api.Package;
 import org.apache.hadoop.hive.metastore.cache.SharedCache.StatsType;
+import org.apache.hadoop.hive.metastore.client.builder.GetPartitionsArgs;
 import org.apache.hadoop.hive.metastore.columnstats.aggr.ColumnStatsAggregator;
 import org.apache.hadoop.hive.metastore.columnstats.aggr.ColumnStatsAggregatorFactory;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
@@ -1473,20 +1474,20 @@ public Table getTable(String catName, String dbName, String tblName, String vali
     sharedCache.removePartitionsFromCache(catName, dbName, tblName, partVals);
   }
 
-  @Override public List<Partition> getPartitions(String catName, String dbName, String tblName, int max, boolean skipColumnSchemaForPartition)
+  @Override public List<Partition> getPartitions(String catName, String dbName, String tblName, GetPartitionsArgs args)
       throws MetaException, NoSuchObjectException {
     catName = normalizeIdentifier(catName);
     dbName = StringUtils.normalizeIdentifier(dbName);
     tblName = StringUtils.normalizeIdentifier(tblName);
     if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {
-      return rawStore.getPartitions(catName, dbName, tblName, max);
+      return rawStore.getPartitions(catName, dbName, tblName, args);
     }
     Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);
     if (tbl == null) {
       // The table containing the partitions is not yet loaded in cache
-      return rawStore.getPartitions(catName, dbName, tblName, max);
+      return rawStore.getPartitions(catName, dbName, tblName, args);
     }
-    List<Partition> parts = sharedCache.listCachedPartitions(catName, dbName, tblName, max);
+    List<Partition> parts = sharedCache.listCachedPartitions(catName, dbName, tblName, args.getMax());
     return parts;
   }
 
@@ -1697,9 +1698,9 @@ private boolean getPartitionNamesPrunedByExprNoTxn(Table table, byte[] expr, Str
 
   @Override
   // TODO: implement using SharedCache
-  public List<Partition> getPartitionsByFilter(String catName, String dbName, String tblName, String filter,
-      short maxParts, boolean skipColSchemaForPartitions) throws MetaException, NoSuchObjectException {
-    return rawStore.getPartitionsByFilter(catName, dbName, tblName, filter, maxParts, skipColSchemaForPartitions);
+  public List<Partition> getPartitionsByFilter(String catName, String dbName, String tblName, GetPartitionsArgs args)
+      throws MetaException, NoSuchObjectException {
+    return rawStore.getPartitionsByFilter(catName, dbName, tblName, args);
   }
 
   @Override
@@ -1711,24 +1712,23 @@ public List<Partition> getPartitionsByFilter(String catName, String dbName, Stri
     return rawStore.getPartitionSpecsByFilterAndProjection(table, projectionSpec, filterSpec);
   }
 
-  @Override public boolean getPartitionsByExpr(String catName, String dbName, String tblName, byte[] expr,
-      String defaultPartitionName, short maxParts, List<Partition> result, boolean skipColSchemaForPartitions) throws TException {
+  @Override public boolean getPartitionsByExpr(String catName, String dbName, String tblName,
+      List<Partition> result, GetPartitionsArgs args) throws TException {
     catName = StringUtils.normalizeIdentifier(catName);
     dbName = StringUtils.normalizeIdentifier(dbName);
     tblName = StringUtils.normalizeIdentifier(tblName);
     if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {
-      return rawStore.getPartitionsByExpr(catName, dbName, tblName, expr, defaultPartitionName, maxParts, result
-              , skipColSchemaForPartitions);
+      return rawStore.getPartitionsByExpr(catName, dbName, tblName, result, args);
     }
     List<String> partNames = new LinkedList<>();
     Table table = sharedCache.getTableFromCache(catName, dbName, tblName);
     if (table == null) {
       // The table is not yet loaded in cache
-      return rawStore.getPartitionsByExpr(catName, dbName, tblName, expr, defaultPartitionName, maxParts, result
-              , skipColSchemaForPartitions);
+      return rawStore.getPartitionsByExpr(catName, dbName, tblName, result, args);
     }
     boolean hasUnknownPartitions =
-        getPartitionNamesPrunedByExprNoTxn(table, expr, defaultPartitionName, maxParts, partNames, sharedCache);
+        getPartitionNamesPrunedByExprNoTxn(table, args.getExpr(), args.getDefaultPartName(),
+            (short) args.getMax(), partNames, sharedCache);
     for (String partName : partNames) {
       Partition part = sharedCache.getPartitionFromCache(catName, dbName, tblName, partNameToVals(partName));
       part.unsetPrivileges();
@@ -1774,20 +1774,20 @@ public List<Partition> getPartitionsByFilter(String catName, String dbName, Stri
   }
 
   @Override public List<Partition> getPartitionsByNames(String catName, String dbName, String tblName,
-      List<String> partNames, boolean skipColSchemaForPartitions) throws MetaException, NoSuchObjectException {
+      GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
     catName = StringUtils.normalizeIdentifier(catName);
     dbName = StringUtils.normalizeIdentifier(dbName);
     tblName = StringUtils.normalizeIdentifier(tblName);
     if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {
-      return rawStore.getPartitionsByNames(catName, dbName, tblName, partNames, skipColSchemaForPartitions);
+      return rawStore.getPartitionsByNames(catName, dbName, tblName, args);
     }
     Table table = sharedCache.getTableFromCache(catName, dbName, tblName);
     if (table == null) {
       // The table is not yet loaded in cache
-      return rawStore.getPartitionsByNames(catName, dbName, tblName, partNames, skipColSchemaForPartitions);
+      return rawStore.getPartitionsByNames(catName, dbName, tblName, args);
     }
     List<Partition> partitions = new ArrayList<>();
-    for (String partName : partNames) {
+    for (String partName : args.getPartNames()) {
       Partition part = sharedCache.getPartitionFromCache(catName, dbName, tblName, partNameToVals(partName));
       if (part != null) {
         partitions.add(part);
@@ -1959,34 +1959,6 @@ public List<Partition> getPartitionsByFilter(String catName, String dbName, Stri
     return p;
   }
 
-  @Override public List<Partition> getPartitionsWithAuth(String catName, String dbName, String tblName, short maxParts,
-      String userName, List<String> groupNames, boolean skipColSchemaForPartitions) throws MetaException, NoSuchObjectException, InvalidObjectException {
-    catName = StringUtils.normalizeIdentifier(catName);
-    dbName = StringUtils.normalizeIdentifier(dbName);
-    tblName = StringUtils.normalizeIdentifier(tblName);
-    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {
-      return rawStore.getPartitionsWithAuth(catName, dbName, tblName, maxParts, userName, groupNames, skipColSchemaForPartitions);
-    }
-    Table table = sharedCache.getTableFromCache(catName, dbName, tblName);
-    if (table == null) {
-      // The table is not yet loaded in cache
-      return rawStore.getPartitionsWithAuth(catName, dbName, tblName, maxParts, userName, groupNames, skipColSchemaForPartitions);
-    }
-    List<Partition> partitions = new ArrayList<>();
-    int count = 0;
-    for (Partition part : sharedCache.listCachedPartitions(catName, dbName, tblName, maxParts)) {
-      if (maxParts == -1 || count < maxParts) {
-        String partName = Warehouse.makePartName(table.getPartitionKeys(), part.getValues());
-        PrincipalPrivilegeSet privs =
-            getPartitionPrivilegeSet(catName, dbName, tblName, partName, userName, groupNames);
-        part.setPrivileges(privs);
-        partitions.add(part);
-        count++;
-      }
-    }
-    return partitions;
-  }
-
   @Override public List<String> listPartitionNamesPs(String catName, String dbName, String tblName,
       List<String> partSpecs, short maxParts) throws MetaException, NoSuchObjectException {
     catName = StringUtils.normalizeIdentifier(catName);
@@ -2021,30 +1993,31 @@ public int getNumPartitionsByPs(String catName, String dbName, String tblName, L
   }
 
   @Override public List<Partition> listPartitionsPsWithAuth(String catName, String dbName, String tblName,
-      List<String> partSpecs, short maxParts, String userName, List<String> groupNames, boolean skipColSchemaForPartitions)
-      throws MetaException, InvalidObjectException, NoSuchObjectException {
+      GetPartitionsArgs args) throws MetaException, InvalidObjectException, NoSuchObjectException {
     catName = StringUtils.normalizeIdentifier(catName);
     dbName = StringUtils.normalizeIdentifier(dbName);
     tblName = StringUtils.normalizeIdentifier(tblName);
     if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {
-      return rawStore.listPartitionsPsWithAuth(catName, dbName, tblName, partSpecs, maxParts, userName, groupNames
-              , skipColSchemaForPartitions);
+      return rawStore.listPartitionsPsWithAuth(catName, dbName, tblName, args);
     }
     Table table = sharedCache.getTableFromCache(catName, dbName, tblName);
     if (table == null) {
       // The table is not yet loaded in cache
-      return rawStore.listPartitionsPsWithAuth(catName, dbName, tblName, partSpecs, maxParts, userName, groupNames
-              , skipColSchemaForPartitions);
+      return rawStore.listPartitionsPsWithAuth(catName, dbName, tblName, args);
     }
-    String partNameMatcher = getPartNameMatcher(table, partSpecs);
+    String partNameMatcher = null;
+    if (args.getPart_vals() != null && !args.getPart_vals().isEmpty()) {
+      partNameMatcher = getPartNameMatcher(table, args.getPart_vals());
+    }
+    int maxParts = args.getMax();
     List<Partition> partitions = new ArrayList<>();
     List<Partition> allPartitions = sharedCache.listCachedPartitions(catName, dbName, tblName, maxParts);
     int count = 0;
     for (Partition part : allPartitions) {
       String partName = Warehouse.makePartName(table.getPartitionKeys(), part.getValues());
-      if (partName.matches(partNameMatcher) && (maxParts == -1 || count < maxParts)) {
+      if ((partNameMatcher == null || partName.matches(partNameMatcher)) && (maxParts == -1 || count < maxParts)) {
         PrincipalPrivilegeSet privs =
-            getPartitionPrivilegeSet(catName, dbName, tblName, partName, userName, groupNames);
+            getPartitionPrivilegeSet(catName, dbName, tblName, partName, args.getUserName(), args.getGroupNames());
         part.setPrivileges(privs);
         partitions.add(part);
         count++;
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/client/builder/GetPartitionsArgs.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/client/builder/GetPartitionsArgs.java
new file mode 100644
index 0000000000..6eb6df1d6d
--- /dev/null
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/client/builder/GetPartitionsArgs.java
@@ -0,0 +1,185 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.metastore.client.builder;
+
+import java.util.List;
+
+public class GetPartitionsArgs {
+  private String filter;
+  private byte[] expr;
+  private String defaultPartName;
+  private int max;
+  private List<String> partNames;
+  private List<String> part_vals;
+  private String userName;
+  private List<String> groupNames;
+  private String includeParamKeyPattern;
+  private String excludeParamKeyPattern;
+  private boolean skipColumnSchemaForPartition;
+
+  private GetPartitionsArgs() {
+
+  }
+
+  public String getFilter() {
+    return filter;
+  }
+
+  public byte[] getExpr() {
+    return expr;
+  }
+
+  public String getDefaultPartName() {
+    return defaultPartName;
+  }
+
+  public int getMax() {
+    return max;
+  }
+
+  public List<String> getPartNames() {
+    return partNames;
+  }
+
+  public List<String> getPart_vals() {
+    return part_vals;
+  }
+
+  public String getUserName() {
+    return userName;
+  }
+
+  public List<String> getGroupNames() {
+    return groupNames;
+  }
+
+  public String getIncludeParamKeyPattern() {
+    return includeParamKeyPattern;
+  }
+
+  public String getExcludeParamKeyPattern() {
+    return excludeParamKeyPattern;
+  }
+
+  public boolean isSkipColumnSchemaForPartition() {
+    return skipColumnSchemaForPartition;
+  }
+
+  public static class GetPartitionsArgsBuilder {
+    private String filter;
+    private byte[] expr;
+    private String defaultPartName;
+    private int max = -1;
+    private List<String> partNames;
+    private List<String> part_vals;
+    private String userName;
+    private List<String> groupNames;
+    private String includeParamKeyPattern;
+    private String excludeParamKeyPattern;
+    private boolean skipColumnSchemaForPartition = false;
+
+    public GetPartitionsArgsBuilder() {
+
+    }
+
+    public GetPartitionsArgsBuilder(GetPartitionsArgs args) {
+      this.filter = args.filter;
+      this.expr = args.expr;
+      this.defaultPartName = args.defaultPartName;
+      this.max = args.max;
+      this.partNames = args.partNames;
+      this.part_vals = args.part_vals;
+      this.userName = args.userName;
+      this.groupNames = args.groupNames;
+      this.includeParamKeyPattern = args.includeParamKeyPattern;
+      this.excludeParamKeyPattern = args.excludeParamKeyPattern;
+      this.skipColumnSchemaForPartition = args.skipColumnSchemaForPartition;
+    }
+
+    public GetPartitionsArgsBuilder filter(String filter) {
+      this.filter = filter;
+      return this;
+    }
+
+    public GetPartitionsArgsBuilder expr(byte[] expr) {
+      this.expr = expr;
+      return this;
+    }
+
+    public GetPartitionsArgsBuilder defaultPartName(String defaultPartName) {
+      this.defaultPartName = defaultPartName;
+      return this;
+    }
+
+    public GetPartitionsArgsBuilder max(int max) {
+      this.max = max;
+      return this;
+    }
+
+    public GetPartitionsArgsBuilder partNames(List<String> partNames) {
+      this.partNames = partNames;
+      return this;
+    }
+
+    public GetPartitionsArgsBuilder part_vals(List<String> part_vals) {
+      this.part_vals = part_vals;
+      return this;
+    }
+
+    public GetPartitionsArgsBuilder userName(String userName) {
+      this.userName = userName;
+      return this;
+    }
+
+    public GetPartitionsArgsBuilder groupNames(List<String> groupNames) {
+      this.groupNames = groupNames;
+      return this;
+    }
+
+    public GetPartitionsArgsBuilder includeParamKeyPattern(String includeParamKeyPattern) {
+      this.includeParamKeyPattern = includeParamKeyPattern;
+      return this;
+    }
+
+    public GetPartitionsArgsBuilder excludeParamKeyPattern(String excludeParamKeyPattern) {
+      this.excludeParamKeyPattern = excludeParamKeyPattern;
+      return this;
+    }
+
+    public GetPartitionsArgsBuilder skipColumnSchemaForPartition(boolean skipColumnSchemaForPartition) {
+      this.skipColumnSchemaForPartition = skipColumnSchemaForPartition;
+      return this;
+    }
+
+    public GetPartitionsArgs build() {
+      GetPartitionsArgs additionalArgs = new GetPartitionsArgs();
+      additionalArgs.filter = filter;
+      additionalArgs.expr = expr;
+      additionalArgs.defaultPartName = defaultPartName;
+      additionalArgs.max = max;
+      additionalArgs.partNames = partNames;
+      additionalArgs.part_vals = part_vals;
+      additionalArgs.userName = userName;
+      additionalArgs.groupNames = groupNames;
+      additionalArgs.includeParamKeyPattern = includeParamKeyPattern;
+      additionalArgs.excludeParamKeyPattern = excludeParamKeyPattern;
+      additionalArgs.skipColumnSchemaForPartition = skipColumnSchemaForPartition;
+      return additionalArgs;
+    }
+  }
+}
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/DummyRawStoreControlledCommit.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/DummyRawStoreControlledCommit.java
index 6b5eb47ef3..4c574d68c7 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/DummyRawStoreControlledCommit.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/DummyRawStoreControlledCommit.java
@@ -113,6 +113,7 @@
 import org.apache.hadoop.hive.metastore.api.WMValidateResourcePlanResponse;
 import org.apache.hadoop.hive.metastore.api.WriteEventInfo;
 
+import org.apache.hadoop.hive.metastore.client.builder.GetPartitionsArgs;
 import org.apache.hadoop.hive.metastore.model.MTable;
 import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;
 import org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils.ColStatsObjWithSourceInfo;
@@ -355,9 +356,9 @@ public List<Partition> getPartitions(String catName, String dbName, String table
   }
 
     @Override
-    public List<Partition> getPartitions(String catName, String dbName, String tblName, int max,
-                                         boolean skipColumnSchemaForPartition) throws MetaException, NoSuchObjectException {
-        return objectStore.getPartitions(catName, dbName, tblName, max, skipColumnSchemaForPartition);
+    public List<Partition> getPartitions(String catName, String dbName, String tblName,
+                                         GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
+        return objectStore.getPartitions(catName, dbName, tblName, args);
     }
 
   @Override
@@ -471,8 +472,8 @@ public List<Partition> getPartitionsByFilter(String catName, String dbName, Stri
 
     @Override
     public List<Partition> getPartitionsByFilter(String catName, String dbName, String tblName,
-                                                 String filter, short maxParts, boolean skipColSchemaForPartitions) throws MetaException, NoSuchObjectException {
-        return objectStore.getPartitionsByFilter(catName, dbName, tblName, filter, maxParts, skipColSchemaForPartitions);
+                                                 GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
+        return objectStore.getPartitionsByFilter(catName, dbName, tblName, args);
     }
 
   @Override
@@ -508,8 +509,8 @@ public List<Partition> getPartitionsByNames(String catName, String dbName, Strin
 
     @Override
     public List<Partition> getPartitionsByNames(String catName, String dbName, String tblName,
-                                                List<String> partNames, boolean skipColSchemaForPartitions) throws MetaException, NoSuchObjectException {
-        return objectStore.getPartitionsByNames(catName, dbName, tblName, partNames, skipColSchemaForPartitions);
+                                                GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
+        return objectStore.getPartitionsByNames(catName, dbName, tblName, args);
     }
 
   @Override
@@ -520,10 +521,9 @@ public boolean getPartitionsByExpr(String catName, String dbName, String tblName
   }
 
     @Override
-    public boolean getPartitionsByExpr(String catName, String dbName, String tblName, byte[] expr,
-                                       String defaultPartitionName, short maxParts, List<Partition> result, boolean skipColSchemaForPartitions) throws TException {
-        return objectStore.getPartitionsByExpr(catName,
-                dbName, tblName, expr, defaultPartitionName, maxParts, result, skipColSchemaForPartitions);
+    public boolean getPartitionsByExpr(String catName, String dbName, String tblName,
+                                       List<Partition> result, GetPartitionsArgs args) throws TException {
+        return objectStore.getPartitionsByExpr(catName, dbName, tblName, result, args);
     }
 
   @Override
@@ -716,15 +716,6 @@ public List<Partition> getPartitionsWithAuth(String catName, String dbName, Stri
         groupNames);
   }
 
-    @Override
-    public List<Partition> getPartitionsWithAuth(String catName, String dbName, String tblName, short maxParts,
-                                                 String userName, List<String> groupNames, boolean isColumnSchemaRequired) throws MetaException, NoSuchObjectException,
-            InvalidObjectException {
-
-        return objectStore.getPartitionsWithAuth(catName, dbName, tblName, maxParts, userName,
-                groupNames, isColumnSchemaRequired);
-    }
-
   @Override
   public List<String> listPartitionNamesPs(String catName, String dbName, String tblName,
       List<String> partVals, short maxParts)
@@ -741,11 +732,9 @@ public List<Partition> listPartitionsPsWithAuth(String catName, String dbName, S
   }
 
     @Override
-    public List<Partition> listPartitionsPsWithAuth(String catName, String dbName, String tblName,
-                                                    List<String> partVals, short maxParts, String userName, List<String> groupNames, boolean skipColSchemaForPartitions)
+    public List<Partition> listPartitionsPsWithAuth(String catName, String dbName, String tblName, GetPartitionsArgs args)
             throws MetaException, InvalidObjectException, NoSuchObjectException {
-        return objectStore.listPartitionsPsWithAuth(catName, dbName, tblName, partVals, maxParts,
-                userName, groupNames, skipColSchemaForPartitions);
+        return objectStore.listPartitionsPsWithAuth(catName, dbName, tblName, args);
     }
 
   @Override
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java
index 7b318101bc..a12b989c73 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java
@@ -127,6 +127,7 @@
 import java.util.Map;
 
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hive.metastore.client.builder.GetPartitionsArgs;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
 import org.apache.hadoop.hive.metastore.model.MTable;
 import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;
@@ -367,8 +368,8 @@ public List<Partition> getPartitions(String catName, String dbName, String table
   }
 
   @Override
-  public List<Partition> getPartitions(String catName, String dbName, String tblName, int max,
-      boolean skipColumnSchemaForPartition) throws MetaException, NoSuchObjectException {
+  public List<Partition> getPartitions(String catName, String dbName, String tblName,
+      GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
     return Collections.emptyList();
   }
 
@@ -489,7 +490,7 @@ public List<Partition> getPartitionsByFilter(String catName, String dbName, Stri
 
   @Override
   public List<Partition> getPartitionsByFilter(String catName, String dbName, String tblName,
-       String filter, short maxParts, boolean skipColSchemaForPartitions)
+       GetPartitionsArgs args)
        throws MetaException, NoSuchObjectException {
     return Collections.emptyList();
   }
@@ -510,7 +511,7 @@ public List<Partition> getPartitionsByNames(String catName, String dbName, Strin
 
   @Override
   public List<Partition> getPartitionsByNames(String catName, String dbName, String tblName,
-      List<String> partNames, boolean skipColSchemaForPartitions) throws MetaException, NoSuchObjectException {
+      GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
     return Collections.emptyList();
   }
 
@@ -521,8 +522,8 @@ public boolean getPartitionsByExpr(String catName, String dbName, String tblName
   }
 
   @Override
-  public boolean getPartitionsByExpr(String catName, String dbName, String tblName, byte[] expr,
-      String defaultPartitionName, short maxParts, List<Partition> result, boolean skipColSchemaForPartitions) throws TException {
+  public boolean getPartitionsByExpr(String catName, String dbName, String tblName,
+      List<Partition> result, GetPartitionsArgs args) throws TException {
     return false;
   }
 
@@ -748,13 +749,6 @@ public List<Partition> getPartitionsWithAuth(String catName, String dbName, Stri
     return Collections.emptyList();
   }
 
-  @Override
-  public List<Partition> getPartitionsWithAuth(String catName, String dbName, String tblName, short maxParts,
-       String userName, List<String> groupNames, boolean isColumnSchemaRequired)
-       throws MetaException, NoSuchObjectException, InvalidObjectException {
-    return Collections.emptyList();
-  }
-
   @Override
   public List<String> listPartitionNamesPs(String catName, String db_name, String tbl_name, List<String> part_vals,
       short max_parts) throws MetaException, NoSuchObjectException {
@@ -772,7 +766,7 @@ public List<Partition> listPartitionsPsWithAuth(String catName, String db_name,
 
   @Override
   public List<Partition> listPartitionsPsWithAuth(String catName, String db_name, String tbl_name,
-       List<String> part_vals, short max_parts, String userName, List<String> groupNames, boolean skipColSchemaForPartitions)
+       GetPartitionsArgs args)
        throws MetaException, InvalidObjectException, NoSuchObjectException {
     return Collections.emptyList();
   }
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestGetPartitionsUsingProjectionAndFilterSpecs.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestGetPartitionsUsingProjectionAndFilterSpecs.java
index 7e63727358..7a37f6032b 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestGetPartitionsUsingProjectionAndFilterSpecs.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestGetPartitionsUsingProjectionAndFilterSpecs.java
@@ -229,8 +229,12 @@ public void testPartitionProjectionEmptySpec() throws Throwable {
       Assert.assertEquals(origPartition.getLastAccessTime(), retPartition.getLastAccessTime());
       Assert.assertEquals(origPartition.getSd().getLocation(),
           sharedSD.getLocation() + retPartition.getRelativePath());
-      validateMap(origPartition.getParameters(), retPartition.getParameters());
-      validateList(origPartition.getValues(), retPartition.getValues());
+      Assert.assertFalse("excluded parameter key is found in the response",
+          retPartition.getParameters().containsKey(EXCLUDE_KEY_PREFIX + "key1"));
+      Assert.assertFalse("excluded parameter key is found in the response",
+          retPartition.getParameters().containsKey(EXCLUDE_KEY_PREFIX + "key2"));
+      Assert.assertEquals("Additional parameters returned",
+          3, retPartition.getParameters().size());
     }
   }
 
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestObjectStore.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestObjectStore.java
index 5c6ad05839..5746a95264 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestObjectStore.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestObjectStore.java
@@ -64,6 +64,7 @@
 import org.apache.hadoop.hive.metastore.api.Table;
 import org.apache.hadoop.hive.metastore.client.builder.CatalogBuilder;
 import org.apache.hadoop.hive.metastore.client.builder.DatabaseBuilder;
+import org.apache.hadoop.hive.metastore.client.builder.GetPartitionsArgs;
 import org.apache.hadoop.hive.metastore.client.builder.PartitionBuilder;
 import org.apache.hadoop.hive.metastore.client.builder.HiveObjectPrivilegeBuilder;
 import org.apache.hadoop.hive.metastore.client.builder.HiveObjectRefBuilder;
@@ -645,7 +646,7 @@ public void testDirectSQLDropPartitionsCacheInSession()
     List<Partition> partitions;
     try(AutoCloseable c =deadline()) {
       partitions = objectStore.getPartitionsInternal(DEFAULT_CATALOG_NAME, DB1, TABLE1,
-          10, false, true);
+          false, true, new GetPartitionsArgs.GetPartitionsArgsBuilder().max(10).build());
     }
     Assert.assertEquals(3, partitions.size());
 
@@ -656,7 +657,8 @@ public void testDirectSQLDropPartitionsCacheInSession()
     }
     try (AutoCloseable c = deadline()) {
       // query the partitions with JDO, checking the cache is not causing any problem
-      partitions = objectStore.getPartitionsInternal(DEFAULT_CATALOG_NAME, DB1, TABLE1, 10, false, true);
+      partitions = objectStore.getPartitionsInternal(DEFAULT_CATALOG_NAME, DB1, TABLE1, false, true,
+          new GetPartitionsArgs.GetPartitionsArgsBuilder().max(10).build());
     }
     Assert.assertEquals(1, partitions.size());
   }
@@ -671,16 +673,17 @@ public void testDirectSQLDropPartitionsCacheCrossSession()
     objectStore2.setConf(conf);
 
     createPartitionedTable(false, false);
+    GetPartitionsArgs args = new GetPartitionsArgs.GetPartitionsArgsBuilder().max(10).build();
     // query the partitions with JDO in the 1st session
     List<Partition> partitions;
     try (AutoCloseable c = deadline()) {
-      partitions = objectStore.getPartitionsInternal(DEFAULT_CATALOG_NAME, DB1, TABLE1, 10, false, true);
+      partitions = objectStore.getPartitionsInternal(DEFAULT_CATALOG_NAME, DB1, TABLE1, false, true, args);
     }
     Assert.assertEquals(3, partitions.size());
 
     // query the partitions with JDO in the 2nd session
     try (AutoCloseable c = deadline()) {
-      partitions = objectStore2.getPartitionsInternal(DEFAULT_CATALOG_NAME, DB1, TABLE1, 10, false, true);
+      partitions = objectStore2.getPartitionsInternal(DEFAULT_CATALOG_NAME, DB1, TABLE1, false, true, args);
     }
     Assert.assertEquals(3, partitions.size());
 
@@ -693,7 +696,7 @@ public void testDirectSQLDropPartitionsCacheCrossSession()
     // query the partitions with JDO in the 2nd session, checking the cache is not causing any
     // problem
     try (AutoCloseable c = deadline()) {
-      partitions = objectStore2.getPartitionsInternal(DEFAULT_CATALOG_NAME, DB1, TABLE1, 10, false, true);
+      partitions = objectStore2.getPartitionsInternal(DEFAULT_CATALOG_NAME, DB1, TABLE1, false, true, args);
     }
     Assert.assertEquals(1, partitions.size());
   }
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java
index ed747356b2..8d209679c1 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java
@@ -33,6 +33,7 @@
 
 import org.apache.commons.lang3.ClassUtils;
 import org.apache.commons.lang3.builder.EqualsBuilder;
+import org.apache.hadoop.hive.metastore.client.builder.GetPartitionsArgs;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.apache.hadoop.hive.metastore.api.ColumnStatistics;
@@ -51,12 +52,12 @@ public VerifyingObjectStore() {
 
   @Override
   public List<Partition> getPartitionsByFilter(String catName, String dbName, String tblName,
-                                               String filter, short maxParts)
+                                               GetPartitionsArgs args)
       throws MetaException, NoSuchObjectException {
     List<Partition> sqlResults = getPartitionsByFilterInternal(
-        catName, dbName, tblName, filter, maxParts, true, false, false);
+        catName, dbName, tblName, true, false, args);
     List<Partition> ormResults = getPartitionsByFilterInternal(
-        catName, dbName, tblName, filter, maxParts, false, true, false);
+        catName, dbName, tblName, false, true, args);
     verifyLists(sqlResults, ormResults, Partition.class);
     return sqlResults;
   }
@@ -64,22 +65,23 @@ public List<Partition> getPartitionsByFilter(String catName, String dbName, Stri
   @Override
   public List<Partition> getPartitionsByNames(String catName, String dbName, String tblName,
       List<String> partNames) throws MetaException, NoSuchObjectException {
+    GetPartitionsArgs args = new GetPartitionsArgs.GetPartitionsArgsBuilder().partNames(partNames).build();
     List<Partition> sqlResults = getPartitionsByNamesInternal(
-        catName, dbName, tblName, partNames, true, false, false);
+        catName, dbName, tblName, true, false, args);
     List<Partition> ormResults = getPartitionsByNamesInternal(
-        catName, dbName, tblName, partNames, false, true, false);
+        catName, dbName, tblName, false, true, args);
     verifyLists(sqlResults, ormResults, Partition.class);
     return sqlResults;
   }
 
   @Override
-  public boolean getPartitionsByExpr(String catName, String dbName, String tblName, byte[] expr,
-      String defaultPartitionName, short maxParts, List<Partition> result) throws TException {
+  public boolean getPartitionsByExpr(String catName, String dbName, String tblName, List<Partition> result,
+      GetPartitionsArgs args) throws TException {
     List<Partition> ormParts = new LinkedList<>();
     boolean sqlResult = getPartitionsByExprInternal(
-        catName, dbName, tblName, expr, defaultPartitionName, maxParts, result, true, false, false);
+        catName, dbName, tblName, result, true, false, args);
     boolean ormResult = getPartitionsByExprInternal(
-        catName, dbName, tblName, expr, defaultPartitionName, maxParts, ormParts, false, true, false);
+        catName, dbName, tblName, ormParts, false, true, args);
     if (sqlResult != ormResult) {
       String msg = "The unknown flag is different - SQL " + sqlResult + ", ORM " + ormResult;
       LOG.error(msg);
@@ -91,10 +93,10 @@ public boolean getPartitionsByExpr(String catName, String dbName, String tblName
 
   @Override
   public List<Partition> getPartitions(
-      String catName, String dbName, String tableName, int maxParts) throws MetaException, NoSuchObjectException {
+      String catName, String dbName, String tableName, GetPartitionsArgs args) throws MetaException, NoSuchObjectException {
     openTransaction();
-    List<Partition> sqlResults = getPartitionsInternal(catName, dbName, tableName, maxParts, true, false);
-    List<Partition> ormResults = getPartitionsInternal(catName, dbName, tableName, maxParts, false, true);
+    List<Partition> sqlResults = getPartitionsInternal(catName, dbName, tableName, true, false, args);
+    List<Partition> ormResults = getPartitionsInternal(catName, dbName, tableName, false, true, args);
     verifyLists(sqlResults, ormResults, Partition.class);
     commitTransaction();
     return sqlResults;
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestListPartitions.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestListPartitions.java
index d06407342f..91ba1c311f 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestListPartitions.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestListPartitions.java
@@ -167,6 +167,11 @@ protected void addPartition(IMetaStoreClient client, Table table, List<String> v
     client.add_partition(partitionBuilder.build(metaStore.getConf()));
   }
 
+  protected void addPartitions(IMetaStoreClient client, List<Partition> partitions)
+      throws TException{
+    client.add_partitions(partitions);
+  }
+
   private Table createTable3PartCols1PartGeneric(IMetaStoreClient client, boolean authOn)
           throws TException {
     Table t = createTestTable(client, DB_NAME, TABLE_NAME, Lists.newArrayList("yyyy", "mm",
@@ -228,7 +233,7 @@ private void assertPartitionsHaveCorrectValues(List<Partition> partitions,
     }
   }
 
-  private void assertCorrectPartitionNames(List<String> names,
+  protected void assertCorrectPartitionNames(List<String> names,
                                                   List<List<String>> testValues,
                                                   List<String>partCols) throws Exception {
     assertEquals(testValues.size(), names.size());
@@ -266,7 +271,9 @@ private void assertCorrectPartitionValuesResponse(List<List<String>> testValues,
     }
   }
 
+  protected void assertPartitionsHaveCorrectParams(List<Partition> partitions) {
 
+  }
 
   /**
    * Testing listPartitions(String,String,short) ->
@@ -277,9 +284,11 @@ public void testListPartitionsAll() throws Exception {
     List<List<String>> testValues = createTable4PartColsParts(client).testValues;
     List<Partition> partitions = client.listPartitions(DB_NAME, TABLE_NAME, (short)-1);
     assertPartitionsHaveCorrectValues(partitions, testValues);
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitions(DB_NAME, TABLE_NAME, (short)1);
     assertPartitionsHaveCorrectValues(partitions, testValues.subList(0, 1));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitions(DB_NAME, TABLE_NAME, (short) 0);
     assertTrue(partitions.isEmpty());
@@ -300,10 +309,12 @@ public void testGetPartitionsRequest() throws Exception {
     req.setMaxParts((short)-1);
     PartitionsResponse res = client.getPartitionsRequest(req);
     assertPartitionsHaveCorrectValues(res.getPartitions(), testValues);
+    assertPartitionsHaveCorrectParams(res.getPartitions());
 
     req.setMaxParts((short)1);
     res = client.getPartitionsRequest(req);
     assertPartitionsHaveCorrectValues(res.getPartitions(), testValues.subList(0, 1));
+    assertPartitionsHaveCorrectParams(res.getPartitions());
 
     req.setMaxParts((short)0);
     res = client.getPartitionsRequest(req);
@@ -385,11 +396,13 @@ public void testListPartitionsByValues() throws Exception {
     assertEquals(2, partitions.size());
     assertEquals(testValues.get(2), partitions.get(0).getValues());
     assertEquals(testValues.get(3), partitions.get(1).getValues());
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitions(DB_NAME, TABLE_NAME,
             Lists.newArrayList("2017", "11"), (short)-1);
     assertEquals(1, partitions.size());
     assertEquals(testValues.get(3), partitions.get(0).getValues());
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitions(DB_NAME, TABLE_NAME,
             Lists.newArrayList("20177", "11"), (short)-1);
@@ -537,11 +550,13 @@ public void testListPartitionsWithAuth() throws Exception {
     assertEquals(4, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues);
     partitions.forEach(partition -> assertAuthInfoReturned(USER_NAME, groups.get(0), partition));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, (short)2, USER_NAME, groups);
     assertEquals(2, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(0, 2));
     partitions.forEach(partition -> assertAuthInfoReturned(USER_NAME, groups.get(0), partition));
+    assertPartitionsHaveCorrectParams(partitions);
   }
 
   @Test(expected = MetaException.class)
@@ -558,10 +573,12 @@ public void testListPartitionsWithAuthLowMaxParts() throws Exception {
         getClient().listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, (short) 2, USER_NAME, Lists.newArrayList(GROUP));
     assertTrue(partitions.size() == 2);
     partitions.forEach(p -> assertAuthInfoReturned(USER_NAME, GROUP, p));
+    assertPartitionsHaveCorrectParams(partitions);
     partitions = getClient().listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, (short) -1, USER_NAME,
         Lists.newArrayList(GROUP));
     assertTrue(partitions.size() == 4);
     partitions.forEach(p -> assertAuthInfoReturned(USER_NAME, GROUP, p));
+    assertPartitionsHaveCorrectParams(partitions);
   }
 
   @Test
@@ -573,6 +590,7 @@ public void testListPartitionsWithAuthNoPrivilegesSet() throws Exception {
     assertEquals(4, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues);
     partitions.forEach(partition -> assertNull(partition.getPrivileges()));
+    assertPartitionsHaveCorrectParams(partitions);
   }
 
   @Test(expected = NoSuchObjectException.class)
@@ -621,13 +639,15 @@ public void testListPartitionsWithAuthNullTblName() throws Exception {
   @Test
   public void testListPartitionsWithAuthNullUser() throws Exception {
     createTable4PartColsPartsAuthOn(client);
-    client.listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, (short)-1, null, Lists.newArrayList());
+    assertPartitionsHaveCorrectParams(client.listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, (short)-1,
+        null, Lists.newArrayList()));
   }
 
   @Test
   public void testListPartitionsWithAuthNullGroup() throws Exception {
     createTable4PartColsPartsAuthOn(client);
-    client.listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, (short)-1, "user0", null);
+    assertPartitionsHaveCorrectParams(client.listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, (short)-1,
+        "user0", null));
   }
 
   /**
@@ -654,6 +674,7 @@ public void testListPartitionsWithAuthRequestByValues() throws Exception {
     assertEquals(1, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(3, 4));
     partitions.forEach(partition -> assertAuthInfoReturned(USER_NAME, groups.get(0), partition));
+    assertPartitionsHaveCorrectParams(partitions);
 
     req.setPartVals(Lists
         .newArrayList("2017"));
@@ -662,6 +683,7 @@ public void testListPartitionsWithAuthRequestByValues() throws Exception {
     assertEquals(2, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(2, 4));
     partitions.forEach(partition -> assertAuthInfoReturned(USER_NAME, groups.get(0), partition));
+    assertPartitionsHaveCorrectParams(partitions);
 
     req.setMaxParts((short)1);
     res = client.listPartitionsWithAuthInfoRequest(req);
@@ -669,6 +691,7 @@ public void testListPartitionsWithAuthRequestByValues() throws Exception {
     assertEquals(1, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(2, 3));
     partitions.forEach(partition -> assertAuthInfoReturned(USER_NAME, groups.get(0), partition));
+    assertPartitionsHaveCorrectParams(partitions);
 
     req.setMaxParts((short)-1);
     req.setPartVals(Lists
@@ -692,18 +715,21 @@ public void testListPartitionsWithAuthByValues() throws Exception {
     assertEquals(1, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(3, 4));
     partitions.forEach(partition -> assertAuthInfoReturned(USER_NAME, groups.get(0), partition));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, Lists
         .newArrayList("2017"), (short)-1, USER_NAME, groups);
     assertEquals(2, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(2, 4));
     partitions.forEach(partition -> assertAuthInfoReturned(USER_NAME, groups.get(0), partition));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, Lists
         .newArrayList("2017"), (short)1, USER_NAME, groups);
     assertEquals(1, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(2, 3));
     partitions.forEach(partition -> assertAuthInfoReturned(USER_NAME, groups.get(0), partition));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, Lists
         .newArrayList("2013"), (short)-1, USER_NAME, groups);
@@ -751,6 +777,7 @@ public void testListPartitionsWithAuthByValuesNoPrivilegesSet() throws Exception
     assertEquals(1, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(3, 4));
     partitions.forEach(partition -> assertAuthInfoReturned(user, groups.get(0), partition));
+    assertPartitionsHaveCorrectParams(partitions);
   }
 
   @Test(expected = NoSuchObjectException.class)
@@ -817,6 +844,7 @@ public void testListPartitionsWithAuthByValuesNullUser() throws Exception {
     List<Partition> partitions = client.listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, Lists
             .newArrayList("2017", "11", "27"), (short)-1, null, Lists.newArrayList());
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(3, 4));
+    assertPartitionsHaveCorrectParams(partitions);
   }
 
   @Test
@@ -825,6 +853,7 @@ public void testListPartitionsWithAuthByValuesNullGroup() throws Exception {
     List<Partition> partitions = client.listPartitionsWithAuthInfo(DB_NAME, TABLE_NAME, Lists
             .newArrayList("2017", "11", "27"), (short)-1, "", null);
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(3, 4));
+    assertPartitionsHaveCorrectParams(partitions);
   }
 
 
@@ -841,15 +870,18 @@ public void testListPartitionsByFilter() throws Exception {
             "yyyy=\"2017\" OR " + "mm=\"02\"", (short)-1);
     assertEquals(3, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(1, 4));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsByFilter(DB_NAME, TABLE_NAME,
             "yyyy=\"2017\" OR " + "mm=\"02\"", (short)2);
     assertEquals(2, partitions.size());
     assertPartitionsHaveCorrectValues(partitions, partValues.subList(1, 3));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsByFilter(DB_NAME, TABLE_NAME,
             "yyyy=\"2017\" OR " + "mm=\"02\"", (short)0);
     assertTrue(partitions.isEmpty());
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsByFilter(DB_NAME, TABLE_NAME,
             "yyyy=\"2017\" AND mm=\"99\"", (short)-1);
@@ -875,26 +907,32 @@ public void testListPartitionsByFilterCaseInsensitive() throws Exception {
     List<Partition> partitions = client.listPartitionsByFilter(DB_NAME, tableName,
         "yYyY=\"2017\"", (short) -1);
     assertPartitionsHaveCorrectValues(partitions, testValues.subList(0, 3));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsByFilter(DB_NAME, tableName,
         "yYyY=\"2017\" AND mOnTh=\"may\"", (short) -1);
     assertPartitionsHaveCorrectValues(partitions, testValues.subList(2, 3));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsByFilter(DB_NAME, tableName,
         "yYyY!=\"2017\"", (short) -1);
     assertPartitionsHaveCorrectValues(partitions, testValues.subList(3, 5));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsByFilter(DB_NAME, tableName,
         "mOnTh=\"september\"", (short) -1);
     assertPartitionsHaveCorrectValues(partitions, testValues.subList(4, 5));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsByFilter(DB_NAME, tableName,
         "mOnTh like \"m%\"", (short) -1);
     assertPartitionsHaveCorrectValues(partitions, testValues.subList(0, 4));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsByFilter(DB_NAME, tableName,
         "yYyY=\"2018\" AND mOnTh like \"m%\"", (short) -1);
     assertPartitionsHaveCorrectValues(partitions, testValues.subList(3, 4));
+    assertPartitionsHaveCorrectParams(partitions);
     client.dropTable(DB_NAME, tableName);
   }
 
@@ -917,6 +955,7 @@ public void testListPartitionsByFilterCaseSensitive() throws Exception {
     List<Partition> partitions = client.listPartitionsByFilter(DB_NAME, tableName,
         "month=\"mArCh\"", (short) -1);
     Assert.assertTrue(partitions.isEmpty());
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsByFilter(DB_NAME, tableName,
         "yyyy=\"2017\" AND month=\"May\"", (short) -1);
@@ -925,12 +964,13 @@ public void testListPartitionsByFilterCaseSensitive() throws Exception {
     partitions = client.listPartitionsByFilter(DB_NAME, tableName,
         "yyyy=\"2017\" AND month!=\"mArCh\"", (short) -1);
     assertPartitionsHaveCorrectValues(partitions, testValues.subList(0, 3));
+    assertPartitionsHaveCorrectParams(partitions);
 
     partitions = client.listPartitionsByFilter(DB_NAME, tableName,
         "month like \"M%\"", (short) -1);
     Assert.assertTrue(partitions.isEmpty());
     client.dropTable(DB_NAME, tableName);
-
+    assertPartitionsHaveCorrectParams(partitions);
   }
 
   @Test(expected = MetaException.class)
@@ -997,6 +1037,7 @@ public void testListPartitionsByFilterNullFilter() throws Exception {
     List<Partition> partitions = client.listPartitionsByFilter(DB_NAME, TABLE_NAME, null,
             (short)-1);
     assertEquals(4, partitions.size());
+    assertPartitionsHaveCorrectParams(partitions);
   }
 
   @Test
@@ -1004,6 +1045,7 @@ public void testListPartitionsByFilterEmptyFilter() throws Exception {
     createTable4PartColsParts(client);
     List<Partition> partitions = client.listPartitionsByFilter(DB_NAME, TABLE_NAME, "", (short)-1);
     assertEquals(4, partitions.size());
+    assertPartitionsHaveCorrectParams(partitions);
   }
 
 
@@ -1608,16 +1650,18 @@ public void otherCatalog() throws TException {
           .addValue("a" + i)
           .build(metaStore.getConf());
     }
-    client.add_partitions(Arrays.asList(parts));
+    addPartitions(client, Arrays.asList(parts));
 
     List<Partition> fetched = client.listPartitions(catName, dbName, tableName, -1);
     Assert.assertEquals(parts.length, fetched.size());
     Assert.assertEquals(catName, fetched.get(0).getCatName());
+    assertPartitionsHaveCorrectParams(fetched);
 
     fetched = client.listPartitions(catName, dbName, tableName,
         Collections.singletonList("a0"), -1);
     Assert.assertEquals(1, fetched.size());
     Assert.assertEquals(catName, fetched.get(0).getCatName());
+    assertPartitionsHaveCorrectParams(fetched);
 
     PartitionSpecProxy proxy = client.listPartitionSpecs(catName, dbName, tableName, -1);
     Assert.assertEquals(parts.length, proxy.size());
@@ -1626,6 +1670,7 @@ public void otherCatalog() throws TException {
     fetched = client.listPartitionsByFilter(catName, dbName, tableName, "partcol=\"a0\"", -1);
     Assert.assertEquals(1, fetched.size());
     Assert.assertEquals(catName, fetched.get(0).getCatName());
+    assertPartitionsHaveCorrectParams(fetched);
 
     proxy = client.listPartitionSpecsByFilter(catName, dbName, tableName, "partcol=\"a0\"", -1);
     Assert.assertEquals(1, proxy.size());
