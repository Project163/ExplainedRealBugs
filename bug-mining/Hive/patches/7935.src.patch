diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
index 35351ef60c..2f9b5a7529 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
@@ -485,7 +485,7 @@ public boolean validate(Task task) {
 
   private Task getReplLoadRootTask(String sourceDb, String replicadb, boolean isIncrementalDump,
                                    Tuple tuple) throws Throwable {
-    HiveConf confTemp = new HiveConf();
+    HiveConf confTemp = driverMirror.getConf();
     Path loadPath = new Path(tuple.dumpLocation, ReplUtils.REPL_HIVE_BASE_DIR);
     ReplicationMetricCollector metricCollector;
     if (isIncrementalDump) {
diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenariosAcrossInstances.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenariosAcrossInstances.java
index b2e5f414a8..b85c0bdb1c 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenariosAcrossInstances.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenariosAcrossInstances.java
@@ -36,7 +36,6 @@
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
 import org.apache.hadoop.hive.metastore.messaging.json.gzip.GzipJSONMessageEncoder;
 import org.apache.hadoop.hive.ql.ErrorMsg;
-import org.apache.hadoop.hive.ql.parse.ReplicationTestUtils;
 import org.apache.hadoop.hive.ql.parse.WarehouseInstance.Tuple;
 import org.apache.hadoop.hive.ql.exec.repl.incremental.IncrementalLoadTasksBuilder;
 import org.apache.hadoop.hive.ql.exec.repl.util.ReplUtils;
@@ -70,8 +69,6 @@
 import static org.apache.hadoop.hive.metastore.ReplChangeManager.SOURCE_OF_REPLICATION;
 import static org.apache.hadoop.hive.ql.exec.repl.ReplAck.LOAD_ACKNOWLEDGEMENT;
 import static org.apache.hadoop.hive.ql.exec.repl.ReplAck.NON_RECOVERABLE_MARKER;
-import static org.apache.hadoop.hive.ql.exec.repl.util.ReplUtils.REPL_HIVE_BASE_DIR;
-import static org.apache.hadoop.hive.ql.exec.repl.util.ReplUtils.TARGET_OF_REPLICATION;
 import static org.hamcrest.CoreMatchers.equalTo;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
@@ -1088,7 +1085,7 @@ public void testIfCkptAndSourceOfReplPropsIgnoredByReplDump() throws Throwable {
 
     // Bootstrap Repl B -> C
     WarehouseInstance.Tuple tupleReplica = replica.run("alter database " + replicatedDbName
-      + " set dbproperties ('" + TARGET_OF_REPLICATION + "' = '')").dump(replicatedDbName);
+            + " set dbproperties ('" + ReplUtils.TARGET_OF_REPLICATION + "' = '')").dump(replicatedDbName);
     String replDbFromReplica = replicatedDbName + "_dupe";
     replica.load(replDbFromReplica, replicatedDbName)
             .run("use " + replDbFromReplica)
@@ -1122,6 +1119,8 @@ public void testIfCkptAndSourceOfReplPropsIgnoredByReplDump() throws Throwable {
     WarehouseInstance.Tuple tupleReplicaInc = replica.load(replicatedDbName, primaryDbName)
             .run("repl status " + replicatedDbName)
             .verifyResult(tuplePrimaryInc.lastReplicationId)
+            .run("alter database " + replicatedDbName
+                    + " set dbproperties ('" + ReplUtils.TARGET_OF_REPLICATION + "' = '')")
             .dump(replicatedDbName, Collections.emptyList());
 
     // Check if DB in B have ckpt property is set to bootstrap dump location used in B and missing for table/partition.
@@ -1153,6 +1152,39 @@ public void testIfCkptAndSourceOfReplPropsIgnoredByReplDump() throws Throwable {
     replica.run("drop database if exists " + replDbFromReplica + " cascade");
   }
 
+  @Test
+  public void testIfReplTargetSetInIncremental() throws Throwable {
+    WarehouseInstance.Tuple tuplePrimary = primary
+            .run("use " + primaryDbName)
+            .run("create table t1 (place string) partitioned by (country string)")
+            .run("insert into table t1 partition(country='india') values ('bangalore')")
+            .dump(primaryDbName);
+
+    // Bootstrap Repl A -> B
+    replica.load(replicatedDbName, primaryDbName);
+
+    //Perform empty dump and load
+    primary.dump(primaryDbName);
+    replica.load(replicatedDbName, primaryDbName);
+    assertTrue(ReplUtils.isTargetOfReplication(replica.getDatabase(replicatedDbName)));
+
+    replica.dumpFailure(replicatedDbName);  //can not dump db which is target of replication
+
+    replica.run("ALTER DATABASE " + replicatedDbName + " Set DBPROPERTIES('repl.target.for' = '')");
+    assertFalse(ReplUtils.isTargetOfReplication(replica.getDatabase(replicatedDbName)));
+    replica.dump(replicatedDbName);
+
+    // do a empty incremental load to allow dump of replicatedDbName
+    primary.run("ALTER DATABASE " + primaryDbName + " Set DBPROPERTIES('custom_property1' = 'custom_value1')")
+            .dump(primaryDbName, Collections.emptyList());
+    replica.load(replicatedDbName, primaryDbName);
+    compareDbProperties(primary.getDatabase(primaryDbName).getParameters(),
+            replica.getDatabase(replicatedDbName).getParameters());
+    assertTrue(ReplUtils.isTargetOfReplication(replica.getDatabase(replicatedDbName)));
+
+    replica.dumpFailure(replicatedDbName);    //Cannot dump database which is target of replication.
+  }
+
   @Test
   public void testIfCkptPropIgnoredByExport() throws Throwable {
     WarehouseInstance.Tuple tuplePrimary = primary
@@ -1563,6 +1595,16 @@ public Boolean apply(NotificationEvent entry) {
             .run(" drop database if exists " + replicatedDbName_CM + " cascade");
   }
 
+  private void compareDbProperties(Map<String, String> primaryDbProps, Map<String, String> replicaDbProps){
+    for (Map.Entry<String, String> prop : primaryDbProps.entrySet()) {
+      if (prop.getKey().equals(SOURCE_OF_REPLICATION)) {
+        continue;
+      }
+      assertTrue(replicaDbProps.containsKey(prop.getKey()));
+      assertTrue(replicaDbProps.get(prop.getKey()).equals(prop.getValue()));
+    }
+  }
+
   // This requires the tables are loaded in a fixed sorted order.
   @Test
   public void testBootstrapLoadRetryAfterFailureForAlterTable() throws Throwable {
diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/WarehouseInstance.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/WarehouseInstance.java
index 89e535d42a..565bcba364 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/WarehouseInstance.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/WarehouseInstance.java
@@ -458,11 +458,6 @@ private void verifyReplTargetProperty(Map<String, String> props) {
     assertTrue(props.containsKey(ReplConst.REPL_TARGET_TABLE_PROPERTY));
   }
 
-  public void verifyTargetOfReplProperty(String dbName) throws Exception {
-    Database db = getDatabase(dbName);
-    assertTrue(db.getParameters().containsKey(ReplUtils.TARGET_OF_REPLICATION));
-    assertTrue(Boolean.getBoolean(db.getParameters().get(ReplUtils.TARGET_OF_REPLICATION)));
-  }
 
   public WarehouseInstance verifyReplTargetProperty(String dbName, List<String> tblNames) throws Exception {
     for (String tblName : tblNames) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadTask.java
index 03092120d3..f7c0f608d4 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadTask.java
@@ -611,6 +611,18 @@ private int executeIncrementalLoad() throws Exception {
     if (work.replScopeModified) {
       dropTablesExcludedInReplScope(work.currentReplScope);
     }
+    if (!ReplUtils.isTargetOfReplication(getHive().getDatabase(work.dbNameToLoadIn))) {
+      Map<String, String> props = new HashMap<>();
+      props.put(ReplUtils.TARGET_OF_REPLICATION, "true");
+      AlterDatabaseSetPropertiesDesc setTargetDesc = new AlterDatabaseSetPropertiesDesc(work.dbNameToLoadIn, props, null);
+      Task<?> addReplTargetPropTask =
+              TaskFactory.get(new DDLWork(new HashSet<>(), new HashSet<>(), setTargetDesc, true,
+                      work.dumpDirectory, work.getMetricCollector()), conf);
+      if (this.childTasks == null) {
+        this.childTasks = new ArrayList<>();
+      }
+      this.childTasks.add(addReplTargetPropTask);
+    }
     IncrementalLoadTasksBuilder builder = work.incrementalLoadTasksBuilder();
     // If incremental events are already applied, then check and perform if need to bootstrap any tables.
     if (!builder.hasMoreWork() && work.isLastReplIDUpdated()) {
