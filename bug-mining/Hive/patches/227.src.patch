diff --git a/CHANGES.txt b/CHANGES.txt
index 895d19e956..3d0ca5512d 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -12,6 +12,8 @@ Trunk -  Unreleased
 
   BUG FIXES
 
+    HIVE-734. problem while inserting nulls. (Ning Zhang via namit)
+
 Release 0.4.0 -  Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 3d747a0fc5..f8d13e7842 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -128,6 +128,8 @@
 import org.apache.hadoop.hive.ql.hooks.ReadEntity;
 import org.apache.hadoop.hive.ql.hooks.WriteEntity;
 
+import org.apache.hadoop.hive.serde.Constants;
+
 /**
  * Implementation of the semantic analyzer
  */
@@ -2525,7 +2527,21 @@ private Operator genFileSinkPlan(String dest, QB qb,
           
           first = false;
           cols = cols.concat(colInfo.getInternalName());
-          colTypes = colTypes.concat(colInfo.getType().getTypeName());
+          
+          // Replace VOID type with string when the output is a temp table or local files.
+          // A VOID type can be generated under the query:
+          // 
+          //     select NULL from tt; 
+          // or
+          //     insert overwrite local directory "abc" select NULL from tt;
+          // 
+          // where there is no column type to which the NULL value should be converted.
+          // 
+          String tName = colInfo.getType().getTypeName();
+          if ( tName.equals(Constants.VOID_TYPE_NAME) )
+            colTypes = colTypes.concat(Constants.STRING_TYPE_NAME);
+          else
+            colTypes = colTypes.concat(tName);
         }
 
         if (!ctx.isMRTmpFileURI(destStr)) {
diff --git a/ql/src/test/queries/clientpositive/null_column.q b/ql/src/test/queries/clientpositive/null_column.q
new file mode 100644
index 0000000000..b3e8eaacf5
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/null_column.q
@@ -0,0 +1,23 @@
+drop table temp_null;
+drop table tt;
+drop table tt_b;
+
+create table temp_null(a int) stored as textfile;
+load data local inpath '../data/files/test.dat' overwrite into table temp_null;
+
+select null, null from temp_null;
+
+create table tt(a int, b string);
+insert overwrite table tt select null, null from temp_null;
+select * from tt;
+
+create table tt_b(a int, b string) row format serde "org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe";
+insert overwrite table tt_b select null, null from temp_null;
+select * from tt_b;
+
+insert overwrite directory "../build/ql/test/data/warehouse/null_columns.out" select null, null from temp_null;
+dfs -cat ../build/ql/test/data/warehouse/null_columns.out/*;
+
+drop table tt;
+drop table tt_b;
+drop table temp_null;
diff --git a/ql/src/test/results/clientpositive/null_column.q.out b/ql/src/test/results/clientpositive/null_column.q.out
new file mode 100644
index 0000000000..cfdfc9c50b
--- /dev/null
+++ b/ql/src/test/results/clientpositive/null_column.q.out
@@ -0,0 +1,52 @@
+query: drop table temp_null
+query: drop table tt
+query: drop table tt_b
+query: create table temp_null(a int) stored as textfile
+query: load data local inpath '../data/files/test.dat' overwrite into table temp_null
+query: select null, null from temp_null
+Input: default/temp_null
+Output: file:/data/users/nzhang/work/734/734-trunk-apache-hive/build/ql/tmp/2083094836/10000
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+query: create table tt(a int, b string)
+query: insert overwrite table tt select null, null from temp_null
+Input: default/temp_null
+Output: default/tt
+query: select * from tt
+Input: default/tt
+Output: file:/data/users/nzhang/work/734/734-trunk-apache-hive/build/ql/tmp/2090243542/10000
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+query: create table tt_b(a int, b string) row format serde "org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe"
+query: insert overwrite table tt_b select null, null from temp_null
+Input: default/temp_null
+Output: default/tt_b
+query: select * from tt_b
+Input: default/tt_b
+Output: file:/data/users/nzhang/work/734/734-trunk-apache-hive/build/ql/tmp/1191541403/10000
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+NULL	NULL
+query: insert overwrite directory "../build/ql/test/data/warehouse/null_columns.out" select null, null from temp_null
+Input: default/temp_null
+Output: ../build/ql/test/data/warehouse/null_columns.out
+\N\N
+\N\N
+\N\N
+\N\N
+\N\N
+\N\N
+query: drop table tt
+query: drop table tt_b
+query: drop table temp_null
