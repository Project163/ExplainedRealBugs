diff --git a/llap-client/src/java/org/apache/hadoop/hive/llap/registry/ServiceInstanceSet.java b/llap-client/src/java/org/apache/hadoop/hive/llap/registry/ServiceInstanceSet.java
index 054403879f..cc124e76ee 100644
--- a/llap-client/src/java/org/apache/hadoop/hive/llap/registry/ServiceInstanceSet.java
+++ b/llap-client/src/java/org/apache/hadoop/hive/llap/registry/ServiceInstanceSet.java
@@ -31,7 +31,7 @@ public interface ServiceInstanceSet {
    * 
    * @return
    */
-  public Collection<ServiceInstance> getAll();
+  Collection<ServiceInstance> getAll();
 
   /**
    * Gets a list containing all the instances. This list has the same iteration order across
@@ -40,7 +40,7 @@ public interface ServiceInstanceSet {
    *                          across calls, by inserting inactive instances to replace the
    *                          removed ones.
    */
-  public Collection<ServiceInstance> getAllInstancesOrdered(boolean consistentIndexes);
+  Collection<ServiceInstance> getAllInstancesOrdered(boolean consistentIndexes);
 
   /**
    * Get an instance by worker identity.
@@ -48,7 +48,7 @@ public interface ServiceInstanceSet {
    * @param name
    * @return
    */
-  public ServiceInstance getInstance(String name);
+  ServiceInstance getInstance(String name);
 
   /**
    * Get a list of service instances for a given host.
@@ -58,12 +58,12 @@ public interface ServiceInstanceSet {
    * @param host
    * @return
    */
-  public Set<ServiceInstance> getByHost(String host);
+  Set<ServiceInstance> getByHost(String host);
 
   /**
    * Get number of instances in the currently availabe.
    *
    * @return - number of instances
    */
-  public int size();
-}
\ No newline at end of file
+  int size();
+}
diff --git a/llap-client/src/java/org/apache/hadoop/hive/llap/registry/ServiceRegistry.java b/llap-client/src/java/org/apache/hadoop/hive/llap/registry/ServiceRegistry.java
index 4938c07b6f..8d7fcb7767 100644
--- a/llap-client/src/java/org/apache/hadoop/hive/llap/registry/ServiceRegistry.java
+++ b/llap-client/src/java/org/apache/hadoop/hive/llap/registry/ServiceRegistry.java
@@ -15,6 +15,8 @@
 
 import java.io.IOException;
 
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+
 /**
  * ServiceRegistry interface for switching between fixed host and dynamic registry implementations.
  */
@@ -67,4 +69,9 @@ public interface ServiceRegistry {
    */
   public void registerStateChangeListener(ServiceInstanceStateChangeListener listener)
       throws IOException;
+
+  /**
+   * @return The application ID of the LLAP cluster.
+   */
+  ApplicationId getApplicationId() throws IOException;
 }
diff --git a/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapFixedRegistryImpl.java b/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapFixedRegistryImpl.java
index 10ff82e474..45ac5bf0f7 100644
--- a/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapFixedRegistryImpl.java
+++ b/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapFixedRegistryImpl.java
@@ -40,6 +40,7 @@
 import org.apache.hadoop.hive.llap.registry.ServiceRegistry;
 import org.apache.hadoop.net.NetUtils;
 import org.apache.hadoop.util.StringUtils;
+import org.apache.hadoop.yarn.api.records.ApplicationId;
 import org.apache.hadoop.yarn.api.records.Resource;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -271,4 +272,9 @@ public void registerStateChangeListener(final ServiceInstanceStateChangeListener
   public String toString() {
     return String.format("FixedRegistry hosts=%s", StringUtils.join(",", this.hosts));
   }
+
+  @Override
+  public ApplicationId getApplicationId() throws IOException {
+    return null; // No good way to find out (may even have no app).
+  }
 }
diff --git a/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapRegistryService.java b/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapRegistryService.java
index badc1827f4..2a5afac22d 100644
--- a/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapRegistryService.java
+++ b/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapRegistryService.java
@@ -24,6 +24,7 @@
 import org.apache.hadoop.hive.llap.registry.ServiceInstanceStateChangeListener;
 import org.apache.hadoop.hive.llap.registry.ServiceRegistry;
 import org.apache.hadoop.service.AbstractService;
+import org.apache.hadoop.yarn.api.records.ApplicationId;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -56,6 +57,7 @@ public static synchronized LlapRegistryService getClient(Configuration conf) {
     String hosts = HiveConf.getTrimmedVar(conf, HiveConf.ConfVars.LLAP_DAEMON_SERVICE_HOSTS);
     Preconditions.checkNotNull(hosts, ConfVars.LLAP_DAEMON_SERVICE_HOSTS.toString() + " must be defined");
     LlapRegistryService registry;
+    // TODO: this is not going to work with multiple users.
     if (hosts.startsWith("@")) {
       // Caching instances only in case of the YARN registry. Each host based list will get it's own copy.
       String name = hosts.substring(1);
@@ -143,4 +145,8 @@ public boolean isDynamic() {
   public String getWorkerIdentity() {
     return identity;
   }
+
+  public ApplicationId getApplicationId() throws IOException {
+    return registry.getApplicationId();
+  }
 }
diff --git a/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapZookeeperRegistryImpl.java b/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapZookeeperRegistryImpl.java
index 34ba6bbec6..ac48b67eb3 100644
--- a/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapZookeeperRegistryImpl.java
+++ b/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapZookeeperRegistryImpl.java
@@ -71,6 +71,8 @@
 import org.apache.hadoop.security.SecurityUtil;
 import org.apache.hadoop.security.UserGroupInformation;
 import org.apache.hadoop.security.authentication.util.KerberosUtil;
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ContainerId;
 import org.apache.hadoop.yarn.api.records.Resource;
 import org.apache.hadoop.yarn.conf.YarnConfiguration;
 import org.apache.zookeeper.ZooDefs;
@@ -573,11 +575,8 @@ public DynamicServiceInstanceSet(final PathChildrenCache cache) {
 
     private void populateCache() {
       for (ChildData childData : instancesCache.getCurrentData()) {
-        if (childData == null) continue;
-        byte[] data = childData.getData();
+        byte[] data = getWorkerData(childData);
         if (data == null) continue;
-        String nodeName = extractNodeName(childData);
-        if (!nodeName.startsWith(WORKER_PREFIX)) continue;
         try {
           ServiceRecord srv = encoder.fromBytes(childData.getPath(), data);
           ServiceInstance instance = new DynamicServiceInstance(srv);
@@ -598,6 +597,33 @@ public Collection<ServiceInstance> getAll() {
       return instances;
     }
 
+    public ApplicationId getApplicationId() {
+      for (ChildData childData : instancesCache.getCurrentData()) {
+        byte[] data = getWorkerData(childData);
+        if (data == null) continue;
+        ServiceRecord sr = null;
+        try {
+          sr = encoder.fromBytes(childData.getPath(), data);
+        } catch (IOException e) {
+          LOG.error("Unable to decode data for zkpath: {}." +
+              " Ignoring from current instances list..", childData.getPath());
+          continue;
+        }
+        String containerStr = sr.get(HiveConf.ConfVars.LLAP_DAEMON_CONTAINER_ID.varname);
+        if (containerStr == null || containerStr.isEmpty()) continue;
+        return ContainerId.fromString(containerStr).getApplicationAttemptId().getApplicationId();
+      }
+      return null;
+    }
+
+    private byte[] getWorkerData(ChildData childData) {
+        if (childData == null) return null;
+        byte[] data = childData.getData();
+        if (data == null) return null;
+        if (!extractNodeName(childData).startsWith(WORKER_PREFIX)) return null;
+        return data;
+    }
+
     @Override
     public Collection<ServiceInstance> getAllInstancesOrdered(boolean consistentIndexes) {
       Map<String, Long> slotByWorker = new HashMap<String, Long>();
@@ -765,6 +791,12 @@ public ServiceInstanceSet getInstances(String component) throws IOException {
     return instances;
   }
 
+  @Override
+  public ApplicationId getApplicationId() throws IOException {
+    getInstances(null);
+    return instances.getApplicationId();
+  }
+
   @Override
   public synchronized void registerStateChangeListener(
       final ServiceInstanceStateChangeListener listener)
diff --git a/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskCommunicator.java b/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskCommunicator.java
index c7f4ce8693..4148dc3213 100644
--- a/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskCommunicator.java
+++ b/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskCommunicator.java
@@ -143,6 +143,7 @@ public LlapTaskCommunicator(
     Preconditions.checkState((token != null) == UserGroupInformation.isSecurityEnabled());
 
     // Not closing this at the moment at shutdown, since this could be a shared instance.
+    // TODO: this is unused.
     serviceRegistry = LlapRegistryService.getClient(conf);
 
     umbilical = new LlapTaskUmbilicalProtocolImpl(getUmbilical());
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
index efa2bdc81c..d6b7f083ff 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
@@ -1735,8 +1735,8 @@ public int execute(boolean deferClose) throws CommandNeedRetryException {
 
       SessionState ss = SessionState.get();
       hookContext = new HookContext(plan, queryState, ctx.getPathToCS(), ss.getUserName(),
-          ss.getUserIpAddress(), InetAddress.getLocalHost().getHostAddress(), operationId, ss.getSessionId(),
-          Thread.currentThread().getName(), ss.isHiveServerQuery(), perfLogger);
+          ss.getUserIpAddress(), InetAddress.getLocalHost().getHostAddress(), operationId,
+          ss.getSessionId(), Thread.currentThread().getName(), ss.isHiveServerQuery(), perfLogger);
       hookContext.setHookType(HookContext.HookType.PRE_EXEC_HOOK);
 
       for (Hook peh : getHooks(HiveConf.ConfVars.PREEXECHOOKS)) {
@@ -1770,9 +1770,8 @@ public int execute(boolean deferClose) throws CommandNeedRetryException {
 
       setQueryDisplays(plan.getRootTasks());
       int mrJobs = Utilities.getMRTasks(plan.getRootTasks()).size();
-      int jobs = mrJobs
-        + Utilities.getTezTasks(plan.getRootTasks()).size()
-        + Utilities.getSparkTasks(plan.getRootTasks()).size();
+      int jobs = mrJobs + Utilities.getTezTasks(plan.getRootTasks()).size()
+          + Utilities.getSparkTasks(plan.getRootTasks()).size();
       if (jobs > 0) {
         logMrWarning(mrJobs);
         console.printInfo("Query ID = " + queryId);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/Utils.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/Utils.java
index 113aa4932c..d691e18fa4 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/Utils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/Utils.java
@@ -38,8 +38,8 @@ public static SplitLocationProvider getSplitLocationProvider(Configuration conf,
     SplitLocationProvider splitLocationProvider;
     LOG.info("SplitGenerator using llap affinitized locations: " + useCustomLocations);
     if (useCustomLocations) {
-      LlapRegistryService serviceRegistry;
-      serviceRegistry = LlapRegistryService.getClient(conf);
+      LlapRegistryService serviceRegistry = LlapRegistryService.getClient(conf);
+      LOG.info("Using LLAP instance " + serviceRegistry.getApplicationId());
 
       Collection<ServiceInstance> serviceInstances =
           serviceRegistry.getInstances().getAllInstancesOrdered(true);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/hooks/ATSHook.java b/ql/src/java/org/apache/hadoop/hive/ql/hooks/ATSHook.java
index d1c795384d..55b922bb7b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/hooks/ATSHook.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/hooks/ATSHook.java
@@ -17,7 +17,7 @@
  */
 package org.apache.hadoop.hive.ql.hooks;
 
-import java.io.Serializable;
+import java.io.IOException;
 import java.net.InetAddress;
 import java.util.ArrayList;
 import java.util.HashMap;
@@ -27,14 +27,13 @@
 import java.util.Set;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
 import java.util.concurrent.LinkedBlockingQueue;
 import java.util.concurrent.ThreadFactory;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 
-import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.llap.registry.impl.LlapRegistryService;
 import org.apache.hadoop.hive.ql.QueryPlan;
 import org.apache.hadoop.hive.ql.QueryState;
 import org.apache.hadoop.hive.ql.exec.ExplainTask;
@@ -44,7 +43,7 @@
 import org.apache.hadoop.hive.ql.log.PerfLogger;
 import org.apache.hadoop.hive.ql.parse.ExplainConfiguration;
 import org.apache.hadoop.hive.ql.plan.ExplainWork;
-import org.apache.hadoop.util.StringUtils;
+import org.apache.hadoop.yarn.api.records.ApplicationId;
 import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity;
 import org.apache.hadoop.yarn.api.records.timeline.TimelineEvent;
 import org.apache.hadoop.yarn.client.api.TimelineClient;
@@ -73,7 +72,7 @@ private enum EventTypes { QUERY_SUBMITTED, QUERY_COMPLETED };
 
   private enum OtherInfoTypes {
     QUERY, STATUS, TEZ, MAPRED, INVOKER_INFO, SESSION_ID, THREAD_NAME, VERSION,
-    CLIENT_IP_ADDRESS, HIVE_ADDRESS, HIVE_INSTANCE_TYPE, CONF, PERF,
+    CLIENT_IP_ADDRESS, HIVE_ADDRESS, HIVE_INSTANCE_TYPE, CONF, PERF, LLAP_APP_ID
   };
   private enum ExecutionMode {
     MR, TEZ, LLAP, SPARK, NONE
@@ -195,12 +194,13 @@ public void run() {
                   hiveInstanceAddress = InetAddress.getLocalHost().getHostAddress();
                 }
                 String hiveInstanceType = hookContext.isHiveServerQuery() ? "HS2" : "CLI";
+                ApplicationId llapId = determineLlapId(conf, plan);
                 fireAndForget(
                     createPreHookEvent(queryId, query, explainPlan, queryStartTime,
                         user, requestuser, numMrJobs, numTezJobs, opId,
                         hookContext.getIpAddress(), hiveInstanceAddress, hiveInstanceType,
                         hookContext.getSessionId(), logID, hookContext.getThreadId(), executionMode,
-                        tablesRead, tablesWritten, conf));
+                        tablesRead, tablesWritten, conf, llapId));
                 break;
               case POST_EXEC_HOOK:
                 fireAndForget(createPostHookEvent(queryId, currentTime, user, requestuser, true, opId, hookContext.getPerfLogger()));
@@ -260,7 +260,8 @@ TimelineEntity createPreHookEvent(String queryId, String query, JSONObject expla
       long startTime, String user, String requestuser, int numMrJobs, int numTezJobs, String opId,
       String clientIpAddress, String hiveInstanceAddress, String hiveInstanceType,
       String sessionID, String logID, String threadId, String executionMode,
-      List<String> tablesRead, List<String> tablesWritten, HiveConf conf) throws Exception {
+      List<String> tablesRead, List<String> tablesWritten, HiveConf conf, ApplicationId llapAppId)
+          throws Exception {
 
     JSONObject queryObj = new JSONObject(new LinkedHashMap<>());
     queryObj.put("queryText", query);
@@ -316,6 +317,9 @@ TimelineEntity createPreHookEvent(String queryId, String query, JSONObject expla
     atsEntity.addOtherInfo(OtherInfoTypes.HIVE_ADDRESS.name(), hiveInstanceAddress);
     atsEntity.addOtherInfo(OtherInfoTypes.HIVE_INSTANCE_TYPE.name(), hiveInstanceType);
     atsEntity.addOtherInfo(OtherInfoTypes.CONF.name(), confObj.toString());
+    if (llapAppId != null) {
+      atsEntity.addOtherInfo(OtherInfoTypes.LLAP_APP_ID.name(), llapAppId.toString());
+    }
 
     return atsEntity;
   }
@@ -362,4 +366,24 @@ public void run() {
       }
     });
   }
+
+  private ApplicationId determineLlapId(final HiveConf conf, QueryPlan plan) throws IOException {
+    // Note: for now, LLAP is only supported in Tez tasks. Will never come to MR; others may
+    //       be added here, although this is only necessary to have extra debug information.
+    for (TezTask tezTask : Utilities.getTezTasks(plan.getRootTasks())) {
+      if (!tezTask.getWork().getLlapMode()) continue;
+      // In HS2, the client should have been cached already for the common case.
+      // Otherwise, this may actually introduce delay to compilation for the first query.
+      String hosts = HiveConf.getVar(conf, HiveConf.ConfVars.LLAP_DAEMON_SERVICE_HOSTS);
+      if (hosts != null && !hosts.isEmpty()) {
+        ApplicationId llapId = LlapRegistryService.getClient(conf).getApplicationId();
+        LOG.info("The query will use LLAP instance " + llapId + " (" + hosts + ")");
+        return llapId;
+      } else {
+        LOG.info("Cannot determine LLAP instance on client - service hosts are not set");
+        return null;
+      }
+    }
+    return null;
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/hooks/HookContext.java b/ql/src/java/org/apache/hadoop/hive/ql/hooks/HookContext.java
index c94100c11a..359c238509 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/hooks/HookContext.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/hooks/HookContext.java
@@ -34,6 +34,7 @@
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.hive.shims.Utils;
 import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.hadoop.yarn.api.records.ApplicationId;
 /**
  * Hook Context keeps all the necessary information for all the hooks.
  * New implemented hook can get the query plan, job conf and the list of all completed tasks from this hook context
@@ -65,12 +66,13 @@ static public enum HookType {
   private final String operationId;
   private final String sessionId;
   private final String threadId;
-  private boolean isHiveServerQuery;
-  private PerfLogger perfLogger;
+  private final boolean isHiveServerQuery;
+  private final PerfLogger perfLogger;
 
   public HookContext(QueryPlan queryPlan, QueryState queryState,
-      Map<String, ContentSummary> inputPathToContentSummary, String userName, String ipAddress, String hiveInstanceAddress,
-      String operationId, String sessionId, String threadId, boolean isHiveServerQuery, PerfLogger perfLogger) throws Exception {
+      Map<String, ContentSummary> inputPathToContentSummary, String userName, String ipAddress,
+      String hiveInstanceAddress, String operationId, String sessionId, String threadId,
+      boolean isHiveServerQuery, PerfLogger perfLogger) throws Exception {
     this.queryPlan = queryPlan;
     this.queryState = queryState;
     this.conf = queryState.getConf();
@@ -227,16 +229,7 @@ public boolean isHiveServerQuery() {
     return isHiveServerQuery;
   }
 
-  public void setHiveServerQuery(boolean isHiveServerQuery) {
-    this.isHiveServerQuery = isHiveServerQuery;
-  }
-
   public PerfLogger getPerfLogger() {
     return perfLogger;
   }
-
-  public void setPerfLogger(PerfLogger perfLogger) {
-    this.perfLogger = perfLogger;
-  }
-
 }
diff --git a/service/src/java/org/apache/hive/service/server/HiveServer2.java b/service/src/java/org/apache/hive/service/server/HiveServer2.java
index bc969f2c89..e5f449122b 100644
--- a/service/src/java/org/apache/hive/service/server/HiveServer2.java
+++ b/service/src/java/org/apache/hive/service/server/HiveServer2.java
@@ -55,6 +55,7 @@
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
 import org.apache.hadoop.hive.llap.coordinator.LlapCoordinator;
+import org.apache.hadoop.hive.llap.registry.impl.LlapRegistryService;
 import org.apache.hadoop.hive.ql.exec.spark.session.SparkSessionManagerImpl;
 import org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager;
 import org.apache.hadoop.hive.ql.metadata.Hive;
@@ -90,6 +91,7 @@
 
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.base.Joiner;
+import com.google.common.base.Preconditions;
 
 /**
  * HiveServer2.
@@ -152,6 +154,13 @@ public void run() {
         throw new RuntimeException(e);
       }
     }
+    // Trigger the creation of LLAP registry client, if in use. Clients may be using a different
+    // cluster than the default one, but at least for the default case we'd have it covered.
+    String llapHosts = HiveConf.getVar(hiveConf, HiveConf.ConfVars.LLAP_DAEMON_SERVICE_HOSTS);
+    if (llapHosts != null && !llapHosts.isEmpty()) {
+      LlapRegistryService.getClient(hiveConf);
+    }
+
     // Create views registry
     try {
       Hive sessionHive = Hive.get(hiveConf);
