diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/MemoryManager.java b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/MemoryManager.java
index 821bd357a0..6432d6ea4f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/MemoryManager.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/MemoryManager.java
@@ -24,10 +24,13 @@
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.conf.HiveConf;
 
+import com.google.common.base.Preconditions;
+
 import java.io.IOException;
 import java.lang.management.ManagementFactory;
 import java.util.HashMap;
 import java.util.Map;
+import java.util.concurrent.locks.ReentrantLock;
 
 /**
  * Implements a memory manager that keeps a global context of how many ORC
@@ -35,9 +38,9 @@
  * dynamic partitions, it is easy to end up with many writers in the same task.
  * By managing the size of each allocation, we try to cut down the size of each
  * allocation and keep the task from running out of memory.
- *
- * This class is thread safe and uses synchronization around the shared state
- * to prevent race conditions.
+ * 
+ * This class is not thread safe, but is re-entrant - ensure creation and all
+ * invocations are triggered from the same thread.
  */
 class MemoryManager {
 
@@ -54,6 +57,14 @@ class MemoryManager {
   private long totalAllocation = 0;
   private double currentScale = 1;
   private int rowsAddedSinceCheck = 0;
+  private final OwnedLock ownerLock = new OwnedLock();
+
+  @SuppressWarnings("serial")
+  private static class OwnedLock extends ReentrantLock {
+    public Thread getOwner() {
+      return super.getOwner();
+    }
+  }
 
   private static class WriterInfo {
     long allocation;
@@ -84,6 +95,17 @@ public interface Callback {
     double maxLoad = conf.getFloat(poolVar.varname, poolVar.defaultFloatVal);
     totalMemoryPool = Math.round(ManagementFactory.getMemoryMXBean().
         getHeapMemoryUsage().getMax() * maxLoad);
+    ownerLock.lock();
+  }
+
+  /**
+   * Light weight thread-safety check for multi-threaded access patterns
+   */
+  private void checkOwner() {
+    Preconditions.checkArgument(ownerLock.isHeldByCurrentThread(),
+        "Owner thread expected %s, got %s",
+        ownerLock.getOwner(),
+        Thread.currentThread());
   }
 
   /**
@@ -92,8 +114,9 @@ public interface Callback {
    * @param path the file that is being written
    * @param requestedAllocation the requested buffer size
    */
-  synchronized void addWriter(Path path, long requestedAllocation,
+  void addWriter(Path path, long requestedAllocation,
                               Callback callback) throws IOException {
+    checkOwner();
     WriterInfo oldVal = writerList.get(path);
     // this should always be null, but we handle the case where the memory
     // manager wasn't told that a writer wasn't still in use and the task
@@ -115,7 +138,8 @@ synchronized void addWriter(Path path, long requestedAllocation,
    * Remove the given writer from the pool.
    * @param path the file that has been closed
    */
-  synchronized void removeWriter(Path path) throws IOException {
+  void removeWriter(Path path) throws IOException {
+    checkOwner();
     WriterInfo val = writerList.get(path);
     if (val != null) {
       writerList.remove(path);
@@ -144,7 +168,7 @@ long getTotalMemoryPool() {
    * @return a fraction between 0.0 and 1.0 of the requested size that is
    * available for each writer.
    */
-  synchronized double getAllocationScale() {
+  double getAllocationScale() {
     return currentScale;
   }
 
@@ -152,7 +176,7 @@ synchronized double getAllocationScale() {
    * Give the memory manager an opportunity for doing a memory check.
    * @throws IOException
    */
-  synchronized void addedRow() throws IOException {
+  void addedRow() throws IOException {
     if (++rowsAddedSinceCheck >= ROWS_BETWEEN_CHECKS) {
       notifyWriters();
     }
@@ -163,6 +187,7 @@ synchronized void addedRow() throws IOException {
    * @throws IOException
    */
   void notifyWriters() throws IOException {
+    checkOwner();
     LOG.debug("Notifying writers after " + rowsAddedSinceCheck);
     for(WriterInfo writer: writerList.values()) {
       boolean flushed = writer.callback.checkMemory(currentScale);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcFile.java b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcFile.java
index 61ee8b991a..4e2bd6a22e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcFile.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcFile.java
@@ -503,14 +503,19 @@ public static Writer createWriter(FileSystem fs,
                         .rowIndexStride(rowIndexStride));
   }
 
-  private static MemoryManager memoryManager = null;
+  private static ThreadLocal<MemoryManager> memoryManager = null;
 
-  private static synchronized
-  MemoryManager getMemoryManager(Configuration conf) {
+  private static synchronized MemoryManager getMemoryManager(
+      final Configuration conf) {
     if (memoryManager == null) {
-      memoryManager = new MemoryManager(conf);
+      memoryManager = new ThreadLocal<MemoryManager>() {
+        @Override
+        protected MemoryManager initialValue() {
+          return new MemoryManager(conf);
+        }
+      };
     }
-    return memoryManager;
+    return memoryManager.get();
   }
 
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java
index d6e4a962da..61a90ddef5 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java
@@ -95,9 +95,14 @@
  * sub-types. Each of the TreeWriters writes the column's data as a set of
  * streams.
  *
- * This class is synchronized so that multi-threaded access is ok. In
- * particular, because the MemoryManager is shared between writers, this class
- * assumes that checkMemory may be called from a separate thread.
+ * This class is unsynchronized like most Stream objects, so from the creation of an OrcFile and all
+ * access to a single instance has to be from a single thread.
+ * 
+ * There are no known cases where these happen between different threads today.
+ * 
+ * Caveat: the MemoryManager is created during WriterOptions create, that has to be confined to a single
+ * thread as well.
+ * 
  */
 public class WriterImpl implements Writer, MemoryManager.Callback {
 
@@ -342,7 +347,7 @@ public static CompressionCodec createCodec(CompressionKind kind) {
   }
 
   @Override
-  public synchronized boolean checkMemory(double newScale) throws IOException {
+  public boolean checkMemory(double newScale) throws IOException {
     long limit = (long) Math.round(adjustedStripeSize * newScale);
     long size = estimateStripeSize();
     if (LOG.isDebugEnabled()) {
@@ -2407,21 +2412,19 @@ private long estimateStripeSize() {
   }
 
   @Override
-  public synchronized void addUserMetadata(String name, ByteBuffer value) {
+  public void addUserMetadata(String name, ByteBuffer value) {
     userMetadata.put(name, ByteString.copyFrom(value));
   }
 
   @Override
   public void addRow(Object row) throws IOException {
-    synchronized (this) {
-      treeWriter.write(row);
-      rowsInStripe += 1;
-      if (buildIndex) {
-        rowsInIndex += 1;
-
-        if (rowsInIndex >= rowIndexStride) {
-          createRowIndexEntry();
-        }
+    treeWriter.write(row);
+    rowsInStripe += 1;
+    if (buildIndex) {
+      rowsInIndex += 1;
+
+      if (rowsInIndex >= rowIndexStride) {
+        createRowIndexEntry();
       }
     }
     memoryManager.addedRow();
@@ -2435,13 +2438,12 @@ public void close() throws IOException {
     // remove us from the memory manager so that we don't get any callbacks
     memoryManager.removeWriter(path);
     // actually close the file
-    synchronized (this) {
-      flushStripe();
-      int metadataLength = writeMetadata(rawWriter.getPos());
-      int footerLength = writeFooter(rawWriter.getPos() - metadataLength);
-      rawWriter.writeByte(writePostScript(footerLength, metadataLength));
-      rawWriter.close();
-    }
+    flushStripe();
+    int metadataLength = writeMetadata(rawWriter.getPos());
+    int footerLength = writeFooter(rawWriter.getPos() - metadataLength);
+    rawWriter.writeByte(writePostScript(footerLength, metadataLength));
+    rawWriter.close();
+
   }
 
   /**
@@ -2463,7 +2465,7 @@ public long getNumberOfRows() {
   }
 
   @Override
-  public synchronized long writeIntermediateFooter() throws IOException {
+  public long writeIntermediateFooter() throws IOException {
     // flush any buffered rows
     flushStripe();
     // write a footer
