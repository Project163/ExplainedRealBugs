diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
index ba28bc71ff..2dc66f7efc 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
@@ -18,16 +18,6 @@
 
 package org.apache.hadoop.hive.ql.optimizer;
 
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.Stack;
-
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator;
@@ -39,7 +29,6 @@
 import org.apache.hadoop.hive.ql.exec.LateralViewForwardOperator;
 import org.apache.hadoop.hive.ql.exec.LateralViewJoinOperator;
 import org.apache.hadoop.hive.ql.exec.LimitOperator;
-import org.apache.hadoop.hive.ql.exec.MapJoinOperator;
 import org.apache.hadoop.hive.ql.exec.Operator;
 import org.apache.hadoop.hive.ql.exec.OperatorFactory;
 import org.apache.hadoop.hive.ql.exec.PTFOperator;
@@ -76,6 +65,16 @@
 import org.apache.hadoop.hive.serde2.objectinspector.StructField;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.Stack;
+
 /**
  * Factory for generating the different node processors used by ColumnPruner.
  */
@@ -600,8 +599,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx ctx,
           // revert output cols of SEL(*) to ExprNodeColumnDesc
           String[] tabcol = rr.reverseLookup(col);
           ColumnInfo colInfo = rr.get(tabcol[0], tabcol[1]);
-          ExprNodeColumnDesc colExpr = new ExprNodeColumnDesc(colInfo.getType(),
-              colInfo.getInternalName(), colInfo.getTabAlias(), colInfo.getIsVirtualCol());
+          ExprNodeColumnDesc colExpr = new ExprNodeColumnDesc(colInfo);
           colList.add(colExpr);
           outputColNames.add(col);
         }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java
index d79879cfcb..477be1daaa 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java
@@ -18,14 +18,8 @@
 
 package org.apache.hadoop.hive.ql.optimizer;
 
-import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.Stack;
+import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -72,8 +66,14 @@
 import org.apache.hadoop.hive.ql.plan.TableDesc;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 
-import com.google.common.collect.Lists;
-import com.google.common.collect.Maps;
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.Stack;
 
 /**
  * When dynamic partitioning (with or without bucketing and sorting) is enabled, this optimization
@@ -209,8 +209,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
       ArrayList<ExprNodeDesc> newValueCols = Lists.newArrayList();
       Map<String, ExprNodeDesc> colExprMap = Maps.newHashMap();
       for (ColumnInfo ci : valColInfo) {
-        newValueCols.add(new ExprNodeColumnDesc(ci.getType(), ci.getInternalName(), ci
-            .getTabAlias(), ci.isHiddenVirtualCol()));
+        newValueCols.add(new ExprNodeColumnDesc(ci));
         colExprMap.put(ci.getInternalName(), newValueCols.get(newValueCols.size() - 1));
       }
       ReduceSinkDesc rsConf = getReduceSinkDesc(partitionPositions, sortPositions, sortOrder,
@@ -476,8 +475,7 @@ private ArrayList<ExprNodeDesc> getPositionsToExprNodes(List<Integer> pos,
 
       for (Integer idx : pos) {
         ColumnInfo ci = colInfos.get(idx);
-        ExprNodeColumnDesc encd = new ExprNodeColumnDesc(ci.getType(), ci.getInternalName(),
-            ci.getTabAlias(), ci.isHiddenVirtualCol());
+        ExprNodeColumnDesc encd = new ExprNodeColumnDesc(ci);
         cols.add(encd);
       }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/translator/JoinCondTypeCheckProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/translator/JoinCondTypeCheckProcFactory.java
index 406c18ef7c..38156c67d7 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/translator/JoinCondTypeCheckProcFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/translator/JoinCondTypeCheckProcFactory.java
@@ -17,15 +17,6 @@
  */
 package org.apache.hadoop.hive.ql.optimizer.optiq.translator;
 
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.Stack;
-
 import org.apache.hadoop.hive.ql.ErrorMsg;
 import org.apache.hadoop.hive.ql.exec.ColumnInfo;
 import org.apache.hadoop.hive.ql.exec.FunctionInfo;
@@ -47,6 +38,15 @@
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPAnd;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr;
 
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.Stack;
+
 /**
  * JoinCondTypeCheckProcFactory is used by Optiq planner(CBO) to generate Join Conditions from Join Condition AST.
  * Reasons for sub class:
@@ -99,8 +99,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
       if (!qualifiedAccess) {
         colInfo = getColInfo(ctx, null, tableOrCol, expr);
         // It's a column.
-        return new ExprNodeColumnDesc(colInfo.getType(), colInfo.getInternalName(),
-            colInfo.getTabAlias(), colInfo.getIsVirtualCol());
+        return new ExprNodeColumnDesc(colInfo);
       } else if (hasTableAlias(ctx, tableOrCol, expr)) {
         return null;
       } else {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java
index e403c5268d..15f0d7064c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java
@@ -18,13 +18,6 @@
 
 package org.apache.hadoop.hive.ql.optimizer.physical;
 
-import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.exec.ColumnInfo;
@@ -60,6 +53,13 @@
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+
 /**
  * GenMRSkewJoinProcessor.
  *
@@ -192,9 +192,7 @@ public static void processSkewJoin(JoinOperator joinOp,
         String newColName = i + "_VALUE_" + k; // any name, it does not matter.
         ColumnInfo columnInfo = new ColumnInfo(newColName, type, alias.toString(), false);
         columnInfos.add(columnInfo);
-        newValueExpr.add(new ExprNodeColumnDesc(
-            columnInfo.getType(), columnInfo.getInternalName(),
-            columnInfo.getTabAlias(), false));
+        newValueExpr.add(new ExprNodeColumnDesc(columnInfo));
         if (!first) {
           colNames = colNames + ",";
           colTypes = colTypes + ",";
@@ -216,9 +214,7 @@ public static void processSkewJoin(JoinOperator joinOp,
         ColumnInfo columnInfo = new ColumnInfo(joinKeys.get(k), TypeInfoFactory
             .getPrimitiveTypeInfo(joinKeyTypes.get(k)), alias.toString(), false);
         columnInfos.add(columnInfo);
-        newKeyExpr.add(new ExprNodeColumnDesc(
-            columnInfo.getType(), columnInfo.getInternalName(),
-            columnInfo.getTabAlias(), false));
+        newKeyExpr.add(new ExprNodeColumnDesc(columnInfo));
       }
 
       newJoinValues.put(alias, newValueExpr);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 9c944b66f4..88fd0fca4d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -20,34 +20,12 @@
 
 import static org.apache.hadoop.hive.conf.HiveConf.ConfVars.HIVESTATSDBCLASS;
 
-import java.io.IOException;
-import java.io.Serializable;
-import java.lang.reflect.Field;
-import java.lang.reflect.InvocationTargetException;
-import java.lang.reflect.UndeclaredThrowableException;
-import java.math.BigDecimal;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.BitSet;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.LinkedHashMap;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Set;
-import java.util.TreeSet;
-import java.util.UUID;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.regex.Pattern;
-import java.util.regex.PatternSyntaxException;
-
 import com.google.common.annotations.VisibleForTesting;
-
-import net.hydromatic.optiq.SchemaPlus;
-import net.hydromatic.optiq.tools.Frameworks;
+import com.google.common.base.Function;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableList.Builder;
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.Lists;
 
 import org.antlr.runtime.ClassicToken;
 import org.antlr.runtime.Token;
@@ -122,7 +100,6 @@
 import org.apache.hadoop.hive.ql.metadata.Table;
 import org.apache.hadoop.hive.ql.metadata.VirtualColumn;
 import org.apache.hadoop.hive.ql.optimizer.Optimizer;
-import org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcContext;
 import org.apache.hadoop.hive.ql.optimizer.optiq.HiveDefaultRelMetadataProvider;
 import org.apache.hadoop.hive.ql.optimizer.optiq.HiveOptiqUtil;
 import org.apache.hadoop.hive.ql.optimizer.optiq.HiveTypeSystemImpl;
@@ -146,6 +123,7 @@
 import org.apache.hadoop.hive.ql.optimizer.optiq.translator.RexNodeConverter;
 import org.apache.hadoop.hive.ql.optimizer.optiq.translator.SqlFunctionConverter;
 import org.apache.hadoop.hive.ql.optimizer.optiq.translator.TypeConverter;
+import org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcContext;
 import org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.tableSpec.SpecType;
 import org.apache.hadoop.hive.ql.parse.PTFInvocationSpec.OrderExpression;
 import org.apache.hadoop.hive.ql.parse.PTFInvocationSpec.OrderSpec;
@@ -279,30 +257,51 @@
 import org.eigenbase.reltype.RelDataTypeFactory;
 import org.eigenbase.reltype.RelDataTypeField;
 import org.eigenbase.rex.RexBuilder;
+import org.eigenbase.rex.RexFieldCollation;
 import org.eigenbase.rex.RexInputRef;
 import org.eigenbase.rex.RexNode;
 import org.eigenbase.rex.RexUtil;
 import org.eigenbase.rex.RexWindowBound;
-import org.eigenbase.rex.RexFieldCollation;
 import org.eigenbase.sql.SqlAggFunction;
-import org.eigenbase.sql.SqlWindow;
-import org.eigenbase.sql.parser.SqlParserPos;
-import org.eigenbase.sql.type.SqlTypeName;
-import org.eigenbase.sql2rel.RelFieldTrimmer;
 import org.eigenbase.sql.SqlCall;
 import org.eigenbase.sql.SqlExplainLevel;
 import org.eigenbase.sql.SqlKind;
-import org.eigenbase.sql.SqlNode;
 import org.eigenbase.sql.SqlLiteral;
+import org.eigenbase.sql.SqlNode;
+import org.eigenbase.sql.SqlWindow;
+import org.eigenbase.sql.parser.SqlParserPos;
+import org.eigenbase.sql.type.SqlTypeName;
+import org.eigenbase.sql2rel.RelFieldTrimmer;
 import org.eigenbase.util.CompositeList;
 import org.eigenbase.util.ImmutableIntList;
 import org.eigenbase.util.Pair;
 
-import com.google.common.base.Function;
-import com.google.common.collect.ImmutableList;
-import com.google.common.collect.ImmutableList.Builder;
-import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
+import java.io.IOException;
+import java.io.Serializable;
+import java.lang.reflect.Field;
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.UndeclaredThrowableException;
+import java.math.BigDecimal;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.BitSet;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedHashMap;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Set;
+import java.util.TreeSet;
+import java.util.UUID;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.regex.Pattern;
+import java.util.regex.PatternSyntaxException;
+
+import net.hydromatic.optiq.SchemaPlus;
+import net.hydromatic.optiq.tools.Frameworks;
 
 /**
  * Implementation of the semantic analyzer. It generates the query plan.
@@ -4133,9 +4132,7 @@ private Operator genGroupByPlanGroupByOperator1(QBParseInfo parseInfo,
         throw new SemanticException(ErrorMsg.INVALID_COLUMN.getMsg(grpbyExpr));
       }
 
-      groupByKeys.add(new ExprNodeColumnDesc(exprInfo.getType(), exprInfo
-          .getInternalName(), exprInfo.getTabAlias(), exprInfo
-          .getIsVirtualCol()));
+      groupByKeys.add(new ExprNodeColumnDesc(exprInfo));
       String field = getColumnInternalName(i);
       outputColumnNames.add(field);
       ColumnInfo oColInfo = new ColumnInfo(field, exprInfo.getType(), "", false);
@@ -6931,9 +6928,7 @@ private Operator genReduceSinkPlanForSortingBucketing(Table tab, Operator input,
     for (ColumnInfo colInfo : inputRR.getColumnInfos()) {
       String internalName = getColumnInternalName(i++);
       outputColumns.add(internalName);
-      valueCols.add(new ExprNodeColumnDesc(colInfo.getType(), colInfo
-          .getInternalName(), colInfo.getTabAlias(), colInfo
-          .getIsVirtualCol()));
+      valueCols.add(new ExprNodeColumnDesc(colInfo));
       colExprMap.put(internalName, valueCols
           .get(valueCols.size() - 1));
     }
@@ -7062,8 +7057,7 @@ private Operator genReduceSinkPlan(String dest, QB qb, Operator<?> input,
       ColumnInfo colInfo = columnInfos.get(i);
       String[] nm = inputRR.reverseLookup(colInfo.getInternalName());
       String[] nm2 = inputRR.getAlternateMappings(colInfo.getInternalName());
-      ExprNodeColumnDesc value = new ExprNodeColumnDesc(colInfo.getType(),
-          colInfo.getInternalName(), colInfo.getTabAlias(), colInfo.getIsVirtualCol());
+      ExprNodeColumnDesc value = new ExprNodeColumnDesc(colInfo);
 
       // backtrack can be null when input is script operator
       ExprNodeDesc valueBack = ExprNodeDescUtils.backtrack(value, dummy, input);
@@ -7315,8 +7309,7 @@ private Operator genJoinReduceSinkChild(QB qb, ExprNodeDesc[] joinKeys,
       ColumnInfo colInfo = columns.get(i);
       String[] nm = inputRR.reverseLookup(colInfo.getInternalName());
       String[] nm2 = inputRR.getAlternateMappings(colInfo.getInternalName());
-      ExprNodeDesc expr = new ExprNodeColumnDesc(colInfo.getType(),
-          colInfo.getInternalName(), colInfo.getTabAlias(), colInfo.getIsVirtualCol());
+      ExprNodeDesc expr = new ExprNodeColumnDesc(colInfo);
 
       // backtrack can be null when input is script operator
       ExprNodeDesc exprBack = ExprNodeDescUtils.backtrack(expr, dummy, child);
@@ -8404,12 +8397,9 @@ private Operator insertSelectAllPlanForGroupBy(Operator input)
         new HashMap<String, ExprNodeDesc>();
     for (int i = 0; i < columns.size(); i++) {
       ColumnInfo col = columns.get(i);
-      colList.add(new ExprNodeColumnDesc(col.getType(), col.getInternalName(),
-          col.getTabAlias(), col.getIsVirtualCol()));
+      colList.add(new ExprNodeColumnDesc(col));
       columnNames.add(col.getInternalName());
-      columnExprMap.put(col.getInternalName(),
-          new ExprNodeColumnDesc(col.getType(), col.getInternalName(),
-              col.getTabAlias(), col.getIsVirtualCol()));
+      columnExprMap.put(col.getInternalName(), new ExprNodeColumnDesc(col));
     }
     Operator output = putOpInsertMap(OperatorFactory.getAndMakeChild(
         new SelectDesc(colList, columnNames, true), new RowSchema(inputRR
@@ -9266,8 +9256,7 @@ private ExprNodeDesc genSamplePredicate(TableSample ts,
       for (String col : bucketCols) {
         ColumnInfo ci = rwsch.get(alias, col);
         // TODO: change type to the one in the table schema
-        args.add(new ExprNodeColumnDesc(ci.getType(), ci.getInternalName(), ci
-            .getTabAlias(), ci.getIsVirtualCol()));
+        args.add(new ExprNodeColumnDesc(ci));
       }
     } else {
       for (ASTNode expr : ts.getExprs()) {
@@ -9848,8 +9837,7 @@ private Operator genLateralViewPlan(QB qb, Operator op, ASTNode lateralViewTree)
     for (ColumnInfo col : source.getColumnInfos()) {
       String[] tabCol = source.reverseLookup(col.getInternalName());
       lvForwardRR.put(tabCol[0], tabCol[1], col);
-      ExprNodeDesc colExpr = new ExprNodeColumnDesc(col.getType(), col.getInternalName(),
-          col.getTabAlias(), false);
+      ExprNodeDesc colExpr = new ExprNodeColumnDesc(col);
       colList.add(colExpr);
       colNames.add(colExpr.getName());
       lvfColExprMap.put(col.getInternalName(), colExpr);
@@ -9938,8 +9926,7 @@ private void LVmergeRowResolvers(RowResolver source, RowResolver dest,
       String tableAlias = tableCol[0];
       String colAlias = tableCol[1];
       dest.put(tableAlias, colAlias, newCol);
-      colExprMap.put(internalName, new ExprNodeColumnDesc(c.getType(), c.getInternalName(),
-          c.getTabAlias(), c.getIsVirtualCol()));
+      colExprMap.put(internalName, new ExprNodeColumnDesc(c));
     }
   }
 
@@ -12000,9 +11987,7 @@ void buildPTFReduceSinkDetails(PartitionedTableFunctionDef tabDef,
      */
     int pos = 0;
     for (ColumnInfo colInfo : colInfoList) {
-        ExprNodeDesc valueColExpr = new ExprNodeColumnDesc(colInfo.getType(), colInfo
-            .getInternalName(), colInfo.getTabAlias(), colInfo
-            .getIsVirtualCol());
+        ExprNodeDesc valueColExpr = new ExprNodeColumnDesc(colInfo);
         valueCols.add(valueColExpr);
         String internalName = SemanticAnalyzer.getColumnInternalName(pos++);
         outputColumnNames.add(internalName);
@@ -12247,9 +12232,7 @@ private Operator genReduceSinkPlanForWindowing(WindowingSpec spec,
     RowResolver rsNewRR = new RowResolver();
     int pos = 0;
     for (ColumnInfo colInfo : colInfoList) {
-        ExprNodeDesc valueColExpr = new ExprNodeColumnDesc(colInfo.getType(), colInfo
-            .getInternalName(), colInfo.getTabAlias(), colInfo
-            .getIsVirtualCol());
+        ExprNodeDesc valueColExpr = new ExprNodeColumnDesc(colInfo);
         valueCols.add(valueColExpr);
         String internalName = SemanticAnalyzer.getColumnInternalName(pos++);
         outputColumnNames.add(internalName);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeColumnDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeColumnDesc.java
index 250208e752..9a320545c2 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeColumnDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeColumnDesc.java
@@ -18,14 +18,15 @@
 
 package org.apache.hadoop.hive.ql.plan;
 
-import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.List;
-
 import org.apache.commons.lang.builder.HashCodeBuilder;
+import org.apache.hadoop.hive.ql.exec.ColumnInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.List;
+
 /**
  * ExprNodeColumnDesc.
  *
@@ -56,6 +57,10 @@ public class ExprNodeColumnDesc extends ExprNodeDesc implements Serializable {
   public ExprNodeColumnDesc() {
   }
 
+  public ExprNodeColumnDesc(ColumnInfo ci) {
+    this(ci.getType(), ci.getInternalName(), ci.getTabAlias(), ci.getIsVirtualCol());
+  }
+
   public ExprNodeColumnDesc(TypeInfo typeInfo, String column, String tabAlias,
       boolean isPartitionColOrVirtualCol) {
     super(typeInfo);
diff --git a/ql/src/test/results/clientnegative/udf_assert_true.q.out b/ql/src/test/results/clientnegative/udf_assert_true.q.out
index 819d723c1a..4a5b30de3b 100644
--- a/ql/src/test/results/clientnegative/udf_assert_true.q.out
+++ b/ql/src/test/results/clientnegative/udf_assert_true.q.out
@@ -21,10 +21,10 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col5
-                  Statistics: Num rows: 1000 Data size: 24000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 158000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: assert_true((_col5 > 0)) (type: void)
                     outputColumnNames: _col0
@@ -48,7 +48,7 @@ STAGE PLANS:
                   function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col5
-                    Statistics: Num rows: 1000 Data size: 24000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 158000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: assert_true((_col5 > 0)) (type: void)
                       outputColumnNames: _col0
@@ -98,10 +98,10 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col5
-                  Statistics: Num rows: 1000 Data size: 24000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 158000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: assert_true((_col5 < 2)) (type: void)
                     outputColumnNames: _col0
@@ -125,7 +125,7 @@ STAGE PLANS:
                   function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col5
-                    Statistics: Num rows: 1000 Data size: 24000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 158000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: assert_true((_col5 < 2)) (type: void)
                       outputColumnNames: _col0
diff --git a/ql/src/test/results/clientnegative/udf_assert_true2.q.out b/ql/src/test/results/clientnegative/udf_assert_true2.q.out
index 9760d0d97a..3684a3f6c5 100644
--- a/ql/src/test/results/clientnegative/udf_assert_true2.q.out
+++ b/ql/src/test/results/clientnegative/udf_assert_true2.q.out
@@ -16,10 +16,10 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col5
-                  Statistics: Num rows: 1000 Data size: 24000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 158000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: (1 + assert_true((_col5 < 2))) (type: double)
                     outputColumnNames: _col0
@@ -43,7 +43,7 @@ STAGE PLANS:
                   function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col5
-                    Statistics: Num rows: 1000 Data size: 24000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 158000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: (1 + assert_true((_col5 < 2))) (type: double)
                       outputColumnNames: _col0
diff --git a/ql/src/test/results/clientpositive/lateral_view.q.out b/ql/src/test/results/clientpositive/lateral_view.q.out
index 66c296831d..25ed62fc53 100644
--- a/ql/src/test/results/clientpositive/lateral_view.q.out
+++ b/ql/src/test/results/clientpositive/lateral_view.q.out
@@ -132,14 +132,14 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col5
-                  Statistics: Num rows: 1000 Data size: 28000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 162000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col5 (type: int)
                     outputColumnNames: _col0
-                    Statistics: Num rows: 1000 Data size: 28000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 162000 Basic stats: COMPLETE Column stats: COMPLETE
                     Limit
                       Number of rows: 3
                       Statistics: Num rows: 3 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
@@ -159,11 +159,11 @@ STAGE PLANS:
                   function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col5
-                    Statistics: Num rows: 1000 Data size: 28000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 162000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col5 (type: int)
                       outputColumnNames: _col0
-                      Statistics: Num rows: 1000 Data size: 28000 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 1000 Data size: 162000 Basic stats: COMPLETE Column stats: COMPLETE
                       Limit
                         Number of rows: 3
                         Statistics: Num rows: 3 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
@@ -199,12 +199,12 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col5
-                  Statistics: Num rows: 1000 Data size: 28000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 162000 Basic stats: COMPLETE Column stats: COMPLETE
                   Lateral View Forward
-                    Statistics: Num rows: 1000 Data size: 28000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 162000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col5 (type: int)
                       outputColumnNames: _col5
@@ -259,9 +259,9 @@ STAGE PLANS:
                   function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col5
-                    Statistics: Num rows: 1000 Data size: 28000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 162000 Basic stats: COMPLETE Column stats: COMPLETE
                     Lateral View Forward
-                      Statistics: Num rows: 1000 Data size: 28000 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 1000 Data size: 162000 Basic stats: COMPLETE Column stats: COMPLETE
                       Select Operator
                         expressions: _col5 (type: int)
                         outputColumnNames: _col5
@@ -332,12 +332,12 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col5
-                  Statistics: Num rows: 1000 Data size: 24000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 158000 Basic stats: COMPLETE Column stats: COMPLETE
                   Lateral View Forward
-                    Statistics: Num rows: 1000 Data size: 24000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 158000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       Statistics: Num rows: 1000 Data size: 268000 Basic stats: COMPLETE Column stats: COMPLETE
                       Lateral View Join Operator
@@ -390,9 +390,9 @@ STAGE PLANS:
                   function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col5
-                    Statistics: Num rows: 1000 Data size: 24000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 158000 Basic stats: COMPLETE Column stats: COMPLETE
                     Lateral View Forward
-                      Statistics: Num rows: 1000 Data size: 24000 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 1000 Data size: 158000 Basic stats: COMPLETE Column stats: COMPLETE
                       Select Operator
                         Statistics: Num rows: 1000 Data size: 268000 Basic stats: COMPLETE Column stats: COMPLETE
                         Lateral View Join Operator
@@ -519,10 +519,10 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 1406 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col4
-                  Statistics: Num rows: 1000 Data size: 28000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 162000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col4 (type: int)
                     outputColumnNames: _col0
@@ -546,7 +546,7 @@ STAGE PLANS:
                   function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col4
-                    Statistics: Num rows: 1000 Data size: 28000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 162000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col4 (type: int)
                       outputColumnNames: _col0
diff --git a/ql/src/test/results/clientpositive/lateral_view_noalias.q.out b/ql/src/test/results/clientpositive/lateral_view_noalias.q.out
index e1445bf3a4..51a29d0c9d 100644
--- a/ql/src/test/results/clientpositive/lateral_view_noalias.q.out
+++ b/ql/src/test/results/clientpositive/lateral_view_noalias.q.out
@@ -18,14 +18,14 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col5, _col6
-                  Statistics: Num rows: 1000 Data size: 192000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 326000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col5 (type: string), _col6 (type: int)
                     outputColumnNames: _col0, _col1
-                    Statistics: Num rows: 1000 Data size: 192000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 326000 Basic stats: COMPLETE Column stats: COMPLETE
                     Limit
                       Number of rows: 2
                       Statistics: Num rows: 2 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
@@ -45,11 +45,11 @@ STAGE PLANS:
                   function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col5, _col6
-                    Statistics: Num rows: 1000 Data size: 192000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 326000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col5 (type: string), _col6 (type: int)
                       outputColumnNames: _col0, _col1
-                      Statistics: Num rows: 1000 Data size: 192000 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 1000 Data size: 326000 Basic stats: COMPLETE Column stats: COMPLETE
                       Limit
                         Number of rows: 2
                         Statistics: Num rows: 2 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
@@ -158,10 +158,10 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col5, _col6
-                  Statistics: Num rows: 1000 Data size: 192000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 326000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col5 (type: string), _col6 (type: int)
                     outputColumnNames: _col0, _col1
@@ -182,7 +182,7 @@ STAGE PLANS:
                   function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col5, _col6
-                    Statistics: Num rows: 1000 Data size: 192000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 326000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col5 (type: string), _col6 (type: int)
                       outputColumnNames: _col0, _col1
@@ -259,10 +259,10 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col5, _col6
-                  Statistics: Num rows: 1000 Data size: 192000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 326000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col5 (type: string), _col6 (type: int)
                     outputColumnNames: _col0, _col1
@@ -283,7 +283,7 @@ STAGE PLANS:
                   function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col5, _col6
-                    Statistics: Num rows: 1000 Data size: 192000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 326000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col5 (type: string), _col6 (type: int)
                       outputColumnNames: _col0, _col1
diff --git a/ql/src/test/results/clientpositive/lateral_view_ppd.q.out b/ql/src/test/results/clientpositive/lateral_view_ppd.q.out
index 12200302d0..b186192c2b 100644
--- a/ql/src/test/results/clientpositive/lateral_view_ppd.q.out
+++ b/ql/src/test/results/clientpositive/lateral_view_ppd.q.out
@@ -175,23 +175,44 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
-            Filter Operator
-              predicate: ((ds = '2008-04-08') and (hr = '12')) (type: boolean)
-              Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
-              Lateral View Forward
-                Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
-                Select Operator
-                  expressions: value (type: string)
-                  outputColumnNames: value
-                  Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
+            Lateral View Forward
+              Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
+              Select Operator
+                expressions: value (type: string)
+                outputColumnNames: value
+                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
+                Lateral View Join Operator
+                  outputColumnNames: _col1, _col7
+                  Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: _col1 (type: string), _col7 (type: int)
+                    outputColumnNames: _col0, _col1
+                    Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
+                    Limit
+                      Number of rows: 12
+                      Statistics: Num rows: 12 Data size: 120 Basic stats: COMPLETE Column stats: NONE
+                      File Output Operator
+                        compressed: false
+                        Statistics: Num rows: 12 Data size: 120 Basic stats: COMPLETE Column stats: NONE
+                        table:
+                            input format: org.apache.hadoop.mapred.TextInputFormat
+                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              Select Operator
+                expressions: array(1,2,3) (type: array<int>)
+                outputColumnNames: _col0
+                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
+                UDTF Operator
+                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
+                  function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col1, _col7
-                    Statistics: Num rows: 4000 Data size: 42496 Basic stats: COMPLETE Column stats: NONE
+                    Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                     Select Operator
                       expressions: _col1 (type: string), _col7 (type: int)
                       outputColumnNames: _col0, _col1
-                      Statistics: Num rows: 4000 Data size: 42496 Basic stats: COMPLETE Column stats: NONE
+                      Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                       Limit
                         Number of rows: 12
                         Statistics: Num rows: 12 Data size: 120 Basic stats: COMPLETE Column stats: NONE
@@ -202,30 +223,6 @@ STAGE PLANS:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                Select Operator
-                  expressions: array(1,2,3) (type: array<int>)
-                  outputColumnNames: _col0
-                  Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
-                  UDTF Operator
-                    Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
-                    function name: explode
-                    Lateral View Join Operator
-                      outputColumnNames: _col1, _col7
-                      Statistics: Num rows: 4000 Data size: 42496 Basic stats: COMPLETE Column stats: NONE
-                      Select Operator
-                        expressions: _col1 (type: string), _col7 (type: int)
-                        outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 4000 Data size: 42496 Basic stats: COMPLETE Column stats: NONE
-                        Limit
-                          Number of rows: 12
-                          Statistics: Num rows: 12 Data size: 120 Basic stats: COMPLETE Column stats: NONE
-                          File Output Operator
-                            compressed: false
-                            Statistics: Num rows: 12 Data size: 120 Basic stats: COMPLETE Column stats: NONE
-                            table:
-                                input format: org.apache.hadoop.mapred.TextInputFormat
-                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-0
     Fetch Operator
@@ -236,18 +233,12 @@ STAGE PLANS:
 PREHOOK: query: SELECT value, myCol FROM (SELECT * FROM srcpart LATERAL VIEW explode(array(1,2,3)) myTable AS myCol) a WHERE ds='2008-04-08' AND hr="12" LIMIT 12
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart
-PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
-PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 #### A masked pattern was here ####
 POSTHOOK: query: SELECT value, myCol FROM (SELECT * FROM srcpart LATERAL VIEW explode(array(1,2,3)) myTable AS myCol) a WHERE ds='2008-04-08' AND hr="12" LIMIT 12
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart
-POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
-POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 #### A masked pattern was here ####
 val_238	1
 val_238	2
diff --git a/ql/src/test/results/clientpositive/udtf_stack.q.out b/ql/src/test/results/clientpositive/udtf_stack.q.out
index 43f0a76e39..80edb65d03 100644
--- a/ql/src/test/results/clientpositive/udtf_stack.q.out
+++ b/ql/src/test/results/clientpositive/udtf_stack.q.out
@@ -21,10 +21,10 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col5, _col6
-                  Statistics: Num rows: 1000 Data size: 111000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 245000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col5 (type: string), _col6 (type: array<int>)
                     outputColumnNames: _col0, _col1
@@ -48,7 +48,7 @@ STAGE PLANS:
                   function name: stack
                   Lateral View Join Operator
                     outputColumnNames: _col5, _col6
-                    Statistics: Num rows: 1000 Data size: 111000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 245000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col5 (type: string), _col6 (type: array<int>)
                       outputColumnNames: _col0, _col1
@@ -88,10 +88,10 @@ STAGE PLANS:
             Lateral View Forward
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
-                Statistics: Num rows: 500 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 500 Data size: 134000 Basic stats: COMPLETE Column stats: COMPLETE
                 Lateral View Join Operator
                   outputColumnNames: _col5, _col6
-                  Statistics: Num rows: 1000 Data size: 135000 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 1000 Data size: 269000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: _col5 (type: string), _col6 (type: array<int>)
                     outputColumnNames: _col0, _col1
@@ -115,7 +115,7 @@ STAGE PLANS:
                   function name: stack
                   Lateral View Join Operator
                     outputColumnNames: _col5, _col6
-                    Statistics: Num rows: 1000 Data size: 135000 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1000 Data size: 269000 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: _col5 (type: string), _col6 (type: array<int>)
                       outputColumnNames: _col0, _col1
diff --git a/ql/src/test/results/clientpositive/union26.q.out b/ql/src/test/results/clientpositive/union26.q.out
index cdc558a0b2..4f9e0d4fb1 100644
--- a/ql/src/test/results/clientpositive/union26.q.out
+++ b/ql/src/test/results/clientpositive/union26.q.out
@@ -103,91 +103,88 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
-            Filter Operator
-              predicate: ((ds = '2008-04-08') and (hr = '11')) (type: boolean)
-              Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
-              Lateral View Forward
-                Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
-                Select Operator
-                  expressions: key (type: string), value (type: string)
-                  outputColumnNames: key, value
-                  Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
+            Lateral View Forward
+              Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
+              Select Operator
+                expressions: key (type: string), value (type: string)
+                outputColumnNames: key, value
+                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
+                Lateral View Join Operator
+                  outputColumnNames: _col0, _col1, _col7
+                  Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: _col0 (type: string), _col1 (type: string)
+                    outputColumnNames: _col0, _col1
+                    Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
+                    Union
+                      Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
+                      Select Operator
+                        expressions: _col0 (type: string), _col1 (type: string)
+                        outputColumnNames: _col0, _col1
+                        Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
+                        Group By Operator
+                          aggregations: count(1)
+                          keys: _col0 (type: string), _col1 (type: string)
+                          mode: hash
+                          outputColumnNames: _col0, _col1, _col2
+                          Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
+                          Reduce Output Operator
+                            key expressions: _col0 (type: string), _col1 (type: string)
+                            sort order: ++
+                            Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
+                            Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
+                            value expressions: _col2 (type: bigint)
+              Select Operator
+                expressions: array(1,2,3) (type: array<int>)
+                outputColumnNames: _col0
+                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
+                UDTF Operator
+                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
+                  function name: explode
                   Lateral View Join Operator
                     outputColumnNames: _col0, _col1, _col7
-                    Statistics: Num rows: 4000 Data size: 42496 Basic stats: COMPLETE Column stats: NONE
+                    Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                     Select Operator
                       expressions: _col0 (type: string), _col1 (type: string)
                       outputColumnNames: _col0, _col1
-                      Statistics: Num rows: 4000 Data size: 42496 Basic stats: COMPLETE Column stats: NONE
+                      Statistics: Num rows: 1000 Data size: 10624 Basic stats: COMPLETE Column stats: NONE
                       Union
-                        Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
+                        Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
                         Select Operator
                           expressions: _col0 (type: string), _col1 (type: string)
                           outputColumnNames: _col0, _col1
-                          Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
+                          Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
                           Group By Operator
                             aggregations: count(1)
                             keys: _col0 (type: string), _col1 (type: string)
                             mode: hash
                             outputColumnNames: _col0, _col1, _col2
-                            Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
+                            Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
                             Reduce Output Operator
                               key expressions: _col0 (type: string), _col1 (type: string)
                               sort order: ++
                               Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
-                              Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
+                              Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
                               value expressions: _col2 (type: bigint)
-                Select Operator
-                  expressions: array(1,2,3) (type: array<int>)
-                  outputColumnNames: _col0
-                  Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
-                  UDTF Operator
-                    Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE
-                    function name: explode
-                    Lateral View Join Operator
-                      outputColumnNames: _col0, _col1, _col7
-                      Statistics: Num rows: 4000 Data size: 42496 Basic stats: COMPLETE Column stats: NONE
-                      Select Operator
-                        expressions: _col0 (type: string), _col1 (type: string)
-                        outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 4000 Data size: 42496 Basic stats: COMPLETE Column stats: NONE
-                        Union
-                          Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
-                          Select Operator
-                            expressions: _col0 (type: string), _col1 (type: string)
-                            outputColumnNames: _col0, _col1
-                            Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
-                            Group By Operator
-                              aggregations: count(1)
-                              keys: _col0 (type: string), _col1 (type: string)
-                              mode: hash
-                              outputColumnNames: _col0, _col1, _col2
-                              Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
-                              Reduce Output Operator
-                                key expressions: _col0 (type: string), _col1 (type: string)
-                                sort order: ++
-                                Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
-                                Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
-                                value expressions: _col2 (type: bigint)
           TableScan
             Union
-              Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
               Select Operator
                 expressions: _col0 (type: string), _col1 (type: string)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
                 Group By Operator
                   aggregations: count(1)
                   keys: _col0 (type: string), _col1 (type: string)
                   mode: hash
                   outputColumnNames: _col0, _col1, _col2
-                  Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
                   Reduce Output Operator
                     key expressions: _col0 (type: string), _col1 (type: string)
                     sort order: ++
                     Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
-                    Statistics: Num rows: 4275 Data size: 45417 Basic stats: COMPLETE Column stats: NONE
+                    Statistics: Num rows: 1275 Data size: 13545 Basic stats: COMPLETE Column stats: NONE
                     value expressions: _col2 (type: bigint)
       Reduce Operator Tree:
         Group By Operator
@@ -195,14 +192,14 @@ STAGE PLANS:
           keys: KEY._col0 (type: string), KEY._col1 (type: string)
           mode: mergepartial
           outputColumnNames: _col0, _col1, _col2
-          Statistics: Num rows: 2137 Data size: 22703 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 637 Data size: 6767 Basic stats: COMPLETE Column stats: NONE
           Select Operator
             expressions: _col2 (type: bigint), _col0 (type: string), _col1 (type: string)
             outputColumnNames: _col0, _col1, _col2
-            Statistics: Num rows: 2137 Data size: 22703 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 637 Data size: 6767 Basic stats: COMPLETE Column stats: NONE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 2137 Data size: 22703 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 637 Data size: 6767 Basic stats: COMPLETE Column stats: NONE
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -238,8 +235,6 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
-PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 #### A masked pattern was here ####
 POSTHOOK: query: SELECT 
 count(1) as counts,
@@ -265,8 +260,6 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
-POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 #### A masked pattern was here ####
 10	100	val_100
 10	103	val_103
@@ -601,8 +594,6 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
-PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 #### A masked pattern was here ####
 POSTHOOK: query: SELECT 
 count(1) as counts,
@@ -628,8 +619,6 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
-POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 #### A masked pattern was here ####
 10	100	val_100
 10	103	val_103
@@ -964,8 +953,6 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
-PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 #### A masked pattern was here ####
 POSTHOOK: query: SELECT 
 count(1) as counts,
@@ -991,8 +978,6 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
-POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 #### A masked pattern was here ####
 10	100	val_100
 10	103	val_103
