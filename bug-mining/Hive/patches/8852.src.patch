diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDirectSqlUtils.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDirectSqlUtils.java
index 8a608a030e..500a4ece93 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDirectSqlUtils.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDirectSqlUtils.java
@@ -20,6 +20,7 @@
 package org.apache.hadoop.hive.metastore;
 
 import org.apache.commons.lang3.BooleanUtils;
+import org.apache.commons.lang3.exception.ExceptionUtils;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.Function;
 import org.apache.hadoop.hive.metastore.api.MetaException;
@@ -78,7 +79,7 @@ static <T> T executeWithArray(Query query, Object[] params, String sql, int limi
       }
       LOG.warn(errorBuilder.toString() + "]", ex);
       // We just logged an exception with (in case of JDO) a humongous callstack. Make a new one.
-      throw new MetaException("See previous errors; " + ex.getMessage() + errorBuilder.toString() + "]");
+      throw new MetaException("See previous errors; " + ExceptionUtils.getRootCauseMessage(ex) + " " +  errorBuilder.toString() + "]");
     }
   }
 
@@ -144,6 +145,8 @@ static <T> int loopJoinOrderedResult(PersistenceManager pm, TreeMap<Long, T> tre
         if (fields == null && !iter.hasNext())
           break;
         long id = entry.getKey();
+        T value = entry.getValue();
+        boolean foundEntries = false;
         while (fields != null || iter.hasNext()) {
           if (fields == null) {
             fields = iter.next();
@@ -152,9 +155,19 @@ static <T> int loopJoinOrderedResult(PersistenceManager pm, TreeMap<Long, T> tre
           if (nestedId < id) {
             throw new MetaException("Found entries for unknown ID " + nestedId);
           }
-          if (nestedId > id)
+          if (nestedId > id) {
+            if (!foundEntries) {
+              Throwable throwable = (new Throwable()).fillInStackTrace();
+              LOG.warn("Multi-value fields are missing for the {}:{}, method: {}", value.getClass().getSimpleName(), id,
+                  throwable.getStackTrace()[2]);
+              if (LOG.isDebugEnabled()) {
+                LOG.debug("loopJoinOrderedResult:", throwable);
+              }
+            }
             break; // fields belong to one of the next entries
-          func.apply(entry.getValue(), fields);
+          }
+          foundEntries = true;
+          func.apply(value, fields);
           fields = null;
         }
         Deadline.checkTimeout();
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreServerUtils.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreServerUtils.java
index bb320510cf..69ec400017 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreServerUtils.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreServerUtils.java
@@ -1556,7 +1556,8 @@ public static String getPartitionName(Table table, Partition partition) {
     try {
       return Warehouse.makePartName(getPartCols(table), partition.getValues());
     } catch (MetaException e) {
-      throw new RuntimeException(e);
+      throw new RuntimeException("Invalid partition found, location: " +
+          getDataLocation(table, partition), e);
     }
   }
 
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestPackageJdo.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestPackageJdo.java
new file mode 100644
index 0000000000..d15735a0ea
--- /dev/null
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestPackageJdo.java
@@ -0,0 +1,154 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.metastore;
+
+import javax.jdo.PersistenceManager;
+import java.io.File;
+import java.sql.Connection;
+import java.sql.ResultSet;
+import java.util.HashSet;
+import java.util.Objects;
+import java.util.Set;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
+import org.apache.hadoop.hive.metastore.utils.JavaUtils;
+import org.apache.hadoop.hive.metastore.utils.TestTxnDbUtil;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+
+public class TestPackageJdo {
+  private static final String TMPDIR = System.getProperty("java.io.tmpdir", "target/tmp");
+  private final Configuration conf = MetastoreConf.newMetastoreConf();
+
+  private final String url1 = "jdbc:derby:;databaseName=" + TMPDIR + "/test_meta_mapping_db1;create=true";
+  private final String url2 = "jdbc:derby:;databaseName=" + TMPDIR + "/test_meta_mapping_db2;create=true";
+  private final String password = "mine";
+
+  @Before
+  public void setup() throws Exception {
+    // Init the schema from script
+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CONNECT_URL_KEY, url1);
+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.PWD, password);
+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CONNECTION_USER_NAME, "APP");
+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CONNECTION_DRIVER,
+        "org.apache.derby.jdbc.EmbeddedDriver");
+    TestTxnDbUtil.prepDb(conf);
+
+    // Init the schema from package.jdo
+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CONNECT_URL_KEY, url2);
+    PersistenceManagerProvider.updatePmfProperties(conf);
+    PersistenceManager pm = PersistenceManagerProvider.getPersistenceManager();
+    Set<Class> classes = new HashSet<>();
+    String packageName = "org/apache/hadoop/hive/metastore/model/";
+    for (File mfile :
+        new File(".", "src/main/java/" + packageName).listFiles()) {
+      String fileName = mfile.getName();
+      if (fileName.endsWith(".java") && !fileName.contains("FetchGroups")) {
+        fileName = packageName.replace("/", ".") +
+            fileName.substring(0, fileName.length() - 5);
+        classes.add(getClass().getClassLoader().loadClass(fileName));
+      }
+    }
+    for (Class clazz : classes) {
+      try {
+        pm.makePersistent(JavaUtils.newInstance(clazz, new Class[0], new Object[0]));
+      } catch (Exception ignore) {
+      }
+    }
+  }
+
+  private static class ColumnInfo {
+    final String columnName;
+    final Object dataType;
+    final Object columnSize;
+    final Object nullable;
+
+    public ColumnInfo(String columnName, Object dataType, Object columnSize, Object nullable) {
+      this.columnName = columnName;
+      this.dataType = dataType;
+      this.columnSize = columnSize;
+      this.nullable = nullable;
+    }
+
+    // Oops, we check only the column names here...
+    @Override
+    public boolean equals(Object o) {
+      if (this == o)
+        return true;
+      if (o == null || getClass() != o.getClass())
+        return false;
+      ColumnInfo that = (ColumnInfo) o;
+      return Objects.equals(columnName, that.columnName);
+    }
+
+    @Override
+    public int hashCode() {
+      return Objects.hash(columnName);
+    }
+
+    @Override
+    public String toString() {
+      return "columnName=" + columnName + ", dataType=" + dataType + ", columnSize=" + columnSize + ", nullable: " + nullable;
+    }
+  }
+
+  @Test
+  public void verifySchema() throws Exception {
+    Connection connection2 = TestTxnDbUtil.getConnection(conf);
+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CONNECT_URL_KEY, url1);
+    Connection connection1 = TestTxnDbUtil.getConnection(conf);
+    try (Connection conn1 = connection1; Connection conn2 = connection2) {
+      Set<String> tables1 = getTableNames(conn1);
+      Set<String> tables2 = getTableNames(conn2);
+      Assert.assertFalse(tables1.isEmpty() || tables2.isEmpty());
+      // We don't define the transaction table in package.jdo, iterator over table2,
+      // check to see if there is any diff on the table schema
+      for (String table : tables2) {
+        ResultSet colRS1 = connection1.getMetaData().getColumns(null, "APP", table, null);
+        ResultSet colRS2 = connection2.getMetaData().getColumns(null, "APP", table, null);
+        Set<ColumnInfo> columnInfos1 = new HashSet<>();
+        Set<ColumnInfo> columnInfos2 = new HashSet<>();
+        while (colRS1.next() && colRS2.next()) {
+          columnInfos1.add(new ColumnInfo(colRS1.getString("COLUMN_NAME"), colRS1.getObject("DATA_TYPE"),
+              colRS1.getObject("COLUMN_SIZE"), colRS1.getString("IS_NULLABLE")));
+          columnInfos2.add(new ColumnInfo(colRS2.getString("COLUMN_NAME"), colRS2.getObject("DATA_TYPE"),
+              colRS2.getObject("COLUMN_SIZE"), colRS2.getString("IS_NULLABLE")));
+        }
+        assertEquals("Different columns found in the table: " + table, columnInfos1, columnInfos2);
+        assertFalse(colRS1.next() || colRS2.next());
+      }
+    }
+  }
+
+  private Set<String> getTableNames(Connection connection) throws Exception {
+    Set<String> tables = new HashSet<>();
+    try (ResultSet rs2 = connection.getMetaData()
+        .getTables(null, "APP", null, new String[] { "TABLE" })) {
+      while (rs2.next()) {
+        tables.add(rs2.getString("TABLE_NAME"));
+      }
+    }
+    return tables;
+  }
+}
