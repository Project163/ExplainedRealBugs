diff --git a/hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/DbNotificationListener.java b/hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/DbNotificationListener.java
index 6d775d665c..b715c97762 100644
--- a/hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/DbNotificationListener.java
+++ b/hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/DbNotificationListener.java
@@ -668,7 +668,7 @@ public void onCommitTxn(CommitTxnEvent commitTxnEvent, Connection dbConn, SQLGen
       return;
     }
     CommitTxnMessage msg =
-        MessageBuilder.getInstance().buildCommitTxnMessage(commitTxnEvent.getTxnId());
+        MessageBuilder.getInstance().buildCommitTxnMessage(commitTxnEvent.getTxnId(), commitTxnEvent.getDatabases(), commitTxnEvent.getWriteId());
 
     NotificationEvent event =
         new NotificationEvent(0, now(), EventType.COMMIT_TXN.toString(),
@@ -688,7 +688,7 @@ public void onAbortTxn(AbortTxnEvent abortTxnEvent, Connection dbConn, SQLGenera
       return;
     }
     AbortTxnMessage msg =
-        MessageBuilder.getInstance().buildAbortTxnMessage(abortTxnEvent.getTxnId(), abortTxnEvent.getDbsUpdated());
+        MessageBuilder.getInstance().buildAbortTxnMessage(abortTxnEvent.getTxnId(), abortTxnEvent.getDbsUpdated(), abortTxnEvent.getWriteId());
     NotificationEvent event =
         new NotificationEvent(0, now(), EventType.ABORT_TXN.toString(),
             msgEncoder.getSerializer().serialize(msg));
diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationFilterTransactions.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationFilterTransactions.java
index dd695e609a..5166c66b76 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationFilterTransactions.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationFilterTransactions.java
@@ -272,10 +272,10 @@ public void setup() throws Throwable {
     PrimaryEventListenerTestImpl.reset();
     ReplicaEventListenerTestImpl.reset();
 
-    // Each test always has 8 openTxns, 6 commitTxn, and 2 abortTxns.
+    // Each test always has 9 openTxns, 7 commitTxn, and 2 abortTxns.
     // Note that this is the number that was done on the primary,
     // and some are done on non-replicated database.
-    expected = new EventCount(8, 6, 2);
+    expected = new EventCount(9, 7, 2);
   }
 
   static void updateTxnMapping(Map<Long, Long> map) throws Exception {
@@ -323,8 +323,11 @@ private void prepareBootstrapData() throws Throwable {
             .run("insert into t999 values (99908)")
             .run("insert into t999 values (99909)")
             .run("insert into t999 values (99910)")
-            .run("drop table t999");
-    txnOffset = 10;
+            .run("drop table t999")
+            .run("create table t10 (id int) clustered by(id) into 3 buckets stored as orc " +
+                    "tblproperties (\"transactional\"=\"true\")")
+            .run("insert into t10 values (10)");
+    txnOffset = 11;
 
     // primaryDbName is replicated, t2 and t2 are ACID tables with initial data.
     // t3 is an ACID table with 2 initial rows, later t3 will be locked to force aborted transaction.
@@ -400,7 +403,8 @@ private void prepareIncrementalData() throws Throwable {
     primary.run("use " + primaryDbName)
             .run("insert into t1 values (2), (3)")
             .run("insert into t2 partition(country='india') values ('chennai')")
-            .run("insert into t2 partition(country='india') values ('pune')");
+            .run("insert into t2 partition(country='india') values ('pune')")
+            .run("truncate table t10");
     prepareAbortTxn(primaryDbName, 222);
     primary.run("use " + otherDbName)
             .run("insert into t1 values (200), (300)")
@@ -481,14 +485,14 @@ private void assertTxnOptimization(boolean optimizationOn, WarehouseInstance.Tup
 
     // Assert the number of Txn events that occurred on the replica.
     // When optimization is on, filtered has the number of Txn events that are expected to have been filtered.
-    // When optimization is off, filtered should be all all 0s.
+    // When optimization is off, filtered should be all 0s.
     Assert.assertEquals(expected.getCountOpenTxn() - filtered.getCountOpenTxn(), ReplicaEventListenerTestImpl.getCountOpenTxn());
     Assert.assertEquals(expected.getCountCommitTxn() - filtered.getCountCommitTxn(), ReplicaEventListenerTestImpl.getCountCommitTxn());
     Assert.assertEquals(expected.getCountAbortTxn() - filtered.getCountAbortTxn(), ReplicaEventListenerTestImpl.getCountAbortTxn());
 
     // Assert the number of Txn event files found.
     // When optimization is on, filtered has the number of Txn events that are expected to have been filtered.
-    // When optimization is off, filtered should be all all 0s.
+    // When optimization is off, filtered should be all 0s.
     // Note that when optimization is on, there should never be optnTxn events.
     Assert.assertEquals(optimizationOn ? 0 : expected.getCountOpenTxn(), openTxns.size());
     Assert.assertEquals(expected.getCountCommitTxn() - filtered.getCountCommitTxn(), commitTxns.size());
@@ -501,5 +505,9 @@ private void assertTxnOptimization(boolean optimizationOn, WarehouseInstance.Tup
     for (Map.Entry<Long, Long> mapping : replicaTxnMapping.entrySet()) {
       Assert.assertEquals(mapping.getKey().longValue()  - txnOffset, mapping.getValue().longValue());
     }
+      Map<Long, Long> postReplicationReplTxnMap = new HashMap<>();
+      // In both the cases, the post replication REPL_TXN_MAP should be empty.
+      TestReplicationFilterTransactions.updateTxnMapping(postReplicationReplTxnMap);
+      Assert.assertEquals(0, postReplicationReplTxnMap.size());
   }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/events/AbortTxnHandler.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/events/AbortTxnHandler.java
index 5191e82185..5847d164fb 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/events/AbortTxnHandler.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/events/AbortTxnHandler.java
@@ -30,6 +30,7 @@
 
 import java.util.ArrayList;
 import java.util.List;
+import java.util.stream.Collectors;
 
 class AbortTxnHandler extends AbstractEventHandler<AbortTxnMessage> {
 
@@ -50,8 +51,12 @@ public void handle(Context withinContext) throws Exception {
 
     if (ReplUtils.filterTransactionOperations(withinContext.hiveConf)) {
       String contextDbName = StringUtils.normalizeIdentifier(withinContext.replScope.getDbName());
-      JSONAbortTxnMessage abortMsg = (JSONAbortTxnMessage)eventMessage;
-      if ((abortMsg.getDbsUpdated() == null) || !abortMsg.getDbsUpdated().contains(contextDbName)) {
+      List<Long> writeIds = eventMessage.getWriteIds();
+      List<String> dbsUpdated = eventMessage.getDbsUpdated()
+                                              .stream()
+                                              .map(StringUtils::normalizeIdentifier)
+                                              .collect(Collectors.toList());
+      if ((writeIds == null || writeIds.isEmpty() || !dbsUpdated.contains(contextDbName))) {
         LOG.info("Filter out #{} ABORT_TXN message : {}", fromEventId(), eventMessageAsJSON);
         return;
       }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/events/CommitTxnHandler.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/events/CommitTxnHandler.java
index ddef7807a4..ed55424559 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/events/CommitTxnHandler.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/events/CommitTxnHandler.java
@@ -27,6 +27,7 @@
 import org.apache.hadoop.hive.metastore.api.NotificationEvent;
 import org.apache.hadoop.hive.metastore.api.WriteEventInfo;
 import org.apache.hadoop.hive.metastore.messaging.CommitTxnMessage;
+import org.apache.hadoop.hive.metastore.messaging.json.JSONMessageEncoder;
 import org.apache.hadoop.hive.metastore.messaging.MessageBuilder;
 import org.apache.hadoop.hive.metastore.utils.StringUtils;
 import org.apache.hadoop.hive.ql.exec.repl.util.ReplUtils;
@@ -43,7 +44,9 @@
 import java.io.File;
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.List;
+import java.util.Optional;
 import java.util.stream.Collectors;
 
 class CommitTxnHandler extends AbstractEventHandler<CommitTxnMessage> {
@@ -173,20 +176,48 @@ public void handle(Context withinContext) throws Exception {
       }
 
       List<WriteEventInfo> writeEventInfoList = null;
+      List<WriteEventInfo> allWriteEventInfoExceptMV = null;
       if (replicatingAcidEvents) {
         writeEventInfoList = getAllWriteEventInfo(withinContext);
 
-        if (ReplUtils.filterTransactionOperations(withinContext.hiveConf)
-           && (writeEventInfoList == null || writeEventInfoList.size() == 0)) {
-          // If optimizing transactions, no need to dump this one
-          // if there were no write events.
-          return;
+        if (writeEventInfoList != null) {
+          allWriteEventInfoExceptMV = getAllWriteEventInfoExceptMV(writeEventInfoList);
+        }
+        String dbName = StringUtils.normalizeIdentifier(withinContext.replScope.getDbName());
+
+        if (ReplUtils.filterTransactionOperations(withinContext.hiveConf)) {
+          List<Long> writeIds = eventMessage.getWriteIds();
+          List<String> databases = Optional.ofNullable(eventMessage.getDatabases())
+                  .orElse(Collections.emptyList())
+                  .stream()
+                  .map(StringUtils::normalizeIdentifier)
+                  .collect(Collectors.toList());
+
+//                                        Truth Table
+//     Operation                | writeIds | writeEventInfoList | databases | allWriteEventInfoExceptMV  | Output
+//       Read                   |  null    | null               | null      | same as writeEventInfoList | Skip
+//      Insert                  | not null | not null           | not null  | same                       | Dump
+//      Truncate                | not null | null               | not null  | same                       | Dump
+//    Materialized view         | not null | not null           | not null  | different                  | Skip
+
+          boolean shouldSkip = (writeIds == null || writeIds.isEmpty() || !databases.contains(dbName));
+          if (writeEventInfoList != null && !writeEventInfoList.isEmpty()) {
+            shouldSkip = writeEventInfoList.size() != allWriteEventInfoExceptMV.size();
+          }
+
+          if (shouldSkip) {
+            // If optimizing transactions, no need to dump this one
+            // if there were no write events.
+            LOG.debug("skipping commit txn event for db: {}, writeIds: {}, writeEventInfoList: {}, databases: {}",
+                dbName, writeIds, writeEventInfoList, databases);
+            return;
+          }
         }
       }
 
-      // Filtering out all write event i related to materialized view
+      // Filtering out all write event info related to materialized view
       if (writeEventInfoList != null) {
-        writeEventInfoList = getAllWriteEventInfoExceptMV(writeEventInfoList);
+        writeEventInfoList = allWriteEventInfoExceptMV;
       }
       int numEntry = (writeEventInfoList != null ? writeEventInfoList.size() : 0);
       if (numEntry != 0) {
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/events/AbortTxnEvent.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/events/AbortTxnEvent.java
index 9c63603d39..9f987971f7 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/events/AbortTxnEvent.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/events/AbortTxnEvent.java
@@ -37,13 +37,14 @@ public class AbortTxnEvent extends ListenerEvent {
   private final Long txnId;
   private final TxnType txnType;
   private final List<String> dbsUpdated;
+  private final List<Long> writeId;
 
   public AbortTxnEvent(Long transactionId, IHMSHandler handler) {
-    this(transactionId, null, handler, null);
+    this(transactionId, null, handler, null, null);
   }
 
   public AbortTxnEvent(Long transactionId, TxnType txnType) {
-    this(transactionId, txnType, null, null);
+    this(transactionId, txnType, null, null, null);
   }
 
   /**
@@ -51,15 +52,17 @@ public AbortTxnEvent(Long transactionId, TxnType txnType) {
    * @param txnType type of transaction
    * @param handler handler that is firing the event
    * @param dbsUpdated list of databases that had update events
+   * @param writeId write id for transaction
    */
-  public AbortTxnEvent(Long transactionId, TxnType txnType, IHMSHandler handler, List<String> dbsUpdated) {
+  public AbortTxnEvent(Long transactionId, TxnType txnType, IHMSHandler handler, List<String> dbsUpdated, List<Long> writeId) {
     super(true, handler);
     this.txnId = transactionId;
     this.txnType = txnType;
     this.dbsUpdated = new ArrayList<String>();
     if (dbsUpdated != null) {
-      this.dbsUpdated.addAll(dbsUpdated);;
+      this.dbsUpdated.addAll(dbsUpdated);
     }
+    this.writeId = writeId == null ? new ArrayList<>() : writeId;
   }
 
   /**
@@ -83,4 +86,11 @@ public TxnType getTxnType() {
   public List<String> getDbsUpdated() {
     return dbsUpdated;
   }
+
+  /**
+   * @return List of write ids which are associated with abort txn
+   */
+  public List<Long> getWriteId() {
+    return writeId;
+  }
 }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/events/CommitTxnEvent.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/events/CommitTxnEvent.java
index b357dbb48c..b28d4a1607 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/events/CommitTxnEvent.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/events/CommitTxnEvent.java
@@ -23,6 +23,8 @@
 import org.apache.hadoop.hive.metastore.IHMSHandler;
 import org.apache.hadoop.hive.metastore.api.TxnType;
 
+import java.util.List;
+
 /**
  * CommitTxnEvent
  * Event generated for commit transaction operation
@@ -33,24 +35,30 @@ public class CommitTxnEvent extends ListenerEvent {
 
   private final Long txnId;
   private final TxnType txnType;
+  private final List<Long> writeId;
+  private final List<String> databases;
 
   public CommitTxnEvent(Long transactionId, IHMSHandler handler) {
-    this(transactionId, null, handler);
+    this(transactionId, null, handler, null, null);
   }
 
   public CommitTxnEvent(Long transactionId, TxnType txnType) {
-    this(transactionId, txnType, null);
+    this(transactionId, txnType, null, null, null);
   }
 
   /**
    * @param transactionId Unique identification for the transaction just got committed.
    * @param txnType type of transaction
    * @param handler handler that is firing the event
+   * @param databases list of databases for which commit txn event is fired
+   * @param writeId write id for transaction
    */
-  public CommitTxnEvent(Long transactionId, TxnType txnType, IHMSHandler handler) {
+  public CommitTxnEvent(Long transactionId, TxnType txnType, IHMSHandler handler, List<String> databases, List<Long> writeId) {
     super(true, handler);
     this.txnId = transactionId;
     this.txnType = txnType;
+    this.writeId = writeId;
+    this.databases = databases;
   }
 
   /**
@@ -66,4 +74,18 @@ public Long getTxnId() {
   public TxnType getTxnType() {
     return txnType;
   }
+
+    /**
+     * @return List of write ids for which commit txn event is fired
+     */
+  public List<Long> getWriteId() {
+    return writeId;
+  }
+
+    /**
+     * @return List of databases for which commit txn event is fired
+     */
+  public List<String> getDatabases() {
+    return databases;
+  }
 }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/AbortTxnMessage.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/AbortTxnMessage.java
index e2ebed17f6..84910c1dd8 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/AbortTxnMessage.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/AbortTxnMessage.java
@@ -36,4 +36,6 @@ protected AbortTxnMessage() {
   public abstract Long getTxnId();
 
   public abstract List<String> getDbsUpdated();
+
+  public abstract List<Long> getWriteIds();
 }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/MessageBuilder.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/MessageBuilder.java
index 5cc570256c..0e4dcb0343 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/MessageBuilder.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/MessageBuilder.java
@@ -303,12 +303,12 @@ public OpenTxnMessage buildOpenTxnMessage(Long fromTxnId, Long toTxnId) {
     return new JSONOpenTxnMessage(MS_SERVER_URL, MS_SERVICE_PRINCIPAL, fromTxnId, toTxnId, now());
   }
 
-  public CommitTxnMessage buildCommitTxnMessage(Long txnId) {
-    return new JSONCommitTxnMessage(MS_SERVER_URL, MS_SERVICE_PRINCIPAL, txnId, now());
+  public CommitTxnMessage buildCommitTxnMessage(Long txnId,  List<String> databases,  List<Long> writeIds) {
+    return new JSONCommitTxnMessage(MS_SERVER_URL, MS_SERVICE_PRINCIPAL, txnId, now(), databases, writeIds);
   }
 
-  public AbortTxnMessage buildAbortTxnMessage(Long txnId, List<String> dbsUpdated) {
-    return new JSONAbortTxnMessage(MS_SERVER_URL, MS_SERVICE_PRINCIPAL, txnId, now(), dbsUpdated);
+  public AbortTxnMessage buildAbortTxnMessage(Long txnId, List<String> dbsUpdated, List<Long> writeIds) {
+    return new JSONAbortTxnMessage(MS_SERVER_URL, MS_SERVICE_PRINCIPAL, txnId, now(), dbsUpdated, writeIds);
   }
 
   public AllocWriteIdMessage buildAllocWriteIdMessage(List<TxnToWriteId> txnToWriteIdList,
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/json/JSONAbortTxnMessage.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/json/JSONAbortTxnMessage.java
index da72a3f0f5..d010121f48 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/json/JSONAbortTxnMessage.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/json/JSONAbortTxnMessage.java
@@ -43,6 +43,8 @@ public class JSONAbortTxnMessage extends AbortTxnMessage {
 
   @JsonProperty
   private List<String> dbsUpdated;
+  @JsonProperty
+  private List<Long> writeIds;
 
   /**
    * Default constructor, needed for Jackson.
@@ -50,12 +52,13 @@ public class JSONAbortTxnMessage extends AbortTxnMessage {
   public JSONAbortTxnMessage() {
   }
 
-  public JSONAbortTxnMessage(String server, String servicePrincipal, Long txnid, Long timestamp, List<String> dbsUpdated) {
+  public JSONAbortTxnMessage(String server, String servicePrincipal, Long txnid, Long timestamp, List<String> dbsUpdated, List<Long> writeIds) {
     this.timestamp = timestamp;
     this.txnid = txnid;
     this.server = server;
     this.servicePrincipal = servicePrincipal;
     this.dbsUpdated = dbsUpdated;
+    this.writeIds = writeIds;
   }
 
   @Override
@@ -88,6 +91,11 @@ public List<String> getDbsUpdated() {
     return dbsUpdated;
   }
 
+  @Override
+  public List<Long> getWriteIds() {
+    return writeIds;
+  }
+
   @Override
   public String toString() {
     try {
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/json/JSONCommitTxnMessage.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/json/JSONCommitTxnMessage.java
index 482fc8e26b..a146bc6fea 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/json/JSONCommitTxnMessage.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/messaging/json/JSONCommitTxnMessage.java
@@ -72,6 +72,12 @@ public JSONCommitTxnMessage(String server, String servicePrincipal, Long txnid,
     this.files = null;
   }
 
+  public JSONCommitTxnMessage(String server, String servicePrincipal, Long txnid, Long timestamp, List<String> databases, List<Long> writeIds) {
+    this(server, servicePrincipal, txnid, timestamp);
+    this.databases = databases;
+    this.writeIds = writeIds;
+  }
+
   @Override
   public Long getTxnId() {
     return txnid;
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
index 547c3a04a6..e12a2d9cf1 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
@@ -81,6 +81,7 @@
 import org.apache.hadoop.hive.metastore.datasource.DataSourceProviderFactory;
 import org.apache.hadoop.hive.metastore.events.AbortTxnEvent;
 import org.apache.hadoop.hive.metastore.events.AcidWriteEvent;
+import org.apache.hadoop.hive.metastore.events.CommitTxnEvent;
 import org.apache.hadoop.hive.metastore.events.ListenerEvent;
 import org.apache.hadoop.hive.metastore.messaging.EventMessage;
 import org.apache.hadoop.hive.metastore.metrics.Metrics;
@@ -90,6 +91,7 @@
 import org.apache.hadoop.hive.metastore.txn.entities.LockInfo;
 import org.apache.hadoop.hive.metastore.txn.entities.MetricsInfo;
 import org.apache.hadoop.hive.metastore.txn.entities.TxnStatus;
+import org.apache.hadoop.hive.metastore.txn.entities.TxnWriteDetails;
 import org.apache.hadoop.hive.metastore.txn.jdbc.commands.*;
 import org.apache.hadoop.hive.metastore.txn.jdbc.functions.*;
 import org.apache.hadoop.hive.metastore.txn.jdbc.queries.*;
@@ -129,6 +131,7 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.function.BiPredicate;
+import java.util.stream.Collectors;
 
 import static org.apache.hadoop.hive.metastore.txn.TxnUtils.getEpochFn;
 import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.getDefaultCatalog;
@@ -513,16 +516,39 @@ public long getTargetTxnId(String replPolicy, long sourceTxnId) throws MetaExcep
 
   @Override
   public void abortTxn(AbortTxnRequest rqst) throws NoSuchTxnException, MetaException, TxnAbortedException {
+    List<TxnWriteDetails> txnWriteDetails = new ArrayList<>();
+    if (transactionalListeners != null) {
+      //Find the write details for this transaction.
+      //Doing it here before the metadata tables are updated below.
+      txnWriteDetails = getWriteIdsForTxnID(rqst.getTxnid());
+    }
     TxnType txnType = new AbortTxnFunction(rqst).execute(jdbcResource); 
     if (txnType != null) {
       if (transactionalListeners != null && (!rqst.isSetReplPolicy() || !TxnType.DEFAULT.equals(rqst.getTxn_type()))) {
-        List<String> dbsUpdated = getTxnDbsUpdated(rqst.getTxnid());
-        MetaStoreListenerNotifier.notifyEventWithDirectSql(transactionalListeners, EventMessage.EventType.ABORT_TXN,
-            new AbortTxnEvent(rqst.getTxnid(), txnType, null, dbsUpdated), jdbcResource.getConnection(), sqlGenerator);
+        notifyCommitOrAbortEvent(rqst.getTxnid(),EventMessage.EventType.ABORT_TXN, txnType, jdbcResource.getConnection(), txnWriteDetails, transactionalListeners);
       }
     }
   }
 
+  public static void notifyCommitOrAbortEvent(long txnId, EventMessage.EventType eventType, TxnType txnType, Connection dbConn,
+                                       List<TxnWriteDetails> txnWriteDetails, List<TransactionalMetaStoreEventListener> transactionalListeners) throws MetaException {
+    List<Long> writeIds = txnWriteDetails.stream()
+            .map(TxnWriteDetails::getWriteId)
+            .collect(Collectors.toList());
+    List<String> databases = txnWriteDetails.stream()
+            .map(TxnWriteDetails::getDbName)
+            .collect(Collectors.toList());
+    ListenerEvent txnEvent;
+    if (eventType.equals(EventMessage.EventType.ABORT_TXN)) {
+      txnEvent = new AbortTxnEvent(txnId, txnType, null, databases, writeIds);
+    } else {
+      txnEvent = new CommitTxnEvent(txnId, txnType, null, databases, writeIds);
+    }
+    MetaStoreListenerNotifier.notifyEventWithDirectSql(transactionalListeners,
+            eventType, txnEvent, dbConn, sqlGenerator);
+  }
+
+
   @Override
   public void abortTxns(AbortTxnsRequest rqst) throws MetaException {
     List<Long> txnIds = rqst.getTxn_ids();
@@ -530,6 +556,13 @@ public void abortTxns(AbortTxnsRequest rqst) throws MetaException {
     if (rqst.isSetErrorCode()) {
       txnErrorMsg = TxnErrorMsg.getTxnErrorMsg(rqst.getErrorCode());
     }
+    HashMap<Long, List<TxnWriteDetails>> txnWriteDetailsMap = new HashMap<>();
+    if (transactionalListeners != null) {
+      //Find the write details for this transaction.
+      //Doing it here before the metadata tables are updated below.
+      for(Long txnId : txnIds)
+        txnWriteDetailsMap.put(txnId, getWriteIdsForTxnID(txnId));
+    }
 
     List<String> queries = new ArrayList<>();
     StringBuilder prefix =
@@ -562,10 +595,8 @@ public void abortTxns(AbortTxnsRequest rqst) throws MetaException {
 
       if (transactionalListeners != null) {
         for (Long txnId : txnIds) {
-          List<String> dbsUpdated = getTxnDbsUpdated(txnId);
-          MetaStoreListenerNotifier.notifyEventWithDirectSql(transactionalListeners,
-              EventMessage.EventType.ABORT_TXN, new AbortTxnEvent(txnId,
-                  nonReadOnlyTxns.getOrDefault(txnId, TxnType.READ_ONLY), null, dbsUpdated), dbConn, sqlGenerator);
+          notifyCommitOrAbortEvent(txnId,EventMessage.EventType.ABORT_TXN,
+                  nonReadOnlyTxns.getOrDefault(txnId, TxnType.READ_ONLY), dbConn, txnWriteDetailsMap.get(txnId), transactionalListeners);
         }
       }
     } catch (SQLException e) {
@@ -1141,4 +1172,24 @@ private List<String> getTxnDbsUpdated(long txnId) throws MetaException {
     }
   }
 
+  /**
+   * Returns the databases and writeID updated by txnId.
+   * Queries TXN_TO_WRITE_ID using txnId.
+   *
+   * @param txnId Transaction ID for which write IDs are requested.
+   * @throws MetaException
+   */
+  public List<TxnWriteDetails> getWriteIdsForTxnID(long txnId) throws MetaException {
+    try {
+      return sqlRetryHandler.executeWithRetry(
+              new SqlRetryCallProperties().withCallerId("GetWriteIdsForTxnIDHandler"),
+              () -> jdbcResource.execute(new GetWriteIdsForTxnIDHandler(txnId)));
+    } catch (MetaException e) {
+      throw e;
+    } catch (TException e) {
+      throw new MetaException(e.getMessage());
+    }
+  }
+
+
 }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/entities/TxnWriteDetails.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/entities/TxnWriteDetails.java
new file mode 100644
index 0000000000..45f115da5d
--- /dev/null
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/entities/TxnWriteDetails.java
@@ -0,0 +1,54 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.metastore.txn.entities;
+
+/**
+ * Class to hold transaction id, database name and write id.
+ */
+public class TxnWriteDetails {
+    private final long txnId;
+    private final String dbName;
+    private final long writeId;
+
+    public TxnWriteDetails(long txnId, String dbName, long writeId) {
+        this.txnId = txnId;
+        this.dbName = dbName;
+        this.writeId = writeId;
+    }
+
+    @Override
+    public String toString() {
+        return "TxnToWriteID{" +
+                "txnId=" + txnId +
+                ", dbName='" + dbName + '\'' +
+                ", writeId=" + writeId +
+                '}';
+    }
+
+    public long getTxnId() {
+        return txnId;
+    }
+
+    public String getDbName() {
+        return dbName;
+    }
+
+    public long getWriteId() {
+        return writeId;
+    }
+}
\ No newline at end of file
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/jdbc/functions/CommitTxnFunction.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/jdbc/functions/CommitTxnFunction.java
index 6b5b81aace..ac90f5ce61 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/jdbc/functions/CommitTxnFunction.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/jdbc/functions/CommitTxnFunction.java
@@ -41,6 +41,7 @@
 import org.apache.hadoop.hive.metastore.txn.entities.TxnStatus;
 import org.apache.hadoop.hive.metastore.txn.TxnStore;
 import org.apache.hadoop.hive.metastore.txn.TxnUtils;
+import org.apache.hadoop.hive.metastore.txn.entities.TxnWriteDetails;
 import org.apache.hadoop.hive.metastore.txn.jdbc.commands.DeleteReplTxnMapEntryCommand;
 import org.apache.hadoop.hive.metastore.txn.jdbc.commands.InsertCompletedTxnComponentsCommand;
 import org.apache.hadoop.hive.metastore.txn.jdbc.commands.RemoveTxnsFromMinHistoryLevelCommand;
@@ -49,6 +50,7 @@
 import org.apache.hadoop.hive.metastore.txn.jdbc.queries.GetCompactionInfoHandler;
 import org.apache.hadoop.hive.metastore.txn.jdbc.queries.GetHighWaterMarkHandler;
 import org.apache.hadoop.hive.metastore.txn.jdbc.queries.GetOpenTxnTypeAndLockHandler;
+import org.apache.hadoop.hive.metastore.txn.jdbc.queries.GetWriteIdsForTxnIDHandler;
 import org.apache.hadoop.hive.metastore.txn.jdbc.queries.TargetTxnIdListHandler;
 import org.apache.hadoop.hive.metastore.txn.jdbc.MultiDataSourceJdbcResource;
 import org.apache.hadoop.hive.metastore.txn.jdbc.RollbackException;
@@ -72,6 +74,7 @@
 import java.util.stream.Collectors;
 import java.util.stream.IntStream;
 
+import static org.apache.hadoop.hive.metastore.txn.TxnHandler.notifyCommitOrAbortEvent;
 import static org.apache.hadoop.hive.metastore.txn.TxnUtils.getEpochFn;
 import static org.apache.hadoop.hive.metastore.utils.StringUtils.normalizeIdentifier;
 
@@ -95,6 +98,14 @@ public TxnType execute(MultiDataSourceJdbcResource jdbcResource) throws MetaExce
 
     boolean isReplayedReplTxn = TxnType.REPL_CREATED.equals(rqst.getTxn_type());
     boolean isHiveReplTxn = rqst.isSetReplPolicy() && TxnType.DEFAULT.equals(rqst.getTxn_type());
+    //Find the write details for this transaction.
+    //Doing it here before the metadata tables are updated below.
+    List<TxnWriteDetails> txnWriteDetails = new ArrayList<>();
+
+    if (!isHiveReplTxn) {
+      txnWriteDetails = jdbcResource.execute(new GetWriteIdsForTxnIDHandler(rqst.getTxnid()));
+
+    }
     // Get the current TXN
     TransactionContext context = jdbcResource.getTransactionManager().getActiveTransaction();
     Long commitId = null;
@@ -262,7 +273,7 @@ public TxnType execute(MultiDataSourceJdbcResource jdbcResource) throws MetaExce
     }
 
     if (!isHiveReplTxn) {
-      createCommitNotificationEvent(jdbcResource, txnid , txnType);
+      createCommitNotificationEvent(jdbcResource, txnid , txnType, txnWriteDetails);
     }
 
     LOG.debug("Going to commit");
@@ -575,15 +586,16 @@ private void updateWSCommitIdAndCleanUpMetadata(MultiDataSourceJdbcResource jdbc
 
   /**
    * Create Notifiaction Events on txn commit
+   *
    * @param txnid committed txn
    * @param txnType transaction type
+   * @param txnWriteDetails write details of the transaction
    * @throws MetaException ex
    */
-  private void createCommitNotificationEvent(MultiDataSourceJdbcResource jdbcResource, long txnid, TxnType txnType)
+  private void createCommitNotificationEvent(MultiDataSourceJdbcResource jdbcResource, long txnid, TxnType txnType, List<TxnWriteDetails> txnWriteDetails)
       throws MetaException {
     if (transactionalListeners != null) {
-      MetaStoreListenerNotifier.notifyEventWithDirectSql(transactionalListeners,
-          EventMessage.EventType.COMMIT_TXN, new CommitTxnEvent(txnid, txnType), jdbcResource.getConnection(), jdbcResource.getSqlGenerator());
+      notifyCommitOrAbortEvent(txnid, EventMessage.EventType.COMMIT_TXN, txnType, jdbcResource.getConnection(), txnWriteDetails, transactionalListeners);
 
       CompactionInfo compactionInfo = jdbcResource.execute(new GetCompactionInfoHandler(txnid, true));
       if (compactionInfo != null) {
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/jdbc/functions/PerformTimeoutsFunction.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/jdbc/functions/PerformTimeoutsFunction.java
index 8a7e9555fb..c70985ec54 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/jdbc/functions/PerformTimeoutsFunction.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/jdbc/functions/PerformTimeoutsFunction.java
@@ -29,10 +29,12 @@
 import org.apache.hadoop.hive.metastore.txn.TxnErrorMsg;
 import org.apache.hadoop.hive.metastore.txn.entities.TxnStatus;
 import org.apache.hadoop.hive.metastore.txn.TxnUtils;
+import org.apache.hadoop.hive.metastore.txn.entities.TxnWriteDetails;
 import org.apache.hadoop.hive.metastore.txn.jdbc.MultiDataSourceJdbcResource;
 import org.apache.hadoop.hive.metastore.txn.jdbc.TransactionContext;
 import org.apache.hadoop.hive.metastore.txn.jdbc.TransactionalFunction;
 import org.apache.hadoop.hive.metastore.txn.jdbc.queries.GetTxnDbsUpdatedHandler;
+import org.apache.hadoop.hive.metastore.txn.jdbc.queries.GetWriteIdsForTxnIDHandler;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.springframework.jdbc.core.namedparam.MapSqlParameterSource;
@@ -45,6 +47,7 @@
 import java.util.Set;
 import java.util.TreeSet;
 
+import static org.apache.hadoop.hive.metastore.txn.TxnHandler.notifyCommitOrAbortEvent;
 import static org.apache.hadoop.hive.metastore.txn.TxnUtils.getEpochFn;
 
 public class PerformTimeoutsFunction implements TransactionalFunction<Void> {
@@ -129,11 +132,9 @@ public Void execute(MultiDataSourceJdbcResource jdbcResource) {
             LOG.info("Aborted the following transactions due to timeout: {}", batchToAbort);
             if (transactionalListeners != null) {
               for (Map.Entry<Long, TxnType> txnEntry : batchToAbort.entrySet()) {
-                List<String> dbsUpdated = jdbcResource.execute(new GetTxnDbsUpdatedHandler(txnEntry.getKey()));
-                MetaStoreListenerNotifier.notifyEventWithDirectSql(transactionalListeners,
-                    EventMessage.EventType.ABORT_TXN,
-                    new AbortTxnEvent(txnEntry.getKey(), txnEntry.getValue(), null, dbsUpdated),
-                    jdbcResource.getConnection(), jdbcResource.getSqlGenerator());
+                List<TxnWriteDetails> txnWriteDetails = jdbcResource.execute(new GetWriteIdsForTxnIDHandler(txnEntry.getKey()));
+                notifyCommitOrAbortEvent(txnEntry.getKey(), EventMessage.EventType.ABORT_TXN , txnEntry.getValue(),
+                        jdbcResource.getConnection(), txnWriteDetails, transactionalListeners);
               }
               LOG.debug("Added Notifications for the transactions that are aborted due to timeout: {}", batchToAbort);
             }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/jdbc/queries/GetWriteIdsForTxnIDHandler.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/jdbc/queries/GetWriteIdsForTxnIDHandler.java
new file mode 100644
index 0000000000..c3a69fc52b
--- /dev/null
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/jdbc/queries/GetWriteIdsForTxnIDHandler.java
@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.metastore.txn.jdbc.queries;
+
+import org.apache.hadoop.hive.metastore.DatabaseProduct;
+import org.apache.hadoop.hive.metastore.api.MetaException;
+import org.apache.hadoop.hive.metastore.txn.entities.TxnWriteDetails;
+import org.apache.hadoop.hive.metastore.txn.jdbc.QueryHandler;
+import org.springframework.dao.DataAccessException;
+import org.springframework.jdbc.core.namedparam.MapSqlParameterSource;
+import org.springframework.jdbc.core.namedparam.SqlParameterSource;
+
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * Returns the databases and writeID updated by txnId.
+ * Queries TXN_TO_WRITE_ID using txnId.
+ */
+public class GetWriteIdsForTxnIDHandler implements QueryHandler<List<TxnWriteDetails>> {
+
+    private final long txnId;
+
+    public GetWriteIdsForTxnIDHandler(long txnId) {
+        this.txnId = txnId;
+    }
+
+    @Override
+    public String getParameterizedQueryString(DatabaseProduct databaseProduct) throws MetaException {
+        return "SELECT DISTINCT \"T2W_DATABASE\", \"T2W_WRITEID\" FROM \"TXN_TO_WRITE_ID\" \"COMMITTED\" WHERE \"T2W_TXNID\" = :txnId";
+    }
+
+    @Override
+    public SqlParameterSource getQueryParameters() {
+        return new MapSqlParameterSource().addValue("txnId", txnId);
+    }
+
+    @Override
+    public List<TxnWriteDetails> extractData(ResultSet rs) throws SQLException, DataAccessException {
+        List<TxnWriteDetails> dbsUpdated = new ArrayList<>();
+        while (rs.next()) {
+            TxnWriteDetails entry = new TxnWriteDetails(txnId, rs.getString(1), rs.getLong(2));
+            dbsUpdated.add(entry);
+        }
+        return dbsUpdated;
+    }
+}
+
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/events/TestAbortTxnEventDbsUpdated.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/events/TestAbortTxnEventDbsUpdated.java
index 40b2432295..90823ecbbc 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/events/TestAbortTxnEventDbsUpdated.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/events/TestAbortTxnEventDbsUpdated.java
@@ -49,9 +49,10 @@ public void testBackwardsCompatibility() {
   @Test
   public void testSerializeDeserialize() {
     List dbsUpdated = Arrays.asList("db1", "db22");
-    AbortTxnEvent event = new AbortTxnEvent(999L, TxnType.DEFAULT, null, dbsUpdated);
+    List writeIds = Arrays.asList(1L, 2L);
+    AbortTxnEvent event = new AbortTxnEvent(999L, TxnType.DEFAULT, null, dbsUpdated, writeIds);
     AbortTxnMessage msg =
-            MessageBuilder.getInstance().buildAbortTxnMessage(event.getTxnId(), event.getDbsUpdated());
+            MessageBuilder.getInstance().buildAbortTxnMessage(event.getTxnId(), event.getDbsUpdated(), event.getWriteId());
     JSONMessageEncoder msgEncoder = new JSONMessageEncoder();
     String json = msgEncoder.getSerializer().serialize(msg);
 
@@ -63,6 +64,12 @@ public void testSerializeDeserialize() {
     Assert.assertTrue(actual.remove("db1"));
     Assert.assertTrue(actual.remove("db22"));
     Assert.assertTrue(actual.isEmpty());
+
+    List actualWriteIds = abortTxnMsg.getWriteIds();
+    Assert.assertTrue(actualWriteIds.remove(1L));
+    Assert.assertTrue(actualWriteIds.remove(2L));
+    Assert.assertTrue(actualWriteIds.isEmpty());
+
     Assert.assertEquals(999L, abortTxnMsg.getTxnId().longValue());
   }
 }
diff --git a/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/events/TestCommitTxnEventWithDbAndWriteId.java b/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/events/TestCommitTxnEventWithDbAndWriteId.java
new file mode 100644
index 0000000000..0929686194
--- /dev/null
+++ b/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/events/TestCommitTxnEventWithDbAndWriteId.java
@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * <p>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.metastore.events;
+
+import org.apache.hadoop.hive.metastore.annotation.MetastoreUnitTest;
+import org.apache.hadoop.hive.metastore.api.TxnType;
+import org.apache.hadoop.hive.metastore.messaging.CommitTxnMessage;
+import org.apache.hadoop.hive.metastore.messaging.MessageBuilder;
+import org.apache.hadoop.hive.metastore.messaging.json.JSONMessageDeserializer;
+import org.apache.hadoop.hive.metastore.messaging.json.JSONMessageEncoder;
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+@Category(MetastoreUnitTest.class)
+public class TestCommitTxnEventWithDbAndWriteId {
+    @Test
+    public void testBackwardsCompatibility() {
+        final String json = "{\"txnid\":12787,\"timestamp\":1654116516,\"server\":\"\",\"servicePrincipal\":\"\"}";
+        JSONMessageDeserializer deserializer = new JSONMessageDeserializer();
+        CommitTxnMessage commitTxnMsg = deserializer.getCommitTxnMessage(json);
+        Assert.assertNull(commitTxnMsg.getDatabases());
+        Assert.assertEquals(12787L, commitTxnMsg.getTxnId().longValue());
+    }
+
+    @Test
+    public void testSerializeDeserialize() {
+        
+        List<String> databases = Arrays.asList("db1", "db22");
+        List<Long> writeIds = Arrays.asList(1L, 2L);
+        CommitTxnEvent event = new CommitTxnEvent(999L, TxnType.DEFAULT, null, databases, writeIds);
+        CommitTxnMessage msg =
+                MessageBuilder.getInstance().buildCommitTxnMessage(event.getTxnId(), event.getDatabases(), event.getWriteId());
+        JSONMessageEncoder msgEncoder = new JSONMessageEncoder();
+        String json = msgEncoder.getSerializer().serialize(msg);
+
+        JSONMessageDeserializer deserializer = new JSONMessageDeserializer();
+        CommitTxnMessage commitTxnMsg = deserializer.getCommitTxnMessage(json);
+        Set<String> expected = new HashSet(databases);
+        Assert.assertEquals(expected.size(), commitTxnMsg.getDatabases().size());
+        List actual = commitTxnMsg.getDatabases();
+        Assert.assertTrue(actual.remove("db1"));
+        Assert.assertTrue(actual.remove("db22"));
+        Assert.assertTrue(actual.isEmpty());
+
+        List actualWriteIds = commitTxnMsg.getWriteIds();
+        Assert.assertTrue(actualWriteIds.remove(1L));
+        Assert.assertTrue(actualWriteIds.remove(2L));
+        Assert.assertTrue(actualWriteIds.isEmpty());
+
+        Assert.assertEquals(999L, commitTxnMsg.getTxnId().longValue());
+    }
+    
+    
+}
