diff --git a/data/files/opencsv-data.txt b/data/files/opencsv-data.txt
new file mode 100644
index 0000000000..7d5968b468
--- /dev/null
+++ b/data/files/opencsv-data.txt
@@ -0,0 +1,3 @@
+why hello there,42,3,100,1412341,true,42.43,85.23423424
+another record,98,4,101,9999999,false,99.89,0.00000009
+third record,45,5,102,999999999,true,89.99,0.00000000000009
\ No newline at end of file
diff --git a/pom.xml b/pom.xml
index 2e128fca30..95fd8f2950 100644
--- a/pom.xml
+++ b/pom.xml
@@ -137,6 +137,7 @@
     <libfb303.version>0.9.0</libfb303.version>
     <libthrift.version>0.9.0</libthrift.version>
     <log4j.version>1.2.16</log4j.version>
+    <opencsv.version>2.3</opencsv.version>
     <mockito-all.version>1.9.5</mockito-all.version>
     <mina.version>2.0.0-M5</mina.version>
     <!--netty is not a direct dependency but due to a change
diff --git a/ql/pom.xml b/ql/pom.xml
index c3e0adb853..85d2a5fd68 100644
--- a/ql/pom.xml
+++ b/ql/pom.xml
@@ -211,6 +211,11 @@
       <artifactId>stax-api</artifactId>
       <version>${stax.version}</version>
     </dependency>
+    <dependency>
+      <groupId>net.sf.opencsv</groupId>
+      <artifactId>opencsv</artifactId>
+      <version>${opencsv.version}</version>
+    </dependency>
     <!-- test intra-project -->
     <!-- test inter-project -->
     <dependency>
@@ -587,6 +592,7 @@
                   <include>org.codehaus.jackson:jackson-core-asl</include>
                   <include>org.codehaus.jackson:jackson-mapper-asl</include>
                   <include>com.google.guava:guava</include>
+                  <include>net.sf.opencsv:opencsv</include>
                 </includes>
               </artifactSet>
               <relocations>
diff --git a/ql/src/test/queries/clientpositive/serde_opencsv.q b/ql/src/test/queries/clientpositive/serde_opencsv.q
new file mode 100644
index 0000000000..a5ef8da5e1
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/serde_opencsv.q
@@ -0,0 +1,36 @@
+EXPLAIN
+CREATE TABLE serde_opencsv(
+                          words STRING,
+                          int1 INT,
+                          tinyint1 TINYINT,
+                          smallint1 SMALLINT,
+                          bigint1 BIGINT,
+                          boolean1 BOOLEAN,
+                          float1 FLOAT,
+                          double1 DOUBLE)
+ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
+WITH SERDEPROPERTIES(
+  "separatorChar" = ",",
+  "quoteChar"     = "'",
+  "escapeChar"    = "\\"
+) stored as textfile;
+
+CREATE TABLE serde_opencsv(
+                          words STRING,
+                          int1 INT,
+                          tinyint1 TINYINT,
+                          smallint1 SMALLINT,
+                          bigint1 BIGINT,
+                          boolean1 BOOLEAN,
+                          float1 FLOAT,
+                          double1 DOUBLE)
+ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
+WITH SERDEPROPERTIES(
+  "separatorChar" = ",",
+  "quoteChar"     = "'",
+  "escapeChar"    = "\\"
+) stored as textfile;
+
+LOAD DATA LOCAL INPATH "../../data/files/opencsv-data.txt" INTO TABLE serde_opencsv;
+
+SELECT count(*) FROM serde_opencsv;
\ No newline at end of file
diff --git a/ql/src/test/results/clientpositive/serde_opencsv.q.out b/ql/src/test/results/clientpositive/serde_opencsv.q.out
new file mode 100644
index 0000000000..230c475ca4
--- /dev/null
+++ b/ql/src/test/results/clientpositive/serde_opencsv.q.out
@@ -0,0 +1,104 @@
+PREHOOK: query: EXPLAIN
+CREATE TABLE serde_opencsv(
+                          words STRING,
+                          int1 INT,
+                          tinyint1 TINYINT,
+                          smallint1 SMALLINT,
+                          bigint1 BIGINT,
+                          boolean1 BOOLEAN,
+                          float1 FLOAT,
+                          double1 DOUBLE)
+ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
+WITH SERDEPROPERTIES(
+  "separatorChar" = ",",
+  "quoteChar"     = "'",
+  "escapeChar"    = "\\"
+) stored as textfile
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: EXPLAIN
+CREATE TABLE serde_opencsv(
+                          words STRING,
+                          int1 INT,
+                          tinyint1 TINYINT,
+                          smallint1 SMALLINT,
+                          bigint1 BIGINT,
+                          boolean1 BOOLEAN,
+                          float1 FLOAT,
+                          double1 DOUBLE)
+ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
+WITH SERDEPROPERTIES(
+  "separatorChar" = ",",
+  "quoteChar"     = "'",
+  "escapeChar"    = "\\"
+) stored as textfile
+POSTHOOK: type: CREATETABLE
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+      Create Table Operator:
+        Create Table
+          columns: words string, int1 int, tinyint1 tinyint, smallint1 smallint, bigint1 bigint, boolean1 boolean, float1 float, double1 double
+          input format: org.apache.hadoop.mapred.TextInputFormat
+          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+          serde name: org.apache.hadoop.hive.serde2.OpenCSVSerde
+          serde properties:
+            escapeChar \
+            quoteChar '
+            separatorChar ,
+          name: default.serde_opencsv
+
+PREHOOK: query: CREATE TABLE serde_opencsv(
+                          words STRING,
+                          int1 INT,
+                          tinyint1 TINYINT,
+                          smallint1 SMALLINT,
+                          bigint1 BIGINT,
+                          boolean1 BOOLEAN,
+                          float1 FLOAT,
+                          double1 DOUBLE)
+ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
+WITH SERDEPROPERTIES(
+  "separatorChar" = ",",
+  "quoteChar"     = "'",
+  "escapeChar"    = "\\"
+) stored as textfile
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@serde_opencsv
+POSTHOOK: query: CREATE TABLE serde_opencsv(
+                          words STRING,
+                          int1 INT,
+                          tinyint1 TINYINT,
+                          smallint1 SMALLINT,
+                          bigint1 BIGINT,
+                          boolean1 BOOLEAN,
+                          float1 FLOAT,
+                          double1 DOUBLE)
+ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
+WITH SERDEPROPERTIES(
+  "separatorChar" = ",",
+  "quoteChar"     = "'",
+  "escapeChar"    = "\\"
+) stored as textfile
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@serde_opencsv
+PREHOOK: query: LOAD DATA LOCAL INPATH "../../data/files/opencsv-data.txt" INTO TABLE serde_opencsv
+PREHOOK: type: LOAD
+#### A masked pattern was here ####
+PREHOOK: Output: default@serde_opencsv
+POSTHOOK: query: LOAD DATA LOCAL INPATH "../../data/files/opencsv-data.txt" INTO TABLE serde_opencsv
+POSTHOOK: type: LOAD
+#### A masked pattern was here ####
+POSTHOOK: Output: default@serde_opencsv
+PREHOOK: query: SELECT count(*) FROM serde_opencsv
+PREHOOK: type: QUERY
+PREHOOK: Input: default@serde_opencsv
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT count(*) FROM serde_opencsv
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@serde_opencsv
+#### A masked pattern was here ####
+3
diff --git a/serde/pom.xml b/serde/pom.xml
index f8bcc830cf..9f327f00f1 100644
--- a/serde/pom.xml
+++ b/serde/pom.xml
@@ -70,7 +70,13 @@
       <artifactId>libthrift</artifactId>
       <version>${libthrift.version}</version>
     </dependency>
-    <!-- test inter-project -->
+    <dependency>
+      <groupId>net.sf.opencsv</groupId>
+      <artifactId>opencsv</artifactId>
+      <version>${opencsv.version}</version>
+    </dependency>
+
+      <!-- test inter-project -->
     <dependency>
       <groupId>junit</groupId>
       <artifactId>junit</artifactId>
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/OpenCSVSerde.java b/serde/src/java/org/apache/hadoop/hive/serde2/OpenCSVSerde.java
new file mode 100644
index 0000000000..ac6c6dd681
--- /dev/null
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/OpenCSVSerde.java
@@ -0,0 +1,205 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.serde2;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hive.serde.serdeConstants;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.objectinspector.StructField;
+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;
+import org.apache.hadoop.io.Text;
+import org.apache.hadoop.io.Writable;
+
+import java.io.CharArrayReader;
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringWriter;
+import java.io.Writer;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+import java.util.Properties;
+
+import au.com.bytecode.opencsv.CSVReader;
+import au.com.bytecode.opencsv.CSVWriter;
+
+/**
+ * OpenCSVSerde use opencsv to deserialize CSV format.
+ * Users can specify custom separator, quote or escape characters. And the default separator(\),
+ * quote("), and escape characters(\) are the same as the opencsv library.
+ *
+ */
+public final class OpenCSVSerde extends AbstractSerDe {
+
+  public static final Log LOG = LogFactory.getLog(OpenCSVSerde.class.getName());
+  private ObjectInspector inspector;
+  private String[] outputFields;
+  private int numCols;
+  private List<String> row;
+
+  private char separatorChar;
+  private char quoteChar;
+  private char escapeChar;
+
+  public static final String SEPARATORCHAR = "separatorChar";
+  public static final String QUOTECHAR = "quoteChar";
+  public static final String ESCAPECHAR = "escapeChar";
+
+  @Override
+  public void initialize(final Configuration conf, final Properties tbl) throws SerDeException {
+
+    final List<String> columnNames = Arrays.asList(tbl.getProperty(serdeConstants.LIST_COLUMNS)
+            .split(","));
+
+    numCols = columnNames.size();
+
+    final List<ObjectInspector> columnOIs = new ArrayList<ObjectInspector>(numCols);
+
+    for (int i = 0; i < numCols; i++) {
+      columnOIs.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);
+    }
+
+    inspector = ObjectInspectorFactory.getStandardStructObjectInspector(columnNames, columnOIs);
+    outputFields = new String[numCols];
+    row = new ArrayList<String>(numCols);
+
+    for (int i = 0; i < numCols; i++) {
+      row.add(null);
+    }
+
+    separatorChar = getProperty(tbl, SEPARATORCHAR, CSVWriter.DEFAULT_SEPARATOR);
+    quoteChar = getProperty(tbl, QUOTECHAR, CSVWriter.DEFAULT_QUOTE_CHARACTER);
+    escapeChar = getProperty(tbl, ESCAPECHAR, CSVWriter.DEFAULT_ESCAPE_CHARACTER);
+  }
+
+  private char getProperty(final Properties tbl, final String property, final char def) {
+    final String val = tbl.getProperty(property);
+
+    if (val != null) {
+      return val.charAt(0);
+    }
+
+    return def;
+  }
+
+  @Override
+  public Writable serialize(Object obj, ObjectInspector objInspector) throws SerDeException {
+    final StructObjectInspector outputRowOI = (StructObjectInspector) objInspector;
+    final List<? extends StructField> outputFieldRefs = outputRowOI.getAllStructFieldRefs();
+
+    if (outputFieldRefs.size() != numCols) {
+      throw new SerDeException("Cannot serialize the object because there are "
+              + outputFieldRefs.size() + " fields but the table has " + numCols + " columns.");
+    }
+
+    // Get all data out.
+    for (int c = 0; c < numCols; c++) {
+      final Object field = outputRowOI.getStructFieldData(obj, outputFieldRefs.get(c));
+      final ObjectInspector fieldOI = outputFieldRefs.get(c).getFieldObjectInspector();
+
+      // The data must be of type String
+      final StringObjectInspector fieldStringOI = (StringObjectInspector) fieldOI;
+
+      // Convert the field to Java class String, because objects of String type
+      // can be stored in String, Text, or some other classes.
+      outputFields[c] = fieldStringOI.getPrimitiveJavaObject(field);
+    }
+
+    final StringWriter writer = new StringWriter();
+    final CSVWriter csv = newWriter(writer, separatorChar, quoteChar, escapeChar);
+
+    try {
+      csv.writeNext(outputFields);
+      csv.close();
+
+      return new Text(writer.toString());
+    } catch (final IOException ioe) {
+      throw new SerDeException(ioe);
+    }
+  }
+
+  @Override
+  public Object deserialize(final Writable blob) throws SerDeException {
+    Text rowText = (Text) blob;
+
+    CSVReader csv = null;
+    try {
+      csv = newReader(new CharArrayReader(rowText.toString().toCharArray()), separatorChar,
+              quoteChar, escapeChar);
+      final String[] read = csv.readNext();
+
+      for (int i = 0; i < numCols; i++) {
+        if (read != null && i < read.length) {
+          row.set(i, read[i]);
+        } else {
+          row.set(i, null);
+        }
+      }
+
+      return row;
+    } catch (final Exception e) {
+      throw new SerDeException(e);
+    } finally {
+      if (csv != null) {
+        try {
+          csv.close();
+        } catch (final Exception e) {
+          LOG.error("fail to close csv writer ", e);
+        }
+      }
+    }
+  }
+
+  private CSVReader newReader(final Reader reader, char separator, char quote, char escape) {
+    // CSVReader will throw an exception if any of separator, quote, or escape is the same, but
+    // the CSV format specifies that the escape character and quote char are the same... very weird
+    if (CSVWriter.DEFAULT_ESCAPE_CHARACTER == escape) {
+      return new CSVReader(reader, separator, quote);
+    } else {
+      return new CSVReader(reader, separator, quote, escape);
+    }
+  }
+
+  private CSVWriter newWriter(final Writer writer, char separator, char quote, char escape) {
+    if (CSVWriter.DEFAULT_ESCAPE_CHARACTER == escape) {
+      return new CSVWriter(writer, separator, quote, "");
+    } else {
+      return new CSVWriter(writer, separator, quote, escape, "");
+    }
+  }
+
+  @Override
+  public ObjectInspector getObjectInspector() throws SerDeException {
+    return inspector;
+  }
+
+  @Override
+  public Class<? extends Writable> getSerializedClass() {
+    return Text.class;
+  }
+
+  @Override
+  public SerDeStats getSerDeStats() {
+    return null;
+  }
+}
diff --git a/serde/src/test/org/apache/hadoop/hive/serde2/TestOpenCSVSerde.java b/serde/src/test/org/apache/hadoop/hive/serde2/TestOpenCSVSerde.java
new file mode 100644
index 0000000000..99fa553f97
--- /dev/null
+++ b/serde/src/test/org/apache/hadoop/hive/serde2/TestOpenCSVSerde.java
@@ -0,0 +1,82 @@
+package org.apache.hadoop.hive.serde2;
+
+import java.util.List;
+import java.util.Properties;
+
+import org.apache.hadoop.hive.serde.serdeConstants;
+import org.apache.hadoop.io.Text;
+import org.junit.Before;
+import org.junit.Test;
+import static org.junit.Assert.assertEquals;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class TestOpenCSVSerde {
+  private final OpenCSVSerde csv = new OpenCSVSerde();
+  private final Properties props = new Properties();
+
+  @Before
+  public void setup() throws Exception {
+    props.setProperty(serdeConstants.LIST_COLUMNS, "a,b,c");
+    props.setProperty(serdeConstants.LIST_COLUMN_TYPES, "string,string,string");
+  }
+
+  @Test
+  public void testDeserialize() throws Exception {
+    csv.initialize(null, props);
+    final Text in = new Text("hello,\"yes, okay\",1");
+
+    final List<String> row = (List<String>) csv.deserialize(in);
+
+    assertEquals("hello", row.get(0));
+    assertEquals("yes, okay", row.get(1));
+    assertEquals("1", row.get(2));
+  }
+
+
+  @Test
+  public void testDeserializeCustomSeparators() throws Exception {
+    props.setProperty(OpenCSVSerde.SEPARATORCHAR, "\t");
+    props.setProperty(OpenCSVSerde.QUOTECHAR, "'");
+
+    csv.initialize(null, props);
+
+    final Text in = new Text("hello\t'yes\tokay'\t1");
+    final List<String> row = (List<String>) csv.deserialize(in);
+
+    assertEquals("hello", row.get(0));
+    assertEquals("yes\tokay", row.get(1));
+    assertEquals("1", row.get(2));
+  }
+
+  @Test
+  public void testDeserializeCustomEscape() throws Exception {
+    props.setProperty(OpenCSVSerde.QUOTECHAR, "'");
+    props.setProperty(OpenCSVSerde.ESCAPECHAR, "\\");
+
+    csv.initialize(null, props);
+
+    final Text in = new Text("hello,'yes\\'okay',1");
+    final List<String> row = (List<String>) csv.deserialize(in);
+
+    assertEquals("hello", row.get(0));
+    assertEquals("yes'okay", row.get(1));
+    assertEquals("1", row.get(2));
+  }
+}
