diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java
index dd75772019..0c50cea7f4 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java
@@ -329,6 +329,15 @@ private int aggregateStats() {
               work.getAggKey(), atomic);
           statsAggregator.cleanUp(work.getAggKey());
         }
+        // The collectable stats for the aggregator needs to be cleared.
+        // For eg. if a file is being loaded, the old number of rows are not valid
+        else if (work.isClearAggregatorStats()) {
+          for (String statType : collectableStats) {
+            if (parameters.containsKey(statType)) {
+              tblStats.setStat(statType, 0L);
+            }
+          }
+        }
       } else {
         // Partitioned table:
         // Need to get the old stats of the partition
@@ -368,7 +377,16 @@ private int aggregateStats() {
                 parameters, partitionID, atomic);
           } else {
             for (String statType : collectableStats) {
-              newPartStats.setStat(statType, currentValues.get(statType));
+              // The collectable stats for the aggregator needs to be cleared.
+              // For eg. if a file is being loaded, the old number of rows are not valid
+              if (work.isClearAggregatorStats()) {
+                if (parameters.containsKey(statType)) {
+                  newPartStats.setStat(statType, 0L);
+                }
+              }
+              else {
+                newPartStats.setStat(statType, currentValues.get(statType));
+              }
             }
           }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
index b5134671c0..22fa20f737 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
@@ -44,7 +44,7 @@
 import org.apache.hadoop.hive.ql.plan.CopyWork;
 import org.apache.hadoop.hive.ql.plan.LoadTableDesc;
 import org.apache.hadoop.hive.ql.plan.MoveWork;
-import org.apache.hadoop.util.Shell;
+import org.apache.hadoop.hive.ql.plan.StatsWork;
 
 /**
  * LoadSemanticAnalyzer.
@@ -259,30 +259,49 @@ public void analyzeInternal(ASTNode ast) throws SemanticException {
     LoadTableDesc loadTableWork = new LoadTableDesc(fromURI.toString(),
         loadTmpPath, Utilities.getTableDesc(ts.tableHandle), partSpec, isOverWrite);
 
+    Task<? extends Serializable> childTask = TaskFactory.get(new MoveWork(getInputs(),
+        getOutputs(), loadTableWork, null, true), conf);
     if (rTask != null) {
-      rTask.addDependentTask(TaskFactory.get(new MoveWork(getInputs(),
-          getOutputs(), loadTableWork, null, true), conf));
+      rTask.addDependentTask(childTask);
     } else {
-      rTask = TaskFactory.get(new MoveWork(getInputs(), getOutputs(),
-          loadTableWork, null, true), conf);
+      rTask = childTask;
     }
 
     rootTasks.add(rTask);
+
+    // The user asked for stats to be collected.
+    // Some stats like number of rows require a scan of the data
+    // However, some other stats, like number of files, do not require a complete scan
+    // Update the stats which do not require a complete scan.
+    Task<? extends Serializable> statTask = null;
+    if (conf.getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
+      StatsWork statDesc = new StatsWork(loadTableWork);
+      statDesc.setNoStatsAggregator(true);
+      statDesc.setClearAggregatorStats(true);
+      statDesc.setStatsReliable(conf.getBoolVar(HiveConf.ConfVars.HIVE_STATS_RELIABLE));
+      statTask = TaskFactory.get(statDesc, conf);
+    }
+
+    // HIVE-3334 has been filed for load file with index auto update
     if (HiveConf.getBoolVar(conf, HiveConf.ConfVars.HIVEINDEXAUTOUPDATE)) {
       IndexUpdater indexUpdater = new IndexUpdater(loadTableWork, getInputs(), conf);
       try {
         List<Task<? extends Serializable>> indexUpdateTasks = indexUpdater.generateUpdateTasks();
+
         for (Task<? extends Serializable> updateTask : indexUpdateTasks) {
-          //LOAD DATA will either have a copy & move or just a move, we always want the update to be dependent on the move
-          if (rTask.getChildren() == null || rTask.getChildren().size() == 0) {
-            rTask.addDependentTask(updateTask);
-          } else {
-            ((Task<? extends Serializable>)rTask.getChildren().get(0)).addDependentTask(updateTask);
+          //LOAD DATA will either have a copy & move or just a move,
+          // we always want the update to be dependent on the move
+          childTask.addDependentTask(updateTask);
+          if (statTask != null) {
+            updateTask.addDependentTask(statTask);
           }
         }
       } catch (HiveException e) {
         console.printInfo("WARNING: could not auto-update stale indexes, indexes are not out of sync");
       }
     }
+    else if (statTask != null) {
+      childTask.addDependentTask(statTask);
+    }
   }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java
index fc48a0e6ae..a07275fa15 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java
@@ -30,11 +30,18 @@
 public class StatsWork implements Serializable {
   private static final long serialVersionUID = 1L;
 
-  private tableSpec tableSpecs;        // source table spec -- for TableScanOperator
-  private LoadTableDesc loadTableDesc; // same as MoveWork.loadTableDesc -- for FileSinkOperator
-  private LoadFileDesc loadFileDesc;   // same as MoveWork.loadFileDesc -- for FileSinkOperator
-  private String aggKey;               // aggregation key prefix
-  private boolean statsReliable;     // are stats completely reliable
+  private tableSpec tableSpecs;         // source table spec -- for TableScanOperator
+  private LoadTableDesc loadTableDesc;  // same as MoveWork.loadTableDesc -- for FileSinkOperator
+  private LoadFileDesc loadFileDesc;    // same as MoveWork.loadFileDesc -- for FileSinkOperator
+  private String aggKey;                // aggregation key prefix
+  private boolean statsReliable;        // are stats completely reliable
+
+  // If stats aggregator is not present, clear the current aggregator stats.
+  // For eg. if a merge is being performed, stats already collected by aggregator (numrows etc.)
+  // are still valid. However, if a load file is being performed, the old stats collected by
+  // aggregator are not valid. It might be a good idea to clear them instead of leaving wrong
+  // and old stats.
+  private boolean clearAggregatorStats = false;
 
   private boolean noStatsAggregator = false;
 
@@ -93,4 +100,12 @@ public boolean isStatsReliable() {
   public void setStatsReliable(boolean statsReliable) {
     this.statsReliable = statsReliable;
   }
+
+  public boolean isClearAggregatorStats() {
+    return clearAggregatorStats;
+  }
+
+  public void setClearAggregatorStats(boolean clearAggregatorStats) {
+    this.clearAggregatorStats = clearAggregatorStats;
+  }
 }
diff --git a/ql/src/test/queries/clientpositive/stats1.q b/ql/src/test/queries/clientpositive/stats1.q
index 2d93c44ccd..0b783de153 100644
--- a/ql/src/test/queries/clientpositive/stats1.q
+++ b/ql/src/test/queries/clientpositive/stats1.q
@@ -21,4 +21,10 @@ FROM (SELECT 'tst1' AS key, cast(count(1) AS string) AS value FROM src s1
 
 SELECT * FROM tmptable x SORT BY x.key, x.value;
 
-DESCRIBE EXTENDED tmptable;
+DESCRIBE FORMATTED tmptable;
+
+-- Load a file into a existing table
+-- Some stats (numFiles, totalSize) should be updated correctly
+-- Some other stats (numRows, rawDataSize) should be cleared
+load data local inpath '../data/files/srcbucket20.txt' INTO TABLE tmptable;
+DESCRIBE FORMATTED tmptable;
\ No newline at end of file
diff --git a/ql/src/test/queries/clientpositive/stats11.q b/ql/src/test/queries/clientpositive/stats11.q
index 6bccbf3791..6618c913ea 100644
--- a/ql/src/test/queries/clientpositive/stats11.q
+++ b/ql/src/test/queries/clientpositive/stats11.q
@@ -6,10 +6,17 @@ load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapj
 load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin;
 
 CREATE TABLE srcbucket_mapjoin_part (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE;
+explain
 load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08');
+load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08');
+
+desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08');
 load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08');
+desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08');
 load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08');
+desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08');
 load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08');
+desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08');
 
 CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE;
 load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08');
diff --git a/ql/src/test/queries/clientpositive/stats13.q b/ql/src/test/queries/clientpositive/stats13.q
index cbc27473f8..beb7bfa42e 100644
--- a/ql/src/test/queries/clientpositive/stats13.q
+++ b/ql/src/test/queries/clientpositive/stats13.q
@@ -11,12 +11,12 @@ analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistic
 
 analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistics;
 
-desc extended analyze_srcpart;
-desc extended analyze_srcpart partition (ds='2008-04-08', hr=11);
-desc extended analyze_srcpart partition (ds='2008-04-08', hr=12);
-desc extended analyze_srcpart partition (ds='2008-04-09', hr=11);
-desc extended analyze_srcpart partition (ds='2008-04-09', hr=12);
+desc formatted analyze_srcpart;
+desc formatted analyze_srcpart partition (ds='2008-04-08', hr=11);
+desc formatted analyze_srcpart partition (ds='2008-04-08', hr=12);
+desc formatted analyze_srcpart partition (ds='2008-04-09', hr=11);
+desc formatted analyze_srcpart partition (ds='2008-04-09', hr=12);
 
 create table analyze_srcpart2 like analyze_srcpart;
 
-desc extended analyze_srcpart2;
+desc formatted analyze_srcpart2;
diff --git a/ql/src/test/queries/clientpositive/stats15.q b/ql/src/test/queries/clientpositive/stats15.q
index 6cb891592c..9a557c6708 100644
--- a/ql/src/test/queries/clientpositive/stats15.q
+++ b/ql/src/test/queries/clientpositive/stats15.q
@@ -24,4 +24,4 @@ analyze table stats_part partition(ds, hr) compute statistics;
 desc formatted stats_part;
 
 drop table stats_src;
-drop table stats_part;
\ No newline at end of file
+drop table stats_part;
diff --git a/ql/src/test/queries/clientpositive/stats18.q b/ql/src/test/queries/clientpositive/stats18.q
new file mode 100644
index 0000000000..425de64c26
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/stats18.q
@@ -0,0 +1,21 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=true;
+set hive.merge.mapfiles=false;
+set hive.merge.mapredfiles=false;
+set hive.map.aggr=true;
+
+create table stats_part like srcpart;
+
+insert overwrite table stats_part partition (ds='2010-04-08', hr = '13') select key, value from src;
+
+-- Load a file into a existing partition
+-- Some stats (numFiles, totalSize) should be updated correctly
+-- Some other stats (numRows, rawDataSize) should be cleared
+desc formatted stats_part partition (ds='2010-04-08', hr='13');
+
+load data local inpath '../data/files/srcbucket20.txt' INTO TABLE stats_part partition (ds='2010-04-08', hr='13');
+
+desc formatted stats_part partition (ds='2010-04-08', hr='13');
+
+drop table stats_src;
+drop table stats_part;
diff --git a/ql/src/test/queries/clientpositive/stats2.q b/ql/src/test/queries/clientpositive/stats2.q
index 44933db26d..d6bb258307 100644
--- a/ql/src/test/queries/clientpositive/stats2.q
+++ b/ql/src/test/queries/clientpositive/stats2.q
@@ -12,10 +12,10 @@ insert overwrite table analyze_t1 partition (ds, hr) select * from srcpart where
 
 insert overwrite table analyze_t1 partition (ds, hr) select * from srcpart where ds is not null;
 
-desc extended analyze_t1;
+desc formatted analyze_t1;
 
 explain analyze table analyze_t1 partition (ds, hr) compute statistics;
 
 analyze table analyze_t1 partition (ds, hr) compute statistics;
 
-describe extended analyze_t1;
+describe formatted analyze_t1;
diff --git a/ql/src/test/queries/clientpositive/stats3.q b/ql/src/test/queries/clientpositive/stats3.q
index 1a105349d8..5962348d9c 100644
--- a/ql/src/test/queries/clientpositive/stats3.q
+++ b/ql/src/test/queries/clientpositive/stats3.q
@@ -4,8 +4,13 @@ drop table hive_test_src;
 drop table hive_test_dst;
 
 create table hive_test_src ( col1 string ) stored as textfile ;
+explain extended
 load data local inpath '../data/files/test.dat' overwrite into table hive_test_src ;
 
+load data local inpath '../data/files/test.dat' overwrite into table hive_test_src ;
+
+desc formatted hive_test_src;
+
 create table hive_test_dst ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as sequencefile;
 insert overwrite table hive_test_dst partition ( pcol1='test_part', pCol2='test_Part') select col1 from hive_test_src ;
 select * from hive_test_dst where pcol1='test_part' and pcol2='test_Part';
@@ -21,7 +26,7 @@ select * from hive_test_dst where pcol1='test_part';
 select * from hive_test_dst where pcol1='test_part' and pcol2='test_part';
 select * from hive_test_dst where pcol1='test_Part';
 
-describe extended hive_test_dst;
+describe formatted hive_test_dst;
 
 drop table hive_test_src;
 drop table hive_test_dst;
diff --git a/ql/src/test/queries/clientpositive/stats4.q b/ql/src/test/queries/clientpositive/stats4.q
index 7affbdc247..62580042d4 100644
--- a/ql/src/test/queries/clientpositive/stats4.q
+++ b/ql/src/test/queries/clientpositive/stats4.q
@@ -28,13 +28,13 @@ show partitions nzhang_part2;
 select * from nzhang_part1 where ds is not null and hr is not null;
 select * from nzhang_part2 where ds is not null and hr is not null;
 
-describe extended nzhang_part1 partition(ds='2008-04-08',hr=11);
-describe extended nzhang_part1 partition(ds='2008-04-08',hr=12);
-describe extended nzhang_part2 partition(ds='2008-12-31',hr=11);
-describe extended nzhang_part2 partition(ds='2008-12-31',hr=12);
+describe formatted nzhang_part1 partition(ds='2008-04-08',hr=11);
+describe formatted nzhang_part1 partition(ds='2008-04-08',hr=12);
+describe formatted nzhang_part2 partition(ds='2008-12-31',hr=11);
+describe formatted nzhang_part2 partition(ds='2008-12-31',hr=12);
 
-describe extended nzhang_part1;
-describe extended nzhang_part2;
+describe formatted nzhang_part1;
+describe formatted nzhang_part2;
 
 drop table nzhang_part1;
 drop table nzhang_part2;
diff --git a/ql/src/test/queries/clientpositive/stats5.q b/ql/src/test/queries/clientpositive/stats5.q
index 40ede5d222..6b5d1384e0 100644
--- a/ql/src/test/queries/clientpositive/stats5.q
+++ b/ql/src/test/queries/clientpositive/stats5.q
@@ -7,4 +7,4 @@ explain analyze table analyze_src compute statistics;
 
 analyze table analyze_src compute statistics;
 
-describe extended analyze_src;
+describe formatted analyze_src;
diff --git a/ql/src/test/queries/clientpositive/stats6.q b/ql/src/test/queries/clientpositive/stats6.q
index 4f82d48310..bef6e8809e 100644
--- a/ql/src/test/queries/clientpositive/stats6.q
+++ b/ql/src/test/queries/clientpositive/stats6.q
@@ -9,9 +9,9 @@ insert overwrite table analyze_srcpart partition (ds, hr) select * from srcpart
 analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistics;
 analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=12) compute statistics;
 
-describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11);
-describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12);
-describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11);
-describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12);
+describe formatted analyze_srcpart PARTITION(ds='2008-04-08',hr=11);
+describe formatted analyze_srcpart PARTITION(ds='2008-04-08',hr=12);
+describe formatted analyze_srcpart PARTITION(ds='2008-04-09',hr=11);
+describe formatted analyze_srcpart PARTITION(ds='2008-04-09',hr=12);
 
-describe extended analyze_srcpart;
+describe formatted analyze_srcpart;
diff --git a/ql/src/test/queries/clientpositive/stats9.q b/ql/src/test/queries/clientpositive/stats9.q
index 10ed6162a0..48b20443a9 100644
--- a/ql/src/test/queries/clientpositive/stats9.q
+++ b/ql/src/test/queries/clientpositive/stats9.q
@@ -6,4 +6,4 @@ insert overwrite table analyze_srcbucket select * from srcbucket;
 
 explain analyze table analyze_srcbucket compute statistics;
 analyze table analyze_srcbucket compute statistics;
-describe extended analyze_srcbucket;
+describe formatted analyze_srcbucket;
diff --git a/ql/src/test/results/clientpositive/binary_output_format.q.out b/ql/src/test/results/clientpositive/binary_output_format.q.out
index 06e016acfc..2f3bde0c8f 100644
--- a/ql/src/test/results/clientpositive/binary_output_format.q.out
+++ b/ql/src/test/results/clientpositive/binary_output_format.q.out
@@ -128,9 +128,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -142,9 +147,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/bucket1.q.out b/ql/src/test/results/clientpositive/bucket1.q.out
index 4c8ffbe9ee..02ce398288 100644
--- a/ql/src/test/results/clientpositive/bucket1.q.out
+++ b/ql/src/test/results/clientpositive/bucket1.q.out
@@ -60,9 +60,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -74,9 +79,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/bucket2.q.out b/ql/src/test/results/clientpositive/bucket2.q.out
index 209ed36608..0c2494631f 100644
--- a/ql/src/test/results/clientpositive/bucket2.q.out
+++ b/ql/src/test/results/clientpositive/bucket2.q.out
@@ -60,9 +60,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -74,9 +79,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/bucket3.q.out b/ql/src/test/results/clientpositive/bucket3.q.out
index 7106be6a21..add132c293 100644
--- a/ql/src/test/results/clientpositive/bucket3.q.out
+++ b/ql/src/test/results/clientpositive/bucket3.q.out
@@ -60,9 +60,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -74,9 +79,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/bucket4.q.out b/ql/src/test/results/clientpositive/bucket4.q.out
index 94959ecffa..108732fb9e 100644
--- a/ql/src/test/results/clientpositive/bucket4.q.out
+++ b/ql/src/test/results/clientpositive/bucket4.q.out
@@ -63,9 +63,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -77,9 +82,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/bucket_map_join_1.q.out b/ql/src/test/results/clientpositive/bucket_map_join_1.q.out
index 9e46654262..be6daee494 100644
--- a/ql/src/test/results/clientpositive/bucket_map_join_1.q.out
+++ b/ql/src/test/results/clientpositive/bucket_map_join_1.q.out
@@ -136,9 +136,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.table1
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct table1 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 20
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -152,9 +157,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.table1
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct table1 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 20
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.table1
@@ -232,7 +242,6 @@ STAGE PLANS:
     Fetch Operator
       limit: -1
 
-
 PREHOOK: query: select /*+ mapjoin(b) */ count(*) from table1 a join table2 b on a.key=b.key and a.value=b.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@table1
diff --git a/ql/src/test/results/clientpositive/bucket_map_join_2.q.out b/ql/src/test/results/clientpositive/bucket_map_join_2.q.out
index 5875f2a909..5b5dbbdb64 100644
--- a/ql/src/test/results/clientpositive/bucket_map_join_2.q.out
+++ b/ql/src/test/results/clientpositive/bucket_map_join_2.q.out
@@ -136,9 +136,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.table1
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct table1 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 20
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -152,9 +157,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.table1
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct table1 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 20
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.table1
@@ -232,7 +242,6 @@ STAGE PLANS:
     Fetch Operator
       limit: -1
 
-
 PREHOOK: query: select /*+ mapjoin(b) */ count(*) from table1 a join table2 b on a.key=b.key and a.value=b.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@table1
diff --git a/ql/src/test/results/clientpositive/bucketcontext_1.q.out b/ql/src/test/results/clientpositive/bucketcontext_1.q.out
index d7b8c5af9c..c644602357 100644
--- a/ql/src/test/results/clientpositive/bucketcontext_1.q.out
+++ b/ql/src/test/results/clientpositive/bucketcontext_1.q.out
@@ -169,10 +169,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 4
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -186,10 +191,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 8
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11624
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
@@ -209,10 +219,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 4
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -226,10 +241,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 8
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11624
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
@@ -386,10 +406,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 4
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -403,10 +428,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 8
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11624
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
@@ -426,10 +456,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 4
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -443,10 +478,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 8
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11624
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
diff --git a/ql/src/test/results/clientpositive/bucketcontext_2.q.out b/ql/src/test/results/clientpositive/bucketcontext_2.q.out
index 36f4fe63d9..a0bdf6b989 100644
--- a/ql/src/test/results/clientpositive/bucketcontext_2.q.out
+++ b/ql/src/test/results/clientpositive/bucketcontext_2.q.out
@@ -157,10 +157,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 2
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -174,10 +179,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 4
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5500
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
@@ -197,10 +207,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 2
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -214,10 +229,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 4
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5500
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
@@ -405,10 +425,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 2
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -422,10 +447,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 4
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5500
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
@@ -445,10 +475,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 2
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -462,10 +497,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 4
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5500
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
diff --git a/ql/src/test/results/clientpositive/bucketcontext_3.q.out b/ql/src/test/results/clientpositive/bucketcontext_3.q.out
index c1fd6963fd..5a89119ae5 100644
--- a/ql/src/test/results/clientpositive/bucketcontext_3.q.out
+++ b/ql/src/test/results/clientpositive/bucketcontext_3.q.out
@@ -157,10 +157,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 4
+              numPartitions 1
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -174,10 +179,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 4
+                numPartitions 1
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
@@ -365,10 +375,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 4
+              numPartitions 1
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -382,10 +397,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 4
+                numPartitions 1
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
diff --git a/ql/src/test/results/clientpositive/bucketcontext_4.q.out b/ql/src/test/results/clientpositive/bucketcontext_4.q.out
index ee6ac1a13d..abf6bc2afd 100644
--- a/ql/src/test/results/clientpositive/bucketcontext_4.q.out
+++ b/ql/src/test/results/clientpositive/bucketcontext_4.q.out
@@ -169,10 +169,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 2
+              numPartitions 1
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -186,10 +191,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 2
+                numPartitions 1
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 2750
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
@@ -377,10 +387,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.bucket_big
+              numFiles 2
+              numPartitions 1
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -394,10 +409,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.bucket_big
+                numFiles 2
+                numPartitions 1
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 2750
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.bucket_big
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin1.q.out b/ql/src/test/results/clientpositive/bucketmapjoin1.q.out
index 449289c30c..ebeb8fd72c 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin1.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin1.q.out
@@ -466,9 +466,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -481,9 +486,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 2750
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin
@@ -953,10 +963,15 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin_part
+              numFiles 4
+              numPartitions 1
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -969,10 +984,15 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin_part
+                numFiles 4
+                numPartitions 1
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin_part
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin2.q.out b/ql/src/test/results/clientpositive/bucketmapjoin2.q.out
index 14995b575d..6ba659d676 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin2.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin2.q.out
@@ -197,10 +197,15 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin_part
+              numFiles 4
+              numPartitions 1
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -213,10 +218,15 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin_part
+                numFiles 4
+                numPartitions 1
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin_part
@@ -684,10 +694,15 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin_part_2
+              numFiles 2
+              numPartitions 1
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 3062
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -700,10 +715,15 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin_part_2
+                numFiles 2
+                numPartitions 1
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 3062
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin_part_2
@@ -1365,10 +1385,15 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin_part
+              numFiles 4
+              numPartitions 1
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1381,10 +1406,15 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin_part
+                numFiles 4
+                numPartitions 1
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin_part
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin3.q.out b/ql/src/test/results/clientpositive/bucketmapjoin3.q.out
index 1d8afb82a5..c0b1ce072b 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin3.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin3.q.out
@@ -214,10 +214,15 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin_part_2
+              numFiles 2
+              numPartitions 1
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 3062
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -230,10 +235,15 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin_part_2
+                numFiles 2
+                numPartitions 1
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 3062
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin_part_2
@@ -701,10 +711,15 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin_part
+              numFiles 4
+              numPartitions 1
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -717,10 +732,15 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin_part
+                numFiles 4
+                numPartitions 1
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin_part
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin4.q.out b/ql/src/test/results/clientpositive/bucketmapjoin4.q.out
index 6be93a75d8..2e66f32498 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin4.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin4.q.out
@@ -212,9 +212,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -227,9 +232,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 2750
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin
@@ -691,9 +701,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -706,9 +721,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 2750
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin5.q.out b/ql/src/test/results/clientpositive/bucketmapjoin5.q.out
index 85604700b2..50bc5f612d 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin5.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin5.q.out
@@ -252,10 +252,15 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin_part
+              numFiles 4
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -268,10 +273,15 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin_part
+                numFiles 8
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11624
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin_part
@@ -290,10 +300,15 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin_part
+              numFiles 4
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -306,10 +321,15 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin_part
+                numFiles 8
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11624
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin_part
@@ -781,10 +801,15 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin_part_2
+              numFiles 2
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 3062
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -797,10 +822,15 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin_part_2
+                numFiles 4
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 6124
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin_part_2
@@ -819,10 +849,15 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin_part_2
+              numFiles 2
+              numPartitions 2
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 3062
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -835,10 +870,15 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin_part_2
+                numFiles 4
+                numPartitions 2
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 6124
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin_part_2
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out b/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out
index 9b879d3845..4d9f453d2f 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out
@@ -173,9 +173,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -188,9 +193,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 2750
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out b/ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out
index 005a7d109f..32a51395f4 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out
@@ -185,9 +185,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -200,9 +205,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 2750
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin
diff --git a/ql/src/test/results/clientpositive/ctas.q.out b/ql/src/test/results/clientpositive/ctas.q.out
index 1555d71339..def351fa83 100644
--- a/ql/src/test/results/clientpositive/ctas.q.out
+++ b/ql/src/test/results/clientpositive/ctas.q.out
@@ -774,9 +774,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -788,9 +793,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/describe_table.q.out b/ql/src/test/results/clientpositive/describe_table.q.out
index 9920105faa..1143f596af 100644
--- a/ql/src/test/results/clientpositive/describe_table.q.out
+++ b/ql/src/test/results/clientpositive/describe_table.q.out
@@ -67,6 +67,11 @@ Retention:          	0
 #### A masked pattern was here ####
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
+	numFiles            	4                   
+	numPartitions       	4                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	23248               
 #### A masked pattern was here ####
 	 	 
 # Storage Information	 	 
@@ -109,6 +114,10 @@ Table:              	srcpart
 Protect Mode:       	None                	 
 #### A masked pattern was here ####
 Partition Parameters:	 	 
+	numFiles            	1                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	5812                
 #### A masked pattern was here ####
 	 	 
 # Storage Information	 	 
diff --git a/ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out b/ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out
index 209ed36608..0c2494631f 100644
--- a/ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out
+++ b/ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out
@@ -60,9 +60,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -74,9 +79,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/groupby_map_ppr.q.out b/ql/src/test/results/clientpositive/groupby_map_ppr.q.out
index d8b9a81ff8..7f2747c5b0 100644
--- a/ql/src/test/results/clientpositive/groupby_map_ppr.q.out
+++ b/ql/src/test/results/clientpositive/groupby_map_ppr.q.out
@@ -86,10 +86,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -101,10 +106,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -123,10 +133,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -138,10 +153,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/groupby_map_ppr_multi_distinct.q.out b/ql/src/test/results/clientpositive/groupby_map_ppr_multi_distinct.q.out
index 6f0d5a64c6..bc7055a89c 100644
--- a/ql/src/test/results/clientpositive/groupby_map_ppr_multi_distinct.q.out
+++ b/ql/src/test/results/clientpositive/groupby_map_ppr_multi_distinct.q.out
@@ -96,10 +96,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -111,10 +116,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -133,10 +143,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -148,10 +163,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/groupby_ppr.q.out b/ql/src/test/results/clientpositive/groupby_ppr.q.out
index 65a9beda49..8a1cbb1091 100644
--- a/ql/src/test/results/clientpositive/groupby_ppr.q.out
+++ b/ql/src/test/results/clientpositive/groupby_ppr.q.out
@@ -69,10 +69,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -84,10 +89,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -106,10 +116,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -121,10 +136,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/groupby_ppr_multi_distinct.q.out b/ql/src/test/results/clientpositive/groupby_ppr_multi_distinct.q.out
index 6d835a3651..fb0b9844eb 100644
--- a/ql/src/test/results/clientpositive/groupby_ppr_multi_distinct.q.out
+++ b/ql/src/test/results/clientpositive/groupby_ppr_multi_distinct.q.out
@@ -71,10 +71,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -86,10 +91,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -108,10 +118,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -123,10 +138,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/input23.q.out b/ql/src/test/results/clientpositive/input23.q.out
index 959d94c354..501f393b6d 100644
--- a/ql/src/test/results/clientpositive/input23.q.out
+++ b/ql/src/test/results/clientpositive/input23.q.out
@@ -70,10 +70,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -85,10 +90,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/input4.q.out b/ql/src/test/results/clientpositive/input4.q.out
index 9520b7ce47..50642dd006 100644
--- a/ql/src/test/results/clientpositive/input4.q.out
+++ b/ql/src/test/results/clientpositive/input4.q.out
@@ -15,6 +15,7 @@ ABSTRACT SYNTAX TREE:
 STAGE DEPENDENCIES:
   Stage-0 is a root stage
   Stage-1 depends on stages: Stage-0
+  Stage-2 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-0
@@ -31,6 +32,9 @@ STAGE PLANS:
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.input4
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+
 
 PREHOOK: query: LOAD DATA LOCAL INPATH '../data/files/kv1.txt' INTO TABLE INPUT4
 PREHOOK: type: LOAD
diff --git a/ql/src/test/results/clientpositive/input42.q.out b/ql/src/test/results/clientpositive/input42.q.out
index 922fcec894..bb4bbc8263 100644
--- a/ql/src/test/results/clientpositive/input42.q.out
+++ b/ql/src/test/results/clientpositive/input42.q.out
@@ -65,10 +65,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -80,10 +85,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -102,10 +112,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -117,10 +132,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -1232,10 +1252,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1247,10 +1272,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -1269,10 +1299,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1284,10 +1319,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -1777,10 +1817,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1792,10 +1837,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -1814,10 +1864,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1829,10 +1884,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/input_part1.q.out b/ql/src/test/results/clientpositive/input_part1.q.out
index d8d96a6dc5..5cd11b99ba 100644
--- a/ql/src/test/results/clientpositive/input_part1.q.out
+++ b/ql/src/test/results/clientpositive/input_part1.q.out
@@ -101,10 +101,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -116,10 +121,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/input_part2.q.out b/ql/src/test/results/clientpositive/input_part2.q.out
index 8fb9e6a92e..2503c4fafa 100644
--- a/ql/src/test/results/clientpositive/input_part2.q.out
+++ b/ql/src/test/results/clientpositive/input_part2.q.out
@@ -166,10 +166,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -181,10 +186,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -203,10 +213,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -218,10 +233,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/input_part7.q.out b/ql/src/test/results/clientpositive/input_part7.q.out
index 2e847fdb56..e24439adb9 100644
--- a/ql/src/test/results/clientpositive/input_part7.q.out
+++ b/ql/src/test/results/clientpositive/input_part7.q.out
@@ -149,10 +149,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -164,10 +169,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -186,10 +196,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -201,10 +216,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/input_part9.q.out b/ql/src/test/results/clientpositive/input_part9.q.out
index b042f48073..447ff4d097 100644
--- a/ql/src/test/results/clientpositive/input_part9.q.out
+++ b/ql/src/test/results/clientpositive/input_part9.q.out
@@ -70,10 +70,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -85,10 +90,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -107,10 +117,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -122,10 +137,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/join17.q.out b/ql/src/test/results/clientpositive/join17.q.out
index 45aad0d9e2..28319be2e7 100644
--- a/ql/src/test/results/clientpositive/join17.q.out
+++ b/ql/src/test/results/clientpositive/join17.q.out
@@ -74,9 +74,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -88,9 +93,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/join26.q.out b/ql/src/test/results/clientpositive/join26.q.out
index 413e112762..1dedefcccf 100644
--- a/ql/src/test/results/clientpositive/join26.q.out
+++ b/ql/src/test/results/clientpositive/join26.q.out
@@ -155,10 +155,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -170,10 +175,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/join32.q.out b/ql/src/test/results/clientpositive/join32.q.out
index af4de4580d..f696b0134d 100644
--- a/ql/src/test/results/clientpositive/join32.q.out
+++ b/ql/src/test/results/clientpositive/join32.q.out
@@ -104,9 +104,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -118,9 +123,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/join33.q.out b/ql/src/test/results/clientpositive/join33.q.out
index aaec3ccab2..d1b660eb82 100644
--- a/ql/src/test/results/clientpositive/join33.q.out
+++ b/ql/src/test/results/clientpositive/join33.q.out
@@ -98,9 +98,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -112,9 +117,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -197,10 +207,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -212,10 +227,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/join34.q.out b/ql/src/test/results/clientpositive/join34.q.out
index 34da1ce972..7e709e5839 100644
--- a/ql/src/test/results/clientpositive/join34.q.out
+++ b/ql/src/test/results/clientpositive/join34.q.out
@@ -221,9 +221,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -235,9 +240,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/join35.q.out b/ql/src/test/results/clientpositive/join35.q.out
index c93532384c..8597ea470c 100644
--- a/ql/src/test/results/clientpositive/join35.q.out
+++ b/ql/src/test/results/clientpositive/join35.q.out
@@ -93,9 +93,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -107,9 +112,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -566,9 +576,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -580,9 +595,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/join9.q.out b/ql/src/test/results/clientpositive/join9.q.out
index 1291fa0744..7739e61292 100644
--- a/ql/src/test/results/clientpositive/join9.q.out
+++ b/ql/src/test/results/clientpositive/join9.q.out
@@ -74,9 +74,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -88,9 +93,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -109,10 +119,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -124,10 +139,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/join_map_ppr.q.out b/ql/src/test/results/clientpositive/join_map_ppr.q.out
index 2cbeeec67b..39fbb9491e 100644
--- a/ql/src/test/results/clientpositive/join_map_ppr.q.out
+++ b/ql/src/test/results/clientpositive/join_map_ppr.q.out
@@ -161,10 +161,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -176,10 +181,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -710,10 +720,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -725,10 +740,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/load_dyn_part8.q.out b/ql/src/test/results/clientpositive/load_dyn_part8.q.out
index 732448bcf6..e35d4001a1 100644
--- a/ql/src/test/results/clientpositive/load_dyn_part8.q.out
+++ b/ql/src/test/results/clientpositive/load_dyn_part8.q.out
@@ -148,10 +148,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -163,10 +168,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -185,10 +195,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -200,10 +215,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -222,10 +242,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -237,10 +262,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -259,10 +289,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -274,10 +309,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/louter_join_ppr.q.out b/ql/src/test/results/clientpositive/louter_join_ppr.q.out
index 9c0a02b791..1b7a651428 100644
--- a/ql/src/test/results/clientpositive/louter_join_ppr.q.out
+++ b/ql/src/test/results/clientpositive/louter_join_ppr.q.out
@@ -88,9 +88,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -102,9 +107,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -123,10 +133,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -138,10 +153,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -160,10 +180,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -175,10 +200,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -359,9 +389,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -373,9 +408,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -394,10 +434,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -409,10 +454,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -431,10 +481,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -446,10 +501,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -468,10 +528,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -483,10 +548,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -505,10 +575,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -520,10 +595,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -711,9 +791,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -725,9 +810,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -746,10 +836,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -761,10 +856,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -783,10 +883,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -798,10 +903,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -820,10 +930,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -835,10 +950,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -857,10 +977,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -872,10 +997,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -1060,9 +1190,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1074,9 +1209,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -1095,10 +1235,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1110,10 +1255,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -1132,10 +1282,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1147,10 +1302,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/outer_join_ppr.q.out b/ql/src/test/results/clientpositive/outer_join_ppr.q.out
index 954e72ff73..a8897d4013 100644
--- a/ql/src/test/results/clientpositive/outer_join_ppr.q.out
+++ b/ql/src/test/results/clientpositive/outer_join_ppr.q.out
@@ -80,9 +80,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -94,9 +99,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -115,10 +125,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -130,10 +145,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -152,10 +172,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -167,10 +192,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -189,10 +219,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -204,10 +239,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -226,10 +266,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -241,10 +286,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -422,9 +472,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -436,9 +491,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -457,10 +517,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -472,10 +537,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -494,10 +564,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -509,10 +584,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -531,10 +611,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -546,10 +631,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -568,10 +658,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -583,10 +678,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/pcr.q.out b/ql/src/test/results/clientpositive/pcr.q.out
index 6dcd3baeae..97c940e28b 100644
--- a/ql/src/test/results/clientpositive/pcr.q.out
+++ b/ql/src/test/results/clientpositive/pcr.q.out
@@ -4833,10 +4833,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -4848,10 +4853,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -4992,10 +5002,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -5007,10 +5022,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -5029,10 +5049,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -5044,10 +5069,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -5193,10 +5223,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -5208,10 +5243,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -5230,10 +5270,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -5245,10 +5290,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/ppr_allchildsarenull.q.out b/ql/src/test/results/clientpositive/ppr_allchildsarenull.q.out
index a9a3fd42ba..9aa501d20e 100644
--- a/ql/src/test/results/clientpositive/ppr_allchildsarenull.q.out
+++ b/ql/src/test/results/clientpositive/ppr_allchildsarenull.q.out
@@ -78,10 +78,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -93,10 +98,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -115,10 +125,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -130,10 +145,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -246,10 +266,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -261,10 +286,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -283,10 +313,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -298,10 +333,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -320,10 +360,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -335,10 +380,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -357,10 +407,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -372,10 +427,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out b/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out
index 0330795dff..babc45ae5b 100644
--- a/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out
+++ b/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out
@@ -63,9 +63,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -77,9 +82,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out b/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out
index b2fb063988..7ed44f3f4b 100644
--- a/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out
+++ b/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out
@@ -94,10 +94,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -109,10 +114,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -131,10 +141,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -146,10 +161,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out b/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
index b52b281b16..d36833c146 100644
--- a/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
+++ b/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
@@ -72,10 +72,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -87,10 +92,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -186,10 +196,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -201,10 +216,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/reduce_deduplicate.q.out b/ql/src/test/results/clientpositive/reduce_deduplicate.q.out
index 068dc67592..ef9c97d6bc 100644
--- a/ql/src/test/results/clientpositive/reduce_deduplicate.q.out
+++ b/ql/src/test/results/clientpositive/reduce_deduplicate.q.out
@@ -63,9 +63,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -77,9 +82,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/regexp_extract.q.out b/ql/src/test/results/clientpositive/regexp_extract.q.out
index 6ce2e9080a..c373e417f6 100644
--- a/ql/src/test/results/clientpositive/regexp_extract.q.out
+++ b/ql/src/test/results/clientpositive/regexp_extract.q.out
@@ -87,9 +87,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -101,9 +106,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -333,9 +343,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -347,9 +362,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/router_join_ppr.q.out b/ql/src/test/results/clientpositive/router_join_ppr.q.out
index c6e633593a..c65d1f83ff 100644
--- a/ql/src/test/results/clientpositive/router_join_ppr.q.out
+++ b/ql/src/test/results/clientpositive/router_join_ppr.q.out
@@ -90,9 +90,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -104,9 +109,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -125,10 +135,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -140,10 +155,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -162,10 +182,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -177,10 +202,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -199,10 +229,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -214,10 +249,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -236,10 +276,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -251,10 +296,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -440,9 +490,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -454,9 +509,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -475,10 +535,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -490,10 +555,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -512,10 +582,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -527,10 +602,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -711,9 +791,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -725,9 +810,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -746,10 +836,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -761,10 +856,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -783,10 +883,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -798,10 +903,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -982,9 +1092,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -996,9 +1111,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -1017,10 +1137,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1032,10 +1157,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -1054,10 +1184,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1069,10 +1204,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -1091,10 +1231,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1106,10 +1251,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -1128,10 +1278,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1143,10 +1298,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/sample1.q.out b/ql/src/test/results/clientpositive/sample1.q.out
index a932e42816..9f41961f09 100644
--- a/ql/src/test/results/clientpositive/sample1.q.out
+++ b/ql/src/test/results/clientpositive/sample1.q.out
@@ -105,10 +105,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -120,10 +125,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/sample2.q.out b/ql/src/test/results/clientpositive/sample2.q.out
index f7e2ac0145..91bdc8702b 100644
--- a/ql/src/test/results/clientpositive/sample2.q.out
+++ b/ql/src/test/results/clientpositive/sample2.q.out
@@ -88,9 +88,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 11603
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -103,9 +108,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11603
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket
diff --git a/ql/src/test/results/clientpositive/sample4.q.out b/ql/src/test/results/clientpositive/sample4.q.out
index 1e9a431b93..ef0aa8c306 100644
--- a/ql/src/test/results/clientpositive/sample4.q.out
+++ b/ql/src/test/results/clientpositive/sample4.q.out
@@ -88,9 +88,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 11603
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -103,9 +108,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11603
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket
diff --git a/ql/src/test/results/clientpositive/sample5.q.out b/ql/src/test/results/clientpositive/sample5.q.out
index 00e2fb8d89..8572282ea4 100644
--- a/ql/src/test/results/clientpositive/sample5.q.out
+++ b/ql/src/test/results/clientpositive/sample5.q.out
@@ -86,9 +86,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 11603
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -101,9 +106,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11603
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket
diff --git a/ql/src/test/results/clientpositive/sample6.q.out b/ql/src/test/results/clientpositive/sample6.q.out
index 0021585dd2..a5b88a2e64 100644
--- a/ql/src/test/results/clientpositive/sample6.q.out
+++ b/ql/src/test/results/clientpositive/sample6.q.out
@@ -86,9 +86,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 11603
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -101,9 +106,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11603
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket
@@ -614,9 +624,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 11603
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -629,9 +644,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11603
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket
@@ -976,9 +996,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 11603
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -991,9 +1016,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11603
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket
@@ -1592,9 +1622,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 11603
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1607,9 +1642,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11603
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket
@@ -2051,9 +2091,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 11603
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -2066,9 +2111,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11603
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket
@@ -2496,9 +2546,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket2
+              numFiles 4
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -2511,9 +2566,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket2
+                numFiles 4
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket2
@@ -2530,9 +2590,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket2
+              numFiles 4
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -2545,9 +2610,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket2
+                numFiles 4
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket2
@@ -2775,9 +2845,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket2
+              numFiles 4
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -2790,9 +2865,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket2
+                numFiles 4
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket2
diff --git a/ql/src/test/results/clientpositive/sample7.q.out b/ql/src/test/results/clientpositive/sample7.q.out
index a77ff0e1f6..92b2d8e3e8 100644
--- a/ql/src/test/results/clientpositive/sample7.q.out
+++ b/ql/src/test/results/clientpositive/sample7.q.out
@@ -93,9 +93,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 11603
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -108,9 +113,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11603
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket
diff --git a/ql/src/test/results/clientpositive/sample8.q.out b/ql/src/test/results/clientpositive/sample8.q.out
index 108fb52684..9f214c187d 100644
--- a/ql/src/test/results/clientpositive/sample8.q.out
+++ b/ql/src/test/results/clientpositive/sample8.q.out
@@ -84,10 +84,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -99,10 +104,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -121,10 +131,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -136,10 +151,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -158,10 +178,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -173,10 +198,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -195,10 +225,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -210,10 +245,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/sample9.q.out b/ql/src/test/results/clientpositive/sample9.q.out
index 8bc83a3263..53dc97da17 100644
--- a/ql/src/test/results/clientpositive/sample9.q.out
+++ b/ql/src/test/results/clientpositive/sample9.q.out
@@ -73,9 +73,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 11603
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -88,9 +93,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 11603
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket
diff --git a/ql/src/test/results/clientpositive/stats0.q.out b/ql/src/test/results/clientpositive/stats0.q.out
index 874ad9210e..e6549de773 100644
--- a/ql/src/test/results/clientpositive/stats0.q.out
+++ b/ql/src/test/results/clientpositive/stats0.q.out
@@ -73,9 +73,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -87,9 +92,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -1391,9 +1401,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -1405,9 +1420,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/stats1.q.out b/ql/src/test/results/clientpositive/stats1.q.out
index 15f94d5319..3e6057c524 100644
--- a/ql/src/test/results/clientpositive/stats1.q.out
+++ b/ql/src/test/results/clientpositive/stats1.q.out
@@ -185,13 +185,89 @@ POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src1)s2.FieldSchema
 66	val_66
 98	val_98
 tst1	500
-PREHOOK: query: DESCRIBE EXTENDED tmptable
+PREHOOK: query: DESCRIBE FORMATTED tmptable
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: DESCRIBE EXTENDED tmptable
+POSTHOOK: query: DESCRIBE FORMATTED tmptable
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: tmptable.key EXPRESSION [(src1)s2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src1)s2.FieldSchema(name:value, type:string, comment:default), ]
-key	string	
-value	string	
+# col_name            	data_type           	comment             
 	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numFiles            	2                   
+	numPartitions       	0                   
+	numRows             	26                  
+	rawDataSize         	199                 
+	totalSize           	225                 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: -- Load a file into a existing table
+-- Some stats (numFiles, totalSize) should be updated correctly
+-- Some other stats (numRows, rawDataSize) should be cleared
+load data local inpath '../data/files/srcbucket20.txt' INTO TABLE tmptable
+PREHOOK: type: LOAD
+PREHOOK: Output: default@tmptable
+POSTHOOK: query: -- Load a file into a existing table
+-- Some stats (numFiles, totalSize) should be updated correctly
+-- Some other stats (numRows, rawDataSize) should be cleared
+load data local inpath '../data/files/srcbucket20.txt' INTO TABLE tmptable
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@tmptable
+POSTHOOK: Lineage: tmptable.key EXPRESSION [(src1)s2.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src1)s2.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: DESCRIBE FORMATTED tmptable
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: DESCRIBE FORMATTED tmptable
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: tmptable.key EXPRESSION [(src1)s2.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src1)s2.FieldSchema(name:value, type:string, comment:default), ]
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
 #### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numFiles            	3                   
+	numPartitions       	0                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	1583                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
diff --git a/ql/src/test/results/clientpositive/stats11.q.out b/ql/src/test/results/clientpositive/stats11.q.out
index 077232a9c7..57abed5736 100644
--- a/ql/src/test/results/clientpositive/stats11.q.out
+++ b/ql/src/test/results/clientpositive/stats11.q.out
@@ -20,6 +20,41 @@ PREHOOK: type: CREATETABLE
 POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_part (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@srcbucket_mapjoin_part
+PREHOOK: query: explain
+load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: explain
+load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+ABSTRACT SYNTAX TREE:
+  (TOK_LOAD '../data/files/srcbucket20.txt' (TOK_TAB (TOK_TABNAME srcbucket_mapjoin_part) (TOK_PARTSPEC (TOK_PARTVAL ds '2008-04-08'))) local)
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+  Stage-2 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-0
+    Copy
+#### A masked pattern was here ####
+
+  Stage: Stage-1
+    Move Operator
+      tables:
+          partition:
+            ds 2008-04-08
+          replace: false
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.srcbucket_mapjoin_part
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+
+
 PREHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
 PREHOOK: type: LOAD
 PREHOOK: Output: default@srcbucket_mapjoin_part
@@ -27,24 +62,176 @@ POSTHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TAB
 POSTHOOK: type: LOAD
 POSTHOOK: Output: default@srcbucket_mapjoin_part
 POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: DESCTABLE
+# col_name            	data_type           	comment             
+	 	 
+key                 	int                 	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08]        	 
+Database:           	default             	 
+Table:              	srcbucket_mapjoin_part	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	numFiles            	1                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	1358                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	4                   	 
+Bucket Columns:     	[key]               	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
 PREHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
 PREHOOK: type: LOAD
 PREHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
 POSTHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
 POSTHOOK: type: LOAD
 POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: DESCTABLE
+# col_name            	data_type           	comment             
+	 	 
+key                 	int                 	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08]        	 
+Database:           	default             	 
+Table:              	srcbucket_mapjoin_part	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	numFiles            	2                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	2750                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	4                   	 
+Bucket Columns:     	[key]               	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
 PREHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
 PREHOOK: type: LOAD
 PREHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
 POSTHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
 POSTHOOK: type: LOAD
 POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: DESCTABLE
+# col_name            	data_type           	comment             
+	 	 
+key                 	int                 	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08]        	 
+Database:           	default             	 
+Table:              	srcbucket_mapjoin_part	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	numFiles            	3                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	4200                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	4                   	 
+Bucket Columns:     	[key]               	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
 PREHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
 PREHOOK: type: LOAD
 PREHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
 POSTHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
 POSTHOOK: type: LOAD
 POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc formatted srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: DESCTABLE
+# col_name            	data_type           	comment             
+	 	 
+key                 	int                 	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08]        	 
+Database:           	default             	 
+Table:              	srcbucket_mapjoin_part	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	numFiles            	4                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	5812                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	4                   	 
+Bucket Columns:     	[key]               	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
 PREHOOK: query: CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
 PREHOOK: type: CREATETABLE
 POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
@@ -214,9 +401,14 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
+              numFiles 2
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 2750
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -229,9 +421,14 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
+                numFiles 2
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 2750
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin
@@ -701,10 +898,15 @@ STAGE PLANS:
               columns.types int:string
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin_part
+              numFiles 4
+              numPartitions 1
+              numRows 0
               partition_columns ds
+              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -717,10 +919,15 @@ STAGE PLANS:
                 columns.types int:string
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin_part
+                numFiles 4
+                numPartitions 1
+                numRows 0
                 partition_columns ds
+                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcbucket_mapjoin_part
diff --git a/ql/src/test/results/clientpositive/stats13.q.out b/ql/src/test/results/clientpositive/stats13.q.out
index e668ea0906..012e79abfb 100644
--- a/ql/src/test/results/clientpositive/stats13.q.out
+++ b/ql/src/test/results/clientpositive/stats13.q.out
@@ -123,9 +123,9 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-PREHOOK: query: desc extended analyze_srcpart
+PREHOOK: query: desc formatted analyze_srcpart
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: desc extended analyze_srcpart
+POSTHOOK: query: desc formatted analyze_srcpart
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -135,15 +135,45 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
 	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numFiles            	1                   
+	numPartitions       	1                   
+	numRows             	500                 
+	rawDataSize         	5312                
+	totalSize           	5812                
 #### A masked pattern was here ####
-PREHOOK: query: desc extended analyze_srcpart partition (ds='2008-04-08', hr=11)
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: desc formatted analyze_srcpart partition (ds='2008-04-08', hr=11)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: desc extended analyze_srcpart partition (ds='2008-04-08', hr=11)
+POSTHOOK: query: desc formatted analyze_srcpart partition (ds='2008-04-08', hr=11)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -153,15 +183,44 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
 	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 11]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
 #### A masked pattern was here ####
-PREHOOK: query: desc extended analyze_srcpart partition (ds='2008-04-08', hr=12)
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	numFiles            	1                   
+	numRows             	500                 
+	rawDataSize         	5312                
+	totalSize           	5812                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: desc formatted analyze_srcpart partition (ds='2008-04-08', hr=12)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: desc extended analyze_srcpart partition (ds='2008-04-08', hr=12)
+POSTHOOK: query: desc formatted analyze_srcpart partition (ds='2008-04-08', hr=12)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -171,15 +230,40 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
 	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 12]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
 #### A masked pattern was here ####
-PREHOOK: query: desc extended analyze_srcpart partition (ds='2008-04-09', hr=11)
+Partition Parameters:	 	 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: desc formatted analyze_srcpart partition (ds='2008-04-09', hr=11)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: desc extended analyze_srcpart partition (ds='2008-04-09', hr=11)
+POSTHOOK: query: desc formatted analyze_srcpart partition (ds='2008-04-09', hr=11)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -189,15 +273,40 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
 	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-09, 11]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
 #### A masked pattern was here ####
-PREHOOK: query: desc extended analyze_srcpart partition (ds='2008-04-09', hr=12)
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: desc formatted analyze_srcpart partition (ds='2008-04-09', hr=12)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: desc extended analyze_srcpart partition (ds='2008-04-09', hr=12)
+POSTHOOK: query: desc formatted analyze_srcpart partition (ds='2008-04-09', hr=12)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -207,12 +316,37 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
 	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-09, 12]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
 #### A masked pattern was here ####
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
 PREHOOK: query: create table analyze_srcpart2 like analyze_srcpart
 PREHOOK: type: CREATETABLE
 POSTHOOK: query: create table analyze_srcpart2 like analyze_srcpart
@@ -226,9 +360,9 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-PREHOOK: query: desc extended analyze_srcpart2
+PREHOOK: query: desc formatted analyze_srcpart2
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: desc extended analyze_srcpart2
+POSTHOOK: query: desc formatted analyze_srcpart2
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -238,9 +372,34 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
 	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
 #### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
diff --git a/ql/src/test/results/clientpositive/stats18.q.out b/ql/src/test/results/clientpositive/stats18.q.out
new file mode 100644
index 0000000000..4deff84e99
--- /dev/null
+++ b/ql/src/test/results/clientpositive/stats18.q.out
@@ -0,0 +1,127 @@
+PREHOOK: query: create table stats_part like srcpart
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table stats_part like srcpart
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@stats_part
+PREHOOK: query: insert overwrite table stats_part partition (ds='2010-04-08', hr = '13') select key, value from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@stats_part@ds=2010-04-08/hr=13
+POSTHOOK: query: insert overwrite table stats_part partition (ds='2010-04-08', hr = '13') select key, value from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@stats_part@ds=2010-04-08/hr=13
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: -- Load a file into a existing partition
+-- Some stats (numFiles, totalSize) should be updated correctly
+-- Some other stats (numRows, rawDataSize) should be cleared
+desc formatted stats_part partition (ds='2010-04-08', hr='13')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: -- Load a file into a existing partition
+-- Some stats (numFiles, totalSize) should be updated correctly
+-- Some other stats (numRows, rawDataSize) should be cleared
+desc formatted stats_part partition (ds='2010-04-08', hr='13')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2010-04-08, 13]    	 
+Database:           	default             	 
+Table:              	stats_part          	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	numFiles            	1                   
+	numRows             	500                 
+	rawDataSize         	5312                
+	totalSize           	5812                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE stats_part partition (ds='2010-04-08', hr='13')
+PREHOOK: type: LOAD
+PREHOOK: Output: default@stats_part@ds=2010-04-08/hr=13
+POSTHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE stats_part partition (ds='2010-04-08', hr='13')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@stats_part@ds=2010-04-08/hr=13
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: desc formatted stats_part partition (ds='2010-04-08', hr='13')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc formatted stats_part partition (ds='2010-04-08', hr='13')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2010-04-08, 13]    	 
+Database:           	default             	 
+Table:              	stats_part          	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	numFiles            	2                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	7170                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: drop table stats_src
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table stats_src
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: drop table stats_part
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@stats_part
+PREHOOK: Output: default@stats_part
+POSTHOOK: query: drop table stats_part
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@stats_part
+POSTHOOK: Output: default@stats_part
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_part PARTITION(ds=2010-04-08,hr=13).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
diff --git a/ql/src/test/results/clientpositive/stats2.q.out b/ql/src/test/results/clientpositive/stats2.q.out
index 4d84992bc9..a834c7965b 100644
--- a/ql/src/test/results/clientpositive/stats2.q.out
+++ b/ql/src/test/results/clientpositive/stats2.q.out
@@ -82,9 +82,9 @@ POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpar
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-PREHOOK: query: desc extended analyze_t1
+PREHOOK: query: desc formatted analyze_t1
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: desc extended analyze_t1
+POSTHOOK: query: desc formatted analyze_t1
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -94,12 +94,37 @@ POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpar
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
 	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
 #### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
 PREHOOK: query: explain analyze table analyze_t1 partition (ds, hr) compute statistics
 PREHOOK: type: QUERY
 POSTHOOK: query: explain analyze table analyze_t1 partition (ds, hr) compute statistics
@@ -161,9 +186,9 @@ POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpar
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-PREHOOK: query: describe extended analyze_t1
+PREHOOK: query: describe formatted analyze_t1
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended analyze_t1
+POSTHOOK: query: describe formatted analyze_t1
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -173,9 +198,39 @@ POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpar
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
 	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
 #### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numFiles            	4                   
+	numPartitions       	4                   
+	numRows             	2000                
+	rawDataSize         	21248               
+	totalSize           	23248               
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
diff --git a/ql/src/test/results/clientpositive/stats3.q.out b/ql/src/test/results/clientpositive/stats3.q.out
index e129a15899..cac54b19a5 100644
--- a/ql/src/test/results/clientpositive/stats3.q.out
+++ b/ql/src/test/results/clientpositive/stats3.q.out
@@ -11,12 +11,90 @@ PREHOOK: type: CREATETABLE
 POSTHOOK: query: create table hive_test_src ( col1 string ) stored as textfile
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@hive_test_src
+PREHOOK: query: explain extended
+load data local inpath '../data/files/test.dat' overwrite into table hive_test_src
+PREHOOK: type: LOAD
+POSTHOOK: query: explain extended
+load data local inpath '../data/files/test.dat' overwrite into table hive_test_src
+POSTHOOK: type: LOAD
+ABSTRACT SYNTAX TREE:
+  (TOK_LOAD '../data/files/test.dat' (TOK_TAB (TOK_TABNAME hive_test_src)) local overwrite)
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+  Stage-2 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-0
+    Copy
+#### A masked pattern was here ####
+
+  Stage: Stage-1
+    Move Operator
+      tables:
+          replace: true
+#### A masked pattern was here ####
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns col1
+                columns.types string
+#### A masked pattern was here ####
+                name default.hive_test_src
+                serialization.ddl struct hive_test_src { string col1}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+#### A masked pattern was here ####
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.hive_test_src
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+
+
 PREHOOK: query: load data local inpath '../data/files/test.dat' overwrite into table hive_test_src
 PREHOOK: type: LOAD
 PREHOOK: Output: default@hive_test_src
 POSTHOOK: query: load data local inpath '../data/files/test.dat' overwrite into table hive_test_src
 POSTHOOK: type: LOAD
 POSTHOOK: Output: default@hive_test_src
+PREHOOK: query: desc formatted hive_test_src
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc formatted hive_test_src
+POSTHOOK: type: DESCTABLE
+# col_name            	data_type           	comment             
+	 	 
+col1                	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numFiles            	1                   
+	numPartitions       	0                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	11                  
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
 PREHOOK: query: create table hive_test_dst ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as sequencefile
 PREHOOK: type: CREATETABLE
 POSTHOOK: query: create table hive_test_dst ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as sequencefile
@@ -117,17 +195,47 @@ POSTHOOK: type: QUERY
 #### A masked pattern was here ####
 POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
 POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
-PREHOOK: query: describe extended hive_test_dst
+PREHOOK: query: describe formatted hive_test_dst
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended hive_test_dst
+POSTHOOK: query: describe formatted hive_test_dst
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
 POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
-col1	string	
-pcol1	string	
-pcol2	string	
+# col_name            	data_type           	comment             
+	 	 
+col1                	string              	None                
 	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+pcol1               	string              	None                
+pcol2               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
 #### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numFiles            	1                   
+	numPartitions       	1                   
+	numRows             	6                   
+	rawDataSize         	6                   
+	totalSize           	171                 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.SequenceFileInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
 PREHOOK: query: drop table hive_test_src
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@hive_test_src
diff --git a/ql/src/test/results/clientpositive/stats4.q.out b/ql/src/test/results/clientpositive/stats4.q.out
index 83553b870e..2775c7d437 100644
--- a/ql/src/test/results/clientpositive/stats4.q.out
+++ b/ql/src/test/results/clientpositive/stats4.q.out
@@ -2315,9 +2315,9 @@ POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(sr
 400	val_400	2008-12-31	12
 200	val_200	2008-12-31	12
 97	val_97	2008-12-31	12
-PREHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=11)
+PREHOOK: query: describe formatted nzhang_part1 partition(ds='2008-04-08',hr=11)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=11)
+POSTHOOK: query: describe formatted nzhang_part1 partition(ds='2008-04-08',hr=11)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -2327,15 +2327,44 @@ POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcp
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
 	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 11]    	 
+Database:           	default             	 
+Table:              	nzhang_part1        	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	numFiles            	1                   
+	numRows             	500                 
+	rawDataSize         	5312                
+	totalSize           	5812                
 #### A masked pattern was here ####
-PREHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=12)
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: describe formatted nzhang_part1 partition(ds='2008-04-08',hr=12)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=12)
+POSTHOOK: query: describe formatted nzhang_part1 partition(ds='2008-04-08',hr=12)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -2345,15 +2374,44 @@ POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcp
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
 	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 12]    	 
+Database:           	default             	 
+Table:              	nzhang_part1        	 
 #### A masked pattern was here ####
-PREHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=11)
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	numFiles            	1                   
+	numRows             	500                 
+	rawDataSize         	5312                
+	totalSize           	5812                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: describe formatted nzhang_part2 partition(ds='2008-12-31',hr=11)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=11)
+POSTHOOK: query: describe formatted nzhang_part2 partition(ds='2008-12-31',hr=11)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -2363,15 +2421,44 @@ POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcp
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
 	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-12-31, 11]    	 
+Database:           	default             	 
+Table:              	nzhang_part2        	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
 #### A masked pattern was here ####
-PREHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=12)
+Partition Parameters:	 	 
+	numFiles            	1                   
+	numRows             	500                 
+	rawDataSize         	5312                
+	totalSize           	5812                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: describe formatted nzhang_part2 partition(ds='2008-12-31',hr=12)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=12)
+POSTHOOK: query: describe formatted nzhang_part2 partition(ds='2008-12-31',hr=12)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -2381,15 +2468,44 @@ POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcp
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
 	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-12-31, 12]    	 
+Database:           	default             	 
+Table:              	nzhang_part2        	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	numFiles            	1                   
+	numRows             	500                 
+	rawDataSize         	5312                
+	totalSize           	5812                
 #### A masked pattern was here ####
-PREHOOK: query: describe extended nzhang_part1
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: describe formatted nzhang_part1
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended nzhang_part1
+POSTHOOK: query: describe formatted nzhang_part1
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -2399,15 +2515,45 @@ POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcp
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
 	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
 #### A masked pattern was here ####
-PREHOOK: query: describe extended nzhang_part2
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numFiles            	2                   
+	numPartitions       	2                   
+	numRows             	1000                
+	rawDataSize         	10624               
+	totalSize           	11624               
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: describe formatted nzhang_part2
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended nzhang_part2
+POSTHOOK: query: describe formatted nzhang_part2
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -2417,12 +2563,42 @@ POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcp
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
 	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
 #### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numFiles            	2                   
+	numPartitions       	2                   
+	numRows             	1000                
+	rawDataSize         	10624               
+	totalSize           	11624               
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
 PREHOOK: query: drop table nzhang_part1
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@nzhang_part1
diff --git a/ql/src/test/results/clientpositive/stats5.q.out b/ql/src/test/results/clientpositive/stats5.q.out
index 9dbfa4a615..dd1c71c400 100644
--- a/ql/src/test/results/clientpositive/stats5.q.out
+++ b/ql/src/test/results/clientpositive/stats5.q.out
@@ -36,11 +36,37 @@ POSTHOOK: query: analyze table analyze_src compute statistics
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@analyze_src
 POSTHOOK: Output: default@analyze_src
-PREHOOK: query: describe extended analyze_src
+PREHOOK: query: describe formatted analyze_src
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended analyze_src
+POSTHOOK: query: describe formatted analyze_src
 POSTHOOK: type: DESCTABLE
-key	string	
-value	string	
+# col_name            	data_type           	comment             
 	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
 #### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numFiles            	1                   
+	numPartitions       	0                   
+	numRows             	500                 
+	rawDataSize         	5312                
+	totalSize           	5812                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
diff --git a/ql/src/test/results/clientpositive/stats6.q.out b/ql/src/test/results/clientpositive/stats6.q.out
index e529c8bf1c..63dada087c 100644
--- a/ql/src/test/results/clientpositive/stats6.q.out
+++ b/ql/src/test/results/clientpositive/stats6.q.out
@@ -64,9 +64,9 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
+PREHOOK: query: describe formatted analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
+POSTHOOK: query: describe formatted analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -76,15 +76,44 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
 	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 11]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
 #### A masked pattern was here ####
-PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
+Partition Parameters:	 	 
+	numFiles            	1                   
+	numRows             	500                 
+	rawDataSize         	5312                
+	totalSize           	5812                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: describe formatted analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
+POSTHOOK: query: describe formatted analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -94,15 +123,44 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
 	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 12]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
 #### A masked pattern was here ####
-PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11)
+Partition Parameters:	 	 
+	numFiles            	1                   
+	numRows             	500                 
+	rawDataSize         	5312                
+	totalSize           	5812                
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: describe formatted analyze_srcpart PARTITION(ds='2008-04-09',hr=11)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11)
+POSTHOOK: query: describe formatted analyze_srcpart PARTITION(ds='2008-04-09',hr=11)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -112,15 +170,40 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
 	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-09, 11]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
 #### A masked pattern was here ####
-PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12)
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: describe formatted analyze_srcpart PARTITION(ds='2008-04-09',hr=12)
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12)
+POSTHOOK: query: describe formatted analyze_srcpart PARTITION(ds='2008-04-09',hr=12)
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -130,15 +213,40 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
 	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-09, 12]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
 #### A masked pattern was here ####
-PREHOOK: query: describe extended analyze_srcpart
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: describe formatted analyze_srcpart
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended analyze_srcpart
+POSTHOOK: query: describe formatted analyze_srcpart
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
@@ -148,9 +256,39 @@ POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(s
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-key	string	default
-value	string	default
-ds	string	
-hr	string	
+# col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
 	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
 #### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numFiles            	2                   
+	numPartitions       	2                   
+	numRows             	1000                
+	rawDataSize         	10624               
+	totalSize           	11624               
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
diff --git a/ql/src/test/results/clientpositive/stats9.q.out b/ql/src/test/results/clientpositive/stats9.q.out
index d0bdfb9161..8242a100c3 100644
--- a/ql/src/test/results/clientpositive/stats9.q.out
+++ b/ql/src/test/results/clientpositive/stats9.q.out
@@ -48,13 +48,39 @@ POSTHOOK: Input: default@analyze_srcbucket
 POSTHOOK: Output: default@analyze_srcbucket
 POSTHOOK: Lineage: analyze_srcbucket.key SIMPLE [(srcbucket)srcbucket.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: analyze_srcbucket.value SIMPLE [(srcbucket)srcbucket.FieldSchema(name:value, type:string, comment:null), ]
-PREHOOK: query: describe extended analyze_srcbucket
+PREHOOK: query: describe formatted analyze_srcbucket
 PREHOOK: type: DESCTABLE
-POSTHOOK: query: describe extended analyze_srcbucket
+POSTHOOK: query: describe formatted analyze_srcbucket
 POSTHOOK: type: DESCTABLE
 POSTHOOK: Lineage: analyze_srcbucket.key SIMPLE [(srcbucket)srcbucket.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: analyze_srcbucket.value SIMPLE [(srcbucket)srcbucket.FieldSchema(name:value, type:string, comment:null), ]
-key	int	
-value	string	
+# col_name            	data_type           	comment             
 	 	 
+key                 	int                 	None                
+value               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Protect Mode:       	None                	 
+Retention:          	0                   	 
 #### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numFiles            	1                   
+	numPartitions       	0                   
+	numRows             	1000                
+	rawDataSize         	10603               
+	totalSize           	11603               
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	2                   	 
+Bucket Columns:     	[key]               	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
diff --git a/ql/src/test/results/clientpositive/transform_ppr1.q.out b/ql/src/test/results/clientpositive/transform_ppr1.q.out
index c2415e515c..da3d405cfb 100644
--- a/ql/src/test/results/clientpositive/transform_ppr1.q.out
+++ b/ql/src/test/results/clientpositive/transform_ppr1.q.out
@@ -89,10 +89,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -104,10 +109,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -126,10 +136,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -141,10 +156,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -163,10 +183,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -178,10 +203,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -200,10 +230,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -215,10 +250,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/transform_ppr2.q.out b/ql/src/test/results/clientpositive/transform_ppr2.q.out
index 5c8752f037..59d83db390 100644
--- a/ql/src/test/results/clientpositive/transform_ppr2.q.out
+++ b/ql/src/test/results/clientpositive/transform_ppr2.q.out
@@ -91,10 +91,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -106,10 +111,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -128,10 +138,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -143,10 +158,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/clientpositive/udf_explode.q.out b/ql/src/test/results/clientpositive/udf_explode.q.out
index 41fb6da912..b5e67bc8b6 100644
--- a/ql/src/test/results/clientpositive/udf_explode.q.out
+++ b/ql/src/test/results/clientpositive/udf_explode.q.out
@@ -67,9 +67,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -81,9 +86,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -143,9 +153,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -157,9 +172,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -365,9 +385,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -379,9 +404,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -443,9 +473,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -457,9 +492,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/udf_java_method.q.out b/ql/src/test/results/clientpositive/udf_java_method.q.out
index ebe31a0ea3..5a55076ab3 100644
--- a/ql/src/test/results/clientpositive/udf_java_method.q.out
+++ b/ql/src/test/results/clientpositive/udf_java_method.q.out
@@ -100,9 +100,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -114,9 +119,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/udf_reflect.q.out b/ql/src/test/results/clientpositive/udf_reflect.q.out
index 86703fce57..f489a79d5c 100644
--- a/ql/src/test/results/clientpositive/udf_reflect.q.out
+++ b/ql/src/test/results/clientpositive/udf_reflect.q.out
@@ -96,9 +96,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -110,9 +115,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/udtf_explode.q.out b/ql/src/test/results/clientpositive/udtf_explode.q.out
index 63c5f5f1dd..65c5ad1ace 100644
--- a/ql/src/test/results/clientpositive/udtf_explode.q.out
+++ b/ql/src/test/results/clientpositive/udtf_explode.q.out
@@ -67,9 +67,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -81,9 +86,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -143,9 +153,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -157,9 +172,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
@@ -395,9 +415,14 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.src
+              numFiles 1
+              numPartitions 0
+              numRows 0
+              rawDataSize 0
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -409,9 +434,14 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.src
+                numFiles 1
+                numPartitions 0
+                numRows 0
+                rawDataSize 0
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.src
diff --git a/ql/src/test/results/clientpositive/union_ppr.q.out b/ql/src/test/results/clientpositive/union_ppr.q.out
index 7d4e48044c..7d29555a89 100644
--- a/ql/src/test/results/clientpositive/union_ppr.q.out
+++ b/ql/src/test/results/clientpositive/union_ppr.q.out
@@ -151,10 +151,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -166,10 +171,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
@@ -188,10 +198,15 @@ STAGE PLANS:
               columns.types string:string
 #### A masked pattern was here ####
               name default.srcpart
+              numFiles 1
+              numPartitions 4
+              numRows 0
               partition_columns ds/hr
+              rawDataSize 0
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
 #### A masked pattern was here ####
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
@@ -203,10 +218,15 @@ STAGE PLANS:
                 columns.types string:string
 #### A masked pattern was here ####
                 name default.srcpart
+                numFiles 4
+                numPartitions 4
+                numRows 0
                 partition_columns ds/hr
+                rawDataSize 0
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 23248
 #### A masked pattern was here ####
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: default.srcpart
diff --git a/ql/src/test/results/compiler/plan/case_sensitivity.q.xml b/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
index 6178858d60..afce19c4d4 100644
--- a/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
+++ b/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.src_thrift</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string></string> 
@@ -547,6 +551,18 @@
           <string>serialization.format</string> 
           <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>serialization.class</string> 
           <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -563,6 +579,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>1606</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -597,6 +617,10 @@
             <string>name</string> 
             <string>default.src_thrift</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string></string> 
@@ -613,6 +637,18 @@
             <string>serialization.format</string> 
             <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>serialization.class</string> 
             <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -629,6 +665,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>1606</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -1266,6 +1306,10 @@
            <string>name</string> 
            <string>default.src_thrift</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string></string> 
@@ -1282,6 +1326,18 @@
            <string>serialization.format</string> 
            <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>serialization.class</string> 
            <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -1298,6 +1354,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>1606</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -1332,6 +1392,10 @@
              <string>name</string> 
              <string>default.src_thrift</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string></string> 
@@ -1348,6 +1412,18 @@
              <string>serialization.format</string> 
              <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>serialization.class</string> 
              <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -1364,6 +1440,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>1606</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/cast1.q.xml b/ql/src/test/results/compiler/plan/cast1.q.xml
index 9f63222ef0..550f1a3590 100644
--- a/ql/src/test/results/compiler/plan/cast1.q.xml
+++ b/ql/src/test/results/compiler/plan/cast1.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1101,6 +1141,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1117,6 +1161,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1129,6 +1185,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1163,6 +1223,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1179,6 +1243,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1191,6 +1267,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/groupby1.q.xml b/ql/src/test/results/compiler/plan/groupby1.q.xml
index cb5f6a24de..4382252085 100755
--- a/ql/src/test/results/compiler/plan/groupby1.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby1.q.xml
@@ -10,7 +10,7 @@
         <void method="add"> 
          <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
           <void property="id"> 
-           <string>Stage-4</string> 
+           <string>Stage-5</string> 
           </void> 
           <void property="parentTasks"> 
            <object class="java.util.ArrayList"> 
@@ -38,7 +38,7 @@
        </object> 
       </void> 
       <void property="id"> 
-       <string>Stage-2</string> 
+       <string>Stage-3</string> 
       </void> 
       <void property="parentTasks"> 
        <object class="java.util.ArrayList"> 
@@ -136,7 +136,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -162,6 +162,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -178,6 +182,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -190,6 +206,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -224,6 +244,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -240,6 +264,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -252,6 +288,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -998,6 +1038,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1014,6 +1058,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1026,6 +1082,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1060,6 +1120,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1076,6 +1140,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1088,6 +1164,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/groupby2.q.xml b/ql/src/test/results/compiler/plan/groupby2.q.xml
index 2af40bc945..eef669c9a5 100755
--- a/ql/src/test/results/compiler/plan/groupby2.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby2.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1119,6 +1159,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1135,6 +1179,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1147,6 +1203,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1181,6 +1241,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1197,6 +1261,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1209,6 +1285,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/groupby3.q.xml b/ql/src/test/results/compiler/plan/groupby3.q.xml
index acef820e74..9743480872 100644
--- a/ql/src/test/results/compiler/plan/groupby3.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby3.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1321,6 +1361,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1337,6 +1381,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1349,6 +1405,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1383,6 +1443,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1399,6 +1463,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1411,6 +1487,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/groupby4.q.xml b/ql/src/test/results/compiler/plan/groupby4.q.xml
index b687c2aba6..617a11a2e5 100644
--- a/ql/src/test/results/compiler/plan/groupby4.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby4.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -768,6 +808,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -784,6 +828,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -796,6 +852,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -830,6 +890,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -846,6 +910,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -858,6 +934,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/groupby5.q.xml b/ql/src/test/results/compiler/plan/groupby5.q.xml
index 4ad660691f..8e07860065 100644
--- a/ql/src/test/results/compiler/plan/groupby5.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby5.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -861,6 +901,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -877,6 +921,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -889,6 +945,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -923,6 +983,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -939,6 +1003,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -951,6 +1027,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/groupby6.q.xml b/ql/src/test/results/compiler/plan/groupby6.q.xml
index 5ab080c073..96bb347f9d 100644
--- a/ql/src/test/results/compiler/plan/groupby6.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby6.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -768,6 +808,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -784,6 +828,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -796,6 +852,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -830,6 +890,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -846,6 +910,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -858,6 +934,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input1.q.xml b/ql/src/test/results/compiler/plan/input1.q.xml
index e594caa2aa..1395099d76 100755
--- a/ql/src/test/results/compiler/plan/input1.q.xml
+++ b/ql/src/test/results/compiler/plan/input1.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -547,6 +551,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -559,6 +575,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -593,6 +613,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -609,6 +633,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -621,6 +657,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1081,6 +1121,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1097,6 +1141,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1109,6 +1165,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1143,6 +1203,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1159,6 +1223,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1171,6 +1247,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input2.q.xml b/ql/src/test/results/compiler/plan/input2.q.xml
index e684ad4fd8..c791a5ca85 100755
--- a/ql/src/test/results/compiler/plan/input2.q.xml
+++ b/ql/src/test/results/compiler/plan/input2.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-11</string> 
+       <string>Stage-12</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-6</string> 
+                   <string>Stage-7</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-7</string> 
+                   <string>Stage-8</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-10</string> 
+                   <string>Stage-11</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-9</string> 
+                       <string>Stage-10</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-8</string> 
+           <string>Stage-9</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-17</string> 
+       <string>Stage-18</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList1" class="java.util.ArrayList"> 
@@ -520,7 +520,7 @@
                 <void method="add"> 
                  <object id="StatsTask1" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-12</string> 
+                   <string>Stage-13</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -548,7 +548,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-3</string> 
+               <string>Stage-4</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -565,7 +565,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-13</string> 
+                   <string>Stage-14</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork1" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -874,7 +874,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-16</string> 
+                   <string>Stage-17</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -888,7 +888,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-15</string> 
+                       <string>Stage-16</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork1"/> 
@@ -946,7 +946,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-14</string> 
+           <string>Stage-15</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork1"/> 
@@ -1000,7 +1000,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-23</string> 
+       <string>Stage-24</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList2" class="java.util.ArrayList"> 
@@ -1015,7 +1015,7 @@
                 <void method="add"> 
                  <object id="StatsTask2" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-18</string> 
+                   <string>Stage-19</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -1043,7 +1043,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-4</string> 
+               <string>Stage-5</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -1060,7 +1060,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-19</string> 
+                   <string>Stage-20</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork2" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -1373,7 +1373,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-22</string> 
+                   <string>Stage-23</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -1387,7 +1387,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-21</string> 
+                       <string>Stage-22</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork2"/> 
@@ -1454,7 +1454,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-20</string> 
+           <string>Stage-21</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork2"/> 
@@ -1508,7 +1508,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-5</string> 
+   <string>Stage-6</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -1534,6 +1534,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -1550,6 +1554,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -1562,6 +1578,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1596,6 +1616,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -1612,6 +1636,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -1624,6 +1660,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -2685,6 +2725,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -2701,6 +2745,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -2713,6 +2769,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -2747,6 +2807,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -2763,6 +2827,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -2775,6 +2851,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input20.q.xml b/ql/src/test/results/compiler/plan/input20.q.xml
index a1e9a54d38..cef82e6f14 100644
--- a/ql/src/test/results/compiler/plan/input20.q.xml
+++ b/ql/src/test/results/compiler/plan/input20.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -885,6 +925,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -901,6 +945,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -913,6 +969,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -947,6 +1007,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -963,6 +1027,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -975,6 +1051,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input3.q.xml b/ql/src/test/results/compiler/plan/input3.q.xml
index 79cf196ebf..53e29ad82c 100755
--- a/ql/src/test/results/compiler/plan/input3.q.xml
+++ b/ql/src/test/results/compiler/plan/input3.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-12</string> 
+       <string>Stage-13</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-7</string> 
+                   <string>Stage-8</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-11</string> 
+                   <string>Stage-12</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-10</string> 
+                       <string>Stage-11</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-9</string> 
+           <string>Stage-10</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-18</string> 
+       <string>Stage-19</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList1" class="java.util.ArrayList"> 
@@ -520,7 +520,7 @@
                 <void method="add"> 
                  <object id="StatsTask1" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-13</string> 
+                   <string>Stage-14</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -548,7 +548,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-3</string> 
+               <string>Stage-4</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -565,7 +565,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-14</string> 
+                   <string>Stage-15</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork1" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -874,7 +874,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-17</string> 
+                   <string>Stage-18</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -888,7 +888,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-16</string> 
+                       <string>Stage-17</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork1"/> 
@@ -946,7 +946,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-15</string> 
+           <string>Stage-16</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork1"/> 
@@ -1000,7 +1000,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-24</string> 
+       <string>Stage-25</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList2" class="java.util.ArrayList"> 
@@ -1015,7 +1015,7 @@
                 <void method="add"> 
                  <object id="StatsTask2" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-19</string> 
+                   <string>Stage-20</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -1043,7 +1043,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-4</string> 
+               <string>Stage-5</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -1060,7 +1060,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-20</string> 
+                   <string>Stage-21</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork2" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -1373,7 +1373,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-23</string> 
+                   <string>Stage-24</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -1387,7 +1387,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-22</string> 
+                       <string>Stage-23</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork2"/> 
@@ -1454,7 +1454,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-21</string> 
+           <string>Stage-22</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork2"/> 
@@ -1508,7 +1508,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-29</string> 
+       <string>Stage-30</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList3" class="java.util.ArrayList"> 
@@ -1519,7 +1519,7 @@
             <void method="add"> 
              <object id="MoveTask10" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
               <void property="id"> 
-               <string>Stage-5</string> 
+               <string>Stage-6</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -1536,7 +1536,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-25</string> 
+                   <string>Stage-26</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork3" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -1759,7 +1759,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-28</string> 
+                   <string>Stage-29</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -1773,7 +1773,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-27</string> 
+                       <string>Stage-28</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork3"/> 
@@ -1831,7 +1831,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-26</string> 
+           <string>Stage-27</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork3"/> 
@@ -1885,7 +1885,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-6</string> 
+   <string>Stage-7</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -1911,6 +1911,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -1927,6 +1931,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -1939,6 +1955,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1973,6 +1993,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -1989,6 +2013,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -2001,6 +2037,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -3351,6 +3391,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -3367,6 +3411,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -3379,6 +3435,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -3413,6 +3473,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -3429,6 +3493,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -3441,6 +3517,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input4.q.xml b/ql/src/test/results/compiler/plan/input4.q.xml
index ff9565b04d..15f12d59ff 100755
--- a/ql/src/test/results/compiler/plan/input4.q.xml
+++ b/ql/src/test/results/compiler/plan/input4.q.xml
@@ -10,7 +10,7 @@
         <void method="add"> 
          <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
           <void property="id"> 
-           <string>Stage-4</string> 
+           <string>Stage-5</string> 
           </void> 
           <void property="parentTasks"> 
            <object class="java.util.ArrayList"> 
@@ -38,7 +38,7 @@
        </object> 
       </void> 
       <void property="id"> 
-       <string>Stage-2</string> 
+       <string>Stage-3</string> 
       </void> 
       <void property="parentTasks"> 
        <object class="java.util.ArrayList"> 
@@ -136,7 +136,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -162,6 +162,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -178,6 +182,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -190,6 +206,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -224,6 +244,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -240,6 +264,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -252,6 +288,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1019,6 +1059,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1035,6 +1079,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1047,6 +1103,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1081,6 +1141,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1097,6 +1161,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1109,6 +1185,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input5.q.xml b/ql/src/test/results/compiler/plan/input5.q.xml
index f81e242154..79e9681861 100644
--- a/ql/src/test/results/compiler/plan/input5.q.xml
+++ b/ql/src/test/results/compiler/plan/input5.q.xml
@@ -10,7 +10,7 @@
         <void method="add"> 
          <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
           <void property="id"> 
-           <string>Stage-4</string> 
+           <string>Stage-5</string> 
           </void> 
           <void property="parentTasks"> 
            <object class="java.util.ArrayList"> 
@@ -38,7 +38,7 @@
        </object> 
       </void> 
       <void property="id"> 
-       <string>Stage-2</string> 
+       <string>Stage-3</string> 
       </void> 
       <void property="parentTasks"> 
        <object class="java.util.ArrayList"> 
@@ -136,7 +136,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -162,6 +162,10 @@
           <string>name</string> 
           <string>default.src_thrift</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string></string> 
@@ -178,6 +182,18 @@
           <string>serialization.format</string> 
           <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>serialization.class</string> 
           <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -194,6 +210,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>1606</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -228,6 +248,10 @@
             <string>name</string> 
             <string>default.src_thrift</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string></string> 
@@ -244,6 +268,18 @@
             <string>serialization.format</string> 
             <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>serialization.class</string> 
             <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -260,6 +296,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>1606</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -1049,6 +1089,10 @@
            <string>name</string> 
            <string>default.src_thrift</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string></string> 
@@ -1065,6 +1109,18 @@
            <string>serialization.format</string> 
            <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>serialization.class</string> 
            <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -1081,6 +1137,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>1606</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -1115,6 +1175,10 @@
              <string>name</string> 
              <string>default.src_thrift</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string></string> 
@@ -1131,6 +1195,18 @@
              <string>serialization.format</string> 
              <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>serialization.class</string> 
              <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -1147,6 +1223,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>1606</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input6.q.xml b/ql/src/test/results/compiler/plan/input6.q.xml
index 04fe6247dd..fa7af70fe4 100644
--- a/ql/src/test/results/compiler/plan/input6.q.xml
+++ b/ql/src/test/results/compiler/plan/input6.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.src1</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -547,6 +551,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -559,6 +575,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>216</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -593,6 +613,10 @@
             <string>name</string> 
             <string>default.src1</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -609,6 +633,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -621,6 +657,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>216</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1067,6 +1107,10 @@
            <string>name</string> 
            <string>default.src1</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1083,6 +1127,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1095,6 +1151,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>216</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1129,6 +1189,10 @@
              <string>name</string> 
              <string>default.src1</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1145,6 +1209,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1157,6 +1233,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>216</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input7.q.xml b/ql/src/test/results/compiler/plan/input7.q.xml
index 708c194f66..e7de225e03 100644
--- a/ql/src/test/results/compiler/plan/input7.q.xml
+++ b/ql/src/test/results/compiler/plan/input7.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.src1</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -547,6 +551,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -559,6 +575,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>216</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -593,6 +613,10 @@
             <string>name</string> 
             <string>default.src1</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -609,6 +633,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -621,6 +657,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>216</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -983,6 +1023,10 @@
            <string>name</string> 
            <string>default.src1</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -999,6 +1043,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1011,6 +1067,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>216</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1045,6 +1105,10 @@
              <string>name</string> 
              <string>default.src1</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1061,6 +1125,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1073,6 +1149,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>216</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input8.q.xml b/ql/src/test/results/compiler/plan/input8.q.xml
index 5a1d58dd21..15bb4ccd42 100644
--- a/ql/src/test/results/compiler/plan/input8.q.xml
+++ b/ql/src/test/results/compiler/plan/input8.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src1</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>216</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src1</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>216</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -676,6 +716,10 @@
            <string>name</string> 
            <string>default.src1</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -692,6 +736,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -704,6 +760,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>216</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -738,6 +798,10 @@
              <string>name</string> 
              <string>default.src1</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -754,6 +818,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -766,6 +842,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>216</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input9.q.xml b/ql/src/test/results/compiler/plan/input9.q.xml
index e7aea332c8..10c5c9f8e8 100644
--- a/ql/src/test/results/compiler/plan/input9.q.xml
+++ b/ql/src/test/results/compiler/plan/input9.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.src1</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -547,6 +551,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -559,6 +575,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>216</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -593,6 +613,10 @@
             <string>name</string> 
             <string>default.src1</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -609,6 +633,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -621,6 +657,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>216</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1060,6 +1100,10 @@
            <string>name</string> 
            <string>default.src1</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1076,6 +1120,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1088,6 +1144,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>216</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1122,6 +1182,10 @@
              <string>name</string> 
              <string>default.src1</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1138,6 +1202,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1150,6 +1226,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>216</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input_part1.q.xml b/ql/src/test/results/compiler/plan/input_part1.q.xml
index a489754424..95534510ad 100644
--- a/ql/src/test/results/compiler/plan/input_part1.q.xml
+++ b/ql/src/test/results/compiler/plan/input_part1.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -37,6 +37,10 @@
           <string>name</string> 
           <string>default.srcpart</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>4</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -53,6 +57,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>4</string> 
+         </void> 
          <void method="put"> 
           <string>partition_columns</string> 
           <string>ds/hr</string> 
@@ -69,6 +85,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>23248</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -103,6 +123,10 @@
             <string>name</string> 
             <string>default.srcpart</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>4</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -119,6 +143,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>4</string> 
+           </void> 
            <void method="put"> 
             <string>partition_columns</string> 
             <string>ds/hr</string> 
@@ -135,6 +171,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>23248</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -796,6 +836,10 @@
            <string>name</string> 
            <string>default.srcpart</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -812,6 +856,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>4</string> 
+          </void> 
           <void method="put"> 
            <string>partition_columns</string> 
            <string>ds/hr</string> 
@@ -828,6 +884,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -862,6 +922,10 @@
              <string>name</string> 
              <string>default.srcpart</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>4</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -878,6 +942,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>4</string> 
+            </void> 
             <void method="put"> 
              <string>partition_columns</string> 
              <string>ds/hr</string> 
@@ -894,6 +970,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>23248</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml b/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
index 5ce8c392d9..6e5e6392ce 100644
--- a/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
+++ b/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -547,6 +551,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -559,6 +575,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -593,6 +613,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -609,6 +633,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -621,6 +657,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -991,6 +1031,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1007,6 +1051,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1019,6 +1075,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1053,6 +1113,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1069,6 +1133,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1081,6 +1157,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input_testxpath.q.xml b/ql/src/test/results/compiler/plan/input_testxpath.q.xml
index c10e18864c..1df0ba58c0 100644
--- a/ql/src/test/results/compiler/plan/input_testxpath.q.xml
+++ b/ql/src/test/results/compiler/plan/input_testxpath.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src_thrift</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string></string> 
@@ -44,6 +48,18 @@
           <string>serialization.format</string> 
           <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>serialization.class</string> 
           <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -60,6 +76,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>1606</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -94,6 +114,10 @@
             <string>name</string> 
             <string>default.src_thrift</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string></string> 
@@ -110,6 +134,18 @@
             <string>serialization.format</string> 
             <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>serialization.class</string> 
             <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -126,6 +162,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>1606</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -788,6 +828,10 @@
            <string>name</string> 
            <string>default.src_thrift</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string></string> 
@@ -804,6 +848,18 @@
            <string>serialization.format</string> 
            <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>serialization.class</string> 
            <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -820,6 +876,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>1606</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -854,6 +914,10 @@
              <string>name</string> 
              <string>default.src_thrift</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string></string> 
@@ -870,6 +934,18 @@
              <string>serialization.format</string> 
              <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>serialization.class</string> 
              <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -886,6 +962,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>1606</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/input_testxpath2.q.xml b/ql/src/test/results/compiler/plan/input_testxpath2.q.xml
index 85f6b96388..70917cf4d1 100644
--- a/ql/src/test/results/compiler/plan/input_testxpath2.q.xml
+++ b/ql/src/test/results/compiler/plan/input_testxpath2.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src_thrift</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string></string> 
@@ -44,6 +48,18 @@
           <string>serialization.format</string> 
           <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>serialization.class</string> 
           <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -60,6 +76,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>1606</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -94,6 +114,10 @@
             <string>name</string> 
             <string>default.src_thrift</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string></string> 
@@ -110,6 +134,18 @@
             <string>serialization.format</string> 
             <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>serialization.class</string> 
             <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -126,6 +162,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>1606</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -876,6 +916,10 @@
            <string>name</string> 
            <string>default.src_thrift</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string></string> 
@@ -892,6 +936,18 @@
            <string>serialization.format</string> 
            <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>serialization.class</string> 
            <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -908,6 +964,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>1606</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
@@ -942,6 +1002,10 @@
              <string>name</string> 
              <string>default.src_thrift</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string></string> 
@@ -958,6 +1022,18 @@
              <string>serialization.format</string> 
              <string>org.apache.thrift.protocol.TBinaryProtocol</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>serialization.class</string> 
              <string>org.apache.hadoop.hive.serde2.thrift.test.Complex</string> 
@@ -974,6 +1050,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.SequenceFileInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>1606</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/join1.q.xml b/ql/src/test/results/compiler/plan/join1.q.xml
index 4c8e0a0c2c..20e44ec0ab 100644
--- a/ql/src/test/results/compiler/plan/join1.q.xml
+++ b/ql/src/test/results/compiler/plan/join1.q.xml
@@ -10,7 +10,7 @@
         <void method="add"> 
          <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
           <void property="id"> 
-           <string>Stage-4</string> 
+           <string>Stage-5</string> 
           </void> 
           <void property="parentTasks"> 
            <object class="java.util.ArrayList"> 
@@ -38,7 +38,7 @@
        </object> 
       </void> 
       <void property="id"> 
-       <string>Stage-2</string> 
+       <string>Stage-3</string> 
       </void> 
       <void property="parentTasks"> 
        <object class="java.util.ArrayList"> 
@@ -136,7 +136,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -162,6 +162,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -178,6 +182,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -190,6 +206,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -224,6 +244,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -240,6 +264,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -252,6 +288,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -294,6 +334,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -310,6 +354,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -322,6 +378,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -356,6 +416,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -372,6 +436,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -384,6 +460,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1078,6 +1158,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1094,6 +1178,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1106,6 +1202,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1140,6 +1240,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1156,6 +1260,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1168,6 +1284,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1489,11 +1609,11 @@
         </void> 
         <void property="noOuterJoin"> 
          <boolean>true</boolean> 
-        </void>
-        <void property="nullSafes">
-         <array class="boolean" length="1"/>
-        </void>
-        <void property="outputColumnNames">
+        </void> 
+        <void property="nullSafes"> 
+         <array class="boolean" length="1"/> 
+        </void> 
+        <void property="outputColumnNames"> 
          <object class="java.util.ArrayList"> 
           <void method="add"> 
            <string>_col0</string> 
diff --git a/ql/src/test/results/compiler/plan/join2.q.xml b/ql/src/test/results/compiler/plan/join2.q.xml
index 46ac8ec12f..55852dd927 100644
--- a/ql/src/test/results/compiler/plan/join2.q.xml
+++ b/ql/src/test/results/compiler/plan/join2.q.xml
@@ -14,7 +14,7 @@
             <void method="add"> 
              <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
               <void property="id"> 
-               <string>Stage-5</string> 
+               <string>Stage-6</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -42,7 +42,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-2</string> 
+           <string>Stage-3</string> 
           </void> 
           <void property="parentTasks"> 
            <object class="java.util.ArrayList"> 
@@ -140,7 +140,7 @@
        </object> 
       </void> 
       <void property="id"> 
-       <string>Stage-4</string> 
+       <string>Stage-5</string> 
       </void> 
       <void property="parentTasks"> 
        <object class="java.util.ArrayList"> 
@@ -173,6 +173,10 @@
               <string>name</string> 
               <string>default.src</string> 
              </void> 
+             <void method="put"> 
+              <string>numFiles</string> 
+              <string>1</string> 
+             </void> 
              <void method="put"> 
               <string>columns.types</string> 
               <string>string:string</string> 
@@ -189,6 +193,18 @@
               <string>columns</string> 
               <string>key,value</string> 
              </void> 
+             <void method="put"> 
+              <string>rawDataSize</string> 
+              <string>0</string> 
+             </void> 
+             <void method="put"> 
+              <string>numRows</string> 
+              <string>0</string> 
+             </void> 
+             <void method="put"> 
+              <string>numPartitions</string> 
+              <string>0</string> 
+             </void> 
              <void method="put"> 
               <string>bucket_count</string> 
               <string>-1</string> 
@@ -201,6 +217,10 @@
               <string>file.inputformat</string> 
               <string>org.apache.hadoop.mapred.TextInputFormat</string> 
              </void> 
+             <void method="put"> 
+              <string>totalSize</string> 
+              <string>5812</string> 
+             </void> 
              <void method="put"> 
               <string>file.outputformat</string> 
               <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -235,6 +255,10 @@
                 <string>name</string> 
                 <string>default.src</string> 
                </void> 
+               <void method="put"> 
+                <string>numFiles</string> 
+                <string>1</string> 
+               </void> 
                <void method="put"> 
                 <string>columns.types</string> 
                 <string>string:string</string> 
@@ -251,6 +275,18 @@
                 <string>columns</string> 
                 <string>key,value</string> 
                </void> 
+               <void method="put"> 
+                <string>rawDataSize</string> 
+                <string>0</string> 
+               </void> 
+               <void method="put"> 
+                <string>numRows</string> 
+                <string>0</string> 
+               </void> 
+               <void method="put"> 
+                <string>numPartitions</string> 
+                <string>0</string> 
+               </void> 
                <void method="put"> 
                 <string>bucket_count</string> 
                 <string>-1</string> 
@@ -263,6 +299,10 @@
                 <string>file.inputformat</string> 
                 <string>org.apache.hadoop.mapred.TextInputFormat</string> 
                </void> 
+               <void method="put"> 
+                <string>totalSize</string> 
+                <string>5812</string> 
+               </void> 
                <void method="put"> 
                 <string>file.outputformat</string> 
                 <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1044,6 +1084,10 @@
                <string>name</string> 
                <string>default.src</string> 
               </void> 
+              <void method="put"> 
+               <string>numFiles</string> 
+               <string>1</string> 
+              </void> 
               <void method="put"> 
                <string>columns.types</string> 
                <string>string:string</string> 
@@ -1060,6 +1104,18 @@
                <string>columns</string> 
                <string>key,value</string> 
               </void> 
+              <void method="put"> 
+               <string>rawDataSize</string> 
+               <string>0</string> 
+              </void> 
+              <void method="put"> 
+               <string>numRows</string> 
+               <string>0</string> 
+              </void> 
+              <void method="put"> 
+               <string>numPartitions</string> 
+               <string>0</string> 
+              </void> 
               <void method="put"> 
                <string>bucket_count</string> 
                <string>-1</string> 
@@ -1072,6 +1128,10 @@
                <string>file.inputformat</string> 
                <string>org.apache.hadoop.mapred.TextInputFormat</string> 
               </void> 
+              <void method="put"> 
+               <string>totalSize</string> 
+               <string>5812</string> 
+              </void> 
               <void method="put"> 
                <string>file.outputformat</string> 
                <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1106,6 +1166,10 @@
                  <string>name</string> 
                  <string>default.src</string> 
                 </void> 
+                <void method="put"> 
+                 <string>numFiles</string> 
+                 <string>1</string> 
+                </void> 
                 <void method="put"> 
                  <string>columns.types</string> 
                  <string>string:string</string> 
@@ -1122,6 +1186,18 @@
                  <string>columns</string> 
                  <string>key,value</string> 
                 </void> 
+                <void method="put"> 
+                 <string>rawDataSize</string> 
+                 <string>0</string> 
+                </void> 
+                <void method="put"> 
+                 <string>numRows</string> 
+                 <string>0</string> 
+                </void> 
+                <void method="put"> 
+                 <string>numPartitions</string> 
+                 <string>0</string> 
+                </void> 
                 <void method="put"> 
                  <string>bucket_count</string> 
                  <string>-1</string> 
@@ -1134,6 +1210,10 @@
                  <string>file.inputformat</string> 
                  <string>org.apache.hadoop.mapred.TextInputFormat</string> 
                 </void> 
+                <void method="put"> 
+                 <string>totalSize</string> 
+                 <string>5812</string> 
+                </void> 
                 <void method="put"> 
                  <string>file.outputformat</string> 
                  <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1455,11 +1535,11 @@
             </void> 
             <void property="noOuterJoin"> 
              <boolean>true</boolean> 
-            </void>
-               <void property="nullSafes">
-              <array class="boolean" length="1"/>
-            </void>
-            <void property="outputColumnNames">
+            </void> 
+            <void property="nullSafes"> 
+             <array class="boolean" length="1"/> 
+            </void> 
+            <void property="outputColumnNames"> 
              <object class="java.util.ArrayList"> 
               <void method="add"> 
                <string>_col4</string> 
@@ -1638,7 +1718,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -1664,6 +1744,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -1680,6 +1764,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -1692,6 +1788,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1726,6 +1826,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -1742,6 +1846,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -1754,6 +1870,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1796,6 +1916,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -1812,6 +1936,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -1824,6 +1960,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1858,6 +1998,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -1874,6 +2018,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -1886,6 +2042,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -2552,6 +2712,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -2568,6 +2732,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -2580,6 +2756,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -2614,6 +2794,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -2630,6 +2814,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -2642,6 +2838,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -2799,11 +2999,11 @@
         </void> 
         <void property="noOuterJoin"> 
          <boolean>true</boolean> 
-        </void>
-        <void property="nullSafes">
-         <array class="boolean" length="1"/>
-        </void>
-        <void property="outputColumnNames">
+        </void> 
+        <void property="nullSafes"> 
+         <array class="boolean" length="1"/> 
+        </void> 
+        <void property="outputColumnNames"> 
          <object class="java.util.ArrayList"> 
           <void method="add"> 
            <string>_col0</string> 
diff --git a/ql/src/test/results/compiler/plan/join3.q.xml b/ql/src/test/results/compiler/plan/join3.q.xml
index d788856165..401dd9b580 100644
--- a/ql/src/test/results/compiler/plan/join3.q.xml
+++ b/ql/src/test/results/compiler/plan/join3.q.xml
@@ -10,7 +10,7 @@
         <void method="add"> 
          <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
           <void property="id"> 
-           <string>Stage-4</string> 
+           <string>Stage-5</string> 
           </void> 
           <void property="parentTasks"> 
            <object class="java.util.ArrayList"> 
@@ -38,7 +38,7 @@
        </object> 
       </void> 
       <void property="id"> 
-       <string>Stage-2</string> 
+       <string>Stage-3</string> 
       </void> 
       <void property="parentTasks"> 
        <object class="java.util.ArrayList"> 
@@ -136,7 +136,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -162,6 +162,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -178,6 +182,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -190,6 +206,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -224,6 +244,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -240,6 +264,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -252,6 +288,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -294,6 +334,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -310,6 +354,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -322,6 +378,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -356,6 +416,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -372,6 +436,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -384,6 +460,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -426,6 +506,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -442,6 +526,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -454,6 +550,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -488,6 +588,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -504,6 +608,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -516,6 +632,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1486,6 +1606,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1502,6 +1626,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1514,6 +1650,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1548,6 +1688,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1564,6 +1708,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1576,6 +1732,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1912,11 +2072,11 @@
         </void> 
         <void property="noOuterJoin"> 
          <boolean>true</boolean> 
-        </void>
-        <void property="nullSafes">
-         <array class="boolean" length="1"/>
-        </void>
-        <void property="outputColumnNames">
+        </void> 
+        <void property="nullSafes"> 
+         <array class="boolean" length="1"/> 
+        </void> 
+        <void property="outputColumnNames"> 
          <object class="java.util.ArrayList"> 
           <void method="add"> 
            <string>_col0</string> 
diff --git a/ql/src/test/results/compiler/plan/join4.q.xml b/ql/src/test/results/compiler/plan/join4.q.xml
index fa63bafe0c..04a70e0e80 100644
--- a/ql/src/test/results/compiler/plan/join4.q.xml
+++ b/ql/src/test/results/compiler/plan/join4.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -160,6 +200,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -176,6 +220,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -188,6 +244,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -222,6 +282,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -238,6 +302,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -250,6 +326,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1488,6 +1568,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1504,6 +1588,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1516,6 +1612,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1550,6 +1650,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1566,6 +1670,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1578,6 +1694,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -2227,11 +2347,11 @@
            <object class="java.util.ArrayList"/> 
           </void> 
          </object> 
-        </void>
-        <void property="nullSafes">
-         <array class="boolean" length="1"/>
-        </void>
-        <void property="outputColumnNames">
+        </void> 
+        <void property="nullSafes"> 
+         <array class="boolean" length="1"/> 
+        </void> 
+        <void property="outputColumnNames"> 
          <object class="java.util.ArrayList"> 
           <void method="add"> 
            <string>_col0</string> 
diff --git a/ql/src/test/results/compiler/plan/join5.q.xml b/ql/src/test/results/compiler/plan/join5.q.xml
index 0ad198d1c6..94386a599b 100644
--- a/ql/src/test/results/compiler/plan/join5.q.xml
+++ b/ql/src/test/results/compiler/plan/join5.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -160,6 +200,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -176,6 +220,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -188,6 +244,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -222,6 +282,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -238,6 +302,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -250,6 +326,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1488,6 +1568,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1504,6 +1588,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1516,6 +1612,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1550,6 +1650,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1566,6 +1670,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1578,6 +1694,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -2227,11 +2347,11 @@
            <object class="java.util.ArrayList"/> 
           </void> 
          </object> 
-        </void>
-        <void property="nullSafes">
-         <array class="boolean" length="1"/>
-        </void>
-        <void property="outputColumnNames">
+        </void> 
+        <void property="nullSafes"> 
+         <array class="boolean" length="1"/> 
+        </void> 
+        <void property="outputColumnNames"> 
          <object class="java.util.ArrayList"> 
           <void method="add"> 
            <string>_col0</string> 
diff --git a/ql/src/test/results/compiler/plan/join6.q.xml b/ql/src/test/results/compiler/plan/join6.q.xml
index 57cba547cd..51c29d30f2 100644
--- a/ql/src/test/results/compiler/plan/join6.q.xml
+++ b/ql/src/test/results/compiler/plan/join6.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -160,6 +200,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -176,6 +220,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -188,6 +244,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -222,6 +282,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -238,6 +302,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -250,6 +326,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1488,6 +1568,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1504,6 +1588,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1516,6 +1612,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1550,6 +1650,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1566,6 +1670,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1578,6 +1694,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -2227,11 +2347,11 @@
            <object class="java.util.ArrayList"/> 
           </void> 
          </object> 
-        </void>
-        <void property="nullSafes">
-         <array class="boolean" length="1"/>
-        </void>
-        <void property="outputColumnNames">
+        </void> 
+        <void property="nullSafes"> 
+         <array class="boolean" length="1"/> 
+        </void> 
+        <void property="outputColumnNames"> 
          <object class="java.util.ArrayList"> 
           <void method="add"> 
            <string>_col0</string> 
diff --git a/ql/src/test/results/compiler/plan/join7.q.xml b/ql/src/test/results/compiler/plan/join7.q.xml
index 1d511b96f3..e5976c708b 100644
--- a/ql/src/test/results/compiler/plan/join7.q.xml
+++ b/ql/src/test/results/compiler/plan/join7.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -160,6 +200,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -176,6 +220,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -188,6 +244,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -222,6 +282,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -238,6 +302,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -250,6 +326,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -292,6 +372,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -308,6 +392,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -320,6 +416,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -354,6 +454,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -370,6 +474,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -382,6 +498,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -2196,6 +2316,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -2212,6 +2336,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -2224,6 +2360,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -2258,6 +2398,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -2274,6 +2418,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -2286,6 +2442,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -3140,11 +3300,11 @@
            <object class="java.util.ArrayList"/> 
           </void> 
          </object> 
-        </void>
-        <void property="nullSafes">
-         <array class="boolean" length="1"/>
-        </void>
-        <void property="outputColumnNames">
+        </void> 
+        <void property="nullSafes"> 
+         <array class="boolean" length="1"/> 
+        </void> 
+        <void property="outputColumnNames"> 
          <object class="java.util.ArrayList"> 
           <void method="add"> 
            <string>_col0</string> 
diff --git a/ql/src/test/results/compiler/plan/join8.q.xml b/ql/src/test/results/compiler/plan/join8.q.xml
index 76c560c5cb..e121a3a3c9 100644
--- a/ql/src/test/results/compiler/plan/join8.q.xml
+++ b/ql/src/test/results/compiler/plan/join8.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -160,6 +200,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -176,6 +220,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -188,6 +244,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -222,6 +282,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -238,6 +302,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -250,6 +326,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1570,6 +1650,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1586,6 +1670,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1598,6 +1694,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1632,6 +1732,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1648,6 +1752,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1660,6 +1776,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -2424,11 +2544,11 @@
            <object class="java.util.ArrayList"/> 
           </void> 
          </object> 
-        </void>
-        <void property="nullSafes">
-         <array class="boolean" length="1"/>
-        </void>
-        <void property="outputColumnNames">
+        </void> 
+        <void property="nullSafes"> 
+         <array class="boolean" length="1"/> 
+        </void> 
+        <void property="outputColumnNames"> 
          <object class="java.util.ArrayList"> 
           <void method="add"> 
            <string>_col0</string> 
diff --git a/ql/src/test/results/compiler/plan/sample1.q.xml b/ql/src/test/results/compiler/plan/sample1.q.xml
index 901099aa64..7836e131eb 100644
--- a/ql/src/test/results/compiler/plan/sample1.q.xml
+++ b/ql/src/test/results/compiler/plan/sample1.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -37,6 +37,10 @@
           <string>name</string> 
           <string>default.srcpart</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>4</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -53,6 +57,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>4</string> 
+         </void> 
          <void method="put"> 
           <string>partition_columns</string> 
           <string>ds/hr</string> 
@@ -69,6 +85,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>23248</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -103,6 +123,10 @@
             <string>name</string> 
             <string>default.srcpart</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>4</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -119,6 +143,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>4</string> 
+           </void> 
            <void method="put"> 
             <string>partition_columns</string> 
             <string>ds/hr</string> 
@@ -135,6 +171,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>23248</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -917,6 +957,10 @@
            <string>name</string> 
            <string>default.srcpart</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -933,6 +977,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>4</string> 
+          </void> 
           <void method="put"> 
            <string>partition_columns</string> 
            <string>ds/hr</string> 
@@ -949,6 +1005,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -983,6 +1043,10 @@
              <string>name</string> 
              <string>default.srcpart</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>4</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -999,6 +1063,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>4</string> 
+            </void> 
             <void method="put"> 
              <string>partition_columns</string> 
              <string>ds/hr</string> 
@@ -1015,6 +1091,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>23248</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/sample2.q.xml b/ql/src/test/results/compiler/plan/sample2.q.xml
index 6ba711951f..e8572bdc17 100644
--- a/ql/src/test/results/compiler/plan/sample2.q.xml
+++ b/ql/src/test/results/compiler/plan/sample2.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.srcbucket</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>2</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>int:string</string> 
@@ -551,6 +555,18 @@
           <string>serialization.format</string> 
           <string>1</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>2</string> 
@@ -563,6 +579,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>11603</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -597,6 +617,10 @@
             <string>name</string> 
             <string>default.srcbucket</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>2</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>int:string</string> 
@@ -617,6 +641,18 @@
             <string>serialization.format</string> 
             <string>1</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>2</string> 
@@ -629,6 +665,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>11603</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1193,6 +1233,10 @@
            <string>name</string> 
            <string>default.srcbucket</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>2</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>int:string</string> 
@@ -1213,6 +1257,18 @@
            <string>serialization.format</string> 
            <string>1</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>2</string> 
@@ -1225,6 +1281,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>11603</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1259,6 +1319,10 @@
              <string>name</string> 
              <string>default.srcbucket</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>2</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>int:string</string> 
@@ -1279,6 +1343,18 @@
              <string>serialization.format</string> 
              <string>1</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>2</string> 
@@ -1291,6 +1367,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>11603</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/sample3.q.xml b/ql/src/test/results/compiler/plan/sample3.q.xml
index 50984a5834..bf6bfec385 100644
--- a/ql/src/test/results/compiler/plan/sample3.q.xml
+++ b/ql/src/test/results/compiler/plan/sample3.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.srcbucket</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>2</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>int:string</string> 
@@ -551,6 +555,18 @@
           <string>serialization.format</string> 
           <string>1</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>2</string> 
@@ -563,6 +579,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>11603</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -597,6 +617,10 @@
             <string>name</string> 
             <string>default.srcbucket</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>2</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>int:string</string> 
@@ -617,6 +641,18 @@
             <string>serialization.format</string> 
             <string>1</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>2</string> 
@@ -629,6 +665,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>11603</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1203,6 +1243,10 @@
            <string>name</string> 
            <string>default.srcbucket</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>2</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>int:string</string> 
@@ -1223,6 +1267,18 @@
            <string>serialization.format</string> 
            <string>1</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>2</string> 
@@ -1235,6 +1291,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>11603</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1269,6 +1329,10 @@
              <string>name</string> 
              <string>default.srcbucket</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>2</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>int:string</string> 
@@ -1289,6 +1353,18 @@
              <string>serialization.format</string> 
              <string>1</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>2</string> 
@@ -1301,6 +1377,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>11603</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/sample4.q.xml b/ql/src/test/results/compiler/plan/sample4.q.xml
index d2fffee0c9..4f69df5755 100644
--- a/ql/src/test/results/compiler/plan/sample4.q.xml
+++ b/ql/src/test/results/compiler/plan/sample4.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.srcbucket</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>2</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>int:string</string> 
@@ -551,6 +555,18 @@
           <string>serialization.format</string> 
           <string>1</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>2</string> 
@@ -563,6 +579,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>11603</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -597,6 +617,10 @@
             <string>name</string> 
             <string>default.srcbucket</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>2</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>int:string</string> 
@@ -617,6 +641,18 @@
             <string>serialization.format</string> 
             <string>1</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>2</string> 
@@ -629,6 +665,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>11603</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1193,6 +1233,10 @@
            <string>name</string> 
            <string>default.srcbucket</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>2</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>int:string</string> 
@@ -1213,6 +1257,18 @@
            <string>serialization.format</string> 
            <string>1</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>2</string> 
@@ -1225,6 +1281,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>11603</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1259,6 +1319,10 @@
              <string>name</string> 
              <string>default.srcbucket</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>2</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>int:string</string> 
@@ -1279,6 +1343,18 @@
              <string>serialization.format</string> 
              <string>1</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>2</string> 
@@ -1291,6 +1367,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>11603</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/sample5.q.xml b/ql/src/test/results/compiler/plan/sample5.q.xml
index d8084f7e1b..4dcb89a8cc 100644
--- a/ql/src/test/results/compiler/plan/sample5.q.xml
+++ b/ql/src/test/results/compiler/plan/sample5.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.srcbucket</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>2</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>int:string</string> 
@@ -551,6 +555,18 @@
           <string>serialization.format</string> 
           <string>1</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>2</string> 
@@ -563,6 +579,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>11603</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -597,6 +617,10 @@
             <string>name</string> 
             <string>default.srcbucket</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>2</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>int:string</string> 
@@ -617,6 +641,18 @@
             <string>serialization.format</string> 
             <string>1</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>2</string> 
@@ -629,6 +665,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>11603</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1190,6 +1230,10 @@
            <string>name</string> 
            <string>default.srcbucket</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>2</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>int:string</string> 
@@ -1210,6 +1254,18 @@
            <string>serialization.format</string> 
            <string>1</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>2</string> 
@@ -1222,6 +1278,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>11603</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1256,6 +1316,10 @@
              <string>name</string> 
              <string>default.srcbucket</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>2</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>int:string</string> 
@@ -1276,6 +1340,18 @@
              <string>serialization.format</string> 
              <string>1</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>2</string> 
@@ -1288,6 +1364,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>11603</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/sample6.q.xml b/ql/src/test/results/compiler/plan/sample6.q.xml
index e034fc7a06..838fa07b99 100644
--- a/ql/src/test/results/compiler/plan/sample6.q.xml
+++ b/ql/src/test/results/compiler/plan/sample6.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.srcbucket</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>2</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>int:string</string> 
@@ -551,6 +555,18 @@
           <string>serialization.format</string> 
           <string>1</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>2</string> 
@@ -563,6 +579,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>11603</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -597,6 +617,10 @@
             <string>name</string> 
             <string>default.srcbucket</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>2</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>int:string</string> 
@@ -617,6 +641,18 @@
             <string>serialization.format</string> 
             <string>1</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>2</string> 
@@ -629,6 +665,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>11603</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1193,6 +1233,10 @@
            <string>name</string> 
            <string>default.srcbucket</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>2</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>int:string</string> 
@@ -1213,6 +1257,18 @@
            <string>serialization.format</string> 
            <string>1</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>2</string> 
@@ -1225,6 +1281,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>11603</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1259,6 +1319,10 @@
              <string>name</string> 
              <string>default.srcbucket</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>2</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>int:string</string> 
@@ -1279,6 +1343,18 @@
              <string>serialization.format</string> 
              <string>1</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>2</string> 
@@ -1291,6 +1367,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>11603</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/sample7.q.xml b/ql/src/test/results/compiler/plan/sample7.q.xml
index 1a3778d5db..7752352a96 100644
--- a/ql/src/test/results/compiler/plan/sample7.q.xml
+++ b/ql/src/test/results/compiler/plan/sample7.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -21,7 +21,7 @@
                 <void method="add"> 
                  <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -49,7 +49,7 @@
                </object> 
               </void> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -66,7 +66,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-5</string> 
+                   <string>Stage-6</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -379,7 +379,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-8</string> 
+                   <string>Stage-9</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -393,7 +393,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-7</string> 
+                       <string>Stage-8</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -451,7 +451,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-6</string> 
+           <string>Stage-7</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -505,7 +505,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -531,6 +531,10 @@
           <string>name</string> 
           <string>default.srcbucket</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>2</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>int:string</string> 
@@ -551,6 +555,18 @@
           <string>serialization.format</string> 
           <string>1</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>2</string> 
@@ -563,6 +579,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>11603</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -597,6 +617,10 @@
             <string>name</string> 
             <string>default.srcbucket</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>2</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>int:string</string> 
@@ -617,6 +641,18 @@
             <string>serialization.format</string> 
             <string>1</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>2</string> 
@@ -629,6 +665,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>11603</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1275,6 +1315,10 @@
            <string>name</string> 
            <string>default.srcbucket</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>2</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>int:string</string> 
@@ -1295,6 +1339,18 @@
            <string>serialization.format</string> 
            <string>1</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>2</string> 
@@ -1307,6 +1363,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>11603</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1341,6 +1401,10 @@
              <string>name</string> 
              <string>default.srcbucket</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>2</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>int:string</string> 
@@ -1361,6 +1425,18 @@
              <string>serialization.format</string> 
              <string>1</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>2</string> 
@@ -1373,6 +1449,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>11603</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/subq.q.xml b/ql/src/test/results/compiler/plan/subq.q.xml
index b906775208..16a0ee99ce 100644
--- a/ql/src/test/results/compiler/plan/subq.q.xml
+++ b/ql/src/test/results/compiler/plan/subq.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-8</string> 
+       <string>Stage-9</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -17,7 +17,7 @@
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -34,7 +34,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -274,7 +274,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-7</string> 
+                   <string>Stage-8</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -288,7 +288,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-6</string> 
+                       <string>Stage-7</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -346,7 +346,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -400,7 +400,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -426,6 +426,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -442,6 +446,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -454,6 +470,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -488,6 +508,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -504,6 +528,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -516,6 +552,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1106,6 +1146,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1122,6 +1166,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1134,6 +1190,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1168,6 +1228,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1184,6 +1248,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1196,6 +1272,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/udf1.q.xml b/ql/src/test/results/compiler/plan/udf1.q.xml
index ba68fcdd15..3c5e05f6f0 100644
--- a/ql/src/test/results/compiler/plan/udf1.q.xml
+++ b/ql/src/test/results/compiler/plan/udf1.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1927,6 +1967,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1943,6 +1987,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1955,6 +2011,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1989,6 +2049,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -2005,6 +2069,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -2017,6 +2093,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/udf4.q.xml b/ql/src/test/results/compiler/plan/udf4.q.xml
index f71784333e..75e51ecca9 100644
--- a/ql/src/test/results/compiler/plan/udf4.q.xml
+++ b/ql/src/test/results/compiler/plan/udf4.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
diff --git a/ql/src/test/results/compiler/plan/udf6.q.xml b/ql/src/test/results/compiler/plan/udf6.q.xml
index 9422a0e107..73b72b0861 100644
--- a/ql/src/test/results/compiler/plan/udf6.q.xml
+++ b/ql/src/test/results/compiler/plan/udf6.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -607,6 +647,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -623,6 +667,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -635,6 +691,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -669,6 +729,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -685,6 +749,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -697,6 +773,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/udf_case.q.xml b/ql/src/test/results/compiler/plan/udf_case.q.xml
index 8a4c081bb8..ea83799b79 100644
--- a/ql/src/test/results/compiler/plan/udf_case.q.xml
+++ b/ql/src/test/results/compiler/plan/udf_case.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -701,6 +741,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -717,6 +761,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -729,6 +785,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -763,6 +823,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -779,6 +843,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -791,6 +867,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/udf_when.q.xml b/ql/src/test/results/compiler/plan/udf_when.q.xml
index e61987ce5e..914289ac28 100644
--- a/ql/src/test/results/compiler/plan/udf_when.q.xml
+++ b/ql/src/test/results/compiler/plan/udf_when.q.xml
@@ -2,7 +2,7 @@
 #### A masked pattern was here #### 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -28,6 +28,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -44,6 +48,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -56,6 +72,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -90,6 +110,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -106,6 +130,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -118,6 +154,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -781,6 +821,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -797,6 +841,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -809,6 +865,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -843,6 +903,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -859,6 +923,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -871,6 +947,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
diff --git a/ql/src/test/results/compiler/plan/union.q.xml b/ql/src/test/results/compiler/plan/union.q.xml
index 69303e8cff..b746a46623 100644
--- a/ql/src/test/results/compiler/plan/union.q.xml
+++ b/ql/src/test/results/compiler/plan/union.q.xml
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-8</string> 
+       <string>Stage-9</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -17,7 +17,7 @@
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
               <void property="id"> 
-               <string>Stage-2</string> 
+               <string>Stage-3</string> 
               </void> 
               <void property="parentTasks"> 
                <object class="java.util.ArrayList"> 
@@ -34,7 +34,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -274,7 +274,7 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-7</string> 
+                   <string>Stage-8</string> 
                   </void> 
                   <void property="parentTasks"> 
                    <object class="java.util.ArrayList"> 
@@ -288,7 +288,7 @@
                        </object> 
                       </void> 
                       <void property="id"> 
-                       <string>Stage-6</string> 
+                       <string>Stage-7</string> 
                       </void> 
                       <void property="work"> 
                        <object idref="MapredWork0"/> 
@@ -346,7 +346,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object idref="MoveWork0"/> 
@@ -400,7 +400,7 @@
    </object> 
   </void> 
   <void property="id"> 
-   <string>Stage-3</string> 
+   <string>Stage-4</string> 
   </void> 
   <void property="work"> 
    <object class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
@@ -426,6 +426,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -442,6 +446,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -454,6 +470,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -488,6 +508,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -504,6 +528,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -516,6 +552,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -558,6 +598,10 @@
           <string>name</string> 
           <string>default.src</string> 
          </void> 
+         <void method="put"> 
+          <string>numFiles</string> 
+          <string>1</string> 
+         </void> 
          <void method="put"> 
           <string>columns.types</string> 
           <string>string:string</string> 
@@ -574,6 +618,18 @@
           <string>columns</string> 
           <string>key,value</string> 
          </void> 
+         <void method="put"> 
+          <string>rawDataSize</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numRows</string> 
+          <string>0</string> 
+         </void> 
+         <void method="put"> 
+          <string>numPartitions</string> 
+          <string>0</string> 
+         </void> 
          <void method="put"> 
           <string>bucket_count</string> 
           <string>-1</string> 
@@ -586,6 +642,10 @@
           <string>file.inputformat</string> 
           <string>org.apache.hadoop.mapred.TextInputFormat</string> 
          </void> 
+         <void method="put"> 
+          <string>totalSize</string> 
+          <string>5812</string> 
+         </void> 
          <void method="put"> 
           <string>file.outputformat</string> 
           <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -620,6 +680,10 @@
             <string>name</string> 
             <string>default.src</string> 
            </void> 
+           <void method="put"> 
+            <string>numFiles</string> 
+            <string>1</string> 
+           </void> 
            <void method="put"> 
             <string>columns.types</string> 
             <string>string:string</string> 
@@ -636,6 +700,18 @@
             <string>columns</string> 
             <string>key,value</string> 
            </void> 
+           <void method="put"> 
+            <string>rawDataSize</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numRows</string> 
+            <string>0</string> 
+           </void> 
+           <void method="put"> 
+            <string>numPartitions</string> 
+            <string>0</string> 
+           </void> 
            <void method="put"> 
             <string>bucket_count</string> 
             <string>-1</string> 
@@ -648,6 +724,10 @@
             <string>file.inputformat</string> 
             <string>org.apache.hadoop.mapred.TextInputFormat</string> 
            </void> 
+           <void method="put"> 
+            <string>totalSize</string> 
+            <string>5812</string> 
+           </void> 
            <void method="put"> 
             <string>file.outputformat</string> 
             <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1618,6 +1698,10 @@
            <string>name</string> 
            <string>default.src</string> 
           </void> 
+          <void method="put"> 
+           <string>numFiles</string> 
+           <string>1</string> 
+          </void> 
           <void method="put"> 
            <string>columns.types</string> 
            <string>string:string</string> 
@@ -1634,6 +1718,18 @@
            <string>columns</string> 
            <string>key,value</string> 
           </void> 
+          <void method="put"> 
+           <string>rawDataSize</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numRows</string> 
+           <string>0</string> 
+          </void> 
+          <void method="put"> 
+           <string>numPartitions</string> 
+           <string>0</string> 
+          </void> 
           <void method="put"> 
            <string>bucket_count</string> 
            <string>-1</string> 
@@ -1646,6 +1742,10 @@
            <string>file.inputformat</string> 
            <string>org.apache.hadoop.mapred.TextInputFormat</string> 
           </void> 
+          <void method="put"> 
+           <string>totalSize</string> 
+           <string>5812</string> 
+          </void> 
           <void method="put"> 
            <string>file.outputformat</string> 
            <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
@@ -1680,6 +1780,10 @@
              <string>name</string> 
              <string>default.src</string> 
             </void> 
+            <void method="put"> 
+             <string>numFiles</string> 
+             <string>1</string> 
+            </void> 
             <void method="put"> 
              <string>columns.types</string> 
              <string>string:string</string> 
@@ -1696,6 +1800,18 @@
              <string>columns</string> 
              <string>key,value</string> 
             </void> 
+            <void method="put"> 
+             <string>rawDataSize</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numRows</string> 
+             <string>0</string> 
+            </void> 
+            <void method="put"> 
+             <string>numPartitions</string> 
+             <string>0</string> 
+            </void> 
             <void method="put"> 
              <string>bucket_count</string> 
              <string>-1</string> 
@@ -1708,6 +1824,10 @@
              <string>file.inputformat</string> 
              <string>org.apache.hadoop.mapred.TextInputFormat</string> 
             </void> 
+            <void method="put"> 
+             <string>totalSize</string> 
+             <string>5812</string> 
+            </void> 
             <void method="put"> 
              <string>file.outputformat</string> 
              <string>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</string> 
