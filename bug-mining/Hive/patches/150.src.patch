diff --git a/CHANGES.txt b/CHANGES.txt
index 3783e1d026..d6a3f1bece 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -135,6 +135,9 @@ Trunk - Unreleased
     HIVE-485. Fix join not to assume all columns are strings.
     (Namit Jain via zshao)
 
+    HIVE-488. Fix load partition for table with multiple partition columns.
+    (Prasad Chakka via athusoo)
+
 Release 0.3.1 - Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/data/files/test.dat b/data/files/test.dat
new file mode 100644
index 0000000000..cf0389a5af
--- /dev/null
+++ b/data/files/test.dat
@@ -0,0 +1,6 @@
+1
+2
+3
+4
+5
+6
\ No newline at end of file
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
index 4c1663c1ff..32a3b8f5bf 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
@@ -770,7 +770,17 @@ static protected void replaceFiles(Path srcf, Path destf, FileSystem fs,
           // point of no return
           boolean b = fs.delete(destf, true);
           LOG.debug("Deleting:"+destf.toString()+",Status:"+b);
+          // create the parent directory otherwise rename can fail if the parent doesn't exist
+          if (!fs.mkdirs(destf.getParent())) {
+            throw new HiveException("Unable to create destination directory: " 
+                  + destf.getParent().toString());
+          }
+          
           b = fs.rename(tmppath, destf);
+          if (!b) {
+            throw new HiveException("Unable to move results to destination directory: " 
+                + destf.getParent().toString());
+          }
           LOG.debug("Renaming:"+tmppath.toString()+",Status:"+b);
 
       } catch (IOException e) {
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java b/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
index 40d94858e3..01fc7f20b5 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
@@ -243,14 +243,14 @@ public void createSources() throws Exception {
         part_spec.put("ds", ds);
         part_spec.put("hr", hr);
         // System.out.println("Loading partition with spec: " + part_spec);
-        db.createPartition(srcpart, part_spec);
+        //db.createPartition(srcpart, part_spec);
         fpath = new Path(testFiles, "kv1.txt");
         newfpath = new Path(tmppath, "kv1.txt");
         fs.copyFromLocalFile(false, true, fpath, newfpath);
         fpath = newfpath;
         //db.loadPartition(fpath, srcpart.getName(), part_spec, true);
         runLoadCmd("LOAD DATA INPATH '" +  newfpath.toString() +
-                   "' INTO TABLE srcpart PARTITION (ds='" + ds + "',hr='" + hr +"')");
+                   "' OVERWRITE INTO TABLE srcpart PARTITION (ds='" + ds + "',hr='" + hr +"')");
       }
     }
     ArrayList<String> bucketCols = new ArrayList<String>();
diff --git a/ql/src/test/queries/clientpositive/loadpart1.q b/ql/src/test/queries/clientpositive/loadpart1.q
new file mode 100644
index 0000000000..eec57ee918
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/loadpart1.q
@@ -0,0 +1,11 @@
+drop table hive_test_src;
+drop table hive_test_dst;
+create table hive_test_src ( col1 string ) stored as textfile ;
+load data local inpath '../data/files/test.dat' overwrite into table hive_test_src ;
+create table hive_test_dst ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as sequencefile;
+insert overwrite table hive_test_dst partition ( pcol1='test_part', pcol2='test_part') select col1 from hive_test_src ;
+select * from hive_test_dst where pcol1='test_part' and pcol2='test_part';
+insert overwrite table hive_test_dst partition ( pcol1='test_part', pcol2='test_part') select col1 from hive_test_src ;
+select * from hive_test_dst where pcol1='test_part' and pcol2='test_part';
+drop table hive_test_src;
+drop table hive_test_dst;
diff --git a/ql/src/test/results/clientpositive/loadpart1.q.out b/ql/src/test/results/clientpositive/loadpart1.q.out
new file mode 100644
index 0000000000..ae9d90e5ff
--- /dev/null
+++ b/ql/src/test/results/clientpositive/loadpart1.q.out
@@ -0,0 +1,31 @@
+query: drop table hive_test_src
+query: drop table hive_test_dst
+query: create table hive_test_src ( col1 string ) stored as textfile
+query: load data local inpath '../data/files/test.dat' overwrite into table hive_test_src
+query: create table hive_test_dst ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as sequencefile
+query: insert overwrite table hive_test_dst partition ( pcol1='test_part', pcol2='test_part') select col1 from hive_test_src
+Input: default/hive_test_src
+Output: default/hive_test_dst/pcol1=test_part/pcol2=test_part
+query: select * from hive_test_dst where pcol1='test_part' and pcol2='test_part'
+Input: default/hive_test_dst/pcol1=test_part/pcol2=test_part
+Output: /data/users/pchakka/workspace/oshive/ql/../build/ql/tmp/608894653/647768977.10000
+1	test_part	test_part
+2	test_part	test_part
+3	test_part	test_part
+4	test_part	test_part
+5	test_part	test_part
+6	test_part	test_part
+query: insert overwrite table hive_test_dst partition ( pcol1='test_part', pcol2='test_part') select col1 from hive_test_src
+Input: default/hive_test_src
+Output: default/hive_test_dst/pcol1=test_part/pcol2=test_part
+query: select * from hive_test_dst where pcol1='test_part' and pcol2='test_part'
+Input: default/hive_test_dst/pcol1=test_part/pcol2=test_part
+Output: /data/users/pchakka/workspace/oshive/ql/../build/ql/tmp/255138744/205167628.10000
+1	test_part	test_part
+2	test_part	test_part
+3	test_part	test_part
+4	test_part	test_part
+5	test_part	test_part
+6	test_part	test_part
+query: drop table hive_test_src
+query: drop table hive_test_dst
