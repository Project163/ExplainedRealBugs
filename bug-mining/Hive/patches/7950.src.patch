diff --git a/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergOutputCommitter.java b/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergOutputCommitter.java
index 82987dc1a4..7a8cffafe7 100644
--- a/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergOutputCommitter.java
+++ b/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergOutputCommitter.java
@@ -25,6 +25,7 @@
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Map;
+import java.util.Optional;
 import java.util.Properties;
 import java.util.Set;
 import java.util.concurrent.ConcurrentLinkedQueue;
@@ -53,6 +54,7 @@
 import org.apache.iceberg.mr.Catalogs;
 import org.apache.iceberg.mr.InputFormatConfig;
 import org.apache.iceberg.relocated.com.google.common.annotations.VisibleForTesting;
+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;
 import org.apache.iceberg.relocated.com.google.common.util.concurrent.ThreadFactoryBuilder;
 import org.apache.iceberg.util.Tasks;
 import org.slf4j.Logger;
@@ -95,8 +97,12 @@ public void commitTask(TaskAttemptContext originalContext) throws IOException {
 
     TaskAttemptID attemptID = context.getTaskAttemptID();
     JobConf jobConf = context.getJobConf();
-    Map<String, HiveIcebergRecordWriter> writers = HiveIcebergRecordWriter.getWriters(attemptID);
     Collection<String> outputs = HiveIcebergStorageHandler.outputTables(context.getJobConf());
+    Map<String, HiveIcebergRecordWriter> writers = Optional.ofNullable(HiveIcebergRecordWriter.getWriters(attemptID))
+        .orElseGet(() -> {
+          LOG.info("CommitTask found no writers for output tables: {}, attemptID: {}", outputs, attemptID);
+          return ImmutableMap.of();
+        });
 
     ExecutorService tableExecutor = tableExecutor(jobConf, outputs.size());
     try {
@@ -110,7 +116,13 @@ public void commitTask(TaskAttemptContext originalContext) throws IOException {
             Table table = HiveIcebergStorageHandler.table(context.getJobConf(), output);
             if (table != null) {
               HiveIcebergRecordWriter writer = writers.get(output);
-              DataFile[] closedFiles = writer != null ? writer.dataFiles() : new DataFile[0];
+              DataFile[] closedFiles;
+              if (writer != null) {
+                closedFiles = writer.dataFiles();
+              } else {
+                LOG.info("CommitTask found no writer for specific table: {}, attemptID: {}", output, attemptID);
+                closedFiles = new DataFile[0];
+              }
               String fileForCommitLocation = generateFileForCommitLocation(table.location(), jobConf,
                   attemptID.getJobID(), attemptID.getTaskID().getId());
 
@@ -179,9 +191,13 @@ public void commitJob(JobContext originalContext) throws IOException {
           .executeWith(tableExecutor)
           .run(output -> {
             Table table = HiveIcebergStorageHandler.table(jobConf, output);
-            String catalogName = HiveIcebergStorageHandler.catalogName(jobConf, output);
-            jobLocations.add(generateJobLocation(table.location(), jobConf, jobContext.getJobID()));
-            commitTable(table.io(), fileExecutor, jobContext, output, table.location(), catalogName);
+            if (table != null) {
+              String catalogName = HiveIcebergStorageHandler.catalogName(jobConf, output);
+              jobLocations.add(generateJobLocation(table.location(), jobConf, jobContext.getJobID()));
+              commitTable(table.io(), fileExecutor, jobContext, output, table.location(), catalogName);
+            } else {
+              LOG.info("CommitJob found no serialized table in config for table: {}. Skipping job commit.", output);
+            }
           });
     } finally {
       fileExecutor.shutdown();
diff --git a/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergStorageHandlerWithEngine.java b/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergStorageHandlerWithEngine.java
index 3b5f824752..bc544fb032 100644
--- a/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergStorageHandlerWithEngine.java
+++ b/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergStorageHandlerWithEngine.java
@@ -718,6 +718,22 @@ public void testWriteWithDefaultWriteFormat() {
     Assert.assertEquals("Linda", results.get(0)[1]);
   }
 
+  @Test
+  public void testInsertEmptyResultSet() throws IOException {
+    Table source = testTables.createTable(shell, "source", HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA,
+        fileFormat, ImmutableList.of());
+    Table target = testTables.createTable(shell, "target", HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA,
+        fileFormat, ImmutableList.of());
+
+    shell.executeStatement("INSERT INTO target SELECT * FROM source");
+    HiveIcebergTestUtils.validateData(target, ImmutableList.of(), 0);
+
+    testTables.appendIcebergTable(shell.getHiveConf(), source, fileFormat, null,
+        HiveIcebergStorageHandlerTestUtils.CUSTOMER_RECORDS);
+    shell.executeStatement("INSERT INTO target SELECT * FROM source WHERE first_name = 'Nobody'");
+    HiveIcebergTestUtils.validateData(target, ImmutableList.of(), 0);
+  }
+
   @Test
   public void testDecimalTableWithPredicateLiterals() throws IOException {
     Schema schema = new Schema(required(1, "decimal_field", Types.DecimalType.of(7, 2)));
