diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/views/HiveMaterializedViewUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/views/HiveMaterializedViewUtils.java
index 87a030c3bc..d7bc98ce2c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/views/HiveMaterializedViewUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/views/HiveMaterializedViewUtils.java
@@ -23,6 +23,8 @@
 import java.util.Collections;
 import java.util.List;
 import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+
 import org.apache.calcite.adapter.druid.DruidQuery;
 import org.apache.calcite.interpreter.BindableConvention;
 import org.apache.calcite.plan.RelOptCluster;
@@ -48,7 +50,9 @@
 import org.apache.hadoop.hive.common.ValidWriteIdList;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.api.CreationMetadata;
+import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.ql.lockmgr.LockException;
+import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.metadata.Table;
 import org.apache.hadoop.hive.ql.optimizer.calcite.HiveRelFactories;
 import org.apache.hadoop.hive.ql.optimizer.calcite.RelOptHiveTable;
@@ -58,6 +62,10 @@
 import org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveRelNode;
 import org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveTableScan;
 import org.apache.hadoop.hive.ql.parse.DruidSqlOperatorConverter;
+import org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAccessControlException;
+import org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthzContext;
+import org.apache.hadoop.hive.ql.security.authorization.plugin.HiveOperationType;
+import org.apache.hadoop.hive.ql.security.authorization.plugin.HivePrivilegeObject;
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hive.common.util.TxnIdUtils;
 import org.slf4j.Logger;
@@ -347,6 +355,38 @@ public static RelNode copyNodeNewCluster(RelOptCluster optCluster, RelNode node)
     }
   }
 
+  /**
+   * Validate if given materialized view has SELECT privileges for current user
+   * @param cachedMVTable
+   * @return false if user does not have privilege otherwise true
+   * @throws HiveException
+   */
+  public static boolean checkPrivilegeForMaterializedViews(List<Table> cachedMVTableList) throws HiveException {
+    List<HivePrivilegeObject> privObjects = new ArrayList<HivePrivilegeObject>();
+
+    for (Table cachedMVTable:cachedMVTableList) {
+      List<String> colNames =
+          cachedMVTable.getAllCols().stream()
+              .map(FieldSchema::getName)
+              .collect(Collectors.toList());
+
+      HivePrivilegeObject privObject = new HivePrivilegeObject(cachedMVTable.getDbName(),
+          cachedMVTable.getTableName(), colNames);
+      privObjects.add(privObject);
+    }
+
+    try {
+      SessionState.get().getAuthorizerV2().
+          checkPrivileges(HiveOperationType.QUERY, privObjects, privObjects, new HiveAuthzContext.Builder().build());
+    } catch (HiveException e) {
+      if (e instanceof HiveAccessControlException) {
+        return false;
+      }
+      throw e;
+    }
+    return true;
+  }
+
   private static RelNode copyNodeScanNewCluster(RelOptCluster optCluster, RelNode scan) {
     final RelNode newScan;
     if (scan instanceof DruidQuery) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
index 6447c18ade..7cd8ac0fa7 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
@@ -2280,6 +2280,15 @@ private RelNode applyMaterializedViewRewriting(RelOptPlanner planner, RelNode ba
         return calcitePreMVRewritingPlan;
       }
 
+      try {
+        if (!HiveMaterializedViewUtils.checkPrivilegeForMaterializedViews(materializedViewsUsedAfterRewrite)) {
+          // if materialized views do not have appropriate privileges, we shouldn't be using them
+          return calcitePreMVRewritingPlan;
+        }
+      } catch (HiveException e) {
+        LOG.warn("Exception checking privileges for materialized views", e);
+        return calcitePreMVRewritingPlan;
+      }
       // A rewriting was produced, we will check whether it was part of an incremental rebuild
       // to try to replace INSERT OVERWRITE by INSERT or MERGE
       if (mvRebuildMode == MaterializationRebuildMode.INSERT_OVERWRITE_REBUILD) {
diff --git a/ql/src/test/queries/clientpositive/materialized_view_authorization_sqlstd.q b/ql/src/test/queries/clientpositive/materialized_view_authorization_sqlstd.q
index 283c8934f6..4bf5f41c56 100644
--- a/ql/src/test/queries/clientpositive/materialized_view_authorization_sqlstd.q
+++ b/ql/src/test/queries/clientpositive/materialized_view_authorization_sqlstd.q
@@ -52,3 +52,26 @@ drop materialized view amvs_mat_view2;
 
 set user.name=hive_admin_user;
 set role ADMIN;
+
+set hive.support.concurrency=true;
+set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
+set user.name=user1;
+
+create database db1;
+create table db1.testmvtable(id int, name string) partitioned by(year int) stored as orc TBLPROPERTIES ('transactional'='true');
+insert into db1.testmvtable partition(year=2016) values(1,'Name1');
+
+create database db2;
+CREATE MATERIALIZED VIEW db2.testmv PARTITIONED ON(year) as select * from db1.testmvtable tmv where year >= 2018;
+
+-- grant all on table to user2
+grant all on table db1.testmvtable to user user2;
+set user.name=user2;
+explain select * from db1.testmvtable where year=2020;
+
+set user.name=user1;
+drop materialized view db2.testmv;
+drop table db1.testmvtable;
+drop database db1 cascade ;
+drop database db2 cascade;
+
diff --git a/ql/src/test/results/clientpositive/llap/materialized_view_authorization_sqlstd.q.out b/ql/src/test/results/clientpositive/llap/materialized_view_authorization_sqlstd.q.out
index 90f6fa474b..cc9e913808 100644
--- a/ql/src/test/results/clientpositive/llap/materialized_view_authorization_sqlstd.q.out
+++ b/ql/src/test/results/clientpositive/llap/materialized_view_authorization_sqlstd.q.out
@@ -183,3 +183,109 @@ PREHOOK: query: set role ADMIN
 PREHOOK: type: SHOW_ROLES
 POSTHOOK: query: set role ADMIN
 POSTHOOK: type: SHOW_ROLES
+PREHOOK: query: create database db1
+PREHOOK: type: CREATEDATABASE
+PREHOOK: Output: database:db1
+POSTHOOK: query: create database db1
+POSTHOOK: type: CREATEDATABASE
+POSTHOOK: Output: database:db1
+PREHOOK: query: create table db1.testmvtable(id int, name string) partitioned by(year int) stored as orc TBLPROPERTIES ('transactional'='true')
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:db1
+PREHOOK: Output: db1@testmvtable
+POSTHOOK: query: create table db1.testmvtable(id int, name string) partitioned by(year int) stored as orc TBLPROPERTIES ('transactional'='true')
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:db1
+POSTHOOK: Output: db1@testmvtable
+PREHOOK: query: insert into db1.testmvtable partition(year=2016) values(1,'Name1')
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: db1@testmvtable@year=2016
+POSTHOOK: query: insert into db1.testmvtable partition(year=2016) values(1,'Name1')
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: db1@testmvtable@year=2016
+POSTHOOK: Lineage: testmvtable PARTITION(year=2016).id SCRIPT []
+POSTHOOK: Lineage: testmvtable PARTITION(year=2016).name SCRIPT []
+PREHOOK: query: create database db2
+PREHOOK: type: CREATEDATABASE
+PREHOOK: Output: database:db2
+POSTHOOK: query: create database db2
+POSTHOOK: type: CREATEDATABASE
+POSTHOOK: Output: database:db2
+PREHOOK: query: CREATE MATERIALIZED VIEW db2.testmv PARTITIONED ON(year) as select * from db1.testmvtable tmv where year >= 2018
+PREHOOK: type: CREATE_MATERIALIZED_VIEW
+PREHOOK: Input: db1@testmvtable
+PREHOOK: Output: database:db2
+PREHOOK: Output: db2@testmv
+PREHOOK: Output: db2@testmv
+POSTHOOK: query: CREATE MATERIALIZED VIEW db2.testmv PARTITIONED ON(year) as select * from db1.testmvtable tmv where year >= 2018
+POSTHOOK: type: CREATE_MATERIALIZED_VIEW
+POSTHOOK: Input: db1@testmvtable
+POSTHOOK: Output: database:db2
+POSTHOOK: Output: db2@testmv
+POSTHOOK: Output: db2@testmv
+PREHOOK: query: grant all on table db1.testmvtable to user user2
+PREHOOK: type: GRANT_PRIVILEGE
+PREHOOK: Output: db1@testmvtable
+POSTHOOK: query: grant all on table db1.testmvtable to user user2
+POSTHOOK: type: GRANT_PRIVILEGE
+POSTHOOK: Output: db1@testmvtable
+PREHOOK: query: explain select * from db1.testmvtable where year=2020
+PREHOOK: type: QUERY
+PREHOOK: Input: db1@testmvtable
+#### A masked pattern was here ####
+POSTHOOK: query: explain select * from db1.testmvtable where year=2020
+POSTHOOK: type: QUERY
+POSTHOOK: Input: db1@testmvtable
+#### A masked pattern was here ####
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: testmvtable
+          filterExpr: (year = 2020) (type: boolean)
+          Filter Operator
+            predicate: (year = 2020) (type: boolean)
+            Select Operator
+              expressions: id (type: int), name (type: string), 2020 (type: int)
+              outputColumnNames: _col0, _col1, _col2
+              ListSink
+
+PREHOOK: query: drop materialized view db2.testmv
+PREHOOK: type: DROP_MATERIALIZED_VIEW
+PREHOOK: Input: db2@testmv
+PREHOOK: Output: db2@testmv
+POSTHOOK: query: drop materialized view db2.testmv
+POSTHOOK: type: DROP_MATERIALIZED_VIEW
+POSTHOOK: Input: db2@testmv
+POSTHOOK: Output: db2@testmv
+PREHOOK: query: drop table db1.testmvtable
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: db1@testmvtable
+PREHOOK: Output: db1@testmvtable
+POSTHOOK: query: drop table db1.testmvtable
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: db1@testmvtable
+POSTHOOK: Output: db1@testmvtable
+PREHOOK: query: drop database db1 cascade
+PREHOOK: type: DROPDATABASE
+PREHOOK: Input: database:db1
+PREHOOK: Output: database:db1
+POSTHOOK: query: drop database db1 cascade
+POSTHOOK: type: DROPDATABASE
+POSTHOOK: Input: database:db1
+POSTHOOK: Output: database:db1
+PREHOOK: query: drop database db2 cascade
+PREHOOK: type: DROPDATABASE
+PREHOOK: Input: database:db2
+PREHOOK: Output: database:db2
+POSTHOOK: query: drop database db2 cascade
+POSTHOOK: type: DROPDATABASE
+POSTHOOK: Input: database:db2
+POSTHOOK: Output: database:db2
