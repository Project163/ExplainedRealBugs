diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
index 05316202c0..55c6f38503 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
@@ -164,6 +164,7 @@ public static Hive get(HiveConf c, boolean needsRefresh) throws HiveException {
       hiveDB.set(newdb);
       return newdb;
     }
+    db.conf = c;
     return db;
   }
 
diff --git a/ql/src/test/queries/clientnegative/dyn_part_max.q b/ql/src/test/queries/clientnegative/dyn_part_max.q
new file mode 100644
index 0000000000..6a7a6255b9
--- /dev/null
+++ b/ql/src/test/queries/clientnegative/dyn_part_max.q
@@ -0,0 +1,16 @@
+USE default;
+
+-- Test of hive.exec.max.dynamic.partitions
+-- Set hive.exec.max.dynamic.partitions.pernode to a large value so it will be ignored
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING);
+
+set hive.exec.dynamic.partition=true;
+set hive.exec.dynamic.partition.mode=nonstrict;
+set hive.exec.max.dynamic.partitions=10;
+set hive.exec.max.dynamic.partitions.pernode=1000;
+
+INSERT OVERWRITE TABLE max_parts PARTITION(value)
+SELECT key, value
+FROM src
+LIMIT 50;
diff --git a/ql/src/test/queries/clientnegative/dyn_part_max_per_node.q b/ql/src/test/queries/clientnegative/dyn_part_max_per_node.q
new file mode 100644
index 0000000000..a411ec520b
--- /dev/null
+++ b/ql/src/test/queries/clientnegative/dyn_part_max_per_node.q
@@ -0,0 +1,15 @@
+USE default;
+
+-- Test of hive.exec.max.dynamic.partitions.pernode
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING);
+
+set hive.exec.dynamic.partition=true;
+set hive.exec.dynamic.partition.mode=nonstrict;
+set hive.exec.max.dynamic.partitions=1000;
+set hive.exec.max.dynamic.partitions.pernode=10;
+
+INSERT OVERWRITE TABLE max_parts PARTITION(value)
+SELECT key, value
+FROM src
+LIMIT 50;
diff --git a/ql/src/test/results/clientnegative/dyn_part_max.q.out b/ql/src/test/results/clientnegative/dyn_part_max.q.out
new file mode 100644
index 0000000000..eb91275a5d
--- /dev/null
+++ b/ql/src/test/results/clientnegative/dyn_part_max.q.out
@@ -0,0 +1,24 @@
+PREHOOK: query: USE default
+PREHOOK: type: SWITCHDATABASE
+POSTHOOK: query: USE default
+POSTHOOK: type: SWITCHDATABASE
+PREHOOK: query: -- Test of hive.exec.max.dynamic.partitions
+-- Set hive.exec.max.dynamic.partitions.pernode to a large value so it will be ignored
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: -- Test of hive.exec.max.dynamic.partitions
+-- Set hive.exec.max.dynamic.partitions.pernode to a large value so it will be ignored
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@max_parts
+PREHOOK: query: INSERT OVERWRITE TABLE max_parts PARTITION(value)
+SELECT key, value
+FROM src
+LIMIT 50
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@max_parts
+Failed with exception Number of dynamic partitions created is 49, which is more than 10. To solve this try to set hive.exec.max.dynamic.partitions to at least 49.
+FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MoveTask
diff --git a/ql/src/test/results/clientnegative/dyn_part_max_per_node.q.out b/ql/src/test/results/clientnegative/dyn_part_max_per_node.q.out
new file mode 100644
index 0000000000..3a3bb1e06b
--- /dev/null
+++ b/ql/src/test/results/clientnegative/dyn_part_max_per_node.q.out
@@ -0,0 +1,31 @@
+PREHOOK: query: USE default
+PREHOOK: type: SWITCHDATABASE
+POSTHOOK: query: USE default
+POSTHOOK: type: SWITCHDATABASE
+PREHOOK: query: -- Test of hive.exec.max.dynamic.partitions.pernode
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: -- Test of hive.exec.max.dynamic.partitions.pernode
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@max_parts
+PREHOOK: query: INSERT OVERWRITE TABLE max_parts PARTITION(value)
+SELECT key, value
+FROM src
+LIMIT 50
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@max_parts
+Execution failed with exit status: 2
+Obtaining error information
+
+Task failed!
+Task ID:
+  Stage-1
+
+Logs:
+
+#### A masked pattern was here ####
+FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask
