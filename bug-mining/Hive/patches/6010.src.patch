diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index 75b77072c6..8b2b333e27 100644
--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -328,6 +328,13 @@ private static URL checkConfigFile(File f) {
     HiveConf.ConfVars.SCRATCHDIR
   };
 
+  /**
+   * encoded parameter values are ;-) encoded.  Use decoder to get ;-) decoded string
+   */
+  public static final HiveConf.ConfVars[] ENCODED_CONF = {
+      ConfVars.HIVEQUERYSTRING
+  };
+
   /**
    * Variables used by LLAP daemons.
    * TODO: Eventually auto-populate this based on prefixes. The conf variables
@@ -3933,6 +3940,16 @@ public boolean isHiddenConfig(String name) {
     return Iterables.any(hiddenSet, hiddenVar -> name.startsWith(hiddenVar));
   }
 
+  public static boolean isEncodedPar(String name) {
+    for (ConfVars confVar : HiveConf.ENCODED_CONF) {
+      ConfVars confVar1 = confVar;
+      if (confVar1.varname.equals(name)) {
+        return true;
+      }
+    }
+    return false;
+  }
+
   /**
    * check whether spark related property is updated, which includes spark configurations,
    * RSC configurations and yarn configuration in Spark on YARN mode.
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java b/ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java
index b9ca938628..64c471148f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java
@@ -143,7 +143,12 @@ private void dumpOption(String s) {
     if (ss.getConf().isHiddenConfig(s)) {
       ss.out.println(s + " is a hidden config");
     } else if (ss.getConf().get(s) != null) {
-      ss.out.println(s + "=" + ss.getConf().get(s));
+      if (ss.getConf().isEncodedPar(s)) {
+        ss.out.println(s + "=" + HiveConf.EncoderDecoderFactory.URL_ENCODER_DECODER
+            .decode(ss.getConf().get(s)));
+      } else {
+        ss.out.println(s + "=" + ss.getConf().get(s));
+      }
     } else if (ss.getHiveVariables().containsKey(s)) {
       ss.out.println(s + "=" + ss.getHiveVariables().get(s));
     } else {
diff --git a/ql/src/test/queries/clientpositive/testSetQueryString.q b/ql/src/test/queries/clientpositive/testSetQueryString.q
new file mode 100644
index 0000000000..f11afb2771
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/testSetQueryString.q
@@ -0,0 +1,4 @@
+create table t1 (c1 int);
+insert into t1 values (1);
+select * from t1;
+set hive.query.string;
\ No newline at end of file
diff --git a/ql/src/test/results/clientpositive/testSetQueryString.q.out b/ql/src/test/results/clientpositive/testSetQueryString.q.out
new file mode 100644
index 0000000000..0bf191950d
--- /dev/null
+++ b/ql/src/test/results/clientpositive/testSetQueryString.q.out
@@ -0,0 +1,26 @@
+PREHOOK: query: create table t1 (c1 int)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t1
+POSTHOOK: query: create table t1 (c1 int)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t1
+PREHOOK: query: insert into t1 values (1)
+PREHOOK: type: QUERY
+PREHOOK: Output: default@t1
+POSTHOOK: query: insert into t1 values (1)
+POSTHOOK: type: QUERY
+POSTHOOK: Output: default@t1
+POSTHOOK: Lineage: t1.c1 EXPRESSION [(values__tmp__table__1)values__tmp__table__1.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
+PREHOOK: query: select * from t1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t1
+#### A masked pattern was here ####
+POSTHOOK: query: select * from t1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t1
+#### A masked pattern was here ####
+1
+hive.query.string=
+select * from t1
