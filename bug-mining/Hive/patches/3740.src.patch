diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index 36bb394d85..9cc798762f 100644
--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -1175,8 +1175,6 @@ public static enum ConfVars {
     HIVEROWOFFSET("hive.exec.rowoffset", false,
         "Whether to provide the row offset virtual column"),
 
-    HIVE_COMBINE_INPUT_FORMAT_SUPPORTS_SPLITTABLE("hive.hadoop.supports.splittable.combineinputformat", false, ""),
-
     // Optimizer
     HIVEOPTINDEXFILTER("hive.optimize.index.filter", false,
         "Whether to enable automatic use of indexes"),
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/CombineHiveInputFormat.java b/ql/src/java/org/apache/hadoop/hive/ql/io/CombineHiveInputFormat.java
index e13c4ddcc4..11740d1816 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/CombineHiveInputFormat.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/CombineHiveInputFormat.java
@@ -374,45 +374,6 @@ private InputSplit[] getCombineSplits(JobConf job, int numSplits,
       }
       FileSystem inpFs = path.getFileSystem(job);
 
-      // Since there is no easy way of knowing whether MAPREDUCE-1597 is present in the tree or not,
-      // we use a configuration variable for the same
-      if (this.mrwork != null && !this.mrwork.getHadoopSupportsSplittable()) {
-        // The following code should be removed, once
-        // https://issues.apache.org/jira/browse/MAPREDUCE-1597 is fixed.
-        // Hadoop does not handle non-splittable files correctly for CombineFileInputFormat,
-        // so don't use CombineFileInputFormat for non-splittable files
-
-        //ie, dont't combine if inputformat is a TextInputFormat and has compression turned on
-
-        if (inputFormat instanceof TextInputFormat) {
-          Queue<Path> dirs = new LinkedList<Path>();
-          FileStatus fStats = inpFs.getFileStatus(path);
-
-          // If path is a directory
-          if (fStats.isDir()) {
-            dirs.offer(path);
-          } else if ((new CompressionCodecFactory(job)).getCodec(path) != null) {
-            //if compresssion codec is set, use HiveInputFormat.getSplits (don't combine)
-            splits = super.getSplits(job, numSplits);
-            return splits;
-          }
-
-          while (dirs.peek() != null) {
-            Path tstPath = dirs.remove();
-            FileStatus[] fStatus = inpFs.listStatus(tstPath, FileUtils.HIDDEN_FILES_PATH_FILTER);
-            for (int idx = 0; idx < fStatus.length; idx++) {
-              if (fStatus[idx].isDir()) {
-                dirs.offer(fStatus[idx].getPath());
-              } else if ((new CompressionCodecFactory(job)).getCodec(
-                  fStatus[idx].getPath()) != null) {
-                //if compresssion codec is set, use HiveInputFormat.getSplits (don't combine)
-                splits = super.getSplits(job, numSplits);
-                return splits;
-              }
-            }
-          }
-        }
-      }
       //don't combine if inputformat is a SymlinkTextInputFormat
       if (inputFormat instanceof SymlinkTextInputFormat) {
         splits = super.getSplits(job, numSplits);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
index 693d8c7e9f..4a325fbb8c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
@@ -933,8 +933,6 @@ public static MapredWork getMapRedWorkFromConf(HiveConf conf) {
     work.setPathToAliases(new LinkedHashMap<String, ArrayList<String>>());
     work.setPathToPartitionInfo(new LinkedHashMap<String, PartitionDesc>());
     work.setAliasToWork(new LinkedHashMap<String, Operator<? extends OperatorDesc>>());
-    work.setHadoopSupportsSplittable(
-        conf.getBoolVar(HiveConf.ConfVars.HIVE_COMBINE_INPUT_FORMAT_SUPPORTS_SPLITTABLE));
     return mrWork;
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java
index 2cb9257506..bc9b64543e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java
@@ -63,8 +63,6 @@ public class MapWork extends BaseWork {
 
   private static final Log LOG = LogFactory.getLog(MapWork.class);
 
-  private boolean hadoopSupportsSplittable;
-
   // use LinkedHashMap to make sure the iteration order is
   // deterministic, to ease testing
   private LinkedHashMap<String, ArrayList<String>> pathToAliases = new LinkedHashMap<String, ArrayList<String>>();
@@ -421,14 +419,6 @@ public boolean isMapperCannotSpanPartns() {
     return this.mapperCannotSpanPartns;
   }
 
-  public boolean getHadoopSupportsSplittable() {
-    return hadoopSupportsSplittable;
-  }
-
-  public void setHadoopSupportsSplittable(boolean hadoopSupportsSplittable) {
-    this.hadoopSupportsSplittable = hadoopSupportsSplittable;
-  }
-
   public String getIndexIntermediateFile() {
     return indexIntermediateFile;
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java
index 76926e7972..b50eaabdbe 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java
@@ -99,14 +99,7 @@ public static synchronized long getCountForMapJoinDumpFilePrefix() {
 
   @SuppressWarnings("nls")
   public static MapredWork getMapRedWork() {
-    try {
-      MapredWork work = new MapredWork();
-      work.getMapWork().setHadoopSupportsSplittable(Hive.get().getConf().getBoolVar(
-          HiveConf.ConfVars.HIVE_COMBINE_INPUT_FORMAT_SUPPORTS_SPLITTABLE));
-      return work;
-    } catch (HiveException ex) {
-      throw new RuntimeException(ex);
-    }
+    return new MapredWork();
   }
 
   public static TableDesc getDefaultTableDesc(CreateTableDesc directoryDesc,
