diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorMR.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorMR.java
index cca06a5704..f83b6db8bf 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorMR.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorMR.java
@@ -233,7 +233,7 @@ void run(HiveConf conf, String jobName, Table t, StorageDescriptor sd,
         launchCompactionJob(jobMinorCompact,
           null, CompactionType.MINOR, null,
           parsedDeltas.subList(jobSubId * maxDeltastoHandle, (jobSubId + 1) * maxDeltastoHandle),
-          maxDeltastoHandle, -1, conf, txnHandler, ci.id);
+          maxDeltastoHandle, -1, conf, txnHandler, ci.id, jobName);
       }
       //now recompute state since we've done minor compactions and have different 'best' set of deltas
       dir = AcidUtils.getAcidState(new Path(sd.getLocation()), conf, txns);
@@ -271,7 +271,7 @@ void run(HiveConf conf, String jobName, Table t, StorageDescriptor sd,
     }
 
     launchCompactionJob(job, baseDir, ci.type, dirsToSearch, dir.getCurrentDirectories(),
-      dir.getCurrentDirectories().size(), dir.getObsolete().size(), conf, txnHandler, ci.id);
+      dir.getCurrentDirectories().size(), dir.getObsolete().size(), conf, txnHandler, ci.id, jobName);
 
     su.gatherStats();
   }
@@ -279,7 +279,7 @@ private void launchCompactionJob(JobConf job, Path baseDir, CompactionType compa
                                    StringableList dirsToSearch,
                                    List<AcidUtils.ParsedDelta> parsedDeltas,
                                    int curDirNumber, int obsoleteDirNumber, HiveConf hiveConf,
-                                   TxnStore txnHandler, long id) throws IOException {
+                                   TxnStore txnHandler, long id, String jobName) throws IOException {
     job.setBoolean(IS_MAJOR, compactionType == CompactionType.MAJOR);
     if(dirsToSearch == null) {
       dirsToSearch = new StringableList();
@@ -314,7 +314,8 @@ private void launchCompactionJob(JobConf job, Path baseDir, CompactionType compa
     txnHandler.setHadoopJobId(rj.getID().toString(), id);
     rj.waitForCompletion();
     if (!rj.isSuccessful()) {
-      throw new IOException("Job failed!");
+      throw new IOException(compactionType == CompactionType.MAJOR ? "Major" : "Minor" +
+          " compactor job failed for " + jobName + "! Hadoop JobId: " + rj.getID() );
     }
   }
   /**
