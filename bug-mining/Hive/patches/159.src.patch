diff --git a/CHANGES.txt b/CHANGES.txt
index 22cecf527f..be827a57d7 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -163,6 +163,9 @@ Trunk - Unreleased
     HIVE-497. Fix predicate pushdowns when all the columns are not
     selected in the query. (Prasad Chakka via athusoo)
 
+    HIVE-500. Fix select from newly created table.
+    (Yongqiang He via zshao)
+
 Release 0.3.1 - Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
index 4b03680302..4f0d8d9ac5 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
@@ -332,7 +332,6 @@ public int execute() {
       throw new RuntimeException("Plan invalid, Reason: " + invalidReason);
     }
 
-    Utilities.setMapRedWork(job, work);
 
     String hiveScratchDir = HiveConf.getVar(job, HiveConf.ConfVars.SCRATCHDIR);
     Path jobScratchDir = new Path(hiveScratchDir + Utilities.randGen.nextInt());
@@ -365,6 +364,7 @@ public int execute() {
 
     try {
       addInputPaths(job, work, hiveScratchDir);
+      Utilities.setMapRedWork(job, work);
 
       // remove the pwd from conf file so that job tracker doesn't show this logs
       String pwd = job.get(HiveConf.ConfVars.METASTOREPWD.varname);
@@ -688,13 +688,15 @@ private void addInputPaths(JobConf job, mapredWork work, String hiveScratchDir)
         LOG.info("Changed input file to " + newPath.toString());
         
         // toggle the work
-        Map<String, ArrayList<String>> pathToAliases = work.getPathToAliases();
-        pathToAliases.put(newPath.toString(), pathToAliases.get(emptyFile));
+        LinkedHashMap<String, ArrayList<String>> pathToAliases = work.getPathToAliases();
+        pathToAliases.put(newPath.toUri().toString(), pathToAliases.get(emptyFile));
         pathToAliases.remove(emptyFile);
+        work.setPathToAliases(pathToAliases);
         
-        Map<String,partitionDesc> pathToPartitionInfo = work.getPathToPartitionInfo();
-        pathToPartitionInfo.put(newPath.toString(), pathToPartitionInfo.get(emptyFile));
+        LinkedHashMap<String,partitionDesc> pathToPartitionInfo = work.getPathToPartitionInfo();
+        pathToPartitionInfo.put(newPath.toUri().toString(), pathToPartitionInfo.get(emptyFile));
         pathToPartitionInfo.remove(emptyFile);
+        work.setPathToPartitionInfo(pathToPartitionInfo);
         
         String onefile = newPath.toString();
         RecordWriter recWriter = outFileFormat.newInstance().getHiveRecordWriter(job, newPath, Text.class, false, new Properties(), null);
