diff --git a/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergSerDe.java b/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergSerDe.java
index c215e48860..c365a9e5bf 100644
--- a/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergSerDe.java
+++ b/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergSerDe.java
@@ -31,6 +31,7 @@
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.hive_metastoreConstants;
 import org.apache.hadoop.hive.ql.session.SessionStateUtil;
+import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.AbstractSerDe;
 import org.apache.hadoop.hive.serde2.ColumnProjectionUtils;
 import org.apache.hadoop.hive.serde2.SerDeException;
@@ -166,22 +167,33 @@ private void createTableForCTAS(Configuration configuration, Properties serDePro
       serDeProperties.put(InputFormatConfig.PARTITION_SPEC, PartitionSpecParser.toJson(spec));
     }
 
+    // clean up the properties for table creation (so that internal serde props don't become table props)
+    Properties createProps = getCTASTableCreationProperties(serDeProperties);
+
     // create CTAS table
     LOG.info("Creating table {} for CTAS with schema: {}, and spec: {}",
         serDeProperties.get(Catalogs.NAME), tableSchema, serDeProperties.get(InputFormatConfig.PARTITION_SPEC));
-    Catalogs.createTable(configuration, serDeProperties);
+    Catalogs.createTable(configuration, createProps);
 
     // set this in the query state so that we can rollback the table in the lifecycle hook in case of failures
     SessionStateUtil.addResource(configuration, InputFormatConfig.CTAS_TABLE_NAME,
         serDeProperties.getProperty(Catalogs.NAME));
   }
 
-  private void assertNotVectorizedTez(Configuration configuration) {
-    if ("tez".equals(configuration.get("hive.execution.engine")) &&
-        "true".equals(configuration.get("hive.vectorized.execution.enabled"))) {
-      throw new UnsupportedOperationException("Vectorized execution on Tez is currently not supported when using " +
-          "Iceberg tables. Please set hive.vectorized.execution.enabled=false and rerun the query.");
-    }
+  private Properties getCTASTableCreationProperties(Properties serDeProperties) {
+    Properties tblProps = (Properties) serDeProperties.clone();
+    tblProps.remove(serdeConstants.LIST_PARTITION_COLUMNS);
+    tblProps.remove(serdeConstants.LIST_PARTITION_COLUMN_TYPES);
+    tblProps.remove(serdeConstants.LIST_PARTITION_COLUMN_COMMENTS);
+
+    tblProps.remove(serdeConstants.LIST_COLUMNS);
+    tblProps.remove(serdeConstants.LIST_COLUMN_TYPES);
+    tblProps.remove(serdeConstants.LIST_COLUMN_COMMENTS);
+
+    tblProps.remove(serdeConstants.COLUMN_NAME_DELIMITER);
+    tblProps.remove(serdeConstants.SERIALIZATION_LIB);
+    tblProps.remove(hive_metastoreConstants.TABLE_IS_CTAS);
+    return tblProps;
   }
 
   @Override
diff --git a/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergCTAS.java b/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergCTAS.java
index 14760ee1ab..4c3e642914 100644
--- a/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergCTAS.java
+++ b/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergCTAS.java
@@ -21,6 +21,7 @@
 
 import java.io.IOException;
 import java.util.List;
+import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.iceberg.AssertHelpers;
 import org.apache.iceberg.Table;
 import org.apache.iceberg.TableProperties;
@@ -88,6 +89,35 @@ public void testCTASPartitionedFromHiveTable() throws TException, InterruptedExc
     Assert.assertEquals("name", table.spec().fields().get(1).name());
   }
 
+  @Test
+  public void testCTASTblPropsAndLocationClause() throws Exception {
+    Assume.assumeTrue(HiveIcebergSerDe.CTAS_EXCEPTION_MSG, testTableType == TestTables.TestTableType.HIVE_CATALOG);
+
+    shell.executeStatement("CREATE TABLE source (id bigint, name string) PARTITIONED BY (dept string) STORED AS ORC");
+    shell.executeStatement(testTables.getInsertQuery(
+        HiveIcebergStorageHandlerTestUtils.CUSTOMER_RECORDS, TableIdentifier.of("default", "source"), false));
+
+    String location = temp.newFolder().toURI().toString();
+    shell.executeStatement(String.format(
+        "CREATE TABLE target PARTITIONED BY (dept, name) " +
+        "STORED BY ICEBERG STORED AS %s LOCATION '%s' TBLPROPERTIES ('customKey'='customValue') " +
+        "AS SELECT * FROM source", fileFormat.toString(), location));
+
+    // check table can be read back correctly
+    List<Object[]> objects = shell.executeStatement("SELECT id, name, dept FROM target ORDER BY id");
+    HiveIcebergTestUtils.validateData(HiveIcebergStorageHandlerTestUtils.CUSTOMER_RECORDS,
+        HiveIcebergTestUtils.valueForRow(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA, objects), 0);
+
+    // check table is created at the correct location
+    org.apache.hadoop.hive.metastore.api.Table tbl = shell.metastore().getTable("default", "target");
+    Assert.assertEquals(location, tbl.getSd().getLocation() + "/" /* HMS trims the trailing dash */);
+
+    // check if valid table properties are preserved, while serde props don't get preserved
+    Assert.assertEquals("customValue", tbl.getParameters().get("customKey"));
+    Assert.assertNull(tbl.getParameters().get(serdeConstants.LIST_COLUMNS));
+    Assert.assertNull(tbl.getParameters().get(serdeConstants.LIST_PARTITION_COLUMNS));
+  }
+
   @Test
   public void testCTASFailureRollback() throws IOException {
     Assume.assumeTrue(HiveIcebergSerDe.CTAS_EXCEPTION_MSG, testTableType == TestTables.TestTableType.HIVE_CATALOG);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index f66e784567..77aa78f060 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -7705,6 +7705,13 @@ protected Operator genFileSinkPlan(String dest, QB qb, Operator input)
       } else {
         tableDescriptor = PlanUtils.getTableDesc(tblDesc, cols, colTypes);
       }
+
+      // if available, set location in table desc properties
+      if (tblDesc != null && tblDesc.getLocation() != null && tableDescriptor != null &&
+          !tableDescriptor.getProperties().containsKey(hive_metastoreConstants.META_TABLE_LOCATION)) {
+        tableDescriptor.getProperties().setProperty(hive_metastoreConstants.META_TABLE_LOCATION, tblDesc.getLocation());
+      }
+
       // We need a specific rowObjectInspector in this case
       try {
         specificRowObjectInspector =
