diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index f03c1abe19..95c5c0efdd 100644
--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -2017,6 +2017,8 @@ public static enum ConfVars {
         "hive.zookeeper.quorum in their connection string."),
     HIVE_SERVER2_ZOOKEEPER_NAMESPACE("hive.server2.zookeeper.namespace", "hiveserver2",
         "The parent node in ZooKeeper used by HiveServer2 when supporting dynamic service discovery."),
+    HIVE_SERVER2_ZOOKEEPER_PUBLISH_CONFIGS("hive.server2.zookeeper.publish.configs", true,
+        "Whether we should publish HiveServer2's configs to ZooKeeper."),
 
     // HiveServer2 global init file location
     HIVE_SERVER2_GLOBAL_INIT_FILE_LOCATION("hive.server2.global.init.file.location", "${env:HIVE_CONF_DIR}",
diff --git a/itests/hive-unit/src/main/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java b/itests/hive-unit/src/main/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java
index 751d8eaed3..a9d9c76813 100644
--- a/itests/hive-unit/src/main/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java
+++ b/itests/hive-unit/src/main/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java
@@ -34,6 +34,7 @@
 import org.apache.hadoop.hive.metastore.MetaStoreUtils;
 import org.apache.hadoop.hive.ql.WindowsPathUtil;
 import org.apache.hadoop.hive.ql.exec.Utilities;
+import org.apache.hadoop.hive.ql.util.ZooKeeperHiveHelper;
 import org.apache.hadoop.hive.shims.HadoopShims.MiniDFSShim;
 import org.apache.hadoop.hive.shims.HadoopShims.MiniMrShim;
 import org.apache.hadoop.hive.shims.ShimLoader;
@@ -303,6 +304,13 @@ public CLIServiceClient getServiceClient() {
     return getServiceClientInternal();
   }
 
+  public HiveConf getServerConf() {
+    if (hiveServer2 != null) {
+      return hiveServer2.getHiveConf();
+    }
+    return null;
+  }
+
   public CLIServiceClient getServiceClientInternal() {
     for (Service service : hiveServer2.getServices()) {
       if (service instanceof ThriftBinaryCLIService) {
@@ -318,8 +326,9 @@ public CLIServiceClient getServiceClientInternal() {
   /**
    * return connection URL for this server instance
    * @return
+   * @throws Exception
    */
-  public String getJdbcURL() {
+  public String getJdbcURL() throws Exception {
     return getJdbcURL("default");
   }
 
@@ -327,8 +336,9 @@ public String getJdbcURL() {
    * return connection URL for this server instance
    * @param dbName - DB name to be included in the URL
    * @return
+   * @throws Exception
    */
-  public String getJdbcURL(String dbName) {
+  public String getJdbcURL(String dbName) throws Exception {
     return getJdbcURL(dbName, "");
   }
 
@@ -337,8 +347,9 @@ public String getJdbcURL(String dbName) {
    * @param dbName - DB name to be included in the URL
    * @param sessionConfExt - Addional string to be appended to sessionConf part of url
    * @return
+   * @throws Exception
    */
-  public String getJdbcURL(String dbName, String sessionConfExt) {
+  public String getJdbcURL(String dbName, String sessionConfExt) throws Exception {
     return getJdbcURL(dbName, sessionConfExt, "");
   }
 
@@ -348,8 +359,9 @@ public String getJdbcURL(String dbName, String sessionConfExt) {
    * @param sessionConfExt - Addional string to be appended to sessionConf part of url
    * @param hiveConfExt - Additional string to be appended to HiveConf part of url (excluding the ?)
    * @return
+   * @throws Exception
    */
-  public String getJdbcURL(String dbName, String sessionConfExt, String hiveConfExt) {
+  public String getJdbcURL(String dbName, String sessionConfExt, String hiveConfExt) throws Exception {
     sessionConfExt = (sessionConfExt == null ? "" : sessionConfExt);
     hiveConfExt = (hiveConfExt == null ? "" : hiveConfExt);
     String krbConfig = "";
@@ -359,7 +371,17 @@ public String getJdbcURL(String dbName, String sessionConfExt, String hiveConfEx
     if (isHttpTransportMode()) {
       sessionConfExt = "transportMode=http;httpPath=cliservice;" + sessionConfExt;
     }
-    String baseJdbcURL = getBaseJdbcURL() + dbName + ";" + krbConfig + ";" + sessionConfExt;
+    String baseJdbcURL;
+    if (isDynamicServiceDiscovery()) {
+      String serviceDiscoveryConfig =
+          "serviceDiscoveryMode=zooKeeper;zooKeeperNamespace="
+              + getServerConf().getVar(HiveConf.ConfVars.HIVE_SERVER2_ZOOKEEPER_NAMESPACE) + ";";
+      baseJdbcURL = getZKBaseJdbcURL() + dbName + ";" + serviceDiscoveryConfig;
+    }
+    else {
+      baseJdbcURL = getBaseJdbcURL() + dbName + ";";
+    }
+    baseJdbcURL = baseJdbcURL + krbConfig + ";" + sessionConfExt;
     if (!hiveConfExt.trim().equals("")) {
       baseJdbcURL = "?" + hiveConfExt;
     }
@@ -379,11 +401,35 @@ public String getBaseJdbcURL() {
     }
   }
 
+  /**
+   * Build zk base JDBC URL
+   * @return
+   */
+  private String getZKBaseJdbcURL() throws Exception {
+    HiveConf hiveConf = getServerConf();
+    if (hiveConf != null) {
+      String zkEnsemble =  ZooKeeperHiveHelper.getQuorumServers(hiveConf);
+      return "jdbc:hive2://" + zkEnsemble + "/";
+    }
+    throw new Exception("Server's HiveConf is null. Unable to read ZooKeeper configs.");
+  }
+
   private boolean isHttpTransportMode() {
     String transportMode = getConfProperty(ConfVars.HIVE_SERVER2_TRANSPORT_MODE.varname);
     return transportMode != null && (transportMode.equalsIgnoreCase(HS2_HTTP_MODE));
   }
 
+  private boolean isDynamicServiceDiscovery() throws Exception {
+    HiveConf hiveConf = getServerConf();
+    if (hiveConf == null) {
+      throw new Exception("Server's HiveConf is null. Unable to read ZooKeeper configs.");
+    }
+    if (hiveConf.getBoolVar(ConfVars.HIVE_SERVER2_SUPPORT_DYNAMIC_SERVICE_DISCOVERY)) {
+      return true;
+    }
+    return false;
+  }
+
   public static String getJdbcDriverName() {
     return driverName;
   }
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithLocalClusterSpark.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithLocalClusterSpark.java
index f649fc2f87..cabddea5c6 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithLocalClusterSpark.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithLocalClusterSpark.java
@@ -92,7 +92,7 @@ public static void beforeTest() throws Exception {
   }
 
   // setup DB
-  private static void createDb() throws SQLException {
+  private static void createDb() throws Exception {
     Connection conn = DriverManager.
         getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
     Statement stmt2 = conn.createStatement();
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniMr.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniMr.java
index bcd65a9df5..637e51a3df 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniMr.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniMr.java
@@ -83,7 +83,7 @@ public static void beforeTest() throws Exception {
   }
 
   // setup DB
-  private static void createDb() throws SQLException {
+  private static void createDb() throws Exception {
     Connection conn = DriverManager.
         getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
     Statement stmt2 = conn.createStatement();
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestMultiSessionsHS2WithLocalClusterSpark.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestMultiSessionsHS2WithLocalClusterSpark.java
index 0c3479d37c..e3f9646b59 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestMultiSessionsHS2WithLocalClusterSpark.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestMultiSessionsHS2WithLocalClusterSpark.java
@@ -101,7 +101,7 @@ public static void beforeTest() throws Exception {
   }
 
   // setup DB
-  private static void createDb() throws SQLException {
+  private static void createDb() throws Exception {
     Connection conn = DriverManager.
       getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
     Statement stmt2 = conn.createStatement();
@@ -124,7 +124,7 @@ public void tearDown() throws Exception {
     closeConnection();
   }
 
-  private void createConnection() throws SQLException {
+  private void createConnection() throws Exception {
     Connection connection = DriverManager.getConnection(miniHS2.getJdbcURL(dbName),
       System.getProperty("user.name"), "bar");
     Statement statement = connection.createStatement();
@@ -216,7 +216,7 @@ public Void call() throws Exception {
   }
 
   private void testKvQuery(String queryStr, String resultVal)
-    throws SQLException {
+    throws Exception {
     createConnection();
     verifyResult(queryStr, resultVal, 2);
     closeConnection();
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestServiceDiscoveryWithMiniHS2.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestServiceDiscoveryWithMiniHS2.java
new file mode 100644
index 0000000000..907ccb0e79
--- /dev/null
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestServiceDiscoveryWithMiniHS2.java
@@ -0,0 +1,132 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hive.jdbc;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+import java.sql.Connection;
+import java.sql.DriverManager;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.Statement;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.curator.test.TestingServer;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
+import org.apache.hive.jdbc.miniHS2.MiniHS2;
+import org.junit.After;
+import org.junit.AfterClass;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+public class TestServiceDiscoveryWithMiniHS2 {
+  private static MiniHS2 miniHS2 = null;
+  private static HiveConf hiveConf;
+  private static TestingServer zkServer;
+  private static String zkRootNamespace = "hs2test";
+  private static String dataFileDir;
+  private static Path kvDataFilePath;
+
+  private Connection hs2Conn = null;
+
+  @BeforeClass
+  public static void beforeTest() throws Exception {
+    zkServer = new TestingServer();
+    Class.forName(MiniHS2.getJdbcDriverName());
+    hiveConf = new HiveConf();
+    hiveConf.setBoolVar(ConfVars.HIVE_SUPPORT_CONCURRENCY, false);
+    // Set up zookeeper dynamic service discovery configs
+    enableZKServiceDiscoveryConfigs(hiveConf);
+    dataFileDir = hiveConf.get("test.data.files").replace('\\', '/').replace("c:", "");
+    kvDataFilePath = new Path(dataFileDir, "kv1.txt");
+  }
+
+  @AfterClass
+  public static void afterTest() throws Exception {
+    if (zkServer != null) {
+      zkServer.close();
+      zkServer = null;
+    }
+  }
+
+  @Before
+  public void setUp() throws Exception {
+    miniHS2 = new MiniHS2(hiveConf);
+  }
+
+  @After
+  public void tearDown() throws Exception {
+    if (hs2Conn != null) {
+      hs2Conn.close();
+    }
+    if ((miniHS2 != null) && miniHS2.isStarted()) {
+      miniHS2.stop();
+    }
+  }
+
+  @Test
+  public void testConnectionWithConfigsPublished() throws Exception {
+    Map<String, String> confOverlay = new HashMap<String, String>();
+    confOverlay.put("hive.server2.zookeeper.publish.configs", "true");
+    miniHS2.start(confOverlay);
+    openConnectionAndRunQuery();
+  }
+
+  @Test
+  public void testConnectionWithoutConfigsPublished() throws Exception {
+    Map<String, String> confOverlay = new HashMap<String, String>();
+    confOverlay.put("hive.server2.zookeeper.publish.configs", "false");
+    miniHS2.start(confOverlay);
+    openConnectionAndRunQuery();
+  }
+
+  private static void enableZKServiceDiscoveryConfigs(HiveConf conf) {
+    conf.setBoolVar(ConfVars.HIVE_SERVER2_SUPPORT_DYNAMIC_SERVICE_DISCOVERY, true);
+    conf.setVar(ConfVars.HIVE_ZOOKEEPER_QUORUM, zkServer.getConnectString());
+    conf.setVar(ConfVars.HIVE_SERVER2_ZOOKEEPER_NAMESPACE, zkRootNamespace);
+  }
+
+  private Connection getConnection(String jdbcURL, String user, String pwd) throws SQLException {
+    Connection conn = DriverManager.getConnection(jdbcURL, user, pwd);
+    return conn;
+  }
+
+  private void openConnectionAndRunQuery() throws Exception {
+    hs2Conn = getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
+    String tableName = "testTab1";
+    Statement stmt = hs2Conn.createStatement();
+    // create table
+    stmt.execute("DROP TABLE IF EXISTS " + tableName);
+    stmt.execute("CREATE TABLE " + tableName
+        + " (under_col INT COMMENT 'the under column', value STRING) COMMENT ' test table'");
+    // load data
+    stmt.execute("load data local inpath '" + kvDataFilePath.toString() + "' into table "
+        + tableName);
+    ResultSet res = stmt.executeQuery("SELECT * FROM " + tableName);
+    assertTrue(res.next());
+    assertEquals("val_238", res.getString(2));
+    res.close();
+    stmt.close();
+  }
+}
\ No newline at end of file
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestHS2AuthzContext.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestHS2AuthzContext.java
index 0bb3c0a5ea..c43776b503 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestHS2AuthzContext.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestHS2AuthzContext.java
@@ -101,7 +101,7 @@ public void testAuthzContextContentsCmdProcessorCmd() throws Exception {
     verifyContextContents("dfs -ls /", "-ls /");
   }
 
-  private void verifyContextContents(final String cmd, String ctxCmd) throws SQLException,
+  private void verifyContextContents(final String cmd, String ctxCmd) throws Exception,
       HiveAuthzPluginException, HiveAccessControlException {
     Connection hs2Conn = getConnection("user1");
     Statement stmt = hs2Conn.createStatement();
@@ -126,7 +126,7 @@ private void verifyContextContents(final String cmd, String ctxCmd) throws SQLEx
 
   }
 
-  private Connection getConnection(String userName) throws SQLException {
+  private Connection getConnection(String userName) throws Exception {
     return DriverManager.getConnection(miniHS2.getJdbcURL(), userName, "bar");
   }
 
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcMetadataApiAuth.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcMetadataApiAuth.java
index 19b311d425..692bfa0d89 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcMetadataApiAuth.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcMetadataApiAuth.java
@@ -253,7 +253,7 @@ private void assertErrorContains(SQLException e, String deniedErr) {
     }
   }
 
-  private static Connection getConnection(String userName) throws SQLException {
+  private static Connection getConnection(String userName) throws Exception {
     return DriverManager.getConnection(miniHS2.getJdbcURL(), userName, "bar");
   }
 
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcWithSQLAuthorization.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcWithSQLAuthorization.java
index dacde45bb6..5e653ec75c 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcWithSQLAuthorization.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcWithSQLAuthorization.java
@@ -126,7 +126,7 @@ public void testAuthorization1() throws Exception {
     }
   }
 
-  private Connection getConnection(String userName) throws SQLException {
+  private Connection getConnection(String userName) throws Exception {
     return DriverManager.getConnection(miniHS2.getJdbcURL(), userName, "bar");
   }
 
diff --git a/jdbc/src/java/org/apache/hive/jdbc/ZooKeeperHiveClientHelper.java b/jdbc/src/java/org/apache/hive/jdbc/ZooKeeperHiveClientHelper.java
index 1ca77a1707..8d6003ad06 100644
--- a/jdbc/src/java/org/apache/hive/jdbc/ZooKeeperHiveClientHelper.java
+++ b/jdbc/src/java/org/apache/hive/jdbc/ZooKeeperHiveClientHelper.java
@@ -71,12 +71,27 @@ static void configureConnParams(JdbcConnectionParams connParams)
       // Now pick a server node randomly
       serverNode = serverHosts.get(randomizer.nextInt(serverHosts.size()));
       connParams.setCurrentHostZnodePath(serverNode);
-      // Read config string from the znode for this server node
-      String serverConfStr =
+      // Read data from the znode for this server node
+      // This data could be either config string (new releases) or server end
+      // point (old releases)
+      String dataStr =
           new String(
               zooKeeperClient.getData().forPath("/" + zooKeeperNamespace + "/" + serverNode),
               Charset.forName("UTF-8"));
-      applyConfs(serverConfStr, connParams);
+      Matcher matcher = kvPattern.matcher(dataStr);
+      // If dataStr is not null and dataStr is not a KV pattern,
+      // it must be the server uri added by an older version HS2
+      if ((dataStr != null) && (!matcher.find())) {
+        String[] split = dataStr.split(":");
+        if (split.length != 2) {
+          throw new ZooKeeperHiveClientException("Unable to read HiveServer2 uri from ZooKeeper: "
+              + dataStr);
+        }
+        connParams.setHost(split[0]);
+        connParams.setPort(Integer.parseInt(split[1]));
+      } else {
+        applyConfs(dataStr, connParams);
+      }
     } catch (Exception e) {
       throw new ZooKeeperHiveClientException("Unable to read HiveServer2 configs from ZooKeeper", e);
     } finally {
diff --git a/service/src/java/org/apache/hive/service/server/HiveServer2.java b/service/src/java/org/apache/hive/service/server/HiveServer2.java
index ab834b9463..d95f78f829 100644
--- a/service/src/java/org/apache/hive/service/server/HiveServer2.java
+++ b/service/src/java/org/apache/hive/service/server/HiveServer2.java
@@ -254,10 +254,6 @@ private void addServerInstanceToZooKeeper(HiveConf hiveConf) throws Exception {
     String rootNamespace = hiveConf.getVar(HiveConf.ConfVars.HIVE_SERVER2_ZOOKEEPER_NAMESPACE);
     String instanceURI = getServerInstanceURI();
     setUpZooKeeperAuth(hiveConf);
-    // HiveServer2 configs that this instance will publish to ZooKeeper,
-    // so that the clients can read these and configure themselves properly.
-    Map<String, String> confsToPublish = new HashMap<String, String>();
-    addConfsToPublish(hiveConf, confsToPublish);
     int sessionTimeout =
         (int) hiveConf.getTimeVar(HiveConf.ConfVars.HIVE_ZOOKEEPER_SESSION_TIMEOUT,
             TimeUnit.MILLISECONDS);
@@ -291,8 +287,16 @@ private void addServerInstanceToZooKeeper(HiveConf hiveConf) throws Exception {
               + ZooKeeperHiveHelper.ZOOKEEPER_PATH_SEPARATOR + "serverUri=" + instanceURI + ";"
               + "version=" + HiveVersionInfo.getVersion() + ";" + "sequence=";
       String znodeData = "";
-      // Publish configs for this instance as the data on the node
-      znodeData = Joiner.on(';').withKeyValueSeparator("=").join(confsToPublish);
+      if (hiveConf.getBoolVar(HiveConf.ConfVars.HIVE_SERVER2_ZOOKEEPER_PUBLISH_CONFIGS)) {
+        // HiveServer2 configs that this instance will publish to ZooKeeper,
+        // so that the clients can read these and configure themselves properly.
+        Map<String, String> confsToPublish = new HashMap<String, String>();
+        addConfsToPublish(hiveConf, confsToPublish);
+        // Publish configs for this instance as the data on the node
+        znodeData = Joiner.on(';').withKeyValueSeparator("=").join(confsToPublish);
+      } else {
+        znodeData = instanceURI;
+      }
       byte[] znodeDataUTF8 = znodeData.getBytes(Charset.forName("UTF-8"));
       znode =
           new PersistentEphemeralNode(zooKeeperClient,
@@ -334,12 +338,12 @@ private void addConfsToPublish(HiveConf hiveConf, Map<String, String> confsToPub
     // Transport specific confs
     if (isHTTPTransportMode(hiveConf)) {
       confsToPublish.put(ConfVars.HIVE_SERVER2_THRIFT_HTTP_PORT.varname,
-          hiveConf.getVar(ConfVars.HIVE_SERVER2_THRIFT_HTTP_PORT));
+          Integer.toString(hiveConf.getIntVar(ConfVars.HIVE_SERVER2_THRIFT_HTTP_PORT)));
       confsToPublish.put(ConfVars.HIVE_SERVER2_THRIFT_HTTP_PATH.varname,
           hiveConf.getVar(ConfVars.HIVE_SERVER2_THRIFT_HTTP_PATH));
     } else {
       confsToPublish.put(ConfVars.HIVE_SERVER2_THRIFT_PORT.varname,
-          hiveConf.getVar(ConfVars.HIVE_SERVER2_THRIFT_PORT));
+          Integer.toString(hiveConf.getIntVar(ConfVars.HIVE_SERVER2_THRIFT_PORT)));
       confsToPublish.put(ConfVars.HIVE_SERVER2_THRIFT_SASL_QOP.varname,
           hiveConf.getVar(ConfVars.HIVE_SERVER2_THRIFT_SASL_QOP));
     }
@@ -352,7 +356,7 @@ private void addConfsToPublish(HiveConf hiveConf, Map<String, String> confsToPub
     }
     // SSL conf
     confsToPublish.put(ConfVars.HIVE_SERVER2_USE_SSL.varname,
-        hiveConf.getVar(ConfVars.HIVE_SERVER2_USE_SSL));
+        Boolean.toString(hiveConf.getBoolVar(ConfVars.HIVE_SERVER2_USE_SSL)));
   }
 
   /**
@@ -443,6 +447,17 @@ private String getServerHost() throws Exception {
   @Override
   public synchronized void start() {
     super.start();
+    // If we're supporting dynamic service discovery, we'll add the service uri for this
+    // HiveServer2 instance to Zookeeper as a znode.
+    HiveConf hiveConf = this.getHiveConf();
+    if (hiveConf.getBoolVar(ConfVars.HIVE_SERVER2_SUPPORT_DYNAMIC_SERVICE_DISCOVERY)) {
+      try {
+        addServerInstanceToZooKeeper(hiveConf);
+      } catch (Exception e) {
+        LOG.error("Error adding this HiveServer2 instance to ZooKeeper: ", e);
+        throw new ServiceException(e);
+      }
+    }
     if (webServer != null) {
       try {
         webServer.start();
@@ -533,12 +548,6 @@ private static void startHiveServer2() throws Throwable {
             "warned upon.", t);
         }
 
-        // If we're supporting dynamic service discovery, we'll add the service uri for this
-        // HiveServer2 instance to Zookeeper as a znode.
-        if (hiveConf.getBoolVar(ConfVars.HIVE_SERVER2_SUPPORT_DYNAMIC_SERVICE_DISCOVERY)) {
-          server.addServerInstanceToZooKeeper(hiveConf);
-        }
-
         if (sessionPool != null) {
           sessionPool.startPool();
         }
