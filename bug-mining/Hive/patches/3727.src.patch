diff --git a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/DefaultOutputFormatContainer.java b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/DefaultOutputFormatContainer.java
index 3a07b0ca7c..f620b83d19 100644
--- a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/DefaultOutputFormatContainer.java
+++ b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/DefaultOutputFormatContainer.java
@@ -51,8 +51,9 @@ public DefaultOutputFormatContainer(org.apache.hadoop.mapred.OutputFormat<Writab
     super(of);
   }
 
-  static synchronized String getOutputName(int partition) {
-    return "part-" + NUMBER_FORMAT.format(partition);
+  static synchronized String getOutputName(TaskAttemptContext context) {
+    return context.getConfiguration().get("mapreduce.output.basename", "part")
+        + "-" + NUMBER_FORMAT.format(context.getTaskAttemptID().getTaskID().getId());
   }
 
   /**
@@ -65,7 +66,7 @@ static synchronized String getOutputName(int partition) {
   @Override
   public RecordWriter<WritableComparable<?>, HCatRecord>
   getRecordWriter(TaskAttemptContext context) throws IOException, InterruptedException {
-    String name = getOutputName(context.getTaskAttemptID().getTaskID().getId());
+    String name = getOutputName(context);
     return new DefaultRecordWriterContainer(context,
       getBaseOutputFormat().getRecordWriter(null, new JobConf(context.getConfiguration()), name, InternalUtil.createReporter(context)));
   }
diff --git a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/DynamicPartitionFileRecordWriterContainer.java b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/DynamicPartitionFileRecordWriterContainer.java
index 60f1b60551..320ace4352 100644
--- a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/DynamicPartitionFileRecordWriterContainer.java
+++ b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/DynamicPartitionFileRecordWriterContainer.java
@@ -205,7 +205,8 @@ protected LocalFileWriter getLocalFileWriter(HCatRecord value) throws IOExceptio
 
       Path parentDir = new Path(currTaskContext.getConfiguration().get("mapred.work.output.dir"));
       Path childPath =
-          new Path(parentDir, FileOutputFormat.getUniqueFile(currTaskContext, "part", ""));
+          new Path(parentDir, FileOutputFormat.getUniqueFile(currTaskContext,
+              currTaskContext.getConfiguration().get("mapreduce.output.basename", "part"), ""));
 
       RecordWriter baseRecordWriter =
           baseOF.getRecordWriter(parentDir.getFileSystem(currTaskContext.getConfiguration()),
diff --git a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputFormatContainer.java b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputFormatContainer.java
index 001b59bbcf..95ee3b4d1a 100644
--- a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputFormatContainer.java
+++ b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputFormatContainer.java
@@ -97,7 +97,8 @@ public RecordWriter<WritableComparable<?>, HCatRecord> getRecordWriter(TaskAttem
           (org.apache.hadoop.mapred.RecordWriter)null, context);
     } else {
       Path parentDir = new Path(context.getConfiguration().get("mapred.work.output.dir"));
-      Path childPath = new Path(parentDir,FileOutputFormat.getUniqueName(new JobConf(context.getConfiguration()), "part"));
+      Path childPath = new Path(parentDir,FileOutputFormat.getUniqueName(new JobConf(context.getConfiguration()),
+               context.getConfiguration().get("mapreduce.output.basename", "part")));
 
       rw = new StaticPartitionFileRecordWriterContainer(
           getBaseOutputFormat().getRecordWriter(
