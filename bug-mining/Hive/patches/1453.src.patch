diff --git a/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java b/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java
index 601bcb36ab..c658dbd282 100644
--- a/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java
+++ b/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java
@@ -31,8 +31,9 @@
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.sql.Types;
+import java.util.ArrayList;
 import java.util.HashMap;
-import java.util.HashSet;
+import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
@@ -460,6 +461,85 @@ public void testNullType() throws Exception {
     }
   }
 
+  // executeQuery should always throw a SQLException,
+  // when it executes a non-ResultSet query (like create)
+  public void testExecuteQueryException() throws Exception {
+    Statement stmt = con.createStatement();
+    try {
+      stmt.executeQuery("create table test_t2 (under_col int, value string)");
+      fail("Expecting SQLException");
+    }
+    catch (SQLException e) {
+      System.out.println("Caught an expected SQLException: " + e.getMessage());
+    }
+    finally {
+      stmt.close();
+    }
+  }
+
+  private void checkResultSetExpected(Statement stmt, List<String> setupQueries, String testQuery,
+      boolean isExpectedResultSet) throws Exception {
+    boolean hasResultSet;
+    // execute the setup queries
+    for(String setupQuery: setupQueries) {
+      try {
+        stmt.execute(setupQuery);
+      } catch (Exception e) {
+        failWithExceptionMsg(e);
+      }
+    }
+    // execute the test query
+    try {
+      hasResultSet = stmt.execute(testQuery);
+      assertEquals(hasResultSet, isExpectedResultSet);
+    }
+    catch(Exception e) {
+      failWithExceptionMsg(e);
+    }
+  }
+
+  private void failWithExceptionMsg(Exception e) {
+    e.printStackTrace();
+    fail(e.toString());
+  }
+
+  public void testNullResultSet() throws Exception {
+    List<String> setupQueries = new ArrayList<String>();
+    String testQuery;
+    boolean hasResultSet;
+    Statement stmt = con.createStatement();
+
+    // -select- should return a ResultSet
+    try {
+      stmt.executeQuery("select * from " + tableName);
+      System.out.println("select: success");
+    }
+    catch(SQLException e) {
+      failWithExceptionMsg(e);
+    }
+
+    // -create- should not return a ResultSet
+    setupQueries.add("drop table test_t1");
+    testQuery = "create table test_t1 (under_col int, value string)";
+    checkResultSetExpected(stmt, setupQueries, testQuery, false);
+    setupQueries.clear();
+
+    // -create table as select- should not return a ResultSet
+    setupQueries.add("drop table test_t1");
+    testQuery = "create table test_t1 as select * from " + tableName;
+    checkResultSetExpected(stmt, setupQueries, testQuery, false);
+    setupQueries.clear();
+
+    // -insert table as select- should not return a ResultSet
+    setupQueries.add("drop table test_t1");
+    setupQueries.add("create table test_t1 (under_col int, value string)");
+    testQuery = "insert into table test_t1 select under_col, value from "  + tableName;
+    checkResultSetExpected(stmt, setupQueries, testQuery, false);
+    setupQueries.clear();
+
+    stmt.close();
+  }
+
   public void testDataTypes() throws Exception {
     Statement stmt = con.createStatement();
 
diff --git a/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java b/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java
index 976a1ef620..611bbbf86f 100644
--- a/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java
+++ b/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java
@@ -19,6 +19,7 @@
 package org.apache.hive.service.cli.operation;
 
 import java.io.IOException;
+import java.io.Serializable;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.List;
@@ -30,6 +31,8 @@
 import org.apache.hadoop.hive.metastore.api.Schema;
 import org.apache.hadoop.hive.ql.CommandNeedRetryException;
 import org.apache.hadoop.hive.ql.Driver;
+import org.apache.hadoop.hive.ql.exec.ExplainTask;
+import org.apache.hadoop.hive.ql.exec.Task;
 import org.apache.hadoop.hive.ql.parse.VariableSubstitution;
 import org.apache.hadoop.hive.ql.processors.CommandProcessorResponse;
 import org.apache.hadoop.hive.ql.session.SessionState;
@@ -99,12 +102,28 @@ public void run() throws HiveSQLException {
       }
 
       mResultSchema = driver.getSchema();
-      if (mResultSchema != null && mResultSchema.isSetFieldSchemas()) {
+
+      // hasResultSet should be true only if the query has a FetchTask
+      // "explain" is an exception for now
+      if(driver.getPlan().getFetchTask() != null) {
+        //Schema has to be set
+        if (mResultSchema == null || !mResultSchema.isSetFieldSchemas()) {
+          throw new HiveSQLException("Error running query: Schema and FieldSchema " +
+              "should be set when query plan has a FetchTask");
+        }
         resultSchema = new TableSchema(mResultSchema);
         setHasResultSet(true);
       } else {
         setHasResultSet(false);
       }
+      // Set hasResultSet true if the plan has ExplainTask
+      // TODO explain should use a FetchTask for reading
+      for (Task<? extends Serializable> task: driver.getPlan().getRootTasks()) {
+        if (task.getClass() == ExplainTask.class) {
+          setHasResultSet(true);
+          break;
+        }
+      }
     } catch (HiveSQLException e) {
       setState(OperationState.ERROR);
       throw e;
