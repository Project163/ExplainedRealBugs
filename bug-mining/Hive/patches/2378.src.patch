diff --git a/contrib/src/test/results/clientnegative/case_with_row_sequence.q.out b/contrib/src/test/results/clientnegative/case_with_row_sequence.q.out
index db564ff8cc..afc492ccca 100644
--- a/contrib/src/test/results/clientnegative/case_with_row_sequence.q.out
+++ b/contrib/src/test/results/clientnegative/case_with_row_sequence.q.out
@@ -5,11 +5,11 @@ POSTHOOK: type: DROPFUNCTION
 PREHOOK: query: create temporary function row_sequence as 
 'org.apache.hadoop.hive.contrib.udf.UDFRowSequence'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: row_sequence
 POSTHOOK: query: create temporary function row_sequence as 
 'org.apache.hadoop.hive.contrib.udf.UDFRowSequence'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: row_sequence
 PREHOOK: query: -- make sure a stateful function inside of CASE throws an exception
 -- since the short-circuiting requirements are contradictory
 SELECT CASE WHEN 3 > 2 THEN 10 WHEN row_sequence() > 5 THEN 20 ELSE 30 END
diff --git a/contrib/src/test/results/clientnegative/invalid_row_sequence.q.out b/contrib/src/test/results/clientnegative/invalid_row_sequence.q.out
index 89646a2ac2..8f3c0b3b0c 100644
--- a/contrib/src/test/results/clientnegative/invalid_row_sequence.q.out
+++ b/contrib/src/test/results/clientnegative/invalid_row_sequence.q.out
@@ -2,18 +2,18 @@ PREHOOK: query: -- Verify that a stateful UDF cannot be used outside of the SELE
 
 drop temporary function row_sequence
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: row_sequence
 POSTHOOK: query: -- Verify that a stateful UDF cannot be used outside of the SELECT list
 
 drop temporary function row_sequence
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: row_sequence
 PREHOOK: query: create temporary function row_sequence as 
 'org.apache.hadoop.hive.contrib.udf.UDFRowSequence'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: row_sequence
 POSTHOOK: query: create temporary function row_sequence as 
 'org.apache.hadoop.hive.contrib.udf.UDFRowSequence'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: row_sequence
 FAILED: SemanticException [Error 10084]: Stateful UDF's can only be invoked in the SELECT list
diff --git a/contrib/src/test/results/clientnegative/udtf_explode2.q.out b/contrib/src/test/results/clientnegative/udtf_explode2.q.out
index 87dc534291..dd1f1af078 100644
--- a/contrib/src/test/results/clientnegative/udtf_explode2.q.out
+++ b/contrib/src/test/results/clientnegative/udtf_explode2.q.out
@@ -1,7 +1,7 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION explode2 AS 'org.apache.hadoop.hive.contrib.udtf.example.GenericUDTFExplode2'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: explode2
 POSTHOOK: query: CREATE TEMPORARY FUNCTION explode2 AS 'org.apache.hadoop.hive.contrib.udtf.example.GenericUDTFExplode2'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: explode2
 FAILED: SemanticException [Error 10083]: The number of aliases supplied in the AS clause does not match the number of columns output by the UDTF expected 2 aliases but got 1
diff --git a/contrib/src/test/results/clientpositive/dboutput.q.out b/contrib/src/test/results/clientpositive/dboutput.q.out
index 909ae2e809..d953acd53b 100644
--- a/contrib/src/test/results/clientpositive/dboutput.q.out
+++ b/contrib/src/test/results/clientpositive/dboutput.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION dboutput AS 'org.apache.hadoop.hive.contrib.genericudf.example.GenericUDFDBOutput'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: dboutput
 POSTHOOK: query: CREATE TEMPORARY FUNCTION dboutput AS 'org.apache.hadoop.hive.contrib.genericudf.example.GenericUDFDBOutput'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: dboutput
 PREHOOK: query: DESCRIBE FUNCTION dboutput
 PREHOOK: type: DESCFUNCTION
 POSTHOOK: query: DESCRIBE FUNCTION dboutput
@@ -186,7 +186,7 @@ POSTHOOK: Input: default@src
 #### A masked pattern was here ####
 PREHOOK: query: DROP TEMPORARY FUNCTION dboutput
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: dboutput
 POSTHOOK: query: DROP TEMPORARY FUNCTION dboutput
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: dboutput
diff --git a/contrib/src/test/results/clientpositive/lateral_view_explode2.q.out b/contrib/src/test/results/clientpositive/lateral_view_explode2.q.out
index 4b849fa774..74a7e1719f 100644
--- a/contrib/src/test/results/clientpositive/lateral_view_explode2.q.out
+++ b/contrib/src/test/results/clientpositive/lateral_view_explode2.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION explode2 AS 'org.apache.hadoop.hive.contrib.udtf.example.GenericUDTFExplode2'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: explode2
 POSTHOOK: query: CREATE TEMPORARY FUNCTION explode2 AS 'org.apache.hadoop.hive.contrib.udtf.example.GenericUDTFExplode2'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: explode2
 PREHOOK: query: SELECT col1, col2 FROM src LATERAL VIEW explode2(array(1,2,3)) myTable AS col1, col2 LIMIT 3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -17,7 +17,7 @@ POSTHOOK: Input: default@src
 3	3
 PREHOOK: query: DROP TEMPORARY FUNCTION explode2
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: explode2
 POSTHOOK: query: DROP TEMPORARY FUNCTION explode2
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: explode2
diff --git a/contrib/src/test/results/clientpositive/udaf_example_avg.q.out b/contrib/src/test/results/clientpositive/udaf_example_avg.q.out
index 3786078251..97523c65d0 100644
--- a/contrib/src/test/results/clientpositive/udaf_example_avg.q.out
+++ b/contrib/src/test/results/clientpositive/udaf_example_avg.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION example_avg AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleAvg'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_avg
 POSTHOOK: query: CREATE TEMPORARY FUNCTION example_avg AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleAvg'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_avg
 PREHOOK: query: EXPLAIN
 SELECT example_avg(substr(value,5)),
        example_avg(IF(substr(value,5) > 250, NULL, substr(value,5)))
@@ -77,7 +77,7 @@ POSTHOOK: Input: default@src
 260.182	134.82926829268294
 PREHOOK: query: DROP TEMPORARY FUNCTION example_avg
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_avg
 POSTHOOK: query: DROP TEMPORARY FUNCTION example_avg
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_avg
diff --git a/contrib/src/test/results/clientpositive/udaf_example_group_concat.q.out b/contrib/src/test/results/clientpositive/udaf_example_group_concat.q.out
index 83b480296c..91d1702037 100644
--- a/contrib/src/test/results/clientpositive/udaf_example_group_concat.q.out
+++ b/contrib/src/test/results/clientpositive/udaf_example_group_concat.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION example_group_concat AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleGroupConcat'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_group_concat
 POSTHOOK: query: CREATE TEMPORARY FUNCTION example_group_concat AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleGroupConcat'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_group_concat
 PREHOOK: query: EXPLAIN
 SELECT substr(value,5,1), example_group_concat("(", key, ":", value, ")")
 FROM src
@@ -90,7 +90,7 @@ POSTHOOK: Input: default@src
 9	(90:val_90)(90:val_90)(90:val_90)(92:val_92)(95:val_95)(95:val_95)(96:val_96)(97:val_97)(97:val_97)(98:val_98)(98:val_98)(9:val_9)
 PREHOOK: query: DROP TEMPORARY FUNCTION example_group_concat
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_group_concat
 POSTHOOK: query: DROP TEMPORARY FUNCTION example_group_concat
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_group_concat
diff --git a/contrib/src/test/results/clientpositive/udaf_example_max.q.out b/contrib/src/test/results/clientpositive/udaf_example_max.q.out
index b68ec6170b..466dc8022a 100644
--- a/contrib/src/test/results/clientpositive/udaf_example_max.q.out
+++ b/contrib/src/test/results/clientpositive/udaf_example_max.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION example_max AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleMax'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_max
 POSTHOOK: query: CREATE TEMPORARY FUNCTION example_max AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleMax'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_max
 PREHOOK: query: DESCRIBE FUNCTION EXTENDED example_max
 PREHOOK: type: DESCFUNCTION
 POSTHOOK: query: DESCRIBE FUNCTION EXTENDED example_max
@@ -82,7 +82,7 @@ POSTHOOK: Input: default@src
 98	98
 PREHOOK: query: DROP TEMPORARY FUNCTION example_max
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_max
 POSTHOOK: query: DROP TEMPORARY FUNCTION example_max
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_max
diff --git a/contrib/src/test/results/clientpositive/udaf_example_max_n.q.out b/contrib/src/test/results/clientpositive/udaf_example_max_n.q.out
index 62632e3e61..f31866e442 100644
--- a/contrib/src/test/results/clientpositive/udaf_example_max_n.q.out
+++ b/contrib/src/test/results/clientpositive/udaf_example_max_n.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION example_max_n AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleMaxN'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_max_n
 POSTHOOK: query: CREATE TEMPORARY FUNCTION example_max_n AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleMaxN'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_max_n
 PREHOOK: query: EXPLAIN
 SELECT example_max_n(substr(value,5),10),
        example_max_n(IF(substr(value,5) > 250, NULL, substr(value,5)),10)
@@ -77,7 +77,7 @@ POSTHOOK: Input: default@src
 [498.0,498.0,498.0,497.0,496.0,495.0,494.0,493.0,492.0,492.0]	[249.0,248.0,247.0,244.0,242.0,242.0,241.0,239.0,239.0,238.0]
 PREHOOK: query: DROP TEMPORARY FUNCTION example_max_n
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_max_n
 POSTHOOK: query: DROP TEMPORARY FUNCTION example_max_n
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_max_n
diff --git a/contrib/src/test/results/clientpositive/udaf_example_min.q.out b/contrib/src/test/results/clientpositive/udaf_example_min.q.out
index ec3a13403b..061f6359cc 100644
--- a/contrib/src/test/results/clientpositive/udaf_example_min.q.out
+++ b/contrib/src/test/results/clientpositive/udaf_example_min.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION example_min AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleMin'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_min
 POSTHOOK: query: CREATE TEMPORARY FUNCTION example_min AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleMin'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_min
 PREHOOK: query: DESCRIBE FUNCTION EXTENDED example_min
 PREHOOK: type: DESCFUNCTION
 POSTHOOK: query: DESCRIBE FUNCTION EXTENDED example_min
@@ -82,7 +82,7 @@ POSTHOOK: Input: default@src
 0	0
 PREHOOK: query: DROP TEMPORARY FUNCTION example_min
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_min
 POSTHOOK: query: DROP TEMPORARY FUNCTION example_min
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_min
diff --git a/contrib/src/test/results/clientpositive/udaf_example_min_n.q.out b/contrib/src/test/results/clientpositive/udaf_example_min_n.q.out
index 2e802e0d9e..3e436313fd 100644
--- a/contrib/src/test/results/clientpositive/udaf_example_min_n.q.out
+++ b/contrib/src/test/results/clientpositive/udaf_example_min_n.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION example_min_n AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleMinN'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_min_n
 POSTHOOK: query: CREATE TEMPORARY FUNCTION example_min_n AS 'org.apache.hadoop.hive.contrib.udaf.example.UDAFExampleMinN'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_min_n
 PREHOOK: query: EXPLAIN
 SELECT example_min_n(substr(value,5),10),
        example_min_n(IF(substr(value,5) < 250, NULL, substr(value,5)),10)
@@ -77,7 +77,7 @@ POSTHOOK: Input: default@src
 [0.0,0.0,0.0,2.0,4.0,5.0,5.0,5.0,8.0,9.0]	[252.0,255.0,255.0,256.0,256.0,257.0,258.0,260.0,262.0,263.0]
 PREHOOK: query: DROP TEMPORARY FUNCTION example_min_n
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_min_n
 POSTHOOK: query: DROP TEMPORARY FUNCTION example_min_n
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_min_n
diff --git a/contrib/src/test/results/clientpositive/udf_example_add.q.out b/contrib/src/test/results/clientpositive/udf_example_add.q.out
index 4510ba468a..944155c320 100644
--- a/contrib/src/test/results/clientpositive/udf_example_add.q.out
+++ b/contrib/src/test/results/clientpositive/udf_example_add.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION example_add AS 'org.apache.hadoop.hive.contrib.udf.example.UDFExampleAdd'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_add
 POSTHOOK: query: CREATE TEMPORARY FUNCTION example_add AS 'org.apache.hadoop.hive.contrib.udf.example.UDFExampleAdd'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_add
 PREHOOK: query: EXPLAIN
 SELECT example_add(1, 2),
        example_add(1, 2, 3),
@@ -81,7 +81,7 @@ POSTHOOK: Input: default@src
 3	6	10	3.3000000000000003	6.6	11.0	10.4
 PREHOOK: query: DROP TEMPORARY FUNCTION example_add
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_add
 POSTHOOK: query: DROP TEMPORARY FUNCTION example_add
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_add
diff --git a/contrib/src/test/results/clientpositive/udf_example_arraymapstruct.q.out b/contrib/src/test/results/clientpositive/udf_example_arraymapstruct.q.out
index 1e3bca4f5f..006a023dac 100644
--- a/contrib/src/test/results/clientpositive/udf_example_arraymapstruct.q.out
+++ b/contrib/src/test/results/clientpositive/udf_example_arraymapstruct.q.out
@@ -1,21 +1,21 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION example_arraysum    AS 'org.apache.hadoop.hive.contrib.udf.example.UDFExampleArraySum'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_arraysum
 POSTHOOK: query: CREATE TEMPORARY FUNCTION example_arraysum    AS 'org.apache.hadoop.hive.contrib.udf.example.UDFExampleArraySum'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_arraysum
 PREHOOK: query: CREATE TEMPORARY FUNCTION example_mapconcat   AS 'org.apache.hadoop.hive.contrib.udf.example.UDFExampleMapConcat'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_mapconcat
 POSTHOOK: query: CREATE TEMPORARY FUNCTION example_mapconcat   AS 'org.apache.hadoop.hive.contrib.udf.example.UDFExampleMapConcat'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_mapconcat
 PREHOOK: query: CREATE TEMPORARY FUNCTION example_structprint AS 'org.apache.hadoop.hive.contrib.udf.example.UDFExampleStructPrint'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_structprint
 POSTHOOK: query: CREATE TEMPORARY FUNCTION example_structprint AS 'org.apache.hadoop.hive.contrib.udf.example.UDFExampleStructPrint'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_structprint
 PREHOOK: query: EXPLAIN
 SELECT example_arraysum(lint), example_mapconcat(mstringstring), example_structprint(lintstring[0])
 FROM src_thrift
@@ -76,19 +76,19 @@ POSTHOOK: Input: default@src_thrift
 NULL	NULL	NULL
 PREHOOK: query: DROP TEMPORARY FUNCTION example_arraysum
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_arraysum
 POSTHOOK: query: DROP TEMPORARY FUNCTION example_arraysum
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_arraysum
 PREHOOK: query: DROP TEMPORARY FUNCTION example_mapconcat
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_mapconcat
 POSTHOOK: query: DROP TEMPORARY FUNCTION example_mapconcat
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_mapconcat
 PREHOOK: query: DROP TEMPORARY FUNCTION example_structprint
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_structprint
 POSTHOOK: query: DROP TEMPORARY FUNCTION example_structprint
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_structprint
diff --git a/contrib/src/test/results/clientpositive/udf_example_format.q.out b/contrib/src/test/results/clientpositive/udf_example_format.q.out
index 83e508ab9c..92543402a1 100644
--- a/contrib/src/test/results/clientpositive/udf_example_format.q.out
+++ b/contrib/src/test/results/clientpositive/udf_example_format.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION example_format AS 'org.apache.hadoop.hive.contrib.udf.example.UDFExampleFormat'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_format
 POSTHOOK: query: CREATE TEMPORARY FUNCTION example_format AS 'org.apache.hadoop.hive.contrib.udf.example.UDFExampleFormat'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_format
 PREHOOK: query: EXPLAIN
 SELECT example_format("abc"),
        example_format("%1$s", 1.1),
@@ -69,7 +69,7 @@ POSTHOOK: Input: default@src
 abc	1.1	1.1 1.200000e+00	a 12 10
 PREHOOK: query: DROP TEMPORARY FUNCTION example_format
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: example_format
 POSTHOOK: query: DROP TEMPORARY FUNCTION example_format
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: example_format
diff --git a/contrib/src/test/results/clientpositive/udf_row_sequence.q.out b/contrib/src/test/results/clientpositive/udf_row_sequence.q.out
index 3b58cb5458..a94e088a2c 100644
--- a/contrib/src/test/results/clientpositive/udf_row_sequence.q.out
+++ b/contrib/src/test/results/clientpositive/udf_row_sequence.q.out
@@ -13,11 +13,11 @@ POSTHOOK: type: DROPFUNCTION
 PREHOOK: query: create temporary function row_sequence as 
 'org.apache.hadoop.hive.contrib.udf.UDFRowSequence'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: row_sequence
 POSTHOOK: query: create temporary function row_sequence as 
 'org.apache.hadoop.hive.contrib.udf.UDFRowSequence'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: row_sequence
 PREHOOK: query: DESCRIBE FUNCTION EXTENDED row_sequence
 PREHOOK: type: DESCFUNCTION
 POSTHOOK: query: DESCRIBE FUNCTION EXTENDED row_sequence
@@ -643,7 +643,7 @@ POSTHOOK: Input: default@src
 119	false
 PREHOOK: query: drop temporary function row_sequence
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: row_sequence
 POSTHOOK: query: drop temporary function row_sequence
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: row_sequence
diff --git a/contrib/src/test/results/clientpositive/udtf_explode2.q.out b/contrib/src/test/results/clientpositive/udtf_explode2.q.out
index 47512c36c1..17c9299edb 100644
--- a/contrib/src/test/results/clientpositive/udtf_explode2.q.out
+++ b/contrib/src/test/results/clientpositive/udtf_explode2.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION explode2 AS 'org.apache.hadoop.hive.contrib.udtf.example.GenericUDTFExplode2'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: explode2
 POSTHOOK: query: CREATE TEMPORARY FUNCTION explode2 AS 'org.apache.hadoop.hive.contrib.udtf.example.GenericUDTFExplode2'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: explode2
 PREHOOK: query: SELECT explode2(array(1,2,3)) AS (col1, col2) FROM src LIMIT 3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -17,7 +17,7 @@ POSTHOOK: Input: default@src
 3	3
 PREHOOK: query: DROP TEMPORARY FUNCTION explode2
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: explode2
 POSTHOOK: query: DROP TEMPORARY FUNCTION explode2
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: explode2
diff --git a/contrib/src/test/results/clientpositive/udtf_output_on_close.q.out b/contrib/src/test/results/clientpositive/udtf_output_on_close.q.out
index 4ce0481842..bd1584af35 100644
--- a/contrib/src/test/results/clientpositive/udtf_output_on_close.q.out
+++ b/contrib/src/test/results/clientpositive/udtf_output_on_close.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION udtfCount2 AS 'org.apache.hadoop.hive.contrib.udtf.example.GenericUDTFCount2'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: udtfcount2
 POSTHOOK: query: CREATE TEMPORARY FUNCTION udtfCount2 AS 'org.apache.hadoop.hive.contrib.udtf.example.GenericUDTFCount2'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: udtfcount2
 PREHOOK: query: SELECT udtfCount2(key) AS count FROM src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcWithSQLAuthorization.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcWithSQLAuthorization.java
index 3618185153..a4ed633538 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcWithSQLAuthorization.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/authorization/TestJdbcWithSQLAuthorization.java
@@ -125,15 +125,14 @@ public void testAllowedCommands() throws Exception {
       // create tables
       try {
         stmt.execute("dfs -ls /tmp/");
-      } catch (SQLException e){
+      } catch (SQLException e) {
         caughtException = true;
-        String msg = "Principal [name=user1, type=USER] does not have following "
-            + "privileges on Object [type=COMMAND_PARAMS, name=[-ls, /tmp/]] for operation "
-            + "DFS : [ADMIN PRIVILEGE]";
+        String msg = "Permission denied: Principal [name=user1, type=USER] does not have "
+            + "following privileges for operation DFS [[ADMIN PRIVILEGE] on "
+            + "Object [type=COMMAND_PARAMS, name=[-ls, /tmp/]]]";
         assertTrue("Checking content of error message:" + e.getMessage(),
             e.getMessage().contains(msg));
-      }
-      finally {
+      } finally {
         stmt.close();
         hs2Conn.close();
       }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
index c89f90cb66..e512199a1e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
@@ -724,18 +724,21 @@ private static List<HivePrivilegeObject> getHivePrivObjects(HashSet<? extends En
 
       //support for authorization on partitions needs to be added
       String dbname = null;
-      String tableURI = null;
+      String objName = null;
       switch(privObject.getType()){
       case DATABASE:
         dbname = privObject.getDatabase() == null ? null : privObject.getDatabase().getName();
         break;
       case TABLE:
         dbname = privObject.getTable() == null ? null : privObject.getTable().getDbName();
-        tableURI = privObject.getTable() == null ? null : privObject.getTable().getTableName();
+        objName = privObject.getTable() == null ? null : privObject.getTable().getTableName();
         break;
       case DFS_DIR:
       case LOCAL_DIR:
-        tableURI = privObject.getD();
+        objName = privObject.getD();
+        break;
+      case FUNCTION:
+        objName = privObject.getFunctionName();
         break;
       case DUMMYPARTITION:
       case PARTITION:
@@ -745,7 +748,7 @@ private static List<HivePrivilegeObject> getHivePrivObjects(HashSet<? extends En
           throw new AssertionError("Unexpected object type");
       }
       HivePrivObjectActionType actionType = AuthorizationUtils.getActionType(privObject);
-      HivePrivilegeObject hPrivObject = new HivePrivilegeObject(privObjType, dbname, tableURI,
+      HivePrivilegeObject hPrivObject = new HivePrivilegeObject(privObjType, dbname, objName,
           actionType);
       hivePrivobjs.add(hPrivObject);
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
index c80a2a3108..7d62f45f1a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
@@ -3170,7 +3170,7 @@ public int compare(HivePrivilegeInfo o1, HivePrivilegeInfo o2) {
       HivePrincipal grantor = privilege.getGrantorPrincipal();
 
       appendNonNull(builder, resource.getDbname(), true);
-      appendNonNull(builder, resource.getTableViewURI());
+      appendNonNull(builder, resource.getObjectName());
       appendNonNull(builder, resource.getPartKeys());
       appendNonNull(builder, resource.getColumns());
       appendNonNull(builder, principal.getName());
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java b/ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java
index 2a38aad948..50c76db0a9 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java
@@ -40,7 +40,7 @@ public class Entity implements Serializable {
    * The type of the entity.
    */
   public static enum Type {
-    DATABASE, TABLE, PARTITION, DUMMYPARTITION, DFS_DIR, LOCAL_DIR
+    DATABASE, TABLE, PARTITION, DUMMYPARTITION, DFS_DIR, LOCAL_DIR, FUNCTION
   }
 
   /**
@@ -64,10 +64,16 @@ public static enum Type {
   private Partition p;
 
   /**
-   * The directory if this is a directory.
+   * The directory if this is a directory
    */
   private String d;
 
+  /**
+   * An object that is represented as a String
+   * Currently used for functions
+   */
+  private String stringObject;
+
   /**
    * This is derived from t and p, but we need to serialize this field to make
    * sure Entity.hashCode() does not need to recursively read into t and p.
@@ -136,6 +142,21 @@ public void setD(String d) {
     this.d = d;
   }
 
+  public String getFunctionName() {
+    if (typ == Type.FUNCTION) {
+      return stringObject;
+    }
+    return null;
+  }
+
+  public void setFunctionName(String funcName) {
+    if (typ != Type.FUNCTION) {
+      throw new IllegalArgumentException(
+          "Set function can't be called on entity if the entity type is not " + Type.FUNCTION);
+    }
+    this.stringObject = funcName;
+  }
+
   /**
    * Only used by serialization.
    */
@@ -209,6 +230,24 @@ public Entity(String d, boolean islocal, boolean complete) {
     this.complete = complete;
   }
 
+  /**
+   * Create an entity representing a object with given name, database namespace and type
+   * @param database - database namespace
+   * @param strObj - object name as string
+   * @param type - the entity type. this constructor only supports FUNCTION type currently
+   */
+  public Entity(Database database, String strObj, Type type) {
+    if (type != Type.FUNCTION) {
+      throw new IllegalArgumentException("This constructor is supported only for type:"
+          + Type.FUNCTION);
+    }
+    this.database = database;
+    this.stringObject = strObj;
+    this.typ = type;
+    this.complete = true;
+    name = computeName();
+  }
+
   /**
    * Get the parameter map of the Entity.
    */
@@ -293,6 +332,8 @@ private String computeName() {
       return t.getDbName() + "@" + t.getTableName() + "@" + p.getName();
     case DUMMYPARTITION:
       return p.getName();
+    case FUNCTION:
+      return stringObject;
     default:
       return d;
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java b/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java
index 26836b6bfb..7f1d71be33 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java
@@ -81,6 +81,19 @@ public WriteEntity(Table t, WriteType type, boolean complete) {
     writeType = type;
   }
 
+  /**
+   * Constructor for objects represented as String.
+   * Currently applicable only for function names.
+   * @param db
+   * @param objName
+   * @param type
+   * @param writeType
+   */
+  public WriteEntity(Database db, String objName, Type type, WriteType writeType) {
+    super(db, objName, type);
+    this.writeType = writeType;
+  }
+
   /**
    * Constructor for a partition.
    *
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java
index d258bc64c8..4300145c93 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java
@@ -173,7 +173,7 @@ public List<org.apache.hadoop.hive.metastore.api.Table> getTableObjectsByName(St
     return tables;
   }
 
-  
+
   @Override
   public boolean tableExists(String databaseName, String tableName) throws MetaException,
   TException, UnknownDBException {
@@ -331,7 +331,7 @@ private void dropTempTable(org.apache.hadoop.hive.metastore.api.Table table, boo
               " is not writable by " + conf.getUser());
         }
       } catch (IOException err) {
-        MetaException metaException = 
+        MetaException metaException =
             new MetaException("Error checking temp table path for " + table.getTableName());
         metaException.initCause(err);
         throw metaException;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/FunctionSemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/FunctionSemanticAnalyzer.java
index e64ef76796..bf3b65a0ff 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/FunctionSemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/FunctionSemanticAnalyzer.java
@@ -24,7 +24,6 @@
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
-import org.apache.hadoop.hive.metastore.MetaStoreUtils;
 import org.apache.hadoop.hive.metastore.api.Database;
 import org.apache.hadoop.hive.metastore.api.ResourceType;
 import org.apache.hadoop.hive.metastore.api.ResourceUri;
@@ -32,14 +31,13 @@
 import org.apache.hadoop.hive.ql.exec.FunctionRegistry;
 import org.apache.hadoop.hive.ql.exec.FunctionUtils;
 import org.apache.hadoop.hive.ql.exec.TaskFactory;
+import org.apache.hadoop.hive.ql.hooks.Entity.Type;
 import org.apache.hadoop.hive.ql.hooks.WriteEntity;
-import org.apache.hadoop.hive.ql.metadata.Hive;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.plan.CreateFunctionDesc;
 import org.apache.hadoop.hive.ql.plan.DropFunctionDesc;
 import org.apache.hadoop.hive.ql.plan.FunctionWork;
 import org.apache.hadoop.hive.ql.plan.PlanUtils;
-import org.apache.hadoop.hive.ql.session.SessionState;
 
 /**
  * FunctionSemanticAnalyzer.
@@ -78,7 +76,7 @@ private void analyzeCreateFunction(ASTNode ast) throws SemanticException {
 
     // find any referenced resources
     List<ResourceUri> resources = getResourceList(ast);
-    
+
     CreateFunctionDesc desc =
         new CreateFunctionDesc(functionName, isTemporaryFunction, className, resources);
     rootTasks.add(TaskFactory.get(new FunctionWork(desc), conf));
@@ -152,15 +150,22 @@ private List<ResourceUri> getResourceList(ASTNode ast) throws SemanticException
   }
 
   /**
-   * Add write entities to the semantic analyzer to restrict function creation to priviliged users.
+   * Add write entities to the semantic analyzer to restrict function creation to privileged users.
    */
   private void addEntities(String functionName, boolean isTemporaryFunction)
       throws SemanticException {
+    // If the function is being added under a database 'namespace', then add an entity representing
+    // the database (only applicable to permanent/metastore functions).
+    // We also add a second entity representing the function name.
+    // The authorization api implementation can decide which entities it wants to use to
+    // authorize the create/drop function call.
+
+    // Add the relevant database 'namespace' as a WriteEntity
     Database database = null;
-    if (isTemporaryFunction) {
-      // This means temp function creation is also restricted.
-      database = getDatabase(MetaStoreUtils.DEFAULT_DATABASE_NAME);
-    } else {
+
+    // temporary functions don't have any database 'namespace' associated with it,
+    // it matters only for permanent functions
+    if (!isTemporaryFunction) {
       try {
         String[] qualifiedNameParts = FunctionUtils.getQualifiedFunctionNameParts(functionName);
         String dbName = qualifiedNameParts[0];
@@ -173,5 +178,9 @@ private void addEntities(String functionName, boolean isTemporaryFunction)
     if (database != null) {
       outputs.add(new WriteEntity(database, WriteEntity.WriteType.DDL_NO_LOCK));
     }
+
+    // Add the function name as a WriteEntity
+    outputs.add(new WriteEntity(database, functionName, Type.FUNCTION,
+        WriteEntity.WriteType.DDL_NO_LOCK));
   }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationUtils.java
index e86442a0f6..698cac5633 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationUtils.java
@@ -99,6 +99,8 @@ public static HivePrivilegeObjectType getHivePrivilegeObjectType(Type type) {
     case PARTITION:
     case DUMMYPARTITION: //need to determine if a different type is needed for dummy partitions
       return HivePrivilegeObjectType.PARTITION;
+    case FUNCTION:
+      return HivePrivilegeObjectType.FUNCTION;
     default:
       return null;
     }
@@ -253,12 +255,8 @@ public static HiveObjectType getThriftHiveObjType(HivePrivilegeObjectType type)
       return HiveObjectType.PARTITION;
     case COLUMN:
       return HiveObjectType.COLUMN;
-    case LOCAL_URI:
-    case DFS_URI:
-      throw new HiveException("Unsupported type " + type);
     default:
-      //should not happen as we have accounted for all types
-      throw new AssertionError("Unsupported type " + type);
+      throw new HiveException("Unsupported type " + type);
     }
   }
 
@@ -301,7 +299,7 @@ public static HiveObjectRef getThriftHiveObjectRef(HivePrivilegeObject privObj)
       return null;
     }
     HiveObjectType objType = getThriftHiveObjType(privObj.getType());
-    return new HiveObjectRef(objType, privObj.getDbname(), privObj.getTableViewURI(), null, null);
+    return new HiveObjectRef(objType, privObj.getDbname(), privObj.getObjectName(), null, null);
   }
 
   public static HivePrivObjectActionType getActionType(Entity privObject) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HivePrivilegeObject.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HivePrivilegeObject.java
index 912be6b614..5733703d60 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HivePrivilegeObject.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HivePrivilegeObject.java
@@ -17,14 +17,13 @@
  */
 package org.apache.hadoop.hive.ql.security.authorization.plugin;
 
+import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.List;
 
 import org.apache.hadoop.hive.common.classification.InterfaceAudience.LimitedPrivate;
 import org.apache.hadoop.hive.common.classification.InterfaceStability.Unstable;
 
-import java.util.ArrayList;
-import java.util.Arrays;
-
 /**
  * Represents the object on which privilege is being granted/revoked
  */
@@ -32,33 +31,6 @@
 @Unstable
 public class HivePrivilegeObject implements Comparable<HivePrivilegeObject> {
 
-  @Override
-  public String toString() {
-    String name = null;
-    switch (type) {
-    case DATABASE:
-      name = dbname;
-      break;
-    case TABLE_OR_VIEW:
-    case PARTITION:
-      name = (dbname == null ? "" : dbname + ".") + tableviewname;
-      if (partKeys != null) {
-        name += partKeys.toString();
-      }
-      break;
-    case COLUMN:
-    case LOCAL_URI:
-    case DFS_URI:
-      name = tableviewname;
-      break;
-    case COMMAND_PARAMS:
-      name = commandParams.toString();
-      break;
-    }
-    return "Object [type=" + type + ", name=" + name + "]";
-
-  }
-
   @Override
   public int compareTo(HivePrivilegeObject o) {
     int compare = type.compareTo(o.type);
@@ -66,9 +38,9 @@ public int compareTo(HivePrivilegeObject o) {
       compare = dbname.compareTo(o.dbname);
     }
     if (compare == 0) {
-      compare = tableviewname != null ?
-          (o.tableviewname != null ? tableviewname.compareTo(o.tableviewname) : 1) :
-          (o.tableviewname != null ? -1 : 0);
+      compare = objectName != null ?
+          (o.objectName != null ? objectName.compareTo(o.objectName) : 1) :
+          (o.objectName != null ? -1 : 0);
     }
     if (compare == 0) {
       compare = partKeys != null ?
@@ -94,7 +66,7 @@ private int compare(List<String> o1, List<String> o2) {
   }
 
   public enum HivePrivilegeObjectType {
-    GLOBAL, DATABASE, TABLE_OR_VIEW, PARTITION, COLUMN, LOCAL_URI, DFS_URI, COMMAND_PARAMS
+    GLOBAL, DATABASE, TABLE_OR_VIEW, PARTITION, COLUMN, LOCAL_URI, DFS_URI, COMMAND_PARAMS, FUNCTION
   } ;
   public enum HivePrivObjectActionType {
     OTHER, INSERT, INSERT_OVERWRITE
@@ -102,26 +74,27 @@ public enum HivePrivObjectActionType {
 
   private final HivePrivilegeObjectType type;
   private final String dbname;
-  private final String tableviewname;
+  private final String objectName;
   private final List<String> commandParams;
   private final List<String> partKeys;
   private final List<String> columns;
   private final HivePrivObjectActionType actionType;
 
-  public HivePrivilegeObject(HivePrivilegeObjectType type, String dbname, String tableViewURI) {
-    this(type, dbname, tableViewURI, HivePrivObjectActionType.OTHER);
+  public HivePrivilegeObject(HivePrivilegeObjectType type, String dbname, String objectName) {
+    this(type, dbname, objectName, HivePrivObjectActionType.OTHER);
   }
 
-  public HivePrivilegeObject(HivePrivilegeObjectType type, String dbname, String tableViewURI
+  public HivePrivilegeObject(HivePrivilegeObjectType type, String dbname, String objectName
       , HivePrivObjectActionType actionType) {
-    this(type, dbname, tableViewURI, null, null, actionType, null);
+    this(type, dbname, objectName, null, null, actionType, null);
   }
 
-  public HivePrivilegeObject(HivePrivilegeObjectType type, String dbname, String tableViewURI,
+  public HivePrivilegeObject(HivePrivilegeObjectType type, String dbname, String objectName,
       List<String> partKeys, String column) {
-    this(type, dbname, tableViewURI, partKeys,
+    this(type, dbname, objectName, partKeys,
         column == null ? null : new ArrayList<String>(Arrays.asList(column)),
         HivePrivObjectActionType.OTHER, null);
+
   }
 
   /**
@@ -134,17 +107,17 @@ public static HivePrivilegeObject createHivePrivilegeObject(List<String> cmdPara
         cmdParams);
   }
 
-  public HivePrivilegeObject(HivePrivilegeObjectType type, String dbname, String tableViewURI,
+  public HivePrivilegeObject(HivePrivilegeObjectType type, String dbname, String objectName,
     List<String> partKeys, List<String> columns, List<String> commandParams) {
-    this(type, dbname, tableViewURI, partKeys, columns, HivePrivObjectActionType.OTHER, commandParams);
+    this(type, dbname, objectName, partKeys, columns, HivePrivObjectActionType.OTHER, commandParams);
   }
 
-  public HivePrivilegeObject(HivePrivilegeObjectType type, String dbname, String tableViewURI,
+  public HivePrivilegeObject(HivePrivilegeObjectType type, String dbname, String objectName,
       List<String> partKeys, List<String> columns, HivePrivObjectActionType actionType,
       List<String> commandParams) {
     this.type = type;
     this.dbname = dbname;
-    this.tableviewname = tableViewURI;
+    this.objectName = objectName;
     this.partKeys = partKeys;
     this.columns = columns;
     this.actionType = actionType;
@@ -159,8 +132,11 @@ public String getDbname() {
     return dbname;
   }
 
-  public String getTableViewURI() {
-    return tableviewname;
+  /**
+   * @return name of table/view/uri/function name
+   */
+  public String getObjectName() {
+    return objectName;
   }
 
   public HivePrivObjectActionType getActionType() {
@@ -178,4 +154,50 @@ public List<String> getPartKeys() {
   public List<String> getColumns() {
     return columns;
   }
+
+  @Override
+  public String toString() {
+    String name = null;
+    switch (type) {
+    case DATABASE:
+      name = dbname;
+      break;
+    case TABLE_OR_VIEW:
+    case PARTITION:
+      name = getDbObjectName(dbname, objectName);
+      if (partKeys != null) {
+        name += partKeys.toString();
+      }
+      break;
+    case FUNCTION:
+      name = getDbObjectName(dbname, objectName);
+      break;
+    case COLUMN:
+    case LOCAL_URI:
+    case DFS_URI:
+      name = objectName;
+      break;
+    case COMMAND_PARAMS:
+      name = commandParams.toString();
+      break;
+    }
+
+    // get the string representing action type if its non default action type
+    String actionTypeStr ="";
+    if (actionType != null) {
+      switch (actionType) {
+      case INSERT:
+      case INSERT_OVERWRITE:
+        actionTypeStr = ", action=" + actionType;
+      default:
+      }
+    }
+
+    return "Object [type=" + type + ", name=" + name + actionTypeStr + "]";
+  }
+
+  private String getDbObjectName(String dbname2, String objectName2) {
+    return (dbname == null ? "" : dbname + ".") + objectName;
+  }
+
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HiveV1Authorizer.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HiveV1Authorizer.java
index 60c9f14921..c747c3384c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HiveV1Authorizer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HiveV1Authorizer.java
@@ -18,6 +18,10 @@
 
 package org.apache.hadoop.hive.ql.security.authorization.plugin;
 
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.Warehouse;
 import org.apache.hadoop.hive.metastore.api.Database;
@@ -38,10 +42,6 @@
 import org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController;
 import org.apache.hadoop.hive.ql.session.SessionState;
 
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map;
-
 public class HiveV1Authorizer implements HiveAuthorizer {
 
   private final HiveConf conf;
@@ -141,8 +141,8 @@ private PrivilegeBag toPrivilegeBag(List<HivePrivilege> privileges,
       throw new HiveException("Database " + privObject.getDbname() + " does not exists");
     }
     Table tableObj = null;
-    if (privObject.getTableViewURI() != null) {
-      tableObj = hive.getTable(dbObj.getName(), privObject.getTableViewURI());
+    if (privObject.getObjectName() != null) {
+      tableObj = hive.getTable(dbObj.getName(), privObject.getObjectName());
     }
 
     List<String> partValues = null;
@@ -308,8 +308,8 @@ public List<HivePrivilegeInfo> showPrivileges(HivePrincipal principal, HivePrivi
           throw new HiveException("Database " + privObj.getDbname() + " does not exists");
         }
         Table tableObj = null;
-        if (privObj.getTableViewURI() != null) {
-          tableObj = hive.getTable(dbObj.getName(), privObj.getTableViewURI());
+        if (privObj.getObjectName() != null) {
+          tableObj = hive.getTable(dbObj.getName(), privObj.getObjectName());
         }
         List<String> partValues = privObj.getPartKeys();
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/GrantPrivAuthUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/GrantPrivAuthUtils.java
index 1ac6cabd82..33d3c24b2d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/GrantPrivAuthUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/GrantPrivAuthUtils.java
@@ -17,6 +17,7 @@
  */
 package org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd;
 
+import java.util.ArrayList;
 import java.util.Collection;
 import java.util.List;
 
@@ -64,9 +65,11 @@ private static void checkRequiredPrivileges(
         metastoreClient, userName, hivePrivObject, curRoles, isAdmin);
 
     // check if required privileges is subset of available privileges
+    List<String> deniedMessages = new ArrayList<String>();
     Collection<SQLPrivTypeGrant> missingPrivs = reqPrivileges.findMissingPrivs(availPrivs);
-    SQLAuthorizationUtils.assertNoMissingPrivilege(missingPrivs, new HivePrincipal(userName,
-        HivePrincipalType.USER), hivePrivObject, opType);
+    SQLAuthorizationUtils.addMissingPrivMsg(missingPrivs, hivePrivObject, deniedMessages);
+    SQLAuthorizationUtils.assertNoDeniedPermissions(new HivePrincipal(userName,
+        HivePrincipalType.USER), opType, deniedMessages);
   }
 
   private static RequiredPrivileges getGrantRequiredPrivileges(List<HivePrivilege> hivePrivileges)
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLAuthorizationUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLAuthorizationUtils.java
index f1220d74b5..6a283ab25f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLAuthorizationUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLAuthorizationUtils.java
@@ -264,7 +264,7 @@ private static boolean isOwner(IMetaStoreClient metastoreClient, String userName
       Table thriftTableObj = null;
       try {
         thriftTableObj = metastoreClient.getTable(hivePrivObject.getDbname(),
-            hivePrivObject.getTableViewURI());
+            hivePrivObject.getObjectName());
       } catch (Exception e) {
         throwGetObjErr(e, hivePrivObject);
       }
@@ -352,19 +352,15 @@ private static void addRequiredPrivs(RequiredPrivileges reqPrivs,
     }
   }
 
-  public static void assertNoMissingPrivilege(Collection<SQLPrivTypeGrant> missingPrivs,
-      HivePrincipal hivePrincipal, HivePrivilegeObject hivePrivObject, HiveOperationType opType)
-      throws HiveAccessControlException {
+  public static void addMissingPrivMsg(Collection<SQLPrivTypeGrant> missingPrivs,
+      HivePrivilegeObject hivePrivObject, List<String> deniedMessages) {
     if (missingPrivs.size() != 0) {
       // there are some required privileges missing, create error message
       // sort the privileges so that error message is deterministic (for tests)
       List<SQLPrivTypeGrant> sortedmissingPrivs = new ArrayList<SQLPrivTypeGrant>(missingPrivs);
       Collections.sort(sortedmissingPrivs);
-
-      String errMsg = "Permission denied. " + hivePrincipal
-          + " does not have following privileges on " + hivePrivObject +
-          " for operation " + opType + " : " + sortedmissingPrivs;
-      throw new HiveAccessControlException(errMsg.toString());
+      String errMsg = sortedmissingPrivs + " on " + hivePrivObject;
+      deniedMessages.add(errMsg);
     }
   }
 
@@ -405,5 +401,16 @@ public static RequiredPrivileges getPrivilegesFromFS(Path filePath, HiveConf con
     return availPrivs;
   }
 
+  public static void assertNoDeniedPermissions(HivePrincipal hivePrincipal,
+      HiveOperationType hiveOpType, List<String> deniedMessages) throws HiveAccessControlException {
+    if (deniedMessages.size() != 0) {
+      Collections.sort(deniedMessages);
+      String errorMessage = "Permission denied: " + hivePrincipal
+          + " does not have following privileges for operation " + hiveOpType + " "
+          + deniedMessages;
+      throw new HiveAccessControlException(errorMessage);
+    }
+  }
+
 
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLStdHiveAccessController.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLStdHiveAccessController.java
index a16f42a7aa..ce12edb490 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLStdHiveAccessController.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLStdHiveAccessController.java
@@ -420,7 +420,7 @@ public List<HivePrivilegeInfo> showPrivileges(HivePrincipal principal, HivePrivi
         }
 
         HivePrivilegeObject resPrivObj = new HivePrivilegeObject(
-            getPluginObjType(msObjRef.getObjectType()), msObjRef.getDbName(),
+            getPluginPrivilegeObjType(msObjRef.getObjectType()), msObjRef.getDbName(),
             msObjRef.getObjectName(), msObjRef.getPartValues(), msObjRef.getColumnName());
 
         // result grantor principal
@@ -479,8 +479,14 @@ private boolean userBelongsToRole(String roleName) throws HiveAuthzPluginExcepti
     return false;
   }
 
-  private HivePrivilegeObjectType getPluginObjType(HiveObjectType objectType)
-      throws HiveAuthzPluginException {
+  /**
+   * Convert metastore object type to HivePrivilegeObjectType.
+   * Also verifies that metastore object type is of a type on which metastore privileges are
+   * supported by sql std auth.
+   * @param objectType
+   * @return corresponding HivePrivilegeObjectType
+   */
+  private HivePrivilegeObjectType getPluginPrivilegeObjType(HiveObjectType objectType) {
     switch (objectType) {
     case DATABASE:
       return HivePrivilegeObjectType.DATABASE;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLStdHiveAuthorizationValidator.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLStdHiveAuthorizationValidator.java
index c472cef511..83a0b45352 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLStdHiveAuthorizationValidator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/SQLStdHiveAuthorizationValidator.java
@@ -17,6 +17,7 @@
  */
 package org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd;
 
+import java.util.ArrayList;
 import java.util.Collection;
 import java.util.List;
 
@@ -71,13 +72,16 @@ public void checkPrivileges(HiveOperationType hiveOpType, List<HivePrivilegeObje
     IMetaStoreClient metastoreClient = metastoreClientFactory.getHiveMetastoreClient();
 
     // check privileges on input and output objects
-    checkPrivileges(hiveOpType, inputHObjs, metastoreClient, userName, IOType.INPUT);
-    checkPrivileges(hiveOpType, outputHObjs, metastoreClient, userName, IOType.OUTPUT);
+    List<String> deniedMessages = new ArrayList<String>();
+    checkPrivileges(hiveOpType, inputHObjs, metastoreClient, userName, IOType.INPUT, deniedMessages);
+    checkPrivileges(hiveOpType, outputHObjs, metastoreClient, userName, IOType.OUTPUT, deniedMessages);
 
+    SQLAuthorizationUtils.assertNoDeniedPermissions(new HivePrincipal(userName,
+        HivePrincipalType.USER), hiveOpType, deniedMessages);
   }
 
   private void checkPrivileges(HiveOperationType hiveOpType, List<HivePrivilegeObject> hiveObjects,
-      IMetaStoreClient metastoreClient, String userName, IOType ioType)
+      IMetaStoreClient metastoreClient, String userName, IOType ioType, List<String> deniedMessages)
       throws HiveAuthzPluginException, HiveAccessControlException {
 
     if (hiveObjects == null) {
@@ -95,7 +99,7 @@ private void checkPrivileges(HiveOperationType hiveOpType, List<HivePrivilegeObj
       switch (hiveObj.getType()) {
       case LOCAL_URI:
       case DFS_URI:
-        availPrivs = SQLAuthorizationUtils.getPrivilegesFromFS(new Path(hiveObj.getTableViewURI()),
+        availPrivs = SQLAuthorizationUtils.getPrivilegesFromFS(new Path(hiveObj.getObjectName()),
             conf, userName);
         break;
       case PARTITION:
@@ -104,9 +108,9 @@ private void checkPrivileges(HiveOperationType hiveOpType, List<HivePrivilegeObj
         // ignore partitions
         continue;
       case COMMAND_PARAMS:
-        // operations that have objects of type COMMAND_PARAMS are authorized
+      case FUNCTION:
+        // operations that have objects of type COMMAND_PARAMS, FUNCTION are authorized
         // solely on the type
-        // Assume no available privileges, unless in admin role
         if (privController.isUserAdmin()) {
           availPrivs.addPrivilege(SQLPrivTypeGrant.ADMIN_PRIV);
         }
@@ -118,8 +122,7 @@ private void checkPrivileges(HiveOperationType hiveOpType, List<HivePrivilegeObj
 
       // Verify that there are no missing privileges
       Collection<SQLPrivTypeGrant> missingPriv = requiredPrivs.findMissingPrivs(availPrivs);
-      SQLAuthorizationUtils.assertNoMissingPrivilege(missingPriv, new HivePrincipal(userName,
-          HivePrincipalType.USER), hiveObj, hiveOpType);
+      SQLAuthorizationUtils.addMissingPrivMsg(missingPriv, hiveObj, deniedMessages);
 
     }
   }
diff --git a/ql/src/test/results/clientnegative/authorization_addjar.q.out b/ql/src/test/results/clientnegative/authorization_addjar.q.out
index 68c3c6071b..913b00e88e 100644
--- a/ql/src/test/results/clientnegative/authorization_addjar.q.out
+++ b/ql/src/test/results/clientnegative/authorization_addjar.q.out
@@ -1 +1 @@
-Query returned non-zero code: 1, cause: Permission denied. Principal [name=hive_test_user, type=USER] does not have following privileges on Object [type=COMMAND_PARAMS, name=[jar, dummy.jar]] for operation ADD : [ADMIN PRIVILEGE]
+Query returned non-zero code: 1, cause: Permission denied: Principal [name=hive_test_user, type=USER] does not have following privileges for operation ADD [[ADMIN PRIVILEGE] on Object [type=COMMAND_PARAMS, name=[jar, dummy.jar]]]
diff --git a/ql/src/test/results/clientnegative/authorization_addpartition.q.out b/ql/src/test/results/clientnegative/authorization_addpartition.q.out
index a14080a58d..9ab2ef825a 100644
--- a/ql/src/test/results/clientnegative/authorization_addpartition.q.out
+++ b/ql/src/test/results/clientnegative/authorization_addpartition.q.out
@@ -7,4 +7,4 @@ create table tpart(i int, j int) partitioned by (k string)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@tpart
-FAILED: HiveAccessControlException Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.tpart] for operation ALTERTABLE_ADDPARTS : [INSERT]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation ALTERTABLE_ADDPARTS [[INSERT] on Object [type=TABLE_OR_VIEW, name=default.tpart]]
diff --git a/ql/src/test/results/clientnegative/authorization_alter_db_owner.q.out b/ql/src/test/results/clientnegative/authorization_alter_db_owner.q.out
index 928e9f5949..6f65f30a82 100644
--- a/ql/src/test/results/clientnegative/authorization_alter_db_owner.q.out
+++ b/ql/src/test/results/clientnegative/authorization_alter_db_owner.q.out
@@ -6,4 +6,4 @@ PREHOOK: type: CREATEDATABASE
 
 create database dbao
 POSTHOOK: type: CREATEDATABASE
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=DATABASE, name=dbao] for operation ALTERDATABASE_OWNER : [ADMIN PRIVILEGE]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation ALTERDATABASE_OWNER [[ADMIN PRIVILEGE] on Object [type=DATABASE, name=dbao]]
diff --git a/ql/src/test/results/clientnegative/authorization_alter_db_owner_default.q.out b/ql/src/test/results/clientnegative/authorization_alter_db_owner_default.q.out
index d4a617e8ed..323ffc2f87 100644
--- a/ql/src/test/results/clientnegative/authorization_alter_db_owner_default.q.out
+++ b/ql/src/test/results/clientnegative/authorization_alter_db_owner_default.q.out
@@ -1 +1 @@
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=DATABASE, name=default] for operation ALTERDATABASE_OWNER : [ADMIN PRIVILEGE]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation ALTERDATABASE_OWNER [[ADMIN PRIVILEGE] on Object [type=DATABASE, name=default]]
diff --git a/ql/src/test/results/clientnegative/authorization_compile.q.out b/ql/src/test/results/clientnegative/authorization_compile.q.out
index cf5e4d1045..3d6f8a87b2 100644
--- a/ql/src/test/results/clientnegative/authorization_compile.q.out
+++ b/ql/src/test/results/clientnegative/authorization_compile.q.out
@@ -1 +1 @@
-Query returned non-zero code: 1, cause: Permission denied. Principal [name=hive_test_user, type=USER] does not have following privileges on Object [type=COMMAND_PARAMS, name=[`dummy code ` AS groovy NAMED something.groovy]] for operation COMPILE : [ADMIN PRIVILEGE]
+Query returned non-zero code: 1, cause: Permission denied: Principal [name=hive_test_user, type=USER] does not have following privileges for operation COMPILE [[ADMIN PRIVILEGE] on Object [type=COMMAND_PARAMS, name=[`dummy code ` AS groovy NAMED something.groovy]]]
diff --git a/ql/src/test/results/clientnegative/authorization_create_func1.q.out b/ql/src/test/results/clientnegative/authorization_create_func1.q.out
index 8863e91a78..3bc49a6279 100644
--- a/ql/src/test/results/clientnegative/authorization_create_func1.q.out
+++ b/ql/src/test/results/clientnegative/authorization_create_func1.q.out
@@ -1 +1 @@
-FAILED: HiveAccessControlException Permission denied. Principal [name=hive_test_user, type=USER] does not have following privileges on Object [type=DATABASE, name=default] for operation CREATEFUNCTION : [ADMIN PRIVILEGE]
+FAILED: HiveAccessControlException Permission denied: Principal [name=hive_test_user, type=USER] does not have following privileges for operation CREATEFUNCTION [[ADMIN PRIVILEGE] on Object [type=DATABASE, name=default], [ADMIN PRIVILEGE] on Object [type=FUNCTION, name=perm_fn]]
diff --git a/ql/src/test/results/clientnegative/authorization_create_func2.q.out b/ql/src/test/results/clientnegative/authorization_create_func2.q.out
index 8863e91a78..0afd36fd32 100644
--- a/ql/src/test/results/clientnegative/authorization_create_func2.q.out
+++ b/ql/src/test/results/clientnegative/authorization_create_func2.q.out
@@ -1 +1 @@
-FAILED: HiveAccessControlException Permission denied. Principal [name=hive_test_user, type=USER] does not have following privileges on Object [type=DATABASE, name=default] for operation CREATEFUNCTION : [ADMIN PRIVILEGE]
+FAILED: HiveAccessControlException Permission denied: Principal [name=hive_test_user, type=USER] does not have following privileges for operation CREATEFUNCTION [[ADMIN PRIVILEGE] on Object [type=FUNCTION, name=temp_fn]]
diff --git a/ql/src/test/results/clientnegative/authorization_create_macro1.q.out b/ql/src/test/results/clientnegative/authorization_create_macro1.q.out
index e4d410c283..4676b75fa0 100644
--- a/ql/src/test/results/clientnegative/authorization_create_macro1.q.out
+++ b/ql/src/test/results/clientnegative/authorization_create_macro1.q.out
@@ -1 +1 @@
-FAILED: HiveAccessControlException Permission denied. Principal [name=hive_test_user, type=USER] does not have following privileges on Object [type=DATABASE, name=default] for operation CREATEMACRO : [ADMIN PRIVILEGE]
+FAILED: HiveAccessControlException Permission denied: Principal [name=hive_test_user, type=USER] does not have following privileges for operation CREATEMACRO [[ADMIN PRIVILEGE] on Object [type=DATABASE, name=default]]
diff --git a/ql/src/test/results/clientnegative/authorization_createview.q.out b/ql/src/test/results/clientnegative/authorization_createview.q.out
index 3d0d191fca..ea14743037 100644
--- a/ql/src/test/results/clientnegative/authorization_createview.q.out
+++ b/ql/src/test/results/clientnegative/authorization_createview.q.out
@@ -7,4 +7,4 @@ create table t1(i int)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@t1
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation CREATEVIEW : [SELECT with grant]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation CREATEVIEW [[SELECT with grant] on Object [type=TABLE_OR_VIEW, name=default.t1]]
diff --git a/ql/src/test/results/clientnegative/authorization_ctas.q.out b/ql/src/test/results/clientnegative/authorization_ctas.q.out
index c9d0130bce..ad704fa608 100644
--- a/ql/src/test/results/clientnegative/authorization_ctas.q.out
+++ b/ql/src/test/results/clientnegative/authorization_ctas.q.out
@@ -7,4 +7,4 @@ create table t1(i int)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@t1
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation CREATETABLE_AS_SELECT : [SELECT]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation CREATETABLE_AS_SELECT [[SELECT] on Object [type=TABLE_OR_VIEW, name=default.t1]]
diff --git a/ql/src/test/results/clientnegative/authorization_deletejar.q.out b/ql/src/test/results/clientnegative/authorization_deletejar.q.out
index 71b11fda83..5ad3526338 100644
--- a/ql/src/test/results/clientnegative/authorization_deletejar.q.out
+++ b/ql/src/test/results/clientnegative/authorization_deletejar.q.out
@@ -1 +1 @@
-Query returned non-zero code: 1, cause: Permission denied. Principal [name=hive_test_user, type=USER] does not have following privileges on Object [type=COMMAND_PARAMS, name=[jar, dummy.jar]] for operation DELETE : [ADMIN PRIVILEGE]
+Query returned non-zero code: 1, cause: Permission denied: Principal [name=hive_test_user, type=USER] does not have following privileges for operation DELETE [[ADMIN PRIVILEGE] on Object [type=COMMAND_PARAMS, name=[jar, dummy.jar]]]
diff --git a/ql/src/test/results/clientnegative/authorization_desc_table_nosel.q.out b/ql/src/test/results/clientnegative/authorization_desc_table_nosel.q.out
index 4583f569f1..bb402ec394 100644
--- a/ql/src/test/results/clientnegative/authorization_desc_table_nosel.q.out
+++ b/ql/src/test/results/clientnegative/authorization_desc_table_nosel.q.out
@@ -26,4 +26,4 @@ PREHOOK: Output: default@t1
 POSTHOOK: query: revoke select on table t1 from user user2
 POSTHOOK: type: REVOKE_PRIVILEGE
 POSTHOOK: Output: default@t1
-FAILED: HiveAccessControlException Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation DESCTABLE : [SELECT]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation DESCTABLE [[SELECT] on Object [type=TABLE_OR_VIEW, name=default.t1]]
diff --git a/ql/src/test/results/clientnegative/authorization_dfs.q.out b/ql/src/test/results/clientnegative/authorization_dfs.q.out
index e95f563120..9cb5646441 100644
--- a/ql/src/test/results/clientnegative/authorization_dfs.q.out
+++ b/ql/src/test/results/clientnegative/authorization_dfs.q.out
@@ -1 +1 @@
-Query returned non-zero code: 1, cause: Permission denied. Principal [name=hive_test_user, type=USER] does not have following privileges on Object [type=COMMAND_PARAMS, name=[-ls, dummy_file]] for operation DFS : [ADMIN PRIVILEGE]
+Query returned non-zero code: 1, cause: Permission denied: Principal [name=hive_test_user, type=USER] does not have following privileges for operation DFS [[ADMIN PRIVILEGE] on Object [type=COMMAND_PARAMS, name=[-ls, dummy_file]]]
diff --git a/ql/src/test/results/clientnegative/authorization_drop_db_cascade.q.out b/ql/src/test/results/clientnegative/authorization_drop_db_cascade.q.out
index 0bf82fc090..2eb7184dfe 100644
--- a/ql/src/test/results/clientnegative/authorization_drop_db_cascade.q.out
+++ b/ql/src/test/results/clientnegative/authorization_drop_db_cascade.q.out
@@ -50,4 +50,4 @@ POSTHOOK: query: show current roles
 POSTHOOK: type: SHOW_ROLES
 public
 
-FAILED: HiveAccessControlException Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=dba2.tab2] for operation DROPDATABASE : [OBJECT OWNERSHIP]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation DROPDATABASE [[OBJECT OWNERSHIP] on Object [type=TABLE_OR_VIEW, name=dba2.tab2]]
diff --git a/ql/src/test/results/clientnegative/authorization_drop_db_empty.q.out b/ql/src/test/results/clientnegative/authorization_drop_db_empty.q.out
index 93a3f1cd1f..097f0deec2 100644
--- a/ql/src/test/results/clientnegative/authorization_drop_db_empty.q.out
+++ b/ql/src/test/results/clientnegative/authorization_drop_db_empty.q.out
@@ -46,4 +46,4 @@ POSTHOOK: query: show current roles
 POSTHOOK: type: SHOW_ROLES
 public
 
-FAILED: HiveAccessControlException Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=DATABASE, name=dba2] for operation DROPDATABASE : [OBJECT OWNERSHIP]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation DROPDATABASE [[OBJECT OWNERSHIP] on Object [type=DATABASE, name=dba2]]
diff --git a/ql/src/test/results/clientnegative/authorization_droppartition.q.out b/ql/src/test/results/clientnegative/authorization_droppartition.q.out
index 3efabfeafc..a5b8ce24bd 100644
--- a/ql/src/test/results/clientnegative/authorization_droppartition.q.out
+++ b/ql/src/test/results/clientnegative/authorization_droppartition.q.out
@@ -16,4 +16,4 @@ POSTHOOK: type: ALTERTABLE_ADDPARTS
 #### A masked pattern was here ####
 POSTHOOK: Output: default@tpart
 POSTHOOK: Output: default@tpart@k=abc
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.tpart] for operation ALTERTABLE_DROPPARTS : [DELETE]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation ALTERTABLE_DROPPARTS [[DELETE] on Object [type=TABLE_OR_VIEW, name=default.tpart]]
diff --git a/ql/src/test/results/clientnegative/authorization_fail_8.q.out b/ql/src/test/results/clientnegative/authorization_fail_8.q.out
index fecb15c4c5..6c9fcf4c6e 100644
--- a/ql/src/test/results/clientnegative/authorization_fail_8.q.out
+++ b/ql/src/test/results/clientnegative/authorization_fail_8.q.out
@@ -45,4 +45,4 @@ PREHOOK: query: -- Now that grant option has been revoked, granting to other use
 GRANT SELECT ON authorization_fail TO USER user3
 PREHOOK: type: GRANT_PRIVILEGE
 PREHOOK: Output: default@authorization_fail
-FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.authorization_fail] for operation GRANT_PRIVILEGE : [SELECT with grant]
+FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation GRANT_PRIVILEGE [[SELECT with grant] on Object [type=TABLE_OR_VIEW, name=default.authorization_fail]]
diff --git a/ql/src/test/results/clientnegative/authorization_grant_table_allpriv.q.out b/ql/src/test/results/clientnegative/authorization_grant_table_allpriv.q.out
index ab4fd1c164..8098d5dd82 100644
--- a/ql/src/test/results/clientnegative/authorization_grant_table_allpriv.q.out
+++ b/ql/src/test/results/clientnegative/authorization_grant_table_allpriv.q.out
@@ -21,4 +21,4 @@ PREHOOK: query: -- try grant all to user3, without having all privileges
 GRANT ALL ON table_priv_allf TO USER user3
 PREHOOK: type: GRANT_PRIVILEGE
 PREHOOK: Output: default@table_priv_allf
-FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.table_priv_allf] for operation GRANT_PRIVILEGE : [SELECT with grant, UPDATE with grant, DELETE with grant]
+FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation GRANT_PRIVILEGE [[SELECT with grant, UPDATE with grant, DELETE with grant] on Object [type=TABLE_OR_VIEW, name=default.table_priv_allf]]
diff --git a/ql/src/test/results/clientnegative/authorization_grant_table_fail1.q.out b/ql/src/test/results/clientnegative/authorization_grant_table_fail1.q.out
index 0975a9ca71..cec3619908 100644
--- a/ql/src/test/results/clientnegative/authorization_grant_table_fail1.q.out
+++ b/ql/src/test/results/clientnegative/authorization_grant_table_fail1.q.out
@@ -13,4 +13,4 @@ PREHOOK: query: -- try grant insert to user3 as user2
 GRANT INSERT ON table_priv_gfail1 TO USER user3
 PREHOOK: type: GRANT_PRIVILEGE
 PREHOOK: Output: default@table_priv_gfail1
-FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.table_priv_gfail1] for operation GRANT_PRIVILEGE : [INSERT with grant]
+FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation GRANT_PRIVILEGE [[INSERT with grant] on Object [type=TABLE_OR_VIEW, name=default.table_priv_gfail1]]
diff --git a/ql/src/test/results/clientnegative/authorization_grant_table_fail_nogrant.q.out b/ql/src/test/results/clientnegative/authorization_grant_table_fail_nogrant.q.out
index 8e3d71c246..67f048fe86 100644
--- a/ql/src/test/results/clientnegative/authorization_grant_table_fail_nogrant.q.out
+++ b/ql/src/test/results/clientnegative/authorization_grant_table_fail_nogrant.q.out
@@ -21,4 +21,4 @@ PREHOOK: query: -- try grant insert to user3
 GRANT INSERT ON table_priv_gfail1 TO USER user3
 PREHOOK: type: GRANT_PRIVILEGE
 PREHOOK: Output: default@table_priv_gfail1
-FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.table_priv_gfail1] for operation GRANT_PRIVILEGE : [INSERT with grant]
+FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation GRANT_PRIVILEGE [[INSERT with grant] on Object [type=TABLE_OR_VIEW, name=default.table_priv_gfail1]]
diff --git a/ql/src/test/results/clientnegative/authorization_insert_noinspriv.q.out b/ql/src/test/results/clientnegative/authorization_insert_noinspriv.q.out
index 332d8a49cd..63ef757a0e 100644
--- a/ql/src/test/results/clientnegative/authorization_insert_noinspriv.q.out
+++ b/ql/src/test/results/clientnegative/authorization_insert_noinspriv.q.out
@@ -14,4 +14,4 @@ POSTHOOK: query: create table user2tab(i int)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@user2tab
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation QUERY : [INSERT]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation QUERY [[INSERT] on Object [type=TABLE_OR_VIEW, name=default.t1, action=INSERT]]
diff --git a/ql/src/test/results/clientnegative/authorization_insert_noselectpriv.q.out b/ql/src/test/results/clientnegative/authorization_insert_noselectpriv.q.out
index 1423e75706..c9ed7542b7 100644
--- a/ql/src/test/results/clientnegative/authorization_insert_noselectpriv.q.out
+++ b/ql/src/test/results/clientnegative/authorization_insert_noselectpriv.q.out
@@ -14,4 +14,4 @@ POSTHOOK: query: create table t2(i int)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@t2
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation QUERY : [SELECT]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation QUERY [[SELECT] on Object [type=TABLE_OR_VIEW, name=default.t1]]
diff --git a/ql/src/test/results/clientnegative/authorization_insertoverwrite_nodel.q.out b/ql/src/test/results/clientnegative/authorization_insertoverwrite_nodel.q.out
index 458e65b2ec..10a5df0aa4 100644
--- a/ql/src/test/results/clientnegative/authorization_insertoverwrite_nodel.q.out
+++ b/ql/src/test/results/clientnegative/authorization_insertoverwrite_nodel.q.out
@@ -33,4 +33,4 @@ POSTHOOK: query: create table user1tab(i int)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@user1tab
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation QUERY : [DELETE]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation QUERY [[DELETE] on Object [type=TABLE_OR_VIEW, name=default.t1, action=INSERT_OVERWRITE]]
diff --git a/ql/src/test/results/clientnegative/authorization_not_owner_alter_tab_rename.q.out b/ql/src/test/results/clientnegative/authorization_not_owner_alter_tab_rename.q.out
index 39642e3c15..c3bd34f5f0 100644
--- a/ql/src/test/results/clientnegative/authorization_not_owner_alter_tab_rename.q.out
+++ b/ql/src/test/results/clientnegative/authorization_not_owner_alter_tab_rename.q.out
@@ -7,4 +7,4 @@ create table t1(i int)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@t1
-FAILED: HiveAccessControlException Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation ALTERTABLE_RENAME : [OBJECT OWNERSHIP]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation ALTERTABLE_RENAME [[OBJECT OWNERSHIP] on Object [type=TABLE_OR_VIEW, name=default.t1], [OBJECT OWNERSHIP] on Object [type=TABLE_OR_VIEW, name=default.t1]]
diff --git a/ql/src/test/results/clientnegative/authorization_not_owner_alter_tab_serdeprop.q.out b/ql/src/test/results/clientnegative/authorization_not_owner_alter_tab_serdeprop.q.out
index 96df5a7986..3b3df095e9 100644
--- a/ql/src/test/results/clientnegative/authorization_not_owner_alter_tab_serdeprop.q.out
+++ b/ql/src/test/results/clientnegative/authorization_not_owner_alter_tab_serdeprop.q.out
@@ -7,4 +7,4 @@ create table t1(i int)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@t1
-FAILED: HiveAccessControlException Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation ALTERTABLE_SERDEPROPERTIES : [OBJECT OWNERSHIP]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation ALTERTABLE_SERDEPROPERTIES [[OBJECT OWNERSHIP] on Object [type=TABLE_OR_VIEW, name=default.t1], [OBJECT OWNERSHIP] on Object [type=TABLE_OR_VIEW, name=default.t1]]
diff --git a/ql/src/test/results/clientnegative/authorization_not_owner_drop_tab.q.out b/ql/src/test/results/clientnegative/authorization_not_owner_drop_tab.q.out
index bf22e89a7e..14b4521a75 100644
--- a/ql/src/test/results/clientnegative/authorization_not_owner_drop_tab.q.out
+++ b/ql/src/test/results/clientnegative/authorization_not_owner_drop_tab.q.out
@@ -7,4 +7,4 @@ create table t1(i int)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@t1
-FAILED: HiveAccessControlException Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation DROPTABLE : [OBJECT OWNERSHIP]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation DROPTABLE [[OBJECT OWNERSHIP] on Object [type=TABLE_OR_VIEW, name=default.t1]]
diff --git a/ql/src/test/results/clientnegative/authorization_not_owner_drop_view.q.out b/ql/src/test/results/clientnegative/authorization_not_owner_drop_view.q.out
index acdc0f347e..73c214bc49 100644
--- a/ql/src/test/results/clientnegative/authorization_not_owner_drop_view.q.out
+++ b/ql/src/test/results/clientnegative/authorization_not_owner_drop_view.q.out
@@ -14,4 +14,4 @@ POSTHOOK: query: create view vt1 as select * from t1
 POSTHOOK: type: CREATEVIEW
 POSTHOOK: Input: default@t1
 POSTHOOK: Output: default@vt1
-FAILED: HiveAccessControlException Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.vt1] for operation DROPVIEW : [OBJECT OWNERSHIP]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation DROPVIEW [[OBJECT OWNERSHIP] on Object [type=TABLE_OR_VIEW, name=default.vt1], [OBJECT OWNERSHIP] on Object [type=TABLE_OR_VIEW, name=default.vt1]]
diff --git a/ql/src/test/results/clientnegative/authorization_priv_current_role_neg.q.out b/ql/src/test/results/clientnegative/authorization_priv_current_role_neg.q.out
index 16927fdc7c..b20ebc848f 100644
--- a/ql/src/test/results/clientnegative/authorization_priv_current_role_neg.q.out
+++ b/ql/src/test/results/clientnegative/authorization_priv_current_role_neg.q.out
@@ -76,4 +76,4 @@ PREHOOK: query: -- set role to public, should fail as role2 is not one of the cu
 grant all on table tpriv_current_role to user user5
 PREHOOK: type: GRANT_PRIVILEGE
 PREHOOK: Output: default@tpriv_current_role
-FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.tpriv_current_role] for operation GRANT_PRIVILEGE : [SELECT with grant, INSERT with grant, UPDATE with grant, DELETE with grant]
+FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation GRANT_PRIVILEGE [[SELECT with grant, INSERT with grant, UPDATE with grant, DELETE with grant] on Object [type=TABLE_OR_VIEW, name=default.tpriv_current_role]]
diff --git a/ql/src/test/results/clientnegative/authorization_rolehierarchy_privs.q.out b/ql/src/test/results/clientnegative/authorization_rolehierarchy_privs.q.out
index 0dcb653ba8..46e3ca74e4 100644
--- a/ql/src/test/results/clientnegative/authorization_rolehierarchy_privs.q.out
+++ b/ql/src/test/results/clientnegative/authorization_rolehierarchy_privs.q.out
@@ -206,4 +206,4 @@ role1
 role2
 role4
 
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation QUERY : [SELECT]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation QUERY [[SELECT] on Object [type=TABLE_OR_VIEW, name=default.t1]]
diff --git a/ql/src/test/results/clientnegative/authorization_select.q.out b/ql/src/test/results/clientnegative/authorization_select.q.out
index 78542000e3..c718e8c357 100644
--- a/ql/src/test/results/clientnegative/authorization_select.q.out
+++ b/ql/src/test/results/clientnegative/authorization_select.q.out
@@ -7,4 +7,4 @@ create table t1(i int)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@t1
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation QUERY : [SELECT]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation QUERY [[SELECT] on Object [type=TABLE_OR_VIEW, name=default.t1]]
diff --git a/ql/src/test/results/clientnegative/authorization_select_view.q.out b/ql/src/test/results/clientnegative/authorization_select_view.q.out
index 9f1e07ede8..877f77f258 100644
--- a/ql/src/test/results/clientnegative/authorization_select_view.q.out
+++ b/ql/src/test/results/clientnegative/authorization_select_view.q.out
@@ -14,4 +14,4 @@ POSTHOOK: query: create view v1 as select * from t1
 POSTHOOK: type: CREATEVIEW
 POSTHOOK: Input: default@t1
 POSTHOOK: Output: default@v1
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.v1] for operation QUERY : [SELECT]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation QUERY [[SELECT] on Object [type=TABLE_OR_VIEW, name=default.v1]]
diff --git a/ql/src/test/results/clientnegative/authorization_show_parts_nosel.q.out b/ql/src/test/results/clientnegative/authorization_show_parts_nosel.q.out
index 306fe2e316..2f7b723335 100644
--- a/ql/src/test/results/clientnegative/authorization_show_parts_nosel.q.out
+++ b/ql/src/test/results/clientnegative/authorization_show_parts_nosel.q.out
@@ -7,4 +7,4 @@ create table t_show_parts(i int) partitioned by (j string)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@t_show_parts
-FAILED: HiveAccessControlException Permission denied. Principal [name=user2, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t_show_parts] for operation SHOWPARTITIONS : [SELECT]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user2, type=USER] does not have following privileges for operation SHOWPARTITIONS [[SELECT] on Object [type=TABLE_OR_VIEW, name=default.t_show_parts]]
diff --git a/ql/src/test/results/clientnegative/authorization_truncate.q.out b/ql/src/test/results/clientnegative/authorization_truncate.q.out
index 3f19aa9484..a414b33563 100644
--- a/ql/src/test/results/clientnegative/authorization_truncate.q.out
+++ b/ql/src/test/results/clientnegative/authorization_truncate.q.out
@@ -7,4 +7,4 @@ create table t1(i int, j int)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@t1
-FAILED: HiveAccessControlException Permission denied. Principal [name=user1, type=USER] does not have following privileges on Object [type=TABLE_OR_VIEW, name=default.t1] for operation TRUNCATETABLE : [OBJECT OWNERSHIP]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user1, type=USER] does not have following privileges for operation TRUNCATETABLE [[OBJECT OWNERSHIP] on Object [type=TABLE_OR_VIEW, name=default.t1]]
diff --git a/ql/src/test/results/clientnegative/authorize_create_tbl.q.out b/ql/src/test/results/clientnegative/authorize_create_tbl.q.out
index 64ebd8beb3..2322e427cd 100644
--- a/ql/src/test/results/clientnegative/authorize_create_tbl.q.out
+++ b/ql/src/test/results/clientnegative/authorize_create_tbl.q.out
@@ -6,4 +6,4 @@ PREHOOK: query: use db23221
 PREHOOK: type: SWITCHDATABASE
 POSTHOOK: query: use db23221
 POSTHOOK: type: SWITCHDATABASE
-FAILED: HiveAccessControlException Permission denied. Principal [name=user44, type=USER] does not have following privileges on Object [type=DATABASE, name=db23221] for operation CREATETABLE : [OBJECT OWNERSHIP]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user44, type=USER] does not have following privileges for operation CREATETABLE [[OBJECT OWNERSHIP] on Object [type=DATABASE, name=db23221]]
diff --git a/ql/src/test/results/clientnegative/create_function_nonexistent_class.q.out b/ql/src/test/results/clientnegative/create_function_nonexistent_class.q.out
index fcd5ce7913..c7405edede 100644
--- a/ql/src/test/results/clientnegative/create_function_nonexistent_class.q.out
+++ b/ql/src/test/results/clientnegative/create_function_nonexistent_class.q.out
@@ -1,5 +1,6 @@
 PREHOOK: query: create function default.badfunc as 'my.nonexistent.class'
 PREHOOK: type: CREATEFUNCTION
 PREHOOK: Output: database:default
+PREHOOK: Output: default.badfunc
 FAILED: Class my.nonexistent.class not found
 FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.FunctionTask
diff --git a/ql/src/test/results/clientnegative/create_function_nonudf_class.q.out b/ql/src/test/results/clientnegative/create_function_nonudf_class.q.out
index 26565bebb7..d0dd50ae2e 100644
--- a/ql/src/test/results/clientnegative/create_function_nonudf_class.q.out
+++ b/ql/src/test/results/clientnegative/create_function_nonudf_class.q.out
@@ -1,5 +1,6 @@
 PREHOOK: query: create function default.badfunc as 'java.lang.String'
 PREHOOK: type: CREATEFUNCTION
 PREHOOK: Output: database:default
+PREHOOK: Output: default.badfunc
 FAILED: Class java.lang.String does not implement UDF, GenericUDF, or UDAF
 FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.FunctionTask
diff --git a/ql/src/test/results/clientnegative/create_udaf_failure.q.out b/ql/src/test/results/clientnegative/create_udaf_failure.q.out
index 433ec44c5d..07c5859cf5 100644
--- a/ql/src/test/results/clientnegative/create_udaf_failure.q.out
+++ b/ql/src/test/results/clientnegative/create_udaf_failure.q.out
@@ -1,7 +1,7 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION test_udaf AS 'org.apache.hadoop.hive.ql.udf.UDAFWrongArgLengthForTestCase'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_udaf
 POSTHOOK: query: CREATE TEMPORARY FUNCTION test_udaf AS 'org.apache.hadoop.hive.ql.udf.UDAFWrongArgLengthForTestCase'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_udaf
 FAILED: SemanticException org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException: public boolean org.apache.hadoop.hive.ql.udf.UDAFWrongArgLengthForTestCase$UDAFWrongArgLengthForTestCaseEvaluator.merge() requires 0 arguments but 1 are passed in.
diff --git a/ql/src/test/results/clientnegative/create_unknown_genericudf.q.out b/ql/src/test/results/clientnegative/create_unknown_genericudf.q.out
index 1a2956fd55..ad1371d6a5 100644
--- a/ql/src/test/results/clientnegative/create_unknown_genericudf.q.out
+++ b/ql/src/test/results/clientnegative/create_unknown_genericudf.q.out
@@ -1,5 +1,5 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION dummy_genericudf AS 'org.apache.hadoop.hive.ql.udf.generic.DummyGenericUDF'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: dummy_genericudf
 FAILED: Class org.apache.hadoop.hive.ql.udf.generic.DummyGenericUDF not found
 FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.FunctionTask
diff --git a/ql/src/test/results/clientnegative/create_unknown_udf_udaf.q.out b/ql/src/test/results/clientnegative/create_unknown_udf_udaf.q.out
index 4263be9b9b..bfb72b4415 100644
--- a/ql/src/test/results/clientnegative/create_unknown_udf_udaf.q.out
+++ b/ql/src/test/results/clientnegative/create_unknown_udf_udaf.q.out
@@ -1,5 +1,5 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION dummy_function AS 'org.apache.hadoop.hive.ql.udf.DummyFunction'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: dummy_function
 FAILED: Class org.apache.hadoop.hive.ql.udf.DummyFunction not found
 FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.FunctionTask
diff --git a/ql/src/test/results/clientnegative/drop_native_udf.q.out b/ql/src/test/results/clientnegative/drop_native_udf.q.out
index 81b17935c9..9f0eaa5130 100644
--- a/ql/src/test/results/clientnegative/drop_native_udf.q.out
+++ b/ql/src/test/results/clientnegative/drop_native_udf.q.out
@@ -1,4 +1,4 @@
 PREHOOK: query: DROP TEMPORARY FUNCTION max
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: max
 FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.FunctionTask
diff --git a/ql/src/test/results/clientnegative/temp_table_authorize_create_tbl.q.out b/ql/src/test/results/clientnegative/temp_table_authorize_create_tbl.q.out
index 64ebd8beb3..2322e427cd 100644
--- a/ql/src/test/results/clientnegative/temp_table_authorize_create_tbl.q.out
+++ b/ql/src/test/results/clientnegative/temp_table_authorize_create_tbl.q.out
@@ -6,4 +6,4 @@ PREHOOK: query: use db23221
 PREHOOK: type: SWITCHDATABASE
 POSTHOOK: query: use db23221
 POSTHOOK: type: SWITCHDATABASE
-FAILED: HiveAccessControlException Permission denied. Principal [name=user44, type=USER] does not have following privileges on Object [type=DATABASE, name=db23221] for operation CREATETABLE : [OBJECT OWNERSHIP]
+FAILED: HiveAccessControlException Permission denied: Principal [name=user44, type=USER] does not have following privileges for operation CREATETABLE [[OBJECT OWNERSHIP] on Object [type=DATABASE, name=db23221]]
diff --git a/ql/src/test/results/clientnegative/udf_function_does_not_implement_udf.q.out b/ql/src/test/results/clientnegative/udf_function_does_not_implement_udf.q.out
index 0bf56a45ca..ab42da766a 100644
--- a/ql/src/test/results/clientnegative/udf_function_does_not_implement_udf.q.out
+++ b/ql/src/test/results/clientnegative/udf_function_does_not_implement_udf.q.out
@@ -1,5 +1,5 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION moo AS 'org.apache.hadoop.hive.ql.Driver'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: moo
 FAILED: Class org.apache.hadoop.hive.ql.Driver does not implement UDF, GenericUDF, or UDAF
 FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.FunctionTask
diff --git a/ql/src/test/results/clientnegative/udf_local_resource.q.out b/ql/src/test/results/clientnegative/udf_local_resource.q.out
index 9e6b09be8c..13a17260c4 100644
--- a/ql/src/test/results/clientnegative/udf_local_resource.q.out
+++ b/ql/src/test/results/clientnegative/udf_local_resource.q.out
@@ -1,4 +1,5 @@
 PREHOOK: query: create function lookup as 'org.apache.hadoop.hive.ql.udf.UDFFileLookup' using file '../../data/files/sales.txt'
 PREHOOK: type: CREATEFUNCTION
 PREHOOK: Output: database:default
+PREHOOK: Output: lookup
 FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.FunctionTask. Hive warehouse is non-local, but ../../data/files/sales.txt specifies file on local filesystem. Resources on non-local warehouse should specify a non-local scheme/path
diff --git a/ql/src/test/results/clientnegative/udf_nonexistent_resource.q.out b/ql/src/test/results/clientnegative/udf_nonexistent_resource.q.out
index 38434288e8..bb8ce14986 100644
--- a/ql/src/test/results/clientnegative/udf_nonexistent_resource.q.out
+++ b/ql/src/test/results/clientnegative/udf_nonexistent_resource.q.out
@@ -1,5 +1,6 @@
 PREHOOK: query: create function lookup as 'org.apache.hadoop.hive.ql.udf.UDFFileLookup' using file 'nonexistent_file.txt'
 PREHOOK: type: CREATEFUNCTION
 PREHOOK: Output: database:default
+PREHOOK: Output: lookup
 nonexistent_file.txt does not exist
 FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.FunctionTask. nonexistent_file.txt does not exist
diff --git a/ql/src/test/results/clientnegative/udf_test_error.q.out b/ql/src/test/results/clientnegative/udf_test_error.q.out
index 3146652404..5ad5ff6ccb 100644
--- a/ql/src/test/results/clientnegative/udf_test_error.q.out
+++ b/ql/src/test/results/clientnegative/udf_test_error.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION test_error AS 'org.apache.hadoop.hive.ql.udf.UDFTestErrorOnFalse'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_error
 POSTHOOK: query: CREATE TEMPORARY FUNCTION test_error AS 'org.apache.hadoop.hive.ql.udf.UDFTestErrorOnFalse'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_error
 PREHOOK: query: SELECT test_error(key < 125 OR key > 130) FROM src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
diff --git a/ql/src/test/results/clientnegative/udf_test_error_reduce.q.out b/ql/src/test/results/clientnegative/udf_test_error_reduce.q.out
index c83c50309d..fec6b5d86b 100644
--- a/ql/src/test/results/clientnegative/udf_test_error_reduce.q.out
+++ b/ql/src/test/results/clientnegative/udf_test_error_reduce.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION test_error AS 'org.apache.hadoop.hive.ql.udf.UDFTestErrorOnFalse'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_error
 POSTHOOK: query: CREATE TEMPORARY FUNCTION test_error AS 'org.apache.hadoop.hive.ql.udf.UDFTestErrorOnFalse'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_error
 PREHOOK: query: SELECT test_error(key < 125 OR key > 130)
 FROM (
   SELECT *
diff --git a/ql/src/test/results/clientpositive/authorization_admin_almighty2.q.out b/ql/src/test/results/clientpositive/authorization_admin_almighty2.q.out
index 1c8c3e3fd8..34dbef84d8 100644
--- a/ql/src/test/results/clientpositive/authorization_admin_almighty2.q.out
+++ b/ql/src/test/results/clientpositive/authorization_admin_almighty2.q.out
@@ -29,10 +29,10 @@ POSTHOOK: query: drop table a_table
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: CREATE TEMPORARY FUNCTION Pyth as 'Pyth'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: pyth
 POSTHOOK: query: CREATE TEMPORARY FUNCTION Pyth as 'Pyth'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: pyth
 PREHOOK: query: SELECT Pyth(3,4) FROM src tablesample (1 rows)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -44,7 +44,7 @@ POSTHOOK: Input: default@src
 5.0
 PREHOOK: query: DROP TEMPORARY FUNCTION Pyth
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: Pyth
 POSTHOOK: query: DROP TEMPORARY FUNCTION Pyth
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: Pyth
diff --git a/ql/src/test/results/clientpositive/authorization_create_func1.q.out b/ql/src/test/results/clientpositive/authorization_create_func1.q.out
index 45f93ba78b..597b187006 100644
--- a/ql/src/test/results/clientpositive/authorization_create_func1.q.out
+++ b/ql/src/test/results/clientpositive/authorization_create_func1.q.out
@@ -6,25 +6,29 @@ set role ADMIN
 POSTHOOK: type: SHOW_ROLES
 PREHOOK: query: create temporary function temp_fn as 'org.apache.hadoop.hive.ql.udf.UDFAscii'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: temp_fn
 POSTHOOK: query: create temporary function temp_fn as 'org.apache.hadoop.hive.ql.udf.UDFAscii'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: temp_fn
 PREHOOK: query: create function perm_fn as 'org.apache.hadoop.hive.ql.udf.UDFAscii'
 PREHOOK: type: CREATEFUNCTION
 PREHOOK: Output: database:default
+PREHOOK: Output: perm_fn
 POSTHOOK: query: create function perm_fn as 'org.apache.hadoop.hive.ql.udf.UDFAscii'
 POSTHOOK: type: CREATEFUNCTION
 POSTHOOK: Output: database:default
+POSTHOOK: Output: perm_fn
 PREHOOK: query: drop temporary function temp_fn
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: temp_fn
 POSTHOOK: query: drop temporary function temp_fn
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: temp_fn
 PREHOOK: query: drop function perm_fn
 PREHOOK: type: DROPFUNCTION
 PREHOOK: Output: database:default
+PREHOOK: Output: perm_fn
 POSTHOOK: query: drop function perm_fn
 POSTHOOK: type: DROPFUNCTION
 POSTHOOK: Output: database:default
+POSTHOOK: Output: perm_fn
diff --git a/ql/src/test/results/clientpositive/autogen_colalias.q.out b/ql/src/test/results/clientpositive/autogen_colalias.q.out
index fa5a7b65db..925b3b5ff2 100644
--- a/ql/src/test/results/clientpositive/autogen_colalias.q.out
+++ b/ql/src/test/results/clientpositive/autogen_colalias.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION test_max AS 'org.apache.hadoop.hive.ql.udf.UDAFTestMax'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_max
 POSTHOOK: query: CREATE TEMPORARY FUNCTION test_max AS 'org.apache.hadoop.hive.ql.udf.UDAFTestMax'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_max
 PREHOOK: query: create table dest_grouped_old1 as select 1+1, 2+2 as zz, src.key, test_max(length(src.value)), count(src.value), sin(count(src.value)), count(sin(src.value)), unix_timestamp(), CAST(SUM(IF(value > 10, value, 1)) AS INT), if(src.key > 1,
 1,
 0)
@@ -93,8 +93,8 @@ key                 	string
 PREHOOK: query: -- Drop the temporary function at the end till HIVE-3160 gets fixed
 DROP TEMPORARY FUNCTION test_max
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_max
 POSTHOOK: query: -- Drop the temporary function at the end till HIVE-3160 gets fixed
 DROP TEMPORARY FUNCTION test_max
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_max
diff --git a/ql/src/test/results/clientpositive/compile_processor.q.out b/ql/src/test/results/clientpositive/compile_processor.q.out
index e86e0f3454..74a7255bc8 100644
--- a/ql/src/test/results/clientpositive/compile_processor.q.out
+++ b/ql/src/test/results/clientpositive/compile_processor.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION Pyth as 'Pyth'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: pyth
 POSTHOOK: query: CREATE TEMPORARY FUNCTION Pyth as 'Pyth'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: pyth
 PREHOOK: query: SELECT Pyth(3,4) FROM src tablesample (1 rows)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -15,7 +15,7 @@ POSTHOOK: Input: default@src
 5.0
 PREHOOK: query: DROP TEMPORARY FUNCTION Pyth
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: Pyth
 POSTHOOK: query: DROP TEMPORARY FUNCTION Pyth
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: Pyth
diff --git a/ql/src/test/results/clientpositive/create_func1.q.out b/ql/src/test/results/clientpositive/create_func1.q.out
index 62ca263fbd..daa4ecced3 100644
--- a/ql/src/test/results/clientpositive/create_func1.q.out
+++ b/ql/src/test/results/clientpositive/create_func1.q.out
@@ -16,9 +16,11 @@ POSTHOOK: type: CREATEDATABASE
 PREHOOK: query: create function mydb.func1 as 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFUpper'
 PREHOOK: type: CREATEFUNCTION
 PREHOOK: Output: database:mydb
+PREHOOK: Output: mydb.func1
 POSTHOOK: query: create function mydb.func1 as 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFUpper'
 POSTHOOK: type: CREATEFUNCTION
 POSTHOOK: Output: database:mydb
+POSTHOOK: Output: mydb.func1
 PREHOOK: query: show functions mydb.func1
 PREHOOK: type: SHOWFUNCTIONS
 POSTHOOK: query: show functions mydb.func1
@@ -36,9 +38,11 @@ ABC
 PREHOOK: query: drop function mydb.func1
 PREHOOK: type: DROPFUNCTION
 PREHOOK: Output: database:mydb
+PREHOOK: Output: mydb.func1
 POSTHOOK: query: drop function mydb.func1
 POSTHOOK: type: DROPFUNCTION
 POSTHOOK: Output: database:mydb
+POSTHOOK: Output: mydb.func1
 PREHOOK: query: -- function should now be gone
 show functions mydb.func1
 PREHOOK: type: SHOWFUNCTIONS
@@ -49,10 +53,12 @@ PREHOOK: query: -- To test function name resolution
 create function mydb.qtest_get_java_boolean as 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFUpper'
 PREHOOK: type: CREATEFUNCTION
 PREHOOK: Output: database:mydb
+PREHOOK: Output: mydb.qtest_get_java_boolean
 POSTHOOK: query: -- To test function name resolution
 create function mydb.qtest_get_java_boolean as 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFUpper'
 POSTHOOK: type: CREATEFUNCTION
 POSTHOOK: Output: database:mydb
+POSTHOOK: Output: mydb.qtest_get_java_boolean
 PREHOOK: query: use default
 PREHOOK: type: SWITCHDATABASE
 POSTHOOK: query: use default
@@ -86,9 +92,11 @@ ABC	NULL	ABC
 PREHOOK: query: drop function mydb.qtest_get_java_boolean
 PREHOOK: type: DROPFUNCTION
 PREHOOK: Output: database:mydb
+PREHOOK: Output: mydb.qtest_get_java_boolean
 POSTHOOK: query: drop function mydb.qtest_get_java_boolean
 POSTHOOK: type: DROPFUNCTION
 POSTHOOK: Output: database:mydb
+POSTHOOK: Output: mydb.qtest_get_java_boolean
 PREHOOK: query: drop database mydb cascade
 PREHOOK: type: DROPDATABASE
 PREHOOK: Input: database:mydb
diff --git a/ql/src/test/results/clientpositive/create_genericudaf.q.out b/ql/src/test/results/clientpositive/create_genericudaf.q.out
index 1641e019aa..cdced8a5e8 100644
--- a/ql/src/test/results/clientpositive/create_genericudaf.q.out
+++ b/ql/src/test/results/clientpositive/create_genericudaf.q.out
@@ -12,10 +12,10 @@ STAGE PLANS:
 
 PREHOOK: query: CREATE TEMPORARY FUNCTION test_avg AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDAFAverage'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_avg
 POSTHOOK: query: CREATE TEMPORARY FUNCTION test_avg AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDAFAverage'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_avg
 PREHOOK: query: EXPLAIN
 SELECT
     test_avg(1),
@@ -93,7 +93,7 @@ POSTHOOK: Input: default@src
 1.0	260.182
 PREHOOK: query: DROP TEMPORARY FUNCTIOn test_avg
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_avg
 POSTHOOK: query: DROP TEMPORARY FUNCTIOn test_avg
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_avg
diff --git a/ql/src/test/results/clientpositive/create_genericudf.q.out b/ql/src/test/results/clientpositive/create_genericudf.q.out
index f012951cc2..ba96685535 100644
--- a/ql/src/test/results/clientpositive/create_genericudf.q.out
+++ b/ql/src/test/results/clientpositive/create_genericudf.q.out
@@ -12,10 +12,10 @@ STAGE PLANS:
 
 PREHOOK: query: CREATE TEMPORARY FUNCTION test_translate AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestTranslate'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_translate
 POSTHOOK: query: CREATE TEMPORARY FUNCTION test_translate AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestTranslate'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_translate
 PREHOOK: query: CREATE TABLE dest1(c1 STRING, c2 STRING, c3 STRING, c4 STRING, c5 STRING, c6 STRING, c7 STRING)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
@@ -67,7 +67,7 @@ POSTHOOK: Input: default@dest1
 bbc	bcc	NULL	NULL	NULL	bc	abc
 PREHOOK: query: DROP TEMPORARY FUNCTION test_translate
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_translate
 POSTHOOK: query: DROP TEMPORARY FUNCTION test_translate
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_translate
diff --git a/ql/src/test/results/clientpositive/create_udaf.q.out b/ql/src/test/results/clientpositive/create_udaf.q.out
index e48c25f950..9f20f7964b 100644
--- a/ql/src/test/results/clientpositive/create_udaf.q.out
+++ b/ql/src/test/results/clientpositive/create_udaf.q.out
@@ -12,10 +12,10 @@ STAGE PLANS:
 
 PREHOOK: query: CREATE TEMPORARY FUNCTION test_max AS 'org.apache.hadoop.hive.ql.udf.UDAFTestMax'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_max
 POSTHOOK: query: CREATE TEMPORARY FUNCTION test_max AS 'org.apache.hadoop.hive.ql.udf.UDAFTestMax'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_max
 PREHOOK: query: CREATE TABLE dest1(col INT)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
@@ -90,7 +90,7 @@ POSTHOOK: Input: default@src
 98
 PREHOOK: query: DROP TEMPORARY FUNCTION test_max
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_max
 POSTHOOK: query: DROP TEMPORARY FUNCTION test_max
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_max
diff --git a/ql/src/test/results/clientpositive/create_view.q.out b/ql/src/test/results/clientpositive/create_view.q.out
index e193a4f18d..2fb71ef5a7 100644
--- a/ql/src/test/results/clientpositive/create_view.q.out
+++ b/ql/src/test/results/clientpositive/create_view.q.out
@@ -693,12 +693,12 @@ PREHOOK: query: -- test usage of a function within a view
 CREATE TEMPORARY FUNCTION test_translate AS
 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestTranslate'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_translate
 POSTHOOK: query: -- test usage of a function within a view
 CREATE TEMPORARY FUNCTION test_translate AS
 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestTranslate'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_translate
 PREHOOK: query: CREATE VIEW view8(c) AS
 SELECT test_translate('abc', 'a', 'b')
 FROM table1
@@ -769,12 +769,12 @@ PREHOOK: query: -- test usage of a UDAF within a view
 CREATE TEMPORARY FUNCTION test_max AS
 'org.apache.hadoop.hive.ql.udf.UDAFTestMax'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_max
 POSTHOOK: query: -- test usage of a UDAF within a view
 CREATE TEMPORARY FUNCTION test_max AS
 'org.apache.hadoop.hive.ql.udf.UDAFTestMax'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_max
 PREHOOK: query: -- disable map-side aggregation
 CREATE VIEW view9(m) AS
 SELECT test_max(length(value))
@@ -987,12 +987,12 @@ PREHOOK: query: -- test usage of a UDTF within a view
 CREATE TEMPORARY FUNCTION test_explode AS
 'org.apache.hadoop.hive.ql.udf.generic.GenericUDTFExplode'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_explode
 POSTHOOK: query: -- test usage of a UDTF within a view
 CREATE TEMPORARY FUNCTION test_explode AS
 'org.apache.hadoop.hive.ql.udf.generic.GenericUDTFExplode'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_explode
 PREHOOK: query: CREATE VIEW view11 AS
 SELECT test_explode(array(1,2,3)) AS (boom)
 FROM table1
@@ -1714,19 +1714,19 @@ POSTHOOK: Input: default@view16
 POSTHOOK: Output: default@view16
 PREHOOK: query: DROP TEMPORARY FUNCTION test_translate
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_translate
 POSTHOOK: query: DROP TEMPORARY FUNCTION test_translate
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_translate
 PREHOOK: query: DROP TEMPORARY FUNCTION test_max
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_max
 POSTHOOK: query: DROP TEMPORARY FUNCTION test_max
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_max
 PREHOOK: query: DROP TEMPORARY FUNCTION test_explode
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_explode
 POSTHOOK: query: DROP TEMPORARY FUNCTION test_explode
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_explode
diff --git a/ql/src/test/results/clientpositive/drop_udf.q.out b/ql/src/test/results/clientpositive/drop_udf.q.out
index c60f43141d..7d9cb84d5b 100644
--- a/ql/src/test/results/clientpositive/drop_udf.q.out
+++ b/ql/src/test/results/clientpositive/drop_udf.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: CREATE TEMPORARY FUNCTION test_translate AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestTranslate'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_translate
 POSTHOOK: query: CREATE TEMPORARY FUNCTION test_translate AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestTranslate'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_translate
 PREHOOK: query: EXPLAIN
 DROP TEMPORARY FUNCTION test_translate
 PREHOOK: type: DROPFUNCTION
@@ -18,7 +18,7 @@ STAGE PLANS:
 
 PREHOOK: query: DROP TEMPORARY FUNCTION test_translate
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_translate
 POSTHOOK: query: DROP TEMPORARY FUNCTION test_translate
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_translate
diff --git a/ql/src/test/results/clientpositive/ptf_register_tblfn.q.out b/ql/src/test/results/clientpositive/ptf_register_tblfn.q.out
index 3b810ec9c0..d205371429 100644
--- a/ql/src/test/results/clientpositive/ptf_register_tblfn.q.out
+++ b/ql/src/test/results/clientpositive/ptf_register_tblfn.q.out
@@ -35,10 +35,10 @@ POSTHOOK: type: LOAD
 POSTHOOK: Output: default@flights_tiny
 PREHOOK: query: create temporary function matchpathtest as 'org.apache.hadoop.hive.ql.udf.ptf.MatchPath$MatchPathResolver'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: matchpathtest
 POSTHOOK: query: create temporary function matchpathtest as 'org.apache.hadoop.hive.ql.udf.ptf.MatchPath$MatchPathResolver'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: matchpathtest
 PREHOOK: query: -- 1. basic Matchpath test
 select origin_city_name, fl_num, year, month, day_of_month, sz, tpath 
 from matchpathtest(on 
@@ -83,7 +83,7 @@ Chicago	897	2010	10	21	3	21
 Chicago	897	2010	10	22	2	22
 PREHOOK: query: drop temporary function matchpathtest
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: matchpathtest
 POSTHOOK: query: drop temporary function matchpathtest
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: matchpathtest
diff --git a/ql/src/test/results/clientpositive/ptf_streaming.q.out b/ql/src/test/results/clientpositive/ptf_streaming.q.out
index 04ceedf273..d0392726e6 100644
--- a/ql/src/test/results/clientpositive/ptf_streaming.q.out
+++ b/ql/src/test/results/clientpositive/ptf_streaming.q.out
@@ -41,10 +41,10 @@ POSTHOOK: type: LOAD
 POSTHOOK: Output: default@part
 PREHOOK: query: create temporary function noopstreaming as 'org.apache.hadoop.hive.ql.udf.ptf.NoopStreaming$NoopStreamingResolver'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: noopstreaming
 POSTHOOK: query: create temporary function noopstreaming as 'org.apache.hadoop.hive.ql.udf.ptf.NoopStreaming$NoopStreamingResolver'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: noopstreaming
 PREHOOK: query: --1. test1
 select p_mfgr, p_name, p_size,
 rank() over (partition by p_mfgr order by p_name) as r,
diff --git a/ql/src/test/results/clientpositive/udaf_sum_list.q.out b/ql/src/test/results/clientpositive/udaf_sum_list.q.out
index 51708b3594..3aa0f9ff70 100644
--- a/ql/src/test/results/clientpositive/udaf_sum_list.q.out
+++ b/ql/src/test/results/clientpositive/udaf_sum_list.q.out
@@ -3,13 +3,13 @@ PREHOOK: query: -- HIVE-5279
 -- After
 create temporary function sum_list as 'org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSumList'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: sum_list
 POSTHOOK: query: -- HIVE-5279
 -- GenericUDAFSumList has Converter which does not have default constructor
 -- After
 create temporary function sum_list as 'org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSumList'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: sum_list
 PREHOOK: query: select sum_list(array(key, key)) from src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
diff --git a/ql/src/test/results/clientpositive/udf_compare_java_string.q.out b/ql/src/test/results/clientpositive/udf_compare_java_string.q.out
index e522e517ca..08bac4a26b 100644
--- a/ql/src/test/results/clientpositive/udf_compare_java_string.q.out
+++ b/ql/src/test/results/clientpositive/udf_compare_java_string.q.out
@@ -12,10 +12,10 @@ STAGE PLANS:
 
 PREHOOK: query: CREATE TEMPORARY FUNCTION test_udf_get_java_string AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestGetJavaString'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_udf_get_java_string
 POSTHOOK: query: CREATE TEMPORARY FUNCTION test_udf_get_java_string AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestGetJavaString'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_udf_get_java_string
 PREHOOK: query: select * from src where value = test_udf_get_java_string("val_66")
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
diff --git a/ql/src/test/results/clientpositive/udf_context_aware.q.out b/ql/src/test/results/clientpositive/udf_context_aware.q.out
index 2e214c5a3e..6432e315da 100644
--- a/ql/src/test/results/clientpositive/udf_context_aware.q.out
+++ b/ql/src/test/results/clientpositive/udf_context_aware.q.out
@@ -1,9 +1,9 @@
 PREHOOK: query: create temporary function counter as 'org.apache.hadoop.hive.ql.udf.generic.DummyContextUDF'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: counter
 POSTHOOK: query: create temporary function counter as 'org.apache.hadoop.hive.ql.udf.generic.DummyContextUDF'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: counter
 PREHOOK: query: select *, counter(key) from src limit 20
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
diff --git a/ql/src/test/results/clientpositive/udf_logic_java_boolean.q.out b/ql/src/test/results/clientpositive/udf_logic_java_boolean.q.out
index f48c8b2b6d..b3a14e7f67 100644
--- a/ql/src/test/results/clientpositive/udf_logic_java_boolean.q.out
+++ b/ql/src/test/results/clientpositive/udf_logic_java_boolean.q.out
@@ -12,10 +12,10 @@ STAGE PLANS:
 
 PREHOOK: query: CREATE TEMPORARY FUNCTION test_udf_get_java_boolean AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestGetJavaBoolean'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_udf_get_java_boolean
 POSTHOOK: query: CREATE TEMPORARY FUNCTION test_udf_get_java_boolean AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestGetJavaBoolean'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_udf_get_java_boolean
 PREHOOK: query: select 1 from src where test_udf_get_java_boolean("false") and True limit 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -171,7 +171,7 @@ POSTHOOK: Input: default@src
 #### A masked pattern was here ####
 PREHOOK: query: DROP TEMPORARY FUNCTION test_udf_get_java_boolean
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: test_udf_get_java_boolean
 POSTHOOK: query: DROP TEMPORARY FUNCTION test_udf_get_java_boolean
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: test_udf_get_java_boolean
diff --git a/ql/src/test/results/clientpositive/udf_testlength.q.out b/ql/src/test/results/clientpositive/udf_testlength.q.out
index 28d96faf2d..021bd8d8d4 100644
--- a/ql/src/test/results/clientpositive/udf_testlength.q.out
+++ b/ql/src/test/results/clientpositive/udf_testlength.q.out
@@ -12,10 +12,10 @@ STAGE PLANS:
 
 PREHOOK: query: CREATE TEMPORARY FUNCTION testlength AS 'org.apache.hadoop.hive.ql.udf.UDFTestLength'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: testlength
 POSTHOOK: query: CREATE TEMPORARY FUNCTION testlength AS 'org.apache.hadoop.hive.ql.udf.UDFTestLength'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: testlength
 PREHOOK: query: SELECT testlength(src.value) FROM src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -526,7 +526,7 @@ POSTHOOK: Input: default@src
 6
 PREHOOK: query: DROP TEMPORARY FUNCTION testlength
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: testlength
 POSTHOOK: query: DROP TEMPORARY FUNCTION testlength
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: testlength
diff --git a/ql/src/test/results/clientpositive/udf_testlength2.q.out b/ql/src/test/results/clientpositive/udf_testlength2.q.out
index 4d2c4076a3..ed5b0a4fa6 100644
--- a/ql/src/test/results/clientpositive/udf_testlength2.q.out
+++ b/ql/src/test/results/clientpositive/udf_testlength2.q.out
@@ -12,10 +12,10 @@ STAGE PLANS:
 
 PREHOOK: query: CREATE TEMPORARY FUNCTION testlength2 AS 'org.apache.hadoop.hive.ql.udf.UDFTestLength2'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: testlength2
 POSTHOOK: query: CREATE TEMPORARY FUNCTION testlength2 AS 'org.apache.hadoop.hive.ql.udf.UDFTestLength2'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: testlength2
 PREHOOK: query: SELECT testlength2(src.value) FROM src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -526,7 +526,7 @@ POSTHOOK: Input: default@src
 6
 PREHOOK: query: DROP TEMPORARY FUNCTION testlength2
 PREHOOK: type: DROPFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: testlength2
 POSTHOOK: query: DROP TEMPORARY FUNCTION testlength2
 POSTHOOK: type: DROPFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: testlength2
diff --git a/ql/src/test/results/clientpositive/udf_using.q.out b/ql/src/test/results/clientpositive/udf_using.q.out
index b29e899249..80d1dfa408 100644
--- a/ql/src/test/results/clientpositive/udf_using.q.out
+++ b/ql/src/test/results/clientpositive/udf_using.q.out
@@ -1,9 +1,11 @@
 #### A masked pattern was here ####
 PREHOOK: type: CREATEFUNCTION
 PREHOOK: Output: database:default
+PREHOOK: Output: lookup
 #### A masked pattern was here ####
 POSTHOOK: type: CREATEFUNCTION
 POSTHOOK: Output: database:default
+POSTHOOK: Output: lookup
 PREHOOK: query: create table udf_using (c1 string)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
@@ -41,7 +43,9 @@ POSTHOOK: Output: default@udf_using
 PREHOOK: query: drop function lookup
 PREHOOK: type: DROPFUNCTION
 PREHOOK: Output: database:default
+PREHOOK: Output: lookup
 POSTHOOK: query: drop function lookup
 POSTHOOK: type: DROPFUNCTION
 POSTHOOK: Output: database:default
+POSTHOOK: Output: lookup
 #### A masked pattern was here ####
diff --git a/ql/src/test/results/clientpositive/windowing_udaf2.q.out b/ql/src/test/results/clientpositive/windowing_udaf2.q.out
index 4a4b6cfe58..2498676ac8 100644
--- a/ql/src/test/results/clientpositive/windowing_udaf2.q.out
+++ b/ql/src/test/results/clientpositive/windowing_udaf2.q.out
@@ -1,11 +1,11 @@
 PREHOOK: query: -- user-added aggregates should be usable as windowing functions
 create temporary function mysum as 'org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSum'
 PREHOOK: type: CREATEFUNCTION
-PREHOOK: Output: database:default
+PREHOOK: Output: mysum
 POSTHOOK: query: -- user-added aggregates should be usable as windowing functions
 create temporary function mysum as 'org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSum'
 POSTHOOK: type: CREATEFUNCTION
-POSTHOOK: Output: database:default
+POSTHOOK: Output: mysum
 PREHOOK: query: select sum(key) over (), mysum(key) over () from src limit 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
