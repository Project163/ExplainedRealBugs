diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorAggregationBufferRow.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorAggregationBufferRow.java
index a7ef154ae4..a265e525d3 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorAggregationBufferRow.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorAggregationBufferRow.java
@@ -89,4 +89,8 @@ public int getAccessCount() {
   public void incrementAccessCount() {
     accessed++;
   }
+
+  public void resetAccessCount() {
+    accessed = 0;
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupByOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupByOperator.java
index 85535f569f..02864d930a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupByOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupByOperator.java
@@ -599,8 +599,10 @@ private void flush(boolean all) throws HiveException {
       while(iter.hasNext()) {
         Map.Entry<KeyWrapper, VectorAggregationBufferRow> pair = iter.next();
         if (!all && avgAccess >= 1) {
-          // Retain entries when access pattern is > than average access
           if (pair.getValue().getAccessCount() > avgAccess) {
+            // resetting to give chance for other entries
+            totalAccessCount -= pair.getValue().getAccessCount();
+            pair.getValue().resetAccessCount();
             continue;
           }
         }
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorGroupByOperator.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorGroupByOperator.java
index c22a833c66..d6a8548c22 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorGroupByOperator.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorGroupByOperator.java
@@ -692,11 +692,18 @@ public void inspectRow(Object row, int tag) throws HiveException {
 
     // This processing would trigger flush
     for (VectorizedRowBatch unit: data) {
+      long zeroAccessBeforeFlush = getElementsWithZeroAccess(processingMode.mapKeysAggregationBuffers);
       vgo.process(unit,  0);
       long freqElementsAfterFlush = getElementsHigherThan(processingMode.mapKeysAggregationBuffers, avgAccess);
 
       assertTrue("After flush: " + freqElementsAfterFlush + ", before flush: " + numElementsToBeRetained,
           (freqElementsAfterFlush >= numElementsToBeRetained));
+
+      // ensure that freq elements are reset for providing chance for others
+      long zeroAccessAfterFlush = getElementsWithZeroAccess(processingMode.mapKeysAggregationBuffers);
+      assertTrue("After flush: " + zeroAccessAfterFlush + ", before flush: " + zeroAccessBeforeFlush,
+          (zeroAccessAfterFlush > zeroAccessBeforeFlush));
+
       break;
     }
     vgo.close(false);
@@ -706,6 +713,10 @@ long getElementsHigherThan(Map<KeyWrapper, VectorAggregationBufferRow> aggMap, i
     return aggMap.values().stream().filter(v -> (v.getAccessCount() > avgAccess)).count();
   }
 
+  long getElementsWithZeroAccess(Map<KeyWrapper, VectorAggregationBufferRow> aggMap) {
+    return aggMap.values().stream().filter(v -> (v.getAccessCount() == 0)).count();
+  }
+
   @Test
   public void testMaxHTEntriesFlush() throws HiveException {
 
