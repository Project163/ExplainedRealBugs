diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/SparkWork.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/SparkWork.java
index 9d46cacb96..9ca5544b49 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/SparkWork.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/SparkWork.java
@@ -30,6 +30,7 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
+import java.util.concurrent.atomic.AtomicInteger;
 
 import org.apache.commons.lang3.tuple.ImmutablePair;
 import org.apache.commons.lang3.tuple.Pair;
@@ -47,7 +48,8 @@
 @Explain(displayName = "Spark", explainLevels = { Level.USER, Level.DEFAULT, Level.EXTENDED },
       vectorization = Vectorization.SUMMARY_PATH)
 public class SparkWork extends AbstractOperatorDesc {
-  private static int counter;
+
+  private static final AtomicInteger counter = new AtomicInteger(1);
   private final String name;
 
   private final Set<BaseWork> roots = new LinkedHashSet<BaseWork>();
@@ -65,7 +67,7 @@ public class SparkWork extends AbstractOperatorDesc {
   private Map<BaseWork, BaseWork> cloneToWork;
 
   public SparkWork(String name) {
-    this.name = name + ":" + (++counter);
+    this.name = name + ":" + counter.getAndIncrement();
     cloneToWork = new HashMap<BaseWork, BaseWork>();
   }
 
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/plan/TestTezWorkConcurrency.java b/ql/src/test/org/apache/hadoop/hive/ql/plan/TestExecutionEngineWorkConcurrency.java
similarity index 56%
rename from ql/src/test/org/apache/hadoop/hive/ql/plan/TestTezWorkConcurrency.java
rename to ql/src/test/org/apache/hadoop/hive/ql/plan/TestExecutionEngineWorkConcurrency.java
index 9af1c1bf00..a7fcad07ad 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/plan/TestTezWorkConcurrency.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/plan/TestExecutionEngineWorkConcurrency.java
@@ -19,8 +19,13 @@
 
 import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
+
 import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
 
+import java.util.Arrays;
+import java.util.Collection;
 import java.util.List;
 import java.util.Set;
 import java.util.concurrent.Callable;
@@ -32,14 +37,27 @@
 
 import static org.junit.Assert.assertEquals;
 
-public final class TestTezWorkConcurrency {
+
+@RunWith(Parameterized.class)
+public final class TestExecutionEngineWorkConcurrency {
+
+  @Parameterized.Parameters
+  public static Collection<Object[]> data() {
+    return Arrays.asList(new Object[][]{{new TezDagIdProvider()}, {new SparkDagIdProvider()}});
+  }
+
+  private final ExecutionEngineDagIdGenerator executionEngineDagIdGenerator;
+
+  public TestExecutionEngineWorkConcurrency(ExecutionEngineDagIdGenerator executionEngineDagIdGenerator) {
+    this.executionEngineDagIdGenerator = executionEngineDagIdGenerator;
+  }
 
   @Test
   public void ensureDagIdIsUnique() throws Exception {
     final int threadCount = 5;
     final CountDownLatch threadReadyToStartSignal = new CountDownLatch(threadCount);
     final CountDownLatch startThreadSignal = new CountDownLatch(1);
-    final int numberOfTezWorkToCreatePerThread = 100;
+    final int numberOfWorkToCreatePerThread = 100;
 
     List<FutureTask<Set<String>>> tasks = Lists.newArrayList();
     for (int i = 0; i < threadCount; i++) {
@@ -48,7 +66,7 @@ public void ensureDagIdIsUnique() throws Exception {
         public Set<String> call() throws Exception {
           threadReadyToStartSignal.countDown();
           startThreadSignal.await();
-          return generateTezWorkDagIds(numberOfTezWorkToCreatePerThread);
+          return generateWorkDagIds(numberOfWorkToCreatePerThread);
         }
       }));
     }
@@ -58,25 +76,44 @@ public Set<String> call() throws Exception {
     }
     threadReadyToStartSignal.await();
     startThreadSignal.countDown();
-    Set<String> allTezWorkDagIds = getAllTezWorkDagIds(tasks);
-    assertEquals(threadCount * numberOfTezWorkToCreatePerThread, allTezWorkDagIds.size());
+    Set<String> allWorkDagIds = getAllWorkDagIds(tasks);
+    assertEquals(threadCount * numberOfWorkToCreatePerThread, allWorkDagIds.size());
   }
 
-  private static Set<String> generateTezWorkDagIds(int numberOfNames) {
-    Set<String> tezWorkIds = Sets.newHashSet();
+  private Set<String> generateWorkDagIds(int numberOfNames) {
+    Set<String> workIds = Sets.newHashSet();
     for (int i = 0; i < numberOfNames; i++) {
-      TezWork work = new TezWork("query-id");
-      tezWorkIds.add(work.getDagId());
+      workIds.add(executionEngineDagIdGenerator.getDagId());
     }
-    return tezWorkIds;
+    return workIds;
   }
 
-  private static Set<String> getAllTezWorkDagIds(List<FutureTask<Set<String>>> tasks)
+  private static Set<String> getAllWorkDagIds(List<FutureTask<Set<String>>> tasks)
       throws ExecutionException, InterruptedException {
-    Set<String> allTezWorkDagIds = Sets.newHashSet();
+    Set<String> allWorkDagIds = Sets.newHashSet();
     for (FutureTask<Set<String>> task : tasks) {
-      allTezWorkDagIds.addAll(task.get());
+      allWorkDagIds.addAll(task.get());
+    }
+    return allWorkDagIds;
+  }
+
+  private interface ExecutionEngineDagIdGenerator {
+    String getDagId();
+  }
+
+  private static final class TezDagIdProvider implements ExecutionEngineDagIdGenerator {
+
+    @Override
+    public String getDagId() {
+      return new TezWork("query-id").getDagId();
+    }
+  }
+
+  private static final class SparkDagIdProvider implements ExecutionEngineDagIdGenerator {
+
+    @Override
+    public String getDagId() {
+      return new SparkWork("query-id").getName();
     }
-    return allTezWorkDagIds;
   }
 }
