diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
index 948fc6eb04..7732b5f767 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
@@ -2812,7 +2812,9 @@ public void testViewsReplication() throws IOException {
 
     run("CREATE TABLE " + dbName + ".unptned(a string) STORED AS TEXTFILE", driver);
     run("CREATE TABLE " + dbName + ".ptned(a string) partitioned by (b int) STORED AS TEXTFILE", driver);
+    run("CREATE TABLE " + dbName + ".ext_ptned(a string) partitioned by (b int) STORED AS TEXTFILE", driver);
     run("CREATE VIEW " + dbName + ".virtual_view AS SELECT * FROM " + dbName + ".unptned", driver);
+    run("CREATE VIEW " + dbName + ".virtual_view_with_partition PARTITIONED ON (b) AS SELECT * FROM " + dbName + ".ext_ptned", driver);
 
     String[] unptn_data = new String[]{ "eleven" , "twelve" };
     String[] ptn_data_1 = new String[]{ "thirteen", "fourteen", "fifteen"};
@@ -2822,14 +2824,17 @@ public void testViewsReplication() throws IOException {
     String unptn_locn = new Path(TEST_PATH , testName + "_unptn").toUri().getPath();
     String ptn_locn_1 = new Path(TEST_PATH , testName + "_ptn1").toUri().getPath();
     String ptn_locn_2 = new Path(TEST_PATH , testName + "_ptn2").toUri().getPath();
+    String ext_ptned_locn = new Path(TEST_PATH , testName + "_ext_ptned").toUri().getPath();
 
     createTestDataFile(unptn_locn, unptn_data);
+    createTestDataFile(ext_ptned_locn, unptn_data);
     createTestDataFile(ptn_locn_1, ptn_data_1);
     createTestDataFile(ptn_locn_2, ptn_data_2);
 
     verifySetup("SELECT a from " + dbName + ".ptned", empty, driver);
     verifySetup("SELECT * from " + dbName + ".unptned", empty, driver);
     verifySetup("SELECT * from " + dbName + ".virtual_view", empty, driver);
+    verifySetup("SELECT * from " + dbName + ".virtual_view_with_partition", empty, driver);
 
     run("LOAD DATA LOCAL INPATH '" + unptn_locn + "' OVERWRITE INTO TABLE " + dbName + ".unptned", driver);
     verifySetup("SELECT * from " + dbName + ".unptned", unptn_data, driver);
@@ -2840,6 +2845,9 @@ public void testViewsReplication() throws IOException {
     run("LOAD DATA LOCAL INPATH '" + ptn_locn_2 + "' OVERWRITE INTO TABLE " + dbName + ".ptned PARTITION(b=2)", driver);
     verifySetup("SELECT a from " + dbName + ".ptned WHERE b=2", ptn_data_2, driver);
 
+    run("LOAD DATA LOCAL INPATH '" + ext_ptned_locn + "' OVERWRITE INTO TABLE " + dbName + ".ext_ptned PARTITION(b=2)", driver);
+    verifySetup("SELECT a from " + dbName + ".ext_ptned WHERE b=2", ptn_data_2, driver);
+
     // TODO: This does not work because materialized views need the creation metadata
     // to be updated in case tables used were replicated to a different database.
     //run("CREATE MATERIALIZED VIEW " + dbName + ".mat_view AS SELECT a FROM " + dbName + ".ptned where b=1", driver);
@@ -2851,12 +2859,17 @@ public void testViewsReplication() throws IOException {
     verifyRun("SELECT * from " + replDbName + ".virtual_view", empty, driverMirror);
     //verifyRun("SELECT a from " + replDbName + ".mat_view", ptn_data_1, driverMirror);
 
+    verifySetup("SELECT * from " + replDbName + ".virtual_view_with_partition", empty, driver);
+
     run("CREATE VIEW " + dbName + ".virtual_view2 AS SELECT a FROM " + dbName + ".ptned where b=2", driver);
     verifySetup("SELECT a from " + dbName + ".virtual_view2", ptn_data_2, driver);
 
     // Create a view with name already exist. Just to verify if failure flow clears the added create_table event.
     run("CREATE VIEW " + dbName + ".virtual_view2 AS SELECT a FROM " + dbName + ".ptned where b=2", driver);
 
+    // Create view with partition
+    run("CREATE VIEW " + dbName + ".virtual_view_with_partition_2 PARTITIONED ON (b) AS SELECT * FROM " + dbName + ".ext_ptned", driver);
+
     //run("CREATE MATERIALIZED VIEW " + dbName + ".mat_view2 AS SELECT * FROM " + dbName + ".unptned", driver);
     //verifySetup("SELECT * from " + dbName + ".mat_view2", unptn_data, driver);
 
@@ -2871,6 +2884,7 @@ public void testViewsReplication() throws IOException {
     // view is referring to old database, so no data
     verifyRun("SELECT * from " + replDbName + ".virtual_view2", empty, driverMirror);
     //verifyRun("SELECT * from " + replDbName + ".mat_view2", unptn_data, driverMirror);
+    verifySetup("SELECT * from " + dbName + ".virtual_view_with_partition_2", empty, driver);
 
     // Test "alter table" with rename
     run("ALTER VIEW " + dbName + ".virtual_view RENAME TO " + dbName + ".virtual_view_rename", driver);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadTask.java
index 666f99b629..91b59f3b8f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadTask.java
@@ -428,29 +428,6 @@ private TaskTracker addLoadFunctionTasks(Context loadContext, BootstrapEventsIte
     return functionsTracker;
   }
 
-  public static Task<?> createViewTask(MetaData metaData, String dbNameToLoadIn, HiveConf conf)
-      throws SemanticException {
-    Table table = new Table(metaData.getTable());
-    String dbName = dbNameToLoadIn == null ? table.getDbName() : dbNameToLoadIn;
-    TableName tableName = HiveTableName.ofNullable(table.getTableName(), dbName);
-    String dbDotView = tableName.getNotEmptyDbTable();
-
-    String viewOriginalText = table.getViewOriginalText();
-    String viewExpandedText = table.getViewExpandedText();
-    if (!dbName.equals(table.getDbName())) {
-      // TODO: If the DB name doesn't match with the metadata from dump, then need to rewrite the original and expanded
-      // texts using new DB name. Currently it refers to the source database name.
-    }
-
-    CreateViewDesc desc = new CreateViewDesc(dbDotView, table.getAllCols(), null, table.getParameters(),
-        table.getPartColNames(), false, false, viewOriginalText, viewExpandedText, table.getPartCols());
-
-    desc.setReplicationSpec(metaData.getReplicationSpec());
-    desc.setOwnerName(table.getOwner());
-
-    return TaskFactory.get(new DDLWork(new HashSet<>(), new HashSet<>(), desc), conf);
-  }
-
   public static Task<?> createViewTask(MetaData metaData, String dbNameToLoadIn, HiveConf conf,
                                        String dumpDirectory, ReplicationMetricCollector metricCollector)
           throws SemanticException {
@@ -466,7 +443,7 @@ public static Task<?> createViewTask(MetaData metaData, String dbNameToLoadIn, H
       // texts using new DB name. Currently it refers to the source database name.
     }
 
-    CreateViewDesc desc = new CreateViewDesc(dbDotView, table.getAllCols(), null, table.getParameters(),
+    CreateViewDesc desc = new CreateViewDesc(dbDotView, table.getCols(), null, table.getParameters(),
             table.getPartColNames(), false, false, viewOriginalText, viewExpandedText, table.getPartCols());
 
     desc.setReplicationSpec(metaData.getReplicationSpec());
