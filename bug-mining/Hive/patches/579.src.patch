diff --git a/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveQueryResultSet.java b/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveQueryResultSet.java
index 9419ecf830..239cb8d75f 100644
--- a/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveQueryResultSet.java
+++ b/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveQueryResultSet.java
@@ -21,6 +21,7 @@
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Iterator;
 import java.util.List;
 import java.util.Properties;
 
@@ -54,6 +55,10 @@ public class HiveQueryResultSet extends HiveBaseResultSet {
 
   private int maxRows = 0;
   private int rowsFetched = 0;
+  private int fetchSize = 50;
+
+  private List<String> fetchedRows;
+  private Iterator<String> fetchedRowsItr;
 
   public HiveQueryResultSet(HiveInterface client, int maxRows) throws SQLException {
     this.client = client;
@@ -96,18 +101,18 @@ private void initSerde() throws SQLException {
       serde = new LazySimpleSerDe();
       Properties props = new Properties();
       if (names.length() > 0) {
-        LOG.info("Column names: " + names);
+        LOG.debug("Column names: " + names);
         props.setProperty(Constants.LIST_COLUMNS, names);
       }
       if (types.length() > 0) {
-        LOG.info("Column types: " + types);
+        LOG.debug("Column types: " + types);
         props.setProperty(Constants.LIST_COLUMN_TYPES, types);
       }
       serde.initialize(new Configuration(), props);
 
     } catch (Exception ex) {
       ex.printStackTrace();
-      throw new SQLException("Could not create ResultSet: " + ex.getMessage());
+      throw new SQLException("Could not create ResultSet: " + ex.getMessage(), ex);
     }
   }
 
@@ -128,9 +133,19 @@ public boolean next() throws SQLException {
       return false;
     }
 
-    String rowStr = "";
     try {
-      rowStr = (String) client.fetchOne();
+      if (fetchedRows == null || !fetchedRowsItr.hasNext()) {
+        fetchedRows = client.fetchN(fetchSize);
+        fetchedRowsItr = fetchedRows.iterator();
+      }
+
+      String rowStr = "";
+      if (fetchedRowsItr.hasNext()) {
+        rowStr = fetchedRowsItr.next();
+      } else {
+        return false;
+      }
+
       rowsFetched++;
       if (LOG.isDebugEnabled()) {
         LOG.debug("Fetched row string: " + rowStr);
@@ -165,6 +180,16 @@ public boolean next() throws SQLException {
     return true;
   }
 
+  @Override
+  public void setFetchSize(int rows) throws SQLException {
+    fetchSize = rows;
+  }
+
+  @Override
+  public int getFetchSize() throws SQLException {
+    return fetchSize;
+  }
+
   /**
    * Convert a LazyObject to a standard Java object in compliance with JDBC 3.0 (see JDBC 3.0
    * Specification, Table B-3: Mapping from JDBC Types to Java Object Types).
diff --git a/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveStatement.java b/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveStatement.java
index 0b60995fc0..5e028b9ad3 100644
--- a/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveStatement.java
+++ b/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveStatement.java
@@ -33,6 +33,8 @@
 public class HiveStatement implements java.sql.Statement {
   private JdbcSessionState session;
   private HiveInterface client;
+  private int fetchSize = 50;
+
   /**
    * We need to keep a reference to the result set to support the following:
    * <code>
@@ -191,6 +193,7 @@ public ResultSet executeQuery(String sql) throws SQLException {
       throw new SQLException(ex.toString(), "08S01");
     }
     resultSet = new HiveQueryResultSet(client, maxRows);
+    resultSet.setFetchSize(fetchSize);
     return resultSet;
   }
 
@@ -266,7 +269,7 @@ public int getFetchDirection() throws SQLException {
    */
 
   public int getFetchSize() throws SQLException {
-    throw new SQLException("Method not supported");
+    return fetchSize;
   }
 
   /*
@@ -446,7 +449,7 @@ public void setFetchDirection(int direction) throws SQLException {
    */
 
   public void setFetchSize(int rows) throws SQLException {
-    throw new SQLException("Method not supported");
+    fetchSize = rows;
   }
 
   /*
diff --git a/jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java b/jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java
index 3148a5e91c..a0822a4072 100644
--- a/jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java
+++ b/jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java
@@ -192,19 +192,23 @@ protected void tearDown() throws Exception {
   }
 
   public final void testSelectAll() throws Exception {
-    doTestSelectAll(tableName, -1); // tests not setting maxRows (return all)
-    doTestSelectAll(tableName, 0); // tests setting maxRows to 0 (return all)
+    doTestSelectAll(tableName, -1, -1); // tests not setting maxRows (return all)
+    doTestSelectAll(tableName, 0, -1); // tests setting maxRows to 0 (return all)
   }
 
   public final void testSelectAllPartioned() throws Exception {
-    doTestSelectAll(partitionedTableName, -1); // tests not setting maxRows
+    doTestSelectAll(partitionedTableName, -1, -1); // tests not setting maxRows
     // (return all)
-    doTestSelectAll(partitionedTableName, 0); // tests setting maxRows to 0
+    doTestSelectAll(partitionedTableName, 0, -1); // tests setting maxRows to 0
     // (return all)
   }
 
   public final void testSelectAllMaxRows() throws Exception {
-    doTestSelectAll(tableName, 100);
+    doTestSelectAll(tableName, 100, -1);
+  }
+
+  public final void testSelectAllFetchSize() throws Exception {
+    doTestSelectAll(tableName, 100, 20);
   }
 
   public void testDataTypes() throws Exception {
@@ -267,11 +271,15 @@ public void testDataTypes() throws Exception {
     assertFalse(res.next());
   }
 
-  private void doTestSelectAll(String tableName, int maxRows) throws Exception {
+  private void doTestSelectAll(String tableName, int maxRows, int fetchSize) throws Exception {
     Statement stmt = con.createStatement();
     if (maxRows >= 0) {
       stmt.setMaxRows(maxRows);
     }
+    if (fetchSize > 0) {
+      stmt.setFetchSize(fetchSize);
+      assertEquals(fetchSize, stmt.getFetchSize());
+    }
 
     // JDBC says that 0 means return all, which is the default
     int expectedMaxRows = maxRows < 1 ? 0 : maxRows;
