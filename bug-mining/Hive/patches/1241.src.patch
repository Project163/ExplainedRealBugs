diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index e8cf2e4ffd..7689c58766 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -2428,6 +2428,7 @@ private Operator<?> genSelectPlan(ASTNode selExprList, QB qb,
       posn++;
     }
 
+    boolean subQuery = qb.getParseInfo().getIsSubQ();
     boolean isInTransform = (selExprList.getChild(posn).getChild(0).getType() ==
         HiveParser.TOK_TRANSFORM);
     if (isInTransform) {
@@ -2463,6 +2464,10 @@ private Operator<?> genSelectPlan(ASTNode selExprList, QB qb,
         unparseTranslator.addIdentifierTranslation((ASTNode) udtfExpr
             .getChild(0));
       }
+      if (isUDTF && (selectStar = udtfExprType == HiveParser.TOK_FUNCTIONSTAR)) {
+        genColListRegex(".*", null, (ASTNode) udtfExpr.getChild(0),
+            col_list, inputRR, pos, out_rwsch, qb.getAliases(), subQuery);
+      }
     }
 
     if (isUDTF) {
@@ -2567,7 +2572,6 @@ private Operator<?> genSelectPlan(ASTNode selExprList, QB qb,
 
       }
 
-      boolean subQuery = qb.getParseInfo().getIsSubQ();
       if (expr.getType() == HiveParser.TOK_ALLCOLREF) {
         pos = genColListRegex(".*", expr.getChildCount() == 0 ? null
             : getUnescapedName((ASTNode) expr.getChild(0)).toLowerCase(),
diff --git a/ql/src/test/queries/clientpositive/allcolref_in_udf.q b/ql/src/test/queries/clientpositive/allcolref_in_udf.q
index cdc32a32d2..020975cc69 100644
--- a/ql/src/test/queries/clientpositive/allcolref_in_udf.q
+++ b/ql/src/test/queries/clientpositive/allcolref_in_udf.q
@@ -14,3 +14,8 @@ select stack(2, *) as (e1,e2,e3) from (
 select stack(2, *) as (e1,e2,e3) from (
   select concat(*), concat(a.*), concat(b.*), concat(a.*, b.key), concat(a.key, b.*)
   from src a join src b on a.key+1=b.key where a.key < 100) x limit 10;
+
+-- HIVE-4181 TOK_FUNCTIONSTAR for UDTF
+create table allcolref as select array(key, value) from src;
+explain select explode(*) as x from allcolref limit 10;
+select explode(*) as x from allcolref limit 10;
diff --git a/ql/src/test/results/clientpositive/allcolref_in_udf.q.out b/ql/src/test/results/clientpositive/allcolref_in_udf.q.out
index af7fc5e1a2..ecbfca8156 100644
--- a/ql/src/test/results/clientpositive/allcolref_in_udf.q.out
+++ b/ql/src/test/results/clientpositive/allcolref_in_udf.q.out
@@ -186,3 +186,68 @@ POSTHOOK: Input: default@src
 8val_89	NULL	9val_9
 9val_910val_10	9val_9	10val_10
 9val_910	NULL	10val_10
+PREHOOK: query: -- HIVE-4181 TOK_FUNCTIONSTAR for UDTF
+create table allcolref as select array(key, value) from src
+PREHOOK: type: CREATETABLE_AS_SELECT
+PREHOOK: Input: default@src
+POSTHOOK: query: -- HIVE-4181 TOK_FUNCTIONSTAR for UDTF
+create table allcolref as select array(key, value) from src
+POSTHOOK: type: CREATETABLE_AS_SELECT
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@allcolref
+PREHOOK: query: explain select explode(*) as x from allcolref limit 10
+PREHOOK: type: QUERY
+POSTHOOK: query: explain select explode(*) as x from allcolref limit 10
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME allcolref))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONSTAR explode) x)) (TOK_LIMIT 10)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        allcolref 
+          TableScan
+            alias: allcolref
+            Select Operator
+              expressions:
+                    expr: _c0
+                    type: array<string>
+              outputColumnNames: _col0
+              UDTF Operator
+                function name: explode
+                Limit
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 0
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 10
+
+
+PREHOOK: query: select explode(*) as x from allcolref limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@allcolref
+#### A masked pattern was here ####
+POSTHOOK: query: select explode(*) as x from allcolref limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@allcolref
+#### A masked pattern was here ####
+238
+val_238
+86
+val_86
+311
+val_311
+27
+val_27
+165
+val_165
