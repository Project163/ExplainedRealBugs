diff --git a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/HCatRecordSerDe.java b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/HCatRecordSerDe.java
index 722e05d924..81c79438fe 100644
--- a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/HCatRecordSerDe.java
+++ b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/HCatRecordSerDe.java
@@ -29,6 +29,7 @@
 import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.SerDe;
 import org.apache.hadoop.hive.serde2.SerDeException;
+import org.apache.hadoop.hive.serde2.SerDeSpec;
 import org.apache.hadoop.hive.serde2.SerDeStats;
 import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector;
@@ -51,6 +52,10 @@
 /**
  * SerDe class for serializing to and from HCatRecord
  */
+
+@SerDeSpec(schemaProps = {serdeConstants.LIST_COLUMNS,
+                          serdeConstants.LIST_COLUMN_TYPES})
+
 public class HCatRecordSerDe implements SerDe {
 
   private static final Logger LOG = LoggerFactory.getLogger(HCatRecordSerDe.class);
@@ -124,7 +129,7 @@ public Object deserialize(Writable data) throws SerDeException {
       throw new SerDeException(getClass().getName() + ": expects HCatRecord!");
     }
 
-    return (HCatRecord) data;
+    return data;
   }
 
   /**
@@ -302,7 +307,7 @@ private static Object serializePrimitiveField(Object field,
    */
   @Override
   public ObjectInspector getObjectInspector() throws SerDeException {
-    return (ObjectInspector) cachedObjectInspector;
+    return cachedObjectInspector;
   }
 
   @Override
diff --git a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java
index 6b683230e7..9b325b6660 100644
--- a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java
+++ b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java
@@ -40,6 +40,7 @@
 import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.SerDe;
 import org.apache.hadoop.hive.serde2.SerDeException;
+import org.apache.hadoop.hive.serde2.SerDeSpec;
 import org.apache.hadoop.hive.serde2.SerDeStats;
 import org.apache.hadoop.hive.serde2.SerDeUtils;
 import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;
@@ -84,6 +85,10 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+@SerDeSpec(schemaProps = {serdeConstants.LIST_COLUMNS,
+                          serdeConstants.LIST_COLUMN_TYPES,
+                          serdeConstants.TIMESTAMP_FORMATS})
+
 public class JsonSerDe implements SerDe {
 
   private static final Logger LOG = LoggerFactory.getLogger(JsonSerDe.class);
@@ -497,7 +502,7 @@ private static void buildJSONString(StringBuilder sb, Object o, ObjectInspector
           break;
         }
         case STRING: {
-          String s = 
+          String s =
                   SerDeUtils.escapeString(((StringObjectInspector) poi).getPrimitiveJavaObject(o));
           appendWithQuotes(sb, s);
           break;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java
index 92968b918a..258d28ec79 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java
@@ -604,7 +604,13 @@ private boolean needConversion(PartitionDesc partitionDesc) {
   // if table and all partitions have the same schema and serde, no need to convert
   private boolean needConversion(TableDesc tableDesc, List<PartitionDesc> partDescs) {
     Class<?> tableSerDe = tableDesc.getDeserializerClass();
-    String[] schemaProps = AnnotationUtils.getAnnotation(tableSerDe, SerDeSpec.class).schemaProps();
+    SerDeSpec spec = AnnotationUtils.getAnnotation(tableSerDe, SerDeSpec.class);
+    if (null == spec) {
+      // Serde may not have this optional annotation defined in which case be conservative
+      // and say conversion is needed.
+      return true;
+    }
+    String[] schemaProps = spec.schemaProps();
     Properties tableProps = tableDesc.getProperties();
     for (PartitionDesc partitionDesc : partDescs) {
       if (!tableSerDe.getName().equals(partitionDesc.getDeserializerClassName())) {
