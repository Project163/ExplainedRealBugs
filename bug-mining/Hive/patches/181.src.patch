diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java
index ae00ae282c..2c91055850 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java
@@ -124,10 +124,15 @@ public void map(Object key, Object value,
         }
 
         rp = reporter;
-      } catch (Exception e) {
+      } catch (Throwable e) {
         abort = true;
         e.printStackTrace();
-        throw new RuntimeException ("Map operator initialization failed", e);
+        if (e instanceof OutOfMemoryError) {
+          // Don't create a new object if we are already out of memory 
+          throw (OutOfMemoryError) e; 
+        } else {
+          throw new RuntimeException ("Map operator initialization failed", e);
+        }
       }
     }
 
@@ -137,10 +142,15 @@ public void map(Object key, Object value,
       else
         // Since there is no concept of a group, we don't invoke startGroup/endGroup for a mapper
         mo.process((Writable)value);
-    } catch (Exception e) {
+    } catch (Throwable e) {
       abort = true;
       e.printStackTrace();
-      throw new RuntimeException ("Map operator process failed", e);
+      if (e instanceof OutOfMemoryError) {
+        // Don't create a new object if we are already out of memory 
+        throw (OutOfMemoryError) e; 
+      } else {
+        throw new RuntimeException (e.getMessage(), e);
+      }
     }
   }
 
@@ -151,10 +161,15 @@ public void close() {
         l4j.trace("Close called no row");
         mo.initialize(jc, null, null);
         rp = null;
-      } catch (Exception e) {
+      } catch (Throwable e) {
         abort = true;
         e.printStackTrace();
-        throw new RuntimeException ("Map operator close failed during initialize", e);
+        if (e instanceof OutOfMemoryError) {
+          // Don't create a new object if we are already out of memory 
+          throw (OutOfMemoryError) e; 
+        } else {
+          throw new RuntimeException ("Map operator close failed during initialize", e);
+        }
       }
     }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecReducer.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecReducer.java
index 073009de66..bee1dbe24e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecReducer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecReducer.java
@@ -118,10 +118,15 @@ public void reduce(Object key, Iterator values,
         reducer.setOutputCollector(oc);
         reducer.initialize(jc, reporter, rowObjectInspector);
         rp = reporter;
-      } catch (Exception e) {
+      } catch (Throwable e) {
         abort = true;
         e.printStackTrace();
-        throw new RuntimeException ("Reduce operator process failed", e);
+        if (e instanceof OutOfMemoryError) {
+          // Don't create a new object if we are already out of memory 
+          throw (OutOfMemoryError) e; 
+        } else {
+          throw new RuntimeException ("Reduce operator initialization failed");
+        }
       }
     }
 
@@ -175,9 +180,14 @@ public void reduce(Object key, Iterator values,
         reducer.process(row, rowObjectInspector[tag.get()], tag.get());
       }
 
-    } catch (Exception e) {
+    } catch (Throwable e) {
       abort = true;
-      throw new IOException (e);
+      if (e instanceof OutOfMemoryError) {
+        // Don't create a new object if we are already out of memory 
+        throw (OutOfMemoryError) e; 
+      } else {
+        throw new IOException (e);
+      }
     }
   }
 
@@ -198,10 +208,15 @@ public void close() {
         l4j.trace("Close called no row");
         reducer.initialize(jc, null, rowObjectInspector);
         rp = null;
-      } catch (Exception e) {
+      } catch (Throwable e) {
         abort = true;
         e.printStackTrace();
-        throw new RuntimeException ("Reduce operator close failed during initialize", e);
+        if (e instanceof OutOfMemoryError) {
+          // Don't create a new object if we are already out of memory 
+          throw (OutOfMemoryError) e; 
+        } else {
+          throw new RuntimeException ("Reduce operator close failed during initialize", e);
+        }
       }
     }
 
