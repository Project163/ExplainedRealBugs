diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
index 85ec142767..eb9205b9bf 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
@@ -83,7 +83,6 @@
 import org.apache.hadoop.mapred.JobConf;
 import org.apache.hadoop.mapred.Partitioner;
 import org.apache.hadoop.mapred.RunningJob;
-import org.apache.hadoop.mapred.lib.TotalOrderPartitioner;
 import org.apache.log4j.Appender;
 import org.apache.log4j.BasicConfigurator;
 import org.apache.log4j.FileAppender;
@@ -505,7 +504,7 @@ private void handleSampling(DriverContext context, MapWork mWork, JobConf job, H
     String tmpPath = context.getCtx().getExternalTmpFileURI(onePath.toUri());
 
     Path partitionFile = new Path(tmpPath, ".partitions");
-    TotalOrderPartitioner.setPartitionFile(job, partitionFile);
+    ShimLoader.getHadoopShims().setTotalOrderPartitionFile(job, partitionFile);
 
     PartitionKeySampler sampler = new PartitionKeySampler();
 
diff --git a/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java b/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java
index a9200de3ff..d2bb34db46 100644
--- a/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java
+++ b/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java
@@ -63,6 +63,7 @@
 import org.apache.hadoop.mapred.TaskLogServlet;
 import org.apache.hadoop.mapred.lib.CombineFileInputFormat;
 import org.apache.hadoop.mapred.lib.CombineFileSplit;
+import org.apache.hadoop.mapred.lib.TotalOrderPartitioner;
 import org.apache.hadoop.mapreduce.Job;
 import org.apache.hadoop.mapreduce.TaskAttemptID;
 import org.apache.hadoop.security.SecurityUtil;
@@ -77,6 +78,7 @@
  * Implemention of shims against Hadoop 0.20.0.
  */
 public class Hadoop20Shims implements HadoopShims {
+
   public boolean usesJobShell() {
     return false;
   }
@@ -194,6 +196,10 @@ public RecordReader getRecordReader(InputSplit split,
     };
   }
 
+  public void setTotalOrderPartitionFile(JobConf jobConf, Path partitionFile){
+    TotalOrderPartitioner.setPartitionFile(jobConf, partitionFile);
+  }
+
   public static class InputSplitShim extends CombineFileSplit implements HadoopShims.InputSplitShim {
     long shrinkedLength;
     boolean _isShrinked;
diff --git a/shims/src/0.20S/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java b/shims/src/0.20S/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
index e4a632d019..3c933937d4 100644
--- a/shims/src/0.20S/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
+++ b/shims/src/0.20S/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
@@ -34,6 +34,8 @@
 import org.apache.hadoop.mapreduce.Job;
 import org.apache.hadoop.mapreduce.TaskAttemptID;
 import org.apache.hadoop.util.Progressable;
+import org.apache.hadoop.mapred.lib.TotalOrderPartitioner;
+
 
 /**
  * Implemention of shims against Hadoop 0.20 with Security.
@@ -122,6 +124,11 @@ public short getDefaultReplication(FileSystem fs, Path path) {
     return fs.getDefaultReplication();
   }
 
+  @Override
+  public void setTotalOrderPartitionFile(JobConf jobConf, Path partitionFile){
+    TotalOrderPartitioner.setPartitionFile(jobConf, partitionFile);
+  }
+
   /**
    * Returns a shim to wrap MiniMrCluster
    */
diff --git a/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java b/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
index 1975385433..62d7fc6429 100644
--- a/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
+++ b/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
@@ -40,6 +40,8 @@
 import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl;
 import org.apache.hadoop.mapreduce.util.HostUtil;
 import org.apache.hadoop.util.Progressable;
+import org.apache.hadoop.mapred.lib.TotalOrderPartitioner;
+
 
 /**
  * Implemention of shims against Hadoop 0.23.0.
@@ -137,6 +139,11 @@ public boolean moveToAppropriateTrash(FileSystem fs, Path path, Configuration co
     return Trash.moveToAppropriateTrash(fs, path, conf);
   }
 
+  @Override
+  public void setTotalOrderPartitionFile(JobConf jobConf, Path partitionFile){
+    TotalOrderPartitioner.setPartitionFile(jobConf, partitionFile);
+  }
+
   /**
    * Returns a shim to wrap MiniMrCluster
    */
diff --git a/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java b/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
index f97534dc7b..30c9fc109a 100644
--- a/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
+++ b/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
@@ -393,6 +393,13 @@ public boolean moveToAppropriateTrash(FileSystem fs, Path path, Configuration co
    */
   UserGroupInformation createProxyUser(String userName) throws IOException;
 
+  /**
+   * The method sets to set the partition file has a different signature between
+   * hadoop versions.
+   * @param jobConf
+   * @param partition
+   */
+  void setTotalOrderPartitionFile(JobConf jobConf, Path partition);
   /**
    * InputSplitShim.
    *
