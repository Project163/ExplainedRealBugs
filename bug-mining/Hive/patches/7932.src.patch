diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveConfPlannerContext.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveConfPlannerContext.java
index b9b0e9ecf3..4c4192504f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveConfPlannerContext.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveConfPlannerContext.java
@@ -21,11 +21,14 @@ public class HiveConfPlannerContext{
 
   private boolean isCorrelatedColumns;
   private boolean heuristicMaterializationStrategy;
+  private boolean isExplainPlan;
 
 
-  public HiveConfPlannerContext(boolean isCorrelatedColumns, boolean heuristicMaterializationStrategy) {
+  public HiveConfPlannerContext(boolean isCorrelatedColumns, boolean heuristicMaterializationStrategy,
+                                boolean isExplainPlan) {
     this.isCorrelatedColumns = isCorrelatedColumns;
     this.heuristicMaterializationStrategy = heuristicMaterializationStrategy;
+    this.isExplainPlan = isExplainPlan;
   }
 
   public boolean getIsCorrelatedColumns() {
@@ -35,4 +38,8 @@ public boolean getIsCorrelatedColumns() {
   public boolean isHeuristicMaterializationStrategy() {
     return heuristicMaterializationStrategy;
   }
+
+  public boolean isExplainPlan() {
+    return isExplainPlan;
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/stats/FilterSelectivityEstimator.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/stats/FilterSelectivityEstimator.java
index 6c04f10927..edfcb76c54 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/stats/FilterSelectivityEstimator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/stats/FilterSelectivityEstimator.java
@@ -39,11 +39,18 @@
 import org.apache.calcite.sql.type.SqlTypeUtil;
 import org.apache.calcite.util.ImmutableBitSet;
 import org.apache.hadoop.hive.ql.optimizer.calcite.HiveCalciteUtil;
+import org.apache.hadoop.hive.ql.optimizer.calcite.HiveConfPlannerContext;
 import org.apache.hadoop.hive.ql.optimizer.calcite.RelOptHiveTable;
 import org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveTableScan;
 import org.apache.hadoop.hive.ql.plan.ColStatistics;
+import org.apache.hadoop.hive.ql.session.SessionState;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 public class FilterSelectivityEstimator extends RexVisitorImpl<Double> {
+
+  protected static final Logger LOG = LoggerFactory.getLogger(FilterSelectivityEstimator.class);
+
   private final RelNode childRel;
   private final double  childCardinality;
   private final RelMetadataQuery mq;
@@ -110,7 +117,17 @@ public Double visitCall(RexCall call) {
         if (totalNoOfTuples >= noOfNulls) {
           selectivity = (totalNoOfTuples - noOfNulls) / Math.max(totalNoOfTuples, 1);
         } else {
-          throw new RuntimeException("Invalid Stats number of null > no of tuples");
+          // If we are running explain, we will print the warning in the console
+          // and the log files. Otherwise, we just print it in the log files.
+          HiveConfPlannerContext ctx = childRel.getCluster().getPlanner().getContext().unwrap(HiveConfPlannerContext.class);
+          String msg = "Invalid statistics: Number of null values > number of tuples. " +
+              "Consider recomputing statistics for table: " +
+              ((RelOptHiveTable) childRel.getTable()).getHiveTableMD().getFullyQualifiedName();
+          if (ctx.isExplainPlan()) {
+            SessionState.getConsole().printError("WARNING: " + msg);
+          }
+          LOG.warn(msg);
+          selectivity = ((double) 1 / (double) 3);
         }
       } else {
         selectivity = computeNotEqualitySelectivity(call);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
index b6c2db45fb..c04f8d96f7 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
@@ -491,12 +491,12 @@ public RelNode genLogicalPlan(ASTNode ast) throws SemanticException {
   }
 
   public static RelOptPlanner createPlanner(HiveConf conf) {
-    return createPlanner(conf, new HashSet<RelNode>(), EmptyStatsSource.INSTANCE);
+    return createPlanner(conf, new HashSet<>(), EmptyStatsSource.INSTANCE, false);
   }
 
   private static RelOptPlanner createPlanner(
       HiveConf conf, Set<RelNode> corrScalarRexSQWithAgg,
-      StatsSource statsSource) {
+      StatsSource statsSource, boolean isExplainPlan) {
     final Double maxSplitSize = (double) HiveConf.getLongVar(
             conf, HiveConf.ConfVars.MAPREDMAXSPLITSIZE);
     final Double maxMemory = (double) HiveConf.getLongVar(
@@ -516,7 +516,8 @@ private static RelOptPlanner createPlanner(
         HiveConf.ConfVars.HIVE_MATERIALIZED_VIEW_REWRITING_SELECTION_STRATEGY).equals("heuristic");
     HivePlannerContext confContext = new HivePlannerContext(algorithmsConf, registry, calciteConfig,
         corrScalarRexSQWithAgg,
-        new HiveConfPlannerContext(isCorrelatedColumns, heuristicMaterializationStrategy), statsSource);
+        new HiveConfPlannerContext(isCorrelatedColumns, heuristicMaterializationStrategy, isExplainPlan),
+        statsSource);
     return HiveVolcanoPlanner.createPlanner(confContext);
   }
 
@@ -1823,7 +1824,7 @@ public RelNode apply(RelOptCluster cluster, RelOptSchema relOptSchema, SchemaPlu
       /*
        * recreate cluster, so that it picks up the additional traitDef
        */
-      RelOptPlanner planner = createPlanner(conf, corrScalarRexSQWithAgg, statsSource);
+      RelOptPlanner planner = createPlanner(conf, corrScalarRexSQWithAgg, statsSource, ctx.isExplainPlan());
       final RexBuilder rexBuilder = cluster.getRexBuilder();
       final RelOptCluster optCluster = RelOptCluster.create(planner, rexBuilder);
 
diff --git a/ql/src/test/queries/clientpositive/stats_cbo_1.q b/ql/src/test/queries/clientpositive/stats_cbo_1.q
new file mode 100644
index 0000000000..b0092a4e7b
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/stats_cbo_1.q
@@ -0,0 +1,19 @@
+CREATE TABLE repro(i STRING) STORED AS ORC;
+INSERT INTO repro VALUES (NULL), (NULL), (NULL);
+
+-- Plan optimized by CBO.
+EXPLAIN
+SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i;
+SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i;
+
+-- STATS_GENERATED_VIA_STATS_TASK                     | true
+-- numRows                                            | 0
+ALTER TABLE repro SET TBLPROPERTIES ('numRows' = '0', 'STATS_GENERATED_VIA_STATS_TASK' = 'true');
+
+-- shows WARNING "Invalid Stats number of null > no of tuples"
+EXPLAIN
+SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i;
+-- Does not show WARNING since query is being executed
+SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i;
+
+DROP TABLE repro;
diff --git a/ql/src/test/results/clientpositive/llap/stats_cbo_1.q.out b/ql/src/test/results/clientpositive/llap/stats_cbo_1.q.out
new file mode 100644
index 0000000000..65684ffac3
--- /dev/null
+++ b/ql/src/test/results/clientpositive/llap/stats_cbo_1.q.out
@@ -0,0 +1,279 @@
+PREHOOK: query: CREATE TABLE repro(i STRING) STORED AS ORC
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@repro
+POSTHOOK: query: CREATE TABLE repro(i STRING) STORED AS ORC
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@repro
+PREHOOK: query: INSERT INTO repro VALUES (NULL), (NULL), (NULL)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@repro
+POSTHOOK: query: INSERT INTO repro VALUES (NULL), (NULL), (NULL)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@repro
+POSTHOOK: Lineage: repro.i EXPRESSION []
+PREHOOK: query: EXPLAIN
+SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i
+PREHOOK: type: QUERY
+PREHOOK: Input: default@repro
+#### A masked pattern was here ####
+POSTHOOK: query: EXPLAIN
+SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@repro
+#### A masked pattern was here ####
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+#### A masked pattern was here ####
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
+        Reducer 3 <- Map 1 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: repro
+                  filterExpr: i is not null (type: boolean)
+                  Statistics: Num rows: 3 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                  Filter Operator
+                    predicate: i is not null (type: boolean)
+                    Statistics: Num rows: 3 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                    Select Operator
+                      expressions: i (type: string)
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 3 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: string)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: string)
+                        Statistics: Num rows: 3 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: string)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: string)
+                        Statistics: Num rows: 3 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+            Execution mode: vectorized, llap
+            LLAP IO: all inputs
+        Map 4 
+            Map Operator Tree:
+                TableScan
+                  alias: repro
+                  filterExpr: i is not null (type: boolean)
+                  Statistics: Num rows: 3 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                  Filter Operator
+                    predicate: i is not null (type: boolean)
+                    Statistics: Num rows: 3 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                    Select Operator
+                      expressions: i (type: string)
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 3 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: string)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: string)
+                        Statistics: Num rows: 3 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+            Execution mode: vectorized, llap
+            LLAP IO: all inputs
+        Reducer 2 
+            Execution mode: llap
+            Reduce Operator Tree:
+              Merge Join Operator
+                condition map:
+                     Inner Join 0 to 1
+                keys:
+                  0 _col0 (type: string)
+                  1 _col0 (type: string)
+                outputColumnNames: _col0, _col1
+                Statistics: Num rows: 9 Data size: 1176 Basic stats: COMPLETE Column stats: COMPLETE
+                Reduce Output Operator
+                  key expressions: _col0 (type: string)
+                  null sort order: z
+                  sort order: +
+                  Map-reduce partition columns: _col0 (type: string)
+                  Statistics: Num rows: 9 Data size: 1176 Basic stats: COMPLETE Column stats: COMPLETE
+                  value expressions: _col1 (type: string)
+        Reducer 3 
+            Execution mode: llap
+            Reduce Operator Tree:
+              Merge Join Operator
+                condition map:
+                     Inner Join 0 to 1
+                keys:
+                  0 _col0 (type: string)
+                  1 _col0 (type: string)
+                outputColumnNames: _col0, _col1, _col2
+                Statistics: Num rows: 27 Data size: 6300 Basic stats: COMPLETE Column stats: COMPLETE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 27 Data size: 6300 Basic stats: COMPLETE Column stats: COMPLETE
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i
+PREHOOK: type: QUERY
+PREHOOK: Input: default@repro
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@repro
+#### A masked pattern was here ####
+PREHOOK: query: ALTER TABLE repro SET TBLPROPERTIES ('numRows' = '0', 'STATS_GENERATED_VIA_STATS_TASK' = 'true')
+PREHOOK: type: ALTERTABLE_PROPERTIES
+PREHOOK: Input: default@repro
+PREHOOK: Output: default@repro
+POSTHOOK: query: ALTER TABLE repro SET TBLPROPERTIES ('numRows' = '0', 'STATS_GENERATED_VIA_STATS_TASK' = 'true')
+POSTHOOK: type: ALTERTABLE_PROPERTIES
+POSTHOOK: Input: default@repro
+POSTHOOK: Output: default@repro
+WARNING: Invalid statistics: Number of null values > number of tuples. Consider recomputing statistics for table: default.repro
+WARNING: Invalid statistics: Number of null values > number of tuples. Consider recomputing statistics for table: default.repro
+PREHOOK: query: EXPLAIN
+SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i
+PREHOOK: type: QUERY
+PREHOOK: Input: default@repro
+#### A masked pattern was here ####
+POSTHOOK: query: EXPLAIN
+SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@repro
+#### A masked pattern was here ####
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+#### A masked pattern was here ####
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
+        Reducer 3 <- Map 1 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: repro
+                  filterExpr: i is not null (type: boolean)
+                  Statistics: Num rows: 1 Data size: 1850 Basic stats: COMPLETE Column stats: COMPLETE
+                  Filter Operator
+                    predicate: i is not null (type: boolean)
+                    Statistics: Num rows: 1 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                    Select Operator
+                      expressions: i (type: string)
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 1 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: string)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: string)
+                        Statistics: Num rows: 1 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: string)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: string)
+                        Statistics: Num rows: 1 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+            Execution mode: vectorized, llap
+            LLAP IO: all inputs
+        Map 4 
+            Map Operator Tree:
+                TableScan
+                  alias: repro
+                  filterExpr: i is not null (type: boolean)
+                  Statistics: Num rows: 1 Data size: 1850 Basic stats: COMPLETE Column stats: COMPLETE
+                  Filter Operator
+                    predicate: i is not null (type: boolean)
+                    Statistics: Num rows: 1 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                    Select Operator
+                      expressions: i (type: string)
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 1 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: string)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: string)
+                        Statistics: Num rows: 1 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
+            Execution mode: vectorized, llap
+            LLAP IO: all inputs
+        Reducer 2 
+            Execution mode: llap
+            Reduce Operator Tree:
+              Merge Join Operator
+                condition map:
+                     Inner Join 0 to 1
+                keys:
+                  0 _col0 (type: string)
+                  1 _col0 (type: string)
+                outputColumnNames: _col0, _col1
+                Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
+                Reduce Output Operator
+                  key expressions: _col0 (type: string)
+                  null sort order: z
+                  sort order: +
+                  Map-reduce partition columns: _col0 (type: string)
+                  Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
+                  value expressions: _col1 (type: string)
+        Reducer 3 
+            Execution mode: llap
+            Reduce Operator Tree:
+              Merge Join Operator
+                condition map:
+                     Inner Join 0 to 1
+                keys:
+                  0 _col0 (type: string)
+                  1 _col0 (type: string)
+                outputColumnNames: _col0, _col1, _col2
+                Statistics: Num rows: 1 Data size: 252 Basic stats: COMPLETE Column stats: COMPLETE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 1 Data size: 252 Basic stats: COMPLETE Column stats: COMPLETE
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i
+PREHOOK: type: QUERY
+PREHOOK: Input: default@repro
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM (SELECT * FROM repro) a, (SELECT * FROM repro) b, (SELECT * FROM repro) c  WHERE a.i IS NOT NULL AND b.i IS NOT NULL AND b.i = a.i AND a.i = c.i
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@repro
+#### A masked pattern was here ####
+PREHOOK: query: DROP TABLE repro
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@repro
+PREHOOK: Output: default@repro
+POSTHOOK: query: DROP TABLE repro
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@repro
+POSTHOOK: Output: default@repro
