diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 5b866207d1..42717d8e16 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -505,34 +505,30 @@ private String processTable(QB qb, ASTNode tabref) throws SemanticException {
         }
       }
     } else if (splitSamplePresent) {
-      // only CombineHiveInputFormat supports this optimize
-      String inputFormat = HiveConf.getVar(conf, HiveConf.ConfVars.HIVEINPUTFORMAT);
-      if (!inputFormat.equals(
-        CombineHiveInputFormat.class.getName())) {
-        throw new SemanticException(generateErrorMessage((ASTNode) tabref.getChild(1),
-            "Percentage sampling is not supported in " + inputFormat));
-      }
       ASTNode sampleClause = (ASTNode) tabref.getChild(1);
-      String alias_id = getAliasId(alias, qb);
 
       Tree type = sampleClause.getChild(0);
-      String numerator = unescapeIdentifier(sampleClause.getChild(1).getText());
+      Tree numerator = sampleClause.getChild(1);
+      String value = unescapeIdentifier(numerator.getText());
+
 
       SplitSample sample;
       if (type.getType() == HiveParser.TOK_PERCENT) {
-        Double percent = Double.valueOf(numerator).doubleValue();
+        assertCombineInputFormat(numerator, "Percentage");
+        Double percent = Double.valueOf(value).doubleValue();
         if (percent < 0  || percent > 100) {
-          throw new SemanticException(generateErrorMessage(sampleClause,
+          throw new SemanticException(generateErrorMessage((ASTNode) numerator,
               "Sampling percentage should be between 0 and 100"));
         }
         int seedNum = conf.getIntVar(ConfVars.HIVESAMPLERANDOMNUM);
         sample = new SplitSample(percent, seedNum);
       } else if (type.getType() == HiveParser.TOK_ROWCOUNT) {
-        sample = new SplitSample(Integer.valueOf(numerator));
+        sample = new SplitSample(Integer.valueOf(value));
       } else {
         assert type.getType() == HiveParser.TOK_LENGTH;
-        long length = Integer.valueOf(numerator.substring(0, numerator.length() - 1));
-        char last = numerator.charAt(numerator.length() - 1);
+        assertCombineInputFormat(numerator, "Total Length");
+        long length = Integer.valueOf(value.substring(0, value.length() - 1));
+        char last = value.charAt(value.length() - 1);
         if (last == 'k' || last == 'K') {
           length <<= 10;
         } else if (last == 'm' || last == 'M') {
@@ -543,6 +539,7 @@ private String processTable(QB qb, ASTNode tabref) throws SemanticException {
         int seedNum = conf.getIntVar(ConfVars.HIVESAMPLERANDOMNUM);
         sample = new SplitSample(length, seedNum);
       }
+      String alias_id = getAliasId(alias, qb);
       nameToSplitSample.put(alias_id, sample);
     }
     // Insert this map into the stats
@@ -560,6 +557,14 @@ private String processTable(QB qb, ASTNode tabref) throws SemanticException {
     return alias;
   }
 
+  private void assertCombineInputFormat(Tree numerator, String message) throws SemanticException {
+    String inputFormat = HiveConf.getVar(conf, HiveConf.ConfVars.HIVEINPUTFORMAT);
+    if (!inputFormat.equals(CombineHiveInputFormat.class.getName())) {
+      throw new SemanticException(generateErrorMessage((ASTNode) numerator,
+          message + " sampling is not supported in " + inputFormat));
+    }
+  }
+
   private String processSubQuery(QB qb, ASTNode subq) throws SemanticException {
 
     // This is a subquery and must have an alias
diff --git a/ql/src/test/queries/clientnegative/split_sample_wrong_format2.q b/ql/src/test/queries/clientnegative/split_sample_wrong_format2.q
new file mode 100644
index 0000000000..1a13c0ff4c
--- /dev/null
+++ b/ql/src/test/queries/clientnegative/split_sample_wrong_format2.q
@@ -0,0 +1,3 @@
+set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;
+
+select key from src tablesample(1K);
diff --git a/ql/src/test/queries/clientpositive/split_sample.q b/ql/src/test/queries/clientpositive/split_sample.q
index 4d7c025f75..0270449831 100644
--- a/ql/src/test/queries/clientpositive/split_sample.q
+++ b/ql/src/test/queries/clientpositive/split_sample.q
@@ -106,3 +106,7 @@ select count(1) from ss_src2 tablesample(100 ROWS);
 set hive.fetch.task.conversion=more;
 select key from ss_src2 tablesample(200B);
 select key from ss_src2 tablesample(10 ROWS);
+
+set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;
+-- ROW type works with other input formats (others, don't)
+select count(1) from ss_src2 tablesample(10 ROWS);
diff --git a/ql/src/test/results/clientnegative/split_sample_out_of_range.q.out b/ql/src/test/results/clientnegative/split_sample_out_of_range.q.out
index 66fb3a0905..54974a79b2 100644
--- a/ql/src/test/results/clientnegative/split_sample_out_of_range.q.out
+++ b/ql/src/test/results/clientnegative/split_sample_out_of_range.q.out
@@ -1 +1 @@
-FAILED: SemanticException 0:0 Sampling percentage should be between 0 and 100. Error encountered near token '105'
+FAILED: SemanticException 3:32 Sampling percentage should be between 0 and 100. Error encountered near token '105'
diff --git a/ql/src/test/results/clientnegative/split_sample_wrong_format.q.out b/ql/src/test/results/clientnegative/split_sample_wrong_format.q.out
index 3c38ec599b..eb6a81df1d 100644
--- a/ql/src/test/results/clientnegative/split_sample_wrong_format.q.out
+++ b/ql/src/test/results/clientnegative/split_sample_wrong_format.q.out
@@ -1 +1 @@
-FAILED: SemanticException 0:0 Percentage sampling is not supported in org.apache.hadoop.hive.ql.io.HiveInputFormat. Error encountered near token '1'
+FAILED: SemanticException 3:32 Percentage sampling is not supported in org.apache.hadoop.hive.ql.io.HiveInputFormat. Error encountered near token '1'
diff --git a/ql/src/test/results/clientnegative/split_sample_wrong_format2.q.out b/ql/src/test/results/clientnegative/split_sample_wrong_format2.q.out
new file mode 100644
index 0000000000..e349e628af
--- /dev/null
+++ b/ql/src/test/results/clientnegative/split_sample_wrong_format2.q.out
@@ -0,0 +1 @@
+FAILED: SemanticException 3:32 Total Length sampling is not supported in org.apache.hadoop.hive.ql.io.HiveInputFormat. Error encountered near token '1K'
diff --git a/ql/src/test/results/clientpositive/split_sample.q.out b/ql/src/test/results/clientpositive/split_sample.q.out
index 0a80479347..91b8fd60c4 100644
--- a/ql/src/test/results/clientpositive/split_sample.q.out
+++ b/ql/src/test/results/clientpositive/split_sample.q.out
@@ -4821,3 +4821,26 @@ POSTHOOK: Lineage: ss_i_part PARTITION(p=3).value SIMPLE [(src)src.FieldSchema(n
 278
 98
 484
+PREHOOK: query: -- ROW type works with other input formats (others, don't)
+select count(1) from ss_src2 tablesample(10 ROWS)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@ss_src2
+#### A masked pattern was here ####
+POSTHOOK: query: -- ROW type works with other input formats (others, don't)
+select count(1) from ss_src2 tablesample(10 ROWS)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@ss_src2
+#### A masked pattern was here ####
+POSTHOOK: Lineage: ss_i_part PARTITION(p=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: ss_i_part PARTITION(p=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: ss_i_part PARTITION(p=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: ss_i_part PARTITION(p=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: ss_i_part PARTITION(p=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: ss_i_part PARTITION(p=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: ss_i_part PARTITION(p=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: ss_i_part PARTITION(p=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: ss_i_part PARTITION(p=3).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: ss_i_part PARTITION(p=3).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: ss_i_part PARTITION(p=3).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: ss_i_part PARTITION(p=3).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+10
