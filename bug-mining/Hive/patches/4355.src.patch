diff --git a/orc/src/gen/protobuf-java/org/apache/orc/OrcProto.java b/orc/src/gen/protobuf-java/org/apache/orc/OrcProto.java
index b1577a318f..24715c34a2 100644
--- a/orc/src/gen/protobuf-java/org/apache/orc/OrcProto.java
+++ b/orc/src/gen/protobuf-java/org/apache/orc/OrcProto.java
@@ -17766,6 +17766,8 @@ public interface PostScriptOrBuilder
      *   0 (or missing) = original
      *   1 = HIVE-8732 fixed
      *   2 = HIVE-4243 fixed
+     *   3 = HIVE-12055 fixed
+     *   4 = HIVE-13083 fixed
      * </pre>
      */
     boolean hasWriterVersion();
@@ -17777,6 +17779,8 @@ public interface PostScriptOrBuilder
      *   0 (or missing) = original
      *   1 = HIVE-8732 fixed
      *   2 = HIVE-4243 fixed
+     *   3 = HIVE-12055 fixed
+     *   4 = HIVE-13083 fixed
      * </pre>
      */
     int getWriterVersion();
@@ -18080,6 +18084,8 @@ public long getMetadataLength() {
      *   0 (or missing) = original
      *   1 = HIVE-8732 fixed
      *   2 = HIVE-4243 fixed
+     *   3 = HIVE-12055 fixed
+     *   4 = HIVE-13083 fixed
      * </pre>
      */
     public boolean hasWriterVersion() {
@@ -18093,6 +18099,8 @@ public boolean hasWriterVersion() {
      *   0 (or missing) = original
      *   1 = HIVE-8732 fixed
      *   2 = HIVE-4243 fixed
+     *   3 = HIVE-12055 fixed
+     *   4 = HIVE-13083 fixed
      * </pre>
      */
     public int getWriterVersion() {
@@ -18764,6 +18772,8 @@ public Builder clearMetadataLength() {
        *   0 (or missing) = original
        *   1 = HIVE-8732 fixed
        *   2 = HIVE-4243 fixed
+       *   3 = HIVE-12055 fixed
+       *   4 = HIVE-13083 fixed
        * </pre>
        */
       public boolean hasWriterVersion() {
@@ -18777,6 +18787,8 @@ public boolean hasWriterVersion() {
        *   0 (or missing) = original
        *   1 = HIVE-8732 fixed
        *   2 = HIVE-4243 fixed
+       *   3 = HIVE-12055 fixed
+       *   4 = HIVE-13083 fixed
        * </pre>
        */
       public int getWriterVersion() {
@@ -18790,6 +18802,8 @@ public int getWriterVersion() {
        *   0 (or missing) = original
        *   1 = HIVE-8732 fixed
        *   2 = HIVE-4243 fixed
+       *   3 = HIVE-12055 fixed
+       *   4 = HIVE-13083 fixed
        * </pre>
        */
       public Builder setWriterVersion(int value) {
@@ -18806,6 +18820,8 @@ public Builder setWriterVersion(int value) {
        *   0 (or missing) = original
        *   1 = HIVE-8732 fixed
        *   2 = HIVE-4243 fixed
+       *   3 = HIVE-12055 fixed
+       *   4 = HIVE-13083 fixed
        * </pre>
        */
       public Builder clearWriterVersion() {
diff --git a/orc/src/java/org/apache/orc/OrcFile.java b/orc/src/java/org/apache/orc/OrcFile.java
index 8061089f84..3945a5dd1a 100644
--- a/orc/src/java/org/apache/orc/OrcFile.java
+++ b/orc/src/java/org/apache/orc/OrcFile.java
@@ -105,6 +105,7 @@ public enum WriterVersion {
     HIVE_8732(1), // corrupted stripe/file maximum column statistics
     HIVE_4243(2), // use real column names from Hive tables
     HIVE_12055(3), // vectorized writer
+    HIVE_13083(4), // decimal writer updating present stream wrongly
 
     // Don't use any magic numbers here except for the below:
     FUTURE(Integer.MAX_VALUE); // a version from a future writer
@@ -142,7 +143,7 @@ public static WriterVersion from(int val) {
       return values[val];
     }
   }
-  public static final WriterVersion CURRENT_WRITER = WriterVersion.HIVE_12055;
+  public static final WriterVersion CURRENT_WRITER = WriterVersion.HIVE_13083;
 
   public enum EncodingStrategy {
     SPEED, COMPRESSION
diff --git a/orc/src/protobuf/orc_proto.proto b/orc/src/protobuf/orc_proto.proto
index 0b3679443b..f4935b4250 100644
--- a/orc/src/protobuf/orc_proto.proto
+++ b/orc/src/protobuf/orc_proto.proto
@@ -214,6 +214,8 @@ message PostScript {
   //   0 (or missing) = original
   //   1 = HIVE-8732 fixed
   //   2 = HIVE-4243 fixed
+  //   3 = HIVE-12055 fixed
+  //   4 = HIVE-13083 fixed
   optional uint32 writerVersion = 6;
   // Leave this last in the record
   optional string magic = 8000;
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcFile.java b/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcFile.java
index a7e657c230..3843c6d4e8 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcFile.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcFile.java
@@ -25,6 +25,7 @@
 
 import java.io.File;
 import java.io.IOException;
+import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.nio.ByteBuffer;
 import java.sql.Date;
@@ -108,6 +109,14 @@
 @RunWith(value = Parameterized.class)
 public class TestOrcFile {
 
+  public static class DecimalStruct {
+    HiveDecimalWritable dec;
+
+    DecimalStruct(HiveDecimalWritable hdw) {
+      this.dec = hdw;
+    }
+  }
+
   public static class SimpleStruct {
     BytesWritable bytes1;
     Text string1;
@@ -540,6 +549,110 @@ public void testTimestamp() throws Exception {
     assertEquals(true, Arrays.equals(expected, included));
   }
 
+  @Test
+  public void testHiveDecimalAllNulls() throws Exception {
+    ObjectInspector inspector;
+    synchronized (TestOrcFile.class) {
+      inspector = ObjectInspectorFactory.getReflectionObjectInspector
+          (DecimalStruct.class, ObjectInspectorFactory.ObjectInspectorOptions.JAVA);
+    }
+
+    Writer writer = OrcFile.createWriter(testFilePath,
+        OrcFile.writerOptions(conf).inspector(inspector).stripeSize(100000).bufferSize(10000));
+    // this is an invalid decimal value, getting HiveDecimal from it will return null
+    writer.addRow(new DecimalStruct(new HiveDecimalWritable("1.463040009E9".getBytes(), 8)));
+    writer.addRow(new DecimalStruct(null));
+    writer.close();
+
+    Reader reader = OrcFile.createReader(testFilePath,
+        OrcFile.readerOptions(conf).filesystem(fs));
+    StructObjectInspector readerInspector =
+        (StructObjectInspector) reader.getObjectInspector();
+    List<? extends StructField> fields = readerInspector.getAllStructFieldRefs();
+    HiveDecimalObjectInspector doi = (HiveDecimalObjectInspector) readerInspector.
+        getStructFieldRef("dec").getFieldObjectInspector();
+    RecordReader rows = reader.rows(null);
+    while (rows.hasNext()) {
+      Object row = rows.next(null);
+      assertEquals(null, doi.getPrimitiveWritableObject(readerInspector.getStructFieldData(row,
+          fields.get(0))));
+    }
+
+    // check the stats
+    ColumnStatistics[] stats = reader.getStatistics();
+    assertEquals(2, stats[0].getNumberOfValues());
+    assertEquals(0, stats[1].getNumberOfValues());
+    assertEquals(true, stats[1].hasNull());
+  }
+
+  @Test
+  public void testHiveDecimalIsNullReset() throws Exception {
+    ObjectInspector inspector;
+    synchronized (TestOrcFile.class) {
+      inspector = ObjectInspectorFactory.getReflectionObjectInspector
+          (DecimalStruct.class, ObjectInspectorFactory.ObjectInspectorOptions.JAVA);
+    }
+
+    Writer writer = OrcFile.createWriter(testFilePath,
+        OrcFile.writerOptions(conf).inspector(inspector).stripeSize(100000).bufferSize(10000));
+
+    // orc creates 1000 batch size to make memory check align with 5000 instead of 5120
+    for (int i = 0; i < 1000; i++) {
+      writer.addRow(new DecimalStruct(null));
+    }
+
+    writer.addRow(new DecimalStruct(new HiveDecimalWritable("1.00")));
+    writer.addRow(new DecimalStruct(new HiveDecimalWritable("2.00")));
+    writer.addRow(new DecimalStruct(new HiveDecimalWritable("3.00")));
+
+    writer.close();
+
+    Reader reader = OrcFile.createReader(testFilePath,
+        OrcFile.readerOptions(conf).filesystem(fs));
+    StructObjectInspector readerInspector =
+        (StructObjectInspector) reader.getObjectInspector();
+    List<? extends StructField> fields = readerInspector.getAllStructFieldRefs();
+    HiveDecimalObjectInspector doi = (HiveDecimalObjectInspector) readerInspector.
+        getStructFieldRef("dec").getFieldObjectInspector();
+    RecordReader rows = reader.rows(null);
+    int idx = 0;
+    while (rows.hasNext()) {
+      Object row = rows.next(null);
+      if (idx < 1000) {
+        assertEquals(null, doi.getPrimitiveWritableObject(readerInspector.getStructFieldData(row,
+            fields.get(0))));
+      }
+
+      if (idx == 1000) {
+        assertEquals(new HiveDecimalWritable(1),
+            doi.getPrimitiveWritableObject(readerInspector.getStructFieldData(row,
+                fields.get(0))));
+      }
+
+      if (idx == 1001) {
+        assertEquals(new HiveDecimalWritable(2),
+            doi.getPrimitiveWritableObject(readerInspector.getStructFieldData(row,
+                fields.get(0))));
+      }
+
+      if (idx == 10002) {
+        assertEquals(new HiveDecimalWritable(3),
+            doi.getPrimitiveWritableObject(readerInspector.getStructFieldData(row,
+                fields.get(0))));
+      }
+      idx++;
+    }
+
+    // check the stats
+    ColumnStatistics[] stats = reader.getStatistics();
+    assertEquals(1003, stats[0].getNumberOfValues());
+    assertEquals(3, stats[1].getNumberOfValues());
+    assertEquals(HiveDecimal.create(3), ((DecimalColumnStatistics) stats[1]).getMaximum());
+    assertEquals(HiveDecimal.create(1), ((DecimalColumnStatistics) stats[1]).getMinimum());
+    assertEquals(HiveDecimal.create(6), ((DecimalColumnStatistics) stats[1]).getSum());
+    assertEquals(true, stats[1].hasNull());
+  }
+
   @Test
   public void testStringAndBinaryStatistics() throws Exception {
 
diff --git a/ql/src/test/resources/orc-file-dump-bloomfilter.out b/ql/src/test/resources/orc-file-dump-bloomfilter.out
index 1654e3338e..18fd2fb093 100644
--- a/ql/src/test/resources/orc-file-dump-bloomfilter.out
+++ b/ql/src/test/resources/orc-file-dump-bloomfilter.out
@@ -1,5 +1,5 @@
 Structure for TestFileDump.testDump.orc
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 21000
 Compression: ZLIB
 Compression size: 4096
diff --git a/ql/src/test/resources/orc-file-dump-bloomfilter2.out b/ql/src/test/resources/orc-file-dump-bloomfilter2.out
index 1f6e046577..fa5cc2d154 100644
--- a/ql/src/test/resources/orc-file-dump-bloomfilter2.out
+++ b/ql/src/test/resources/orc-file-dump-bloomfilter2.out
@@ -1,5 +1,5 @@
 Structure for TestFileDump.testDump.orc
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 21000
 Compression: ZLIB
 Compression size: 4096
diff --git a/ql/src/test/resources/orc-file-dump-dictionary-threshold.out b/ql/src/test/resources/orc-file-dump-dictionary-threshold.out
index 64cf0e9cc5..17a964b31d 100644
--- a/ql/src/test/resources/orc-file-dump-dictionary-threshold.out
+++ b/ql/src/test/resources/orc-file-dump-dictionary-threshold.out
@@ -1,5 +1,5 @@
 Structure for TestFileDump.testDump.orc
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 21000
 Compression: ZLIB
 Compression size: 4096
diff --git a/ql/src/test/resources/orc-file-dump.json b/ql/src/test/resources/orc-file-dump.json
index 0376d8aaf1..bf654a13f1 100644
--- a/ql/src/test/resources/orc-file-dump.json
+++ b/ql/src/test/resources/orc-file-dump.json
@@ -1,7 +1,7 @@
 {
   "fileName": "TestFileDump.testDump.orc",
   "fileVersion": "0.12",
-  "writerVersion": "HIVE_12055",
+  "writerVersion": "HIVE_13083",
   "numberOfRows": 21000,
   "compression": "ZLIB",
   "compressionBufferSize": 4096,
diff --git a/ql/src/test/resources/orc-file-dump.out b/ql/src/test/resources/orc-file-dump.out
index 57356d30b0..70f7fbd058 100644
--- a/ql/src/test/resources/orc-file-dump.out
+++ b/ql/src/test/resources/orc-file-dump.out
@@ -1,5 +1,5 @@
 Structure for TestFileDump.testDump.orc
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 21000
 Compression: ZLIB
 Compression size: 4096
diff --git a/ql/src/test/resources/orc-file-has-null.out b/ql/src/test/resources/orc-file-has-null.out
index 0e915c643f..e98a73fd9c 100644
--- a/ql/src/test/resources/orc-file-has-null.out
+++ b/ql/src/test/resources/orc-file-has-null.out
@@ -1,5 +1,5 @@
 Structure for TestOrcFile.testHasNull.orc
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 20000
 Compression: ZLIB
 Compression size: 4096
diff --git a/ql/src/test/results/clientpositive/orc_file_dump.q.out b/ql/src/test/results/clientpositive/orc_file_dump.q.out
index 4c73bacc1b..a97f6de10c 100644
--- a/ql/src/test/results/clientpositive/orc_file_dump.q.out
+++ b/ql/src/test/results/clientpositive/orc_file_dump.q.out
@@ -93,7 +93,7 @@ PREHOOK: Input: default@orc_ppd
 #### A masked pattern was here ####
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 1049
 Compression: ZLIB
 Compression size: 262144
@@ -213,7 +213,7 @@ PREHOOK: Input: default@orc_ppd
 #### A masked pattern was here ####
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 1049
 Compression: ZLIB
 Compression size: 262144
@@ -345,7 +345,7 @@ PREHOOK: Input: default@orc_ppd_part@ds=2015/hr=10
 #### A masked pattern was here ####
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 1049
 Compression: ZLIB
 Compression size: 262144
diff --git a/ql/src/test/results/clientpositive/orc_merge10.q.out b/ql/src/test/results/clientpositive/orc_merge10.q.out
index 776ca9a5f8..cf70dcfa7c 100644
--- a/ql/src/test/results/clientpositive/orc_merge10.q.out
+++ b/ql/src/test/results/clientpositive/orc_merge10.q.out
@@ -517,7 +517,7 @@ PREHOOK: Input: default@orcfile_merge1@ds=1/part=0
 #### A masked pattern was here ####
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 242
 Compression: SNAPPY
 Compression size: 4096
@@ -579,7 +579,7 @@ PREHOOK: Input: default@orcfile_merge1c@ds=1/part=0
 #### A masked pattern was here ####
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 242
 Compression: SNAPPY
 Compression size: 4096
diff --git a/ql/src/test/results/clientpositive/orc_merge11.q.out b/ql/src/test/results/clientpositive/orc_merge11.q.out
index 65e3d8b8a8..8a4d8e9ea1 100644
--- a/ql/src/test/results/clientpositive/orc_merge11.q.out
+++ b/ql/src/test/results/clientpositive/orc_merge11.q.out
@@ -72,7 +72,7 @@ PREHOOK: Input: default@orcfile_merge1
 #### A masked pattern was here ####
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 50000
 Compression: ZLIB
 Compression size: 4096
@@ -133,7 +133,7 @@ ________________________________________________________________________________
 -- END ORC FILE DUMP --
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 50000
 Compression: ZLIB
 Compression size: 4096
@@ -217,7 +217,7 @@ PREHOOK: Input: default@orcfile_merge1
 #### A masked pattern was here ####
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 100000
 Compression: ZLIB
 Compression size: 4096
diff --git a/ql/src/test/results/clientpositive/tez/orc_merge10.q.out b/ql/src/test/results/clientpositive/tez/orc_merge10.q.out
index 8b6a595470..bcba1bd50f 100644
--- a/ql/src/test/results/clientpositive/tez/orc_merge10.q.out
+++ b/ql/src/test/results/clientpositive/tez/orc_merge10.q.out
@@ -552,7 +552,7 @@ PREHOOK: Input: default@orcfile_merge1@ds=1/part=0
 #### A masked pattern was here ####
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 242
 Compression: SNAPPY
 Compression size: 4096
@@ -629,7 +629,7 @@ PREHOOK: Input: default@orcfile_merge1c@ds=1/part=0
 #### A masked pattern was here ####
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 242
 Compression: SNAPPY
 Compression size: 4096
diff --git a/ql/src/test/results/clientpositive/tez/orc_merge11.q.out b/ql/src/test/results/clientpositive/tez/orc_merge11.q.out
index 65e3d8b8a8..8a4d8e9ea1 100644
--- a/ql/src/test/results/clientpositive/tez/orc_merge11.q.out
+++ b/ql/src/test/results/clientpositive/tez/orc_merge11.q.out
@@ -72,7 +72,7 @@ PREHOOK: Input: default@orcfile_merge1
 #### A masked pattern was here ####
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 50000
 Compression: ZLIB
 Compression size: 4096
@@ -133,7 +133,7 @@ ________________________________________________________________________________
 -- END ORC FILE DUMP --
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 50000
 Compression: ZLIB
 Compression size: 4096
@@ -217,7 +217,7 @@ PREHOOK: Input: default@orcfile_merge1
 #### A masked pattern was here ####
 -- BEGIN ORC FILE DUMP --
 #### A masked pattern was here ####
-File Version: 0.12 with HIVE_12055
+File Version: 0.12 with HIVE_13083
 Rows: 100000
 Compression: ZLIB
 Compression size: 4096
diff --git a/storage-api/src/java/org/apache/hadoop/hive/ql/exec/vector/DecimalColumnVector.java b/storage-api/src/java/org/apache/hadoop/hive/ql/exec/vector/DecimalColumnVector.java
index fe8ad8542b..1523ff6b7c 100644
--- a/storage-api/src/java/org/apache/hadoop/hive/ql/exec/vector/DecimalColumnVector.java
+++ b/storage-api/src/java/org/apache/hadoop/hive/ql/exec/vector/DecimalColumnVector.java
@@ -108,12 +108,17 @@ public void stringifyValue(StringBuilder buffer, int row) {
   }
 
   public void set(int elementNum, HiveDecimalWritable writeable) {
-    HiveDecimal hiveDec = writeable.getHiveDecimal(precision, scale);
-    if (hiveDec == null) {
+    if (writeable == null) {
       noNulls = false;
       isNull[elementNum] = true;
     } else {
-      vector[elementNum].set(hiveDec);
+      HiveDecimal hiveDec = writeable.getHiveDecimal(precision, scale);
+      if (hiveDec == null) {
+        noNulls = false;
+        isNull[elementNum] = true;
+      } else {
+        vector[elementNum].set(hiveDec);
+      }
     }
   }
 
