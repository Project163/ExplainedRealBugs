diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
index 8ea5af8abc..70dee6da5d 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
@@ -316,6 +316,17 @@ private Tuple replDumpDb(String dbName, List<String> withClauseOptions) throws I
     return new Tuple(dumpLocation, lastReplId);
   }
 
+  private Tuple replDumpAllDbs(List<String> withClauseOptions) throws IOException {
+    String withClause = getWithClause(withClauseOptions);
+    advanceDumpDir();
+    String dumpCmd = "REPL DUMP `*` " + withClause;
+    run(dumpCmd, driver);
+    String dumpLocation = getResult(0, 0, driver);
+    String lastReplId = getResult(0, 1, true, driver);
+    LOG.info("Dumped to {} with id {} for command: {}", dumpLocation, lastReplId, dumpCmd);
+    return new Tuple(dumpLocation, lastReplId);
+  }
+
   private String getWithClause(List<String> withClauseOptions) {
     if (withClauseOptions != null && !withClauseOptions.isEmpty()) {
       return  " with (" + StringUtils.join(withClauseOptions, ",") + ")";
@@ -1049,6 +1060,55 @@ public void testIncrementalAdds() throws IOException {
     verifyRun("SELECT a from " + replDbName + ".ptned_late WHERE b=2", ptn_data_2, driverMirror);
   }
 
+  @Test
+  public void testMultipleDbMetadataOnlyDump() throws IOException {
+    verifySetupSteps = true;
+    String name = testName.getMethodName();
+    String dbName = createDB(name, driver);
+    //create one extra db for bootstrap
+    String bootstrapDb = dbName + "_boot";
+
+    //insert data in the additional db
+    String[] unptn_data = new String[]{ "eleven" , "twelve" };
+    String unptn_locn = new Path(TEST_PATH, name + "_unptn").toUri().getPath();
+    createTestDataFile(unptn_locn, unptn_data);
+    run("CREATE DATABASE " + bootstrapDb, driver);
+    run("CREATE TABLE " + bootstrapDb + ".unptned(a string) STORED AS TEXTFILE", driver);
+    run("LOAD DATA LOCAL INPATH '" + unptn_locn + "' OVERWRITE INTO TABLE " + bootstrapDb + ".unptned", true, driver);
+    verifySetup("SELECT * from " + bootstrapDb + ".unptned", unptn_data, driver);
+    List<String> metadataOnlyClause = Arrays.asList("'" + HiveConf.ConfVars.REPL_DUMP_METADATA_ONLY.varname + "'='true'");
+
+    //dump all dbs and create load-marker
+    Tuple bootstrapDump = replDumpAllDbs(metadataOnlyClause);
+    FileSystem fs = new Path(bootstrapDump.dumpLocation).getFileSystem(hconf);
+    Path hiveDumpPath = new Path(bootstrapDump.dumpLocation, ReplUtils.REPL_HIVE_BASE_DIR);
+    assertTrue(fs.exists(new Path(hiveDumpPath, DUMP_ACKNOWLEDGEMENT.toString())));
+    fs.create(new Path(hiveDumpPath, LOAD_ACKNOWLEDGEMENT.toString()));
+    assertTrue(fs.exists(new Path(hiveDumpPath, LOAD_ACKNOWLEDGEMENT.toString())));
+
+    //create new database and dump all databases again
+    String incDbName1 = dbName + "_inc1";
+    run("CREATE DATABASE " + incDbName1 , driver);
+    run("CREATE TABLE " + incDbName1 + ".unptned(a string) STORED AS TEXTFILE", driver);
+    run("LOAD DATA LOCAL INPATH '" + unptn_locn + "' OVERWRITE INTO TABLE " + incDbName1 + ".unptned", true, driver);
+    verifySetup("SELECT * from " + incDbName1 + ".unptned", unptn_data, driver);
+    Tuple incrementalDump = replDumpAllDbs(metadataOnlyClause);
+
+    //create load-marker
+    hiveDumpPath = new Path(incrementalDump.dumpLocation, ReplUtils.REPL_HIVE_BASE_DIR);
+    assertTrue(fs.exists(new Path(hiveDumpPath, DUMP_ACKNOWLEDGEMENT.toString())));
+    fs.create(new Path(hiveDumpPath, LOAD_ACKNOWLEDGEMENT.toString()));
+    assertTrue(fs.exists(new Path(hiveDumpPath, LOAD_ACKNOWLEDGEMENT.toString())));
+
+    //create new database and dump all databases again
+    String incDbName2 = dbName + "_inc2";
+    run("CREATE DATABASE " + incDbName2 , driver);
+    run("CREATE TABLE " + incDbName2 + ".unptned(a string) STORED AS TEXTFILE", driver);
+    run("LOAD DATA LOCAL INPATH '" + unptn_locn + "' OVERWRITE INTO TABLE " + incDbName2 + ".unptned", true, driver);
+    verifySetup("SELECT * from " + incDbName2 + ".unptned", unptn_data, driver);
+    replDumpAllDbs(metadataOnlyClause);
+  }
+
   @Test
   public void testIncrementalLoadWithVariableLengthEventId() throws IOException, TException {
     String testName = "incrementalLoadWithVariableLengthEventId";
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java
index c55012cc61..f8de8e2dd2 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java
@@ -676,40 +676,42 @@ private Long incrementalDump(Path dumpRoot, DumpMetaData dmd, Path cmRoot, Hive
             conf.getBoolVar(REPL_EXTERNAL_WAREHOUSE_SINGLE_COPY_TASK)
                 && work.replScope.includeAllTables();
         boolean isExternalTablePresent = false;
-        for (String tableName : Utils.matchesTbl(hiveDb, dbName, work.replScope)) {
-          try {
-            Table table = hiveDb.getTable(dbName, tableName);
-
-            // Dump external table locations if required.
-            if (TableType.EXTERNAL_TABLE.equals(table.getTableType())
-                    && shouldDumpExternalTableLocation()) {
-              dbPath = new Path(hiveDb.getDatabase(dbName).getLocationUri());
-              externalTablesWriter.dataLocationDump(table, extTableFileList, dbPath,
-                  !isSingleCopyTaskForExternalTables, conf);
-              isExternalTablePresent=true;
-            }
-            
-            // Dump the table to be bootstrapped if required.
-            if (shouldBootstrapDumpTable(table)) {
-              HiveWrapper.Tuple<Table> tableTuple = new HiveWrapper(hiveDb, dbName).table(table);
-              dumpTable(dbName, tableName, validTxnList, dbRootMetadata, dbRootData, bootDumpBeginReplId,
-                      hiveDb, tableTuple, managedTblList, dataCopyAtLoad);
+        for(String matchedDbName : Utils.matchesDb(hiveDb, work.dbNameOrPattern)) {
+          for (String tableName : Utils.matchesTbl(hiveDb, matchedDbName, work.replScope)) {
+            try {
+              Table table = hiveDb.getTable(matchedDbName, tableName);
+
+              // Dump external table locations if required.
+              if (TableType.EXTERNAL_TABLE.equals(table.getTableType())
+                      && shouldDumpExternalTableLocation()) {
+                dbPath = new Path(hiveDb.getDatabase(matchedDbName).getLocationUri());
+                externalTablesWriter.dataLocationDump(table, extTableFileList, dbPath,
+                        !isSingleCopyTaskForExternalTables, conf);
+                isExternalTablePresent = true;
+              }
+
+              // Dump the table to be bootstrapped if required.
+              if (shouldBootstrapDumpTable(table)) {
+                HiveWrapper.Tuple<Table> tableTuple = new HiveWrapper(hiveDb, matchedDbName).table(table);
+                dumpTable(matchedDbName, tableName, validTxnList, dbRootMetadata, dbRootData, bootDumpBeginReplId,
+                        hiveDb, tableTuple, managedTblList, dataCopyAtLoad);
+              }
+              if (tableList != null && isTableSatifiesConfig(table)) {
+                tableList.add(tableName);
+              }
+            } catch (InvalidTableException te) {
+              // Repl dump shouldn't fail if the table is dropped/renamed while dumping it.
+              // Just log a debug message and skip it.
+              LOG.debug(te.getMessage());
             }
-            if (tableList != null && isTableSatifiesConfig(table)) {
-              tableList.add(tableName);
+            // if it is not a table level replication, add a single task for
+            // the database default location for external tables...
+            if (isExternalTablePresent && shouldDumpExternalTableLocation()
+                    && isSingleCopyTaskForExternalTables) {
+              // Using the lower case of the database name, to keep it
+              // consistent with the name used during bootstrap.
+              externalTablesWriter.dbLocationDump(matchedDbName.toLowerCase(), dbPath, extTableFileList, conf);
             }
-          } catch (InvalidTableException te) {
-            // Repl dump shouldn't fail if the table is dropped/renamed while dumping it.
-            // Just log a debug message and skip it.
-            LOG.debug(te.getMessage());
-          }
-          // if it is not a table level replication, add a single task for
-          // the database default location for external tables...
-          if (isExternalTablePresent && shouldDumpExternalTableLocation()
-              && isSingleCopyTaskForExternalTables) {
-            // Using the lower case of the database name, to keep it
-            // consistent with the name used during bootstrap.
-            externalTablesWriter.dbLocationDump(dbName.toLowerCase(), dbPath, extTableFileList, conf);
           }
         }
         dumpTableListToDumpLocation(tableList, dumpRoot, dbName, conf);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/EximUtil.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/EximUtil.java
index 7be821498b..e86d8163d1 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/EximUtil.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/EximUtil.java
@@ -387,7 +387,7 @@ private static void updateIfCustomDbLocations(Database database, Configuration c
               MetastoreConf.getVar(conf, MetastoreConf.ConfVars.WAREHOUSE));
       Path dbDerivedLoc = new Path(whLocatoion, database.getName().toLowerCase() + DATABASE_PATH_SUFFIX);
       String defaultDbLoc = Utilities.getQualifiedPath((HiveConf) conf, dbDerivedLoc);
-      database.getParameters().put(ReplUtils.REPL_IS_CUSTOM_DB_LOC,
+      database.putToParameters(ReplUtils.REPL_IS_CUSTOM_DB_LOC,
               Boolean.toString(!defaultDbLoc.equals(database.getLocationUri())));
       String whManagedLocatoion = MetastoreConf.getVar(conf, MetastoreConf.ConfVars.WAREHOUSE);
       Path dbDerivedManagedLoc = new Path(whManagedLocatoion, database.getName().toLowerCase()
