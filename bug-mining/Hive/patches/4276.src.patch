diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java b/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java
index 1f1aac7bf5..b36cf6499b 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java
@@ -394,8 +394,8 @@ protected Void performDataRead() throws IOException {
             counters.incrCounter(Counter.METADATA_CACHE_MISS);
             ensureMetadataReader();
             long startTimeHdfs = counters.startTimeCounter();
-            stripeMetadata = new OrcStripeMetadata(
-                stripeKey, metadataReader, stripe, stripeIncludes, sargColumns);
+            stripeMetadata = new OrcStripeMetadata(new OrcBatchKey(fileId, stripeIx, 0),
+                metadataReader, stripe, stripeIncludes, sargColumns);
             counters.incrTimeCounter(Counter.HDFS_TIME_US, startTimeHdfs);
             if (hasFileId && metadataCache != null) {
               stripeMetadata = metadataCache.putStripeMetadata(stripeMetadata);
@@ -403,9 +403,7 @@ protected Void performDataRead() throws IOException {
                 LlapIoImpl.LOG.info("Caching stripe " + stripeKey.stripeIx
                     + " metadata with includes: " + DebugUtils.toString(stripeIncludes));
               }
-              stripeKey = new OrcBatchKey(fileId, -1, 0);
             }
-
           }
           consumer.setStripeMetadata(stripeMetadata);
         }
@@ -658,7 +656,8 @@ private ArrayList<OrcStripeMetadata> readStripesMetadata(
         StripeInformation si = fileMetadata.getStripes().get(stripeIx);
         if (value == null) {
           long startTime = counters.startTimeCounter();
-          value = new OrcStripeMetadata(stripeKey, metadataReader, si, globalInc, sargColumns);
+          value = new OrcStripeMetadata(new OrcBatchKey(fileId, stripeIx, 0),
+              metadataReader, si, globalInc, sargColumns);
           counters.incrTimeCounter(Counter.HDFS_TIME_US, startTime);
           if (hasFileId && metadataCache != null) {
             value = metadataCache.putStripeMetadata(value);
@@ -666,8 +665,6 @@ private ArrayList<OrcStripeMetadata> readStripesMetadata(
               LlapIoImpl.LOG.info("Caching stripe " + stripeKey.stripeIx
                   + " metadata with includes: " + DebugUtils.toString(globalInc));
             }
-            // Create new key object to reuse for gets; we've used the old one to put in cache.
-            stripeKey = new OrcBatchKey(fileId, 0, 0);
           }
         }
         // We might have got an old value from cache; recheck it has indexes.
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
index fed6de001b..6cec80ee96 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
@@ -106,7 +106,7 @@ public DiskRangeList createCacheChunk(MemoryBuffer buffer, long offset, long end
   private ByteBufferAllocatorPool pool;
   private boolean isDebugTracingEnabled;
 
-  public EncodedReaderImpl(long fileId, List<OrcProto.Type> types, CompressionCodec codec,
+  public EncodedReaderImpl(Long fileId, List<OrcProto.Type> types, CompressionCodec codec,
       int bufferSize, long strideRate, DataCache cache, DataReader dataReader, PoolFactory pf)
           throws IOException {
     this.fileId = fileId;
