diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/ExprProcCtx.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/ExprProcCtx.java
index cccc004aaa..7999504289 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/ExprProcCtx.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/ExprProcCtx.java
@@ -23,6 +23,7 @@
 /**
  * The processor context for partition pruner. This contains the table alias
  * that is being currently processed.
+ * TODO: this class may be not useful.
  */
 public class ExprProcCtx implements NodeProcessorCtx {
 
@@ -31,15 +32,8 @@ public class ExprProcCtx implements NodeProcessorCtx {
    */
   String tabAlias;
 
-  /**
-   * Flag to hold whether there are any non partition columns accessed in the
-   * expression.
-   */
-  boolean hasNonPartCols;
-
   public ExprProcCtx(String tabAlias) {
     this.tabAlias = tabAlias;
-    hasNonPartCols = false;
   }
 
   public String getTabAlias() {
@@ -49,12 +43,4 @@ public String getTabAlias() {
   public void setTabAlias(String tabAlias) {
     this.tabAlias = tabAlias;
   }
-
-  public boolean getHasNonPartCols() {
-    return hasNonPartCols;
-  }
-
-  public void setHasNonPartCols(boolean val) {
-    hasNonPartCols = val;
-  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/ExprProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/ExprProcFactory.java
index 9ff94cfbc6..69fbddfccd 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/ExprProcFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/ExprProcFactory.java
@@ -64,7 +64,6 @@ protected ExprNodeDesc processColumnDesc(NodeProcessorCtx procCtx, ExprNodeColum
         newcd = cd.clone();
       } else {
         newcd = new ExprNodeConstantDesc(cd.getTypeInfo(), null);
-        epc.setHasNonPartCols(true);
       }
       return newcd;
     }
@@ -88,12 +87,10 @@ public static NodeProcessor getColumnProcessor() {
    * @param pred
    *          The predicate from which the partition pruner needs to be
    *          generated
-   * @return hasNonPartCols returns true/false depending upon whether this pred
-   *         has a non partition column
-   * @throws SemanticException
+   * @return The pruner expression.
    */
-  public static ExprNodeDesc genPruner(String tabAlias, ExprNodeDesc pred,
-      boolean hasNonPartCols) throws SemanticException {
+  public static ExprNodeDesc genPruner(
+      String tabAlias, ExprNodeDesc pred) throws SemanticException {
     // Create the walker, the rules dispatcher and the context.
     ExprProcCtx pprCtx = new ExprProcCtx(tabAlias);
 
@@ -101,8 +98,6 @@ public static ExprNodeDesc genPruner(String tabAlias, ExprNodeDesc pred,
     Map<Node, Object> outputMap = PrunerUtils.walkExprTree(pred, pprCtx, getColumnProcessor(),
         getFieldProcessor(), getGenericFuncProcessor(), getDefaultExprProcessor());
 
-    hasNonPartCols = pprCtx.getHasNonPartCols();
-
     // Get the exprNodeDesc corresponding to the first start node;
     return (ExprNodeDesc) outputMap.get(pred);
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/OpProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/OpProcFactory.java
index ecf28edba8..fd51628a9f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/OpProcFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/OpProcFactory.java
@@ -59,10 +59,7 @@ protected void generatePredicate(NodeProcessorCtx procCtx, FilterOperator fop,
       String alias = top.getConf().getAlias();
 
       // Generate the partition pruning predicate
-      boolean hasNonPartCols = false;
-      ExprNodeDesc ppr_pred = ExprProcFactory.genPruner(alias, predicate,
-          hasNonPartCols);
-      owc.addHasNonPartCols(hasNonPartCols);
+      ExprNodeDesc ppr_pred = ExprProcFactory.genPruner(alias, predicate);
 
       // Add the pruning predicate to the table scan operator
       addPruningPred(owc.getOpToPartPruner(), top, ppr_pred);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/OpWalkerCtx.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/OpWalkerCtx.java
index 380a2a15f1..b31cc6a9c9 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/OpWalkerCtx.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/OpWalkerCtx.java
@@ -26,11 +26,10 @@
 
 /**
  * Context class for operator tree walker for partition pruner.
+ * TODO: this class may be not useful.
  */
 public class OpWalkerCtx implements NodeProcessorCtx {
 
-  private boolean hasNonPartCols;
-
   /**
    * Map from tablescan operator to partition pruning predicate that is
    * initialized from the ParseContext.
@@ -42,18 +41,9 @@ public class OpWalkerCtx implements NodeProcessorCtx {
    */
   public OpWalkerCtx(HashMap<TableScanOperator, ExprNodeDesc> opToPartPruner) {
     this.opToPartPruner = opToPartPruner;
-    hasNonPartCols = false;
   }
 
   public HashMap<TableScanOperator, ExprNodeDesc> getOpToPartPruner() {
     return opToPartPruner;
   }
-
-  public void addHasNonPartCols(boolean val) {
-    hasNonPartCols = (hasNonPartCols || val);
-  }
-
-  public boolean getHasNonPartCols() {
-    return hasNonPartCols;
-  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java
index 4715e7f797..6210048760 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java
@@ -88,8 +88,6 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {
     /* Move logic to PrunerUtils.walkOperatorTree() so that it can be reused. */
     PrunerUtils.walkOperatorTree(pctx, opWalkerCtx, OpProcFactory.getFilterProc(),
         OpProcFactory.getDefaultProc());
-    pctx.setHasNonPartCols(opWalkerCtx.getHasNonPartCols());
-
     return pctx;
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseContext.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseContext.java
index ce361cb3d9..cf3f59e2dd 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseContext.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseContext.java
@@ -100,15 +100,6 @@ public class ParseContext {
    */
   private LineageInfo lInfo;
 
-  // is set to true if the expression only contains partitioning columns and not
-  // any other column reference.
-  // This is used to optimize select * from table where ... scenario, when the
-  // where condition only references
-  // partitioning columns - the partitions are identified and streamed directly
-  // to the client without requiring
-  // a map-reduce job
-  private boolean hasNonPartCols;
-
   private GlobalLimitCtx globalLimitCtx;
 
   private HashSet<ReadEntity> semanticInputs;
@@ -206,7 +197,6 @@ public ParseContext(
     this.destTableId = destTableId;
     this.uCtx = uCtx;
     this.listMapJoinOpsNoReducer = listMapJoinOpsNoReducer;
-    hasNonPartCols = false;
     this.groupOpToInputTables = groupOpToInputTables;
     this.prunedPartitions = prunedPartitions;
     this.opToSamplePruner = opToSamplePruner;
@@ -514,22 +504,6 @@ public void setListMapJoinOpsNoReducer(
     this.listMapJoinOpsNoReducer = listMapJoinOpsNoReducer;
   }
 
-  /**
-   * Sets the hasNonPartCols flag.
-   *
-   * @param val
-   */
-  public void setHasNonPartCols(boolean val) {
-    hasNonPartCols = val;
-  }
-
-  /**
-   * Gets the value of the hasNonPartCols flag.
-   */
-  public boolean getHasNonPartCols() {
-    return hasNonPartCols;
-  }
-
   /**
    * @return the opToSamplePruner
    */
