diff --git a/CHANGES.txt b/CHANGES.txt
index f0ebabf45b..b57e13fae0 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -424,6 +424,9 @@ Trunk - Unreleased
     HIVE-673. Bug in handling of null partitions.
     (Namit Jain via zshao)
 
+    HIVE-690. Fix script operator timeout bug
+    (Zheng Shao via namit)
+
 Release 0.3.1 - Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index 5822c6de4d..54cfdc30a1 100644
--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -112,6 +112,7 @@ public static enum ConfVars {
     // for hive script operator
     HIVETABLENAME("hive.table.name", ""),
     HIVEPARTITIONNAME("hive.partition.name", ""),
+    HIVESCRIPTAUTOPROGRESS("hive.script.auto.progress", false),
     HIVEMAPREDMODE("hive.mapred.mode", "nonstrict"),
     HIVEALIAS("hive.alias", ""),
     HIVEMAPSIDEAGGREGATE("hive.map.aggr", "true"),
diff --git a/conf/hive-default.xml b/conf/hive-default.xml
index 80d460b732..98b14acf6a 100644
--- a/conf/hive-default.xml
+++ b/conf/hive-default.xml
@@ -326,4 +326,10 @@
   <description>Size of merged files at the end of the job</description>
 </property>
 
+<property>
+  <name>hive.script.auto.progress</name>
+  <value>false</value>
+  <description>Whether Hive Tranform/Map/Reduce Clause should automatically send progress information to TaskTracker to avoid the task getting killed because of inactivity.  Hive sends progress information when the script is outputting to stderr.  This option removes the need of periodically producing stderr messages, but users should be cautious because this may prevent infinite loops in the scripts to be killed by TaskTracker.  </description>
+</property>
+
 </configuration>
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java
index 2c54221a71..de2fe07dfe 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java
@@ -229,22 +229,25 @@ protected void initializeOp(Configuration hconf) throws HiveException {
                                    (HiveConf.getIntVar(hconf, HiveConf.ConfVars.SCRIPTERRORLIMIT)),
                                    "ErrorProcessor");
       
-      /* Timer that reports every 5 minutes to the jobtracker. This ensures that even if
-         the user script is not returning rows for greater than that duration, a progress
-         report is sent to the tracker so that the tracker does not think that the job 
-         is dead.
-      */
-      Integer exp_interval = null;
-      int exp_int;
-      exp_interval = Integer.decode(hconf.get("mapred.tasktracker.expiry.interval"));
-      if (exp_interval != null)
-        exp_int = exp_interval.intValue() / 2;
-      else
-        exp_int = 300000;
-
-      rpTimer = new Timer(true);
-      rpTimer.scheduleAtFixedRate(new ReporterTask(reporter), 0, exp_interval);
-
+      if (HiveConf.getBoolVar(hconf, HiveConf.ConfVars.HIVESCRIPTAUTOPROGRESS)) {
+        /* Timer that reports every 5 minutes to the jobtracker. This ensures that even if
+           the user script is not returning rows for greater than that duration, a progress
+           report is sent to the tracker so that the tracker does not think that the job 
+           is dead.
+        */
+        Integer expInterval = Integer.decode(hconf.get("mapred.tasktracker.expiry.interval"));
+        int notificationInterval;
+        if (expInterval != null) {
+          notificationInterval = expInterval.intValue() / 2;
+        } else {
+          // 5 minutes
+          notificationInterval = 5 * 60 * 1000;
+        }
+  
+        rpTimer = new Timer(true);
+        rpTimer.scheduleAtFixedRate(new ReporterTask(reporter), 0, notificationInterval);
+      }
+      
       // initialize all children before starting the script
       initializeChildren(hconf);
       outThread.start();
@@ -339,21 +342,48 @@ public void close() {
     }
   }
 
+  /**
+   * The processor for stderr stream.
+   * 
+   * TODO: In the future when we move to hadoop 0.18 and above, we should borrow the logic
+   * from HadoopStreaming: PipeMapRed.java MRErrorThread to support counters and status
+   * updates. 
+   */
   class ErrorStreamProcessor implements StreamProcessor {
     private long bytesCopied = 0;
     private long maxBytes;
 
+    private long lastReportTime;
+    
     public ErrorStreamProcessor (int maxBytes) {
       this.maxBytes = (long)maxBytes;
+      lastReportTime = 0;
     }
+    
     public void processLine(Text line) throws HiveException {
+      
+      String stringLine = line.toString();
+      
+      // Report progress for each stderr line, but no more frequently than once per minute.
+      long now = System.currentTimeMillis();
+      // reporter is a member variable of the Operator class.
+      if (now - lastReportTime > 60 * 1000 && reporter != null) {
+        lastReportTime = now;
+        reporter.progress();
+      }
+      
       if((maxBytes < 0) || (bytesCopied < maxBytes)) {
-        System.err.println(line.toString());
+        System.err.println(stringLine);
       }
+      if (bytesCopied < maxBytes && bytesCopied + line.getLength() >= maxBytes) {
+        System.err.println("Operator " + id + " " + getName()
+            + ": exceeding stderr limit of " + maxBytes + " bytes, will truncate stderr messages.");
+      }      
       bytesCopied += line.getLength();
     }
     public void close() {
     }
+    
   }
 
 
