diff --git a/CHANGES.txt b/CHANGES.txt
index fb5f5866d0..f5b7ac1f56 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -270,6 +270,9 @@ Trunk - Unreleased
     HIVE-472. HiveFileFormatUtils's checkInputFormat does not include RCFile.
     (He Yongqiang via namit)
 
+    HIVE-560. Column Pruning for mapjoins
+    (He Yongqiang via namit)
+
 Release 0.3.1 - Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java
index 2351fe9333..0c9293d8b3 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java
@@ -24,16 +24,9 @@
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.plan.joinDesc;
 import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
-import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
 import org.apache.hadoop.hive.serde2.objectinspector.StructField;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.ObjectInspectorCopyOption;
-import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
-import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
-import org.apache.hadoop.io.Text;
 import org.apache.hadoop.mapred.Reporter;
 
 
@@ -47,8 +40,6 @@ public class JoinOperator extends CommonJoinOperator<joinDesc> implements Serial
   public void initializeOp(Configuration hconf, Reporter reporter, ObjectInspector[] inputObjInspector) throws HiveException {
     super.initializeOp(hconf, reporter, inputObjInspector);
 
-    ArrayList<ObjectInspector> structFieldObjectInspectors = new ArrayList<ObjectInspector>(totalSz);
-
     initializeChildren(hconf, reporter, new ObjectInspector[]{joinOutputObjectInspector});
   }
   
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java
index 94f9837ab0..e62ad3d4ab 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java
@@ -40,7 +40,10 @@
 import org.apache.hadoop.hive.serde2.SerDe;
 import org.apache.hadoop.hive.serde2.SerDeException;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
+import org.apache.hadoop.hive.serde2.objectinspector.StructField;
+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.ObjectInspectorCopyOption;
 import org.apache.hadoop.mapred.Reporter;
 import org.apache.hadoop.util.ReflectionUtils;
@@ -169,6 +172,23 @@ public void initializeOp(Configuration hconf, Reporter reporter, ObjectInspector
       
       mapJoinRowsKey = HiveConf.getIntVar(hconf, HiveConf.ConfVars.HIVEMAPJOINROWSIZE);
       
+      List<? extends StructField> structFields = ((StructObjectInspector)joinOutputObjectInspector).getAllStructFieldRefs();
+      if (conf.getOutputColumnNames().size() < structFields.size()) {
+        List<ObjectInspector> structFieldObjectInspectors = new ArrayList<ObjectInspector>();
+        for (Byte alias : order) {
+          int sz = conf.getExprs().get(alias).size();
+          List<Integer> retained = conf.getRetainList().get(alias);
+          for (int i = 0; i < sz; i++) {
+            int pos = retained.get(i);
+            structFieldObjectInspectors.add(structFields.get(pos)
+                .getFieldObjectInspector());
+          }
+        }
+        joinOutputObjectInspector = ObjectInspectorFactory
+            .getStandardStructObjectInspector(conf.getOutputColumnNames(),
+                structFieldObjectInspectors);
+      }
+      
       initializeChildren(hconf, reporter, new ObjectInspector[]{joinOutputObjectInspector});
     } catch (IOException e) {
       e.printStackTrace();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPruner.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPruner.java
index 6157fbd42c..5c2995d18d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPruner.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPruner.java
@@ -91,6 +91,8 @@ public ParseContext transform(ParseContext pactx) throws SemanticException {
     opRules.put(new RuleRegExp("R2", "GBY%"), ColumnPrunerProcFactory.getGroupByProc());
     opRules.put(new RuleRegExp("R3", "RS%"), ColumnPrunerProcFactory.getReduceSinkProc());
     opRules.put(new RuleRegExp("R4", "SEL%"), ColumnPrunerProcFactory.getSelectProc());
+    opRules.put(new RuleRegExp("R5", "JOIN%"), ColumnPrunerProcFactory.getJoinProc());
+    opRules.put(new RuleRegExp("R6", "MAPJOIN%"), ColumnPrunerProcFactory.getMapJoinProc());
 
     // The dispatcher fires the processor corresponding to the closest matching rule and passes the context along
     Dispatcher disp = new DefaultRuleDispatcher(ColumnPrunerProcFactory.getDefaultProc(), opRules, cppCtx);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcCtx.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcCtx.java
index 7fc11db574..d879af7a39 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcCtx.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcCtx.java
@@ -24,6 +24,9 @@
 import java.util.List;
 import java.util.Map;
 
+import org.apache.hadoop.hive.ql.exec.CommonJoinOperator;
+import org.apache.hadoop.hive.ql.exec.JoinOperator;
+import org.apache.hadoop.hive.ql.exec.MapJoinOperator;
 import org.apache.hadoop.hive.ql.exec.Operator;
 import org.apache.hadoop.hive.ql.exec.SelectOperator;
 import org.apache.hadoop.hive.ql.exec.Utilities;
@@ -41,12 +44,20 @@ public class ColumnPrunerProcCtx implements NodeProcessorCtx {
   private  Map<Operator<? extends Serializable>,List<String>> prunedColLists;
   
   private HashMap<Operator<? extends Serializable>, OpParseContext> opToParseCtxMap;
+  
+  private  Map<CommonJoinOperator,Map<Byte,List<String>>> joinPrunedColLists;
     
+
   public ColumnPrunerProcCtx(HashMap<Operator<? extends Serializable>, OpParseContext> opToParseContextMap) {
     prunedColLists = new HashMap<Operator<? extends Serializable>, List<String>>();
     this.opToParseCtxMap = opToParseContextMap;
+    joinPrunedColLists = new HashMap<CommonJoinOperator,Map<Byte,List<String>>>();
   }
 
+  public Map<CommonJoinOperator, Map<Byte, List<String>>> getJoinPrunedColLists() {
+    return joinPrunedColLists;
+  }
+  
   /**
    * @return the prunedColLists
    */
@@ -74,8 +85,18 @@ public Map<Operator<? extends Serializable>, List<String>> getPrunedColLists() {
   public List<String> genColLists(Operator<? extends Serializable> curOp) throws SemanticException {
     List<String> colList = new ArrayList<String>();
     if(curOp.getChildOperators() != null) {
-      for(Operator<? extends Serializable> child: curOp.getChildOperators())
-        colList = Utilities.mergeUniqElems(colList, prunedColLists.get(child));
+      for (Operator<? extends Serializable> child : curOp.getChildOperators()) {
+        if (child instanceof CommonJoinOperator) {
+          int tag = child.getParentOperators().indexOf(curOp);
+          List<String> prunList = joinPrunedColLists.get((CommonJoinOperator) child).get(
+              (byte) tag);
+          colList = Utilities
+              .mergeUniqElems(colList, prunList);
+        } else {
+          colList = Utilities
+              .mergeUniqElems(colList, prunedColLists.get(child));
+        }
+      }
     }
     return colList;
   }
@@ -107,6 +128,12 @@ public List<String> getColsFromSelectExpr(SelectOperator op) {
   public List<String> getSelectColsFromChildren(SelectOperator op, List<String> colList) {
     List<String> cols = new ArrayList<String>();
     selectDesc conf = op.getConf();
+    
+    if(conf.isSelStarNoCompute()){
+      cols.addAll(colList);
+      return cols;
+    }
+    
     ArrayList<exprNodeDesc> selectExprs = conf.getColList();
     
     // The colList is the output columns used by child operators, they are different
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
index b2ae31c2b6..9f39c4d254 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
@@ -20,21 +20,25 @@
 
 import java.io.Serializable;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.HashMap;
+import java.util.Iterator;
 import java.util.List;
+import java.util.Map;
+import java.util.Set;
 import java.util.Stack;
 import java.util.Vector;
 
 import org.apache.hadoop.hive.ql.exec.ColumnInfo;
-import org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator;
+import org.apache.hadoop.hive.ql.exec.CommonJoinOperator;
 import org.apache.hadoop.hive.ql.exec.FileSinkOperator;
 import org.apache.hadoop.hive.ql.exec.FilterOperator;
 import org.apache.hadoop.hive.ql.exec.GroupByOperator;
 import org.apache.hadoop.hive.ql.exec.JoinOperator;
 import org.apache.hadoop.hive.ql.exec.LimitOperator;
+import org.apache.hadoop.hive.ql.exec.MapJoinOperator;
 import org.apache.hadoop.hive.ql.exec.Operator;
 import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;
-import org.apache.hadoop.hive.ql.exec.RowSchema;
 import org.apache.hadoop.hive.ql.exec.ScriptOperator;
 import org.apache.hadoop.hive.ql.exec.SelectOperator;
 import org.apache.hadoop.hive.ql.exec.UnionOperator;
@@ -42,15 +46,18 @@
 import org.apache.hadoop.hive.ql.lib.Node;
 import org.apache.hadoop.hive.ql.lib.NodeProcessor;
 import org.apache.hadoop.hive.ql.lib.NodeProcessorCtx;
-import org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcessor;
 import org.apache.hadoop.hive.ql.parse.OpParseContext;
 import org.apache.hadoop.hive.ql.parse.RowResolver;
 import org.apache.hadoop.hive.ql.parse.SemanticException;
+import org.apache.hadoop.hive.ql.plan.PlanUtils;
 import org.apache.hadoop.hive.ql.plan.aggregationDesc;
 import org.apache.hadoop.hive.ql.plan.exprNodeDesc;
 import org.apache.hadoop.hive.ql.plan.groupByDesc;
+import org.apache.hadoop.hive.ql.plan.joinDesc;
+import org.apache.hadoop.hive.ql.plan.mapJoinDesc;
 import org.apache.hadoop.hive.ql.plan.reduceSinkDesc;
 import org.apache.hadoop.hive.ql.plan.selectDesc;
+import org.apache.hadoop.hive.ql.plan.tableDesc;
 
 /**
  * Factory for generating the different node processors used by ColumnPruner.
@@ -148,10 +155,6 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx ctx, Object..
       reduceSinkDesc conf = op.getConf();
       List<Operator<? extends Serializable>> childOperators = op.getChildOperators();
       List<Operator<? extends Serializable>> parentOperators = op.getParentOperators();
-      List<String> childColLists = new ArrayList<String>();
-
-      for(Operator<? extends Serializable> child: childOperators)
-        childColLists = Utilities.mergeUniqElems(childColLists, cppCtx.getPrunedColLists().get(child));
 
       List<String> colLists = new ArrayList<String>();
       ArrayList<exprNodeDesc> keys = conf.getKeyCols();
@@ -161,18 +164,28 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx ctx, Object..
       if ((childOperators.size() == 1) && (childOperators.get(0) instanceof JoinOperator)) {
         assert parentOperators.size() == 1;
         Operator<? extends Serializable> par = parentOperators.get(0);
+        JoinOperator childJoin = (JoinOperator)childOperators.get(0);
         RowResolver parRR = opToParseCtxMap.get(par).getRR();
-        RowResolver childRR = opToParseCtxMap.get(childOperators.get(0)).getRR();
-
-        for (String childCol : childColLists) {
-          String [] nm = childRR.reverseLookup(childCol);
-          ColumnInfo cInfo = redSinkRR.get(nm[0],nm[1]);
-          if (cInfo != null) {
-            cInfo = parRR.get(nm[0], nm[1]);
-            if (!colLists.contains(cInfo.getInternalName()))
-              colLists.add(cInfo.getInternalName());
+        List<String> childJoinCols = cppCtx.getJoinPrunedColLists().get(childJoin).get((byte)conf.getTag());
+        boolean[] flags = new boolean[conf.getValueCols().size()];
+        for (int i = 0; i < flags.length; i++)
+          flags[i] = false;
+        if (childJoinCols != null && childJoinCols.size() > 0) {
+          Map<String,exprNodeDesc> exprMap = op.getColumnExprMap();
+          for (String childCol : childJoinCols) {
+            exprNodeDesc desc = exprMap.get(childCol);
+            int index = conf.getValueCols().indexOf(desc);
+            flags[index] = true;
+            String[] nm = redSinkRR.reverseLookup(childCol);
+            if (nm != null) {
+              ColumnInfo cInfo = parRR.get(nm[0], nm[1]);
+              if (!colLists.contains(cInfo.getInternalName()))
+                colLists.add(cInfo.getInternalName());
+            }
           }
         }
+        Collections.sort(colLists);
+        pruneReduceSinkOperator(flags, op, cppCtx);
       }
       else {
         // Reduce Sink contains the columns needed - no need to aggregate from children
@@ -214,15 +227,18 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx ctx, Object..
             cppCtx.getPrunedColLists().put(op, cppCtx.getColsFromSelectExpr(op));
             return null;
           }
-          cols = Utilities.mergeUniqElems(cols, cppCtx.getPrunedColLists().get(child));
         }
       }
+      cols = cppCtx.genColLists(op);
 
       selectDesc conf = op.getConf();
       // The input to the select does not matter. Go over the expressions 
       // and return the ones which have a marked column
       cppCtx.getPrunedColLists().put(op, cppCtx.getSelectColsFromChildren(op, cols));
       
+      if(conf.isSelStarNoCompute())
+        return null;
+      
       // do we need to prune the select operator?
       List<exprNodeDesc> originalColList = op.getConf().getColList();
       List<String> columns = new ArrayList<String>();
@@ -251,7 +267,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx ctx, Object..
         op.getSchema().setSignature(rs_newsignature);
         conf.setColList(newColList);
         conf.setOutputColumnNames(newOutputColumnNames);
-        handleChildren(op, cols);
+        handleChildren(op, cols, cppCtx);
       }
       return null;
     }
@@ -264,54 +280,102 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx ctx, Object..
      * 
      * @param op
      * @param retainedSelOutputCols
+     * @throws SemanticException 
      */
     private void handleChildren(SelectOperator op,
-        List<String> retainedSelOutputCols) {
+        List<String> retainedSelOutputCols, ColumnPrunerProcCtx cppCtx) throws SemanticException {
       for(Operator<? extends Serializable> child: op.getChildOperators()) {
         if (child instanceof ReduceSinkOperator) {
-          pruneReduceSinkOperator(retainedSelOutputCols, (ReduceSinkOperator)child);
+          boolean[] flags = getPruneReduceSinkOpRetainFlags(retainedSelOutputCols, (ReduceSinkOperator)child);
+          pruneReduceSinkOperator(flags, (ReduceSinkOperator)child, cppCtx);
         }else if (child instanceof FilterOperator){
           //filter operator has the same output columns as its parent
           for(Operator<? extends Serializable> filterChild: child.getChildOperators()){
-            if (filterChild instanceof ReduceSinkOperator)
-              pruneReduceSinkOperator(retainedSelOutputCols, (ReduceSinkOperator)filterChild);
+            if (filterChild instanceof ReduceSinkOperator) {
+              boolean[] flags = getPruneReduceSinkOpRetainFlags(retainedSelOutputCols, (ReduceSinkOperator)filterChild);
+              pruneReduceSinkOperator(flags, (ReduceSinkOperator)filterChild, cppCtx);
+            }
           }
         }
       }
     }
-
-    private void pruneReduceSinkOperator(List<String> retainedSelOpOutputCols,
-        ReduceSinkOperator child) {
-      ReduceSinkOperator reduce = (ReduceSinkOperator) child;
-      reduceSinkDesc reduceConf = reduce.getConf();
-      ArrayList<String> originalValueOutputColNames = reduceConf
-          .getOutputValueColumnNames();
-      java.util.ArrayList<exprNodeDesc> originalValueEval = reduceConf
-          .getValueCols();
-      ArrayList<String> newOutputColNames = new ArrayList<String>();
-      java.util.ArrayList<exprNodeDesc> newValueEval = new ArrayList<exprNodeDesc>();
-      for (int i = 0; i < originalValueEval.size(); i++) {
-        boolean retain = false;
-        List<String> current = originalValueEval.get(i).getCols();
-        if (current != null) {
-          for (int j = 0; j < current.size(); j++) {
-            if (retainedSelOpOutputCols.contains(current.get(j))) {
-              retain = true;
-              break;
-            }
+  }
+  
+  private static boolean[] getPruneReduceSinkOpRetainFlags(List<String> retainedParentOpOutputCols, ReduceSinkOperator reduce){
+    reduceSinkDesc reduceConf = reduce.getConf();
+    java.util.ArrayList<exprNodeDesc> originalValueEval = reduceConf.getValueCols();
+    boolean[] flags = new boolean[originalValueEval.size()];
+    for (int i = 0; i < originalValueEval.size(); i++) {
+      flags[i] = false;
+      List<String> current = originalValueEval.get(i).getCols();
+      if (current != null) {
+        for (int j = 0; j < current.size(); j++) {
+          if (retainedParentOpOutputCols.contains(current.get(j))) {
+            flags[i] = true;
+            break;
           }
         }
-        if (retain) {
-          newOutputColNames.add(originalValueOutputColNames.get(i));
-          newValueEval.add(originalValueEval.get(i));
+      }
+    }
+    return flags;
+  }
+  
+  private static void pruneReduceSinkOperator(boolean[] retainFlags,
+      ReduceSinkOperator reduce, ColumnPrunerProcCtx cppCtx) throws SemanticException {
+    reduceSinkDesc reduceConf = reduce.getConf();
+    Map<String, exprNodeDesc> oldMap = reduce.getColumnExprMap();
+    Map<String, exprNodeDesc> newMap = new HashMap<String, exprNodeDesc>();
+    Vector<ColumnInfo> sig = new Vector<ColumnInfo>();
+    RowResolver oldRR = cppCtx.getOpToParseCtxMap().get(reduce).getRR();
+    RowResolver newRR = new RowResolver();
+    ArrayList<String> originalValueOutputColNames = reduceConf
+        .getOutputValueColumnNames();
+    java.util.ArrayList<exprNodeDesc> originalValueEval = reduceConf
+        .getValueCols();
+    ArrayList<String> newOutputColNames = new ArrayList<String>();
+    java.util.ArrayList<exprNodeDesc> newValueEval = new ArrayList<exprNodeDesc>();
+    for (int i = 0; i < retainFlags.length; i++) {
+      if (retainFlags[i]) {
+        newValueEval.add(originalValueEval.get(i));
+        String outputCol = originalValueOutputColNames.get(i);
+        newOutputColNames.add(outputCol);
+        String[] nm = oldRR.reverseLookup(outputCol);
+        if (nm == null) {
+          outputCol = Utilities.ReduceField.VALUE.toString() + "." + outputCol;
+          nm = oldRR.reverseLookup(outputCol);
         }
+        newMap.put(outputCol, oldMap.get(outputCol));
+        ColumnInfo colInfo = oldRR.get(nm[0], nm[1]);
+        newRR.put(nm[0], nm[1], colInfo);
+        sig.add(colInfo);
       }
-      reduceConf.setOutputValueColumnNames(newOutputColNames);
-      reduceConf.setValueCols(newValueEval);
     }
-
+    
+    ArrayList<exprNodeDesc> keyCols = reduceConf.getKeyCols();
+    List<String> keys = new ArrayList<String>();
+    RowResolver parResover = cppCtx.getOpToParseCtxMap().get(reduce.getParentOperators().get(0)).getRR();
+    for (int i = 0; i < keyCols.size(); i++) {
+      keys = Utilities.mergeUniqElems(keys, keyCols.get(i).getCols());
+    }
+    for (int i = 0; i < keys.size(); i++) {
+      String outputCol = keys.get(i);
+      String[] nm = parResover.reverseLookup(outputCol);
+      ColumnInfo colInfo = oldRR.get(nm[0], nm[1]);
+      if (colInfo != null)
+        newRR.put(nm[0], nm[1], colInfo);
+    }
+    
+    cppCtx.getOpToParseCtxMap().get(reduce).setRR(newRR);
+    reduce.setColumnExprMap(newMap);
+    reduce.getSchema().setSignature(sig);
+    reduceConf.setOutputValueColumnNames(newOutputColNames);
+    reduceConf.setValueCols(newValueEval);
+    tableDesc newValueTable = PlanUtils.getLazySimpleSerDeTableDesc(PlanUtils.getFieldSchemasFromColumnList(
+        reduceConf.getValueCols(), newOutputColNames, 0, ""));
+    reduceConf.setValueSerializeInfo(newValueTable);
   }
 
+
   /**
    * The Factory method to get the ColumnPrunerSelectProc class.
    * @return ColumnPrunerSelectProc
@@ -320,4 +384,150 @@ public static ColumnPrunerSelectProc getSelectProc() {
     return new ColumnPrunerSelectProc();
   }
   
+  /**
+   * The Node Processor for Column Pruning on Join Operators.
+   */
+  public static class ColumnPrunerJoinProc implements NodeProcessor {
+    public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx ctx,
+        Object... nodeOutputs) throws SemanticException {
+      JoinOperator op = (JoinOperator) nd;
+      pruneJoinOperator(ctx, op, op.getConf(), op.getColumnExprMap(), null, false);
+      return null;
+    }
+  }
+
+  /**
+   * The Factory method to get ColumnJoinProc class.
+   * 
+   * @return ColumnPrunerJoinProc
+   */
+  public static ColumnPrunerJoinProc getJoinProc() {
+    return new ColumnPrunerJoinProc();
+  }
+  
+  /**
+   * The Node Processor for Column Pruning on Join Operators.
+   */
+  public static class ColumnPrunerMapJoinProc implements NodeProcessor {
+    public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx ctx,
+        Object... nodeOutputs) throws SemanticException {
+      MapJoinOperator op = (MapJoinOperator) nd;
+      pruneJoinOperator(ctx, op, op.getConf(), op.getColumnExprMap(), op.getConf().getRetainList(), true);
+      return null;
+    }
+  }
+  
+  private static void pruneJoinOperator(NodeProcessorCtx ctx,
+      CommonJoinOperator op, joinDesc conf,
+      Map<String, exprNodeDesc> columnExprMap,
+      Map<Byte, List<Integer>> retainMap, boolean mapJoin) throws SemanticException {
+    ColumnPrunerProcCtx cppCtx = (ColumnPrunerProcCtx) ctx;
+    Map<Byte, List<String>> prunedColLists = new HashMap<Byte, List<String>>();
+    List<Operator<? extends Serializable>> childOperators = op
+        .getChildOperators();
+
+    for (Operator<? extends Serializable> child : childOperators) {
+      if (child instanceof FileSinkOperator)
+        return;
+    }
+
+    List<String> childColLists = cppCtx.genColLists((Operator<? extends Serializable>)op);
+    
+    RowResolver joinRR = cppCtx.getOpToParseCtxMap().get(op).getRR();
+    RowResolver newJoinRR = new RowResolver();
+    ArrayList<String> outputCols = new ArrayList<String>();
+    Vector<ColumnInfo> rs = new Vector<ColumnInfo>();
+    Map<String, exprNodeDesc> newColExprMap = new HashMap<String, exprNodeDesc>();
+
+    for (int i = 0; i < conf.getOutputColumnNames().size(); i++) {
+      String internalName = conf.getOutputColumnNames().get(i);
+      exprNodeDesc desc = columnExprMap.get(internalName);
+      Byte tag = conf.getReversedExprs().get(internalName);
+      if (!childColLists.contains(internalName)) {
+        int index = conf.getExprs().get(tag).indexOf(desc);
+        if (index < 0)
+          continue;
+        conf.getExprs().get(tag).remove(desc);
+        if (retainMap != null)
+          retainMap.get(tag).remove(index);
+      } else {
+        List<String> prunedRSList = prunedColLists.get(tag);
+        if (prunedRSList == null) {
+          prunedRSList = new ArrayList<String>();
+          prunedColLists.put(tag, prunedRSList);
+        }
+        prunedRSList = Utilities.mergeUniqElems(prunedRSList, desc.getCols());
+        outputCols.add(internalName);
+        newColExprMap.put(internalName, desc);
+      }
+    }
+    
+    if (mapJoin) {
+      // regenerate the valueTableDesc
+      List<tableDesc> valueTableDescs = new ArrayList<tableDesc>();
+      for (int pos = 0; pos < op.getParentOperators().size(); pos++) {
+        List<exprNodeDesc> valueCols = conf.getExprs()
+            .get(new Byte((byte) pos));
+        StringBuilder keyOrder = new StringBuilder();
+        for (int i = 0; i < valueCols.size(); i++) {
+          keyOrder.append("+");
+        }
+
+        tableDesc valueTableDesc = PlanUtils
+            .getLazySimpleSerDeTableDesc(PlanUtils
+                .getFieldSchemasFromColumnList(valueCols, "mapjoinvalue"));
+
+        valueTableDescs.add(valueTableDesc);
+      }
+      ((mapJoinDesc) conf).setValueTblDescs(valueTableDescs);
+
+      Set<Map.Entry<Byte, List<exprNodeDesc>>> exprs = ((mapJoinDesc) conf)
+          .getKeys().entrySet();
+      Iterator<Map.Entry<Byte, List<exprNodeDesc>>> iters = exprs.iterator();
+      while (iters.hasNext()) {
+        Map.Entry<Byte, List<exprNodeDesc>> entry = iters.next();
+        List<exprNodeDesc> lists = entry.getValue();
+        for (int j = 0; j < lists.size(); j++) {
+          exprNodeDesc desc = lists.get(j);
+          Byte tag = entry.getKey();
+          List<String> cols = prunedColLists.get(tag);
+          cols = Utilities.mergeUniqElems(cols, desc.getCols());
+          prunedColLists.put(tag, cols);
+        }
+      }
+
+    }
+
+    for (Operator<? extends Serializable> child : childOperators) {
+      if (child instanceof ReduceSinkOperator) {
+        boolean[] flags = getPruneReduceSinkOpRetainFlags(childColLists,
+            (ReduceSinkOperator) child);
+        pruneReduceSinkOperator(flags, (ReduceSinkOperator) child, cppCtx);
+      }
+    }
+
+    for (int i = 0; i < childColLists.size(); i++) {
+      String internalName = childColLists.get(i);
+      String[] nm = joinRR.reverseLookup(internalName);
+      ColumnInfo col = joinRR.get(nm[0], nm[1]);
+      newJoinRR.put(nm[0], nm[1], col);
+      rs.add(col);
+    }
+
+    op.setColumnExprMap(newColExprMap);
+    conf.setOutputColumnNames(outputCols);
+    op.getSchema().setSignature(rs);
+    cppCtx.getOpToParseCtxMap().get(op).setRR(newJoinRR);
+    cppCtx.getJoinPrunedColLists().put(op, prunedColLists);
+  }
+
+  /**
+   * The Factory method to get ColumnJoinProc class.
+   * 
+   * @return ColumnPrunerJoinProc
+   */
+  public static ColumnPrunerMapJoinProc getMapJoinProc() {
+    return new ColumnPrunerMapJoinProc();
+  }
+  
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
index df9869f4fa..e1c8fb5190 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
@@ -112,7 +112,7 @@ private void convertMapJoin(ParseContext pctx, JoinOperator op, QBJoinTree joinT
     List<Operator<? extends Serializable>> parentOps = op.getParentOperators();
     List<Operator<? extends Serializable>> newParentOps = new ArrayList<Operator<? extends Serializable>>();
     List<Operator<? extends Serializable>> oldReduceSinkParentOps = new ArrayList<Operator<? extends Serializable>>();
-    
+    Map<String, exprNodeDesc> colExprMap = new HashMap<String, exprNodeDesc>();
     // found a source which is not to be stored in memory
     if (leftSrc != null) {
       //      assert mapJoinPos == 0;
@@ -166,15 +166,17 @@ private void convertMapJoin(ParseContext pctx, JoinOperator op, QBJoinTree joinT
         {
           String field = fNamesIter.next();
           ColumnInfo valueInfo = inputRS.get(key, field);
-          values.add(new exprNodeColumnDesc(valueInfo.getType(), valueInfo.getInternalName()));
           ColumnInfo oldValueInfo = oldOutputRS.get(key, field);
-          String col = field;
-          if(oldValueInfo != null)
-            col = oldValueInfo.getInternalName();
-          if (outputRS.get(key, col) == null) {
-            outputColumnNames.add(col);
-            outputRS.put(key, col, new ColumnInfo(col, 
+          if(oldValueInfo == null)
+            continue;
+          String outputCol = oldValueInfo.getInternalName();
+          if (outputRS.get(key, field) == null) {
+            outputColumnNames.add(outputCol);
+            exprNodeDesc colDesc = new exprNodeColumnDesc(valueInfo.getType(), valueInfo.getInternalName());
+            values.add(colDesc);
+            outputRS.put(key, field, new ColumnInfo(outputCol, 
                 valueInfo.getType()));
+            colExprMap.put(outputCol, colDesc);
           }
         }
       }
@@ -238,6 +240,9 @@ private void convertMapJoin(ParseContext pctx, JoinOperator op, QBJoinTree joinT
       new mapJoinDesc(keyExprMap, keyTableDesc, valueExprMap, valueTableDescs, outputColumnNames, mapJoinPos, joinCondns),
       new RowSchema(outputRS.getColumnInfos()), newPar), outputRS);
     
+    mapJoinOp.getConf().setReversedExprs(op.getConf().getReversedExprs());
+    mapJoinOp.setColumnExprMap(colExprMap);
+    
     // change the children of the original join operator to point to the map join operator
     List<Operator<? extends Serializable>> childOps = op.getChildOperators();
     for (Operator<? extends Serializable> childOp : childOps) 
@@ -252,15 +257,40 @@ private void convertMapJoin(ParseContext pctx, JoinOperator op, QBJoinTree joinT
     genSelectPlan(pctx, mapJoinOp);
   }
 
-  private void genSelectPlan(ParseContext pctx, Operator<? extends Serializable> input) {
+  private void genSelectPlan(ParseContext pctx, MapJoinOperator input) throws SemanticException {
     List<Operator<? extends Serializable>> childOps = input.getChildOperators();
     input.setChildOperators(null);
 
     // create a dummy select - This select is needed by the walker to split the mapJoin later on
   	RowResolver inputRR = pctx.getOpParseCtx().get(input).getRR();
+  	
+  	ArrayList<exprNodeDesc> exprs = new ArrayList<exprNodeDesc>();
+  	ArrayList<String> outputs = new ArrayList<String>();
+    List<String> outputCols = input.getConf().getOutputColumnNames();
+    RowResolver outputRS = new RowResolver();
+    
+    Map<String, exprNodeDesc> colExprMap = new HashMap<String, exprNodeDesc>();
+    
+    for (int i = 0; i < outputCols.size(); i++) {
+      String internalName = outputCols.get(i);
+      String[] nm = inputRR.reverseLookup(internalName);
+      ColumnInfo valueInfo = inputRR.get(nm[0], nm[1]);
+      exprNodeDesc colDesc = new exprNodeColumnDesc(valueInfo.getType(),
+          valueInfo.getInternalName());
+      exprs.add(colDesc);
+      outputs.add(internalName);
+      outputRS .put(nm[0], nm[1], new ColumnInfo(internalName, 
+          valueInfo.getType()));
+      colExprMap.put(internalName, colDesc);
+    }
+  	
+  	selectDesc select = new selectDesc(exprs, outputs, false);
+  	
     SelectOperator sel = 
       (SelectOperator)putOpInsertMap(OperatorFactory.getAndMakeChild(
-                       new selectDesc(true), new RowSchema(inputRR.getColumnInfos()), input), inputRR);
+          select, new RowSchema(inputRR.getColumnInfos()), input), inputRR);
+    
+    sel.setColumnExprMap(colExprMap);
     
     // Insert the select operator in between. 
     sel.setChildOperators(childOps);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 6645aeb759..ed980c229d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -2625,6 +2625,7 @@ private Operator genJoinOperatorChildren(QBJoinTree join, Operator left, Operato
     int pos = 0;
     int outputPos = 0;
 
+    Map<String, Byte> reversedExprs = new HashMap<String, Byte>(); 
     HashMap<Byte, List<exprNodeDesc>> exprMap = new HashMap<Byte, List<exprNodeDesc>>();
     Map<String, exprNodeDesc> colExprMap = new HashMap<String, exprNodeDesc>();
     HashMap<Integer, Set<String>> posToAliasMap = new HashMap<Integer, Set<String>>();
@@ -2660,6 +2661,7 @@ private Operator genJoinOperatorChildren(QBJoinTree join, Operator left, Operato
             colExprMap.put(colName, keyDesc.get(keyDesc.size() - 1));
             outputRS.put(key, field, new ColumnInfo(colName, 
                                                     valueInfo.getType()));
+            reversedExprs.put(colName, tag);
           }
         }
       }
@@ -2674,7 +2676,9 @@ private Operator genJoinOperatorChildren(QBJoinTree join, Operator left, Operato
       joinCondns[i] = new org.apache.hadoop.hive.ql.plan.joinCond(condn);
     }
 
-    JoinOperator joinOp = (JoinOperator) OperatorFactory.getAndMakeChild(new joinDesc(exprMap, outputColumnNames, joinCondns),
+    joinDesc desc = new joinDesc(exprMap, outputColumnNames, joinCondns);
+    desc.setReversedExprs(reversedExprs);
+    JoinOperator joinOp = (JoinOperator) OperatorFactory.getAndMakeChild(desc,
                                     new RowSchema(outputRS.getColumnInfos()), rightOps);
     joinOp.setColumnExprMap(colExprMap);
     joinOp.setPosToAliasMap(posToAliasMap);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/joinDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/joinDesc.java
index fccc690e6e..232ad83e98 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/joinDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/joinDesc.java
@@ -22,9 +22,13 @@
 
 import org.apache.hadoop.hive.ql.plan.exprNodeDesc;
 import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.Set;
+import java.util.Map.Entry;
 
 /**
  * Join operator Descriptor implementation.
@@ -41,8 +45,12 @@ public class joinDesc implements Serializable {
   // alias to key mapping
   private Map<Byte, List<exprNodeDesc>> exprs;
   
+  //used for create joinOutputObjectInspector
   protected java.util.ArrayList<java.lang.String> outputColumnNames;
   
+  // key:column output name, value:tag
+  transient private Map<String, Byte> reversedExprs;
+  
   // No outer join involved
   protected boolean noOuterJoin;
 
@@ -58,23 +66,25 @@ public joinDesc(final Map<Byte, List<exprNodeDesc>> exprs, ArrayList<String> out
   }
   
   public joinDesc(final Map<Byte, List<exprNodeDesc>> exprs, ArrayList<String> outputColumnNames) {
-    this.exprs = exprs;
-    this.outputColumnNames = outputColumnNames;
-    this.noOuterJoin = true;
-    this.conds = null;
+    this(exprs, outputColumnNames, true, null);
   }
 
   public joinDesc(final Map<Byte, List<exprNodeDesc>> exprs, ArrayList<String> outputColumnNames, final joinCond[] conds) {
-    this.exprs = exprs;
-    this.outputColumnNames = outputColumnNames;
-    this.noOuterJoin = false;
-    this.conds = conds;
+    this(exprs, outputColumnNames, false, conds);
   }
   
   public Map<Byte, List<exprNodeDesc>> getExprs() {
     return this.exprs;
   }
+  
+  public Map<String, Byte> getReversedExprs() {
+    return reversedExprs;
+  }
 
+  public void setReversedExprs(Map<String, Byte> reversed_Exprs) {
+    this.reversedExprs = reversed_Exprs;
+  }
+  
   @explain(displayName="condition expressions")
   public Map<Byte, String> getExprsStringMap() {
     if (getExprs() == null) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/mapJoinDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/mapJoinDesc.java
index bf5bd1474c..8e37bfb814 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/mapJoinDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/mapJoinDesc.java
@@ -23,8 +23,12 @@
 import org.apache.hadoop.hive.ql.plan.exprNodeDesc;
 
 import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
+import java.util.Set;
+import java.util.Map.Entry;
 
 /**
  * Map Join operator Descriptor implementation.
@@ -40,6 +44,8 @@ public class mapJoinDesc extends joinDesc implements Serializable {
   
   private int posBigTable;
   
+  private Map<Byte, List<Integer>> retainList;
+  
   public mapJoinDesc() { }
 
   public mapJoinDesc(final Map<Byte, List<exprNodeDesc>> keys, 
@@ -54,8 +60,31 @@ public mapJoinDesc(final Map<Byte, List<exprNodeDesc>> keys,
     this.keyTblDesc  = keyTblDesc;
     this.valueTblDescs = valueTblDescs;
     this.posBigTable = posBigTable;
+    initRetainExprList();
   }
 
+  private void initRetainExprList() {
+    retainList = new HashMap<Byte, List<Integer>>();
+    Set<Entry<Byte, List<exprNodeDesc>>> set = super.getExprs().entrySet();
+    Iterator<Entry<Byte, List<exprNodeDesc>>> setIter = set.iterator();
+    while (setIter.hasNext()) {
+      Entry<Byte, List<exprNodeDesc>> current = setIter.next();
+      List<Integer> list = new ArrayList<Integer>();
+      for (int i = 0; i < current.getValue().size(); i++) {
+        list.add(i);
+      }
+      retainList.put(current.getKey(), list);
+    }
+  }
+  
+  public Map<Byte, List<Integer>> getRetainList() {
+    return retainList;
+  }
+
+  public void setRetainList(Map<Byte, List<Integer>> retainList) {
+    this.retainList = retainList;
+  }
+  
   /**
    * @return the keys
    */
diff --git a/ql/src/test/results/clientpositive/cluster.q.out b/ql/src/test/results/clientpositive/cluster.q.out
index 4a46b93a10..22c949ba00 100644
--- a/ql/src/test/results/clientpositive/cluster.q.out
+++ b/ql/src/test/results/clientpositive/cluster.q.out
@@ -56,7 +56,7 @@ STAGE PLANS:
 
 query: SELECT * FROM SRC x where x.key = 10 CLUSTER BY x.key
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/469446419/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1095159989/10000
 10	val_10
 query: EXPLAIN
 SELECT * FROM SRC x  where x.key = 20 CLUSTER BY key
@@ -116,7 +116,7 @@ STAGE PLANS:
 
 query: SELECT * FROM SRC x where x.key = 20 CLUSTER BY key
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/918784205/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1519767132/10000
 20	val_20
 query: EXPLAIN
 SELECT x.* FROM SRC x where x.key = 20 CLUSTER BY key
@@ -176,7 +176,7 @@ STAGE PLANS:
 
 query: SELECT x.* FROM SRC x where x.key = 20 CLUSTER BY key
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/787341560/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1645256115/10000
 20	val_20
 query: EXPLAIN
 SELECT x.*  FROM SRC x where x.key = 20 CLUSTER BY x.key
@@ -236,7 +236,7 @@ STAGE PLANS:
 
 query: SELECT x.*  FROM SRC x where x.key = 20 CLUSTER BY x.key
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/2112333625/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/97254899/10000
 20	val_20
 query: EXPLAIN
 SELECT x.key, x.value as v1 FROM SRC x where x.key = 20 CLUSTER BY key
@@ -296,7 +296,7 @@ STAGE PLANS:
 
 query: SELECT x.key, x.value as v1 FROM SRC x where x.key = 20 CLUSTER BY key
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/82082573/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/519369730/10000
 20	val_20
 query: EXPLAIN
 SELECT x.key, x.value as v1 FROM SRC x where x.key = 20 CLUSTER BY x.key
@@ -356,7 +356,7 @@ STAGE PLANS:
 
 query: SELECT x.key, x.value as v1 FROM SRC x where x.key = 20 CLUSTER BY x.key
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/585460645/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1772518510/10000
 20	val_20
 query: EXPLAIN
 SELECT x.key, x.value as v1  FROM SRC x where x.key = 20 CLUSTER BY v1
@@ -416,7 +416,7 @@ STAGE PLANS:
 
 query: SELECT x.key, x.value as v1  FROM SRC x where x.key = 20 CLUSTER BY v1
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1403624942/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1378918493/10000
 20	val_20
 query: EXPLAIN
 SELECT y.* from (SELECT x.* FROM SRC x CLUSTER BY x.key) y where y.key = 20
@@ -478,7 +478,7 @@ STAGE PLANS:
 
 query: SELECT y.* from (SELECT x.* FROM SRC x CLUSTER BY x.key) y where y.key = 20
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/595719915/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1355587729/10000
 20	val_20
 query: EXPLAIN 
 SELECT x.key, x.value as v1, y.key  FROM SRC x JOIN SRC y ON (x.key = y.key)  where x.key = 20 CLUSTER BY v1
@@ -507,8 +507,6 @@ STAGE PLANS:
               value expressions:
                     expr: key
                     type: string
-                    expr: value
-                    type: string
         x 
             Filter Operator
               predicate:
@@ -534,7 +532,7 @@ STAGE PLANS:
                Inner Join 0 to 1
           condition expressions:
             0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            1 {VALUE._col0}
           Filter Operator
             predicate:
                 expr: (UDFToDouble(_col0) = UDFToDouble(20))
@@ -558,7 +556,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/654289407/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/347887659/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col1
@@ -591,7 +589,7 @@ STAGE PLANS:
 
 query: SELECT x.key, x.value as v1, y.key  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY v1
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1865686895/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1452481387/10000
 20	val_20	20
 query: EXPLAIN 
 SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY v1
@@ -673,7 +671,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/782657504/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1377636554/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col1
@@ -708,7 +706,7 @@ STAGE PLANS:
 
 query: SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY v1
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1662517786/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/270617627/10000
 20	val_20	20	val_20
 query: EXPLAIN
 SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY x.key
@@ -790,7 +788,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1094038570/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1638142206/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -825,7 +823,7 @@ STAGE PLANS:
 
 query: SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY x.key
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1889196452/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1510688507/10000
 20	val_20	20	val_20
 query: EXPLAIN
 SELECT x.key, x.value as v1, y.key as yk  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY key
@@ -854,8 +852,6 @@ STAGE PLANS:
               value expressions:
                     expr: key
                     type: string
-                    expr: value
-                    type: string
         x 
             Filter Operator
               predicate:
@@ -881,7 +877,7 @@ STAGE PLANS:
                Inner Join 0 to 1
           condition expressions:
             0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            1 {VALUE._col0}
           Filter Operator
             predicate:
                 expr: (UDFToDouble(_col0) = UDFToDouble(20))
@@ -905,7 +901,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1162478443/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/221814948/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -938,7 +934,7 @@ STAGE PLANS:
 
 query: SELECT x.key, x.value as v1, y.key as yk  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY key
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/681246043/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1735292170/10000
 20	val_20	20
 query: EXPLAIN
 SELECT unioninput.*
@@ -1053,7 +1049,7 @@ FROM (
 ) unioninput
 CLUSTER BY unioninput.key
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/571624743/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/432509193/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join1.q.out b/ql/src/test/results/clientpositive/join1.q.out
index 86e99f59fb..931c1d3fa8 100644
--- a/ql/src/test/results/clientpositive/join1.q.out
+++ b/ql/src/test/results/clientpositive/join1.q.out
@@ -24,8 +24,6 @@ STAGE PLANS:
                     type: string
               tag: 1
               value expressions:
-                    expr: key
-                    type: string
                     expr: value
                     type: string
         src1 
@@ -41,15 +39,13 @@ STAGE PLANS:
               value expressions:
                     expr: key
                     type: string
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0}
+            1 {VALUE._col1}
           Select Operator
             expressions:
                   expr: _col0
@@ -88,7 +84,7 @@ Input: default/src
 Output: default/dest_j1
 query: SELECT dest_j1.* FROM dest_j1
 Input: default/dest_j1
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/791244140/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1850221773/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join10.q.out b/ql/src/test/results/clientpositive/join10.q.out
index c8b0c5182d..02da2ae2c8 100644
--- a/ql/src/test/results/clientpositive/join10.q.out
+++ b/ql/src/test/results/clientpositive/join10.q.out
@@ -29,9 +29,6 @@ STAGE PLANS:
                       expr: _col0
                       type: string
                 tag: 0
-                value expressions:
-                      expr: _col0
-                      type: string
         y:src 
             Select Operator
               expressions:
@@ -58,7 +55,7 @@ STAGE PLANS:
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
+            0 
             1 {VALUE._col0} {VALUE._col1}
           Select Operator
             expressions:
@@ -85,7 +82,7 @@ JOIN
 ON (x.key = Y.key)
 SELECT Y.*
 Input: default/src
-Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/397770096/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/576477959/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join11.q.out b/ql/src/test/results/clientpositive/join11.q.out
index 26fd650bf9..062a498938 100644
--- a/ql/src/test/results/clientpositive/join11.q.out
+++ b/ql/src/test/results/clientpositive/join11.q.out
@@ -33,8 +33,6 @@ STAGE PLANS:
                       type: string
                 tag: 1
                 value expressions:
-                      expr: _col0
-                      type: string
                       expr: _col1
                       type: string
         src1:src 
@@ -67,8 +65,8 @@ STAGE PLANS:
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0}
+            1 {VALUE._col1}
           Select Operator
             expressions:
                   expr: _col0
@@ -94,7 +92,7 @@ JOIN
 (SELECT src.key as c3, src.value as c4 from src) src2
 ON src1.c1 = src2.c3 AND src1.c1 < 100
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1092092252/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/774077443/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join12.q.out b/ql/src/test/results/clientpositive/join12.q.out
index a70cadf6e5..497ccbd173 100644
--- a/ql/src/test/results/clientpositive/join12.q.out
+++ b/ql/src/test/results/clientpositive/join12.q.out
@@ -36,8 +36,6 @@ STAGE PLANS:
                       type: string
                 tag: 1
                 value expressions:
-                      expr: _col0
-                      type: string
                       expr: _col1
                       type: string
         src1:src 
@@ -87,18 +85,15 @@ STAGE PLANS:
                           expr: _col0
                           type: string
                     tag: 2
-                    value expressions:
-                          expr: _col0
-                          type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
                Inner Join 0 to 2
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
-            2 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0}
+            1 {VALUE._col1}
+            2 
           Select Operator
             expressions:
                   expr: _col0
@@ -127,7 +122,7 @@ JOIN
 (SELECT src.key as c5, src.value as c6 from src) src3
 ON src1.c1 = src3.c5 AND src3.c5 < 80
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/2007793008/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1217946262/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join13.q.out b/ql/src/test/results/clientpositive/join13.q.out
index c1f2b2cfb1..2c60087d26 100644
--- a/ql/src/test/results/clientpositive/join13.q.out
+++ b/ql/src/test/results/clientpositive/join13.q.out
@@ -71,7 +71,7 @@ STAGE PLANS:
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0}
             1 {VALUE._col0} {VALUE._col1}
           File Output Operator
             compressed: false
@@ -95,14 +95,10 @@ STAGE PLANS:
                     type: double
               tag: 0
               value expressions:
-                    expr: _col2
-                    type: string
                     expr: _col3
                     type: string
                     expr: _col0
                     type: string
-                    expr: _col1
-                    type: string
         src3:src 
             Filter Operator
               predicate:
@@ -125,16 +121,13 @@ STAGE PLANS:
                           expr: UDFToDouble(_col0)
                           type: double
                     tag: 1
-                    value expressions:
-                          expr: _col0
-                          type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
-            1 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col1} {VALUE._col2}
+            1 
           Select Operator
             expressions:
                   expr: _col2
@@ -163,7 +156,7 @@ JOIN
 (SELECT src.key as c5, src.value as c6 from src) src3
 ON src1.c1 + src2.c3 = src3.c5 AND src3.c5 < 200
 Input: default/src
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1162005483/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/372904562/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join14.q.out b/ql/src/test/results/clientpositive/join14.q.out
index bb84ba601c..c4e9cdb909 100644
--- a/ql/src/test/results/clientpositive/join14.q.out
+++ b/ql/src/test/results/clientpositive/join14.q.out
@@ -32,14 +32,8 @@ STAGE PLANS:
                         type: string
                   tag: 1
                   value expressions:
-                        expr: key
-                        type: string
                         expr: value
                         type: string
-                        expr: ds
-                        type: string
-                        expr: hr
-                        type: string
         src 
             Filter Operator
               predicate:
@@ -61,15 +55,13 @@ STAGE PLANS:
                   value expressions:
                         expr: key
                         type: string
-                        expr: value
-                        type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
+            0 {VALUE._col0}
+            1 {VALUE._col1}
           Select Operator
             expressions:
                   expr: _col0
@@ -110,7 +102,7 @@ Input: default/src
 Output: default/dest1
 query: select dest1.* from dest1
 Input: default/dest1
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/285954832/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/500537057/10000
 103	val_103
 103	val_103
 103	val_103
diff --git a/ql/src/test/results/clientpositive/join16.q.out b/ql/src/test/results/clientpositive/join16.q.out
index 5e8a4396c4..ca365ecbcd 100644
--- a/ql/src/test/results/clientpositive/join16.q.out
+++ b/ql/src/test/results/clientpositive/join16.q.out
@@ -45,8 +45,6 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: string
-                            expr: _col1
-                            type: string
         tab 
             Filter Operator
               predicate:
@@ -66,8 +64,6 @@ STAGE PLANS:
                       type: string
                 tag: 1
                 value expressions:
-                      expr: key
-                      type: string
                       expr: value
                       type: string
       Reduce Operator Tree:
@@ -75,8 +71,8 @@ STAGE PLANS:
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0}
+            1 {VALUE._col1}
           Filter Operator
             predicate:
                 expr: (UDFToDouble(_col3) < UDFToDouble(200))
diff --git a/ql/src/test/results/clientpositive/join19.q.out b/ql/src/test/results/clientpositive/join19.q.out
index 3dfcd2b0bc..36444ccbd6 100644
--- a/ql/src/test/results/clientpositive/join19.q.out
+++ b/ql/src/test/results/clientpositive/join19.q.out
@@ -93,8 +93,6 @@ STAGE PLANS:
                           type: string
                     tag: 1
                     value expressions:
-                          expr: _col0
-                          type: string
                           expr: _col1
                           type: string
         t33:t3 
@@ -124,8 +122,6 @@ STAGE PLANS:
                     value expressions:
                           expr: _col0
                           type: string
-                          expr: _col1
-                          type: string
         t11:t1 
             Filter Operator
               predicate:
@@ -158,8 +154,8 @@ STAGE PLANS:
                Inner Join 0 to 2
           condition expressions:
             0 {VALUE._col0}
-            1 {VALUE._col0} {VALUE._col1}
-            2 {VALUE._col0} {VALUE._col1}
+            1 {VALUE._col1}
+            2 {VALUE._col0}
           File Output Operator
             compressed: false
             GlobalTableId: 0
@@ -184,12 +180,8 @@ STAGE PLANS:
               value expressions:
                     expr: _col3
                     type: string
-                    expr: _col4
-                    type: string
                     expr: _col0
                     type: string
-                    expr: _col1
-                    type: string
                     expr: _col2
                     type: string
         t55:t5 
@@ -217,8 +209,6 @@ STAGE PLANS:
                           type: string
                     tag: 2
                     value expressions:
-                          expr: _col0
-                          type: string
                           expr: _col1
                           type: string
         t44:t4 
@@ -243,18 +233,15 @@ STAGE PLANS:
                           expr: _col0
                           type: string
                     tag: 1
-                    value expressions:
-                          expr: _col0
-                          type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
                Inner Join 1 to 2
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3} {VALUE._col4}
-            1 {VALUE._col0}
-            2 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0} {VALUE._col2} {VALUE._col4}
+            1 
+            2 {VALUE._col1}
           File Output Operator
             compressed: false
             GlobalTableId: 0
@@ -291,8 +278,6 @@ STAGE PLANS:
                           type: string
                     tag: 1
                     value expressions:
-                          expr: _col0
-                          type: string
                           expr: _col1
                           type: string
         $INTNAME 
@@ -308,18 +293,10 @@ STAGE PLANS:
               value expressions:
                     expr: _col0
                     type: string
-                    expr: _col1
-                    type: string
-                    expr: _col5
-                    type: string
                     expr: _col2
                     type: string
-                    expr: _col3
-                    type: string
                     expr: _col4
                     type: string
-                    expr: _col6
-                    type: string
                     expr: _col7
                     type: string
       Reduce Operator Tree:
@@ -327,8 +304,8 @@ STAGE PLANS:
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3} {VALUE._col4} {VALUE._col5} {VALUE._col6} {VALUE._col7}
-            1 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0} {VALUE._col3} {VALUE._col5} {VALUE._col7}
+            1 {VALUE._col1}
           Select Operator
             expressions:
                   expr: _col3
diff --git a/ql/src/test/results/clientpositive/join2.q.out b/ql/src/test/results/clientpositive/join2.q.out
index 8ded7dd0e5..4f268cb69a 100644
--- a/ql/src/test/results/clientpositive/join2.q.out
+++ b/ql/src/test/results/clientpositive/join2.q.out
@@ -27,8 +27,6 @@ STAGE PLANS:
               value expressions:
                     expr: key
                     type: string
-                    expr: value
-                    type: string
         src1 
             Reduce Output Operator
               key expressions:
@@ -42,15 +40,13 @@ STAGE PLANS:
               value expressions:
                     expr: key
                     type: string
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0}
+            1 {VALUE._col0}
           File Output Operator
             compressed: false
             GlobalTableId: 0
@@ -73,14 +69,8 @@ STAGE PLANS:
                     type: double
               tag: 0
               value expressions:
-                    expr: _col2
-                    type: string
-                    expr: _col3
-                    type: string
                     expr: _col0
                     type: string
-                    expr: _col1
-                    type: string
         src3 
             Reduce Output Operator
               key expressions:
@@ -92,8 +82,6 @@ STAGE PLANS:
                     type: double
               tag: 1
               value expressions:
-                    expr: key
-                    type: string
                     expr: value
                     type: string
       Reduce Operator Tree:
@@ -101,8 +89,8 @@ STAGE PLANS:
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
-            1 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col2}
+            1 {VALUE._col1}
           Select Operator
             expressions:
                   expr: _col2
@@ -141,7 +129,7 @@ Input: default/src
 Output: default/dest_j2
 query: SELECT dest_j2.* FROM dest_j2
 Input: default/dest_j2
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/1218468210/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/47427829/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join22.q.out b/ql/src/test/results/clientpositive/join22.q.out
index 7fe80dc7cd..082536b6f8 100644
--- a/ql/src/test/results/clientpositive/join22.q.out
+++ b/ql/src/test/results/clientpositive/join22.q.out
@@ -22,11 +22,6 @@ STAGE PLANS:
                     expr: key
                     type: string
               tag: 1
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
         src5:src3:src1 
             Reduce Output Operator
               key expressions:
@@ -48,7 +43,7 @@ STAGE PLANS:
                Inner Join 0 to 1
           condition expressions:
             0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            1 
           Select Operator
             expressions:
                   expr: _col0
@@ -77,8 +72,6 @@ STAGE PLANS:
                     type: string
               tag: 1
               value expressions:
-                    expr: _col2
-                    type: string
                     expr: _col3
                     type: string
         src5:src4 
@@ -91,18 +84,13 @@ STAGE PLANS:
                     expr: key
                     type: string
               tag: 0
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
+            0 
+            1 {VALUE._col3}
           Select Operator
             expressions:
                   expr: _col5
diff --git a/ql/src/test/results/clientpositive/join25.q.out b/ql/src/test/results/clientpositive/join25.q.out
index f14192f81b..98c9cb7bac 100644
--- a/ql/src/test/results/clientpositive/join25.q.out
+++ b/ql/src/test/results/clientpositive/join25.q.out
@@ -23,7 +23,7 @@ STAGE PLANS:
                    Inner Join 0 to 1
               condition expressions:
                 0 {key} {value}
-                1 {key} {value}
+                1 {value}
               keys:
                 0 
                 1 
@@ -47,7 +47,7 @@ STAGE PLANS:
                        Inner Join 0 to 1
                   condition expressions:
                     0 {key} {value}
-                    1 {key} {value}
+                    1 {value}
                   keys:
                     0 
                     1 
@@ -62,8 +62,15 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/njain/hive4/hive4/build/ql/tmp/379733965/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1076139727/10002 
           Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: string
+                  expr: _col3
+                  type: string
             Select Operator
               expressions:
                     expr: _col0
@@ -95,10 +102,10 @@ STAGE PLANS:
           Move Operator
             files:
                 hdfs directory: true
-                destination: file:/data/users/njain/hive4/hive4/build/ql/tmp/757142377/10000
+                destination: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/554961035/10000
           Map Reduce
             Alias -> Map Operator Tree:
-              file:/data/users/njain/hive4/hive4/build/ql/tmp/379733965/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1076139727/10003 
                   Reduce Output Operator
                     sort order: 
                     Map-reduce partition columns:
@@ -142,7 +149,7 @@ Input: default/src1
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key
 Input: default/dest_j1
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/1000064941/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/2016361816/10000
 66	val_66	val_66
 98	val_98	val_98
 98	val_98	val_98
diff --git a/ql/src/test/results/clientpositive/join26.q.out b/ql/src/test/results/clientpositive/join26.q.out
index 26236af8ae..b8b8a96df0 100644
--- a/ql/src/test/results/clientpositive/join26.q.out
+++ b/ql/src/test/results/clientpositive/join26.q.out
@@ -35,9 +35,9 @@ STAGE PLANS:
                          Inner Join 0 to 1
                          Inner Join 0 to 2
                     condition expressions:
-                      0 {key} {value}
-                      1 {key} {value}
-                      2 {key} {value} {ds} {hr}
+                      0 {key}
+                      1 {value}
+                      2 {value}
                     keys:
                       0 
                       1 
@@ -46,13 +46,13 @@ STAGE PLANS:
                     File Output Operator
                       compressed: false
                       GlobalTableId: 0
-                      directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1173758888/10002
+                      directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1938408572/10002
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                           properties:
-                            columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
-                            columns.types string,string,string,string,string,string,string,string
+                            columns _col0,_col3,_col5
+                            columns.types string,string,string
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
@@ -69,9 +69,9 @@ STAGE PLANS:
                        Inner Join 0 to 1
                        Inner Join 0 to 2
                   condition expressions:
-                    0 {key} {value}
-                    1 {key} {value}
-                    2 {key} {value} {ds} {hr}
+                    0 {key}
+                    1 {value}
+                    2 {value}
                   keys:
                     0 
                     1 
@@ -80,22 +80,22 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1173758888/10002
+                    directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1938408572/10002
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                         properties:
-                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
-                          columns.types string,string,string,string,string,string,string,string
+                          columns _col0,_col3,_col5
+                          columns.types string,string,string
             x 
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
                        Inner Join 0 to 2
                   condition expressions:
-                    0 {key} {value}
-                    1 {key} {value}
-                    2 {key} {value} {ds} {hr}
+                    0 {key}
+                    1 {value}
+                    2 {value}
                   keys:
                     0 
                     1 
@@ -104,18 +104,18 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1173758888/10002
+                    directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1938408572/10002
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                         properties:
-                          columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
-                          columns.types string,string,string,string,string,string,string,string
+                          columns _col0,_col3,_col5
+                          columns.types string,string,string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             partition values:
               ds 2008-04-08
@@ -134,15 +134,22 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1173758888/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1938408572/10002 
           Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col3
+                  type: string
+                  expr: _col5
+                  type: string
             Select Operator
               expressions:
                     expr: _col0
@@ -154,7 +161,7 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
-                directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1173758888/10003
+                directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1938408572/10003
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -168,21 +175,21 @@ STAGE PLANS:
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       file.inputformat org.apache.hadoop.mapred.TextInputFormat
                       file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                      location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest_j1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1173758888/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1938408572/10002 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1173758888/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1938408572/10002 
           Partition
           
               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
               properties:
-                columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
-                columns.types string,string,string,string,string,string,string,string
+                columns _col0,_col3,_col5
+                columns.types string,string,string
 
   Stage: Stage-5
     Conditional Operator
@@ -190,11 +197,11 @@ STAGE PLANS:
           Move Operator
             files:
                 hdfs directory: true
-                source: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1173758888/10003
-                destination: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1120006262/10000
+                source: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1938408572/10003
+                destination: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/934580575/10000
           Map Reduce
             Alias -> Map Operator Tree:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1173758888/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1938408572/10003 
                   Reduce Output Operator
                     sort order: 
                     Map-reduce partition columns:
@@ -210,9 +217,9 @@ STAGE PLANS:
                           type: string
             Needs Tagging: false
             Path -> Alias:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1173758888/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1938408572/10003 
             Path -> Partition:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1173758888/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1938408572/10003 
                 Partition
                 
                     input format: org.apache.hadoop.mapred.TextInputFormat
@@ -227,7 +234,7 @@ STAGE PLANS:
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       file.inputformat org.apache.hadoop.mapred.TextInputFormat
                       file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                      location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest_j1
             Reduce Operator Tree:
@@ -235,7 +242,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1120006262/10000
+                  directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/934580575/10000
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -249,7 +256,7 @@ STAGE PLANS:
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                        location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest_j1
 
@@ -257,7 +264,7 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1120006262/10000
+          source: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/934580575/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -271,10 +278,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1120006262/10001
+          tmp directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/934580575/10001
 
 
 query: INSERT OVERWRITE TABLE dest_j1
@@ -287,7 +294,7 @@ Input: default/src1
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key
 Input: default/dest_j1
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1885363957/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1666620544/10000
 128	val_128	val_128
 128	val_128	val_128
 128	val_128	val_128
diff --git a/ql/src/test/results/clientpositive/join27.q.out b/ql/src/test/results/clientpositive/join27.q.out
index a8a9163b3e..7e2f6b6586 100644
--- a/ql/src/test/results/clientpositive/join27.q.out
+++ b/ql/src/test/results/clientpositive/join27.q.out
@@ -23,7 +23,7 @@ STAGE PLANS:
                    Inner Join 0 to 1
               condition expressions:
                 0 {key} {value}
-                1 {key} {value}
+                1 {value}
               keys:
                 0 
                 1 
@@ -47,7 +47,7 @@ STAGE PLANS:
                        Inner Join 0 to 1
                   condition expressions:
                     0 {key} {value}
-                    1 {key} {value}
+                    1 {value}
                   keys:
                     0 
                     1 
@@ -62,8 +62,15 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/njain/hive4/hive4/build/ql/tmp/2020334716/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1103571809/10002 
           Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: string
+                  expr: _col3
+                  type: string
             Select Operator
               expressions:
                     expr: _col0
@@ -95,10 +102,10 @@ STAGE PLANS:
           Move Operator
             files:
                 hdfs directory: true
-                destination: file:/data/users/njain/hive4/hive4/build/ql/tmp/1935107021/10000
+                destination: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1381867998/10000
           Map Reduce
             Alias -> Map Operator Tree:
-              file:/data/users/njain/hive4/hive4/build/ql/tmp/2020334716/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1103571809/10003 
                   Reduce Output Operator
                     sort order: 
                     Map-reduce partition columns:
@@ -142,7 +149,7 @@ Input: default/src1
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key, x.value
 Input: default/dest_j1
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/744630343/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1375214861/10000
 NULL	val_165	val_165
 NULL	val_165	val_165
 NULL	val_193	val_193
diff --git a/ql/src/test/results/clientpositive/join28.q.out b/ql/src/test/results/clientpositive/join28.q.out
index 64d6b26ce1..54cc34e58c 100644
--- a/ql/src/test/results/clientpositive/join28.q.out
+++ b/ql/src/test/results/clientpositive/join28.q.out
@@ -26,8 +26,8 @@ STAGE PLANS:
               condition map:
                    Inner Join 0 to 1
               condition expressions:
-                0 {key} {value}
-                1 {key} {value}
+                0 {key}
+                1 
               keys:
                 0 
                 1 
@@ -50,8 +50,8 @@ STAGE PLANS:
                   condition map:
                        Inner Join 0 to 1
                   condition expressions:
-                    0 {key} {value}
-                    1 {key} {value}
+                    0 {key}
+                    1 
                   keys:
                     0 
                     1 
@@ -66,8 +66,11 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1815676421/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/2012162302/10002 
           Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
             Select Operator
               expressions:
                     expr: _col0
@@ -77,7 +80,7 @@ STAGE PLANS:
                      Inner Join 0 to 1
                 condition expressions:
                   0 {_col0}
-                  1 {key} {value} {ds} {hr}
+                  1 {value}
                 keys:
                   0 
                   1 
@@ -113,7 +116,7 @@ STAGE PLANS:
                              Inner Join 0 to 1
                         condition expressions:
                           0 {_col0}
-                          1 {key} {value} {ds} {hr}
+                          1 {value}
                         keys:
                           0 
                           1 
@@ -128,8 +131,13 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1815676421/10003 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/2012162302/10003 
           Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col5
+                  type: string
             Select Operator
               expressions:
                     expr: _col0
@@ -151,10 +159,10 @@ STAGE PLANS:
           Move Operator
             files:
                 hdfs directory: true
-                destination: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1094740336/10000
+                destination: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/16485935/10000
           Map Reduce
             Alias -> Map Operator Tree:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1815676421/10004 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/2012162302/10004 
                   Reduce Output Operator
                     sort order: 
                     Map-reduce partition columns:
@@ -200,7 +208,7 @@ Input: default/srcpart/ds=2008-04-08/hr=11
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key
 Input: default/dest_j1
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1009140217/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/634729814/10000
 128	val_128
 128	val_128
 128	val_128
diff --git a/ql/src/test/results/clientpositive/join29.q.out b/ql/src/test/results/clientpositive/join29.q.out
index db2657556b..48c9cb040d 100644
--- a/ql/src/test/results/clientpositive/join29.q.out
+++ b/ql/src/test/results/clientpositive/join29.q.out
@@ -73,13 +73,13 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/njain/hive4/hive4/build/ql/tmp/1531940851/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1590163898/10002 
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
               condition expressions:
                 0 {_col0} {_col1}
-                1 {_col0} {_col1}
+                1 {_col1}
               keys:
                 0 
                 1 
@@ -93,17 +93,17 @@ STAGE PLANS:
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
-            file:/data/users/njain/hive4/hive4/build/ql/tmp/1531940851/10005 
+            file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1590163898/10005 
               Fetch Operator
                 limit: -1
           Alias -> Map Local Operator Tree:
-            file:/data/users/njain/hive4/hive4/build/ql/tmp/1531940851/10005 
+            file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1590163898/10005 
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
                   condition expressions:
                     0 {_col0} {_col1}
-                    1 {_col0} {_col1}
+                    1 {_col1}
                   keys:
                     0 
                     1 
@@ -118,8 +118,15 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/njain/hive4/hive4/build/ql/tmp/1531940851/10003 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1590163898/10003 
           Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: bigint
+                  expr: _col3
+                  type: bigint
             Select Operator
               expressions:
                     expr: _col0
@@ -151,10 +158,10 @@ STAGE PLANS:
           Move Operator
             files:
                 hdfs directory: true
-                destination: file:/data/users/njain/hive4/hive4/build/ql/tmp/512693083/10000
+                destination: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/959537275/10000
           Map Reduce
             Alias -> Map Operator Tree:
-              file:/data/users/njain/hive4/hive4/build/ql/tmp/1531940851/10004 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1590163898/10004 
                   Reduce Output Operator
                     sort order: 
                     Map-reduce partition columns:
@@ -248,7 +255,7 @@ Input: default/src1
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key
 Input: default/dest_j1
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/1489048746/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/948921556/10000
 128	1	3
 146	1	2
 150	1	1
diff --git a/ql/src/test/results/clientpositive/join3.q.out b/ql/src/test/results/clientpositive/join3.q.out
index 22c26d0b7d..6d2b148eb8 100644
--- a/ql/src/test/results/clientpositive/join3.q.out
+++ b/ql/src/test/results/clientpositive/join3.q.out
@@ -23,11 +23,6 @@ STAGE PLANS:
                     expr: key
                     type: string
               tag: 1
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
         src3 
             Reduce Output Operator
               key expressions:
@@ -39,8 +34,6 @@ STAGE PLANS:
                     type: string
               tag: 2
               value expressions:
-                    expr: key
-                    type: string
                     expr: value
                     type: string
         src1 
@@ -56,17 +49,15 @@ STAGE PLANS:
               value expressions:
                     expr: key
                     type: string
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
                Inner Join 0 to 2
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
-            2 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0}
+            1 
+            2 {VALUE._col1}
           Select Operator
             expressions:
                   expr: _col0
@@ -105,7 +96,7 @@ Input: default/src
 Output: default/dest1
 query: SELECT dest1.* FROM dest1
 Input: default/dest1
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/447413355/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1106403218/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join30.q.out b/ql/src/test/results/clientpositive/join30.q.out
index e3f82ebaf0..8980016744 100644
--- a/ql/src/test/results/clientpositive/join30.q.out
+++ b/ql/src/test/results/clientpositive/join30.q.out
@@ -20,8 +20,8 @@ STAGE PLANS:
               condition map:
                    Inner Join 0 to 1
               condition expressions:
-                0 {key} {value}
-                1 {key} {value}
+                0 {key}
+                1 
               keys:
                 0 
                 1 
@@ -44,8 +44,8 @@ STAGE PLANS:
                   condition map:
                        Inner Join 0 to 1
                   condition expressions:
-                    0 {key} {value}
-                    1 {key} {value}
+                    0 {key}
+                    1 
                   keys:
                     0 
                     1 
@@ -60,8 +60,11 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/njain/hive4/hive4/build/ql/tmp/1868281911/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1483061275/10002 
           Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
             Select Operator
               expressions:
                     expr: _col0
@@ -132,7 +135,7 @@ Input: default/src1
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key
 Input: default/dest_j1
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/1393129158/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1361140895/10000
 66	1
 98	2
 128	3
diff --git a/ql/src/test/results/clientpositive/join31.q.out b/ql/src/test/results/clientpositive/join31.q.out
index 1d4d115aa7..1567ce836b 100644
--- a/ql/src/test/results/clientpositive/join31.q.out
+++ b/ql/src/test/results/clientpositive/join31.q.out
@@ -70,13 +70,13 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/njain/hive4/hive4/build/ql/tmp/1913053399/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1203288551/10002 
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
               condition expressions:
                 0 {_col0}
-                1 {_col0}
+                1 
               keys:
                 0 
                 1 
@@ -90,17 +90,17 @@ STAGE PLANS:
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
-            file:/data/users/njain/hive4/hive4/build/ql/tmp/1913053399/10004 
+            file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1203288551/10004 
               Fetch Operator
                 limit: -1
           Alias -> Map Local Operator Tree:
-            file:/data/users/njain/hive4/hive4/build/ql/tmp/1913053399/10004 
+            file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1203288551/10004 
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
                   condition expressions:
                     0 {_col0}
-                    1 {_col0}
+                    1 
                   keys:
                     0 
                     1 
@@ -115,8 +115,11 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/njain/hive4/hive4/build/ql/tmp/1913053399/10003 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1203288551/10003 
           Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
             Select Operator
               expressions:
                     expr: _col0
@@ -237,7 +240,7 @@ Input: default/src1
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key
 Input: default/dest_j1
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/1094372260/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1617117942/10000
 128	1
 146	1
 150	1
diff --git a/ql/src/test/results/clientpositive/join32.q.out b/ql/src/test/results/clientpositive/join32.q.out
index 29355ca09d..0d08c446a8 100644
--- a/ql/src/test/results/clientpositive/join32.q.out
+++ b/ql/src/test/results/clientpositive/join32.q.out
@@ -24,7 +24,7 @@ STAGE PLANS:
                    Inner Join 0 to 1
               condition expressions:
                 0 {key} {value}
-                1 {key} {value}
+                1 {value}
               keys:
                 0 
                 1 
@@ -32,13 +32,13 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10004
+                directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10004
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                     properties:
-                      columns _col0,_col1,_col2,_col3
-                      columns.types string,string,string,string
+                      columns _col0,_col1,_col3
+                      columns.types string,string,string
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
@@ -52,7 +52,7 @@ STAGE PLANS:
                        Inner Join 0 to 1
                   condition expressions:
                     0 {key} {value}
-                    1 {key} {value}
+                    1 {value}
                   keys:
                     0 
                     1 
@@ -60,18 +60,18 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10004
+                    directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10004
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                         properties:
-                          columns _col0,_col1,_col2,_col3
-                          columns.types string,string,string,string
+                          columns _col0,_col1,_col3
+                          columns.types string,string,string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -86,21 +86,28 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
 
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10004 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10004 
           Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: string
+                  expr: _col3
+                  type: string
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
               condition expressions:
-                0 {_col2} {_col3} {_col0} {_col1}
-                1 {key} {value} {ds} {hr}
+                0 {_col3} {_col0}
+                1 {value}
               keys:
                 0 
                 1 
@@ -108,13 +115,13 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10002
+                directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10002
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                     properties:
-                      columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
-                      columns.types string,string,string,string,string,string,string,string
+                      columns _col1,_col2,_col5
+                      columns.types string,string,string
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
@@ -139,8 +146,8 @@ STAGE PLANS:
                         condition map:
                              Inner Join 0 to 1
                         condition expressions:
-                          0 {_col2} {_col3} {_col0} {_col1}
-                          1 {key} {value} {ds} {hr}
+                          0 {_col3} {_col0}
+                          1 {value}
                         keys:
                           0 
                           1 
@@ -148,31 +155,38 @@ STAGE PLANS:
                         File Output Operator
                           compressed: false
                           GlobalTableId: 0
-                          directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10002
+                          directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10002
                           table:
                               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                               properties:
-                                columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
-                                columns.types string,string,string,string,string,string,string,string
+                                columns _col1,_col2,_col5
+                                columns.types string,string,string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10004 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10004 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10004 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10004 
           Partition
           
               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
               properties:
-                columns _col0,_col1,_col2,_col3
-                columns.types string,string,string,string
+                columns _col0,_col1,_col3
+                columns.types string,string,string
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10002 
           Select Operator
+            expressions:
+                  expr: _col1
+                  type: string
+                  expr: _col2
+                  type: string
+                  expr: _col5
+                  type: string
             Select Operator
               expressions:
                     expr: _col2
@@ -184,7 +198,7 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
-                directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10003
+                directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10003
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -198,21 +212,21 @@ STAGE PLANS:
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       file.inputformat org.apache.hadoop.mapred.TextInputFormat
                       file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                      location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest_j1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10002 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10002 
           Partition
           
               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
               properties:
-                columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
-                columns.types string,string,string,string,string,string,string,string
+                columns _col1,_col2,_col5
+                columns.types string,string,string
 
   Stage: Stage-5
     Conditional Operator
@@ -220,11 +234,11 @@ STAGE PLANS:
           Move Operator
             files:
                 hdfs directory: true
-                source: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10003
-                destination: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/186721190/10000
+                source: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10003
+                destination: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/236043717/10000
           Map Reduce
             Alias -> Map Operator Tree:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10003 
                   Reduce Output Operator
                     sort order: 
                     Map-reduce partition columns:
@@ -240,9 +254,9 @@ STAGE PLANS:
                           type: string
             Needs Tagging: false
             Path -> Alias:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10003 
             Path -> Partition:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1346847963/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1927041156/10003 
                 Partition
                 
                     input format: org.apache.hadoop.mapred.TextInputFormat
@@ -257,7 +271,7 @@ STAGE PLANS:
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       file.inputformat org.apache.hadoop.mapred.TextInputFormat
                       file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                      location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest_j1
             Reduce Operator Tree:
@@ -265,7 +279,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/186721190/10000
+                  directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/236043717/10000
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -279,7 +293,7 @@ STAGE PLANS:
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                        location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest_j1
 
@@ -287,7 +301,7 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/186721190/10000
+          source: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/236043717/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -301,10 +315,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/186721190/10001
+          tmp directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/236043717/10001
 
 
 query: INSERT OVERWRITE TABLE dest_j1
@@ -317,7 +331,7 @@ Input: default/src1
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key
 Input: default/dest_j1
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1483693438/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/38655143/10000
 146	val_146	val_146
 146	val_146	val_146
 146	val_146	val_146
diff --git a/ql/src/test/results/clientpositive/join33.q.out b/ql/src/test/results/clientpositive/join33.q.out
index d1f55c5c62..7806b685a2 100644
--- a/ql/src/test/results/clientpositive/join33.q.out
+++ b/ql/src/test/results/clientpositive/join33.q.out
@@ -22,7 +22,7 @@ STAGE PLANS:
                    Inner Join 0 to 1
               condition expressions:
                 0 {key} {value}
-                1 {key} {value}
+                1 {value}
               keys:
                 0 
                 1 
@@ -30,13 +30,13 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1543545927/10002
+                directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1449467605/10002
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                     properties:
-                      columns _col0,_col1,_col2,_col3
-                      columns.types string,string,string,string
+                      columns _col0,_col1,_col3
+                      columns.types string,string,string
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
@@ -50,7 +50,7 @@ STAGE PLANS:
                        Inner Join 0 to 1
                   condition expressions:
                     0 {key} {value}
-                    1 {key} {value}
+                    1 {value}
                   keys:
                     0 
                     1 
@@ -58,18 +58,18 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1543545927/10002
+                    directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1449467605/10002
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                         properties:
-                          columns _col0,_col1,_col2,_col3
-                          columns.types string,string,string,string
+                          columns _col0,_col1,_col3
+                          columns.types string,string,string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -84,7 +84,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
 
@@ -114,16 +114,17 @@ STAGE PLANS:
                           type: string
                     tag: 1
                     value expressions:
-                          expr: key
-                          type: string
                           expr: value
                           type: string
-                          expr: ds
-                          type: string
-                          expr: hr
-                          type: string
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1543545927/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1449467605/10002 
           Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: string
+                  expr: _col3
+                  type: string
             Reduce Output Operator
               key expressions:
                     expr: _col1
@@ -134,20 +135,16 @@ STAGE PLANS:
                     type: string
               tag: 0
               value expressions:
-                    expr: _col2
-                    type: string
                     expr: _col3
                     type: string
                     expr: _col0
                     type: string
-                    expr: _col1
-                    type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1543545927/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1449467605/10002 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             partition values:
               ds 2008-04-08
@@ -166,24 +163,24 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1543545927/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1449467605/10002 
           Partition
           
               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
               properties:
-                columns _col0,_col1,_col2,_col3
-                columns.types string,string,string,string
+                columns _col0,_col1,_col3
+                columns.types string,string,string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
-            1 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
+            0 {VALUE._col1} {VALUE._col2}
+            1 {VALUE._col1}
           Select Operator
             expressions:
                   expr: _col2
@@ -195,7 +192,7 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1051890475/10000
+              directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/500697673/10000
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -209,7 +206,7 @@ STAGE PLANS:
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                    location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest_j1
 
@@ -217,7 +214,7 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1051890475/10000
+          source: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/500697673/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -231,10 +228,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1051890475/10001
+          tmp directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/500697673/10001
 
 
 query: INSERT OVERWRITE TABLE dest_j1
@@ -247,7 +244,7 @@ Input: default/src1
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key
 Input: default/dest_j1
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/306446495/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1659514145/10000
 146	val_146	val_146
 146	val_146	val_146
 146	val_146	val_146
diff --git a/ql/src/test/results/clientpositive/join34.q.out b/ql/src/test/results/clientpositive/join34.q.out
index 3fa2937cb4..422cfeed5e 100644
--- a/ql/src/test/results/clientpositive/join34.q.out
+++ b/ql/src/test/results/clientpositive/join34.q.out
@@ -42,7 +42,7 @@ STAGE PLANS:
                       condition map:
                            Inner Join 0 to 1
                       condition expressions:
-                        0 {_col0} {_col1}
+                        0 {_col1}
                         1 {key} {value}
                       keys:
                         0 
@@ -51,13 +51,13 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 0
-                        directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1917925981/10002
+                        directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798138861/10002
                         table:
                             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                             properties:
-                              columns _col0,_col1,_col2,_col3
-                              columns.types string,string,string,string
+                              columns _col1,_col2,_col3
+                              columns.types string,string,string
         null-subquery2:subq1-subquery2:x1 
             Filter Operator
               predicate:
@@ -78,7 +78,7 @@ STAGE PLANS:
                       condition map:
                            Inner Join 0 to 1
                       condition expressions:
-                        0 {_col0} {_col1}
+                        0 {_col1}
                         1 {key} {value}
                       keys:
                         0 
@@ -87,13 +87,13 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 0
-                        directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1917925981/10002
+                        directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798138861/10002
                         table:
                             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                             properties:
-                              columns _col0,_col1,_col2,_col3
-                              columns.types string,string,string,string
+                              columns _col1,_col2,_col3
+                              columns.types string,string,string
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
@@ -106,7 +106,7 @@ STAGE PLANS:
                   condition map:
                        Inner Join 0 to 1
                   condition expressions:
-                    0 {_col0} {_col1}
+                    0 {_col1}
                     1 {key} {value}
                   keys:
                     0 
@@ -115,18 +115,18 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1917925981/10002
+                    directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798138861/10002
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                         properties:
-                          columns _col0,_col1,_col2,_col3
-                          columns.types string,string,string,string
+                          columns _col1,_col2,_col3
+                          columns.types string,string,string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -141,15 +141,22 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1917925981/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798138861/10002 
           Select Operator
+            expressions:
+                  expr: _col1
+                  type: string
+                  expr: _col2
+                  type: string
+                  expr: _col3
+                  type: string
             Select Operator
               expressions:
                     expr: _col2
@@ -161,7 +168,7 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
-                directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1917925981/10003
+                directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798138861/10003
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -175,21 +182,21 @@ STAGE PLANS:
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       file.inputformat org.apache.hadoop.mapred.TextInputFormat
                       file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                      location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest_j1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1917925981/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798138861/10002 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1917925981/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798138861/10002 
           Partition
           
               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
               properties:
-                columns _col0,_col1,_col2,_col3
-                columns.types string,string,string,string
+                columns _col1,_col2,_col3
+                columns.types string,string,string
 
   Stage: Stage-5
     Conditional Operator
@@ -197,11 +204,11 @@ STAGE PLANS:
           Move Operator
             files:
                 hdfs directory: true
-                source: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1917925981/10003
-                destination: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/3484851/10000
+                source: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798138861/10003
+                destination: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1395275171/10000
           Map Reduce
             Alias -> Map Operator Tree:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1917925981/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798138861/10003 
                   Reduce Output Operator
                     sort order: 
                     Map-reduce partition columns:
@@ -217,9 +224,9 @@ STAGE PLANS:
                           type: string
             Needs Tagging: false
             Path -> Alias:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1917925981/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798138861/10003 
             Path -> Partition:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1917925981/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798138861/10003 
                 Partition
                 
                     input format: org.apache.hadoop.mapred.TextInputFormat
@@ -234,7 +241,7 @@ STAGE PLANS:
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       file.inputformat org.apache.hadoop.mapred.TextInputFormat
                       file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                      location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest_j1
             Reduce Operator Tree:
@@ -242,7 +249,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/3484851/10000
+                  directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1395275171/10000
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -256,7 +263,7 @@ STAGE PLANS:
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                        location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest_j1
 
@@ -264,7 +271,7 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/3484851/10000
+          source: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1395275171/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -278,10 +285,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/3484851/10001
+          tmp directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1395275171/10001
 
 
 query: INSERT OVERWRITE TABLE dest_j1
@@ -297,7 +304,7 @@ Input: default/src1
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key
 Input: default/dest_j1
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/374627927/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/513374112/10000
 128		val_128
 128		val_128
 128		val_128
diff --git a/ql/src/test/results/clientpositive/join35.q.out b/ql/src/test/results/clientpositive/join35.q.out
index 3b132adbd8..30fb951fbe 100644
--- a/ql/src/test/results/clientpositive/join35.q.out
+++ b/ql/src/test/results/clientpositive/join35.q.out
@@ -62,9 +62,9 @@ STAGE PLANS:
                             type: bigint
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -79,7 +79,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
       Reduce Operator Tree:
@@ -99,7 +99,7 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10002
+              directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10002
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -112,13 +112,13 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10002 
           Union
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
               condition expressions:
-                0 {_col0} {_col1}
+                0 {_col1}
                 1 {key} {value}
               keys:
                 0 
@@ -127,20 +127,20 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10003
+                directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10003
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                     properties:
-                      columns _col0,_col1,_col2,_col3
-                      columns.types string,bigint,string,string
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10005 
+                      columns _col1,_col2,_col3
+                      columns.types bigint,string,string
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10005 
           Union
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
               condition expressions:
-                0 {_col0} {_col1}
+                0 {_col1}
                 1 {key} {value}
               keys:
                 0 
@@ -149,13 +149,13 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10003
+                directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10003
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                     properties:
-                      columns _col0,_col1,_col2,_col3
-                      columns.types string,bigint,string,string
+                      columns _col1,_col2,_col3
+                      columns.types bigint,string,string
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
@@ -168,7 +168,7 @@ STAGE PLANS:
                   condition map:
                        Inner Join 0 to 1
                   condition expressions:
-                    0 {_col0} {_col1}
+                    0 {_col1}
                     1 {key} {value}
                   keys:
                     0 
@@ -177,19 +177,19 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10003
+                    directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10003
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                         properties:
-                          columns _col0,_col1,_col2,_col3
-                          columns.types string,bigint,string,string
+                          columns _col1,_col2,_col3
+                          columns.types bigint,string,string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10002 
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10005 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10005 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10002 
           Partition
           
               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -199,7 +199,7 @@ STAGE PLANS:
                 serialization.ddl struct binary_table { string _col0, i64 _col1}
                 serialization.format com.facebook.thrift.protocol.TBinaryProtocol
               name: binary_table
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10005 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10005 
           Partition
           
               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -213,8 +213,15 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10003 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10003 
           Select Operator
+            expressions:
+                  expr: _col1
+                  type: bigint
+                  expr: _col2
+                  type: string
+                  expr: _col3
+                  type: string
             Select Operator
               expressions:
                     expr: _col2
@@ -234,7 +241,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10004
+                  directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10004
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -248,21 +255,21 @@ STAGE PLANS:
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                        location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest_j1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10003 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10003 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10003 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10003 
           Partition
           
               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
               properties:
-                columns _col0,_col1,_col2,_col3
-                columns.types string,bigint,string,string
+                columns _col1,_col2,_col3
+                columns.types bigint,string,string
 
   Stage: Stage-6
     Conditional Operator
@@ -270,11 +277,11 @@ STAGE PLANS:
           Move Operator
             files:
                 hdfs directory: true
-                source: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10004
-                destination: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/100379931/10000
+                source: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10004
+                destination: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/221309053/10000
           Map Reduce
             Alias -> Map Operator Tree:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10004 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10004 
                   Reduce Output Operator
                     sort order: 
                     Map-reduce partition columns:
@@ -290,9 +297,9 @@ STAGE PLANS:
                           type: int
             Needs Tagging: false
             Path -> Alias:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10004 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10004 
             Path -> Partition:
-              file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10004 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10004 
                 Partition
                 
                     input format: org.apache.hadoop.mapred.TextInputFormat
@@ -307,7 +314,7 @@ STAGE PLANS:
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       file.inputformat org.apache.hadoop.mapred.TextInputFormat
                       file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                      location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest_j1
             Reduce Operator Tree:
@@ -315,7 +322,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/100379931/10000
+                  directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/221309053/10000
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -329,7 +336,7 @@ STAGE PLANS:
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                        location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest_j1
 
@@ -337,7 +344,7 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/100379931/10000
+          source: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/221309053/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -351,10 +358,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest_j1
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest_j1
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/100379931/10001
+          tmp directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/221309053/10001
 
   Stage: Stage-7
     Map Reduce
@@ -393,9 +400,9 @@ STAGE PLANS:
                             type: bigint
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -410,7 +417,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
       Reduce Operator Tree:
@@ -430,7 +437,7 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1491787652/10005
+              directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1960311627/10005
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -454,7 +461,7 @@ Input: default/src1
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key
 Input: default/dest_j1
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/2035491366/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1484717471/10000
 128		3
 146	val_146	2
 150	val_150	1
diff --git a/ql/src/test/results/clientpositive/join36.q.out b/ql/src/test/results/clientpositive/join36.q.out
index 798da357ec..99fda52b4c 100644
--- a/ql/src/test/results/clientpositive/join36.q.out
+++ b/ql/src/test/results/clientpositive/join36.q.out
@@ -35,7 +35,7 @@ STAGE PLANS:
                    Inner Join 0 to 1
               condition expressions:
                 0 {key} {cnt}
-                1 {key} {cnt}
+                1 {cnt}
               keys:
                 0 
                 1 
@@ -59,7 +59,7 @@ STAGE PLANS:
                        Inner Join 0 to 1
                   condition expressions:
                     0 {key} {cnt}
-                    1 {key} {cnt}
+                    1 {cnt}
                   keys:
                     0 
                     1 
@@ -74,8 +74,15 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/njain/hive4/hive4/build/ql/tmp/1544683463/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1818872230/10002 
           Select Operator
+            expressions:
+                  expr: _col0
+                  type: int
+                  expr: _col1
+                  type: int
+                  expr: _col3
+                  type: int
             Select Operator
               expressions:
                     expr: _col0
@@ -99,10 +106,10 @@ STAGE PLANS:
           Move Operator
             files:
                 hdfs directory: true
-                destination: file:/data/users/njain/hive4/hive4/build/ql/tmp/1680197079/10000
+                destination: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/989321268/10000
           Map Reduce
             Alias -> Map Operator Tree:
-              file:/data/users/njain/hive4/hive4/build/ql/tmp/1544683463/10003 
+              file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1818872230/10003 
                   Reduce Output Operator
                     sort order: 
                     Map-reduce partition columns:
@@ -146,7 +153,7 @@ Input: default/tmp1
 Output: default/dest_j1
 query: select * from dest_j1 x order by x.key
 Input: default/dest_j1
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/1167058397/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/798843783/10000
 0	3	3
 2	1	1
 4	1	1
diff --git a/ql/src/test/results/clientpositive/join9.q.out b/ql/src/test/results/clientpositive/join9.q.out
index 60980b33c7..ac0d87082f 100644
--- a/ql/src/test/results/clientpositive/join9.q.out
+++ b/ql/src/test/results/clientpositive/join9.q.out
@@ -24,8 +24,6 @@ STAGE PLANS:
                     type: string
               tag: 1
               value expressions:
-                    expr: key
-                    type: string
                     expr: value
                     type: string
         src1 
@@ -45,18 +43,16 @@ STAGE PLANS:
                 value expressions:
                       expr: key
                       type: string
-                      expr: value
-                      type: string
                       expr: ds
                       type: string
                       expr: hr
                       type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -71,10 +67,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             partition values:
               ds 2008-04-08
@@ -93,7 +89,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
       Reduce Operator Tree:
@@ -101,8 +97,8 @@ STAGE PLANS:
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
-            1 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0} {VALUE._col2} {VALUE._col3}
+            1 {VALUE._col1}
           Filter Operator
             predicate:
                 expr: ((_col2 = '2008-04-08') and (_col3 = '12'))
@@ -122,7 +118,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1604556353/10000
+                  directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/856054437/10000
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -136,7 +132,7 @@ STAGE PLANS:
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest1
+                        location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest1
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
 
@@ -144,7 +140,7 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1604556353/10000
+          source: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/856054437/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -158,10 +154,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/dest1
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest1
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1604556353/10001
+          tmp directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/856054437/10001
 
 
 query: FROM srcpart src1 JOIN src src2 ON (src1.key = src2.key)
@@ -171,7 +167,7 @@ Input: default/srcpart/ds=2008-04-08/hr=12
 Output: default/dest1
 query: SELECT dest1.* FROM dest1
 Input: default/dest1
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/794663470/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/2105971410/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join_thrift.q.out b/ql/src/test/results/clientpositive/join_thrift.q.out
index d9799c787c..c7774f5077 100644
--- a/ql/src/test/results/clientpositive/join_thrift.q.out
+++ b/ql/src/test/results/clientpositive/join_thrift.q.out
@@ -32,18 +32,8 @@ STAGE PLANS:
                     type: int
               tag: 1
               value expressions:
-                    expr: aint
-                    type: int
-                    expr: astring
-                    type: string
-                    expr: lint
-                    type: array<int>
-                    expr: lstring
-                    type: array<string>
                     expr: lintstring
                     type: array<struct<myint:int,mystring:string,underscore_int:int>>
-                    expr: mstringstring
-                    type: map<string,string>
         s1 
             Reduce Output Operator
               key expressions:
@@ -57,23 +47,13 @@ STAGE PLANS:
               value expressions:
                     expr: aint
                     type: int
-                    expr: astring
-                    type: string
-                    expr: lint
-                    type: array<int>
-                    expr: lstring
-                    type: array<string>
-                    expr: lintstring
-                    type: array<struct<myint:int,mystring:string,underscore_int:int>>
-                    expr: mstringstring
-                    type: map<string,string>
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3} {VALUE._col4} {VALUE._col5}
-            1 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3} {VALUE._col4} {VALUE._col5}
+            0 {VALUE._col0}
+            1 {VALUE._col4}
           Select Operator
             expressions:
                   expr: _col0
@@ -97,7 +77,7 @@ FROM src_thrift s1
 JOIN src_thrift s2
 ON s1.aint = s2.aint
 Input: default/src_thrift
-Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1473150956/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1144800345/10000
 -1952710710	[{"myint":25,"mystring":"125","underscore_int":5}]
 -1461153973	[{"myint":49,"mystring":"343","underscore_int":7}]
 -751827638	[{"myint":4,"mystring":"8","underscore_int":2}]
diff --git a/ql/src/test/results/clientpositive/ppd_clusterby.q.out b/ql/src/test/results/clientpositive/ppd_clusterby.q.out
index eabfcc0545..1d6b7e4d5d 100644
--- a/ql/src/test/results/clientpositive/ppd_clusterby.q.out
+++ b/ql/src/test/results/clientpositive/ppd_clusterby.q.out
@@ -56,7 +56,7 @@ STAGE PLANS:
 
 query: SELECT * FROM SRC x where x.key = 10 CLUSTER BY x.key
 Input: default/src
-Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/241519225/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/673778413/10000
 10	val_10
 query: EXPLAIN 
 SELECT x.key, x.value as v1, y.key  FROM SRC x JOIN SRC y ON (x.key = y.key)  where x.key = 20 CLUSTER BY v1
@@ -85,8 +85,6 @@ STAGE PLANS:
               value expressions:
                     expr: key
                     type: string
-                    expr: value
-                    type: string
         x 
             Filter Operator
               predicate:
@@ -112,7 +110,7 @@ STAGE PLANS:
                Inner Join 0 to 1
           condition expressions:
             0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            1 {VALUE._col0}
           Filter Operator
             predicate:
                 expr: (UDFToDouble(_col0) = UDFToDouble(20))
@@ -136,7 +134,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1825740657/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1323731431/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col1
@@ -169,5 +167,5 @@ STAGE PLANS:
 
 query: SELECT x.key, x.value as v1, y.key  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY v1
 Input: default/src
-Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1443480977/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1056466885/10000
 20	val_20	20
diff --git a/ql/src/test/results/clientpositive/ppd_gby_join.q.out b/ql/src/test/results/clientpositive/ppd_gby_join.q.out
index d7a57ce914..54ea3ca02d 100644
--- a/ql/src/test/results/clientpositive/ppd_gby_join.q.out
+++ b/ql/src/test/results/clientpositive/ppd_gby_join.q.out
@@ -83,7 +83,7 @@ STAGE PLANS:
                Inner Join 0 to 1
           condition expressions:
             0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            1 {VALUE._col0}
           Filter Operator
             predicate:
                 expr: ((((_col0 > '20') and ((_col1 < 'val_50') or (_col0 > '2'))) and ((_col2 > '50') or (_col0 < '50'))) and (_col2 <> '4'))
@@ -110,7 +110,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1901853163/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1497686794/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
diff --git a/ql/src/test/results/clientpositive/ppd_join2.q.out b/ql/src/test/results/clientpositive/ppd_join2.q.out
index 9927269a75..9f665978b7 100644
--- a/ql/src/test/results/clientpositive/ppd_join2.q.out
+++ b/ql/src/test/results/clientpositive/ppd_join2.q.out
@@ -147,15 +147,13 @@ STAGE PLANS:
                     value expressions:
                           expr: _col0
                           type: string
-                          expr: _col1
-                          type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
           condition expressions:
             0 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
-            1 {VALUE._col0} {VALUE._col1}
+            1 {VALUE._col0}
           Filter Operator
             predicate:
                 expr: (((((_col2 <> '311') and ((_col3 <> 'val_50') or (_col2 > '1'))) and ((_col0 <> '10') or (_col2 <> '10'))) and (_col0 <> '14')) and (sqrt(UDFToDouble(_col4)) <> UDFToDouble(13)))
@@ -189,7 +187,7 @@ JOIN
 ON src1.c2 = src3.c6
 WHERE src1.c1 <> '311' and (src1.c2 <> 'val_50' or src1.c1 > '1') and (src2.c3 <> '10' or src1.c1 <> '10') and (src2.c3 <> '14') and (sqrt(src3.c5) <> 13)
 Input: default/src
-Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1480187717/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/976262349/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/ppd_join3.q.out b/ql/src/test/results/clientpositive/ppd_join3.q.out
index d28c9c90d3..a87534419e 100644
--- a/ql/src/test/results/clientpositive/ppd_join3.q.out
+++ b/ql/src/test/results/clientpositive/ppd_join3.q.out
@@ -115,7 +115,7 @@ STAGE PLANS:
           condition expressions:
             0 {VALUE._col0} {VALUE._col1}
             1 {VALUE._col0} {VALUE._col1}
-            2 {VALUE._col0} {VALUE._col1}
+            2 {VALUE._col0}
           Filter Operator
             predicate:
                 expr: (((((_col0 > '0') and ((_col1 <> 'val_500') or (_col0 > '1'))) and ((_col2 > '10') or (_col0 <> '10'))) and (_col2 <> '4')) and (_col4 <> '1'))
@@ -149,7 +149,7 @@ JOIN
 ON src1.c1 = src3.c5
 WHERE src1.c1 > '0' and (src1.c2 <> 'val_500' or src1.c1 > '1') and (src2.c3 > '10' or src1.c1 <> '10') and (src2.c3 <> '4') and (src3.c5 <> '1')
 Input: default/src
-Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1778414382/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1296260582/10000
 100	val_100
 100	val_100
 100	val_100
diff --git a/ql/src/test/results/clientpositive/ppd_multi_insert.q.out b/ql/src/test/results/clientpositive/ppd_multi_insert.q.out
index 7a0f05c63e..903e37938e 100644
--- a/ql/src/test/results/clientpositive/ppd_multi_insert.q.out
+++ b/ql/src/test/results/clientpositive/ppd_multi_insert.q.out
@@ -34,11 +34,6 @@ STAGE PLANS:
                     expr: key
                     type: string
               tag: 1
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
         a 
             Reduce Output Operator
               key expressions:
@@ -60,7 +55,7 @@ STAGE PLANS:
                Inner Join 0 to 1
           condition expressions:
             0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            1 
           Filter Operator
             predicate:
                 expr: (UDFToDouble(_col0) < UDFToDouble(100))
@@ -196,7 +191,7 @@ Output: default/mi3/ds=2008-04-08/hr=12
 Output: ../build/ql/test/data/warehouse/mi4.out
 query: SELECT mi1.* FROM mi1
 Input: default/mi1
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/1767221832/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1556379466/10000
 0	val_0
 0	val_0
 0	val_0
@@ -347,7 +342,7 @@ Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/1767221832/10000
 98	val_98
 query: SELECT mi2.* FROM mi2
 Input: default/mi2
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/255224107/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1335038556/10000
 100	val_100
 100	val_100
 100	val_100
@@ -561,7 +556,7 @@ Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/255224107/10000
 199	val_199
 query: SELECT mi3.* FROM mi3
 Input: default/mi3/ds=2008-04-08/hr=12
-Output: file:/data/users/njain/hive4/hive4/build/ql/tmp/928924656/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/584372656/10000
 200	2008-04-08	12
 200	2008-04-08	12
 200	2008-04-08	12
diff --git a/ql/src/test/results/clientpositive/ppd_outer_join4.q.out b/ql/src/test/results/clientpositive/ppd_outer_join4.q.out
index 204a3f1d71..477247db37 100644
--- a/ql/src/test/results/clientpositive/ppd_outer_join4.q.out
+++ b/ql/src/test/results/clientpositive/ppd_outer_join4.q.out
@@ -48,8 +48,6 @@ STAGE PLANS:
               value expressions:
                     expr: key
                     type: string
-                    expr: value
-                    type: string
         a 
             Reduce Output Operator
               key expressions:
@@ -73,7 +71,7 @@ STAGE PLANS:
           condition expressions:
             0 {VALUE._col0} {VALUE._col1}
             1 {VALUE._col0} {VALUE._col1}
-            2 {VALUE._col0} {VALUE._col1}
+            2 {VALUE._col0}
           Filter Operator
             predicate:
                 expr: (((((_col0 > '10') and (_col0 < '20')) and (_col2 > '15')) and (_col2 < '25')) and (sqrt(UDFToDouble(_col4)) <> UDFToDouble(13)))
@@ -113,7 +111,7 @@ query: FROM
  SELECT a.key, a.value, b.key, b.value, c.key
  WHERE a.key > '10' AND a.key < '20' AND b.key > '15' AND b.key < '25' AND sqrt(c.key) <> 13
 Input: default/src
-Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/706058332/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/390144859/10000
 150	val_150	150	val_150	150
 152	val_152	152	val_152	152
 152	val_152	152	val_152	152
diff --git a/ql/src/test/results/clientpositive/ppd_random.q.out b/ql/src/test/results/clientpositive/ppd_random.q.out
index 101821b3ce..28b311aa40 100644
--- a/ql/src/test/results/clientpositive/ppd_random.q.out
+++ b/ql/src/test/results/clientpositive/ppd_random.q.out
@@ -42,8 +42,6 @@ STAGE PLANS:
                           type: string
                     tag: 1
                     value expressions:
-                          expr: _col0
-                          type: string
                           expr: _col1
                           type: string
         src1:src 
@@ -68,8 +66,8 @@ STAGE PLANS:
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0}
+            1 {VALUE._col1}
           Filter Operator
             predicate:
                 expr: (rand() > 0.5)
diff --git a/ql/src/test/results/clientpositive/regex_col.q.out b/ql/src/test/results/clientpositive/regex_col.q.out
index acec2f79e4..ca7de67dba 100644
--- a/ql/src/test/results/clientpositive/regex_col.q.out
+++ b/ql/src/test/results/clientpositive/regex_col.q.out
@@ -105,10 +105,6 @@ STAGE PLANS:
                     type: string
               tag: 1
               value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
                     expr: ds
                     type: string
                     expr: hr
@@ -128,10 +124,6 @@ STAGE PLANS:
                     type: string
               tag: 0
               value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
                     expr: ds
                     type: string
                     expr: hr
@@ -141,8 +133,8 @@ STAGE PLANS:
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
-            1 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
+            0 {VALUE._col2} {VALUE._col3}
+            1 {VALUE._col2} {VALUE._col3}
           Select Operator
             expressions:
                   expr: _col2
@@ -200,10 +192,6 @@ STAGE PLANS:
                     type: string
               tag: 1
               value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
                     expr: ds
                     type: string
                     expr: hr
@@ -234,22 +222,13 @@ STAGE PLANS:
                         expr: ds
                         type: string
                   tag: 0
-                  value expressions:
-                        expr: key
-                        type: string
-                        expr: value
-                        type: string
-                        expr: ds
-                        type: string
-                        expr: hr
-                        type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
-            1 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
+            0 
+            1 {VALUE._col2} {VALUE._col3}
           Select Operator
             expressions:
                   expr: _col6
@@ -267,7 +246,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/805719823/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1521077193/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -302,7 +281,7 @@ Input: default/srcpart/ds=2008-04-08/hr=11
 Input: default/srcpart/ds=2008-04-08/hr=12
 Input: default/srcpart/ds=2008-04-09/hr=11
 Input: default/srcpart/ds=2008-04-09/hr=12
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1129854195/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1366398818/10000
 2008-04-08	11
 2008-04-08	11
 2008-04-08	11
@@ -466,7 +445,7 @@ Input: default/srcpart/ds=2008-04-08/hr=11
 Input: default/srcpart/ds=2008-04-08/hr=12
 Input: default/srcpart/ds=2008-04-09/hr=11
 Input: default/srcpart/ds=2008-04-09/hr=12
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1035513263/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/544471444/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/sample8.q.out b/ql/src/test/results/clientpositive/sample8.q.out
index 0bdb1c4f7b..3e124ede0e 100644
--- a/ql/src/test/results/clientpositive/sample8.q.out
+++ b/ql/src/test/results/clientpositive/sample8.q.out
@@ -35,10 +35,6 @@ STAGE PLANS:
                         type: string
                         expr: value
                         type: string
-                        expr: ds
-                        type: string
-                        expr: hr
-                        type: string
         s 
             Filter Operator
               predicate:
@@ -62,12 +58,12 @@ STAGE PLANS:
                         type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             partition values:
               ds 2008-04-08
@@ -86,10 +82,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             partition values:
               ds 2008-04-08
@@ -108,10 +104,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             partition values:
               ds 2008-04-09
@@ -130,10 +126,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
-        file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             partition values:
               ds 2008-04-09
@@ -152,7 +148,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/srcpart
+                location file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
       Reduce Operator Tree:
@@ -161,7 +157,7 @@ STAGE PLANS:
                Inner Join 0 to 1
           condition expressions:
             0 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
-            1 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3}
+            1 {VALUE._col0} {VALUE._col1}
           Filter Operator
             predicate:
                 expr: ((((((_col4 = _col0) and (_col5 = _col1)) and (_col2 = '2008-04-08')) and (_col3 = '11')) and (_col2 = '2008-04-08')) and (_col3 = '11'))
@@ -179,7 +175,7 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/709064843/10002
+                directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/179920971/10002
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -192,7 +188,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/709064843/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/179920971/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -217,9 +213,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/709064843/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/179920971/10002 
       Path -> Partition:
-        file:/data/users/pchakka/workspace/oshive/build/ql/tmp/709064843/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/179920971/10002 
           Partition
           
               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -234,7 +230,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/709064843/10001
+            directory: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/179920971/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -257,7 +253,7 @@ Input: default/srcpart/ds=2008-04-08/hr=11
 Input: default/srcpart/ds=2008-04-08/hr=12
 Input: default/srcpart/ds=2008-04-09/hr=11
 Input: default/srcpart/ds=2008-04-09/hr=12
-Output: file:/data/users/pchakka/workspace/oshive/build/ql/tmp/362051028/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1641045144/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/udf_case_column_pruning.q.out b/ql/src/test/results/clientpositive/udf_case_column_pruning.q.out
index db8e15d6ce..d4d3c0cccc 100644
--- a/ql/src/test/results/clientpositive/udf_case_column_pruning.q.out
+++ b/ql/src/test/results/clientpositive/udf_case_column_pruning.q.out
@@ -29,11 +29,6 @@ STAGE PLANS:
                     expr: key
                     type: string
               tag: 1
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
         a 
             Reduce Output Operator
               key expressions:
@@ -47,15 +42,13 @@ STAGE PLANS:
               value expressions:
                     expr: key
                     type: string
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
                Inner Join 0 to 1
           condition expressions:
-            0 {VALUE._col0} {VALUE._col1}
-            1 {VALUE._col0} {VALUE._col1}
+            0 {VALUE._col0}
+            1 
           Select Operator
             expressions:
                   expr: CASE (_col0) WHEN ('1') THEN (2) WHEN ('3') THEN (4) ELSE (5) END
@@ -71,7 +64,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1081703636/10002 
+        file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1330132213/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -105,7 +98,7 @@ FROM src a JOIN src b
 ON a.key = b.key
 ORDER BY key LIMIT 10
 Input: default/src
-Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/10034618/10000
+Output: file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/303679320/10000
 5
 5
 5
diff --git a/ql/src/test/results/compiler/plan/join1.q.xml b/ql/src/test/results/compiler/plan/join1.q.xml
index 2ade803221..67cb115c94 100644
--- a/ql/src/test/results/compiler/plan/join1.q.xml
+++ b/ql/src/test/results/compiler/plan/join1.q.xml
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_07" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_03-p3" class="java.beans.XMLDecoder"> 
  <object id="MapRedTask0" class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="childTasks"> 
    <object class="java.util.ArrayList"> 
@@ -26,7 +26,7 @@
            <boolean>true</boolean> 
           </void> 
           <void property="sourceDir"> 
-           <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1688226816/10000</string> 
+           <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/27679623/10000</string> 
           </void> 
           <void property="table"> 
            <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -79,7 +79,7 @@
               </void> 
               <void method="put"> 
                <string>location</string> 
-               <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/dest1</string> 
+               <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest1</string> 
               </void> 
              </object> 
             </void> 
@@ -89,7 +89,7 @@
            </object> 
           </void> 
           <void property="tmpDir"> 
-           <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1688226816/10001</string> 
+           <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/27679623/10001</string> 
           </void> 
          </object> 
         </void> 
@@ -162,7 +162,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -230,7 +230,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -268,17 +268,6 @@
                 </void> 
                </object> 
               </void> 
-              <void method="put"> 
-               <string>VALUE._col0</string> 
-               <object id="exprNodeColumnDesc1" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                <void property="column"> 
-                 <string>key</string> 
-                </void> 
-                <void property="typeInfo"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
-                </void> 
-               </object> 
-              </void> 
              </object> 
             </void> 
             <void property="conf"> 
@@ -342,9 +331,6 @@
               </void> 
               <void property="outputValueColumnNames"> 
                <object class="java.util.ArrayList"> 
-                <void method="add"> 
-                 <string>_col0</string> 
-                </void> 
                 <void method="add"> 
                  <string>_col1</string> 
                 </void> 
@@ -358,9 +344,6 @@
               </void> 
               <void property="valueCols"> 
                <object class="java.util.ArrayList"> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc1"/> 
-                </void> 
                 <void method="add"> 
                  <object idref="exprNodeColumnDesc0"/> 
                 </void> 
@@ -381,11 +364,11 @@
                  <object class="java.util.Properties"> 
                   <void method="put"> 
                    <string>columns</string> 
-                   <string>_col0,_col1</string> 
+                   <string>_col1</string> 
                   </void> 
                   <void method="put"> 
                    <string>columns.types</string> 
-                   <string>string,string</string> 
+                   <string>string</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -404,16 +387,6 @@
              <object class="org.apache.hadoop.hive.ql.exec.RowSchema"> 
               <void property="signature"> 
                <object class="java.util.Vector"> 
-                <void method="add"> 
-                 <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                  <void property="internalName"> 
-                   <string>VALUE._col0</string> 
-                  </void> 
-                  <void property="type"> 
-                   <object idref="PrimitiveTypeInfo0"/> 
-                  </void> 
-                 </object> 
-                </void> 
                 <void method="add"> 
                  <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
                   <void property="internalName"> 
@@ -471,20 +444,9 @@
            <object id="ReduceSinkOperator1" class="org.apache.hadoop.hive.ql.exec.ReduceSinkOperator"> 
             <void property="columnExprMap"> 
              <object class="java.util.HashMap"> 
-              <void method="put"> 
-               <string>VALUE._col1</string> 
-               <object id="exprNodeColumnDesc2" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                <void property="column"> 
-                 <string>value</string> 
-                </void> 
-                <void property="typeInfo"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
-                </void> 
-               </object> 
-              </void> 
               <void method="put"> 
                <string>VALUE._col0</string> 
-               <object id="exprNodeColumnDesc3" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+               <object id="exprNodeColumnDesc1" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
                 <void property="column"> 
                  <string>key</string> 
                 </void> 
@@ -559,9 +521,6 @@
                 <void method="add"> 
                  <string>_col0</string> 
                 </void> 
-                <void method="add"> 
-                 <string>_col1</string> 
-                </void> 
                </object> 
               </void> 
               <void property="partitionCols"> 
@@ -570,10 +529,7 @@
               <void property="valueCols"> 
                <object class="java.util.ArrayList"> 
                 <void method="add"> 
-                 <object idref="exprNodeColumnDesc3"/> 
-                </void> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc2"/> 
+                 <object idref="exprNodeColumnDesc1"/> 
                 </void> 
                </object> 
               </void> 
@@ -592,11 +548,11 @@
                  <object class="java.util.Properties"> 
                   <void method="put"> 
                    <string>columns</string> 
-                   <string>_col0,_col1</string> 
+                   <string>_col0</string> 
                   </void> 
                   <void method="put"> 
                    <string>columns.types</string> 
-                   <string>string,string</string> 
+                   <string>string</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -625,16 +581,6 @@
                   </void> 
                  </object> 
                 </void> 
-                <void method="add"> 
-                 <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                  <void property="internalName"> 
-                   <string>VALUE._col1</string> 
-                  </void> 
-                  <void property="type"> 
-                   <object idref="PrimitiveTypeInfo0"/> 
-                  </void> 
-                 </object> 
-                </void> 
                </object> 
               </void> 
              </object> 
@@ -687,7 +633,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src2</string> 
@@ -702,7 +648,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object idref="LinkedHashMap0"/> 
@@ -746,7 +692,7 @@
                  <int>1</int> 
                 </void> 
                 <void property="dirName"> 
-                 <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1688226816/10000</string> 
+                 <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/27679623/10000</string> 
                 </void> 
                 <void property="tableInfo"> 
                  <object idref="tableDesc0"/> 
@@ -796,7 +742,7 @@
            <object class="java.util.HashMap"> 
             <void method="put"> 
              <string>_col1</string> 
-             <object id="exprNodeColumnDesc4" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+             <object id="exprNodeColumnDesc2" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
               <void property="column"> 
                <string>_col3</string> 
               </void> 
@@ -807,7 +753,7 @@
             </void> 
             <void method="put"> 
              <string>_col0</string> 
-             <object id="exprNodeColumnDesc5" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+             <object id="exprNodeColumnDesc3" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
               <void property="column"> 
                <string>_col0</string> 
               </void> 
@@ -823,10 +769,10 @@
             <void property="colList"> 
              <object class="java.util.ArrayList"> 
               <void method="add"> 
-               <object idref="exprNodeColumnDesc5"/> 
+               <object idref="exprNodeColumnDesc3"/> 
               </void> 
               <void method="add"> 
-               <object idref="exprNodeColumnDesc4"/> 
+               <object idref="exprNodeColumnDesc2"/> 
               </void> 
              </object> 
             </void> 
@@ -885,29 +831,7 @@
        <object class="java.util.HashMap"> 
         <void method="put"> 
          <string>_col3</string> 
-         <object id="exprNodeColumnDesc6" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-          <void property="column"> 
-           <string>VALUE._col1</string> 
-          </void> 
-          <void property="typeInfo"> 
-           <object idref="PrimitiveTypeInfo0"/> 
-          </void> 
-         </object> 
-        </void> 
-        <void method="put"> 
-         <string>_col2</string> 
-         <object id="exprNodeColumnDesc7" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-          <void property="column"> 
-           <string>VALUE._col0</string> 
-          </void> 
-          <void property="typeInfo"> 
-           <object idref="PrimitiveTypeInfo0"/> 
-          </void> 
-         </object> 
-        </void> 
-        <void method="put"> 
-         <string>_col1</string> 
-         <object id="exprNodeColumnDesc8" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+         <object id="exprNodeColumnDesc4" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
           <void property="column"> 
            <string>VALUE._col1</string> 
           </void> 
@@ -918,7 +842,7 @@
         </void> 
         <void method="put"> 
          <string>_col0</string> 
-         <object id="exprNodeColumnDesc9" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+         <object id="exprNodeColumnDesc5" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
           <void property="column"> 
            <string>VALUE._col0</string> 
           </void> 
@@ -948,10 +872,7 @@
            <byte>0</byte> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
-             <object idref="exprNodeColumnDesc9"/> 
-            </void> 
-            <void method="add"> 
-             <object idref="exprNodeColumnDesc8"/> 
+             <object idref="exprNodeColumnDesc5"/> 
             </void> 
            </object> 
           </void> 
@@ -959,10 +880,7 @@
            <byte>1</byte> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
-             <object idref="exprNodeColumnDesc7"/> 
-            </void> 
-            <void method="add"> 
-             <object idref="exprNodeColumnDesc6"/> 
+             <object idref="exprNodeColumnDesc4"/> 
             </void> 
            </object> 
           </void> 
@@ -974,13 +892,27 @@
            <string>_col0</string> 
           </void> 
           <void method="add"> 
-           <string>_col1</string> 
+           <string>_col3</string> 
           </void> 
-          <void method="add"> 
+         </object> 
+        </void> 
+        <void property="reversedExprs"> 
+         <object class="java.util.HashMap"> 
+          <void method="put"> 
+           <string>_col3</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
            <string>_col2</string> 
+           <byte>1</byte> 
           </void> 
-          <void method="add"> 
-           <string>_col3</string> 
+          <void method="put"> 
+           <string>_col1</string> 
+           <byte>0</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col0</string> 
+           <byte>0</byte> 
           </void> 
          </object> 
         </void> 
@@ -1030,26 +962,6 @@
             </void> 
            </object> 
           </void> 
-          <void method="add"> 
-           <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-            <void property="internalName"> 
-             <string>_col1</string> 
-            </void> 
-            <void property="type"> 
-             <object idref="PrimitiveTypeInfo0"/> 
-            </void> 
-           </object> 
-          </void> 
-          <void method="add"> 
-           <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-            <void property="internalName"> 
-             <string>_col2</string> 
-            </void> 
-            <void property="type"> 
-             <object idref="PrimitiveTypeInfo0"/> 
-            </void> 
-           </object> 
-          </void> 
           <void method="add"> 
            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
             <void property="internalName"> 
diff --git a/ql/src/test/results/compiler/plan/join2.q.xml b/ql/src/test/results/compiler/plan/join2.q.xml
index 2597a75d5e..fa00f1aa09 100644
--- a/ql/src/test/results/compiler/plan/join2.q.xml
+++ b/ql/src/test/results/compiler/plan/join2.q.xml
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_07" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_03-p3" class="java.beans.XMLDecoder"> 
  <object id="MapRedTask0" class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="childTasks"> 
    <object class="java.util.ArrayList"> 
@@ -30,7 +30,7 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1920214870/10000</string> 
+               <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/397277816/10000</string> 
               </void> 
               <void property="table"> 
                <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -83,7 +83,7 @@
                   </void> 
                   <void method="put"> 
                    <string>location</string> 
-                   <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/dest1</string> 
+                   <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest1</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -93,7 +93,7 @@
                </object> 
               </void> 
               <void property="tmpDir"> 
-               <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1920214870/10001</string> 
+               <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/397277816/10001</string> 
               </void> 
              </object> 
             </void> 
@@ -173,7 +173,7 @@
                </void> 
                <void method="put"> 
                 <string>location</string> 
-                <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+                <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
                </void> 
               </object> 
              </void> 
@@ -197,10 +197,10 @@
                 <void property="columnExprMap"> 
                  <object class="java.util.HashMap"> 
                   <void method="put"> 
-                   <string>VALUE._col3</string> 
+                   <string>VALUE._col2</string> 
                    <object id="exprNodeColumnDesc0" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
                     <void property="column"> 
-                     <string>_col1</string> 
+                     <string>_col0</string> 
                     </void> 
                     <void property="typeInfo"> 
                      <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
@@ -211,39 +211,6 @@
                     </void> 
                    </object> 
                   </void> 
-                  <void method="put"> 
-                   <string>VALUE._col2</string> 
-                   <object id="exprNodeColumnDesc1" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                    <void property="column"> 
-                     <string>_col0</string> 
-                    </void> 
-                    <void property="typeInfo"> 
-                     <object idref="PrimitiveTypeInfo0"/> 
-                    </void> 
-                   </object> 
-                  </void> 
-                  <void method="put"> 
-                   <string>VALUE._col1</string> 
-                   <object id="exprNodeColumnDesc2" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                    <void property="column"> 
-                     <string>_col3</string> 
-                    </void> 
-                    <void property="typeInfo"> 
-                     <object idref="PrimitiveTypeInfo0"/> 
-                    </void> 
-                   </object> 
-                  </void> 
-                  <void method="put"> 
-                   <string>VALUE._col0</string> 
-                   <object id="exprNodeColumnDesc3" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                    <void property="column"> 
-                     <string>_col2</string> 
-                    </void> 
-                    <void property="typeInfo"> 
-                     <object idref="PrimitiveTypeInfo0"/> 
-                    </void> 
-                   </object> 
-                  </void> 
                  </object> 
                 </void> 
                 <void property="conf"> 
@@ -396,18 +363,9 @@
                   </void> 
                   <void property="outputValueColumnNames"> 
                    <object class="java.util.ArrayList"> 
-                    <void method="add"> 
-                     <string>_col0</string> 
-                    </void> 
-                    <void method="add"> 
-                     <string>_col1</string> 
-                    </void> 
                     <void method="add"> 
                      <string>_col2</string> 
                     </void> 
-                    <void method="add"> 
-                     <string>_col3</string> 
-                    </void> 
                    </object> 
                   </void> 
                   <void property="partitionCols"> 
@@ -415,15 +373,6 @@
                   </void> 
                   <void property="valueCols"> 
                    <object class="java.util.ArrayList"> 
-                    <void method="add"> 
-                     <object idref="exprNodeColumnDesc3"/> 
-                    </void> 
-                    <void method="add"> 
-                     <object idref="exprNodeColumnDesc2"/> 
-                    </void> 
-                    <void method="add"> 
-                     <object idref="exprNodeColumnDesc1"/> 
-                    </void> 
                     <void method="add"> 
                      <object idref="exprNodeColumnDesc0"/> 
                     </void> 
@@ -444,11 +393,11 @@
                      <object class="java.util.Properties"> 
                       <void method="put"> 
                        <string>columns</string> 
-                       <string>_col0,_col1,_col2,_col3</string> 
+                       <string>_col2</string> 
                       </void> 
                       <void method="put"> 
                        <string>columns.types</string> 
-                       <string>string,string,string,string</string> 
+                       <string>string</string> 
                       </void> 
                      </object> 
                     </void> 
@@ -467,26 +416,6 @@
                  <object class="org.apache.hadoop.hive.ql.exec.RowSchema"> 
                   <void property="signature"> 
                    <object class="java.util.Vector"> 
-                    <void method="add"> 
-                     <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                      <void property="internalName"> 
-                       <string>VALUE._col0</string> 
-                      </void> 
-                      <void property="type"> 
-                       <object idref="PrimitiveTypeInfo0"/> 
-                      </void> 
-                     </object> 
-                    </void> 
-                    <void method="add"> 
-                     <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                      <void property="internalName"> 
-                       <string>VALUE._col1</string> 
-                      </void> 
-                      <void property="type"> 
-                       <object idref="PrimitiveTypeInfo0"/> 
-                      </void> 
-                     </object> 
-                    </void> 
                     <void method="add"> 
                      <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
                       <void property="internalName"> 
@@ -497,16 +426,6 @@
                       </void> 
                      </object> 
                     </void> 
-                    <void method="add"> 
-                     <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                      <void property="internalName"> 
-                       <string>VALUE._col3</string> 
-                      </void> 
-                      <void property="type"> 
-                       <object idref="PrimitiveTypeInfo0"/> 
-                      </void> 
-                     </object> 
-                    </void> 
                    </object> 
                   </void> 
                  </object> 
@@ -529,16 +448,6 @@
                   </void> 
                  </object> 
                 </void> 
-                <void method="add"> 
-                 <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                  <void property="internalName"> 
-                   <string>_col1</string> 
-                  </void> 
-                  <void property="type"> 
-                   <object idref="PrimitiveTypeInfo0"/> 
-                  </void> 
-                 </object> 
-                </void> 
                 <void method="add"> 
                  <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
                   <void property="internalName"> 
@@ -549,16 +458,6 @@
                   </void> 
                  </object> 
                 </void> 
-                <void method="add"> 
-                 <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                  <void property="internalName"> 
-                   <string>_col3</string> 
-                  </void> 
-                  <void property="type"> 
-                   <object idref="PrimitiveTypeInfo0"/> 
-                  </void> 
-                 </object> 
-                </void> 
                </object> 
               </void> 
              </object> 
@@ -576,7 +475,7 @@
                  <object class="java.util.HashMap"> 
                   <void method="put"> 
                    <string>VALUE._col1</string> 
-                   <object id="exprNodeColumnDesc4" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+                   <object id="exprNodeColumnDesc1" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
                     <void property="column"> 
                      <string>value</string> 
                     </void> 
@@ -585,17 +484,6 @@
                     </void> 
                    </object> 
                   </void> 
-                  <void method="put"> 
-                   <string>VALUE._col0</string> 
-                   <object id="exprNodeColumnDesc5" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                    <void property="column"> 
-                     <string>key</string> 
-                    </void> 
-                    <void property="typeInfo"> 
-                     <object idref="PrimitiveTypeInfo0"/> 
-                    </void> 
-                   </object> 
-                  </void> 
                  </object> 
                 </void> 
                 <void property="conf"> 
@@ -683,9 +571,6 @@
                   </void> 
                   <void property="outputValueColumnNames"> 
                    <object class="java.util.ArrayList"> 
-                    <void method="add"> 
-                     <string>_col0</string> 
-                    </void> 
                     <void method="add"> 
                      <string>_col1</string> 
                     </void> 
@@ -700,10 +585,7 @@
                   <void property="valueCols"> 
                    <object class="java.util.ArrayList"> 
                     <void method="add"> 
-                     <object idref="exprNodeColumnDesc5"/> 
-                    </void> 
-                    <void method="add"> 
-                     <object idref="exprNodeColumnDesc4"/> 
+                     <object idref="exprNodeColumnDesc1"/> 
                     </void> 
                    </object> 
                   </void> 
@@ -722,11 +604,11 @@
                      <object class="java.util.Properties"> 
                       <void method="put"> 
                        <string>columns</string> 
-                       <string>_col0,_col1</string> 
+                       <string>_col1</string> 
                       </void> 
                       <void method="put"> 
                        <string>columns.types</string> 
-                       <string>string,string</string> 
+                       <string>string</string> 
                       </void> 
                      </object> 
                     </void> 
@@ -745,16 +627,6 @@
                  <object class="org.apache.hadoop.hive.ql.exec.RowSchema"> 
                   <void property="signature"> 
                    <object class="java.util.Vector"> 
-                    <void method="add"> 
-                     <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                      <void property="internalName"> 
-                       <string>VALUE._col0</string> 
-                      </void> 
-                      <void property="type"> 
-                       <object idref="PrimitiveTypeInfo0"/> 
-                      </void> 
-                     </object> 
-                    </void> 
                     <void method="add"> 
                      <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
                       <void property="internalName"> 
@@ -817,7 +689,7 @@
         <void property="pathToAliases"> 
          <object class="java.util.LinkedHashMap"> 
           <void method="put"> 
-           <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1381792002/10002</string> 
+           <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1187118357/10002</string> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <string>$INTNAME</string> 
@@ -825,7 +697,7 @@
            </object> 
           </void> 
           <void method="put"> 
-           <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+           <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <string>src3</string> 
@@ -837,7 +709,7 @@
         <void property="pathToPartitionInfo"> 
          <object class="java.util.LinkedHashMap"> 
           <void method="put"> 
-           <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1381792002/10002</string> 
+           <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1187118357/10002</string> 
            <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
             <void property="tableDesc"> 
              <object id="tableDesc4" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -858,7 +730,7 @@
                 </void> 
                 <void method="put"> 
                  <string>serialization.ddl</string> 
-                 <string>struct binary_table { string _col0, string _col1, string _col2, string _col3}</string> 
+                 <string>struct binary_table { string _col0, string _col2}</string> 
                 </void> 
                 <void method="put"> 
                  <string>serialization.format</string> 
@@ -871,7 +743,7 @@
            </object> 
           </void> 
           <void method="put"> 
-           <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+           <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
             <void property="partSpec"> 
              <object idref="LinkedHashMap0"/> 
@@ -915,7 +787,7 @@
                      <int>1</int> 
                     </void> 
                     <void property="dirName"> 
-                     <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1920214870/10000</string> 
+                     <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/397277816/10000</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object idref="tableDesc0"/> 
@@ -965,7 +837,7 @@
                <object class="java.util.HashMap"> 
                 <void method="put"> 
                  <string>_col1</string> 
-                 <object id="exprNodeColumnDesc6" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+                 <object id="exprNodeColumnDesc2" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
                   <void property="column"> 
                    <string>_col5</string> 
                   </void> 
@@ -976,7 +848,7 @@
                 </void> 
                 <void method="put"> 
                  <string>_col0</string> 
-                 <object id="exprNodeColumnDesc7" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+                 <object id="exprNodeColumnDesc3" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
                   <void property="column"> 
                    <string>_col2</string> 
                   </void> 
@@ -992,10 +864,10 @@
                 <void property="colList"> 
                  <object class="java.util.ArrayList"> 
                   <void method="add"> 
-                   <object idref="exprNodeColumnDesc7"/> 
+                   <object idref="exprNodeColumnDesc3"/> 
                   </void> 
                   <void method="add"> 
-                   <object idref="exprNodeColumnDesc6"/> 
+                   <object idref="exprNodeColumnDesc2"/> 
                   </void> 
                  </object> 
                 </void> 
@@ -1054,7 +926,7 @@
            <object class="java.util.HashMap"> 
             <void method="put"> 
              <string>_col5</string> 
-             <object id="exprNodeColumnDesc8" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+             <object id="exprNodeColumnDesc4" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
               <void property="column"> 
                <string>VALUE._col1</string> 
               </void> 
@@ -1063,31 +935,9 @@
               </void> 
              </object> 
             </void> 
-            <void method="put"> 
-             <string>_col4</string> 
-             <object id="exprNodeColumnDesc9" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-              <void property="column"> 
-               <string>VALUE._col0</string> 
-              </void> 
-              <void property="typeInfo"> 
-               <object idref="PrimitiveTypeInfo0"/> 
-              </void> 
-             </object> 
-            </void> 
-            <void method="put"> 
-             <string>_col3</string> 
-             <object id="exprNodeColumnDesc10" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-              <void property="column"> 
-               <string>VALUE._col3</string> 
-              </void> 
-              <void property="typeInfo"> 
-               <object idref="PrimitiveTypeInfo0"/> 
-              </void> 
-             </object> 
-            </void> 
             <void method="put"> 
              <string>_col2</string> 
-             <object id="exprNodeColumnDesc11" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+             <object id="exprNodeColumnDesc5" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
               <void property="column"> 
                <string>VALUE._col2</string> 
               </void> 
@@ -1096,28 +946,6 @@
               </void> 
              </object> 
             </void> 
-            <void method="put"> 
-             <string>_col1</string> 
-             <object id="exprNodeColumnDesc12" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-              <void property="column"> 
-               <string>VALUE._col1</string> 
-              </void> 
-              <void property="typeInfo"> 
-               <object idref="PrimitiveTypeInfo0"/> 
-              </void> 
-             </object> 
-            </void> 
-            <void method="put"> 
-             <string>_col0</string> 
-             <object id="exprNodeColumnDesc13" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-              <void property="column"> 
-               <string>VALUE._col0</string> 
-              </void> 
-              <void property="typeInfo"> 
-               <object idref="PrimitiveTypeInfo0"/> 
-              </void> 
-             </object> 
-            </void> 
            </object> 
           </void> 
           <void property="conf"> 
@@ -1139,16 +967,7 @@
                <byte>0</byte> 
                <object class="java.util.ArrayList"> 
                 <void method="add"> 
-                 <object idref="exprNodeColumnDesc13"/> 
-                </void> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc12"/> 
-                </void> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc11"/> 
-                </void> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc10"/> 
+                 <object idref="exprNodeColumnDesc5"/> 
                 </void> 
                </object> 
               </void> 
@@ -1156,10 +975,7 @@
                <byte>1</byte> 
                <object class="java.util.ArrayList"> 
                 <void method="add"> 
-                 <object idref="exprNodeColumnDesc9"/> 
-                </void> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc8"/> 
+                 <object idref="exprNodeColumnDesc4"/> 
                 </void> 
                </object> 
               </void> 
@@ -1168,22 +984,38 @@
             <void property="outputColumnNames"> 
              <object class="java.util.ArrayList"> 
               <void method="add"> 
-               <string>_col0</string> 
+               <string>_col2</string> 
               </void> 
               <void method="add"> 
-               <string>_col1</string> 
+               <string>_col5</string> 
               </void> 
-              <void method="add"> 
-               <string>_col2</string> 
+             </object> 
+            </void> 
+            <void property="reversedExprs"> 
+             <object class="java.util.HashMap"> 
+              <void method="put"> 
+               <string>_col5</string> 
+               <byte>1</byte> 
               </void> 
-              <void method="add"> 
+              <void method="put"> 
+               <string>_col4</string> 
+               <byte>1</byte> 
+              </void> 
+              <void method="put"> 
                <string>_col3</string> 
+               <byte>0</byte> 
               </void> 
-              <void method="add"> 
-               <string>_col4</string> 
+              <void method="put"> 
+               <string>_col2</string> 
+               <byte>0</byte> 
               </void> 
-              <void method="add"> 
-               <string>_col5</string> 
+              <void method="put"> 
+               <string>_col1</string> 
+               <byte>0</byte> 
+              </void> 
+              <void method="put"> 
+               <string>_col0</string> 
+               <byte>0</byte> 
               </void> 
              </object> 
             </void> 
@@ -1226,26 +1058,6 @@
            <object class="org.apache.hadoop.hive.ql.exec.RowSchema"> 
             <void property="signature"> 
              <object class="java.util.Vector"> 
-              <void method="add"> 
-               <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                <void property="internalName"> 
-                 <string>_col0</string> 
-                </void> 
-                <void property="type"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
-                </void> 
-               </object> 
-              </void> 
-              <void method="add"> 
-               <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                <void property="internalName"> 
-                 <string>_col1</string> 
-                </void> 
-                <void property="type"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
-                </void> 
-               </object> 
-              </void> 
               <void method="add"> 
                <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
                 <void property="internalName"> 
@@ -1256,26 +1068,6 @@
                 </void> 
                </object> 
               </void> 
-              <void method="add"> 
-               <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                <void property="internalName"> 
-                 <string>_col3</string> 
-                </void> 
-                <void property="type"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
-                </void> 
-               </object> 
-              </void> 
-              <void method="add"> 
-               <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                <void property="internalName"> 
-                 <string>_col4</string> 
-                </void> 
-                <void property="type"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
-                </void> 
-               </object> 
-              </void> 
               <void method="add"> 
                <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
                 <void property="internalName"> 
@@ -1371,7 +1163,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -1439,7 +1231,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -1462,20 +1254,9 @@
            <object id="ReduceSinkOperator2" class="org.apache.hadoop.hive.ql.exec.ReduceSinkOperator"> 
             <void property="columnExprMap"> 
              <object class="java.util.HashMap"> 
-              <void method="put"> 
-               <string>VALUE._col1</string> 
-               <object id="exprNodeColumnDesc14" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                <void property="column"> 
-                 <string>value</string> 
-                </void> 
-                <void property="typeInfo"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
-                </void> 
-               </object> 
-              </void> 
               <void method="put"> 
                <string>VALUE._col0</string> 
-               <object id="exprNodeColumnDesc15" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+               <object id="exprNodeColumnDesc6" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
                 <void property="column"> 
                  <string>key</string> 
                 </void> 
@@ -1550,9 +1331,6 @@
                 <void method="add"> 
                  <string>_col0</string> 
                 </void> 
-                <void method="add"> 
-                 <string>_col1</string> 
-                </void> 
                </object> 
               </void> 
               <void property="partitionCols"> 
@@ -1564,10 +1342,7 @@
               <void property="valueCols"> 
                <object class="java.util.ArrayList"> 
                 <void method="add"> 
-                 <object idref="exprNodeColumnDesc15"/> 
-                </void> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc14"/> 
+                 <object idref="exprNodeColumnDesc6"/> 
                 </void> 
                </object> 
               </void> 
@@ -1586,11 +1361,11 @@
                  <object class="java.util.Properties"> 
                   <void method="put"> 
                    <string>columns</string> 
-                   <string>_col0,_col1</string> 
+                   <string>_col0</string> 
                   </void> 
                   <void method="put"> 
                    <string>columns.types</string> 
-                   <string>string,string</string> 
+                   <string>string</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -1619,16 +1394,6 @@
                   </void> 
                  </object> 
                 </void> 
-                <void method="add"> 
-                 <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                  <void property="internalName"> 
-                   <string>VALUE._col1</string> 
-                  </void> 
-                  <void property="type"> 
-                   <object idref="PrimitiveTypeInfo0"/> 
-                  </void> 
-                 </object> 
-                </void> 
                </object> 
               </void> 
              </object> 
@@ -1676,20 +1441,9 @@
            <object id="ReduceSinkOperator3" class="org.apache.hadoop.hive.ql.exec.ReduceSinkOperator"> 
             <void property="columnExprMap"> 
              <object class="java.util.HashMap"> 
-              <void method="put"> 
-               <string>VALUE._col1</string> 
-               <object id="exprNodeColumnDesc16" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                <void property="column"> 
-                 <string>value</string> 
-                </void> 
-                <void property="typeInfo"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
-                </void> 
-               </object> 
-              </void> 
               <void method="put"> 
                <string>VALUE._col0</string> 
-               <object id="exprNodeColumnDesc17" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+               <object id="exprNodeColumnDesc7" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
                 <void property="column"> 
                  <string>key</string> 
                 </void> 
@@ -1764,9 +1518,6 @@
                 <void method="add"> 
                  <string>_col0</string> 
                 </void> 
-                <void method="add"> 
-                 <string>_col1</string> 
-                </void> 
                </object> 
               </void> 
               <void property="partitionCols"> 
@@ -1775,10 +1526,7 @@
               <void property="valueCols"> 
                <object class="java.util.ArrayList"> 
                 <void method="add"> 
-                 <object idref="exprNodeColumnDesc17"/> 
-                </void> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc16"/> 
+                 <object idref="exprNodeColumnDesc7"/> 
                 </void> 
                </object> 
               </void> 
@@ -1797,11 +1545,11 @@
                  <object class="java.util.Properties"> 
                   <void method="put"> 
                    <string>columns</string> 
-                   <string>_col0,_col1</string> 
+                   <string>_col0</string> 
                   </void> 
                   <void method="put"> 
                    <string>columns.types</string> 
-                   <string>string,string</string> 
+                   <string>string</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -1830,16 +1578,6 @@
                   </void> 
                  </object> 
                 </void> 
-                <void method="add"> 
-                 <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                  <void property="internalName"> 
-                   <string>VALUE._col1</string> 
-                  </void> 
-                  <void property="type"> 
-                   <object idref="PrimitiveTypeInfo0"/> 
-                  </void> 
-                 </object> 
-                </void> 
                </object> 
               </void> 
              </object> 
@@ -1892,7 +1630,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src2</string> 
@@ -1907,7 +1645,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object idref="LinkedHashMap1"/> 
@@ -1944,7 +1682,7 @@
           <void property="conf"> 
            <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
             <void property="dirName"> 
-             <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1381792002/10002</string> 
+             <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1187118357/10002</string> 
             </void> 
             <void property="tableInfo"> 
              <object idref="tableDesc4"/> 
@@ -1967,20 +1705,9 @@
       </void> 
       <void property="columnExprMap"> 
        <object class="java.util.HashMap"> 
-        <void method="put"> 
-         <string>_col3</string> 
-         <object id="exprNodeColumnDesc18" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-          <void property="column"> 
-           <string>VALUE._col1</string> 
-          </void> 
-          <void property="typeInfo"> 
-           <object idref="PrimitiveTypeInfo0"/> 
-          </void> 
-         </object> 
-        </void> 
         <void method="put"> 
          <string>_col2</string> 
-         <object id="exprNodeColumnDesc19" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+         <object id="exprNodeColumnDesc8" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
           <void property="column"> 
            <string>VALUE._col0</string> 
           </void> 
@@ -1989,20 +1716,9 @@
           </void> 
          </object> 
         </void> 
-        <void method="put"> 
-         <string>_col1</string> 
-         <object id="exprNodeColumnDesc20" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-          <void property="column"> 
-           <string>VALUE._col1</string> 
-          </void> 
-          <void property="typeInfo"> 
-           <object idref="PrimitiveTypeInfo0"/> 
-          </void> 
-         </object> 
-        </void> 
         <void method="put"> 
          <string>_col0</string> 
-         <object id="exprNodeColumnDesc21" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+         <object id="exprNodeColumnDesc9" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
           <void property="column"> 
            <string>VALUE._col0</string> 
           </void> 
@@ -2032,10 +1748,7 @@
            <byte>0</byte> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
-             <object idref="exprNodeColumnDesc21"/> 
-            </void> 
-            <void method="add"> 
-             <object idref="exprNodeColumnDesc20"/> 
+             <object idref="exprNodeColumnDesc9"/> 
             </void> 
            </object> 
           </void> 
@@ -2043,10 +1756,7 @@
            <byte>1</byte> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
-             <object idref="exprNodeColumnDesc19"/> 
-            </void> 
-            <void method="add"> 
-             <object idref="exprNodeColumnDesc18"/> 
+             <object idref="exprNodeColumnDesc8"/> 
             </void> 
            </object> 
           </void> 
@@ -2057,14 +1767,28 @@
           <void method="add"> 
            <string>_col0</string> 
           </void> 
-          <void method="add"> 
-           <string>_col1</string> 
-          </void> 
           <void method="add"> 
            <string>_col2</string> 
           </void> 
-          <void method="add"> 
+         </object> 
+        </void> 
+        <void property="reversedExprs"> 
+         <object class="java.util.HashMap"> 
+          <void method="put"> 
            <string>_col3</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col2</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col1</string> 
+           <byte>0</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col0</string> 
+           <byte>0</byte> 
           </void> 
          </object> 
         </void> 
diff --git a/ql/src/test/results/compiler/plan/join3.q.xml b/ql/src/test/results/compiler/plan/join3.q.xml
index d16ce398f4..dcbed54226 100644
--- a/ql/src/test/results/compiler/plan/join3.q.xml
+++ b/ql/src/test/results/compiler/plan/join3.q.xml
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_07" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_03-p3" class="java.beans.XMLDecoder"> 
  <object id="MapRedTask0" class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="childTasks"> 
    <object class="java.util.ArrayList"> 
@@ -26,7 +26,7 @@
            <boolean>true</boolean> 
           </void> 
           <void property="sourceDir"> 
-           <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1413156311/10000</string> 
+           <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1290613046/10000</string> 
           </void> 
           <void property="table"> 
            <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -79,7 +79,7 @@
               </void> 
               <void method="put"> 
                <string>location</string> 
-               <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/dest1</string> 
+               <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/dest1</string> 
               </void> 
              </object> 
             </void> 
@@ -89,7 +89,7 @@
            </object> 
           </void> 
           <void property="tmpDir"> 
-           <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1413156311/10001</string> 
+           <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1290613046/10001</string> 
           </void> 
          </object> 
         </void> 
@@ -162,7 +162,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -230,7 +230,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -298,7 +298,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -320,34 +320,7 @@
           <void method="add"> 
            <object id="ReduceSinkOperator0" class="org.apache.hadoop.hive.ql.exec.ReduceSinkOperator"> 
             <void property="columnExprMap"> 
-             <object class="java.util.HashMap"> 
-              <void method="put"> 
-               <string>VALUE._col1</string> 
-               <object id="exprNodeColumnDesc0" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                <void property="column"> 
-                 <string>value</string> 
-                </void> 
-                <void property="typeInfo"> 
-                 <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
-                  <void property="typeName"> 
-                   <string>string</string> 
-                  </void> 
-                 </object> 
-                </void> 
-               </object> 
-              </void> 
-              <void method="put"> 
-               <string>VALUE._col0</string> 
-               <object id="exprNodeColumnDesc1" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                <void property="column"> 
-                 <string>key</string> 
-                </void> 
-                <void property="typeInfo"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
-                </void> 
-               </object> 
-              </void> 
-             </object> 
+             <object class="java.util.HashMap"/> 
             </void> 
             <void property="conf"> 
              <object class="org.apache.hadoop.hive.ql.plan.reduceSinkDesc"> 
@@ -359,7 +332,11 @@
                    <string>key</string> 
                   </void> 
                   <void property="typeInfo"> 
-                   <object idref="PrimitiveTypeInfo0"/> 
+                   <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                    <void property="typeName"> 
+                     <string>string</string> 
+                    </void> 
+                   </object> 
                   </void> 
                  </object> 
                 </void> 
@@ -409,14 +386,7 @@
                </object> 
               </void> 
               <void property="outputValueColumnNames"> 
-               <object class="java.util.ArrayList"> 
-                <void method="add"> 
-                 <string>_col0</string> 
-                </void> 
-                <void method="add"> 
-                 <string>_col1</string> 
-                </void> 
-               </object> 
+               <object class="java.util.ArrayList"/> 
               </void> 
               <void property="partitionCols"> 
                <object idref="ArrayList0"/> 
@@ -425,14 +395,7 @@
                <int>1</int> 
               </void> 
               <void property="valueCols"> 
-               <object class="java.util.ArrayList"> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc1"/> 
-                </void> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc0"/> 
-                </void> 
-               </object> 
+               <object class="java.util.ArrayList"/> 
               </void> 
               <void property="valueSerializeInfo"> 
                <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -449,11 +412,11 @@
                  <object class="java.util.Properties"> 
                   <void method="put"> 
                    <string>columns</string> 
-                   <string>_col0,_col1</string> 
+                   <string></string> 
                   </void> 
                   <void method="put"> 
                    <string>columns.types</string> 
-                   <string>string,string</string> 
+                   <string></string> 
                   </void> 
                  </object> 
                 </void> 
@@ -471,28 +434,7 @@
             <void property="schema"> 
              <object class="org.apache.hadoop.hive.ql.exec.RowSchema"> 
               <void property="signature"> 
-               <object class="java.util.Vector"> 
-                <void method="add"> 
-                 <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                  <void property="internalName"> 
-                   <string>VALUE._col0</string> 
-                  </void> 
-                  <void property="type"> 
-                   <object idref="PrimitiveTypeInfo0"/> 
-                  </void> 
-                 </object> 
-                </void> 
-                <void method="add"> 
-                 <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                  <void property="internalName"> 
-                   <string>VALUE._col1</string> 
-                  </void> 
-                  <void property="type"> 
-                   <object idref="PrimitiveTypeInfo0"/> 
-                  </void> 
-                 </object> 
-                </void> 
-               </object> 
+               <object class="java.util.Vector"/> 
               </void> 
              </object> 
             </void> 
@@ -541,7 +483,7 @@
              <object class="java.util.HashMap"> 
               <void method="put"> 
                <string>VALUE._col1</string> 
-               <object id="exprNodeColumnDesc2" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+               <object id="exprNodeColumnDesc0" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
                 <void property="column"> 
                  <string>value</string> 
                 </void> 
@@ -550,17 +492,6 @@
                 </void> 
                </object> 
               </void> 
-              <void method="put"> 
-               <string>VALUE._col0</string> 
-               <object id="exprNodeColumnDesc3" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                <void property="column"> 
-                 <string>key</string> 
-                </void> 
-                <void property="typeInfo"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
-                </void> 
-               </object> 
-              </void> 
              </object> 
             </void> 
             <void property="conf"> 
@@ -624,9 +555,6 @@
               </void> 
               <void property="outputValueColumnNames"> 
                <object class="java.util.ArrayList"> 
-                <void method="add"> 
-                 <string>_col0</string> 
-                </void> 
                 <void method="add"> 
                  <string>_col1</string> 
                 </void> 
@@ -641,10 +569,7 @@
               <void property="valueCols"> 
                <object class="java.util.ArrayList"> 
                 <void method="add"> 
-                 <object idref="exprNodeColumnDesc3"/> 
-                </void> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc2"/> 
+                 <object idref="exprNodeColumnDesc0"/> 
                 </void> 
                </object> 
               </void> 
@@ -663,11 +588,11 @@
                  <object class="java.util.Properties"> 
                   <void method="put"> 
                    <string>columns</string> 
-                   <string>_col0,_col1</string> 
+                   <string>_col1</string> 
                   </void> 
                   <void method="put"> 
                    <string>columns.types</string> 
-                   <string>string,string</string> 
+                   <string>string</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -686,16 +611,6 @@
              <object class="org.apache.hadoop.hive.ql.exec.RowSchema"> 
               <void property="signature"> 
                <object class="java.util.Vector"> 
-                <void method="add"> 
-                 <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                  <void property="internalName"> 
-                   <string>VALUE._col0</string> 
-                  </void> 
-                  <void property="type"> 
-                   <object idref="PrimitiveTypeInfo0"/> 
-                  </void> 
-                 </object> 
-                </void> 
                 <void method="add"> 
                  <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
                   <void property="internalName"> 
@@ -753,20 +668,9 @@
            <object id="ReduceSinkOperator2" class="org.apache.hadoop.hive.ql.exec.ReduceSinkOperator"> 
             <void property="columnExprMap"> 
              <object class="java.util.HashMap"> 
-              <void method="put"> 
-               <string>VALUE._col1</string> 
-               <object id="exprNodeColumnDesc4" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-                <void property="column"> 
-                 <string>value</string> 
-                </void> 
-                <void property="typeInfo"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
-                </void> 
-               </object> 
-              </void> 
               <void method="put"> 
                <string>VALUE._col0</string> 
-               <object id="exprNodeColumnDesc5" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+               <object id="exprNodeColumnDesc1" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
                 <void property="column"> 
                  <string>key</string> 
                 </void> 
@@ -841,9 +745,6 @@
                 <void method="add"> 
                  <string>_col0</string> 
                 </void> 
-                <void method="add"> 
-                 <string>_col1</string> 
-                </void> 
                </object> 
               </void> 
               <void property="partitionCols"> 
@@ -852,10 +753,7 @@
               <void property="valueCols"> 
                <object class="java.util.ArrayList"> 
                 <void method="add"> 
-                 <object idref="exprNodeColumnDesc5"/> 
-                </void> 
-                <void method="add"> 
-                 <object idref="exprNodeColumnDesc4"/> 
+                 <object idref="exprNodeColumnDesc1"/> 
                 </void> 
                </object> 
               </void> 
@@ -874,11 +772,11 @@
                  <object class="java.util.Properties"> 
                   <void method="put"> 
                    <string>columns</string> 
-                   <string>_col0,_col1</string> 
+                   <string>_col0</string> 
                   </void> 
                   <void method="put"> 
                    <string>columns.types</string> 
-                   <string>string,string</string> 
+                   <string>string</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -907,16 +805,6 @@
                   </void> 
                  </object> 
                 </void> 
-                <void method="add"> 
-                 <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-                  <void property="internalName"> 
-                   <string>VALUE._col1</string> 
-                  </void> 
-                  <void property="type"> 
-                   <object idref="PrimitiveTypeInfo0"/> 
-                  </void> 
-                 </object> 
-                </void> 
                </object> 
               </void> 
              </object> 
@@ -969,7 +857,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src2</string> 
@@ -987,7 +875,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive4/hive4/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object idref="LinkedHashMap0"/> 
@@ -1031,7 +919,7 @@
                  <int>1</int> 
                 </void> 
                 <void property="dirName"> 
-                 <string>file:/data/users/njain/hive4/hive4/build/ql/tmp/1413156311/10000</string> 
+                 <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1290613046/10000</string> 
                 </void> 
                 <void property="tableInfo"> 
                  <object idref="tableDesc0"/> 
@@ -1081,7 +969,7 @@
            <object class="java.util.HashMap"> 
             <void method="put"> 
              <string>_col1</string> 
-             <object id="exprNodeColumnDesc6" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+             <object id="exprNodeColumnDesc2" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
               <void property="column"> 
                <string>_col5</string> 
               </void> 
@@ -1092,7 +980,7 @@
             </void> 
             <void method="put"> 
              <string>_col0</string> 
-             <object id="exprNodeColumnDesc7" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+             <object id="exprNodeColumnDesc3" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
               <void property="column"> 
                <string>_col0</string> 
               </void> 
@@ -1108,10 +996,10 @@
             <void property="colList"> 
              <object class="java.util.ArrayList"> 
               <void method="add"> 
-               <object idref="exprNodeColumnDesc7"/> 
+               <object idref="exprNodeColumnDesc3"/> 
               </void> 
               <void method="add"> 
-               <object idref="exprNodeColumnDesc6"/> 
+               <object idref="exprNodeColumnDesc2"/> 
               </void> 
              </object> 
             </void> 
@@ -1170,51 +1058,7 @@
        <object class="java.util.HashMap"> 
         <void method="put"> 
          <string>_col5</string> 
-         <object id="exprNodeColumnDesc8" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-          <void property="column"> 
-           <string>VALUE._col1</string> 
-          </void> 
-          <void property="typeInfo"> 
-           <object idref="PrimitiveTypeInfo0"/> 
-          </void> 
-         </object> 
-        </void> 
-        <void method="put"> 
-         <string>_col4</string> 
-         <object id="exprNodeColumnDesc9" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-          <void property="column"> 
-           <string>VALUE._col0</string> 
-          </void> 
-          <void property="typeInfo"> 
-           <object idref="PrimitiveTypeInfo0"/> 
-          </void> 
-         </object> 
-        </void> 
-        <void method="put"> 
-         <string>_col3</string> 
-         <object id="exprNodeColumnDesc10" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-          <void property="column"> 
-           <string>VALUE._col1</string> 
-          </void> 
-          <void property="typeInfo"> 
-           <object idref="PrimitiveTypeInfo0"/> 
-          </void> 
-         </object> 
-        </void> 
-        <void method="put"> 
-         <string>_col2</string> 
-         <object id="exprNodeColumnDesc11" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
-          <void property="column"> 
-           <string>VALUE._col0</string> 
-          </void> 
-          <void property="typeInfo"> 
-           <object idref="PrimitiveTypeInfo0"/> 
-          </void> 
-         </object> 
-        </void> 
-        <void method="put"> 
-         <string>_col1</string> 
-         <object id="exprNodeColumnDesc12" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+         <object id="exprNodeColumnDesc4" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
           <void property="column"> 
            <string>VALUE._col1</string> 
           </void> 
@@ -1225,7 +1069,7 @@
         </void> 
         <void method="put"> 
          <string>_col0</string> 
-         <object id="exprNodeColumnDesc13" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
+         <object id="exprNodeColumnDesc5" class="org.apache.hadoop.hive.ql.plan.exprNodeColumnDesc"> 
           <void property="column"> 
            <string>VALUE._col0</string> 
           </void> 
@@ -1262,32 +1106,19 @@
            <byte>0</byte> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
-             <object idref="exprNodeColumnDesc13"/> 
-            </void> 
-            <void method="add"> 
-             <object idref="exprNodeColumnDesc12"/> 
+             <object idref="exprNodeColumnDesc5"/> 
             </void> 
            </object> 
           </void> 
           <void method="put"> 
            <byte>1</byte> 
-           <object class="java.util.ArrayList"> 
-            <void method="add"> 
-             <object idref="exprNodeColumnDesc11"/> 
-            </void> 
-            <void method="add"> 
-             <object idref="exprNodeColumnDesc10"/> 
-            </void> 
-           </object> 
+           <object class="java.util.ArrayList"/> 
           </void> 
           <void method="put"> 
            <byte>2</byte> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
-             <object idref="exprNodeColumnDesc9"/> 
-            </void> 
-            <void method="add"> 
-             <object idref="exprNodeColumnDesc8"/> 
+             <object idref="exprNodeColumnDesc4"/> 
             </void> 
            </object> 
           </void> 
@@ -1299,19 +1130,35 @@
            <string>_col0</string> 
           </void> 
           <void method="add"> 
-           <string>_col1</string> 
+           <string>_col5</string> 
           </void> 
-          <void method="add"> 
-           <string>_col2</string> 
+         </object> 
+        </void> 
+        <void property="reversedExprs"> 
+         <object class="java.util.HashMap"> 
+          <void method="put"> 
+           <string>_col5</string> 
+           <byte>2</byte> 
           </void> 
-          <void method="add"> 
+          <void method="put"> 
+           <string>_col4</string> 
+           <byte>2</byte> 
+          </void> 
+          <void method="put"> 
            <string>_col3</string> 
+           <byte>1</byte> 
           </void> 
-          <void method="add"> 
-           <string>_col4</string> 
+          <void method="put"> 
+           <string>_col2</string> 
+           <byte>1</byte> 
           </void> 
-          <void method="add"> 
-           <string>_col5</string> 
+          <void method="put"> 
+           <string>_col1</string> 
+           <byte>0</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col0</string> 
+           <byte>0</byte> 
           </void> 
          </object> 
         </void> 
@@ -1372,46 +1219,6 @@
             </void> 
            </object> 
           </void> 
-          <void method="add"> 
-           <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-            <void property="internalName"> 
-             <string>_col1</string> 
-            </void> 
-            <void property="type"> 
-             <object idref="PrimitiveTypeInfo0"/> 
-            </void> 
-           </object> 
-          </void> 
-          <void method="add"> 
-           <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-            <void property="internalName"> 
-             <string>_col2</string> 
-            </void> 
-            <void property="type"> 
-             <object idref="PrimitiveTypeInfo0"/> 
-            </void> 
-           </object> 
-          </void> 
-          <void method="add"> 
-           <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-            <void property="internalName"> 
-             <string>_col3</string> 
-            </void> 
-            <void property="type"> 
-             <object idref="PrimitiveTypeInfo0"/> 
-            </void> 
-           </object> 
-          </void> 
-          <void method="add"> 
-           <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
-            <void property="internalName"> 
-             <string>_col4</string> 
-            </void> 
-            <void property="type"> 
-             <object idref="PrimitiveTypeInfo0"/> 
-            </void> 
-           </object> 
-          </void> 
           <void method="add"> 
            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
             <void property="internalName"> 
diff --git a/ql/src/test/results/compiler/plan/join4.q.xml b/ql/src/test/results/compiler/plan/join4.q.xml
index 9eda0bdeb6..00da520052 100644
--- a/ql/src/test/results/compiler/plan/join4.q.xml
+++ b/ql/src/test/results/compiler/plan/join4.q.xml
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_07" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_03-p3" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-2</string> 
@@ -64,7 +64,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -132,7 +132,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -1643,7 +1643,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1658,7 +1658,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object idref="LinkedHashMap0"/> 
@@ -1703,7 +1703,7 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>file:/data/users/pchakka/workspace/oshive/build/ql/tmp/96596828/10001</string> 
+                     <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/1797989074/10001</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -2183,6 +2183,26 @@
           </void> 
          </object> 
         </void> 
+        <void property="reversedExprs"> 
+         <object class="java.util.HashMap"> 
+          <void method="put"> 
+           <string>_col3</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col2</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col1</string> 
+           <byte>0</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col0</string> 
+           <byte>0</byte> 
+          </void> 
+         </object> 
+        </void> 
        </object> 
       </void> 
       <void property="parentOperators"> 
diff --git a/ql/src/test/results/compiler/plan/join5.q.xml b/ql/src/test/results/compiler/plan/join5.q.xml
index 4a46d90c4d..b901fb1396 100644
--- a/ql/src/test/results/compiler/plan/join5.q.xml
+++ b/ql/src/test/results/compiler/plan/join5.q.xml
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_07" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_03-p3" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-2</string> 
@@ -64,7 +64,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -132,7 +132,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -1643,7 +1643,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1658,7 +1658,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object idref="LinkedHashMap0"/> 
@@ -1703,7 +1703,7 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1620719628/10001</string> 
+                     <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/712670663/10001</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -2183,6 +2183,26 @@
           </void> 
          </object> 
         </void> 
+        <void property="reversedExprs"> 
+         <object class="java.util.HashMap"> 
+          <void method="put"> 
+           <string>_col3</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col2</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col1</string> 
+           <byte>0</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col0</string> 
+           <byte>0</byte> 
+          </void> 
+         </object> 
+        </void> 
        </object> 
       </void> 
       <void property="parentOperators"> 
diff --git a/ql/src/test/results/compiler/plan/join6.q.xml b/ql/src/test/results/compiler/plan/join6.q.xml
index 2e3b5cbf2a..e2142066fd 100644
--- a/ql/src/test/results/compiler/plan/join6.q.xml
+++ b/ql/src/test/results/compiler/plan/join6.q.xml
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_07" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_03-p3" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-2</string> 
@@ -64,7 +64,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -132,7 +132,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -1643,7 +1643,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1658,7 +1658,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object idref="LinkedHashMap0"/> 
@@ -1703,7 +1703,7 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>file:/data/users/pchakka/workspace/oshive/build/ql/tmp/1670337258/10001</string> 
+                     <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/336278542/10001</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -2183,6 +2183,26 @@
           </void> 
          </object> 
         </void> 
+        <void property="reversedExprs"> 
+         <object class="java.util.HashMap"> 
+          <void method="put"> 
+           <string>_col3</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col2</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col1</string> 
+           <byte>0</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col0</string> 
+           <byte>0</byte> 
+          </void> 
+         </object> 
+        </void> 
        </object> 
       </void> 
       <void property="parentOperators"> 
diff --git a/ql/src/test/results/compiler/plan/join7.q.xml b/ql/src/test/results/compiler/plan/join7.q.xml
index e93bbd0a22..8d6e519204 100644
--- a/ql/src/test/results/compiler/plan/join7.q.xml
+++ b/ql/src/test/results/compiler/plan/join7.q.xml
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_07" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_03-p3" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-2</string> 
@@ -64,7 +64,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -132,7 +132,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -200,7 +200,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -2446,7 +2446,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -2464,7 +2464,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object idref="LinkedHashMap0"/> 
@@ -2509,7 +2509,7 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>file:/data/users/pchakka/workspace/oshive/build/ql/tmp/620356375/10001</string> 
+                     <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/2127603756/10001</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -3166,6 +3166,34 @@
           </void> 
          </object> 
         </void> 
+        <void property="reversedExprs"> 
+         <object class="java.util.HashMap"> 
+          <void method="put"> 
+           <string>_col5</string> 
+           <byte>2</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col4</string> 
+           <byte>2</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col3</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col2</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col1</string> 
+           <byte>0</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col0</string> 
+           <byte>0</byte> 
+          </void> 
+         </object> 
+        </void> 
        </object> 
       </void> 
       <void property="parentOperators"> 
diff --git a/ql/src/test/results/compiler/plan/join8.q.xml b/ql/src/test/results/compiler/plan/join8.q.xml
index 5c6893d167..4015afe3d3 100644
--- a/ql/src/test/results/compiler/plan/join8.q.xml
+++ b/ql/src/test/results/compiler/plan/join8.q.xml
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_07" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_03-p3" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-2</string> 
@@ -64,7 +64,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -132,7 +132,7 @@
            </void> 
            <void method="put"> 
             <string>location</string> 
-            <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+            <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
            </void> 
           </object> 
          </void> 
@@ -1643,7 +1643,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1658,7 +1658,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/pchakka/workspace/oshive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object idref="LinkedHashMap0"/> 
@@ -1707,7 +1707,7 @@
                       <void property="conf"> 
                        <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                         <void property="dirName"> 
-                         <string>file:/data/users/pchakka/workspace/oshive/build/ql/tmp/133283184/10001</string> 
+                         <string>file:/Users/char/Documents/workspace/Hive-460/build/ql/tmp/2060759954/10001</string> 
                         </void> 
                         <void property="tableInfo"> 
                          <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -2297,6 +2297,26 @@
           </void> 
          </object> 
         </void> 
+        <void property="reversedExprs"> 
+         <object class="java.util.HashMap"> 
+          <void method="put"> 
+           <string>_col3</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col2</string> 
+           <byte>1</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col1</string> 
+           <byte>0</byte> 
+          </void> 
+          <void method="put"> 
+           <string>_col0</string> 
+           <byte>0</byte> 
+          </void> 
+         </object> 
+        </void> 
        </object> 
       </void> 
       <void property="parentOperators"> 
