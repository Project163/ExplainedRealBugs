diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
index f8a0416839..523b25f823 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
@@ -267,7 +267,7 @@ public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException
    **/
   @VisibleForTesting
   public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {
-    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);
+    driverTxnHandler.endTransactionAndCleanup(commit, txnManager);
   }
 
   /**
@@ -402,7 +402,7 @@ private void compileInternal(String command, boolean deferClose) throws CommandP
         compile(command, true, deferClose);
       } catch (CommandProcessorException cpe) {
         try {
-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);
+          driverTxnHandler.endTransactionAndCleanup(false);
         } catch (LockException e) {
           LOG.warn("Exception in releasing locks. " + StringUtils.stringifyException(e));
         }
@@ -479,7 +479,7 @@ private void runInternal(String command, boolean alreadyCompiled) throws Command
           // Snapshot was outdated when locks were acquired, hence regenerate context,
           // txn list and retry (see ReExecutionRetryLockPlugin)
           try {
-            driverTxnHandler.releaseLocksAndCommitOrRollback(false);
+            driverTxnHandler.endTransactionAndCleanup(false);
           } catch (LockException e) {
             handleHiveException(e, 12);
           }
@@ -505,15 +505,15 @@ private void runInternal(String command, boolean alreadyCompiled) throws Command
         //since set autocommit starts an implicit txn, close it
         if (driverContext.getTxnManager().isImplicitTransactionOpen() ||
             driverContext.getPlan().getOperation() == HiveOperation.COMMIT) {
-          driverTxnHandler.releaseLocksAndCommitOrRollback(true);
+          driverTxnHandler.endTransactionAndCleanup(true);
         }
         else if(driverContext.getPlan().getOperation() == HiveOperation.ROLLBACK) {
-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);
+          driverTxnHandler.endTransactionAndCleanup(false);
         } else if (!driverContext.getTxnManager().isTxnOpen() &&
             driverContext.getQueryState().getHiveOperation() == HiveOperation.REPLLOAD) {
           // repl load during migration, commits the explicit txn and start some internal txns. Call
           // releaseLocksAndCommitOrRollback to do the clean up.
-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);
+          driverTxnHandler.endTransactionAndCleanup(false);
         } else {
           //txn (if there is one started) is not finished
         }
@@ -555,7 +555,7 @@ else if(driverContext.getPlan().getOperation() == HiveOperation.ROLLBACK) {
 
   private void rollback(CommandProcessorException cpe) throws CommandProcessorException {
     try {
-      driverTxnHandler.releaseLocksAndCommitOrRollback(false);
+      driverTxnHandler.endTransactionAndCleanup(false);
     } catch (LockException e) {
       LOG.error("rollback() FAILED: " + cpe); //make sure not to loose
       handleHiveException(e, 12, "Additional info in hive.log at \"rollback() FAILED\"");
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/DriverTxnHandler.java b/ql/src/java/org/apache/hadoop/hive/ql/DriverTxnHandler.java
index e3e6131ee2..b8648d9936 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/DriverTxnHandler.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/DriverTxnHandler.java
@@ -91,7 +91,7 @@ class DriverTxnHandler {
   private final List<HiveLock> hiveLocks = new ArrayList<HiveLock>();
 
   private Context context;
-  private Runnable shutdownRunner;
+  private Runnable txnRollbackRunner;
 
   DriverTxnHandler(Driver driver, DriverContext driverContext, DriverState driverState) {
     this.driverContext = driverContext;
@@ -112,19 +112,19 @@ void createTxnManager() throws CommandProcessorException {
 
       // In case when user Ctrl-C twice to kill Hive CLI JVM, we want to release locks
       // if compile is being called multiple times, clear the old shutdownhook
-      ShutdownHookManager.removeShutdownHook(shutdownRunner);
-      shutdownRunner = new Runnable() {
+      ShutdownHookManager.removeShutdownHook(txnRollbackRunner);
+      txnRollbackRunner = new Runnable() {
         @Override
         public void run() {
           try {
-            releaseLocksAndCommitOrRollback(false, driverContext.getTxnManager());
+            endTransactionAndCleanup(false, driverContext.getTxnManager());
           } catch (LockException e) {
             LOG.warn("Exception when releasing locks in ShutdownHook for Driver: " +
                 e.getMessage());
           }
         }
       };
-      ShutdownHookManager.addShutdownHook(shutdownRunner, SHUTDOWN_HOOK_PRIORITY);
+      ShutdownHookManager.addShutdownHook(txnRollbackRunner, SHUTDOWN_HOOK_PRIORITY);
     } catch (LockException e) {
       ErrorMsg error = ErrorMsg.getErrorMsg(e.getMessage());
       String errorMessage = "FAILED: " + e.getClass().getSimpleName() + " [Error "  + error.getErrorCode()  + "]:";
@@ -548,19 +548,21 @@ void destroy() {
   private void release(boolean releaseLocks) {
     if (releaseLocks) {
       try {
-        releaseLocksAndCommitOrRollback(false);
+        endTransactionAndCleanup(false);
       } catch (LockException e) {
         LOG.warn("Exception when releasing locking in destroy: " + e.getMessage());
       }
     }
-    ShutdownHookManager.removeShutdownHook(shutdownRunner);
+    ShutdownHookManager.removeShutdownHook(txnRollbackRunner);
   }
 
-  void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {
-    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());
+  void endTransactionAndCleanup(boolean commit) throws LockException {
+    endTransactionAndCleanup(commit, driverContext.getTxnManager());
+    ShutdownHookManager.removeShutdownHook(txnRollbackRunner);
+    txnRollbackRunner = null;
   }
 
-  void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {
+  void endTransactionAndCleanup(boolean commit, HiveTxnManager txnManager) throws LockException {
     PerfLogger perfLogger = SessionState.getPerfLogger();
     perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.RELEASE_LOCKS);
     
diff --git a/service/src/test/org/apache/hadoop/util/ShutdownHookManagerInspector.java b/service/src/test/org/apache/hadoop/util/ShutdownHookManagerInspector.java
new file mode 100644
index 0000000000..d360475fda
--- /dev/null
+++ b/service/src/test/org/apache/hadoop/util/ShutdownHookManagerInspector.java
@@ -0,0 +1,28 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.util;
+
+import java.util.List;
+
+public class ShutdownHookManagerInspector {
+
+  public static List<ShutdownHookManager.HookEntry> getShutdownHooksInOrder() {
+    return ShutdownHookManager.get().getShutdownHooksInOrder();
+  }
+}
diff --git a/service/src/test/org/apache/hive/service/cli/operation/TestQueryShutdownHooks.java b/service/src/test/org/apache/hive/service/cli/operation/TestQueryShutdownHooks.java
new file mode 100644
index 0000000000..ed2fd4d8c8
--- /dev/null
+++ b/service/src/test/org/apache/hive/service/cli/operation/TestQueryShutdownHooks.java
@@ -0,0 +1,181 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hive.service.cli.operation;
+
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
+import org.apache.hadoop.util.ShutdownHookManagerInspector;
+import org.apache.hive.service.cli.HiveSQLException;
+import org.apache.hive.service.cli.OperationHandle;
+import org.apache.hive.service.cli.OperationState;
+import org.apache.hive.service.cli.OperationStatus;
+import org.apache.hive.service.cli.SessionHandle;
+import org.apache.hive.service.cli.thrift.EmbeddedThriftBinaryCLIService;
+import org.apache.hive.service.cli.thrift.ThriftCLIServiceClient;
+import org.junit.Before;
+import org.junit.Test;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.fail;
+
+public class TestQueryShutdownHooks {
+
+  private EmbeddedThriftBinaryCLIService service;
+  private ThriftCLIServiceClient client;
+
+  @Before
+  public void setUp() throws Exception {
+
+    service = new EmbeddedThriftBinaryCLIService();
+    HiveConf hiveConf = new HiveConf();
+    hiveConf.setVar(HiveConf.ConfVars.HIVE_AUTHORIZATION_MANAGER,
+            "org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory");
+    hiveConf.setBoolVar(ConfVars.HIVE_SERVER2_ENABLE_DOAS, false);
+    hiveConf.setVar(ConfVars.HIVE_LOCK_MANAGER, "org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager");
+    service.init(hiveConf);
+    client = new ThriftCLIServiceClient(service);
+    SessionHandle tempSession = client.openSession("anonymous", "anonymous", new HashMap<>());
+    // any job causes creation of HadoopJobExecHelper's shutdown hook. It is once per JVM
+    // We want it to be created before we count the hooks so it does not cause off by one error in our count
+    client.executeStatement(tempSession, "select reflect(\"java.lang.System\", \"currentTimeMillis\")", new HashMap<>());
+    client.closeSession(tempSession);
+  }
+
+  @Test
+  public void testSync() throws Exception {
+    Map<String, String> opConf = new HashMap<String, String>();
+
+    SessionHandle sessHandle = client.openSession("anonymous",
+            "anonymous", opConf);
+
+    int shutdownHooksBeforeQueries = ShutdownHookManagerInspector.getShutdownHooksInOrder().size();
+
+    String[] someQueries = {
+            "CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)",
+            "INSERT INTO sample_shutdown_hook VALUES (1, 'a')",
+            "INSERT INTO sample_shutdown_hook VALUES (2, 'b')",
+            "INSERT INTO sample_shutdown_hook VALUES (3, 'c')",
+            "INSERT INTO sample_shutdown_hook VALUES (4, 'd')",
+            "INSERT INTO sample_shutdown_hook VALUES (5, 'e')",
+            "INSERT INTO sample_shutdown_hook VALUES (6, 'f')",
+            "INSERT INTO sample_shutdown_hook VALUES (7, 'g')",
+            "SELECT * FROM sample_shutdown_hook",
+            "DROP TABLE sample_shutdown_hook",
+    };
+    for (String queryStr : someQueries) {
+      OperationHandle opHandle = client.executeStatement(sessHandle, queryStr, opConf);
+      assertNotNull(opHandle);
+      OperationStatus opStatus = client.getOperationStatus(opHandle, false);
+      assertNotNull(opStatus);
+      OperationState state = opStatus.getState();
+      assertEquals("Query should be finished", OperationState.FINISHED, state);
+    }
+
+    int shutdownHooksAfterFinished = ShutdownHookManagerInspector.getShutdownHooksInOrder().size();
+
+    assertEquals(shutdownHooksBeforeQueries, shutdownHooksAfterFinished);
+
+    client.closeSession(sessHandle);
+  }
+
+  @Test
+  public void testAsync() throws Exception {
+    Map<String, String> opConf = new HashMap<String, String>();
+
+    SessionHandle sessHandle = client.openSession("anonymous", "anonymous", opConf);
+    int shutdownHooksBeforeQueries = ShutdownHookManagerInspector.getShutdownHooksInOrder().size();
+
+    String[] someQueries = {
+            "select reflect(\"java.lang.Thread\", \"sleep\", bigint(1000))",
+            "select reflect(\"java.lang.Thread\", \"sleep\", bigint(1000))",
+            "select reflect(\"java.lang.Thread\", \"sleep\", bigint(1000))",
+            "select reflect(\"java.lang.Thread\", \"sleep\", bigint(1000))"
+    };
+
+    List<OperationHandle> operationHandles = new ArrayList<>();
+    for (String queryStr : someQueries) {
+      OperationHandle opHandle = client.executeStatementAsync(sessHandle, queryStr, opConf);
+      assertNotNull(opHandle);
+      operationHandles.add(opHandle);
+    }
+
+    boolean allComplete = false;
+    final long step = 200;
+    final long timeout = System.currentTimeMillis() + 60000;
+
+    while (!allComplete) {
+      allComplete = true;
+      for (OperationHandle opHandle : operationHandles) {
+        OperationStatus operationStatus = client.getOperationStatus(opHandle, false);
+        if (operationStatus.getState() != OperationState.FINISHED) {
+          if (System.currentTimeMillis() > timeout) {
+            fail("Queries did not complete timely");
+          }
+          allComplete = false;
+          Thread.sleep(step);
+          break;
+        }
+      }
+    }
+
+    int shutdownHooksAfterFinished = ShutdownHookManagerInspector.getShutdownHooksInOrder().size();
+
+    assertEquals(shutdownHooksBeforeQueries, shutdownHooksAfterFinished);
+    client.closeSession(sessHandle);
+  }
+
+  @Test
+  public void testShutdownHookManagerIsRegistered() throws HiveSQLException, InterruptedException {
+    Map<String, String> opConf = new HashMap<String, String>();
+
+    SessionHandle sessHandle = client.openSession("anonymous", "anonymous", opConf);
+    int shutdownHooksBeforeQuery = ShutdownHookManagerInspector.getShutdownHooksInOrder().size();
+
+    String queryStr = "select reflect(\"java.lang.Thread\", \"sleep\", bigint(5000))";
+    OperationHandle opHandle = client.executeStatementAsync(sessHandle, queryStr, opConf);
+    assertNotNull(opHandle);
+
+    assertEquals(shutdownHooksBeforeQuery + 1, ShutdownHookManagerInspector.getShutdownHooksInOrder().size());
+
+    final long step = 200;
+    final long timeout = System.currentTimeMillis() + 60000;
+
+    while (true) {
+      OperationStatus operationStatus = client.getOperationStatus(opHandle, false);
+      if (operationStatus.getState() == OperationState.FINISHED) {
+        break;
+      }
+      if (System.currentTimeMillis() > timeout) {
+        fail("Query did not complete timely");
+      }
+      Thread.sleep(step);
+    }
+
+    int shutdownHooksAfterFinished = ShutdownHookManagerInspector.getShutdownHooksInOrder().size();
+
+    assertEquals(shutdownHooksBeforeQuery, shutdownHooksAfterFinished);
+    client.closeSession(sessHandle);
+  }
+}
