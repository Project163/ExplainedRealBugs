diff --git a/CHANGES.txt b/CHANGES.txt
index e5194f3a82..b0fcfb937e 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -255,3 +255,8 @@ Trunk (unreleased changes)
 
     HIVE-257. Set hive history log location to build for tests.
     (Suresh Anthony via athusoo)
+
+    HIVE-256. Fix in map side aggregation wherein we were not including
+    private members of the records in calculating the avg size of the
+    rows and we were also not estimating variable length columns 
+    properly. (Namit Jain via athusoo)
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java
index e745f65b94..7275739e58 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java
@@ -192,6 +192,7 @@ public void initialize(Configuration hconf, Reporter reporter) throws HiveExcept
       hashAggregations = new HashMap<ArrayList<Object>, UDAFEvaluator[]>();
       hashAggr = true;
       keyPositionsSize = new ArrayList<Integer>();
+      aggrPositions = new ArrayList<varLenFields>();
     }
 
     // init objectInspectors
@@ -326,11 +327,13 @@ private void estimateRowSize() {
     // Go over all the aggregation classes and and get the size of the fields of fixed length. Keep track of the variable length
     // fields in these aggregation classes.
     for(int i=0; i < aggregationClasses.length; i++) {
+
       fixedRowSize += javaObjectOverHead;
       Class<? extends UDAFEvaluator> agg = aggregationClasses[i];
-      Field[] fArr = agg.getFields();
-      for (Field f : fArr) 
-        fixedRowSize += getSize(i, agg, f);
+      Field[] fArr = agg.getDeclaredFields();
+      for (Field f : fArr) {
+        fixedRowSize += getSize(i, f.getType(), f);
+      }
     }
   }
 
@@ -486,7 +489,7 @@ private boolean shouldBeFlushed(ArrayList<Object> newKeys) {
     int numEntries = hashAggregations.size();
 
     // The fixed size for the aggregation class is already known. Get the variable portion of the size every NUMROWSESTIMATESIZE rows.
-    if ((numEntries % NUMROWSESTIMATESIZE) == 0) {
+    if ((numEntriesHashTable == 0) || ((numEntries % NUMROWSESTIMATESIZE) == 0)) {
       for (Integer pos : keyPositionsSize) {
         Object key = newKeys.get(pos.intValue());
         totalVariableSize += ((String)key).length();
@@ -511,6 +514,7 @@ private boolean shouldBeFlushed(ArrayList<Object> newKeys) {
       }
 
       numEntriesVarSize++;
+
       // Update the number of entries that can fit in the hash table
       numEntriesHashTable = (int)(maxHashTblMemory / (fixedRowSize + ((int)totalVariableSize/numEntriesVarSize)));
       LOG.trace("Hash Aggr: #hash table = " + numEntries + " #max in hash table = " + numEntriesHashTable);
