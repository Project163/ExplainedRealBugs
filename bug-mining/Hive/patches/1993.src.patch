diff --git a/itests/qtest/pom.xml b/itests/qtest/pom.xml
index c25f78812a..e17218c312 100644
--- a/itests/qtest/pom.xml
+++ b/itests/qtest/pom.xml
@@ -38,7 +38,7 @@
     <execute.beeline.tests>false</execute.beeline.tests>
     <minimr.query.files>stats_counter_partitioned.q,list_bucket_dml_10.q,input16_cc.q,scriptfile1.q,scriptfile1_win.q,bucket4.q,bucketmapjoin6.q,disable_merge_for_bucketing.q,reduce_deduplicate.q,smb_mapjoin_8.q,join1.q,groupby2.q,bucketizedhiveinputformat.q,bucketmapjoin7.q,optrstat_groupby.q,bucket_num_reducers.q,bucket5.q,load_fs2.q,bucket_num_reducers2.q,infer_bucket_sort_merge.q,infer_bucket_sort_reducers_power_two.q,infer_bucket_sort_dyn_part.q,infer_bucket_sort_bucketed_table.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_num_buckets.q,leftsemijoin_mr.q,schemeAuthority.q,schemeAuthority2.q,truncate_column_buckets.q,remote_script.q,,load_hdfs_file_with_space_in_the_name.q,parallel_orderby.q,import_exported_table.q,stats_counter.q,auto_sortmerge_join_16.q,quotedid_smb.q,file_with_header_footer.q,external_table_with_space_in_location_path.q,root_dir_external_table.q,index_bitmap3.q,ql_rewrite_gbtoidx.q,index_bitmap_auto.q,udf_using.q</minimr.query.files>
     <minimr.query.negative.files>cluster_tasklog_retrieval.q,minimr_broken_pipe.q,mapreduce_stack_trace.q,mapreduce_stack_trace_turnoff.q,mapreduce_stack_trace_hadoop20.q,mapreduce_stack_trace_turnoff_hadoop20.q,file_with_header_footer_negative.q,udf_local_resource.q</minimr.query.negative.files>
-    <minitez.query.files>tez_join_tests.q,tez_joins_explain.q,mrr.q,tez_dml.q,tez_insert_overwrite_local_directory_1.q,tez_union.q</minitez.query.files>
+    <minitez.query.files>mapjoin_decimal.q,tez_join_tests.q,tez_joins_explain.q,mrr.q,tez_dml.q,tez_insert_overwrite_local_directory_1.q,tez_union.q</minitez.query.files>
     <minitez.query.files.shared>orc_analyze.q,join0.q,join1.q,auto_join0.q,auto_join1.q,bucket2.q,bucket3.q,bucket4.q,count.q,create_merge_compressed.q,cross_join.q,ctas.q,custom_input_output_format.q,disable_merge_for_bucketing.q,enforce_order.q,filter_join_breaktask.q,filter_join_breaktask2.q,groupby1.q,groupby2.q,groupby3.q,having.q,insert1.q,insert_into1.q,insert_into2.q,leftsemijoin.q,limit_pushdown.q,load_dyn_part1.q,load_dyn_part2.q,load_dyn_part3.q,mapjoin_mapjoin.q,mapreduce1.q,mapreduce2.q,merge1.q,merge2.q,metadata_only_queries.q,sample1.q,subquery_in.q,subquery_exists.q,vectorization_15.q,ptf.q,stats_counter.q,stats_noscan_1.q,stats_counter_partitioned.q,union2.q,union3.q,union4.q,union5.q,union6.q,union7.q,union8.q,union9.q</minitez.query.files.shared>
     <beeline.positive.exclude>add_part_exist.q,alter1.q,alter2.q,alter4.q,alter5.q,alter_rename_partition.q,alter_rename_partition_authorization.q,archive.q,archive_corrupt.q,archive_multi.q,archive_mr_1806.q,archive_multi_mr_1806.q,authorization_1.q,authorization_2.q,authorization_4.q,authorization_5.q,authorization_6.q,authorization_7.q,ba_table1.q,ba_table2.q,ba_table3.q,ba_table_udfs.q,binary_table_bincolserde.q,binary_table_colserde.q,cluster.q,columnarserde_create_shortcut.q,combine2.q,constant_prop.q,create_nested_type.q,create_or_replace_view.q,create_struct_table.q,create_union_table.q,database.q,database_location.q,database_properties.q,ddltime.q,describe_database_json.q,drop_database_removes_partition_dirs.q,escape1.q,escape2.q,exim_00_nonpart_empty.q,exim_01_nonpart.q,exim_02_00_part_empty.q,exim_02_part.q,exim_03_nonpart_over_compat.q,exim_04_all_part.q,exim_04_evolved_parts.q,exim_05_some_part.q,exim_06_one_part.q,exim_07_all_part_over_nonoverlap.q,exim_08_nonpart_rename.q,exim_09_part_spec_nonoverlap.q,exim_10_external_managed.q,exim_11_managed_external.q,exim_12_external_location.q,exim_13_managed_location.q,exim_14_managed_location_over_existing.q,exim_15_external_part.q,exim_16_part_external.q,exim_17_part_managed.q,exim_18_part_external.q,exim_19_00_part_external_location.q,exim_19_part_external_location.q,exim_20_part_managed_location.q,exim_21_export_authsuccess.q,exim_22_import_exist_authsuccess.q,exim_23_import_part_authsuccess.q,exim_24_import_nonexist_authsuccess.q,global_limit.q,groupby_complex_types.q,groupby_complex_types_multi_single_reducer.q,index_auth.q,index_auto.q,index_auto_empty.q,index_bitmap.q,index_bitmap1.q,index_bitmap2.q,index_bitmap3.q,index_bitmap_auto.q,index_bitmap_rc.q,index_compact.q,index_compact_1.q,index_compact_2.q,index_compact_3.q,index_stale_partitioned.q,init_file.q,input16.q,input16_cc.q,input46.q,input_columnarserde.q,input_dynamicserde.q,input_lazyserde.q,input_testxpath3.q,input_testxpath4.q,insert2_overwrite_partitions.q,insertexternal1.q,join_thrift.q,lateral_view.q,load_binary_data.q,load_exist_part_authsuccess.q,load_nonpart_authsuccess.q,load_part_authsuccess.q,loadpart_err.q,lock1.q,lock2.q,lock3.q,lock4.q,merge_dynamic_partition.q,multi_insert.q,multi_insert_move_tasks_share_dependencies.q,null_column.q,ppd_clusterby.q,query_with_semi.q,rename_column.q,sample6.q,sample_islocalmode_hook.q,set_processor_namespaces.q,show_tables.q,source.q,split_sample.q,str_to_map.q,transform1.q,udaf_collect_set.q,udaf_context_ngrams.q,udaf_histogram_numeric.q,udaf_ngrams.q,udaf_percentile_approx.q,udf_array.q,udf_bitmap_and.q,udf_bitmap_or.q,udf_explode.q,udf_format_number.q,udf_map.q,udf_map_keys.q,udf_map_values.q,udf_max.q,udf_min.q,udf_named_struct.q,udf_percentile.q,udf_printf.q,udf_sentences.q,udf_sort_array.q,udf_split.q,udf_struct.q,udf_substr.q,udf_translate.q,udf_union.q,udf_xpath.q,udtf_stack.q,view.q,virtual_column.q</beeline.positive.exclude>
   </properties>
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinKey.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinKey.java
index a00aab393d..64f0be294b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinKey.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinKey.java
@@ -22,6 +22,7 @@
 import java.io.ObjectOutputStream;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.HashSet;
 import java.util.List;
 
 import org.apache.hadoop.hive.common.type.Decimal128;
@@ -38,6 +39,9 @@
 import org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils;
 import org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.StringWrapper;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;
 import org.apache.hadoop.hive.serde2.objectinspector.StructField;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 
@@ -57,7 +61,7 @@ public static MapJoinKey read(Output output, MapJoinKey key, MapJoinObjectSerDeC
     Object obj = serde.deserialize(writable);
     boolean useOptimized = useOptimizedKeyBasedOnPrev(key);
     if (useOptimized || key == null) {
-      byte[] structBytes = serializeKey(output, obj, serde.getObjectInspector());
+      byte[] structBytes = serializeKey(output, obj, serde.getObjectInspector(), !useOptimized);
       if (structBytes != null) {
         return MapJoinKeyBytes.fromBytes(key, mayReuseKey, structBytes);
       } else if (useOptimized) {
@@ -70,8 +74,29 @@ public static MapJoinKey read(Output output, MapJoinKey key, MapJoinObjectSerDeC
     return result;
   }
 
-  private static byte[] serializeKey(
-      Output byteStream, Object obj, ObjectInspector oi) throws SerDeException {
+  private static final HashSet<PrimitiveCategory> SUPPORTED_PRIMITIVES
+      = new HashSet<PrimitiveCategory>();
+  static {
+    // All but decimal.
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.BOOLEAN);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.VOID);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.BOOLEAN);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.BYTE);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.SHORT);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.INT);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.LONG);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.FLOAT);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.DOUBLE);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.STRING);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.DATE);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.TIMESTAMP);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.BINARY);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.VARCHAR);
+    SUPPORTED_PRIMITIVES.add(PrimitiveCategory.CHAR);
+  }
+
+  private static byte[] serializeKey(Output byteStream,
+      Object obj, ObjectInspector oi, boolean checkTypes) throws SerDeException {
     if (null == obj || !(oi instanceof StructObjectInspector)) {
       return null; // not supported
     }
@@ -87,8 +112,14 @@ private static byte[] serializeKey(
     List<ObjectInspector> fieldOis = new ArrayList<ObjectInspector>(size);
     for (int i = 0; i < size; ++i) {
       StructField field = fields.get(i);
+      ObjectInspector foi = field.getFieldObjectInspector();
+      if (checkTypes) {
+        if (foi.getCategory() != Category.PRIMITIVE) return null; // not supported
+        PrimitiveCategory pc = ((PrimitiveObjectInspector)foi).getPrimitiveCategory();
+        if (!SUPPORTED_PRIMITIVES.contains(pc)) return null; // not supported
+      }
       fieldData[i] = soi.getStructFieldData(obj, field);
-      fieldOis.add(field.getFieldObjectInspector());
+      fieldOis.add(foi);
     }
 
     return serializeRowCommon(byteStream, fieldData, fieldOis);
diff --git a/ql/src/test/queries/clientpositive/mapjoin_decimal.q b/ql/src/test/queries/clientpositive/mapjoin_decimal.q
new file mode 100644
index 0000000000..b65a7be2d2
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/mapjoin_decimal.q
@@ -0,0 +1,35 @@
+set hive.auto.convert.join=true;
+set hive.auto.convert.join.noconditionaltask=true;
+set hive.auto.convert.join.noconditionaltask.size=10000000;
+
+CREATE TABLE over1k(t tinyint,
+           si smallint,
+           i int,
+           b bigint,
+           f float,
+           d double,
+           bo boolean,
+           s string,
+           ts timestamp,
+           dec decimal(4,2),
+           bin binary)
+ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
+STORED AS TEXTFILE;
+
+LOAD DATA LOCAL INPATH '../../data/files/over1k' OVERWRITE INTO TABLE over1k;
+
+CREATE TABLE t1(dec decimal(4,2)) STORED AS ORC;
+INSERT INTO TABLE t1 select dec from over1k;
+CREATE TABLE t2(dec decimal(4,0)) STORED AS ORC;
+INSERT INTO TABLE t2 select dec from over1k;
+
+explain
+select t1.dec, t2.dec from t1 join t2 on (t1.dec=t2.dec);
+
+set hive.mapjoin.optimized.keys=false;
+
+select t1.dec, t2.dec from t1 join t2 on (t1.dec=t2.dec);
+
+set hive.mapjoin.optimized.keys=true;
+
+select t1.dec, t2.dec from t1 join t2 on (t1.dec=t2.dec);
\ No newline at end of file
diff --git a/ql/src/test/results/clientpositive/tez/mapjoin_decimal.q.out b/ql/src/test/results/clientpositive/tez/mapjoin_decimal.q.out
new file mode 100644
index 0000000000..3c55b5c407
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/mapjoin_decimal.q.out
@@ -0,0 +1,371 @@
+PREHOOK: query: CREATE TABLE over1k(t tinyint,
+           si smallint,
+           i int,
+           b bigint,
+           f float,
+           d double,
+           bo boolean,
+           s string,
+           ts timestamp,
+           dec decimal(4,2),
+           bin binary)
+ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
+STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+POSTHOOK: query: CREATE TABLE over1k(t tinyint,
+           si smallint,
+           i int,
+           b bigint,
+           f float,
+           d double,
+           bo boolean,
+           s string,
+           ts timestamp,
+           dec decimal(4,2),
+           bin binary)
+ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
+STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@over1k
+PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/over1k' OVERWRITE INTO TABLE over1k
+PREHOOK: type: LOAD
+#### A masked pattern was here ####
+PREHOOK: Output: default@over1k
+POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/over1k' OVERWRITE INTO TABLE over1k
+POSTHOOK: type: LOAD
+#### A masked pattern was here ####
+POSTHOOK: Output: default@over1k
+PREHOOK: query: CREATE TABLE t1(dec decimal(4,2)) STORED AS ORC
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+POSTHOOK: query: CREATE TABLE t1(dec decimal(4,2)) STORED AS ORC
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t1
+PREHOOK: query: INSERT INTO TABLE t1 select dec from over1k
+PREHOOK: type: QUERY
+PREHOOK: Input: default@over1k
+PREHOOK: Output: default@t1
+POSTHOOK: query: INSERT INTO TABLE t1 select dec from over1k
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@over1k
+POSTHOOK: Output: default@t1
+POSTHOOK: Lineage: t1.dec SIMPLE [(over1k)over1k.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
+PREHOOK: query: CREATE TABLE t2(dec decimal(4,0)) STORED AS ORC
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+POSTHOOK: query: CREATE TABLE t2(dec decimal(4,0)) STORED AS ORC
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t2
+POSTHOOK: Lineage: t1.dec SIMPLE [(over1k)over1k.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
+PREHOOK: query: INSERT INTO TABLE t2 select dec from over1k
+PREHOOK: type: QUERY
+PREHOOK: Input: default@over1k
+PREHOOK: Output: default@t2
+POSTHOOK: query: INSERT INTO TABLE t2 select dec from over1k
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@over1k
+POSTHOOK: Output: default@t2
+POSTHOOK: Lineage: t1.dec SIMPLE [(over1k)over1k.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
+POSTHOOK: Lineage: t2.dec EXPRESSION [(over1k)over1k.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
+PREHOOK: query: explain
+select t1.dec, t2.dec from t1 join t2 on (t1.dec=t2.dec)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+select t1.dec, t2.dec from t1 join t2 on (t1.dec=t2.dec)
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: t1.dec SIMPLE [(over1k)over1k.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
+POSTHOOK: Lineage: t2.dec EXPRESSION [(over1k)over1k.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Edges:
+        Map 2 <- Map 1 (BROADCAST_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: t2
+                  Statistics: Num rows: 1049 Data size: 117488 Basic stats: COMPLETE Column stats: NONE
+                  Reduce Output Operator
+                    key expressions: dec (type: decimal(4,0))
+                    sort order: +
+                    Map-reduce partition columns: dec (type: decimal(4,0))
+                    Statistics: Num rows: 1049 Data size: 117488 Basic stats: COMPLETE Column stats: NONE
+                    value expressions: dec (type: decimal(4,0))
+        Map 2 
+            Map Operator Tree:
+                TableScan
+                  alias: t1
+                  Statistics: Num rows: 1049 Data size: 117488 Basic stats: COMPLETE Column stats: NONE
+                  Map Join Operator
+                    condition map:
+                         Inner Join 0 to 1
+                    condition expressions:
+                      0 {dec}
+                      1 {dec}
+                    keys:
+                      0 dec (type: decimal(4,2))
+                      1 dec (type: decimal(4,0))
+                    outputColumnNames: _col0, _col3
+                    Statistics: Num rows: 1153 Data size: 129236 Basic stats: COMPLETE Column stats: NONE
+                    Select Operator
+                      expressions: _col0 (type: decimal(4,2)), _col3 (type: decimal(4,0))
+                      outputColumnNames: _col0, _col1
+                      Statistics: Num rows: 1153 Data size: 129236 Basic stats: COMPLETE Column stats: NONE
+                      File Output Operator
+                        compressed: false
+                        Statistics: Num rows: 1153 Data size: 129236 Basic stats: COMPLETE Column stats: NONE
+                        table:
+                            input format: org.apache.hadoop.mapred.TextInputFormat
+                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+PREHOOK: query: select t1.dec, t2.dec from t1 join t2 on (t1.dec=t2.dec)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t1
+PREHOOK: Input: default@t2
+#### A masked pattern was here ####
+POSTHOOK: query: select t1.dec, t2.dec from t1 join t2 on (t1.dec=t2.dec)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t1
+POSTHOOK: Input: default@t2
+#### A masked pattern was here ####
+POSTHOOK: Lineage: t1.dec SIMPLE [(over1k)over1k.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
+POSTHOOK: Lineage: t2.dec EXPRESSION [(over1k)over1k.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+45	45
+45	45
+45	45
+45	45
+45	45
+79	79
+79	79
+79	79
+79	79
+79	79
+79	79
+17	17
+17	17
+17	17
+17	17
+17	17
+17	17
+17	17
+17	17
+17	17
+17	17
+6	6
+6	6
+6	6
+6	6
+6	6
+6	6
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+70	70
+70	70
+70	70
+70	70
+70	70
+70	70
+70	70
+14	14
+14	14
+14	14
+14	14
+14	14
+14	14
+14	14
+14	14
+14	14
+PREHOOK: query: select t1.dec, t2.dec from t1 join t2 on (t1.dec=t2.dec)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t1
+PREHOOK: Input: default@t2
+#### A masked pattern was here ####
+POSTHOOK: query: select t1.dec, t2.dec from t1 join t2 on (t1.dec=t2.dec)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t1
+POSTHOOK: Input: default@t2
+#### A masked pattern was here ####
+POSTHOOK: Lineage: t1.dec SIMPLE [(over1k)over1k.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
+POSTHOOK: Lineage: t2.dec EXPRESSION [(over1k)over1k.FieldSchema(name:dec, type:decimal(4,2), comment:null), ]
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+9	9
+45	45
+45	45
+45	45
+45	45
+45	45
+79	79
+79	79
+79	79
+79	79
+79	79
+79	79
+17	17
+17	17
+17	17
+17	17
+17	17
+17	17
+17	17
+17	17
+17	17
+17	17
+6	6
+6	6
+6	6
+6	6
+6	6
+6	6
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+62	62
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+64	64
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+89	89
+70	70
+70	70
+70	70
+70	70
+70	70
+70	70
+70	70
+14	14
+14	14
+14	14
+14	14
+14	14
+14	14
+14	14
+14	14
+14	14
