diff --git a/accumulo-handler/src/test/results/positive/accumulo_joins.q.out b/accumulo-handler/src/test/results/positive/accumulo_joins.q.out
index e0b66323b1..5f11f94b4e 100644
--- a/accumulo-handler/src/test/results/positive/accumulo_joins.q.out
+++ b/accumulo-handler/src/test/results/positive/accumulo_joins.q.out
@@ -14,9 +14,7 @@ PREHOOK: query: DROP TABLE users_level
 PREHOOK: type: DROPTABLE
 POSTHOOK: query: DROP TABLE users_level
 POSTHOOK: type: DROPTABLE
-PREHOOK: query: -- From HIVE-1257
-
-CREATE TABLE users(key string, state string, country string, country_id int)
+PREHOOK: query: CREATE TABLE users(key string, state string, country string, country_id int)
 STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
 WITH SERDEPROPERTIES (
 "accumulo.columns.mapping" = ":rowID,info:state,info:country,info:country_id"
@@ -24,9 +22,7 @@ WITH SERDEPROPERTIES (
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@users
-POSTHOOK: query: -- From HIVE-1257
-
-CREATE TABLE users(key string, state string, country string, country_id int)
+POSTHOOK: query: CREATE TABLE users(key string, state string, country string, country_id int)
 STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
 WITH SERDEPROPERTIES (
 "accumulo.columns.mapping" = ":rowID,info:state,info:country,info:country_id"
@@ -246,18 +242,14 @@ WITH SERDEPROPERTIES ("accumulo.columns.mapping" = ":rowID,f:userid,f:level")
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@users_level
-PREHOOK: query: -- HIVE-1903:  the problem fixed here showed up even without any data,
--- so no need to load any to test it
-SELECT year(from_unixtime(users.created)) AS year, level, count(users.userid) AS num 
+PREHOOK: query: SELECT year(from_unixtime(users.created)) AS year, level, count(users.userid) AS num 
  FROM users JOIN users_level ON (users.userid = users_level.userid) 
  GROUP BY year(from_unixtime(users.created)), level
 PREHOOK: type: QUERY
 PREHOOK: Input: default@users
 PREHOOK: Input: default@users_level
 #### A masked pattern was here ####
-POSTHOOK: query: -- HIVE-1903:  the problem fixed here showed up even without any data,
--- so no need to load any to test it
-SELECT year(from_unixtime(users.created)) AS year, level, count(users.userid) AS num 
+POSTHOOK: query: SELECT year(from_unixtime(users.created)) AS year, level, count(users.userid) AS num 
  FROM users JOIN users_level ON (users.userid = users_level.userid) 
  GROUP BY year(from_unixtime(users.created)), level
 POSTHOOK: type: QUERY
diff --git a/accumulo-handler/src/test/results/positive/accumulo_predicate_pushdown.q.out b/accumulo-handler/src/test/results/positive/accumulo_predicate_pushdown.q.out
index fc4f9aa5fc..93b10a86ab 100644
--- a/accumulo-handler/src/test/results/positive/accumulo_predicate_pushdown.q.out
+++ b/accumulo-handler/src/test/results/positive/accumulo_predicate_pushdown.q.out
@@ -22,11 +22,9 @@ FROM src
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Output: default@accumulo_pushdown
-PREHOOK: query: -- with full pushdown
-explain select * from accumulo_pushdown where key>'90'
+PREHOOK: query: explain select * from accumulo_pushdown where key>'90'
 PREHOOK: type: QUERY
-POSTHOOK: query: -- with full pushdown
-explain select * from accumulo_pushdown where key>'90'
+POSTHOOK: query: explain select * from accumulo_pushdown where key>'90'
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
   Stage-0 is a root stage
@@ -163,11 +161,9 @@ POSTHOOK: Input: default@accumulo_pushdown
 96	val_96
 97	val_97
 98	val_98
-PREHOOK: query: -- with constant expression
-explain select * from accumulo_pushdown where key>=cast(40 + 50 as string)
+PREHOOK: query: explain select * from accumulo_pushdown where key>=cast(40 + 50 as string)
 PREHOOK: type: QUERY
-POSTHOOK: query: -- with constant expression
-explain select * from accumulo_pushdown where key>=cast(40 + 50 as string)
+POSTHOOK: query: explain select * from accumulo_pushdown where key>=cast(40 + 50 as string)
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
   Stage-0 is a root stage
@@ -201,13 +197,9 @@ POSTHOOK: Input: default@accumulo_pushdown
 96	val_96
 97	val_97
 98	val_98
-PREHOOK: query: -- with partial pushdown
-
-explain select * from accumulo_pushdown where key>'90' and value like '%9%'
+PREHOOK: query: explain select * from accumulo_pushdown where key>'90' and value like '%9%'
 PREHOOK: type: QUERY
-POSTHOOK: query: -- with partial pushdown
-
-explain select * from accumulo_pushdown where key>'90' and value like '%9%'
+POSTHOOK: query: explain select * from accumulo_pushdown where key>'90' and value like '%9%'
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
@@ -255,14 +247,10 @@ POSTHOOK: Input: default@accumulo_pushdown
 96	val_96
 97	val_97
 98	val_98
-PREHOOK: query: -- with two residuals
-
-explain select * from accumulo_pushdown
+PREHOOK: query: explain select * from accumulo_pushdown
 where key>='90' and value like '%9%' and key=cast(value as int)
 PREHOOK: type: QUERY
-POSTHOOK: query: -- with two residuals
-
-explain select * from accumulo_pushdown
+POSTHOOK: query: explain select * from accumulo_pushdown
 where key>='90' and value like '%9%' and key=cast(value as int)
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
@@ -308,14 +296,10 @@ where key>='90' and value like '%9%' and key=cast(value as int)
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@accumulo_pushdown
 #### A masked pattern was here ####
-PREHOOK: query: -- with contradictory pushdowns
-
-explain select * from accumulo_pushdown
+PREHOOK: query: explain select * from accumulo_pushdown
 where key<'80' and key>'90' and value like '%90%'
 PREHOOK: type: QUERY
-POSTHOOK: query: -- with contradictory pushdowns
-
-explain select * from accumulo_pushdown
+POSTHOOK: query: explain select * from accumulo_pushdown
 where key<'80' and key>'90' and value like '%90%'
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
@@ -361,13 +345,9 @@ where key<'80' and key>'90' and value like '%90%'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@accumulo_pushdown
 #### A masked pattern was here ####
-PREHOOK: query: -- with nothing to push down
-
-explain select * from accumulo_pushdown
+PREHOOK: query: explain select * from accumulo_pushdown
 PREHOOK: type: QUERY
-POSTHOOK: query: -- with nothing to push down
-
-explain select * from accumulo_pushdown
+POSTHOOK: query: explain select * from accumulo_pushdown
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
   Stage-0 is a root stage
@@ -386,16 +366,10 @@ STAGE PLANS:
             Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
             ListSink
 
-PREHOOK: query: -- with a predicate which is not actually part of the filter, so
--- it should be ignored by pushdown
-
-explain select * from accumulo_pushdown
+PREHOOK: query: explain select * from accumulo_pushdown
 where (case when key<'90' then 2 else 4 end) > 3
 PREHOOK: type: QUERY
-POSTHOOK: query: -- with a predicate which is not actually part of the filter, so
--- it should be ignored by pushdown
-
-explain select * from accumulo_pushdown
+POSTHOOK: query: explain select * from accumulo_pushdown
 where (case when key<'90' then 2 else 4 end) > 3
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
@@ -430,16 +404,10 @@ STAGE PLANS:
       Processor Tree:
         ListSink
 
-PREHOOK: query: -- with a predicate which is under an OR, so it should
--- be ignored by pushdown
-
-explain select * from accumulo_pushdown
+PREHOOK: query: explain select * from accumulo_pushdown
 where key<='80' or value like '%90%'
 PREHOOK: type: QUERY
-POSTHOOK: query: -- with a predicate which is under an OR, so it should
--- be ignored by pushdown
-
-explain select * from accumulo_pushdown
+POSTHOOK: query: explain select * from accumulo_pushdown
 where key<='80' or value like '%90%'
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
@@ -513,13 +481,9 @@ POSTHOOK: Input: default@accumulo_pushdown
 284	val_284
 285	val_285
 286	val_286
-PREHOOK: query: -- with pushdown disabled
-
-explain select * from accumulo_pushdown where key<='90'
+PREHOOK: query: explain select * from accumulo_pushdown where key<='90'
 PREHOOK: type: QUERY
-POSTHOOK: query: -- with pushdown disabled
-
-explain select * from accumulo_pushdown where key<='90'
+POSTHOOK: query: explain select * from accumulo_pushdown where key<='90'
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
diff --git a/accumulo-handler/src/test/results/positive/accumulo_single_sourced_multi_insert.q.out b/accumulo-handler/src/test/results/positive/accumulo_single_sourced_multi_insert.q.out
index 5d0d78804b..55e71767b3 100644
--- a/accumulo-handler/src/test/results/positive/accumulo_single_sourced_multi_insert.q.out
+++ b/accumulo-handler/src/test/results/positive/accumulo_single_sourced_multi_insert.q.out
@@ -1,10 +1,8 @@
-PREHOOK: query: -- HIVE-4375 Single sourced multi insert consists of native and non-native table mixed throws NPE
-CREATE TABLE src_x1(key string, value string)
+PREHOOK: query: CREATE TABLE src_x1(key string, value string)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@src_x1
-POSTHOOK: query: -- HIVE-4375 Single sourced multi insert consists of native and non-native table mixed throws NPE
-CREATE TABLE src_x1(key string, value string)
+POSTHOOK: query: CREATE TABLE src_x1(key string, value string)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@src_x1
diff --git a/contrib/src/test/results/clientnegative/case_with_row_sequence.q.out b/contrib/src/test/results/clientnegative/case_with_row_sequence.q.out
index 31fb030091..9ee319f9c2 100644
--- a/contrib/src/test/results/clientnegative/case_with_row_sequence.q.out
+++ b/contrib/src/test/results/clientnegative/case_with_row_sequence.q.out
@@ -10,9 +10,7 @@ POSTHOOK: query: create temporary function row_sequence as
 'org.apache.hadoop.hive.contrib.udf.UDFRowSequence'
 POSTHOOK: type: CREATEFUNCTION
 POSTHOOK: Output: row_sequence
-PREHOOK: query: -- make sure a stateful function inside of CASE throws an exception
--- since the short-circuiting requirements are contradictory
-SELECT CASE WHEN 3 > 2 THEN 10 WHEN row_sequence() > 5 THEN 20 ELSE 30 END
+PREHOOK: query: SELECT CASE WHEN 3 > 2 THEN 10 WHEN row_sequence() > 5 THEN 20 ELSE 30 END
 FROM src LIMIT 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
diff --git a/contrib/src/test/results/clientnegative/invalid_row_sequence.q.out b/contrib/src/test/results/clientnegative/invalid_row_sequence.q.out
index 15b96c266e..dc16e406ba 100644
--- a/contrib/src/test/results/clientnegative/invalid_row_sequence.q.out
+++ b/contrib/src/test/results/clientnegative/invalid_row_sequence.q.out
@@ -1,10 +1,6 @@
-PREHOOK: query: -- Verify that a stateful UDF cannot be used outside of the SELECT list
-
-drop temporary function row_sequence
+PREHOOK: query: drop temporary function row_sequence
 PREHOOK: type: DROPFUNCTION
-POSTHOOK: query: -- Verify that a stateful UDF cannot be used outside of the SELECT list
-
-drop temporary function row_sequence
+POSTHOOK: query: drop temporary function row_sequence
 POSTHOOK: type: DROPFUNCTION
 PREHOOK: query: create temporary function row_sequence as 
 'org.apache.hadoop.hive.contrib.udf.UDFRowSequence'
diff --git a/contrib/src/test/results/clientnegative/serde_regex.q.out b/contrib/src/test/results/clientnegative/serde_regex.q.out
index 0f9b036a9f..58b1c02d12 100644
--- a/contrib/src/test/results/clientnegative/serde_regex.q.out
+++ b/contrib/src/test/results/clientnegative/serde_regex.q.out
@@ -4,8 +4,7 @@ PREHOOK: Input: database:default
 POSTHOOK: query: USE default
 POSTHOOK: type: SWITCHDATABASE
 POSTHOOK: Input: database:default
-PREHOOK: query: --  This should fail because Regex SerDe supports only columns of type string
-EXPLAIN
+PREHOOK: query: EXPLAIN
 CREATE TABLE serde_regex(
   host STRING,
   identity STRING,
@@ -23,8 +22,7 @@ WITH SERDEPROPERTIES (
 )
 STORED AS TEXTFILE
 PREHOOK: type: CREATETABLE
-POSTHOOK: query: --  This should fail because Regex SerDe supports only columns of type string
-EXPLAIN
+POSTHOOK: query: EXPLAIN
 CREATE TABLE serde_regex(
   host STRING,
   identity STRING,
diff --git a/contrib/src/test/results/clientpositive/dboutput.q.out b/contrib/src/test/results/clientpositive/dboutput.q.out
index fb985ea5d9..442a98a73d 100644
--- a/contrib/src/test/results/clientpositive/dboutput.q.out
+++ b/contrib/src/test/results/clientpositive/dboutput.q.out
@@ -24,7 +24,7 @@ Function class:org.apache.hadoop.hive.contrib.genericudf.example.GenericUDFDBOut
 Function type:TEMPORARY
 PREHOOK: query: EXPLAIN FROM src
 
-SELECT dboutput ( 'jdbc:derby:../build/test_dboutput_db;create=true','','',
+SELECT dboutput ( 'jdbc:derby:../build/test_dboutput_db\;create=true','','',
 'CREATE TABLE app_info ( kkey VARCHAR(255) NOT NULL, vvalue VARCHAR(255) NOT NULL, UNIQUE(kkey))' ),
 
 dboutput('jdbc:derby:../build/test_dboutput_db','','',
@@ -37,7 +37,7 @@ limit 1
 PREHOOK: type: QUERY
 POSTHOOK: query: EXPLAIN FROM src
 
-SELECT dboutput ( 'jdbc:derby:../build/test_dboutput_db;create=true','','',
+SELECT dboutput ( 'jdbc:derby:../build/test_dboutput_db\;create=true','','',
 'CREATE TABLE app_info ( kkey VARCHAR(255) NOT NULL, vvalue VARCHAR(255) NOT NULL, UNIQUE(kkey))' ),
 
 dboutput('jdbc:derby:../build/test_dboutput_db','','',
@@ -82,7 +82,7 @@ STAGE PLANS:
 
 PREHOOK: query: FROM src 
 
-SELECT dboutput ( 'jdbc:derby:../build/test_dboutput_db;create=true','','',
+SELECT dboutput ( 'jdbc:derby:../build/test_dboutput_db\;create=true','','',
 'CREATE TABLE app_info ( kkey INTEGER NOT NULL, vvalue VARCHAR(255) NOT NULL, UNIQUE(kkey))' ),
 
 dboutput('jdbc:derby:../build/test_dboutput_db','','',
@@ -97,7 +97,7 @@ PREHOOK: Input: default@src
 #### A masked pattern was here ####
 POSTHOOK: query: FROM src 
 
-SELECT dboutput ( 'jdbc:derby:../build/test_dboutput_db;create=true','','',
+SELECT dboutput ( 'jdbc:derby:../build/test_dboutput_db\;create=true','','',
 'CREATE TABLE app_info ( kkey INTEGER NOT NULL, vvalue VARCHAR(255) NOT NULL, UNIQUE(kkey))' ),
 
 dboutput('jdbc:derby:../build/test_dboutput_db','','',
diff --git a/contrib/src/test/results/clientpositive/fileformat_base64.q.out b/contrib/src/test/results/clientpositive/fileformat_base64.q.out
index 1be29952d7..7fd0ede284 100644
--- a/contrib/src/test/results/clientpositive/fileformat_base64.q.out
+++ b/contrib/src/test/results/clientpositive/fileformat_base64.q.out
@@ -78,19 +78,13 @@ POSTHOOK: Input: default@base64_test
 2	val_2
 5	val_5
 9	val_9
-PREHOOK: query: -- Base64TextInput/OutputFormat supports signature (a prefix to check the validity of
--- the data). These queries test that prefix capabilities.
-
-FROM src
+PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE base64_test
 SELECT key, value WHERE key < 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Output: default@base64_test
-POSTHOOK: query: -- Base64TextInput/OutputFormat supports signature (a prefix to check the validity of
--- the data). These queries test that prefix capabilities.
-
-FROM src
+POSTHOOK: query: FROM src
 INSERT OVERWRITE TABLE base64_test
 SELECT key, value WHERE key < 10
 POSTHOOK: type: QUERY
diff --git a/contrib/src/test/results/clientpositive/udf_row_sequence.q.out b/contrib/src/test/results/clientpositive/udf_row_sequence.q.out
index 65c773241f..9715c75dcb 100644
--- a/contrib/src/test/results/clientpositive/udf_row_sequence.q.out
+++ b/contrib/src/test/results/clientpositive/udf_row_sequence.q.out
@@ -1,14 +1,6 @@
-PREHOOK: query: -- The ORDER BY on the outer query will typically have no effect,
--- but there is really no guarantee that the ordering is preserved
--- across various SQL operators.
-
-drop temporary function row_sequence
+PREHOOK: query: drop temporary function row_sequence
 PREHOOK: type: DROPFUNCTION
-POSTHOOK: query: -- The ORDER BY on the outer query will typically have no effect,
--- but there is really no guarantee that the ordering is preserved
--- across various SQL operators.
-
-drop temporary function row_sequence
+POSTHOOK: query: drop temporary function row_sequence
 POSTHOOK: type: DROPFUNCTION
 PREHOOK: query: create temporary function row_sequence as 
 'org.apache.hadoop.hive.contrib.udf.UDFRowSequence'
@@ -586,17 +578,13 @@ POSTHOOK: Input: default@src
 400	498
 200	499
 97	500
-PREHOOK: query: -- make sure stateful functions do not get short-circuited away
--- a true result for key=105 would indicate undesired short-circuiting
-select key, (key = 105) and (row_sequence() = 1)
+PREHOOK: query: select key, (key = 105) and (row_sequence() = 1)
 from (select key from src order by key) x
 order by key limit 20
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 #### A masked pattern was here ####
-POSTHOOK: query: -- make sure stateful functions do not get short-circuited away
--- a true result for key=105 would indicate undesired short-circuiting
-select key, (key = 105) and (row_sequence() = 1)
+POSTHOOK: query: select key, (key = 105) and (row_sequence() = 1)
 from (select key from src order by key) x
 order by key limit 20
 POSTHOOK: type: QUERY
diff --git a/contrib/src/test/results/clientpositive/url_hook.q.out b/contrib/src/test/results/clientpositive/url_hook.q.out
index ca04d15320..55e4b3cff8 100644
--- a/contrib/src/test/results/clientpositive/url_hook.q.out
+++ b/contrib/src/test/results/clientpositive/url_hook.q.out
@@ -5,11 +5,9 @@ POSTHOOK: query: SHOW TABLES 'src'
 POSTHOOK: type: SHOWTABLES
 POSTHOOK: Input: database:default
 src
-PREHOOK: query: -- changes to dummy derby store.. should return empty result
-SHOW TABLES 'src'
+PREHOOK: query: SHOW TABLES 'src'
 PREHOOK: type: SHOWTABLES
 PREHOOK: Input: database:default
-POSTHOOK: query: -- changes to dummy derby store.. should return empty result
-SHOW TABLES 'src'
+POSTHOOK: query: SHOW TABLES 'src'
 POSTHOOK: type: SHOWTABLES
 POSTHOOK: Input: database:default
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/ctas.q.out b/itests/hive-blobstore/src/test/results/clientpositive/ctas.q.out
index 9f25b26213..0c91fee23b 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/ctas.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/ctas.q.out
@@ -37,11 +37,9 @@ POSTHOOK: query: INSERT INTO TABLE ctas_hdfs_table_src VALUES (1), (2), (3)
 POSTHOOK: type: QUERY
 POSTHOOK: Output: default@ctas_hdfs_table_src
 POSTHOOK: Lineage: ctas_hdfs_table_src.col EXPRESSION [(values__tmp__table__2)values__tmp__table__2.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
-PREHOOK: query: -- Test select from a Blobstore and write to HDFS
-DROP TABLE IF EXISTS ctas_hdfs_table_dst
+PREHOOK: query: DROP TABLE IF EXISTS ctas_hdfs_table_dst
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Test select from a Blobstore and write to HDFS
-DROP TABLE IF EXISTS ctas_hdfs_table_dst
+POSTHOOK: query: DROP TABLE IF EXISTS ctas_hdfs_table_dst
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: EXPLAIN EXTENDED CREATE TABLE ctas_hdfs_table_dst AS SELECT * FROM ctas_blobstore_table_src
 PREHOOK: type: CREATETABLE_AS_SELECT
@@ -301,11 +299,9 @@ POSTHOOK: Input: default@ctas_hdfs_table_dst
 1
 2
 3
-PREHOOK: query: -- Test select from HDFS and write to a Blobstore
-DROP TABLE IF EXISTS ctas_blobstore_table_dst
+PREHOOK: query: DROP TABLE IF EXISTS ctas_blobstore_table_dst
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Test select from HDFS and write to a Blobstore
-DROP TABLE IF EXISTS ctas_blobstore_table_dst
+POSTHOOK: query: DROP TABLE IF EXISTS ctas_blobstore_table_dst
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE_AS_SELECT
@@ -573,13 +569,11 @@ POSTHOOK: Input: default@ctas_blobstore_table_dst
 1
 2
 3
-PREHOOK: query: -- Test select from a Blobstore and write to a Blobstore
-DROP TABLE IF EXISTS ctas_blobstore_table_dst
+PREHOOK: query: DROP TABLE IF EXISTS ctas_blobstore_table_dst
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@ctas_blobstore_table_dst
 PREHOOK: Output: default@ctas_blobstore_table_dst
-POSTHOOK: query: -- Test select from a Blobstore and write to a Blobstore
-DROP TABLE IF EXISTS ctas_blobstore_table_dst
+POSTHOOK: query: DROP TABLE IF EXISTS ctas_blobstore_table_dst
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@ctas_blobstore_table_dst
 POSTHOOK: Output: default@ctas_blobstore_table_dst
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/insert_into_dynamic_partitions.q.out b/itests/hive-blobstore/src/test/results/clientpositive/insert_into_dynamic_partitions.q.out
index d7613f3b02..6983d99178 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/insert_into_dynamic_partitions.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/insert_into_dynamic_partitions.q.out
@@ -1,8 +1,6 @@
-PREHOOK: query: -- Single partition with buckets
-DROP TABLE table1
+PREHOOK: query: DROP TABLE table1
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Single partition with buckets
-DROP TABLE table1
+POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
@@ -216,13 +214,11 @@ POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@table1
 POSTHOOK: Output: default@table1
-PREHOOK: query: -- Multiple partitions
-CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
+PREHOOK: query: CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@table1
-POSTHOOK: query: -- Multiple partitions
-CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
+POSTHOOK: query: CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@table1
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/insert_into_table.q.out b/itests/hive-blobstore/src/test/results/clientpositive/insert_into_table.q.out
index fe7fdb0312..3f9ce9188c 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/insert_into_table.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/insert_into_table.q.out
@@ -1,8 +1,6 @@
-PREHOOK: query: -- Insert unpartitioned table;
-DROP TABLE table1
+PREHOOK: query: DROP TABLE table1
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Insert unpartitioned table;
-DROP TABLE table1
+POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_directory.q.out b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_directory.q.out
index 82fb95d6f7..7d8d6c8ee5 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_directory.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_directory.q.out
@@ -1,8 +1,6 @@
-PREHOOK: query: -- Create a simple source table;
-DROP TABLE table1
+PREHOOK: query: DROP TABLE table1
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Create a simple source table;
-DROP TABLE table1
+POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: CREATE TABLE table1 (id int, key string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
 PREHOOK: type: CREATETABLE
@@ -28,28 +26,24 @@ POSTHOOK: type: QUERY
 POSTHOOK: Output: default@table1
 POSTHOOK: Lineage: table1.id EXPRESSION [(values__tmp__table__2)values__tmp__table__2.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
 POSTHOOK: Lineage: table1.key SIMPLE [(values__tmp__table__2)values__tmp__table__2.FieldSchema(name:tmp_values_col2, type:string, comment:), ]
-PREHOOK: query: -- Write and verify data on the directory;
-INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
+PREHOOK: query: INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@table1
 PREHOOK: Output: ### test.blobstore.path ###/table1.dir
-POSTHOOK: query: -- Write and verify data on the directory;
-INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
+POSTHOOK: query: INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@table1
 POSTHOOK: Output: ### test.blobstore.path ###/table1.dir
 1k1
 2k2
-PREHOOK: query: -- Write and verify data using FROM ... INSERT OVERWRITE DIRECTORY;
-FROM table1
+PREHOOK: query: FROM table1
 INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT id
 INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table2.dir/' SELECT key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@table1
 PREHOOK: Output: ### test.blobstore.path ###/table1.dir
 PREHOOK: Output: ### test.blobstore.path ###/table2.dir
-POSTHOOK: query: -- Write and verify data using FROM ... INSERT OVERWRITE DIRECTORY;
-FROM table1
+POSTHOOK: query: FROM table1
 INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT id
 INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table2.dir/' SELECT key
 POSTHOOK: type: QUERY
@@ -60,11 +54,9 @@ POSTHOOK: Output: ### test.blobstore.path ###/table2.dir
 2
 k1
 k2
-PREHOOK: query: -- Verify plan is optimizedl
-EXPLAIN EXTENDED INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
+PREHOOK: query: EXPLAIN EXTENDED INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
 PREHOOK: type: QUERY
-POSTHOOK: query: -- Verify plan is optimizedl
-EXPLAIN EXTENDED INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
+POSTHOOK: query: EXPLAIN EXTENDED INSERT OVERWRITE DIRECTORY '### test.blobstore.path ###/table1.dir/' SELECT * FROM table1
 POSTHOOK: type: QUERY
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_dynamic_partitions.q.out b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_dynamic_partitions.q.out
index 4d0c1535ee..48adac0943 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_dynamic_partitions.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_dynamic_partitions.q.out
@@ -1,8 +1,6 @@
-PREHOOK: query: -- Single partition with buckets
-DROP TABLE table1
+PREHOOK: query: DROP TABLE table1
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Single partition with buckets
-DROP TABLE table1
+POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
@@ -234,13 +232,11 @@ POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@table1
 POSTHOOK: Output: default@table1
-PREHOOK: query: -- Multiple partitions
-CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
+PREHOOK: query: CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@table1
-POSTHOOK: query: -- Multiple partitions
-CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
+POSTHOOK: query: CREATE TABLE table1 (name string, age int) PARTITIONED BY (country string, state string)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@table1
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_table.q.out b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_table.q.out
index 82ae25f315..5eff2af170 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_table.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/insert_overwrite_table.q.out
@@ -1,8 +1,6 @@
-PREHOOK: query: -- Insert unpartitioned table;
-DROP TABLE table1
+PREHOOK: query: DROP TABLE table1
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Insert unpartitioned table;
-DROP TABLE table1
+POSTHOOK: query: DROP TABLE table1
 POSTHOOK: type: DROPTABLE
 #### A masked pattern was here ####
 PREHOOK: type: CREATETABLE
diff --git a/itests/hive-blobstore/src/test/results/clientpositive/write_final_output_blobstore.q.out b/itests/hive-blobstore/src/test/results/clientpositive/write_final_output_blobstore.q.out
index 1b1ea971d0..e48647fa78 100644
--- a/itests/hive-blobstore/src/test/results/clientpositive/write_final_output_blobstore.q.out
+++ b/itests/hive-blobstore/src/test/results/clientpositive/write_final_output_blobstore.q.out
@@ -1,24 +1,16 @@
-PREHOOK: query: -- Test that the when multiple MR jobs are created for a query, that only the FSOP from the last job writes to S3
-
--- Drop tables
-DROP TABLE IF EXISTS hdfs_table
+PREHOOK: query: DROP TABLE IF EXISTS hdfs_table
 PREHOOK: type: DROPTABLE
-POSTHOOK: query: -- Test that the when multiple MR jobs are created for a query, that only the FSOP from the last job writes to S3
-
--- Drop tables
-DROP TABLE IF EXISTS hdfs_table
+POSTHOOK: query: DROP TABLE IF EXISTS hdfs_table
 POSTHOOK: type: DROPTABLE
 PREHOOK: query: DROP TABLE IF EXISTS blobstore_table
 PREHOOK: type: DROPTABLE
 POSTHOOK: query: DROP TABLE IF EXISTS blobstore_table
 POSTHOOK: type: DROPTABLE
-PREHOOK: query: -- Create a table one table on HDFS and another on S3
-CREATE TABLE hdfs_table(key INT)
+PREHOOK: query: CREATE TABLE hdfs_table(key INT)
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@hdfs_table
-POSTHOOK: query: -- Create a table one table on HDFS and another on S3
-CREATE TABLE hdfs_table(key INT)
+POSTHOOK: query: CREATE TABLE hdfs_table(key INT)
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@hdfs_table
@@ -446,13 +438,11 @@ STAGE PLANS:
     Stats-Aggr Operator
       Stats Aggregation Key Prefix: ### BLOBSTORE_STAGING_PATH ###
 
-PREHOOK: query: -- Drop tables
-DROP TABLE hdfs_table
+PREHOOK: query: DROP TABLE hdfs_table
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@hdfs_table
 PREHOOK: Output: default@hdfs_table
-POSTHOOK: query: -- Drop tables
-DROP TABLE hdfs_table
+POSTHOOK: query: DROP TABLE hdfs_table
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@hdfs_table
 POSTHOOK: Output: default@hdfs_table
