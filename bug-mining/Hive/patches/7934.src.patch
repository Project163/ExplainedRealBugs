diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
index b5ba982482..35351ef60c 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
@@ -4332,6 +4332,24 @@ public void testPolicyIdImplicitly() throws Exception {
     System.out.print(result);
     assertTrue(result.get(0),
         result.get(0).contains("repl.source.for=default_REPL DUMP " + dbName));
+
+    // Remove SOURCE_OF_REPLICATION property after bootstrap dump.
+    run("ALTER DATABASE " + name + " Set DBPROPERTIES ( '"
+            + SOURCE_OF_REPLICATION + "' = '')", driver);
+    run("INSERT INTO TABLE " + dbName + ".dataTable values('a', 'b', 'c')", driver);
+
+    Tuple incrementalDump = incrementalLoadAndVerify(dbName, replicatedDbName);
+    fs = new Path(incrementalDump.dumpLocation).getFileSystem(hconf);
+    dumpPath = new Path(incrementalDump.dumpLocation, ReplUtils.REPL_HIVE_BASE_DIR);
+    assertTrue(fs.exists(new Path(dumpPath, DUMP_ACKNOWLEDGEMENT.toString())));
+    assertTrue(fs.exists(new Path(dumpPath, LOAD_ACKNOWLEDGEMENT.toString())));
+
+    // Check the value of SOURCE_OF_REPLICATION in the database, it should
+    // get set automatically.
+    run("DESCRIBE DATABASE EXTENDED " + dbName, driver);
+    result = getOutput(driver);
+    assertTrue(result.get(0),
+            result.get(0).contains("repl.source.for=default_REPL DUMP " + dbName));
   }
 
   @Test
diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestScheduledReplicationScenarios.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestScheduledReplicationScenarios.java
index 8fb04f14f8..a045d5c38d 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestScheduledReplicationScenarios.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestScheduledReplicationScenarios.java
@@ -310,6 +310,20 @@ public void testSetPolicyId() throws Throwable {
           return false;
         }
       }, 100, 10000);
+
+      // Remove the SOURCE_OF_REPLICATION property from the database.
+      primary.run("ALTER DATABASE " + primaryDbName + " Set DBPROPERTIES ( '"
+              + SOURCE_OF_REPLICATION + "' = '')");
+
+      GenericTestUtils.waitFor(() -> {
+        try {
+          primary.run("DESCRIBE DATABASE EXTENDED " + primaryDbName);
+          return primary.getOutput().get(0)
+                  .contains("repl.source.for=s1_t2_new");
+        } catch (Throwable e) {
+          return false;
+        }
+      }, 100, 10000);
     } finally {
       primary.run("drop scheduled query s1_t2_new");
       replica.run("drop scheduled query s2_t2");
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java
index cb322968e0..ced5e7e141 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java
@@ -51,7 +51,6 @@
 import org.apache.hadoop.hive.ql.exec.repl.util.AddDependencyToLeaves;
 import org.apache.hadoop.hive.ql.exec.repl.util.FileList;
 import org.apache.hadoop.hive.ql.exec.repl.util.ReplUtils;
-import org.apache.hadoop.hive.ql.exec.repl.ReplExternalTables;
 import org.apache.hadoop.hive.ql.exec.repl.util.TaskTracker;
 import org.apache.hadoop.hive.ql.exec.util.DAGTraversal;
 import org.apache.hadoop.hive.ql.exec.util.Retryable;
@@ -584,6 +583,11 @@ private Long incrementalDump(Path dumpRoot, DumpMetaData dmd, Path cmRoot, Hive
     String dbName = (null != work.dbNameOrPattern && !work.dbNameOrPattern.isEmpty())
         ? work.dbNameOrPattern
         : "?";
+    Database db = hiveDb.getDatabase(dbName);
+    if (db != null && !HiveConf.getBoolVar(conf, REPL_DUMP_METADATA_ONLY)) {
+      setReplSourceFor(hiveDb, dbName, db);
+    }
+
     long estimatedNumEvents = evFetcher.getDbNotificationEventsCount(work.eventFrom, dbName, work.eventTo,
         maxEventLimit);
     try {
@@ -905,23 +909,7 @@ Long bootStrapDump(Path dumpRoot, DumpMetaData dmd, Path cmRoot, Hive hiveDb)
         }
 
         if (db != null && !HiveConf.getBoolVar(conf, REPL_DUMP_METADATA_ONLY)) {
-          if (!ReplChangeManager.isSourceOfReplication(db)) {
-            // Check if the schedule name is available else set the query value
-            // as default.
-            String value = conf.get(SCHEDULED_QUERY_SCHEDULENAME,
-                "default_" + getQueryState().getQueryString());
-            updateReplSourceFor(hiveDb, dbName, db, value);
-          } else {
-            // If a schedule name is available and that isn't part of the
-            // existing conf, append the schedule name to the conf.
-            String scheduleQuery = conf.get(SCHEDULED_QUERY_SCHEDULENAME);
-            if (!StringUtils.isEmpty(scheduleQuery)) {
-              if (!getReplPolicyIdString(db).contains(scheduleQuery)) {
-                updateReplSourceFor(hiveDb, dbName, db,
-                    getReplPolicyIdString(db) + ", " + scheduleQuery);
-              }
-            }
-          }
+          setReplSourceFor(hiveDb, dbName, db);
         }
 
         int estimatedNumTables = Utils.getAllTables(hiveDb, dbName, work.replScope).size();
@@ -1026,8 +1014,27 @@ Long bootStrapDump(Path dumpRoot, DumpMetaData dmd, Path cmRoot, Hive hiveDb)
     }
   }
 
-  private void updateReplSourceFor(Hive hiveDb, String dbName, Database db,
-      String value) throws HiveException {
+  private void setReplSourceFor(Hive hiveDb, String dbName, Database db) throws HiveException {
+    if (!ReplChangeManager.isSourceOfReplication(db)) {
+      // Check if the schedule name is available else set the query value
+      // as default.
+      String value = conf.get(SCHEDULED_QUERY_SCHEDULENAME,
+              "default_" + getQueryState().getQueryString());
+      updateReplSourceFor(hiveDb, dbName, db, value);
+    } else {
+      // If a schedule name is available and that isn't part of the
+      // existing conf, append the schedule name to the conf.
+      String scheduleQuery = conf.get(SCHEDULED_QUERY_SCHEDULENAME);
+      if (!StringUtils.isEmpty(scheduleQuery)) {
+        if (!getReplPolicyIdString(db).contains(scheduleQuery)) {
+          updateReplSourceFor(hiveDb, dbName, db,
+                  getReplPolicyIdString(db) + ", " + scheduleQuery);
+        }
+      }
+    }
+  }
+
+  private void updateReplSourceFor(Hive hiveDb, String dbName, Database db, String value) throws HiveException {
     Map<String, String> params = db.getParameters();
     if (params != null) {
       params.put("repl.source.for", value);
