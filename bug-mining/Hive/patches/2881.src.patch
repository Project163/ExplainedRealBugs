diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonMergeJoinOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonMergeJoinOperator.java
index 7a4e7cafd4..6a066688bd 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonMergeJoinOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonMergeJoinOperator.java
@@ -134,6 +134,19 @@ public void initializeOp(Configuration hconf) throws HiveException {
     sources = ((TezContext) MapredContext.get()).getRecordSources();
   }
 
+  @Override
+  public void endGroup() throws HiveException {
+    // we do not want the end group to cause a checkAndGenObject
+    defaultEndGroup();
+  }
+
+  @Override
+  public void startGroup() throws HiveException {
+    // we do not want the start group to clear the storage
+    defaultStartGroup();
+  }
+
+
   /*
    * (non-Javadoc)
    *
@@ -275,7 +288,7 @@ private void fetchNextGroup(Byte t) throws HiveException {
     if (foundNextKeyGroup[t]) {
       // first promote the next group to be the current group if we reached a
       // new group in the previous fetch
-      if ((this.nextKeyWritables[t] != null) || (this.fetchDone[t] == false)) {
+      if (this.nextKeyWritables[t] != null) {
         promoteNextGroupToCandidate(t);
       } else {
         this.keyWritables[t] = null;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java
index 017a72afa1..aa80510168 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java
@@ -19,6 +19,7 @@
 
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
@@ -73,10 +74,10 @@ public class ReduceRecordSource implements RecordSource {
   // for different tags
   private SerDe inputValueDeserializer;
 
-  TableDesc keyTableDesc;
-  TableDesc valueTableDesc;
+  private TableDesc keyTableDesc;
+  private TableDesc valueTableDesc;
 
-  ObjectInspector rowObjectInspector;
+  private ObjectInspector rowObjectInspector;
   private Operator<?> reducer;
 
   private Object keyObject = null;
@@ -84,8 +85,6 @@ public class ReduceRecordSource implements RecordSource {
 
   private boolean vectorized = false;
 
-  List<Object> row = new ArrayList<Object>(Utilities.reduceFieldNameList.size());
-
   private DataOutputBuffer keyBuffer;
   private DataOutputBuffer valueBuffer;
   private VectorizedRowBatchCtx batchContext;
@@ -111,7 +110,7 @@ public class ReduceRecordSource implements RecordSource {
 
   private Iterable<Object> valueWritables;
   
-  private final boolean grouped = true;
+  private final GroupIterator groupIterator = new GroupIterator();
 
   void init(JobConf jconf, Operator<?> reducer, boolean vectorized, TableDesc keyTableDesc,
       TableDesc valueTableDesc, KeyValuesReader reader, boolean handleGroupKey, byte tag,
@@ -207,13 +206,19 @@ void init(JobConf jconf, Operator<?> reducer, boolean vectorized, TableDesc keyT
   
   @Override
   public final boolean isGrouped() {
-    return grouped;
+    return vectorized;
   }
 
   @Override
   public boolean pushRecord() throws HiveException {
     BytesWritable keyWritable;
 
+    if (!vectorized && groupIterator.hasNext()) {
+      // if we have records left in the group we push one of those
+      groupIterator.next();
+      return true;
+    }
+
     try {
       if (!reader.next()) {
         return false;
@@ -245,11 +250,13 @@ public boolean pushRecord() throws HiveException {
         reducer.setGroupKeyObject(keyObject);
       }
 
-      /* this.keyObject passed via reference */
       if(vectorized) {
         processVectors(valueWritables, tag);
       } else {
-        processKeyValues(valueWritables, tag);
+        groupIterator.initialize(valueWritables, keyObject, tag);
+        if (groupIterator.hasNext()) {
+          groupIterator.next(); // push first record of group
+        }
       }
       return true;
     } catch (Throwable e) {
@@ -279,16 +286,29 @@ private Object deserializeValue(BytesWritable valueWritable, byte tag)
     }
   }
 
-  /**
-   * @param values
-   * @return true if it is not done and can take more inputs
-   */
-  private void processKeyValues(Iterable<Object> values, byte tag) throws HiveException {
-    List<Object> passDownKey = null;
-    for (Object value : values) {
-      BytesWritable valueWritable = (BytesWritable) value;
+  private class GroupIterator {
+    private final List<Object> row = new ArrayList<Object>(Utilities.reduceFieldNameList.size());
+    private List<Object> passDownKey = null;
+    private Iterator<Object> values;
+    private byte tag;
+    private Object keyObject;
+
+    public void initialize(Iterable<Object> values, Object keyObject, byte tag) {
+      this.passDownKey = null;
+      this.values = values.iterator();
+      this.tag = tag;
+      this.keyObject = keyObject;
+    }
 
+    public boolean hasNext() {
+      return values != null && values.hasNext();
+    }
+
+    public void next() throws HiveException {
       row.clear();
+      Object value = values.next();
+      BytesWritable valueWritable = (BytesWritable) value;
+
       if (passDownKey == null) {
         row.add(this.keyObject);
       } else {
@@ -387,7 +407,6 @@ boolean close() throws Exception {
     } catch (Exception e) {
       if (!abort) {
         // signal new failure to map-reduce
-        l4j.error("Hit error while closing operators - failing tree");
         throw new RuntimeException("Hive Runtime Error while closing operators: "
             + e.getMessage(), e);
       }
diff --git a/ql/src/test/results/clientpositive/tez/vector_decimal_3.q.out b/ql/src/test/results/clientpositive/tez/vector_decimal_3.q.out
index 9c8b02bb7a..7987d080b3 100644
--- a/ql/src/test/results/clientpositive/tez/vector_decimal_3.q.out
+++ b/ql/src/test/results/clientpositive/tez/vector_decimal_3.q.out
@@ -295,8 +295,14 @@ POSTHOOK: Input: default@decimal_3
 -0.33	0	-0.33	0
 -0.3	0	-0.3	0
 0.000000000000000000	0	0.000000000000000000	0
+0.000000000000000000	0	0	0
+0.000000000000000000	0	0	0
+0	0	0	0
 0	0	0.000000000000000000	0
+0	0	0	0
 0	0	0.000000000000000000	0
+0	0	0	0
+0	0	0	0
 0.01	0	0.01	0
 0.02	0	0.02	0
 0.1	0	0.1	0
@@ -305,8 +311,14 @@ POSTHOOK: Input: default@decimal_3
 0.33	0	0.33	0
 0.333	0	0.333	0
 1	1	1	1
+1	1	1.0	1
+1	1	1.000000000000000000	1
+1.0	1	1.000000000000000000	1
+1.0	1	1.0	1
 1.0	1	1	1
+1.000000000000000000	1	1.000000000000000000	1
 1.000000000000000000	1	1	1
+1.000000000000000000	1	1.0	1
 1.12	1	1.12	1
 1.122	1	1.122	1
 2	2	2	2
@@ -322,9 +334,13 @@ POSTHOOK: Input: default@decimal_3
 3.14	3	3.14	3
 3.14	3	3.14	3
 3.14	3	3.14	3
+3.14	3	3.140	4
+3.14	3	3.140	4
+3.14	3	3.140	4
 3.140	4	3.14	3
 3.140	4	3.14	3
 3.140	4	3.14	3
+3.140	4	3.140	4
 10	10	10	10
 20	20	20	20
 100	100	100	100
