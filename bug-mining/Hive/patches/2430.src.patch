diff --git a/pom.xml b/pom.xml
index 5cdca5d748..90733dfde3 100644
--- a/pom.xml
+++ b/pom.xml
@@ -147,7 +147,7 @@
     <slf4j.version>1.7.5</slf4j.version>
     <ST4.version>4.0.4</ST4.version>
     <tez.version>0.4.0-incubating</tez.version>
-    <spark.version>1.0.1</spark.version>
+    <spark.version>1.1.0-SNAPSHOT</spark.version>
     <scala.binary.version>2.10</scala.binary.version>
     <scala.version>2.10.4</scala.version>
     <tempus-fugit.version>1.1</tempus-fugit.version>
@@ -193,7 +193,7 @@
       <snapshots>
         <enabled>false</enabled>
       </snapshots>
-    </repository>
+     </repository>
      <repository>
        <id>sonatype-snapshot</id>
        <url>https://oss.sonatype.org/content/repositories/snapshots</url>
@@ -204,6 +204,16 @@
          <enabled>false</enabled>
        </snapshots>
      </repository>
+     <repository>
+       <id>spark-snapshot</id>
+       <url>http://ec2-50-18-79-139.us-west-1.compute.amazonaws.com/data/spark_2.10-1.1-SNAPSHOT/</url>
+       <releases>
+         <enabled>false</enabled>
+       </releases>
+       <snapshots>
+         <enabled>true</enabled>
+       </snapshots>
+     </repository>
   </repositories>
 
   <!-- Hadoop dependency management is done at the bottom under profiles -->
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SortByShuffler.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SortByShuffler.java
index c915deb9b1..70e20b0ae0 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SortByShuffler.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SortByShuffler.java
@@ -18,23 +18,24 @@
 
 package org.apache.hadoop.hive.ql.exec.spark;
 
-import java.util.*;
-
-import com.google.common.collect.Ordering;
 import org.apache.hadoop.io.BytesWritable;
 import org.apache.spark.api.java.JavaPairRDD;
 import org.apache.spark.api.java.function.PairFlatMapFunction;
-
 import scala.Tuple2;
 
+import java.util.*;
+
 public class SortByShuffler implements SparkShuffler {
 
   @Override
   public JavaPairRDD<BytesWritable, Iterable<BytesWritable>> shuffle(
       JavaPairRDD<BytesWritable, BytesWritable> input, int numPartitions) {
-    Comparator comp = Ordering.<BytesWritable>natural();
-    // Due to HIVE-7540, numPartitions must be to 1
-    JavaPairRDD<BytesWritable, BytesWritable> rdd = input.sortByKey(comp, true, 1);
+    JavaPairRDD<BytesWritable, BytesWritable> rdd;
+    if (numPartitions > 0) {
+      rdd = input.sortByKey(true, numPartitions);
+    } else {
+      rdd = input.sortByKey(true);
+    }
     return rdd.mapPartitionsToPair(new ShuffleFunction());
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/SparkEdgeProperty.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/SparkEdgeProperty.java
index beeeab8581..f22870a890 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/SparkEdgeProperty.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/SparkEdgeProperty.java
@@ -28,7 +28,7 @@ public class SparkEdgeProperty {
   private long edgeType;
   
   private int numPartitions;
-  
+
   public SparkEdgeProperty(long edgeType, int numPartitions) {
     this.edgeType = edgeType;
     this.numPartitions = numPartitions;
