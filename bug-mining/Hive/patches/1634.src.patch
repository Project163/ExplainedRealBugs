diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
index 0ff4954d6d..1f00a7e13e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
@@ -354,7 +354,7 @@ public void initialize(Configuration hconf, ObjectInspector[] inputOIs)
     // initialize structure to maintain child op info. operator tree changes
     // while
     // initializing so this need to be done here instead of initialize() method
-    if (childOperators != null) {
+    if (childOperators != null && !childOperators.isEmpty()) {
       childOperatorsArray = new Operator[childOperators.size()];
       for (int i = 0; i < childOperatorsArray.length; i++) {
         childOperatorsArray[i] = childOperators.get(i);
@@ -411,7 +411,7 @@ protected void initializeOp(Configuration hconf) throws HiveException {
   protected void initializeChildren(Configuration hconf) throws HiveException {
     state = State.INIT;
     LOG.info("Operator " + id + " " + getName() + " initialized");
-    if (childOperators == null) {
+    if (childOperators == null || childOperators.isEmpty()) {
       return;
     }
     LOG.info("Initializing children of " + id + " " + getName());
@@ -780,7 +780,7 @@ public boolean removeChildren(int depth) {
     Operator<? extends OperatorDesc> currOp = this;
     for (int i = 0; i < depth; i++) {
       // If there are more than 1 children at any level, don't do anything
-      if ((currOp.getChildOperators() == null) ||
+      if ((currOp.getChildOperators() == null) || (currOp.getChildOperators().isEmpty()) || 
           (currOp.getChildOperators().size() > 1)) {
         return false;
       }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConvertJoinMapJoin.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConvertJoinMapJoin.java
index 05898986fd..d812819ed1 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConvertJoinMapJoin.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConvertJoinMapJoin.java
@@ -162,7 +162,7 @@ public Object process(Node nd, Stack<Node> stack,
     ParseContext parseContext = context.parseContext;
     MapJoinOperator mapJoinOp = MapJoinProcessor.
       convertJoinOpMapJoinOp(context.conf, parseContext.getOpParseCtx(),
-      joinOp, parseContext.getJoinContext().get(joinOp), bigTablePosition, true, false);
+      joinOp, parseContext.getJoinContext().get(joinOp), bigTablePosition, true);
 
     Operator<? extends OperatorDesc> parentBigTableOp
       = mapJoinOp.getParentOperators().get(bigTablePosition);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GroupByOptimizer.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GroupByOptimizer.java
index 670e39cb7c..c16010fc84 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GroupByOptimizer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GroupByOptimizer.java
@@ -286,7 +286,7 @@ protected GroupByOptimizerSortMatch checkSortGroupBy(Stack<Node> stack,
       currOp = currOp.getParentOperators().get(0);
 
       while (true) {
-        if (currOp.getParentOperators() == null) {
+        if ((currOp.getParentOperators() == null) || (currOp.getParentOperators().isEmpty())) {
           break;
         }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
index eeca808532..0f87f50e6a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
@@ -376,7 +376,7 @@ public static MapJoinOperator convertMapJoin(HiveConf conf,
 
     // create the map-join operator
     MapJoinOperator mapJoinOp = convertJoinOpMapJoinOp(conf, opParseCtxMap,
-        op, joinTree, mapJoinPos, noCheckOuterJoin, validateMapJoinTree);
+        op, joinTree, mapJoinPos, noCheckOuterJoin);
 
 
     // remove old parents
@@ -389,6 +389,10 @@ public static MapJoinOperator convertMapJoin(HiveConf conf,
     mapJoinOp.getParentOperators().removeAll(oldReduceSinkParentOps);
     mapJoinOp.setParentOperators(newParentOps);
 
+    // make sure only map-joins can be performed.
+    if (validateMapJoinTree) {
+      validateMapJoinTypes(mapJoinOp);
+    }
 
     // change the children of the original join operator to point to the map
     // join operator
@@ -398,8 +402,7 @@ public static MapJoinOperator convertMapJoin(HiveConf conf,
 
   public static MapJoinOperator convertJoinOpMapJoinOp(HiveConf hconf,
       LinkedHashMap<Operator<? extends OperatorDesc>, OpParseContext> opParseCtxMap,
-      JoinOperator op, QBJoinTree joinTree, int mapJoinPos, boolean noCheckOuterJoin,
-      boolean validateMapJoinTree)
+      JoinOperator op, QBJoinTree joinTree, int mapJoinPos, boolean noCheckOuterJoin)
       throws SemanticException {
 
     JoinDesc desc = op.getConf();
@@ -565,11 +568,6 @@ public static MapJoinOperator convertJoinOpMapJoinOp(HiveConf hconf,
     op.setChildOperators(null);
     op.setParentOperators(null);
 
-    // make sure only map-joins can be performed.
-    if (validateMapJoinTree) {
-      validateMapJoinTypes(mapJoinOp);
-    }
-
     return mapJoinOp;
 
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SkewJoinOptimizer.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SkewJoinOptimizer.java
index a49a216e93..54afbfe9bf 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SkewJoinOptimizer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SkewJoinOptimizer.java
@@ -398,7 +398,8 @@ private Table getTable(
             return parseContext.getTopToTable().get(tsOp);
           }
         }
-        if ((op.getParentOperators() == null) || (op.getParentOperators().size() > 1)) {
+        if ((op.getParentOperators() == null) || (op.getParentOperators().isEmpty()) || 
+            (op.getParentOperators().size() > 1)) {
           return null;
         }
         op = op.getParentOperators().get(0);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/CorrelationOptimizer.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/CorrelationOptimizer.java
index f38b8ccaec..d17eb51eba 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/CorrelationOptimizer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/CorrelationOptimizer.java
@@ -346,7 +346,7 @@ private LinkedHashSet<ReduceSinkOperator> findCorrelatedReduceSinkOperators(
             "involved in this operator");
         return correlatedReduceSinkOperators;
       }
-      if (current.getParentOperators() == null) {
+      if ((current.getParentOperators() == null) || (current.getParentOperators().isEmpty())) {
         return correlatedReduceSinkOperators;
       }
       if (current instanceof PTFOperator) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java
index 0b41db8376..0a747be57e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java
@@ -204,7 +204,7 @@ private boolean isEligibleForOptimization(SMBMapJoinOperator originalSMBJoinOp)
 
     Operator<? extends OperatorDesc> currOp = originalSMBJoinOp;
     while (true) {
-      if (currOp.getChildOperators() == null) {
+      if ((currOp.getChildOperators() == null) || (currOp.getChildOperators().isEmpty())) {
         if (currOp instanceof FileSinkOperator) {
           FileSinkOperator fsOp = (FileSinkOperator)currOp;
           // The query has enforced that a sort-merge join should be performed.
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/TableAccessAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/TableAccessAnalyzer.java
index 5fdfcf1518..d847a16b41 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/TableAccessAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/TableAccessAnalyzer.java
@@ -239,7 +239,7 @@ public static TableScanOperator genRootTableScan(
     // and filters.
     while (true) {
       parentOps = currOp.getParentOperators();
-      if (parentOps == null) {
+      if ((parentOps == null) || (parentOps.isEmpty())) {
         return (TableScanOperator) currOp;
       }
 
