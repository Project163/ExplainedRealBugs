diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
index 4a9af80fdc..2edf749399 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java
@@ -21,6 +21,7 @@
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
@@ -64,6 +65,7 @@
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
 import org.apache.hadoop.hive.metastore.ObjectStore;
 import org.apache.hadoop.hive.ql.exec.FunctionRegistry;
+import org.apache.hadoop.hive.ql.exec.UDF;
 import org.apache.hive.common.util.ReflectionUtil;
 import org.apache.hive.jdbc.miniHS2.MiniHS2;
 import org.datanucleus.ClassLoaderResolver;
@@ -1378,6 +1380,86 @@ public void testReplDumpResultSet() throws Exception {
     }
   }
 
+  public static class SleepMsUDF extends UDF {
+    public Integer evaluate(final Integer value, final Integer ms) {
+      try {
+        Thread.sleep(ms);
+      } catch (InterruptedException e) {
+        // No-op
+      }
+      return value;
+    }
+  }
+
+  /**
+   * Test CLI kill command of a query that is running.
+   * We spawn 2 threads - one running the query and
+   * the other attempting to cancel.
+   * We're using a dummy udf to simulate a query,
+   * that runs for a sufficiently long time.
+   * @throws Exception
+   */
+  @Test
+  public void testKillQuery() throws Exception {
+    Connection con = conTestDb;
+    Connection con2 = getConnection(testDbName);
+
+    String udfName = SleepMsUDF.class.getName();
+    Statement stmt1 = con.createStatement();
+    final Statement stmt2 = con2.createStatement();
+    stmt1.execute("create temporary function sleepMsUDF as '" + udfName + "'");
+    stmt1.close();
+    final Statement stmt = con.createStatement();
+    final ExceptionHolder tExecuteHolder = new ExceptionHolder();
+    final ExceptionHolder tKillHolder = new ExceptionHolder();
+
+    // Thread executing the query
+    Thread tExecute = new Thread(new Runnable() {
+      @Override
+      public void run() {
+        try {
+          System.out.println("Executing query: ");
+          // The test table has 500 rows, so total query time should be ~ 500*500ms
+          stmt.executeQuery("select sleepMsUDF(t1.int_col, 100), t1.int_col, t2.int_col " +
+              "from " + tableName + " t1 join " + tableName + " t2 on t1.int_col = t2.int_col");
+          fail("Expecting SQLException");
+        } catch (SQLException e) {
+          tExecuteHolder.throwable = e;
+        }
+      }
+    });
+    // Thread killing the query
+    Thread tKill = new Thread(new Runnable() {
+      @Override
+      public void run() {
+        try {
+          Thread.sleep(2000);
+          String queryId = ((HiveStatement) stmt).getQueryId();
+          System.out.println("Killing query: " + queryId);
+
+          stmt2.execute("kill query '" + queryId + "'");
+          stmt2.close();
+        } catch (Exception e) {
+          tKillHolder.throwable = e;
+        }
+      }
+    });
+
+    tExecute.start();
+    tKill.start();
+    tExecute.join();
+    tKill.join();
+    stmt.close();
+    con2.close();
+
+    assertNotNull("tExecute", tExecuteHolder.throwable);
+    assertNull("tCancel", tKillHolder.throwable);
+  }
+
+  private static class ExceptionHolder {
+    Throwable throwable;
+  }
+
   @Test
   public void testFetchSize() throws Exception {
     // Test setting fetch size below max
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniLlap.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniLlap.java
index 28fa7a5783..91d03771a8 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniLlap.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniLlap.java
@@ -22,6 +22,7 @@
 import static org.junit.Assert.assertArrayEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
@@ -117,6 +118,7 @@ public static void beforeTest() throws Exception {
 
     conf = new HiveConf();
     conf.setBoolVar(ConfVars.HIVE_SUPPORT_CONCURRENCY, false);
+    conf.setBoolVar(ConfVars.HIVE_SERVER2_ENABLE_DOAS, false);
 
     conf.addResource(new URL("file://" + new File(confDir).toURI().getPath()
         + "/tez-site.xml"));
@@ -527,4 +529,76 @@ private int processQuery(String currentDatabase, String query, int numSplits, Ro
 
     return rowCount;
   }
+
+  /**
+   * Test CLI kill command of a query that is running.
+   * We spawn 2 threads - one running the query and
+   * the other attempting to cancel.
+   * We're using a dummy udf to simulate a query,
+   * that runs for a sufficiently long time.
+   * @throws Exception
+   */
+  @Test
+  public void testKillQuery() throws Exception {
+    String tableName = "testtab1";
+    createTestTable(tableName);
+    Connection con = hs2Conn;
+    Connection con2 = getConnection(miniHS2.getJdbcURL(), System.getProperty("user.name"), "bar");
+
+    String udfName = TestJdbcWithMiniHS2.SleepMsUDF.class.getName();
+    Statement stmt1 = con.createStatement();
+    Statement stmt2 = con2.createStatement();
+    stmt1.execute("create temporary function sleepMsUDF as '" + udfName + "'");
+    stmt1.close();
+    final Statement stmt = con.createStatement();
+
+    ExceptionHolder tExecuteHolder = new ExceptionHolder();
+    ExceptionHolder tKillHolder = new ExceptionHolder();
+
+    // Thread executing the query
+    Thread tExecute = new Thread(new Runnable() {
+      @Override
+      public void run() {
+        try {
+          System.out.println("Executing query: ");
+          // The test table has 500 rows, so total query time should be ~ 500*500ms
+          stmt.executeQuery("select sleepMsUDF(t1.under_col, 100), t1.under_col, t2.under_col " +
+              "from " + tableName + " t1 join " + tableName + " t2 on t1.under_col = t2.under_col");
+          fail("Expecting SQLException");
+        } catch (SQLException e) {
+          tExecuteHolder.throwable = e;
+        }
+      }
+    });
+    // Thread killing the query
+    Thread tKill = new Thread(new Runnable() {
+      @Override
+      public void run() {
+        try {
+          Thread.sleep(2000);
+          String queryId = ((HiveStatement) stmt).getQueryId();
+          System.out.println("Killing query: " + queryId);
+
+          stmt2.execute("kill query '" + queryId + "'");
+          stmt2.close();
+        } catch (Exception e) {
+          tKillHolder.throwable = e;
+        }
+      }
+    });
+
+    tExecute.start();
+    tKill.start();
+    tExecute.join();
+    tKill.join();
+    stmt.close();
+    con2.close();
+
+    assertNotNull("tExecute", tExecuteHolder.throwable);
+    assertNull("tCancel", tKillHolder.throwable);
+  }
+
+  private static class ExceptionHolder {
+    Throwable throwable;
+  }
 }
\ No newline at end of file
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestServiceDiscoveryWithMiniHS2.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestServiceDiscoveryWithMiniHS2.java
index e8051e40f2..dc59f4b7fb 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestServiceDiscoveryWithMiniHS2.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestServiceDiscoveryWithMiniHS2.java
@@ -131,4 +131,26 @@ private void openConnectionAndRunQuery() throws Exception {
     res.close();
     stmt.close();
   }
+
+  @Test
+  public void testGetAllUrlsZk() throws Exception {
+    Map<String, String> confOverlay = new HashMap<String, String>();
+    confOverlay.put("hive.server2.zookeeper.publish.configs", "true");
+    miniHS2.start(confOverlay);
+    String directUrl = HiveConnection.getAllUrls(miniHS2.getJdbcURL()).get(0).getJdbcUriString();
+    String jdbcUrl = "jdbc:hive2://" + miniHS2.getHost() + ":" + miniHS2.getBinaryPort() +
+        "/default;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hs2test;";
+    assertEquals(jdbcUrl, directUrl);
+  }
+
+  @Test
+  public void testGetAllUrlsDirect() throws Exception {
+    Map<String, String> confOverlay = new HashMap<String, String>();
+    confOverlay.put("hive.server2.zookeeper.publish.configs", "false");
+    miniHS2.start(confOverlay);
+    String directUrl = HiveConnection.getAllUrls(miniHS2.getJdbcURL()).get(0).getJdbcUriString();
+    String jdbcUrl = "jdbc:hive2://" + miniHS2.getHost() + ":" + miniHS2.getBinaryPort() +
+        "/default;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hs2test;";
+    assertEquals(jdbcUrl, directUrl);
+  }
 }
\ No newline at end of file
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/service/cli/session/TestHiveSessionImpl.java b/itests/hive-unit/src/test/java/org/apache/hive/service/cli/session/TestHiveSessionImpl.java
index 76059f8b07..ebcf4a8751 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/service/cli/session/TestHiveSessionImpl.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/service/cli/session/TestHiveSessionImpl.java
@@ -29,6 +29,7 @@
 import org.mockito.Mockito;
 import static org.mockito.Matchers.*;
 
+import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Map;
 
@@ -86,7 +87,7 @@ protected synchronized void release(boolean userAccess, boolean isOperation) {
 
     } catch (HiveSQLException e) {
       if (!"Fail for clean up test".equals(e.getMessage())) {
-        Assert.fail("unexpected exception:" + e.getMessage());
+        Assert.fail("unexpected exception:" + Arrays.toString(e.getStackTrace()));
       }
       //operationManager.closeOperation() is expected to be invoked once
       Mockito.verify(operationManager, Mockito.times(1)).closeOperation(opHandle);
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/service/cli/session/TestQueryDisplay.java b/itests/hive-unit/src/test/java/org/apache/hive/service/cli/session/TestQueryDisplay.java
index da01a2947d..32e2fc9489 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/service/cli/session/TestQueryDisplay.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/service/cli/session/TestQueryDisplay.java
@@ -48,8 +48,7 @@ public void setup() {
     conf = new HiveConf();
     conf.set("hive.support.concurrency", "false");
 
-    HiveServer2 dummyHs2 = new HiveServer2();
-    sessionManager = new SessionManager(dummyHs2);
+    sessionManager = new SessionManager(null);
     sessionManager.init(conf);
   }
 
diff --git a/itests/src/test/resources/testconfiguration.properties b/itests/src/test/resources/testconfiguration.properties
index d510a2f416..52161ffff1 100644
--- a/itests/src/test/resources/testconfiguration.properties
+++ b/itests/src/test/resources/testconfiguration.properties
@@ -187,6 +187,7 @@ minillaplocal.shared.query.files=alter_merge_2_orc.q,\
   join_emit_interval.q,\
   join46.q,\
   join_nullsafe.q,\
+  kill_query.q,\
   leftsemijoin.q,\
   limit_pushdown.q,\
   load_dyn_part1.q,\
diff --git a/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java b/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java
index 1311d2d88c..a9a4f2cf66 100644
--- a/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java
+++ b/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java
@@ -100,6 +100,7 @@
 import java.sql.Statement;
 import java.sql.Struct;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.LinkedList;
 import java.util.List;
@@ -136,6 +137,20 @@ public class HiveConnection implements java.sql.Connection {
   private int fetchSize = HiveStatement.DEFAULT_FETCH_SIZE;
   private String initFile = null;
 
+  /**
+   * Get all direct HiveServer2 URLs from a ZooKeeper based HiveServer2 URL
+   * @param zookeeperBasedHS2Url
+   * @return
+   * @throws Exception
+   */
+  public static List<JdbcConnectionParams> getAllUrls(String zookeeperBasedHS2Url) throws Exception {
+    JdbcConnectionParams params = Utils.parseURL(zookeeperBasedHS2Url, new Properties());
+    if (params.getZooKeeperEnsemble() == null) {
+      return Collections.singletonList(params);
+    }
+    return ZooKeeperHiveClientHelper.getDirectParamsList(params);
+  }
+
   public HiveConnection(String uri, Properties info) throws SQLException {
     setupLoginTimeout();
     try {
diff --git a/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java b/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java
index c6bd41feb7..a8e3bd9518 100644
--- a/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java
+++ b/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java
@@ -18,6 +18,7 @@
 
 package org.apache.hive.jdbc;
 
+import com.google.common.annotations.VisibleForTesting;
 import org.apache.commons.codec.binary.Base64;
 import org.apache.hive.jdbc.logs.InPlaceUpdateStream;
 import org.apache.hive.service.cli.RowSet;
@@ -34,6 +35,7 @@
 import org.apache.hive.service.rpc.thrift.TFetchResultsResp;
 import org.apache.hive.service.rpc.thrift.TGetOperationStatusReq;
 import org.apache.hive.service.rpc.thrift.TGetOperationStatusResp;
+import org.apache.hive.service.rpc.thrift.TGetQueryIdReq;
 import org.apache.hive.service.rpc.thrift.TOperationHandle;
 import org.apache.hive.service.rpc.thrift.TSessionHandle;
 import org.apache.thrift.TException;
@@ -986,4 +988,13 @@ public String getYarnATSGuid() {
   public void setInPlaceUpdateStream(InPlaceUpdateStream stream) {
     this.inPlaceUpdateStream = stream;
   }
+
+  @VisibleForTesting
+  public String getQueryId() throws SQLException {
+    try {
+      return client.GetQueryId(new TGetQueryIdReq(stmtHandle)).getQueryId();
+    } catch (TException e) {
+      throw new SQLException(e);
+    }
+  }
 }
diff --git a/jdbc/src/java/org/apache/hive/jdbc/Utils.java b/jdbc/src/java/org/apache/hive/jdbc/Utils.java
index bfae8b9e41..574fb7e1d2 100644
--- a/jdbc/src/java/org/apache/hive/jdbc/Utils.java
+++ b/jdbc/src/java/org/apache/hive/jdbc/Utils.java
@@ -154,6 +154,21 @@ public static class JdbcConnectionParams {
 
     public JdbcConnectionParams() {
     }
+    
+    public JdbcConnectionParams(JdbcConnectionParams params) {
+      this.host = params.host;
+      this.port = params.port;
+      this.jdbcUriString = params.jdbcUriString;
+      this.dbName = params.dbName;
+      this.hiveConfs.putAll(params.hiveConfs);
+      this.hiveVars.putAll(params.hiveVars);
+      this.sessionVars.putAll(params.sessionVars);
+      this.isEmbeddedMode = params.isEmbeddedMode;
+      this.authorityList = params.authorityList;
+      this.zooKeeperEnsemble = params.zooKeeperEnsemble;
+      this.currentHostZnodePath = params.currentHostZnodePath;
+      this.rejectedHostZnodePaths.addAll(rejectedHostZnodePaths);
+    }
 
     public String getHost() {
       return host;
diff --git a/jdbc/src/java/org/apache/hive/jdbc/ZooKeeperHiveClientHelper.java b/jdbc/src/java/org/apache/hive/jdbc/ZooKeeperHiveClientHelper.java
index 8d6003ad06..91bc1a1db6 100644
--- a/jdbc/src/java/org/apache/hive/jdbc/ZooKeeperHiveClientHelper.java
+++ b/jdbc/src/java/org/apache/hive/jdbc/ZooKeeperHiveClientHelper.java
@@ -19,6 +19,7 @@
 package org.apache.hive.jdbc;
 
 import java.nio.charset.Charset;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Random;
 import java.util.regex.Matcher;
@@ -45,53 +46,94 @@ public void process(org.apache.zookeeper.WatchedEvent event) {
     }
   }
 
-  static void configureConnParams(JdbcConnectionParams connParams)
-      throws ZooKeeperHiveClientException {
-    String zooKeeperEnsemble = connParams.getZooKeeperEnsemble();
-    String zooKeeperNamespace =
-        connParams.getSessionVars().get(JdbcConnectionParams.ZOOKEEPER_NAMESPACE);
+  private static String getZooKeeperNamespace(JdbcConnectionParams connParams) {
+    String zooKeeperNamespace = connParams.getSessionVars().get(JdbcConnectionParams.ZOOKEEPER_NAMESPACE);
     if ((zooKeeperNamespace == null) || (zooKeeperNamespace.isEmpty())) {
       zooKeeperNamespace = JdbcConnectionParams.ZOOKEEPER_DEFAULT_NAMESPACE;
     }
-    List<String> serverHosts;
-    Random randomizer = new Random();
-    String serverNode;
+    return zooKeeperNamespace;
+  }
+
+  private static CuratorFramework getZkClient(JdbcConnectionParams connParams) throws Exception {
+    String zooKeeperEnsemble = connParams.getZooKeeperEnsemble();
     CuratorFramework zooKeeperClient =
         CuratorFrameworkFactory.builder().connectString(zooKeeperEnsemble)
             .retryPolicy(new ExponentialBackoffRetry(1000, 3)).build();
-    try {
-      zooKeeperClient.start();
-      serverHosts = zooKeeperClient.getChildren().forPath("/" + zooKeeperNamespace);
-      // Remove the znodes we've already tried from this list
-      serverHosts.removeAll(connParams.getRejectedHostZnodePaths());
-      if (serverHosts.isEmpty()) {
-        throw new ZooKeeperHiveClientException(
-            "Tried all existing HiveServer2 uris from ZooKeeper.");
+    zooKeeperClient.start();
+    return zooKeeperClient;
+  }
+
+  private static List<String> getServerHosts(JdbcConnectionParams connParams, CuratorFramework
+      zooKeeperClient) throws Exception {
+    List<String> serverHosts = zooKeeperClient.getChildren().forPath("/" + getZooKeeperNamespace(connParams));
+    // Remove the znodes we've already tried from this list
+    serverHosts.removeAll(connParams.getRejectedHostZnodePaths());
+    if (serverHosts.isEmpty()) {
+      throw new ZooKeeperHiveClientException(
+          "Tried all existing HiveServer2 uris from ZooKeeper.");
+    }
+    return serverHosts;
+  }
+
+  private static void updateParamsWithZKServerNode(JdbcConnectionParams connParams,
+      CuratorFramework zooKeeperClient, String serverNode) throws Exception {
+    String zooKeeperNamespace = getZooKeeperNamespace(connParams);
+    connParams.setCurrentHostZnodePath(serverNode);
+    // Read data from the znode for this server node
+    // This data could be either config string (new releases) or server end
+    // point (old releases)
+    String dataStr =
+        new String(
+            zooKeeperClient.getData().forPath("/" + zooKeeperNamespace + "/" + serverNode),
+            Charset.forName("UTF-8"));
+    // If dataStr is not null and dataStr is not a KV pattern,
+    // it must be the server uri added by an older version HS2
+    Matcher matcher = kvPattern.matcher(dataStr);
+    if ((dataStr != null) && (!matcher.find())) {
+      String[] split = dataStr.split(":");
+      if (split.length != 2) {
+        throw new ZooKeeperHiveClientException("Unable to read HiveServer2 uri from ZooKeeper: "
+            + dataStr);
       }
+      connParams.setHost(split[0]);
+      connParams.setPort(Integer.parseInt(split[1]));
+    } else {
+      applyConfs(dataStr, connParams);
+    }
+  }
+
+  static void configureConnParams(JdbcConnectionParams connParams) throws ZooKeeperHiveClientException {
+    CuratorFramework zooKeeperClient = null;
+    try {
+      zooKeeperClient = getZkClient(connParams);
+      List<String> serverHosts = getServerHosts(connParams, zooKeeperClient);
       // Now pick a server node randomly
-      serverNode = serverHosts.get(randomizer.nextInt(serverHosts.size()));
-      connParams.setCurrentHostZnodePath(serverNode);
-      // Read data from the znode for this server node
-      // This data could be either config string (new releases) or server end
-      // point (old releases)
-      String dataStr =
-          new String(
-              zooKeeperClient.getData().forPath("/" + zooKeeperNamespace + "/" + serverNode),
-              Charset.forName("UTF-8"));
-      Matcher matcher = kvPattern.matcher(dataStr);
-      // If dataStr is not null and dataStr is not a KV pattern,
-      // it must be the server uri added by an older version HS2
-      if ((dataStr != null) && (!matcher.find())) {
-        String[] split = dataStr.split(":");
-        if (split.length != 2) {
-          throw new ZooKeeperHiveClientException("Unable to read HiveServer2 uri from ZooKeeper: "
-              + dataStr);
-        }
-        connParams.setHost(split[0]);
-        connParams.setPort(Integer.parseInt(split[1]));
-      } else {
-        applyConfs(dataStr, connParams);
+      String serverNode = serverHosts.get(new Random().nextInt(serverHosts.size()));
+      updateParamsWithZKServerNode(connParams, zooKeeperClient, serverNode);
+    } catch (Exception e) {
+      throw new ZooKeeperHiveClientException("Unable to read HiveServer2 configs from ZooKeeper", e);
+    } finally {
+      // Close the client connection with ZooKeeper
+      if (zooKeeperClient != null) {
+        zooKeeperClient.close();
+      }
+    }
+  }
+
+  static List<JdbcConnectionParams> getDirectParamsList(JdbcConnectionParams connParams)
+      throws ZooKeeperHiveClientException {
+    CuratorFramework zooKeeperClient = null;
+    try {
+      zooKeeperClient = getZkClient(connParams);
+      List<String> serverHosts = getServerHosts(connParams, zooKeeperClient);
+      final List<JdbcConnectionParams> directParamsList = new ArrayList<>();
+      // For each node
+      for (String serverNode : serverHosts) {
+        JdbcConnectionParams directConnParams = new JdbcConnectionParams(connParams);
+        directParamsList.add(directConnParams);
+        updateParamsWithZKServerNode(directConnParams, zooKeeperClient, serverNode);
       }
+      return directParamsList;
     } catch (Exception e) {
       throw new ZooKeeperHiveClientException("Unable to read HiveServer2 configs from ZooKeeper", e);
     } finally {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
index e802d42a4d..ec228b4933 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
@@ -712,6 +712,7 @@ private boolean startImplicitTxn(HiveTxnManager txnManager) throws LockException
       case SHOW_COMPACTIONS:
       case SHOW_TRANSACTIONS:
       case ABORT_TRANSACTIONS:
+      case KILL_QUERY:
         shouldOpenImplicitTxn = false;
         //this implies that no locks are needed for such a command
     }
@@ -1098,6 +1099,9 @@ private static List<HivePrivilegeObject> getHivePrivObjects(
       case PARTITION:
         // not currently handled
         continue;
+      case SERVICE_NAME:
+        objName = privObject.getServiceName();
+        break;
         default:
           throw new AssertionError("Unexpected object type");
       }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
index fd9197455d..2cf5bfdbea 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
@@ -179,6 +179,7 @@
 import org.apache.hadoop.hive.ql.plan.GrantDesc;
 import org.apache.hadoop.hive.ql.plan.GrantRevokeRoleDDL;
 import org.apache.hadoop.hive.ql.plan.InsertTableDesc;
+import org.apache.hadoop.hive.ql.plan.KillQueryDesc;
 import org.apache.hadoop.hive.ql.plan.ListBucketingCtx;
 import org.apache.hadoop.hive.ql.plan.LockDatabaseDesc;
 import org.apache.hadoop.hive.ql.plan.LockTableDesc;
@@ -592,6 +593,11 @@ public int execute(DriverContext driverContext) {
       if (preInsertTableDesc != null) {
         return preInsertWork(db, preInsertTableDesc);
       }
+
+      KillQueryDesc killQueryDesc = work.getKillQueryDesc();
+      if (killQueryDesc != null) {
+        return killQuery(db, killQueryDesc);
+      }
     } catch (Throwable e) {
       failed(e);
       return 1;
@@ -3031,6 +3037,15 @@ private int abortTxns(Hive db, AbortTxnsDesc desc) throws HiveException {
     return 0;
   }
 
+  private int killQuery(Hive db, KillQueryDesc desc) throws HiveException {
+    SessionState sessionState = SessionState.get();
+    for (String queryId : desc.getQueryIds()) {
+      sessionState.getKillQuery().killQuery(queryId);
+    }
+    LOG.info("kill query called (" + desc.getQueryIds().toString() + ")");
+    return 0;
+  }
+
    /**
    * Lock the table/partition specified
    * @param db
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java b/ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java
index 131c1e1bb5..820e4e2f67 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java
@@ -41,7 +41,7 @@ public class Entity implements Serializable {
    * The type of the entity.
    */
   public static enum Type {
-    DATABASE, TABLE, PARTITION, DUMMYPARTITION, DFS_DIR, LOCAL_DIR, FUNCTION
+    DATABASE, TABLE, PARTITION, DUMMYPARTITION, DFS_DIR, LOCAL_DIR, FUNCTION, SERVICE_NAME
   }
 
   /**
@@ -71,7 +71,7 @@ public static enum Type {
 
   /**
    * An object that is represented as a String
-   * Currently used for functions
+   * Currently used for functions and service name
    */
   private String stringObject;
 
@@ -154,6 +154,13 @@ public void setFunctionName(String funcName) {
     this.stringObject = funcName;
   }
 
+  public String getServiceName() {
+    if (typ == Type.SERVICE_NAME) {
+      return stringObject;
+    }
+    return null;
+  }
+
   /**
    * Only used by serialization.
    */
@@ -176,6 +183,21 @@ public Entity(Database database, boolean complete) {
     this.complete = complete;
   }
 
+  /**
+   * Constructor for a entity with string object representation (eg SERVICE_NAME)
+   *
+   * @param name
+   *          Used for service that action is being authorized on.
+   *          Currently hostname is used for service name.
+   * @param t
+   *         Type of entity
+   */
+  public Entity(String name, Type t) {
+    this.stringObject = name;
+    this.typ = t;
+    this.name = computeName();
+  }
+
   /**
    * Constructor for a table.
    *
@@ -345,6 +367,8 @@ private String doComputeName() {
         return database.getName() + "." + stringObject;
       }
       return stringObject;
+    case SERVICE_NAME:
+      return stringObject;
     default:
       return d.toString();
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java b/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java
index da8c1e2305..4707c4d1bb 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java
@@ -139,6 +139,11 @@ public WriteEntity(Path d, boolean islocal, boolean isTemp) {
     this.writeType = WriteType.PATH_WRITE;
   }
 
+  public WriteEntity(String name, Type t) {
+    super(name, t);
+    this.writeType = WriteType.DDL_NO_LOCK;
+  }
+
   /**
    * Determine which type of write this is.  This is needed by the lock
    * manager so it can understand what kind of lock to acquire.
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
index 2c55011d71..e70a72cabb 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
@@ -58,6 +58,7 @@
 import org.apache.hadoop.hive.ql.exec.Utilities;
 import org.apache.hadoop.hive.ql.hooks.ReadEntity;
 import org.apache.hadoop.hive.ql.hooks.WriteEntity;
+import org.apache.hadoop.hive.ql.hooks.Entity.Type;
 import org.apache.hadoop.hive.ql.hooks.WriteEntity.WriteType;
 import org.apache.hadoop.hive.ql.index.HiveIndex;
 import org.apache.hadoop.hive.ql.index.HiveIndex.IndexType;
@@ -105,6 +106,7 @@
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc;
 import org.apache.hadoop.hive.ql.plan.HiveOperation;
+import org.apache.hadoop.hive.ql.plan.KillQueryDesc;
 import org.apache.hadoop.hive.ql.plan.ListBucketingCtx;
 import org.apache.hadoop.hive.ql.plan.LoadTableDesc;
 import org.apache.hadoop.hive.ql.plan.LockDatabaseDesc;
@@ -401,6 +403,9 @@ public void analyzeInternal(ASTNode input) throws SemanticException {
     case HiveParser.TOK_ABORT_TRANSACTIONS:
       analyzeAbortTxns(ast);
       break;
+    case HiveParser.TOK_KILL_QUERY:
+      analyzeKillQuery(ast);
+      break;
     case HiveParser.TOK_SHOWCONF:
       ctx.setResFile(ctx.getLocalTmpPath());
       analyzeShowConf(ast);
@@ -2564,6 +2569,36 @@ private void analyzeAbortTxns(ASTNode ast) throws SemanticException {
   }
 
    /**
+   * Add a task to execute "Kill query"
+   * @param ast The parsed command tree
+   * @throws SemanticException Parsing failed
+   */
+  private void analyzeKillQuery(ASTNode ast) throws SemanticException {
+    List<String> queryIds = new ArrayList<String>();
+    int numChildren = ast.getChildCount();
+    for (int i = 0; i < numChildren; i++) {
+      queryIds.add(stripQuotes(ast.getChild(i).getText()));
+    }
+    KillQueryDesc desc = new KillQueryDesc(queryIds);
+    String hs2Hostname = getHS2Host();
+    if (hs2Hostname != null) {
+      outputs.add(new WriteEntity(hs2Hostname, Type.SERVICE_NAME));
+    }
+    rootTasks.add(TaskFactory.get(new DDLWork(getInputs(), getOutputs(), desc), conf));
+  }
+
+  private String getHS2Host() throws SemanticException {
+    if (SessionState.get().isHiveServerQuery()) {
+      return SessionState.get().getHiveServer2Host();
+    }
+    if (conf.getBoolVar(ConfVars.HIVE_TEST_AUTHORIZATION_SQLSTD_HS2_MODE)) {
+      // dummy value for use in tests
+      return "dummyHostnameForTest";
+    }
+    throw new SemanticException("Kill query is only supported in HiveServer2 (not hive cli)");
+  }
+
+  /**
    * Add the task according to the parsed command tree. This is used for the CLI
    * command "UNLOCK TABLE ..;".
    *
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g b/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g
index b5792ac485..0f1f6f617d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g
@@ -159,6 +159,7 @@ KW_COLLECTION: 'COLLECTION';
 KW_ITEMS: 'ITEMS';
 KW_KEYS: 'KEYS';
 KW_KEY_TYPE: '$KEY$';
+KW_KILL: 'KILL';
 KW_LINES: 'LINES';
 KW_STORED: 'STORED';
 KW_FILEFORMAT: 'FILEFORMAT';
@@ -308,6 +309,7 @@ KW_CONF: 'CONF';
 KW_VALUES: 'VALUES';
 KW_RELOAD: 'RELOAD';
 KW_YEAR: 'YEAR' | 'YEARS';
+KW_QUERY: 'QUERY';
 KW_QUARTER: 'QUARTER';
 KW_MONTH: 'MONTH' | 'MONTHS';
 KW_WEEK: 'WEEK' | 'WEEKS';
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g b/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
index 429e0d995a..e8fa9f2314 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
@@ -400,6 +400,7 @@ TOK_OPERATOR;
 TOK_EXPRESSION;
 TOK_DETAIL;
 TOK_BLOCKING;
+TOK_KILL_QUERY;
 }
 
 
@@ -570,6 +571,8 @@ import org.apache.hadoop.hive.conf.HiveConf;
     xlateMap.put("KW_COMPACTIONS", "COMPACTIONS");
     xlateMap.put("KW_COMPACT", "COMPACT");
     xlateMap.put("KW_WAIT", "WAIT");
+    xlateMap.put("KW_KILL", "KILL");
+    xlateMap.put("KW_QUERY", "QUERY");
 
     // Operators
     xlateMap.put("DOT", ".");
@@ -892,6 +895,7 @@ ddlStatement
     | setRole
     | showCurrentRole
     | abortTransactionStatement
+    | killQueryStatement
     ;
 
 ifExists
@@ -1896,7 +1900,7 @@ createMaterializedViewStatement
     : KW_CREATE KW_MATERIALIZED KW_VIEW (ifNotExists)? name=tableName
         rewriteEnabled? tableComment? tableRowFormat? tableFileFormat? tableLocation?
         tablePropertiesPrefixed? KW_AS selectStatementWithCTE
-    -> ^(TOK_CREATE_MATERIALIZED_VIEW $name 
+    -> ^(TOK_CREATE_MATERIALIZED_VIEW $name
          ifNotExists?
          rewriteEnabled?
          tableComment?
@@ -2921,3 +2925,10 @@ updateOrDelete
 /*
 END SQL Merge statement
 */
+
+killQueryStatement
+@init { pushMsg("kill query statement", state); }
+@after { popMsg(state); }
+  :
+  KW_KILL KW_QUERY ( StringLiteral )+ -> ^(TOK_KILL_QUERY ( StringLiteral )+)
+  ;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g b/ql/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g
index 003e09fd13..cd21de2d6c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g
@@ -786,11 +786,11 @@ nonReserved
     | KW_DESC | KW_DIRECTORIES | KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE | KW_DOW | KW_ELEM_TYPE 
     | KW_ENABLE | KW_ESCAPED | KW_EXCLUSIVE | KW_EXPLAIN | KW_EXPORT | KW_FIELDS | KW_FILE | KW_FILEFORMAT
     | KW_FIRST | KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_HOLD_DDLTIME | KW_HOUR | KW_IDXPROPERTIES | KW_IGNORE
-    | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER | KW_INPUTFORMAT | KW_ITEMS | KW_JAR
+    | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER | KW_INPUTFORMAT | KW_ITEMS | KW_JAR | KW_KILL
     | KW_KEYS | KW_KEY_TYPE | KW_LAST | KW_LIMIT | KW_OFFSET | KW_LINES | KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG
     | KW_MAPJOIN | KW_MATERIALIZED | KW_METADATA | KW_MINUTE | KW_MONTH | KW_MSCK | KW_NOSCAN | KW_NO_DROP | KW_NULLS | KW_OFFLINE
     | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT | KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PLUS | KW_PRETTY
-    | KW_PRINCIPALS | KW_PROTECTION | KW_PURGE | KW_QUARTER | KW_READ | KW_READONLY | KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER
+    | KW_PRINCIPALS | KW_PROTECTION | KW_PURGE | KW_QUERY | KW_QUARTER | KW_READ | KW_READONLY | KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER
     | KW_RELOAD | KW_RENAME | KW_REPAIR | KW_REPLACE | KW_REPLICATION | KW_RESTRICT | KW_REWRITE
     | KW_ROLE | KW_ROLES | KW_SCHEMA | KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER | KW_SETS | KW_SHARED
     | KW_SHOW | KW_SHOW_DATABASE | KW_SKEWED | KW_SORT | KW_SORTED | KW_SSL | KW_STATISTICS | KW_STORED
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
index 553dd64b5f..f481308da5 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
@@ -133,6 +133,7 @@ public final class SemanticAnalyzerFactory {
     commandType.put(HiveParser.TOK_REPL_DUMP, HiveOperation.REPLDUMP);
     commandType.put(HiveParser.TOK_REPL_LOAD, HiveOperation.REPLLOAD);
     commandType.put(HiveParser.TOK_REPL_STATUS, HiveOperation.REPLSTATUS);
+    commandType.put(HiveParser.TOK_KILL_QUERY, HiveOperation.KILL_QUERY);
   }
 
   static {
@@ -307,6 +308,7 @@ private static BaseSemanticAnalyzer getInternal(QueryState queryState, ASTNode t
       case HiveParser.TOK_TRUNCATETABLE:
       case HiveParser.TOK_SHOW_SET_ROLE:
       case HiveParser.TOK_CACHE_METADATA:
+      case HiveParser.TOK_KILL_QUERY:
         return new DDLSemanticAnalyzer(queryState);
 
       case HiveParser.TOK_CREATEFUNCTION:
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java
index 2b9e897a54..0b7c559648 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java
@@ -76,6 +76,7 @@ public class DDLWork implements Serializable {
   private AlterTableAlterPartDesc alterTableAlterPartDesc;
   private TruncateTableDesc truncateTblDesc;
   private AlterTableExchangePartition alterTableExchangePartition;
+  private KillQueryDesc killQueryDesc;
 
   private RoleDDLDesc roleDDLDesc;
   private GrantDesc grantDesc;
@@ -540,6 +541,12 @@ public DDLWork(HashSet<ReadEntity> inputs, HashSet<WriteEntity> outputs,
     this.preInsertTableDesc = preInsertTableDesc;
   }
 
+  public DDLWork(HashSet<ReadEntity> inputs, HashSet<WriteEntity> outputs,
+                 KillQueryDesc killQueryDesc) {
+    this(inputs, outputs);
+    this.killQueryDesc = killQueryDesc;
+  }
+
   /**
    * @return Create Database descriptor
    */
@@ -814,6 +821,11 @@ public DescFunctionDesc getDescFunctionDesc() {
     return descFunctionDesc;
   }
 
+  @Explain(displayName = "Kill Query Operator", explainLevels = { Level.USER, Level.DEFAULT, Level.EXTENDED })
+  public KillQueryDesc getKillQueryDesc() {
+    return killQueryDesc;
+  }
+
   /**
    * @param showFuncsDesc
    *          the showFuncsDesc to set
@@ -842,6 +854,10 @@ public void setAbortTxnsDesc(AbortTxnsDesc abortTxnsDesc) {
     this.abortTxnsDesc = abortTxnsDesc;
   }
 
+  public void setKillQueryDesc(KillQueryDesc killQueryDesc) {
+    this.killQueryDesc = killQueryDesc;
+  }
+
   /**
    * @param lockTblDesc
    *          the lockTblDesc to set
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java
index e1f1f53c3c..0f69de27dc 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java
@@ -138,7 +138,8 @@ public enum HiveOperation {
   COMMIT("COMMIT", null, null, true, true),
   ROLLBACK("ROLLBACK", null, null, true, true),
   SET_AUTOCOMMIT("SET AUTOCOMMIT", null, null, true, false),
-  ABORT_TRANSACTIONS("ABORT TRANSACTIONS", null, null, false, false);
+  ABORT_TRANSACTIONS("ABORT TRANSACTIONS", null, null, false, false),
+  KILL_QUERY("KILL QUERY", null, null);
 
   private String operationName;
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/KillQueryDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/KillQueryDesc.java
new file mode 100644
index 0000000000..84983d61ee
--- /dev/null
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/KillQueryDesc.java
@@ -0,0 +1,45 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.ql.plan;
+import java.io.Serializable;
+import java.util.List;
+
+/**
+ * Descriptor for killing queries.
+ */
+@Explain(displayName = "Kill Query", explainLevels = { Explain.Level.USER, Explain.Level.DEFAULT, Explain.Level.EXTENDED })
+public class KillQueryDesc extends DDLDesc implements Serializable {
+  private static final long serialVersionUID = 1L;
+  private List<String> queryIds;
+  
+  public KillQueryDesc() {
+  }
+
+  public KillQueryDesc(List<String> queryIds) {
+    this.queryIds = queryIds;
+  }
+
+  @Explain(displayName = "Query IDs", explainLevels = { Explain.Level.USER, Explain.Level.DEFAULT, Explain.Level.EXTENDED })
+  public List<String> getQueryIds() {
+    return queryIds;
+  }
+  
+  public void setQueryIds(List<String> queryIds) {
+    this.queryIds = queryIds;
+  }
+}
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationUtils.java
index 04e5565506..f1e443bd71 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationUtils.java
@@ -99,6 +99,8 @@ public static HivePrivilegeObjectType getHivePrivilegeObjectType(Type type) {
       return HivePrivilegeObjectType.PARTITION;
     case FUNCTION:
       return HivePrivilegeObjectType.FUNCTION;
+    case SERVICE_NAME:
+      return HivePrivilegeObjectType.SERVICE_NAME;
     default:
       return null;
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HiveOperationType.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HiveOperationType.java
index 3af97ea02f..a3ab8f00f0 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HiveOperationType.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HiveOperationType.java
@@ -131,6 +131,7 @@ public enum HiveOperationType {
   SHOW_COMPACTIONS,
   SHOW_TRANSACTIONS,
   ABORT_TRANSACTIONS,
+  KILL_QUERY,
   // ==== Hive command operation types starts here ==== //
   SET,
   RESET,
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HivePrivilegeObject.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HivePrivilegeObject.java
index 41983f1b4c..fb4c3206be 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HivePrivilegeObject.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HivePrivilegeObject.java
@@ -90,7 +90,11 @@ private int compare(Collection<String> o1, Collection<String> o2) {
    * used.
    */
   public enum HivePrivilegeObjectType {
-    GLOBAL, DATABASE, TABLE_OR_VIEW, PARTITION, COLUMN, LOCAL_URI, DFS_URI, COMMAND_PARAMS, FUNCTION
+    GLOBAL, DATABASE, TABLE_OR_VIEW, PARTITION, COLUMN, LOCAL_URI, DFS_URI, COMMAND_PARAMS, FUNCTION,
+    // HIVE_SERVICE refers to a logical service name. For now hiveserver2 hostname will be
+    // used to give service actions a name. This is used by kill query command so it can
+    // be authorized specifically to a service if necessary.
+    SERVICE_NAME
   };
 
   /**
@@ -238,6 +242,8 @@ public String toString() {
     case COMMAND_PARAMS:
       name = commandParams.toString();
       break;
+    case SERVICE_NAME:
+      name = objectName;
     }
 
     // get the string representing action type if its non default action type
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/Operation2Privilege.java b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/Operation2Privilege.java
index da99972e0c..366737a0ba 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/Operation2Privilege.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/Operation2Privilege.java
@@ -310,6 +310,7 @@ public HivePrivilegeObjectType getObjectType() {
         SEL_NOGRANT_AR, null));
     adminPrivOps.add(HiveOperationType.REPLDUMP);
     adminPrivOps.add(HiveOperationType.REPLLOAD);
+    adminPrivOps.add(HiveOperationType.KILL_QUERY);
 
     // operations require select priv
     op2Priv.put(HiveOperationType.SHOWCOLUMNS, PrivRequirement.newIOPrivRequirement
@@ -465,6 +466,7 @@ public HivePrivilegeObjectType getObjectType() {
             arr(SQLPrivTypeGrant.SELECT_NOGRANT, SQLPrivTypeGrant.DELETE_NOGRANT), INS_NOGRANT_AR));
     op2Priv.put(HiveOperationType.ABORT_TRANSACTIONS, PrivRequirement.newIOPrivRequirement
       (null, null));
+    op2Priv.put(HiveOperationType.KILL_QUERY, PrivRequirement.newIOPrivRequirement(null, null));
   }
 
   /**
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/session/KillQuery.java b/ql/src/java/org/apache/hadoop/hive/ql/session/KillQuery.java
new file mode 100644
index 0000000000..4bc81b3f51
--- /dev/null
+++ b/ql/src/java/org/apache/hadoop/hive/ql/session/KillQuery.java
@@ -0,0 +1,25 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.session;
+
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+
+public interface KillQuery {
+  void killQuery(String queryId) throws HiveException;
+}
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/session/NullKillQuery.java b/ql/src/java/org/apache/hadoop/hive/ql/session/NullKillQuery.java
new file mode 100644
index 0000000000..eab8fbfc39
--- /dev/null
+++ b/ql/src/java/org/apache/hadoop/hive/ql/session/NullKillQuery.java
@@ -0,0 +1,28 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.session;
+
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+
+public class NullKillQuery implements KillQuery {
+  @Override
+  public void killQuery(String queryId) throws HiveException {
+    // Do nothing
+  }
+}
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java b/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
index 97c8124293..cceeec02c1 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
@@ -189,6 +189,10 @@ public class SessionState {
   private HiveAuthorizer authorizerV2;
   private volatile ProgressMonitor progressMonitor;
 
+  private String hiveServer2HostName;
+
+  private KillQuery killQuery;
+
   public enum AuthorizationMode{V1, V2};
 
   private HiveAuthenticationProvider authenticator;
@@ -396,6 +400,7 @@ public SessionState(HiveConf conf, String userName) {
     this.sessionConf.setClassLoader(currentLoader);
     resourceDownloader = new ResourceDownloader(conf,
         HiveConf.getVar(conf, ConfVars.DOWNLOADED_RESOURCES_DIR));
+    killQuery = new NullKillQuery();
   }
 
   public Map<String, String> getHiveVariables() {
@@ -1907,6 +1912,21 @@ public ProgressMonitor getProgressMonitor() {
     return progressMonitor;
   }
 
+  public void setHiveServer2Host(String hiveServer2HostName) {
+    this.hiveServer2HostName = hiveServer2HostName;
+  }
+
+  public String getHiveServer2Host() {
+    return hiveServer2HostName;
+  }
+
+  public void setKillQuery(KillQuery killQuery) {
+    this.killQuery = killQuery;
+  }
+
+  public KillQuery getKillQuery() {
+    return killQuery;
+  }
 }
 
 class ResourceMaps {
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/parse/TestSQL11ReservedKeyWordsNegative.java b/ql/src/test/org/apache/hadoop/hive/ql/parse/TestSQL11ReservedKeyWordsNegative.java
index 1a89eb1263..71de3cb515 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/parse/TestSQL11ReservedKeyWordsNegative.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/parse/TestSQL11ReservedKeyWordsNegative.java
@@ -1163,4 +1163,17 @@ public void testSQL11ReservedKeyWords_TIME() {
     }
   }
 
+	@Test
+	public void testSQL11ReservedKeyWords_KILL() {
+		try {
+			parse("CREATE TABLE KILL QUERY (col STRING)");
+			Assert.fail("Expected ParseException");
+		} catch (ParseException ex) {
+			Assert.assertEquals(
+					"Failure didn't match.",
+					"line 1:18 cannot recognize input near 'QUERY' '(' 'col' in create table statement",
+					ex.getMessage());
+		}
+	}
+
 }
diff --git a/ql/src/test/queries/clientnegative/authorization_kill_query.q b/ql/src/test/queries/clientnegative/authorization_kill_query.q
new file mode 100644
index 0000000000..5379f87764
--- /dev/null
+++ b/ql/src/test/queries/clientnegative/authorization_kill_query.q
@@ -0,0 +1,15 @@
+set hive.security.authorization.enabled=true;
+set hive.test.authz.sstd.hs2.mode=true;
+set hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest;
+set hive.security.authenticator.manager=org.apache.hadoop.hive.ql.security.SessionStateConfigUserAuthenticator;
+
+set user.name=hive_admin_user;
+set role ADMIN;
+explain authorization kill query 'dummyqueryid';
+kill query 'dummyqueryid';
+
+set user.name=ruser1;
+
+-- kill query as non-admin should fail
+explain authorization kill query 'dummyqueryid';
+kill query 'dummyqueryid';
diff --git a/ql/src/test/queries/clientpositive/kill_query.q b/ql/src/test/queries/clientpositive/kill_query.q
new file mode 100644
index 0000000000..9949317b74
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/kill_query.q
@@ -0,0 +1,7 @@
+set hive.test.authz.sstd.hs2.mode=true;
+
+explain kill query 'query_1244656';
+explain kill query 'query_123456677' 'query_1238503495';
+
+kill query 'query_1244656';
+kill query 'query_123456677' 'query_1238503495';
diff --git a/ql/src/test/results/clientnegative/authorization_kill_query.q.out b/ql/src/test/results/clientnegative/authorization_kill_query.q.out
new file mode 100644
index 0000000000..1ce79c0ec7
--- /dev/null
+++ b/ql/src/test/results/clientnegative/authorization_kill_query.q.out
@@ -0,0 +1,34 @@
+PREHOOK: query: set role ADMIN
+PREHOOK: type: SHOW_ROLES
+POSTHOOK: query: set role ADMIN
+POSTHOOK: type: SHOW_ROLES
+PREHOOK: query: explain authorization kill query 'dummyqueryid'
+PREHOOK: type: KILL QUERY
+POSTHOOK: query: explain authorization kill query 'dummyqueryid'
+POSTHOOK: type: KILL QUERY
+INPUTS: 
+OUTPUTS: 
+  dummyHostnameForTest
+CURRENT_USER: 
+  hive_admin_user
+OPERATION: 
+  KILL_QUERY
+PREHOOK: query: kill query 'dummyqueryid'
+PREHOOK: type: KILL QUERY
+PREHOOK: Output: dummyHostnameForTest
+POSTHOOK: query: kill query 'dummyqueryid'
+POSTHOOK: type: KILL QUERY
+PREHOOK: query: explain authorization kill query 'dummyqueryid'
+PREHOOK: type: KILL QUERY
+POSTHOOK: query: explain authorization kill query 'dummyqueryid'
+POSTHOOK: type: KILL QUERY
+INPUTS: 
+OUTPUTS: 
+  dummyHostnameForTest
+CURRENT_USER: 
+  ruser1
+OPERATION: 
+  KILL_QUERY
+AUTHORIZATION_FAILURES: 
+  Permission denied: Principal [name=ruser1, type=USER] does not have following privileges for operation KILL_QUERY [ADMIN PRIVILEGE on INPUT, ADMIN PRIVILEGE on OUTPUT]
+FAILED: HiveAccessControlException Permission denied: Principal [name=ruser1, type=USER] does not have following privileges for operation KILL_QUERY [ADMIN PRIVILEGE on INPUT, ADMIN PRIVILEGE on OUTPUT]
diff --git a/ql/src/test/results/clientpositive/kill_query.q.out b/ql/src/test/results/clientpositive/kill_query.q.out
new file mode 100644
index 0000000000..c1800237e9
--- /dev/null
+++ b/ql/src/test/results/clientpositive/kill_query.q.out
@@ -0,0 +1,36 @@
+PREHOOK: query: explain kill query 'query_1244656'
+PREHOOK: type: KILL QUERY
+POSTHOOK: query: explain kill query 'query_1244656'
+POSTHOOK: type: KILL QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+      Kill Query Operator:
+        Kill Query
+          Query IDs: query_1244656
+
+PREHOOK: query: explain kill query 'query_123456677' 'query_1238503495'
+PREHOOK: type: KILL QUERY
+POSTHOOK: query: explain kill query 'query_123456677' 'query_1238503495'
+POSTHOOK: type: KILL QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+      Kill Query Operator:
+        Kill Query
+          Query IDs: query_123456677, query_1238503495
+
+PREHOOK: query: kill query 'query_1244656'
+PREHOOK: type: KILL QUERY
+PREHOOK: Output: dummyHostnameForTest
+POSTHOOK: query: kill query 'query_1244656'
+POSTHOOK: type: KILL QUERY
+PREHOOK: query: kill query 'query_123456677' 'query_1238503495'
+PREHOOK: type: KILL QUERY
+PREHOOK: Output: dummyHostnameForTest
+POSTHOOK: query: kill query 'query_123456677' 'query_1238503495'
+POSTHOOK: type: KILL QUERY
diff --git a/ql/src/test/results/clientpositive/llap/kill_query.q.out b/ql/src/test/results/clientpositive/llap/kill_query.q.out
new file mode 100644
index 0000000000..c1800237e9
--- /dev/null
+++ b/ql/src/test/results/clientpositive/llap/kill_query.q.out
@@ -0,0 +1,36 @@
+PREHOOK: query: explain kill query 'query_1244656'
+PREHOOK: type: KILL QUERY
+POSTHOOK: query: explain kill query 'query_1244656'
+POSTHOOK: type: KILL QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+      Kill Query Operator:
+        Kill Query
+          Query IDs: query_1244656
+
+PREHOOK: query: explain kill query 'query_123456677' 'query_1238503495'
+PREHOOK: type: KILL QUERY
+POSTHOOK: query: explain kill query 'query_123456677' 'query_1238503495'
+POSTHOOK: type: KILL QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+      Kill Query Operator:
+        Kill Query
+          Query IDs: query_123456677, query_1238503495
+
+PREHOOK: query: kill query 'query_1244656'
+PREHOOK: type: KILL QUERY
+PREHOOK: Output: dummyHostnameForTest
+POSTHOOK: query: kill query 'query_1244656'
+POSTHOOK: type: KILL QUERY
+PREHOOK: query: kill query 'query_123456677' 'query_1238503495'
+PREHOOK: type: KILL QUERY
+PREHOOK: Output: dummyHostnameForTest
+POSTHOOK: query: kill query 'query_123456677' 'query_1238503495'
+POSTHOOK: type: KILL QUERY
diff --git a/service-rpc/if/TCLIService.thrift b/service-rpc/if/TCLIService.thrift
index 976ca9b6b3..e03b36c4b7 100644
--- a/service-rpc/if/TCLIService.thrift
+++ b/service-rpc/if/TCLIService.thrift
@@ -1230,6 +1230,14 @@ struct TProgressUpdateResp {
   6: required i64 startTime
 }
 
+struct TGetQueryIdReq {
+  1: required TOperationHandle operationHandle
+}
+
+struct TGetQueryIdResp {
+  1: required string queryId
+}
+
 service TCLIService {
 
   TOpenSessionResp OpenSession(1:TOpenSessionReq req);
@@ -1273,4 +1281,6 @@ service TCLIService {
   TCancelDelegationTokenResp CancelDelegationToken(1:TCancelDelegationTokenReq req);
 
   TRenewDelegationTokenResp RenewDelegationToken(1:TRenewDelegationTokenReq req);
+
+  TGetQueryIdResp GetQueryId(1:TGetQueryIdReq req);
 }
diff --git a/service-rpc/src/gen/thrift/gen-cpp/TCLIService.cpp b/service-rpc/src/gen/thrift/gen-cpp/TCLIService.cpp
index 3597d44f2d..1f0b683b39 100644
--- a/service-rpc/src/gen/thrift/gen-cpp/TCLIService.cpp
+++ b/service-rpc/src/gen/thrift/gen-cpp/TCLIService.cpp
@@ -3935,6 +3935,193 @@ uint32_t TCLIService_RenewDelegationToken_presult::read(::apache::thrift::protoc
   return xfer;
 }
 
+
+TCLIService_GetQueryId_args::~TCLIService_GetQueryId_args() throw() {
+}
+
+
+uint32_t TCLIService_GetQueryId_args::read(::apache::thrift::protocol::TProtocol* iprot) {
+
+  apache::thrift::protocol::TInputRecursionTracker tracker(*iprot);
+  uint32_t xfer = 0;
+  std::string fname;
+  ::apache::thrift::protocol::TType ftype;
+  int16_t fid;
+
+  xfer += iprot->readStructBegin(fname);
+
+  using ::apache::thrift::protocol::TProtocolException;
+
+
+  while (true)
+  {
+    xfer += iprot->readFieldBegin(fname, ftype, fid);
+    if (ftype == ::apache::thrift::protocol::T_STOP) {
+      break;
+    }
+    switch (fid)
+    {
+      case 1:
+        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
+          xfer += this->req.read(iprot);
+          this->__isset.req = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      default:
+        xfer += iprot->skip(ftype);
+        break;
+    }
+    xfer += iprot->readFieldEnd();
+  }
+
+  xfer += iprot->readStructEnd();
+
+  return xfer;
+}
+
+uint32_t TCLIService_GetQueryId_args::write(::apache::thrift::protocol::TProtocol* oprot) const {
+  uint32_t xfer = 0;
+  apache::thrift::protocol::TOutputRecursionTracker tracker(*oprot);
+  xfer += oprot->writeStructBegin("TCLIService_GetQueryId_args");
+
+  xfer += oprot->writeFieldBegin("req", ::apache::thrift::protocol::T_STRUCT, 1);
+  xfer += this->req.write(oprot);
+  xfer += oprot->writeFieldEnd();
+
+  xfer += oprot->writeFieldStop();
+  xfer += oprot->writeStructEnd();
+  return xfer;
+}
+
+
+TCLIService_GetQueryId_pargs::~TCLIService_GetQueryId_pargs() throw() {
+}
+
+
+uint32_t TCLIService_GetQueryId_pargs::write(::apache::thrift::protocol::TProtocol* oprot) const {
+  uint32_t xfer = 0;
+  apache::thrift::protocol::TOutputRecursionTracker tracker(*oprot);
+  xfer += oprot->writeStructBegin("TCLIService_GetQueryId_pargs");
+
+  xfer += oprot->writeFieldBegin("req", ::apache::thrift::protocol::T_STRUCT, 1);
+  xfer += (*(this->req)).write(oprot);
+  xfer += oprot->writeFieldEnd();
+
+  xfer += oprot->writeFieldStop();
+  xfer += oprot->writeStructEnd();
+  return xfer;
+}
+
+
+TCLIService_GetQueryId_result::~TCLIService_GetQueryId_result() throw() {
+}
+
+
+uint32_t TCLIService_GetQueryId_result::read(::apache::thrift::protocol::TProtocol* iprot) {
+
+  apache::thrift::protocol::TInputRecursionTracker tracker(*iprot);
+  uint32_t xfer = 0;
+  std::string fname;
+  ::apache::thrift::protocol::TType ftype;
+  int16_t fid;
+
+  xfer += iprot->readStructBegin(fname);
+
+  using ::apache::thrift::protocol::TProtocolException;
+
+
+  while (true)
+  {
+    xfer += iprot->readFieldBegin(fname, ftype, fid);
+    if (ftype == ::apache::thrift::protocol::T_STOP) {
+      break;
+    }
+    switch (fid)
+    {
+      case 0:
+        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
+          xfer += this->success.read(iprot);
+          this->__isset.success = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      default:
+        xfer += iprot->skip(ftype);
+        break;
+    }
+    xfer += iprot->readFieldEnd();
+  }
+
+  xfer += iprot->readStructEnd();
+
+  return xfer;
+}
+
+uint32_t TCLIService_GetQueryId_result::write(::apache::thrift::protocol::TProtocol* oprot) const {
+
+  uint32_t xfer = 0;
+
+  xfer += oprot->writeStructBegin("TCLIService_GetQueryId_result");
+
+  if (this->__isset.success) {
+    xfer += oprot->writeFieldBegin("success", ::apache::thrift::protocol::T_STRUCT, 0);
+    xfer += this->success.write(oprot);
+    xfer += oprot->writeFieldEnd();
+  }
+  xfer += oprot->writeFieldStop();
+  xfer += oprot->writeStructEnd();
+  return xfer;
+}
+
+
+TCLIService_GetQueryId_presult::~TCLIService_GetQueryId_presult() throw() {
+}
+
+
+uint32_t TCLIService_GetQueryId_presult::read(::apache::thrift::protocol::TProtocol* iprot) {
+
+  apache::thrift::protocol::TInputRecursionTracker tracker(*iprot);
+  uint32_t xfer = 0;
+  std::string fname;
+  ::apache::thrift::protocol::TType ftype;
+  int16_t fid;
+
+  xfer += iprot->readStructBegin(fname);
+
+  using ::apache::thrift::protocol::TProtocolException;
+
+
+  while (true)
+  {
+    xfer += iprot->readFieldBegin(fname, ftype, fid);
+    if (ftype == ::apache::thrift::protocol::T_STOP) {
+      break;
+    }
+    switch (fid)
+    {
+      case 0:
+        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
+          xfer += (*(this->success)).read(iprot);
+          this->__isset.success = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      default:
+        xfer += iprot->skip(ftype);
+        break;
+    }
+    xfer += iprot->readFieldEnd();
+  }
+
+  xfer += iprot->readStructEnd();
+
+  return xfer;
+}
+
 void TCLIServiceClient::OpenSession(TOpenSessionResp& _return, const TOpenSessionReq& req)
 {
   send_OpenSession(req);
@@ -5153,6 +5340,64 @@ void TCLIServiceClient::recv_RenewDelegationToken(TRenewDelegationTokenResp& _re
   throw ::apache::thrift::TApplicationException(::apache::thrift::TApplicationException::MISSING_RESULT, "RenewDelegationToken failed: unknown result");
 }
 
+void TCLIServiceClient::GetQueryId(TGetQueryIdResp& _return, const TGetQueryIdReq& req)
+{
+  send_GetQueryId(req);
+  recv_GetQueryId(_return);
+}
+
+void TCLIServiceClient::send_GetQueryId(const TGetQueryIdReq& req)
+{
+  int32_t cseqid = 0;
+  oprot_->writeMessageBegin("GetQueryId", ::apache::thrift::protocol::T_CALL, cseqid);
+
+  TCLIService_GetQueryId_pargs args;
+  args.req = &req;
+  args.write(oprot_);
+
+  oprot_->writeMessageEnd();
+  oprot_->getTransport()->writeEnd();
+  oprot_->getTransport()->flush();
+}
+
+void TCLIServiceClient::recv_GetQueryId(TGetQueryIdResp& _return)
+{
+
+  int32_t rseqid = 0;
+  std::string fname;
+  ::apache::thrift::protocol::TMessageType mtype;
+
+  iprot_->readMessageBegin(fname, mtype, rseqid);
+  if (mtype == ::apache::thrift::protocol::T_EXCEPTION) {
+    ::apache::thrift::TApplicationException x;
+    x.read(iprot_);
+    iprot_->readMessageEnd();
+    iprot_->getTransport()->readEnd();
+    throw x;
+  }
+  if (mtype != ::apache::thrift::protocol::T_REPLY) {
+    iprot_->skip(::apache::thrift::protocol::T_STRUCT);
+    iprot_->readMessageEnd();
+    iprot_->getTransport()->readEnd();
+  }
+  if (fname.compare("GetQueryId") != 0) {
+    iprot_->skip(::apache::thrift::protocol::T_STRUCT);
+    iprot_->readMessageEnd();
+    iprot_->getTransport()->readEnd();
+  }
+  TCLIService_GetQueryId_presult result;
+  result.success = &_return;
+  result.read(iprot_);
+  iprot_->readMessageEnd();
+  iprot_->getTransport()->readEnd();
+
+  if (result.__isset.success) {
+    // _return pointer has now been filled
+    return;
+  }
+  throw ::apache::thrift::TApplicationException(::apache::thrift::TApplicationException::MISSING_RESULT, "GetQueryId failed: unknown result");
+}
+
 bool TCLIServiceProcessor::dispatchCall(::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, const std::string& fname, int32_t seqid, void* callContext) {
   ProcessMap::iterator pfn;
   pfn = processMap_.find(fname);
@@ -6306,6 +6551,60 @@ void TCLIServiceProcessor::process_RenewDelegationToken(int32_t seqid, ::apache:
   }
 }
 
+void TCLIServiceProcessor::process_GetQueryId(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext)
+{
+  void* ctx = NULL;
+  if (this->eventHandler_.get() != NULL) {
+    ctx = this->eventHandler_->getContext("TCLIService.GetQueryId", callContext);
+  }
+  ::apache::thrift::TProcessorContextFreer freer(this->eventHandler_.get(), ctx, "TCLIService.GetQueryId");
+
+  if (this->eventHandler_.get() != NULL) {
+    this->eventHandler_->preRead(ctx, "TCLIService.GetQueryId");
+  }
+
+  TCLIService_GetQueryId_args args;
+  args.read(iprot);
+  iprot->readMessageEnd();
+  uint32_t bytes = iprot->getTransport()->readEnd();
+
+  if (this->eventHandler_.get() != NULL) {
+    this->eventHandler_->postRead(ctx, "TCLIService.GetQueryId", bytes);
+  }
+
+  TCLIService_GetQueryId_result result;
+  try {
+    iface_->GetQueryId(result.success, args.req);
+    result.__isset.success = true;
+  } catch (const std::exception& e) {
+    if (this->eventHandler_.get() != NULL) {
+      this->eventHandler_->handlerError(ctx, "TCLIService.GetQueryId");
+    }
+
+    ::apache::thrift::TApplicationException x(e.what());
+    oprot->writeMessageBegin("GetQueryId", ::apache::thrift::protocol::T_EXCEPTION, seqid);
+    x.write(oprot);
+    oprot->writeMessageEnd();
+    oprot->getTransport()->writeEnd();
+    oprot->getTransport()->flush();
+    return;
+  }
+
+  if (this->eventHandler_.get() != NULL) {
+    this->eventHandler_->preWrite(ctx, "TCLIService.GetQueryId");
+  }
+
+  oprot->writeMessageBegin("GetQueryId", ::apache::thrift::protocol::T_REPLY, seqid);
+  result.write(oprot);
+  oprot->writeMessageEnd();
+  bytes = oprot->getTransport()->writeEnd();
+  oprot->getTransport()->flush();
+
+  if (this->eventHandler_.get() != NULL) {
+    this->eventHandler_->postWrite(ctx, "TCLIService.GetQueryId", bytes);
+  }
+}
+
 ::boost::shared_ptr< ::apache::thrift::TProcessor > TCLIServiceProcessorFactory::getProcessor(const ::apache::thrift::TConnectionInfo& connInfo) {
   ::apache::thrift::ReleaseHandler< TCLIServiceIfFactory > cleanup(handlerFactory_);
   ::boost::shared_ptr< TCLIServiceIf > handler(handlerFactory_->getHandler(connInfo), cleanup);
@@ -8077,5 +8376,89 @@ void TCLIServiceConcurrentClient::recv_RenewDelegationToken(TRenewDelegationToke
   } // end while(true)
 }
 
+void TCLIServiceConcurrentClient::GetQueryId(TGetQueryIdResp& _return, const TGetQueryIdReq& req)
+{
+  int32_t seqid = send_GetQueryId(req);
+  recv_GetQueryId(_return, seqid);
+}
+
+int32_t TCLIServiceConcurrentClient::send_GetQueryId(const TGetQueryIdReq& req)
+{
+  int32_t cseqid = this->sync_.generateSeqId();
+  ::apache::thrift::async::TConcurrentSendSentry sentry(&this->sync_);
+  oprot_->writeMessageBegin("GetQueryId", ::apache::thrift::protocol::T_CALL, cseqid);
+
+  TCLIService_GetQueryId_pargs args;
+  args.req = &req;
+  args.write(oprot_);
+
+  oprot_->writeMessageEnd();
+  oprot_->getTransport()->writeEnd();
+  oprot_->getTransport()->flush();
+
+  sentry.commit();
+  return cseqid;
+}
+
+void TCLIServiceConcurrentClient::recv_GetQueryId(TGetQueryIdResp& _return, const int32_t seqid)
+{
+
+  int32_t rseqid = 0;
+  std::string fname;
+  ::apache::thrift::protocol::TMessageType mtype;
+
+  // the read mutex gets dropped and reacquired as part of waitForWork()
+  // The destructor of this sentry wakes up other clients
+  ::apache::thrift::async::TConcurrentRecvSentry sentry(&this->sync_, seqid);
+
+  while(true) {
+    if(!this->sync_.getPending(fname, mtype, rseqid)) {
+      iprot_->readMessageBegin(fname, mtype, rseqid);
+    }
+    if(seqid == rseqid) {
+      if (mtype == ::apache::thrift::protocol::T_EXCEPTION) {
+        ::apache::thrift::TApplicationException x;
+        x.read(iprot_);
+        iprot_->readMessageEnd();
+        iprot_->getTransport()->readEnd();
+        sentry.commit();
+        throw x;
+      }
+      if (mtype != ::apache::thrift::protocol::T_REPLY) {
+        iprot_->skip(::apache::thrift::protocol::T_STRUCT);
+        iprot_->readMessageEnd();
+        iprot_->getTransport()->readEnd();
+      }
+      if (fname.compare("GetQueryId") != 0) {
+        iprot_->skip(::apache::thrift::protocol::T_STRUCT);
+        iprot_->readMessageEnd();
+        iprot_->getTransport()->readEnd();
+
+        // in a bad state, don't commit
+        using ::apache::thrift::protocol::TProtocolException;
+        throw TProtocolException(TProtocolException::INVALID_DATA);
+      }
+      TCLIService_GetQueryId_presult result;
+      result.success = &_return;
+      result.read(iprot_);
+      iprot_->readMessageEnd();
+      iprot_->getTransport()->readEnd();
+
+      if (result.__isset.success) {
+        // _return pointer has now been filled
+        sentry.commit();
+        return;
+      }
+      // in a bad state, don't commit
+      throw ::apache::thrift::TApplicationException(::apache::thrift::TApplicationException::MISSING_RESULT, "GetQueryId failed: unknown result");
+    }
+    // seqid != rseqid
+    this->sync_.updatePending(fname, mtype, rseqid);
+
+    // this will temporarily unlock the readMutex, and let other clients get work done
+    this->sync_.waitForWork(seqid);
+  } // end while(true)
+}
+
 }}}}} // namespace
 
diff --git a/service-rpc/src/gen/thrift/gen-cpp/TCLIService.h b/service-rpc/src/gen/thrift/gen-cpp/TCLIService.h
index 5fd423da6e..a508af7dbf 100644
--- a/service-rpc/src/gen/thrift/gen-cpp/TCLIService.h
+++ b/service-rpc/src/gen/thrift/gen-cpp/TCLIService.h
@@ -42,6 +42,7 @@ class TCLIServiceIf {
   virtual void GetDelegationToken(TGetDelegationTokenResp& _return, const TGetDelegationTokenReq& req) = 0;
   virtual void CancelDelegationToken(TCancelDelegationTokenResp& _return, const TCancelDelegationTokenReq& req) = 0;
   virtual void RenewDelegationToken(TRenewDelegationTokenResp& _return, const TRenewDelegationTokenReq& req) = 0;
+  virtual void GetQueryId(TGetQueryIdResp& _return, const TGetQueryIdReq& req) = 0;
 };
 
 class TCLIServiceIfFactory {
@@ -134,6 +135,9 @@ class TCLIServiceNull : virtual public TCLIServiceIf {
   void RenewDelegationToken(TRenewDelegationTokenResp& /* _return */, const TRenewDelegationTokenReq& /* req */) {
     return;
   }
+  void GetQueryId(TGetQueryIdResp& /* _return */, const TGetQueryIdReq& /* req */) {
+    return;
+  }
 };
 
 typedef struct _TCLIService_OpenSession_args__isset {
@@ -2320,6 +2324,110 @@ class TCLIService_RenewDelegationToken_presult {
 
 };
 
+typedef struct _TCLIService_GetQueryId_args__isset {
+  _TCLIService_GetQueryId_args__isset() : req(false) {}
+  bool req :1;
+} _TCLIService_GetQueryId_args__isset;
+
+class TCLIService_GetQueryId_args {
+ public:
+
+  TCLIService_GetQueryId_args(const TCLIService_GetQueryId_args&);
+  TCLIService_GetQueryId_args& operator=(const TCLIService_GetQueryId_args&);
+  TCLIService_GetQueryId_args() {
+  }
+
+  virtual ~TCLIService_GetQueryId_args() throw();
+  TGetQueryIdReq req;
+
+  _TCLIService_GetQueryId_args__isset __isset;
+
+  void __set_req(const TGetQueryIdReq& val);
+
+  bool operator == (const TCLIService_GetQueryId_args & rhs) const
+  {
+    if (!(req == rhs.req))
+      return false;
+    return true;
+  }
+  bool operator != (const TCLIService_GetQueryId_args &rhs) const {
+    return !(*this == rhs);
+  }
+
+  bool operator < (const TCLIService_GetQueryId_args & ) const;
+
+  uint32_t read(::apache::thrift::protocol::TProtocol* iprot);
+  uint32_t write(::apache::thrift::protocol::TProtocol* oprot) const;
+
+};
+
+
+class TCLIService_GetQueryId_pargs {
+ public:
+
+
+  virtual ~TCLIService_GetQueryId_pargs() throw();
+  const TGetQueryIdReq* req;
+
+  uint32_t write(::apache::thrift::protocol::TProtocol* oprot) const;
+
+};
+
+typedef struct _TCLIService_GetQueryId_result__isset {
+  _TCLIService_GetQueryId_result__isset() : success(false) {}
+  bool success :1;
+} _TCLIService_GetQueryId_result__isset;
+
+class TCLIService_GetQueryId_result {
+ public:
+
+  TCLIService_GetQueryId_result(const TCLIService_GetQueryId_result&);
+  TCLIService_GetQueryId_result& operator=(const TCLIService_GetQueryId_result&);
+  TCLIService_GetQueryId_result() {
+  }
+
+  virtual ~TCLIService_GetQueryId_result() throw();
+  TGetQueryIdResp success;
+
+  _TCLIService_GetQueryId_result__isset __isset;
+
+  void __set_success(const TGetQueryIdResp& val);
+
+  bool operator == (const TCLIService_GetQueryId_result & rhs) const
+  {
+    if (!(success == rhs.success))
+      return false;
+    return true;
+  }
+  bool operator != (const TCLIService_GetQueryId_result &rhs) const {
+    return !(*this == rhs);
+  }
+
+  bool operator < (const TCLIService_GetQueryId_result & ) const;
+
+  uint32_t read(::apache::thrift::protocol::TProtocol* iprot);
+  uint32_t write(::apache::thrift::protocol::TProtocol* oprot) const;
+
+};
+
+typedef struct _TCLIService_GetQueryId_presult__isset {
+  _TCLIService_GetQueryId_presult__isset() : success(false) {}
+  bool success :1;
+} _TCLIService_GetQueryId_presult__isset;
+
+class TCLIService_GetQueryId_presult {
+ public:
+
+
+  virtual ~TCLIService_GetQueryId_presult() throw();
+  TGetQueryIdResp* success;
+
+  _TCLIService_GetQueryId_presult__isset __isset;
+
+  uint32_t read(::apache::thrift::protocol::TProtocol* iprot);
+
+};
+
 class TCLIServiceClient : virtual public TCLIServiceIf {
  public:
   TCLIServiceClient(boost::shared_ptr< ::apache::thrift::protocol::TProtocol> prot) {
@@ -2408,6 +2516,9 @@ class TCLIServiceClient : virtual public TCLIServiceIf {
   void RenewDelegationToken(TRenewDelegationTokenResp& _return, const TRenewDelegationTokenReq& req);
   void send_RenewDelegationToken(const TRenewDelegationTokenReq& req);
   void recv_RenewDelegationToken(TRenewDelegationTokenResp& _return);
+  void GetQueryId(TGetQueryIdResp& _return, const TGetQueryIdReq& req);
+  void send_GetQueryId(const TGetQueryIdReq& req);
+  void recv_GetQueryId(TGetQueryIdResp& _return);
  protected:
   boost::shared_ptr< ::apache::thrift::protocol::TProtocol> piprot_;
   boost::shared_ptr< ::apache::thrift::protocol::TProtocol> poprot_;
@@ -2444,6 +2555,7 @@ class TCLIServiceProcessor : public ::apache::thrift::TDispatchProcessor {
   void process_GetDelegationToken(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext);
   void process_CancelDelegationToken(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext);
   void process_RenewDelegationToken(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext);
+  void process_GetQueryId(int32_t seqid, ::apache::thrift::protocol::TProtocol* iprot, ::apache::thrift::protocol::TProtocol* oprot, void* callContext);
  public:
   TCLIServiceProcessor(boost::shared_ptr<TCLIServiceIf> iface) :
     iface_(iface) {
@@ -2468,6 +2580,7 @@ class TCLIServiceProcessor : public ::apache::thrift::TDispatchProcessor {
     processMap_["GetDelegationToken"] = &TCLIServiceProcessor::process_GetDelegationToken;
     processMap_["CancelDelegationToken"] = &TCLIServiceProcessor::process_CancelDelegationToken;
     processMap_["RenewDelegationToken"] = &TCLIServiceProcessor::process_RenewDelegationToken;
+    processMap_["GetQueryId"] = &TCLIServiceProcessor::process_GetQueryId;
   }
 
   virtual ~TCLIServiceProcessor() {}
@@ -2706,6 +2819,16 @@ class TCLIServiceMultiface : virtual public TCLIServiceIf {
     return;
   }
 
+  void GetQueryId(TGetQueryIdResp& _return, const TGetQueryIdReq& req) {
+    size_t sz = ifaces_.size();
+    size_t i = 0;
+    for (; i < (sz - 1); ++i) {
+      ifaces_[i]->GetQueryId(_return, req);
+    }
+    ifaces_[i]->GetQueryId(_return, req);
+    return;
+  }
+
 };
 
 // The 'concurrent' client is a thread safe client that correctly handles
@@ -2799,6 +2922,9 @@ class TCLIServiceConcurrentClient : virtual public TCLIServiceIf {
   void RenewDelegationToken(TRenewDelegationTokenResp& _return, const TRenewDelegationTokenReq& req);
   int32_t send_RenewDelegationToken(const TRenewDelegationTokenReq& req);
   void recv_RenewDelegationToken(TRenewDelegationTokenResp& _return, const int32_t seqid);
+  void GetQueryId(TGetQueryIdResp& _return, const TGetQueryIdReq& req);
+  int32_t send_GetQueryId(const TGetQueryIdReq& req);
+  void recv_GetQueryId(TGetQueryIdResp& _return, const int32_t seqid);
  protected:
   boost::shared_ptr< ::apache::thrift::protocol::TProtocol> piprot_;
   boost::shared_ptr< ::apache::thrift::protocol::TProtocol> poprot_;
diff --git a/service-rpc/src/gen/thrift/gen-cpp/TCLIService_server.skeleton.cpp b/service-rpc/src/gen/thrift/gen-cpp/TCLIService_server.skeleton.cpp
index 5d7caf9783..9c8b466ad6 100644
--- a/service-rpc/src/gen/thrift/gen-cpp/TCLIService_server.skeleton.cpp
+++ b/service-rpc/src/gen/thrift/gen-cpp/TCLIService_server.skeleton.cpp
@@ -127,6 +127,11 @@ class TCLIServiceHandler : virtual public TCLIServiceIf {
     printf("RenewDelegationToken\n");
   }
 
+  void GetQueryId(TGetQueryIdResp& _return, const TGetQueryIdReq& req) {
+    // Your implementation goes here
+    printf("GetQueryId\n");
+  }
+
 };
 
 int main(int argc, char **argv) {
diff --git a/service-rpc/src/gen/thrift/gen-cpp/TCLIService_types.cpp b/service-rpc/src/gen/thrift/gen-cpp/TCLIService_types.cpp
index ec3f066516..d8c01b6070 100644
--- a/service-rpc/src/gen/thrift/gen-cpp/TCLIService_types.cpp
+++ b/service-rpc/src/gen/thrift/gen-cpp/TCLIService_types.cpp
@@ -10312,4 +10312,176 @@ void TProgressUpdateResp::printTo(std::ostream& out) const {
   out << ")";
 }
 
+
+TGetQueryIdReq::~TGetQueryIdReq() throw() {
+}
+
+
+void TGetQueryIdReq::__set_operationHandle(const TOperationHandle& val) {
+  this->operationHandle = val;
+}
+
+uint32_t TGetQueryIdReq::read(::apache::thrift::protocol::TProtocol* iprot) {
+
+  apache::thrift::protocol::TInputRecursionTracker tracker(*iprot);
+  uint32_t xfer = 0;
+  std::string fname;
+  ::apache::thrift::protocol::TType ftype;
+  int16_t fid;
+
+  xfer += iprot->readStructBegin(fname);
+
+  using ::apache::thrift::protocol::TProtocolException;
+
+  bool isset_operationHandle = false;
+
+  while (true)
+  {
+    xfer += iprot->readFieldBegin(fname, ftype, fid);
+    if (ftype == ::apache::thrift::protocol::T_STOP) {
+      break;
+    }
+    switch (fid)
+    {
+      case 1:
+        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
+          xfer += this->operationHandle.read(iprot);
+          isset_operationHandle = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      default:
+        xfer += iprot->skip(ftype);
+        break;
+    }
+    xfer += iprot->readFieldEnd();
+  }
+
+  xfer += iprot->readStructEnd();
+
+  if (!isset_operationHandle)
+    throw TProtocolException(TProtocolException::INVALID_DATA);
+  return xfer;
+}
+
+uint32_t TGetQueryIdReq::write(::apache::thrift::protocol::TProtocol* oprot) const {
+  uint32_t xfer = 0;
+  apache::thrift::protocol::TOutputRecursionTracker tracker(*oprot);
+  xfer += oprot->writeStructBegin("TGetQueryIdReq");
+
+  xfer += oprot->writeFieldBegin("operationHandle", ::apache::thrift::protocol::T_STRUCT, 1);
+  xfer += this->operationHandle.write(oprot);
+  xfer += oprot->writeFieldEnd();
+
+  xfer += oprot->writeFieldStop();
+  xfer += oprot->writeStructEnd();
+  return xfer;
+}
+
+void swap(TGetQueryIdReq &a, TGetQueryIdReq &b) {
+  using ::std::swap;
+  swap(a.operationHandle, b.operationHandle);
+}
+
+TGetQueryIdReq::TGetQueryIdReq(const TGetQueryIdReq& other323) {
+  operationHandle = other323.operationHandle;
+}
+TGetQueryIdReq& TGetQueryIdReq::operator=(const TGetQueryIdReq& other324) {
+  operationHandle = other324.operationHandle;
+  return *this;
+}
+void TGetQueryIdReq::printTo(std::ostream& out) const {
+  using ::apache::thrift::to_string;
+  out << "TGetQueryIdReq(";
+  out << "operationHandle=" << to_string(operationHandle);
+  out << ")";
+}
+
+
+TGetQueryIdResp::~TGetQueryIdResp() throw() {
+}
+
+
+void TGetQueryIdResp::__set_queryId(const std::string& val) {
+  this->queryId = val;
+}
+
+uint32_t TGetQueryIdResp::read(::apache::thrift::protocol::TProtocol* iprot) {
+
+  apache::thrift::protocol::TInputRecursionTracker tracker(*iprot);
+  uint32_t xfer = 0;
+  std::string fname;
+  ::apache::thrift::protocol::TType ftype;
+  int16_t fid;
+
+  xfer += iprot->readStructBegin(fname);
+
+  using ::apache::thrift::protocol::TProtocolException;
+
+  bool isset_queryId = false;
+
+  while (true)
+  {
+    xfer += iprot->readFieldBegin(fname, ftype, fid);
+    if (ftype == ::apache::thrift::protocol::T_STOP) {
+      break;
+    }
+    switch (fid)
+    {
+      case 1:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->queryId);
+          isset_queryId = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      default:
+        xfer += iprot->skip(ftype);
+        break;
+    }
+    xfer += iprot->readFieldEnd();
+  }
+
+  xfer += iprot->readStructEnd();
+
+  if (!isset_queryId)
+    throw TProtocolException(TProtocolException::INVALID_DATA);
+  return xfer;
+}
+
+uint32_t TGetQueryIdResp::write(::apache::thrift::protocol::TProtocol* oprot) const {
+  uint32_t xfer = 0;
+  apache::thrift::protocol::TOutputRecursionTracker tracker(*oprot);
+  xfer += oprot->writeStructBegin("TGetQueryIdResp");
+
+  xfer += oprot->writeFieldBegin("queryId", ::apache::thrift::protocol::T_STRING, 1);
+  xfer += oprot->writeString(this->queryId);
+  xfer += oprot->writeFieldEnd();
+
+  xfer += oprot->writeFieldStop();
+  xfer += oprot->writeStructEnd();
+  return xfer;
+}
+
+void swap(TGetQueryIdResp &a, TGetQueryIdResp &b) {
+  using ::std::swap;
+  swap(a.queryId, b.queryId);
+}
+
+TGetQueryIdResp::TGetQueryIdResp(const TGetQueryIdResp& other325) {
+  queryId = other325.queryId;
+}
+TGetQueryIdResp& TGetQueryIdResp::operator=(const TGetQueryIdResp& other326) {
+  queryId = other326.queryId;
+  return *this;
+}
+void TGetQueryIdResp::printTo(std::ostream& out) const {
+  using ::apache::thrift::to_string;
+  out << "TGetQueryIdResp(";
+  out << "queryId=" << to_string(queryId);
+  out << ")";
+}
+
 }}}}} // namespace
diff --git a/service-rpc/src/gen/thrift/gen-cpp/TCLIService_types.h b/service-rpc/src/gen/thrift/gen-cpp/TCLIService_types.h
index cb62db00ea..30a771d3d4 100644
--- a/service-rpc/src/gen/thrift/gen-cpp/TCLIService_types.h
+++ b/service-rpc/src/gen/thrift/gen-cpp/TCLIService_types.h
@@ -354,6 +354,10 @@ class TRenewDelegationTokenResp;
 
 class TProgressUpdateResp;
 
+class TGetQueryIdReq;
+
+class TGetQueryIdResp;
+
 typedef struct _TTypeQualifierValue__isset {
   _TTypeQualifierValue__isset() : i32Value(false), stringValue(false) {}
   bool i32Value :1;
@@ -4571,6 +4575,86 @@ inline std::ostream& operator<<(std::ostream& out, const TProgressUpdateResp& ob
   return out;
 }
 
+
+class TGetQueryIdReq {
+ public:
+
+  TGetQueryIdReq(const TGetQueryIdReq&);
+  TGetQueryIdReq& operator=(const TGetQueryIdReq&);
+  TGetQueryIdReq() {
+  }
+
+  virtual ~TGetQueryIdReq() throw();
+  TOperationHandle operationHandle;
+
+  void __set_operationHandle(const TOperationHandle& val);
+
+  bool operator == (const TGetQueryIdReq & rhs) const
+  {
+    if (!(operationHandle == rhs.operationHandle))
+      return false;
+    return true;
+  }
+  bool operator != (const TGetQueryIdReq &rhs) const {
+    return !(*this == rhs);
+  }
+
+  bool operator < (const TGetQueryIdReq & ) const;
+
+  uint32_t read(::apache::thrift::protocol::TProtocol* iprot);
+  uint32_t write(::apache::thrift::protocol::TProtocol* oprot) const;
+
+  virtual void printTo(std::ostream& out) const;
+};
+
+void swap(TGetQueryIdReq &a, TGetQueryIdReq &b);
+
+inline std::ostream& operator<<(std::ostream& out, const TGetQueryIdReq& obj)
+{
+  obj.printTo(out);
+  return out;
+}
+
+
+class TGetQueryIdResp {
+ public:
+
+  TGetQueryIdResp(const TGetQueryIdResp&);
+  TGetQueryIdResp& operator=(const TGetQueryIdResp&);
+  TGetQueryIdResp() : queryId() {
+  }
+
+  virtual ~TGetQueryIdResp() throw();
+  std::string queryId;
+
+  void __set_queryId(const std::string& val);
+
+  bool operator == (const TGetQueryIdResp & rhs) const
+  {
+    if (!(queryId == rhs.queryId))
+      return false;
+    return true;
+  }
+  bool operator != (const TGetQueryIdResp &rhs) const {
+    return !(*this == rhs);
+  }
+
+  bool operator < (const TGetQueryIdResp & ) const;
+
+  uint32_t read(::apache::thrift::protocol::TProtocol* iprot);
+  uint32_t write(::apache::thrift::protocol::TProtocol* oprot) const;
+
+  virtual void printTo(std::ostream& out) const;
+};
+
+void swap(TGetQueryIdResp &a, TGetQueryIdResp &b);
+
+inline std::ostream& operator<<(std::ostream& out, const TGetQueryIdResp& obj)
+{
+  obj.printTo(out);
+  return out;
+}
+
 }}}}} // namespace
 
 #endif
diff --git a/service-rpc/src/gen/thrift/gen-javabean/org/apache/hive/service/rpc/thrift/TCLIService.java b/service-rpc/src/gen/thrift/gen-javabean/org/apache/hive/service/rpc/thrift/TCLIService.java
index 6dba0512b4..2f44a4fba6 100644
--- a/service-rpc/src/gen/thrift/gen-javabean/org/apache/hive/service/rpc/thrift/TCLIService.java
+++ b/service-rpc/src/gen/thrift/gen-javabean/org/apache/hive/service/rpc/thrift/TCLIService.java
@@ -81,6 +81,8 @@ public interface Iface {
 
     public TRenewDelegationTokenResp RenewDelegationToken(TRenewDelegationTokenReq req) throws org.apache.thrift.TException;
 
+    public TGetQueryIdResp GetQueryId(TGetQueryIdReq req) throws org.apache.thrift.TException;
+
   }
 
   public interface AsyncIface {
@@ -127,6 +129,8 @@ public interface AsyncIface {
 
     public void RenewDelegationToken(TRenewDelegationTokenReq req, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException;
 
+    public void GetQueryId(TGetQueryIdReq req, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException;
+
   }
 
   public static class Client extends org.apache.thrift.TServiceClient implements Iface {
@@ -632,6 +636,29 @@ public TRenewDelegationTokenResp recv_RenewDelegationToken() throws org.apache.t
       throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "RenewDelegationToken failed: unknown result");
     }
 
+    public TGetQueryIdResp GetQueryId(TGetQueryIdReq req) throws org.apache.thrift.TException
+    {
+      send_GetQueryId(req);
+      return recv_GetQueryId();
+    }
+
+    public void send_GetQueryId(TGetQueryIdReq req) throws org.apache.thrift.TException
+    {
+      GetQueryId_args args = new GetQueryId_args();
+      args.setReq(req);
+      sendBase("GetQueryId", args);
+    }
+
+    public TGetQueryIdResp recv_GetQueryId() throws org.apache.thrift.TException
+    {
+      GetQueryId_result result = new GetQueryId_result();
+      receiveBase(result, "GetQueryId");
+      if (result.isSetSuccess()) {
+        return result.success;
+      }
+      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "GetQueryId failed: unknown result");
+    }
+
   }
   public static class AsyncClient extends org.apache.thrift.async.TAsyncClient implements AsyncIface {
     public static class Factory implements org.apache.thrift.async.TAsyncClientFactory<AsyncClient> {
@@ -1322,6 +1349,38 @@ public TRenewDelegationTokenResp getResult() throws org.apache.thrift.TException
       }
     }
 
+    public void GetQueryId(TGetQueryIdReq req, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {
+      checkReady();
+      GetQueryId_call method_call = new GetQueryId_call(req, resultHandler, this, ___protocolFactory, ___transport);
+      this.___currentMethod = method_call;
+      ___manager.call(method_call);
+    }
+
+    public static class GetQueryId_call extends org.apache.thrift.async.TAsyncMethodCall {
+      private TGetQueryIdReq req;
+      public GetQueryId_call(TGetQueryIdReq req, org.apache.thrift.async.AsyncMethodCallback resultHandler, org.apache.thrift.async.TAsyncClient client, org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.transport.TNonblockingTransport transport) throws org.apache.thrift.TException {
+        super(client, protocolFactory, transport, resultHandler, false);
+        this.req = req;
+      }
+
+      public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException {
+        prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("GetQueryId", org.apache.thrift.protocol.TMessageType.CALL, 0));
+        GetQueryId_args args = new GetQueryId_args();
+        args.setReq(req);
+        args.write(prot);
+        prot.writeMessageEnd();
+      }
+
+      public TGetQueryIdResp getResult() throws org.apache.thrift.TException {
+        if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
+          throw new IllegalStateException("Method call not finished!");
+        }
+        org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
+        org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
+        return (new Client(prot)).recv_GetQueryId();
+      }
+    }
+
   }
 
   public static class Processor<I extends Iface> extends org.apache.thrift.TBaseProcessor<I> implements org.apache.thrift.TProcessor {
@@ -1356,6 +1415,7 @@ protected Processor(I iface, Map<String,  org.apache.thrift.ProcessFunction<I, ?
       processMap.put("GetDelegationToken", new GetDelegationToken());
       processMap.put("CancelDelegationToken", new CancelDelegationToken());
       processMap.put("RenewDelegationToken", new RenewDelegationToken());
+      processMap.put("GetQueryId", new GetQueryId());
       return processMap;
     }
 
@@ -1779,6 +1839,26 @@ public RenewDelegationToken_result getResult(I iface, RenewDelegationToken_args
       }
     }
 
+    public static class GetQueryId<I extends Iface> extends org.apache.thrift.ProcessFunction<I, GetQueryId_args> {
+      public GetQueryId() {
+        super("GetQueryId");
+      }
+
+      public GetQueryId_args getEmptyArgsInstance() {
+        return new GetQueryId_args();
+      }
+
+      protected boolean isOneway() {
+        return false;
+      }
+
+      public GetQueryId_result getResult(I iface, GetQueryId_args args) throws org.apache.thrift.TException {
+        GetQueryId_result result = new GetQueryId_result();
+        result.success = iface.GetQueryId(args.req);
+        return result;
+      }
+    }
+
   }
 
   public static class AsyncProcessor<I extends AsyncIface> extends org.apache.thrift.TBaseAsyncProcessor<I> {
@@ -1813,6 +1893,7 @@ protected AsyncProcessor(I iface, Map<String,  org.apache.thrift.AsyncProcessFun
       processMap.put("GetDelegationToken", new GetDelegationToken());
       processMap.put("CancelDelegationToken", new CancelDelegationToken());
       processMap.put("RenewDelegationToken", new RenewDelegationToken());
+      processMap.put("GetQueryId", new GetQueryId());
       return processMap;
     }
 
@@ -2887,6 +2968,57 @@ public void start(I iface, RenewDelegationToken_args args, org.apache.thrift.asy
       }
     }
 
+    public static class GetQueryId<I extends AsyncIface> extends org.apache.thrift.AsyncProcessFunction<I, GetQueryId_args, TGetQueryIdResp> {
+      public GetQueryId() {
+        super("GetQueryId");
+      }
+
+      public GetQueryId_args getEmptyArgsInstance() {
+        return new GetQueryId_args();
+      }
+
+      public AsyncMethodCallback<TGetQueryIdResp> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {
+        final org.apache.thrift.AsyncProcessFunction fcall = this;
+        return new AsyncMethodCallback<TGetQueryIdResp>() { 
+          public void onComplete(TGetQueryIdResp o) {
+            GetQueryId_result result = new GetQueryId_result();
+            result.success = o;
+            try {
+              fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);
+              return;
+            } catch (Exception e) {
+              LOGGER.error("Exception writing to internal frame buffer", e);
+            }
+            fb.close();
+          }
+          public void onError(Exception e) {
+            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;
+            org.apache.thrift.TBase msg;
+            GetQueryId_result result = new GetQueryId_result();
+            {
+              msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;
+              msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());
+            }
+            try {
+              fcall.sendResponse(fb,msg,msgType,seqid);
+              return;
+            } catch (Exception ex) {
+              LOGGER.error("Exception writing to internal frame buffer", ex);
+            }
+            fb.close();
+          }
+        };
+      }
+
+      protected boolean isOneway() {
+        return false;
+      }
+
+      public void start(I iface, GetQueryId_args args, org.apache.thrift.async.AsyncMethodCallback<TGetQueryIdResp> resultHandler) throws TException {
+        iface.GetQueryId(args.req,resultHandler);
+      }
+    }
+
   }
 
   public static class OpenSession_args implements org.apache.thrift.TBase<OpenSession_args, OpenSession_args._Fields>, java.io.Serializable, Cloneable, Comparable<OpenSession_args>   {
@@ -18135,4 +18267,730 @@ public void read(org.apache.thrift.protocol.TProtocol prot, RenewDelegationToken
 
   }
 
+  public static class GetQueryId_args implements org.apache.thrift.TBase<GetQueryId_args, GetQueryId_args._Fields>, java.io.Serializable, Cloneable, Comparable<GetQueryId_args>   {
+    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("GetQueryId_args");
+
+    private static final org.apache.thrift.protocol.TField REQ_FIELD_DESC = new org.apache.thrift.protocol.TField("req", org.apache.thrift.protocol.TType.STRUCT, (short)1);
+
+    private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
+    static {
+      schemes.put(StandardScheme.class, new GetQueryId_argsStandardSchemeFactory());
+      schemes.put(TupleScheme.class, new GetQueryId_argsTupleSchemeFactory());
+    }
+
+    private TGetQueryIdReq req; // required
+
+    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
+    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
+      REQ((short)1, "req");
+
+      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
+
+      static {
+        for (_Fields field : EnumSet.allOf(_Fields.class)) {
+          byName.put(field.getFieldName(), field);
+        }
+      }
+
+      /**
+       * Find the _Fields constant that matches fieldId, or null if its not found.
+       */
+      public static _Fields findByThriftId(int fieldId) {
+        switch(fieldId) {
+          case 1: // REQ
+            return REQ;
+          default:
+            return null;
+        }
+      }
+
+      /**
+       * Find the _Fields constant that matches fieldId, throwing an exception
+       * if it is not found.
+       */
+      public static _Fields findByThriftIdOrThrow(int fieldId) {
+        _Fields fields = findByThriftId(fieldId);
+        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
+        return fields;
+      }
+
+      /**
+       * Find the _Fields constant that matches name, or null if its not found.
+       */
+      public static _Fields findByName(String name) {
+        return byName.get(name);
+      }
+
+      private final short _thriftId;
+      private final String _fieldName;
+
+      _Fields(short thriftId, String fieldName) {
+        _thriftId = thriftId;
+        _fieldName = fieldName;
+      }
+
+      public short getThriftFieldId() {
+        return _thriftId;
+      }
+
+      public String getFieldName() {
+        return _fieldName;
+      }
+    }
+
+    // isset id assignments
+    public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
+    static {
+      Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
+      tmpMap.put(_Fields.REQ, new org.apache.thrift.meta_data.FieldMetaData("req", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, TGetQueryIdReq.class)));
+      metaDataMap = Collections.unmodifiableMap(tmpMap);
+      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(GetQueryId_args.class, metaDataMap);
+    }
+
+    public GetQueryId_args() {
+    }
+
+    public GetQueryId_args(
+      TGetQueryIdReq req)
+    {
+      this();
+      this.req = req;
+    }
+
+    /**
+     * Performs a deep copy on <i>other</i>.
+     */
+    public GetQueryId_args(GetQueryId_args other) {
+      if (other.isSetReq()) {
+        this.req = new TGetQueryIdReq(other.req);
+      }
+    }
+
+    public GetQueryId_args deepCopy() {
+      return new GetQueryId_args(this);
+    }
+
+    @Override
+    public void clear() {
+      this.req = null;
+    }
+
+    public TGetQueryIdReq getReq() {
+      return this.req;
+    }
+
+    public void setReq(TGetQueryIdReq req) {
+      this.req = req;
+    }
+
+    public void unsetReq() {
+      this.req = null;
+    }
+
+    /** Returns true if field req is set (has been assigned a value) and false otherwise */
+    public boolean isSetReq() {
+      return this.req != null;
+    }
+
+    public void setReqIsSet(boolean value) {
+      if (!value) {
+        this.req = null;
+      }
+    }
+
+    public void setFieldValue(_Fields field, Object value) {
+      switch (field) {
+      case REQ:
+        if (value == null) {
+          unsetReq();
+        } else {
+          setReq((TGetQueryIdReq)value);
+        }
+        break;
+
+      }
+    }
+
+    public Object getFieldValue(_Fields field) {
+      switch (field) {
+      case REQ:
+        return getReq();
+
+      }
+      throw new IllegalStateException();
+    }
+
+    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
+    public boolean isSet(_Fields field) {
+      if (field == null) {
+        throw new IllegalArgumentException();
+      }
+
+      switch (field) {
+      case REQ:
+        return isSetReq();
+      }
+      throw new IllegalStateException();
+    }
+
+    @Override
+    public boolean equals(Object that) {
+      if (that == null)
+        return false;
+      if (that instanceof GetQueryId_args)
+        return this.equals((GetQueryId_args)that);
+      return false;
+    }
+
+    public boolean equals(GetQueryId_args that) {
+      if (that == null)
+        return false;
+
+      boolean this_present_req = true && this.isSetReq();
+      boolean that_present_req = true && that.isSetReq();
+      if (this_present_req || that_present_req) {
+        if (!(this_present_req && that_present_req))
+          return false;
+        if (!this.req.equals(that.req))
+          return false;
+      }
+
+      return true;
+    }
+
+    @Override
+    public int hashCode() {
+      List<Object> list = new ArrayList<Object>();
+
+      boolean present_req = true && (isSetReq());
+      list.add(present_req);
+      if (present_req)
+        list.add(req);
+
+      return list.hashCode();
+    }
+
+    @Override
+    public int compareTo(GetQueryId_args other) {
+      if (!getClass().equals(other.getClass())) {
+        return getClass().getName().compareTo(other.getClass().getName());
+      }
+
+      int lastComparison = 0;
+
+      lastComparison = Boolean.valueOf(isSetReq()).compareTo(other.isSetReq());
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+      if (isSetReq()) {
+        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.req, other.req);
+        if (lastComparison != 0) {
+          return lastComparison;
+        }
+      }
+      return 0;
+    }
+
+    public _Fields fieldForId(int fieldId) {
+      return _Fields.findByThriftId(fieldId);
+    }
+
+    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
+      schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
+    }
+
+    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
+      schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
+    }
+
+    @Override
+    public String toString() {
+      StringBuilder sb = new StringBuilder("GetQueryId_args(");
+      boolean first = true;
+
+      sb.append("req:");
+      if (this.req == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.req);
+      }
+      first = false;
+      sb.append(")");
+      return sb.toString();
+    }
+
+    public void validate() throws org.apache.thrift.TException {
+      // check for required fields
+      // check for sub-struct validity
+      if (req != null) {
+        req.validate();
+      }
+    }
+
+    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
+      try {
+        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
+      } catch (org.apache.thrift.TException te) {
+        throw new java.io.IOException(te);
+      }
+    }
+
+    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
+      try {
+        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
+      } catch (org.apache.thrift.TException te) {
+        throw new java.io.IOException(te);
+      }
+    }
+
+    private static class GetQueryId_argsStandardSchemeFactory implements SchemeFactory {
+      public GetQueryId_argsStandardScheme getScheme() {
+        return new GetQueryId_argsStandardScheme();
+      }
+    }
+
+    private static class GetQueryId_argsStandardScheme extends StandardScheme<GetQueryId_args> {
+
+      public void read(org.apache.thrift.protocol.TProtocol iprot, GetQueryId_args struct) throws org.apache.thrift.TException {
+        org.apache.thrift.protocol.TField schemeField;
+        iprot.readStructBegin();
+        while (true)
+        {
+          schemeField = iprot.readFieldBegin();
+          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
+            break;
+          }
+          switch (schemeField.id) {
+            case 1: // REQ
+              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
+                struct.req = new TGetQueryIdReq();
+                struct.req.read(iprot);
+                struct.setReqIsSet(true);
+              } else { 
+                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+              }
+              break;
+            default:
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+          }
+          iprot.readFieldEnd();
+        }
+        iprot.readStructEnd();
+        struct.validate();
+      }
+
+      public void write(org.apache.thrift.protocol.TProtocol oprot, GetQueryId_args struct) throws org.apache.thrift.TException {
+        struct.validate();
+
+        oprot.writeStructBegin(STRUCT_DESC);
+        if (struct.req != null) {
+          oprot.writeFieldBegin(REQ_FIELD_DESC);
+          struct.req.write(oprot);
+          oprot.writeFieldEnd();
+        }
+        oprot.writeFieldStop();
+        oprot.writeStructEnd();
+      }
+
+    }
+
+    private static class GetQueryId_argsTupleSchemeFactory implements SchemeFactory {
+      public GetQueryId_argsTupleScheme getScheme() {
+        return new GetQueryId_argsTupleScheme();
+      }
+    }
+
+    private static class GetQueryId_argsTupleScheme extends TupleScheme<GetQueryId_args> {
+
+      @Override
+      public void write(org.apache.thrift.protocol.TProtocol prot, GetQueryId_args struct) throws org.apache.thrift.TException {
+        TTupleProtocol oprot = (TTupleProtocol) prot;
+        BitSet optionals = new BitSet();
+        if (struct.isSetReq()) {
+          optionals.set(0);
+        }
+        oprot.writeBitSet(optionals, 1);
+        if (struct.isSetReq()) {
+          struct.req.write(oprot);
+        }
+      }
+
+      @Override
+      public void read(org.apache.thrift.protocol.TProtocol prot, GetQueryId_args struct) throws org.apache.thrift.TException {
+        TTupleProtocol iprot = (TTupleProtocol) prot;
+        BitSet incoming = iprot.readBitSet(1);
+        if (incoming.get(0)) {
+          struct.req = new TGetQueryIdReq();
+          struct.req.read(iprot);
+          struct.setReqIsSet(true);
+        }
+      }
+    }
+
+  }
+
+  public static class GetQueryId_result implements org.apache.thrift.TBase<GetQueryId_result, GetQueryId_result._Fields>, java.io.Serializable, Cloneable, Comparable<GetQueryId_result>   {
+    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("GetQueryId_result");
+
+    private static final org.apache.thrift.protocol.TField SUCCESS_FIELD_DESC = new org.apache.thrift.protocol.TField("success", org.apache.thrift.protocol.TType.STRUCT, (short)0);
+
+    private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
+    static {
+      schemes.put(StandardScheme.class, new GetQueryId_resultStandardSchemeFactory());
+      schemes.put(TupleScheme.class, new GetQueryId_resultTupleSchemeFactory());
+    }
+
+    private TGetQueryIdResp success; // required
+
+    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
+    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
+      SUCCESS((short)0, "success");
+
+      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
+
+      static {
+        for (_Fields field : EnumSet.allOf(_Fields.class)) {
+          byName.put(field.getFieldName(), field);
+        }
+      }
+
+      /**
+       * Find the _Fields constant that matches fieldId, or null if its not found.
+       */
+      public static _Fields findByThriftId(int fieldId) {
+        switch(fieldId) {
+          case 0: // SUCCESS
+            return SUCCESS;
+          default:
+            return null;
+        }
+      }
+
+      /**
+       * Find the _Fields constant that matches fieldId, throwing an exception
+       * if it is not found.
+       */
+      public static _Fields findByThriftIdOrThrow(int fieldId) {
+        _Fields fields = findByThriftId(fieldId);
+        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
+        return fields;
+      }
+
+      /**
+       * Find the _Fields constant that matches name, or null if its not found.
+       */
+      public static _Fields findByName(String name) {
+        return byName.get(name);
+      }
+
+      private final short _thriftId;
+      private final String _fieldName;
+
+      _Fields(short thriftId, String fieldName) {
+        _thriftId = thriftId;
+        _fieldName = fieldName;
+      }
+
+      public short getThriftFieldId() {
+        return _thriftId;
+      }
+
+      public String getFieldName() {
+        return _fieldName;
+      }
+    }
+
+    // isset id assignments
+    public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
+    static {
+      Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
+      tmpMap.put(_Fields.SUCCESS, new org.apache.thrift.meta_data.FieldMetaData("success", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+          new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, TGetQueryIdResp.class)));
+      metaDataMap = Collections.unmodifiableMap(tmpMap);
+      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(GetQueryId_result.class, metaDataMap);
+    }
+
+    public GetQueryId_result() {
+    }
+
+    public GetQueryId_result(
+      TGetQueryIdResp success)
+    {
+      this();
+      this.success = success;
+    }
+
+    /**
+     * Performs a deep copy on <i>other</i>.
+     */
+    public GetQueryId_result(GetQueryId_result other) {
+      if (other.isSetSuccess()) {
+        this.success = new TGetQueryIdResp(other.success);
+      }
+    }
+
+    public GetQueryId_result deepCopy() {
+      return new GetQueryId_result(this);
+    }
+
+    @Override
+    public void clear() {
+      this.success = null;
+    }
+
+    public TGetQueryIdResp getSuccess() {
+      return this.success;
+    }
+
+    public void setSuccess(TGetQueryIdResp success) {
+      this.success = success;
+    }
+
+    public void unsetSuccess() {
+      this.success = null;
+    }
+
+    /** Returns true if field success is set (has been assigned a value) and false otherwise */
+    public boolean isSetSuccess() {
+      return this.success != null;
+    }
+
+    public void setSuccessIsSet(boolean value) {
+      if (!value) {
+        this.success = null;
+      }
+    }
+
+    public void setFieldValue(_Fields field, Object value) {
+      switch (field) {
+      case SUCCESS:
+        if (value == null) {
+          unsetSuccess();
+        } else {
+          setSuccess((TGetQueryIdResp)value);
+        }
+        break;
+
+      }
+    }
+
+    public Object getFieldValue(_Fields field) {
+      switch (field) {
+      case SUCCESS:
+        return getSuccess();
+
+      }
+      throw new IllegalStateException();
+    }
+
+    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
+    public boolean isSet(_Fields field) {
+      if (field == null) {
+        throw new IllegalArgumentException();
+      }
+
+      switch (field) {
+      case SUCCESS:
+        return isSetSuccess();
+      }
+      throw new IllegalStateException();
+    }
+
+    @Override
+    public boolean equals(Object that) {
+      if (that == null)
+        return false;
+      if (that instanceof GetQueryId_result)
+        return this.equals((GetQueryId_result)that);
+      return false;
+    }
+
+    public boolean equals(GetQueryId_result that) {
+      if (that == null)
+        return false;
+
+      boolean this_present_success = true && this.isSetSuccess();
+      boolean that_present_success = true && that.isSetSuccess();
+      if (this_present_success || that_present_success) {
+        if (!(this_present_success && that_present_success))
+          return false;
+        if (!this.success.equals(that.success))
+          return false;
+      }
+
+      return true;
+    }
+
+    @Override
+    public int hashCode() {
+      List<Object> list = new ArrayList<Object>();
+
+      boolean present_success = true && (isSetSuccess());
+      list.add(present_success);
+      if (present_success)
+        list.add(success);
+
+      return list.hashCode();
+    }
+
+    @Override
+    public int compareTo(GetQueryId_result other) {
+      if (!getClass().equals(other.getClass())) {
+        return getClass().getName().compareTo(other.getClass().getName());
+      }
+
+      int lastComparison = 0;
+
+      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(other.isSetSuccess());
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+      if (isSetSuccess()) {
+        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, other.success);
+        if (lastComparison != 0) {
+          return lastComparison;
+        }
+      }
+      return 0;
+    }
+
+    public _Fields fieldForId(int fieldId) {
+      return _Fields.findByThriftId(fieldId);
+    }
+
+    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
+      schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
+    }
+
+    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
+      schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
+      }
+
+    @Override
+    public String toString() {
+      StringBuilder sb = new StringBuilder("GetQueryId_result(");
+      boolean first = true;
+
+      sb.append("success:");
+      if (this.success == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.success);
+      }
+      first = false;
+      sb.append(")");
+      return sb.toString();
+    }
+
+    public void validate() throws org.apache.thrift.TException {
+      // check for required fields
+      // check for sub-struct validity
+      if (success != null) {
+        success.validate();
+      }
+    }
+
+    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
+      try {
+        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
+      } catch (org.apache.thrift.TException te) {
+        throw new java.io.IOException(te);
+      }
+    }
+
+    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
+      try {
+        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
+      } catch (org.apache.thrift.TException te) {
+        throw new java.io.IOException(te);
+      }
+    }
+
+    private static class GetQueryId_resultStandardSchemeFactory implements SchemeFactory {
+      public GetQueryId_resultStandardScheme getScheme() {
+        return new GetQueryId_resultStandardScheme();
+      }
+    }
+
+    private static class GetQueryId_resultStandardScheme extends StandardScheme<GetQueryId_result> {
+
+      public void read(org.apache.thrift.protocol.TProtocol iprot, GetQueryId_result struct) throws org.apache.thrift.TException {
+        org.apache.thrift.protocol.TField schemeField;
+        iprot.readStructBegin();
+        while (true)
+        {
+          schemeField = iprot.readFieldBegin();
+          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
+            break;
+          }
+          switch (schemeField.id) {
+            case 0: // SUCCESS
+              if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
+                struct.success = new TGetQueryIdResp();
+                struct.success.read(iprot);
+                struct.setSuccessIsSet(true);
+              } else { 
+                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+              }
+              break;
+            default:
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+          }
+          iprot.readFieldEnd();
+        }
+        iprot.readStructEnd();
+        struct.validate();
+      }
+
+      public void write(org.apache.thrift.protocol.TProtocol oprot, GetQueryId_result struct) throws org.apache.thrift.TException {
+        struct.validate();
+
+        oprot.writeStructBegin(STRUCT_DESC);
+        if (struct.success != null) {
+          oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
+          struct.success.write(oprot);
+          oprot.writeFieldEnd();
+        }
+        oprot.writeFieldStop();
+        oprot.writeStructEnd();
+      }
+
+    }
+
+    private static class GetQueryId_resultTupleSchemeFactory implements SchemeFactory {
+      public GetQueryId_resultTupleScheme getScheme() {
+        return new GetQueryId_resultTupleScheme();
+      }
+    }
+
+    private static class GetQueryId_resultTupleScheme extends TupleScheme<GetQueryId_result> {
+
+      @Override
+      public void write(org.apache.thrift.protocol.TProtocol prot, GetQueryId_result struct) throws org.apache.thrift.TException {
+        TTupleProtocol oprot = (TTupleProtocol) prot;
+        BitSet optionals = new BitSet();
+        if (struct.isSetSuccess()) {
+          optionals.set(0);
+        }
+        oprot.writeBitSet(optionals, 1);
+        if (struct.isSetSuccess()) {
+          struct.success.write(oprot);
+        }
+      }
+
+      @Override
+      public void read(org.apache.thrift.protocol.TProtocol prot, GetQueryId_result struct) throws org.apache.thrift.TException {
+        TTupleProtocol iprot = (TTupleProtocol) prot;
+        BitSet incoming = iprot.readBitSet(1);
+        if (incoming.get(0)) {
+          struct.success = new TGetQueryIdResp();
+          struct.success.read(iprot);
+          struct.setSuccessIsSet(true);
+        }
+      }
+    }
+
+  }
+
 }
diff --git a/service-rpc/src/gen/thrift/gen-javabean/org/apache/hive/service/rpc/thrift/TGetQueryIdReq.java b/service-rpc/src/gen/thrift/gen-javabean/org/apache/hive/service/rpc/thrift/TGetQueryIdReq.java
new file mode 100644
index 0000000000..bc904f19ff
--- /dev/null
+++ b/service-rpc/src/gen/thrift/gen-javabean/org/apache/hive/service/rpc/thrift/TGetQueryIdReq.java
@@ -0,0 +1,394 @@
+/**
+ * Autogenerated by Thrift Compiler (0.9.3)
+ *
+ * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
+ *  @generated
+ */
+package org.apache.hive.service.rpc.thrift;
+
+import org.apache.thrift.scheme.IScheme;
+import org.apache.thrift.scheme.SchemeFactory;
+import org.apache.thrift.scheme.StandardScheme;
+
+import org.apache.thrift.scheme.TupleScheme;
+import org.apache.thrift.protocol.TTupleProtocol;
+import org.apache.thrift.protocol.TProtocolException;
+import org.apache.thrift.EncodingUtils;
+import org.apache.thrift.TException;
+import org.apache.thrift.async.AsyncMethodCallback;
+import org.apache.thrift.server.AbstractNonblockingServer.*;
+import java.util.List;
+import java.util.ArrayList;
+import java.util.Map;
+import java.util.HashMap;
+import java.util.EnumMap;
+import java.util.Set;
+import java.util.HashSet;
+import java.util.EnumSet;
+import java.util.Collections;
+import java.util.BitSet;
+import java.nio.ByteBuffer;
+import java.util.Arrays;
+import javax.annotation.Generated;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+@SuppressWarnings({"cast", "rawtypes", "serial", "unchecked"})
+@Generated(value = "Autogenerated by Thrift Compiler (0.9.3)")
+public class TGetQueryIdReq implements org.apache.thrift.TBase<TGetQueryIdReq, TGetQueryIdReq._Fields>, java.io.Serializable, Cloneable, Comparable<TGetQueryIdReq> {
+  private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("TGetQueryIdReq");
+
+  private static final org.apache.thrift.protocol.TField OPERATION_HANDLE_FIELD_DESC = new org.apache.thrift.protocol.TField("operationHandle", org.apache.thrift.protocol.TType.STRUCT, (short)1);
+
+  private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
+  static {
+    schemes.put(StandardScheme.class, new TGetQueryIdReqStandardSchemeFactory());
+    schemes.put(TupleScheme.class, new TGetQueryIdReqTupleSchemeFactory());
+  }
+
+  private TOperationHandle operationHandle; // required
+
+  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
+  public enum _Fields implements org.apache.thrift.TFieldIdEnum {
+    OPERATION_HANDLE((short)1, "operationHandle");
+
+    private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
+
+    static {
+      for (_Fields field : EnumSet.allOf(_Fields.class)) {
+        byName.put(field.getFieldName(), field);
+      }
+    }
+
+    /**
+     * Find the _Fields constant that matches fieldId, or null if its not found.
+     */
+    public static _Fields findByThriftId(int fieldId) {
+      switch(fieldId) {
+        case 1: // OPERATION_HANDLE
+          return OPERATION_HANDLE;
+        default:
+          return null;
+      }
+    }
+
+    /**
+     * Find the _Fields constant that matches fieldId, throwing an exception
+     * if it is not found.
+     */
+    public static _Fields findByThriftIdOrThrow(int fieldId) {
+      _Fields fields = findByThriftId(fieldId);
+      if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
+      return fields;
+    }
+
+    /**
+     * Find the _Fields constant that matches name, or null if its not found.
+     */
+    public static _Fields findByName(String name) {
+      return byName.get(name);
+    }
+
+    private final short _thriftId;
+    private final String _fieldName;
+
+    _Fields(short thriftId, String fieldName) {
+      _thriftId = thriftId;
+      _fieldName = fieldName;
+    }
+
+    public short getThriftFieldId() {
+      return _thriftId;
+    }
+
+    public String getFieldName() {
+      return _fieldName;
+    }
+  }
+
+  // isset id assignments
+  public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
+  static {
+    Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
+    tmpMap.put(_Fields.OPERATION_HANDLE, new org.apache.thrift.meta_data.FieldMetaData("operationHandle", org.apache.thrift.TFieldRequirementType.REQUIRED, 
+        new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, TOperationHandle.class)));
+    metaDataMap = Collections.unmodifiableMap(tmpMap);
+    org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(TGetQueryIdReq.class, metaDataMap);
+  }
+
+  public TGetQueryIdReq() {
+  }
+
+  public TGetQueryIdReq(
+    TOperationHandle operationHandle)
+  {
+    this();
+    this.operationHandle = operationHandle;
+  }
+
+  /**
+   * Performs a deep copy on <i>other</i>.
+   */
+  public TGetQueryIdReq(TGetQueryIdReq other) {
+    if (other.isSetOperationHandle()) {
+      this.operationHandle = new TOperationHandle(other.operationHandle);
+    }
+  }
+
+  public TGetQueryIdReq deepCopy() {
+    return new TGetQueryIdReq(this);
+  }
+
+  @Override
+  public void clear() {
+    this.operationHandle = null;
+  }
+
+  public TOperationHandle getOperationHandle() {
+    return this.operationHandle;
+  }
+
+  public void setOperationHandle(TOperationHandle operationHandle) {
+    this.operationHandle = operationHandle;
+  }
+
+  public void unsetOperationHandle() {
+    this.operationHandle = null;
+  }
+
+  /** Returns true if field operationHandle is set (has been assigned a value) and false otherwise */
+  public boolean isSetOperationHandle() {
+    return this.operationHandle != null;
+  }
+
+  public void setOperationHandleIsSet(boolean value) {
+    if (!value) {
+      this.operationHandle = null;
+    }
+  }
+
+  public void setFieldValue(_Fields field, Object value) {
+    switch (field) {
+    case OPERATION_HANDLE:
+      if (value == null) {
+        unsetOperationHandle();
+      } else {
+        setOperationHandle((TOperationHandle)value);
+      }
+      break;
+
+    }
+  }
+
+  public Object getFieldValue(_Fields field) {
+    switch (field) {
+    case OPERATION_HANDLE:
+      return getOperationHandle();
+
+    }
+    throw new IllegalStateException();
+  }
+
+  /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
+  public boolean isSet(_Fields field) {
+    if (field == null) {
+      throw new IllegalArgumentException();
+    }
+
+    switch (field) {
+    case OPERATION_HANDLE:
+      return isSetOperationHandle();
+    }
+    throw new IllegalStateException();
+  }
+
+  @Override
+  public boolean equals(Object that) {
+    if (that == null)
+      return false;
+    if (that instanceof TGetQueryIdReq)
+      return this.equals((TGetQueryIdReq)that);
+    return false;
+  }
+
+  public boolean equals(TGetQueryIdReq that) {
+    if (that == null)
+      return false;
+
+    boolean this_present_operationHandle = true && this.isSetOperationHandle();
+    boolean that_present_operationHandle = true && that.isSetOperationHandle();
+    if (this_present_operationHandle || that_present_operationHandle) {
+      if (!(this_present_operationHandle && that_present_operationHandle))
+        return false;
+      if (!this.operationHandle.equals(that.operationHandle))
+        return false;
+    }
+
+    return true;
+  }
+
+  @Override
+  public int hashCode() {
+    List<Object> list = new ArrayList<Object>();
+
+    boolean present_operationHandle = true && (isSetOperationHandle());
+    list.add(present_operationHandle);
+    if (present_operationHandle)
+      list.add(operationHandle);
+
+    return list.hashCode();
+  }
+
+  @Override
+  public int compareTo(TGetQueryIdReq other) {
+    if (!getClass().equals(other.getClass())) {
+      return getClass().getName().compareTo(other.getClass().getName());
+    }
+
+    int lastComparison = 0;
+
+    lastComparison = Boolean.valueOf(isSetOperationHandle()).compareTo(other.isSetOperationHandle());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetOperationHandle()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.operationHandle, other.operationHandle);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    return 0;
+  }
+
+  public _Fields fieldForId(int fieldId) {
+    return _Fields.findByThriftId(fieldId);
+  }
+
+  public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
+    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
+  }
+
+  public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
+    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
+  }
+
+  @Override
+  public String toString() {
+    StringBuilder sb = new StringBuilder("TGetQueryIdReq(");
+    boolean first = true;
+
+    sb.append("operationHandle:");
+    if (this.operationHandle == null) {
+      sb.append("null");
+    } else {
+      sb.append(this.operationHandle);
+    }
+    first = false;
+    sb.append(")");
+    return sb.toString();
+  }
+
+  public void validate() throws org.apache.thrift.TException {
+    // check for required fields
+    if (!isSetOperationHandle()) {
+      throw new org.apache.thrift.protocol.TProtocolException("Required field 'operationHandle' is unset! Struct:" + toString());
+    }
+
+    // check for sub-struct validity
+    if (operationHandle != null) {
+      operationHandle.validate();
+    }
+  }
+
+  private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
+    try {
+      write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
+    } catch (org.apache.thrift.TException te) {
+      throw new java.io.IOException(te);
+    }
+  }
+
+  private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
+    try {
+      read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
+    } catch (org.apache.thrift.TException te) {
+      throw new java.io.IOException(te);
+    }
+  }
+
+  private static class TGetQueryIdReqStandardSchemeFactory implements SchemeFactory {
+    public TGetQueryIdReqStandardScheme getScheme() {
+      return new TGetQueryIdReqStandardScheme();
+    }
+  }
+
+  private static class TGetQueryIdReqStandardScheme extends StandardScheme<TGetQueryIdReq> {
+
+    public void read(org.apache.thrift.protocol.TProtocol iprot, TGetQueryIdReq struct) throws org.apache.thrift.TException {
+      org.apache.thrift.protocol.TField schemeField;
+      iprot.readStructBegin();
+      while (true)
+      {
+        schemeField = iprot.readFieldBegin();
+        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
+          break;
+        }
+        switch (schemeField.id) {
+          case 1: // OPERATION_HANDLE
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
+              struct.operationHandle = new TOperationHandle();
+              struct.operationHandle.read(iprot);
+              struct.setOperationHandleIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
+          default:
+            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+        }
+        iprot.readFieldEnd();
+      }
+      iprot.readStructEnd();
+      struct.validate();
+    }
+
+    public void write(org.apache.thrift.protocol.TProtocol oprot, TGetQueryIdReq struct) throws org.apache.thrift.TException {
+      struct.validate();
+
+      oprot.writeStructBegin(STRUCT_DESC);
+      if (struct.operationHandle != null) {
+        oprot.writeFieldBegin(OPERATION_HANDLE_FIELD_DESC);
+        struct.operationHandle.write(oprot);
+        oprot.writeFieldEnd();
+      }
+      oprot.writeFieldStop();
+      oprot.writeStructEnd();
+    }
+
+  }
+
+  private static class TGetQueryIdReqTupleSchemeFactory implements SchemeFactory {
+    public TGetQueryIdReqTupleScheme getScheme() {
+      return new TGetQueryIdReqTupleScheme();
+    }
+  }
+
+  private static class TGetQueryIdReqTupleScheme extends TupleScheme<TGetQueryIdReq> {
+
+    @Override
+    public void write(org.apache.thrift.protocol.TProtocol prot, TGetQueryIdReq struct) throws org.apache.thrift.TException {
+      TTupleProtocol oprot = (TTupleProtocol) prot;
+      struct.operationHandle.write(oprot);
+    }
+
+    @Override
+    public void read(org.apache.thrift.protocol.TProtocol prot, TGetQueryIdReq struct) throws org.apache.thrift.TException {
+      TTupleProtocol iprot = (TTupleProtocol) prot;
+      struct.operationHandle = new TOperationHandle();
+      struct.operationHandle.read(iprot);
+      struct.setOperationHandleIsSet(true);
+    }
+  }
+
+}
+
diff --git a/service-rpc/src/gen/thrift/gen-javabean/org/apache/hive/service/rpc/thrift/TGetQueryIdResp.java b/service-rpc/src/gen/thrift/gen-javabean/org/apache/hive/service/rpc/thrift/TGetQueryIdResp.java
new file mode 100644
index 0000000000..91aa1e90cd
--- /dev/null
+++ b/service-rpc/src/gen/thrift/gen-javabean/org/apache/hive/service/rpc/thrift/TGetQueryIdResp.java
@@ -0,0 +1,389 @@
+/**
+ * Autogenerated by Thrift Compiler (0.9.3)
+ *
+ * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
+ *  @generated
+ */
+package org.apache.hive.service.rpc.thrift;
+
+import org.apache.thrift.scheme.IScheme;
+import org.apache.thrift.scheme.SchemeFactory;
+import org.apache.thrift.scheme.StandardScheme;
+
+import org.apache.thrift.scheme.TupleScheme;
+import org.apache.thrift.protocol.TTupleProtocol;
+import org.apache.thrift.protocol.TProtocolException;
+import org.apache.thrift.EncodingUtils;
+import org.apache.thrift.TException;
+import org.apache.thrift.async.AsyncMethodCallback;
+import org.apache.thrift.server.AbstractNonblockingServer.*;
+import java.util.List;
+import java.util.ArrayList;
+import java.util.Map;
+import java.util.HashMap;
+import java.util.EnumMap;
+import java.util.Set;
+import java.util.HashSet;
+import java.util.EnumSet;
+import java.util.Collections;
+import java.util.BitSet;
+import java.nio.ByteBuffer;
+import java.util.Arrays;
+import javax.annotation.Generated;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+@SuppressWarnings({"cast", "rawtypes", "serial", "unchecked"})
+@Generated(value = "Autogenerated by Thrift Compiler (0.9.3)")
+public class TGetQueryIdResp implements org.apache.thrift.TBase<TGetQueryIdResp, TGetQueryIdResp._Fields>, java.io.Serializable, Cloneable, Comparable<TGetQueryIdResp> {
+  private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("TGetQueryIdResp");
+
+  private static final org.apache.thrift.protocol.TField QUERY_ID_FIELD_DESC = new org.apache.thrift.protocol.TField("queryId", org.apache.thrift.protocol.TType.STRING, (short)1);
+
+  private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
+  static {
+    schemes.put(StandardScheme.class, new TGetQueryIdRespStandardSchemeFactory());
+    schemes.put(TupleScheme.class, new TGetQueryIdRespTupleSchemeFactory());
+  }
+
+  private String queryId; // required
+
+  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
+  public enum _Fields implements org.apache.thrift.TFieldIdEnum {
+    QUERY_ID((short)1, "queryId");
+
+    private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
+
+    static {
+      for (_Fields field : EnumSet.allOf(_Fields.class)) {
+        byName.put(field.getFieldName(), field);
+      }
+    }
+
+    /**
+     * Find the _Fields constant that matches fieldId, or null if its not found.
+     */
+    public static _Fields findByThriftId(int fieldId) {
+      switch(fieldId) {
+        case 1: // QUERY_ID
+          return QUERY_ID;
+        default:
+          return null;
+      }
+    }
+
+    /**
+     * Find the _Fields constant that matches fieldId, throwing an exception
+     * if it is not found.
+     */
+    public static _Fields findByThriftIdOrThrow(int fieldId) {
+      _Fields fields = findByThriftId(fieldId);
+      if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
+      return fields;
+    }
+
+    /**
+     * Find the _Fields constant that matches name, or null if its not found.
+     */
+    public static _Fields findByName(String name) {
+      return byName.get(name);
+    }
+
+    private final short _thriftId;
+    private final String _fieldName;
+
+    _Fields(short thriftId, String fieldName) {
+      _thriftId = thriftId;
+      _fieldName = fieldName;
+    }
+
+    public short getThriftFieldId() {
+      return _thriftId;
+    }
+
+    public String getFieldName() {
+      return _fieldName;
+    }
+  }
+
+  // isset id assignments
+  public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
+  static {
+    Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
+    tmpMap.put(_Fields.QUERY_ID, new org.apache.thrift.meta_data.FieldMetaData("queryId", org.apache.thrift.TFieldRequirementType.REQUIRED, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
+    metaDataMap = Collections.unmodifiableMap(tmpMap);
+    org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(TGetQueryIdResp.class, metaDataMap);
+  }
+
+  public TGetQueryIdResp() {
+  }
+
+  public TGetQueryIdResp(
+    String queryId)
+  {
+    this();
+    this.queryId = queryId;
+  }
+
+  /**
+   * Performs a deep copy on <i>other</i>.
+   */
+  public TGetQueryIdResp(TGetQueryIdResp other) {
+    if (other.isSetQueryId()) {
+      this.queryId = other.queryId;
+    }
+  }
+
+  public TGetQueryIdResp deepCopy() {
+    return new TGetQueryIdResp(this);
+  }
+
+  @Override
+  public void clear() {
+    this.queryId = null;
+  }
+
+  public String getQueryId() {
+    return this.queryId;
+  }
+
+  public void setQueryId(String queryId) {
+    this.queryId = queryId;
+  }
+
+  public void unsetQueryId() {
+    this.queryId = null;
+  }
+
+  /** Returns true if field queryId is set (has been assigned a value) and false otherwise */
+  public boolean isSetQueryId() {
+    return this.queryId != null;
+  }
+
+  public void setQueryIdIsSet(boolean value) {
+    if (!value) {
+      this.queryId = null;
+    }
+  }
+
+  public void setFieldValue(_Fields field, Object value) {
+    switch (field) {
+    case QUERY_ID:
+      if (value == null) {
+        unsetQueryId();
+      } else {
+        setQueryId((String)value);
+      }
+      break;
+
+    }
+  }
+
+  public Object getFieldValue(_Fields field) {
+    switch (field) {
+    case QUERY_ID:
+      return getQueryId();
+
+    }
+    throw new IllegalStateException();
+  }
+
+  /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
+  public boolean isSet(_Fields field) {
+    if (field == null) {
+      throw new IllegalArgumentException();
+    }
+
+    switch (field) {
+    case QUERY_ID:
+      return isSetQueryId();
+    }
+    throw new IllegalStateException();
+  }
+
+  @Override
+  public boolean equals(Object that) {
+    if (that == null)
+      return false;
+    if (that instanceof TGetQueryIdResp)
+      return this.equals((TGetQueryIdResp)that);
+    return false;
+  }
+
+  public boolean equals(TGetQueryIdResp that) {
+    if (that == null)
+      return false;
+
+    boolean this_present_queryId = true && this.isSetQueryId();
+    boolean that_present_queryId = true && that.isSetQueryId();
+    if (this_present_queryId || that_present_queryId) {
+      if (!(this_present_queryId && that_present_queryId))
+        return false;
+      if (!this.queryId.equals(that.queryId))
+        return false;
+    }
+
+    return true;
+  }
+
+  @Override
+  public int hashCode() {
+    List<Object> list = new ArrayList<Object>();
+
+    boolean present_queryId = true && (isSetQueryId());
+    list.add(present_queryId);
+    if (present_queryId)
+      list.add(queryId);
+
+    return list.hashCode();
+  }
+
+  @Override
+  public int compareTo(TGetQueryIdResp other) {
+    if (!getClass().equals(other.getClass())) {
+      return getClass().getName().compareTo(other.getClass().getName());
+    }
+
+    int lastComparison = 0;
+
+    lastComparison = Boolean.valueOf(isSetQueryId()).compareTo(other.isSetQueryId());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetQueryId()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.queryId, other.queryId);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    return 0;
+  }
+
+  public _Fields fieldForId(int fieldId) {
+    return _Fields.findByThriftId(fieldId);
+  }
+
+  public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
+    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
+  }
+
+  public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
+    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
+  }
+
+  @Override
+  public String toString() {
+    StringBuilder sb = new StringBuilder("TGetQueryIdResp(");
+    boolean first = true;
+
+    sb.append("queryId:");
+    if (this.queryId == null) {
+      sb.append("null");
+    } else {
+      sb.append(this.queryId);
+    }
+    first = false;
+    sb.append(")");
+    return sb.toString();
+  }
+
+  public void validate() throws org.apache.thrift.TException {
+    // check for required fields
+    if (!isSetQueryId()) {
+      throw new org.apache.thrift.protocol.TProtocolException("Required field 'queryId' is unset! Struct:" + toString());
+    }
+
+    // check for sub-struct validity
+  }
+
+  private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
+    try {
+      write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
+    } catch (org.apache.thrift.TException te) {
+      throw new java.io.IOException(te);
+    }
+  }
+
+  private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
+    try {
+      read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
+    } catch (org.apache.thrift.TException te) {
+      throw new java.io.IOException(te);
+    }
+  }
+
+  private static class TGetQueryIdRespStandardSchemeFactory implements SchemeFactory {
+    public TGetQueryIdRespStandardScheme getScheme() {
+      return new TGetQueryIdRespStandardScheme();
+    }
+  }
+
+  private static class TGetQueryIdRespStandardScheme extends StandardScheme<TGetQueryIdResp> {
+
+    public void read(org.apache.thrift.protocol.TProtocol iprot, TGetQueryIdResp struct) throws org.apache.thrift.TException {
+      org.apache.thrift.protocol.TField schemeField;
+      iprot.readStructBegin();
+      while (true)
+      {
+        schemeField = iprot.readFieldBegin();
+        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
+          break;
+        }
+        switch (schemeField.id) {
+          case 1: // QUERY_ID
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
+              struct.queryId = iprot.readString();
+              struct.setQueryIdIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
+          default:
+            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+        }
+        iprot.readFieldEnd();
+      }
+      iprot.readStructEnd();
+      struct.validate();
+    }
+
+    public void write(org.apache.thrift.protocol.TProtocol oprot, TGetQueryIdResp struct) throws org.apache.thrift.TException {
+      struct.validate();
+
+      oprot.writeStructBegin(STRUCT_DESC);
+      if (struct.queryId != null) {
+        oprot.writeFieldBegin(QUERY_ID_FIELD_DESC);
+        oprot.writeString(struct.queryId);
+        oprot.writeFieldEnd();
+      }
+      oprot.writeFieldStop();
+      oprot.writeStructEnd();
+    }
+
+  }
+
+  private static class TGetQueryIdRespTupleSchemeFactory implements SchemeFactory {
+    public TGetQueryIdRespTupleScheme getScheme() {
+      return new TGetQueryIdRespTupleScheme();
+    }
+  }
+
+  private static class TGetQueryIdRespTupleScheme extends TupleScheme<TGetQueryIdResp> {
+
+    @Override
+    public void write(org.apache.thrift.protocol.TProtocol prot, TGetQueryIdResp struct) throws org.apache.thrift.TException {
+      TTupleProtocol oprot = (TTupleProtocol) prot;
+      oprot.writeString(struct.queryId);
+    }
+
+    @Override
+    public void read(org.apache.thrift.protocol.TProtocol prot, TGetQueryIdResp struct) throws org.apache.thrift.TException {
+      TTupleProtocol iprot = (TTupleProtocol) prot;
+      struct.queryId = iprot.readString();
+      struct.setQueryIdIsSet(true);
+    }
+  }
+
+}
+
diff --git a/service-rpc/src/gen/thrift/gen-php/TCLIService.php b/service-rpc/src/gen/thrift/gen-php/TCLIService.php
index d283145b69..c76b24c6ce 100644
--- a/service-rpc/src/gen/thrift/gen-php/TCLIService.php
+++ b/service-rpc/src/gen/thrift/gen-php/TCLIService.php
@@ -121,6 +121,11 @@ interface TCLIServiceIf {
    * @return \TRenewDelegationTokenResp
    */
   public function RenewDelegationToken(\TRenewDelegationTokenReq $req);
+  /**
+   * @param \TGetQueryIdReq $req
+   * @return \TGetQueryIdResp
+   */
+  public function GetQueryId(\TGetQueryIdReq $req);
 }
 
 class TCLIServiceClient implements \TCLIServiceIf {
@@ -1205,6 +1210,57 @@ class TCLIServiceClient implements \TCLIServiceIf {
     throw new \Exception("RenewDelegationToken failed: unknown result");
   }
 
+  public function GetQueryId(\TGetQueryIdReq $req)
+  {
+    $this->send_GetQueryId($req);
+    return $this->recv_GetQueryId();
+  }
+
+  public function send_GetQueryId(\TGetQueryIdReq $req)
+  {
+    $args = new \TCLIService_GetQueryId_args();
+    $args->req = $req;
+    $bin_accel = ($this->output_ instanceof TBinaryProtocolAccelerated) && function_exists('thrift_protocol_write_binary');
+    if ($bin_accel)
+    {
+      thrift_protocol_write_binary($this->output_, 'GetQueryId', TMessageType::CALL, $args, $this->seqid_, $this->output_->isStrictWrite());
+    }
+    else
+    {
+      $this->output_->writeMessageBegin('GetQueryId', TMessageType::CALL, $this->seqid_);
+      $args->write($this->output_);
+      $this->output_->writeMessageEnd();
+      $this->output_->getTransport()->flush();
+    }
+  }
+
+  public function recv_GetQueryId()
+  {
+    $bin_accel = ($this->input_ instanceof TBinaryProtocolAccelerated) && function_exists('thrift_protocol_read_binary');
+    if ($bin_accel) $result = thrift_protocol_read_binary($this->input_, '\TCLIService_GetQueryId_result', $this->input_->isStrictRead());
+    else
+    {
+      $rseqid = 0;
+      $fname = null;
+      $mtype = 0;
+
+      $this->input_->readMessageBegin($fname, $mtype, $rseqid);
+      if ($mtype == TMessageType::EXCEPTION) {
+        $x = new TApplicationException();
+        $x->read($this->input_);
+        $this->input_->readMessageEnd();
+        throw $x;
+      }
+      $result = new \TCLIService_GetQueryId_result();
+      $result->read($this->input_);
+      $this->input_->readMessageEnd();
+    }
+    if ($result->success !== null) {
+      return $result->success;
+    }
+    throw new \Exception("GetQueryId failed: unknown result");
+  }
+
 }
 
 // HELPER FUNCTIONS AND STRUCTURES
@@ -4569,4 +4625,164 @@ class TCLIService_RenewDelegationToken_result {
 
 }
 
+class TCLIService_GetQueryId_args {
+  static $_TSPEC;
+
+  /**
+   * @var \TGetQueryIdReq
+   */
+  public $req = null;
+
+  public function __construct($vals=null) {
+    if (!isset(self::$_TSPEC)) {
+      self::$_TSPEC = array(
+        1 => array(
+          'var' => 'req',
+          'type' => TType::STRUCT,
+          'class' => '\TGetQueryIdReq',
+          ),
+        );
+    }
+    if (is_array($vals)) {
+      if (isset($vals['req'])) {
+        $this->req = $vals['req'];
+      }
+    }
+  }
+
+  public function getName() {
+    return 'TCLIService_GetQueryId_args';
+  }
+
+  public function read($input)
+  {
+    $xfer = 0;
+    $fname = null;
+    $ftype = 0;
+    $fid = 0;
+    $xfer += $input->readStructBegin($fname);
+    while (true)
+    {
+      $xfer += $input->readFieldBegin($fname, $ftype, $fid);
+      if ($ftype == TType::STOP) {
+        break;
+      }
+      switch ($fid)
+      {
+        case 1:
+          if ($ftype == TType::STRUCT) {
+            $this->req = new \TGetQueryIdReq();
+            $xfer += $this->req->read($input);
+          } else {
+            $xfer += $input->skip($ftype);
+          }
+          break;
+        default:
+          $xfer += $input->skip($ftype);
+          break;
+      }
+      $xfer += $input->readFieldEnd();
+    }
+    $xfer += $input->readStructEnd();
+    return $xfer;
+  }
+
+  public function write($output) {
+    $xfer = 0;
+    $xfer += $output->writeStructBegin('TCLIService_GetQueryId_args');
+    if ($this->req !== null) {
+      if (!is_object($this->req)) {
+        throw new TProtocolException('Bad type in structure.', TProtocolException::INVALID_DATA);
+      }
+      $xfer += $output->writeFieldBegin('req', TType::STRUCT, 1);
+      $xfer += $this->req->write($output);
+      $xfer += $output->writeFieldEnd();
+    }
+    $xfer += $output->writeFieldStop();
+    $xfer += $output->writeStructEnd();
+    return $xfer;
+  }
+
+}
+
+class TCLIService_GetQueryId_result {
+  static $_TSPEC;
+
+  /**
+   * @var \TGetQueryIdResp
+   */
+  public $success = null;
+
+  public function __construct($vals=null) {
+    if (!isset(self::$_TSPEC)) {
+      self::$_TSPEC = array(
+        0 => array(
+          'var' => 'success',
+          'type' => TType::STRUCT,
+          'class' => '\TGetQueryIdResp',
+          ),
+        );
+    }
+    if (is_array($vals)) {
+      if (isset($vals['success'])) {
+        $this->success = $vals['success'];
+      }
+    }
+  }
+
+  public function getName() {
+    return 'TCLIService_GetQueryId_result';
+  }
+
+  public function read($input)
+  {
+    $xfer = 0;
+    $fname = null;
+    $ftype = 0;
+    $fid = 0;
+    $xfer += $input->readStructBegin($fname);
+    while (true)
+    {
+      $xfer += $input->readFieldBegin($fname, $ftype, $fid);
+      if ($ftype == TType::STOP) {
+        break;
+      }
+      switch ($fid)
+      {
+        case 0:
+          if ($ftype == TType::STRUCT) {
+            $this->success = new \TGetQueryIdResp();
+            $xfer += $this->success->read($input);
+          } else {
+            $xfer += $input->skip($ftype);
+          }
+          break;
+        default:
+          $xfer += $input->skip($ftype);
+          break;
+      }
+      $xfer += $input->readFieldEnd();
+    }
+    $xfer += $input->readStructEnd();
+    return $xfer;
+  }
+
+  public function write($output) {
+    $xfer = 0;
+    $xfer += $output->writeStructBegin('TCLIService_GetQueryId_result');
+    if ($this->success !== null) {
+      if (!is_object($this->success)) {
+        throw new TProtocolException('Bad type in structure.', TProtocolException::INVALID_DATA);
+      }
+      $xfer += $output->writeFieldBegin('success', TType::STRUCT, 0);
+      $xfer += $this->success->write($output);
+      $xfer += $output->writeFieldEnd();
+    }
+    $xfer += $output->writeFieldStop();
+    $xfer += $output->writeStructEnd();
+    return $xfer;
+  }
+
+}
+
 
diff --git a/service-rpc/src/gen/thrift/gen-php/Types.php b/service-rpc/src/gen/thrift/gen-php/Types.php
index f34a0cf30a..da2b811354 100644
--- a/service-rpc/src/gen/thrift/gen-php/Types.php
+++ b/service-rpc/src/gen/thrift/gen-php/Types.php
@@ -10029,6 +10029,161 @@ class TProgressUpdateResp {
 
 }
 
+class TGetQueryIdReq {
+  static $_TSPEC;
+
+  /**
+   * @var \TOperationHandle
+   */
+  public $operationHandle = null;
+
+  public function __construct($vals=null) {
+    if (!isset(self::$_TSPEC)) {
+      self::$_TSPEC = array(
+        1 => array(
+          'var' => 'operationHandle',
+          'type' => TType::STRUCT,
+          'class' => '\TOperationHandle',
+          ),
+        );
+    }
+    if (is_array($vals)) {
+      if (isset($vals['operationHandle'])) {
+        $this->operationHandle = $vals['operationHandle'];
+      }
+    }
+  }
+
+  public function getName() {
+    return 'TGetQueryIdReq';
+  }
+
+  public function read($input)
+  {
+    $xfer = 0;
+    $fname = null;
+    $ftype = 0;
+    $fid = 0;
+    $xfer += $input->readStructBegin($fname);
+    while (true)
+    {
+      $xfer += $input->readFieldBegin($fname, $ftype, $fid);
+      if ($ftype == TType::STOP) {
+        break;
+      }
+      switch ($fid)
+      {
+        case 1:
+          if ($ftype == TType::STRUCT) {
+            $this->operationHandle = new \TOperationHandle();
+            $xfer += $this->operationHandle->read($input);
+          } else {
+            $xfer += $input->skip($ftype);
+          }
+          break;
+        default:
+          $xfer += $input->skip($ftype);
+          break;
+      }
+      $xfer += $input->readFieldEnd();
+    }
+    $xfer += $input->readStructEnd();
+    return $xfer;
+  }
+
+  public function write($output) {
+    $xfer = 0;
+    $xfer += $output->writeStructBegin('TGetQueryIdReq');
+    if ($this->operationHandle !== null) {
+      if (!is_object($this->operationHandle)) {
+        throw new TProtocolException('Bad type in structure.', TProtocolException::INVALID_DATA);
+      }
+      $xfer += $output->writeFieldBegin('operationHandle', TType::STRUCT, 1);
+      $xfer += $this->operationHandle->write($output);
+      $xfer += $output->writeFieldEnd();
+    }
+    $xfer += $output->writeFieldStop();
+    $xfer += $output->writeStructEnd();
+    return $xfer;
+  }
+
+}
+
+class TGetQueryIdResp {
+  static $_TSPEC;
+
+  /**
+   * @var string
+   */
+  public $queryId = null;
+
+  public function __construct($vals=null) {
+    if (!isset(self::$_TSPEC)) {
+      self::$_TSPEC = array(
+        1 => array(
+          'var' => 'queryId',
+          'type' => TType::STRING,
+          ),
+        );
+    }
+    if (is_array($vals)) {
+      if (isset($vals['queryId'])) {
+        $this->queryId = $vals['queryId'];
+      }
+    }
+  }
+
+  public function getName() {
+    return 'TGetQueryIdResp';
+  }
+
+  public function read($input)
+  {
+    $xfer = 0;
+    $fname = null;
+    $ftype = 0;
+    $fid = 0;
+    $xfer += $input->readStructBegin($fname);
+    while (true)
+    {
+      $xfer += $input->readFieldBegin($fname, $ftype, $fid);
+      if ($ftype == TType::STOP) {
+        break;
+      }
+      switch ($fid)
+      {
+        case 1:
+          if ($ftype == TType::STRING) {
+            $xfer += $input->readString($this->queryId);
+          } else {
+            $xfer += $input->skip($ftype);
+          }
+          break;
+        default:
+          $xfer += $input->skip($ftype);
+          break;
+      }
+      $xfer += $input->readFieldEnd();
+    }
+    $xfer += $input->readStructEnd();
+    return $xfer;
+  }
+
+  public function write($output) {
+    $xfer = 0;
+    $xfer += $output->writeStructBegin('TGetQueryIdResp');
+    if ($this->queryId !== null) {
+      $xfer += $output->writeFieldBegin('queryId', TType::STRING, 1);
+      $xfer += $output->writeString($this->queryId);
+      $xfer += $output->writeFieldEnd();
+    }
+    $xfer += $output->writeFieldStop();
+    $xfer += $output->writeStructEnd();
+    return $xfer;
+  }
+
+}
+
 final class Constant extends \Thrift\Type\TConstant {
   static protected $PRIMITIVE_TYPES;
   static protected $COMPLEX_TYPES;
diff --git a/service-rpc/src/gen/thrift/gen-py/TCLIService/TCLIService-remote b/service-rpc/src/gen/thrift/gen-py/TCLIService/TCLIService-remote
index 62b87a35cc..915ee138ad 100755
--- a/service-rpc/src/gen/thrift/gen-py/TCLIService/TCLIService-remote
+++ b/service-rpc/src/gen/thrift/gen-py/TCLIService/TCLIService-remote
@@ -45,6 +45,7 @@ if len(sys.argv) <= 1 or sys.argv[1] == '--help':
   print('  TGetDelegationTokenResp GetDelegationToken(TGetDelegationTokenReq req)')
   print('  TCancelDelegationTokenResp CancelDelegationToken(TCancelDelegationTokenReq req)')
   print('  TRenewDelegationTokenResp RenewDelegationToken(TRenewDelegationTokenReq req)')
+  print('  TGetQueryIdResp GetQueryId(TGetQueryIdReq req)')
   print('')
   sys.exit(0)
 
@@ -227,6 +228,12 @@ elif cmd == 'RenewDelegationToken':
     sys.exit(1)
   pp.pprint(client.RenewDelegationToken(eval(args[0]),))
 
+elif cmd == 'GetQueryId':
+  if len(args) != 1:
+    print('GetQueryId requires 1 args')
+    sys.exit(1)
+  pp.pprint(client.GetQueryId(eval(args[0]),))
+
 else:
   print('Unrecognized method %s' % cmd)
   sys.exit(1)
diff --git a/service-rpc/src/gen/thrift/gen-py/TCLIService/TCLIService.py b/service-rpc/src/gen/thrift/gen-py/TCLIService/TCLIService.py
index 35f2ae47c7..6054b7f776 100644
--- a/service-rpc/src/gen/thrift/gen-py/TCLIService/TCLIService.py
+++ b/service-rpc/src/gen/thrift/gen-py/TCLIService/TCLIService.py
@@ -166,6 +166,13 @@ def RenewDelegationToken(self, req):
     """
     pass
 
+  def GetQueryId(self, req):
+    """
+    Parameters:
+     - req
+    """
+    pass
+
 
 class Client(Iface):
   def __init__(self, iprot, oprot=None):
@@ -825,6 +832,37 @@ def recv_RenewDelegationToken(self):
       return result.success
     raise TApplicationException(TApplicationException.MISSING_RESULT, "RenewDelegationToken failed: unknown result")
 
+  def GetQueryId(self, req):
+    """
+    Parameters:
+     - req
+    """
+    self.send_GetQueryId(req)
+    return self.recv_GetQueryId()
+
+  def send_GetQueryId(self, req):
+    self._oprot.writeMessageBegin('GetQueryId', TMessageType.CALL, self._seqid)
+    args = GetQueryId_args()
+    args.req = req
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_GetQueryId(self):
+    iprot = self._iprot
+    (fname, mtype, rseqid) = iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(iprot)
+      iprot.readMessageEnd()
+      raise x
+    result = GetQueryId_result()
+    result.read(iprot)
+    iprot.readMessageEnd()
+    if result.success is not None:
+      return result.success
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "GetQueryId failed: unknown result")
+
 
 class Processor(Iface, TProcessor):
   def __init__(self, handler):
@@ -851,6 +889,7 @@ def __init__(self, handler):
     self._processMap["GetDelegationToken"] = Processor.process_GetDelegationToken
     self._processMap["CancelDelegationToken"] = Processor.process_CancelDelegationToken
     self._processMap["RenewDelegationToken"] = Processor.process_RenewDelegationToken
+    self._processMap["GetQueryId"] = Processor.process_GetQueryId
 
   def process(self, iprot, oprot):
     (name, type, seqid) = iprot.readMessageBegin()
@@ -1266,6 +1305,25 @@ def process_RenewDelegationToken(self, seqid, iprot, oprot):
     oprot.writeMessageEnd()
     oprot.trans.flush()
 
+  def process_GetQueryId(self, seqid, iprot, oprot):
+    args = GetQueryId_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = GetQueryId_result()
+    try:
+      result.success = self._handler.GetQueryId(args.req)
+      msg_type = TMessageType.REPLY
+    except (TTransport.TTransportException, KeyboardInterrupt, SystemExit):
+      raise
+    except Exception as ex:
+      msg_type = TMessageType.EXCEPTION
+      logging.exception(ex)
+      result = TApplicationException(TApplicationException.INTERNAL_ERROR, 'Internal error')
+    oprot.writeMessageBegin("GetQueryId", msg_type, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
 
 # HELPER FUNCTIONS AND STRUCTURES
 
@@ -4004,6 +4062,137 @@ def validate(self):
     return
 
 
+  def __hash__(self):
+    value = 17
+    value = (value * 31) ^ hash(self.success)
+    return value
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class GetQueryId_args:
+  """
+  Attributes:
+   - req
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'req', (TGetQueryIdReq, TGetQueryIdReq.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, req=None,):
+    self.req = req
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.req = TGetQueryIdReq()
+          self.req.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('GetQueryId_args')
+    if self.req is not None:
+      oprot.writeFieldBegin('req', TType.STRUCT, 1)
+      self.req.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+
+  def validate(self):
+    return
+
+
+  def __hash__(self):
+    value = 17
+    value = (value * 31) ^ hash(self.req)
+    return value
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class GetQueryId_result:
+  """
+  Attributes:
+   - success
+  """
+
+  thrift_spec = (
+    (0, TType.STRUCT, 'success', (TGetQueryIdResp, TGetQueryIdResp.thrift_spec), None, ), # 0
+  )
+
+  def __init__(self, success=None,):
+    self.success = success
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRUCT:
+          self.success = TGetQueryIdResp()
+          self.success.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('GetQueryId_result')
+    if self.success is not None:
+      oprot.writeFieldBegin('success', TType.STRUCT, 0)
+      self.success.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+
+  def validate(self):
+    return
+
+
   def __hash__(self):
     value = 17
     value = (value * 31) ^ hash(self.success)
diff --git a/service-rpc/src/gen/thrift/gen-py/TCLIService/ttypes.py b/service-rpc/src/gen/thrift/gen-py/TCLIService/ttypes.py
index acc8c3a1b6..8421e8f2c5 100644
--- a/service-rpc/src/gen/thrift/gen-py/TCLIService/ttypes.py
+++ b/service-rpc/src/gen/thrift/gen-py/TCLIService/ttypes.py
@@ -7588,3 +7588,138 @@ def __eq__(self, other):
 
   def __ne__(self, other):
     return not (self == other)
+
+class TGetQueryIdReq:
+  """
+  Attributes:
+   - operationHandle
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'operationHandle', (TOperationHandle, TOperationHandle.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, operationHandle=None,):
+    self.operationHandle = operationHandle
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.operationHandle = TOperationHandle()
+          self.operationHandle.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('TGetQueryIdReq')
+    if self.operationHandle is not None:
+      oprot.writeFieldBegin('operationHandle', TType.STRUCT, 1)
+      self.operationHandle.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+
+  def validate(self):
+    if self.operationHandle is None:
+      raise TProtocol.TProtocolException(message='Required field operationHandle is unset!')
+    return
+
+
+  def __hash__(self):
+    value = 17
+    value = (value * 31) ^ hash(self.operationHandle)
+    return value
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class TGetQueryIdResp:
+  """
+  Attributes:
+   - queryId
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'queryId', None, None, ), # 1
+  )
+
+  def __init__(self, queryId=None,):
+    self.queryId = queryId
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.queryId = iprot.readString()
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('TGetQueryIdResp')
+    if self.queryId is not None:
+      oprot.writeFieldBegin('queryId', TType.STRING, 1)
+      oprot.writeString(self.queryId)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+
+  def validate(self):
+    if self.queryId is None:
+      raise TProtocol.TProtocolException(message='Required field queryId is unset!')
+    return
+
+
+  def __hash__(self):
+    value = 17
+    value = (value * 31) ^ hash(self.queryId)
+    return value
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
diff --git a/service-rpc/src/gen/thrift/gen-rb/t_c_l_i_service.rb b/service-rpc/src/gen/thrift/gen-rb/t_c_l_i_service.rb
index a50fe259f7..11e058c15c 100644
--- a/service-rpc/src/gen/thrift/gen-rb/t_c_l_i_service.rb
+++ b/service-rpc/src/gen/thrift/gen-rb/t_c_l_i_service.rb
@@ -326,6 +326,21 @@ module TCLIService
       raise ::Thrift::ApplicationException.new(::Thrift::ApplicationException::MISSING_RESULT, 'RenewDelegationToken failed: unknown result')
     end
 
+    def GetQueryId(req)
+      send_GetQueryId(req)
+      return recv_GetQueryId()
+    end
+
+    def send_GetQueryId(req)
+      send_message('GetQueryId', GetQueryId_args, :req => req)
+    end
+
+    def recv_GetQueryId()
+      result = receive_message(GetQueryId_result)
+      return result.success unless result.success.nil?
+      raise ::Thrift::ApplicationException.new(::Thrift::ApplicationException::MISSING_RESULT, 'GetQueryId failed: unknown result')
+    end
+
   end
 
   class Processor
@@ -478,6 +493,13 @@ module TCLIService
       write_result(result, oprot, 'RenewDelegationToken', seqid)
     end
 
+    def process_GetQueryId(seqid, iprot, oprot)
+      args = read_args(iprot, GetQueryId_args)
+      result = GetQueryId_result.new()
+      result.success = @handler.GetQueryId(args.req)
+      write_result(result, oprot, 'GetQueryId', seqid)
+    end
+
   end
 
   # HELPER FUNCTIONS AND STRUCTURES
@@ -1154,5 +1176,37 @@ module TCLIService
     ::Thrift::Struct.generate_accessors self
   end
 
+  class GetQueryId_args
+    include ::Thrift::Struct, ::Thrift::Struct_Union
+    REQ = 1
+
+    FIELDS = {
+      REQ => {:type => ::Thrift::Types::STRUCT, :name => 'req', :class => ::TGetQueryIdReq}
+    }
+
+    def struct_fields; FIELDS; end
+
+    def validate
+    end
+
+    ::Thrift::Struct.generate_accessors self
+  end
+
+  class GetQueryId_result
+    include ::Thrift::Struct, ::Thrift::Struct_Union
+    SUCCESS = 0
+
+    FIELDS = {
+      SUCCESS => {:type => ::Thrift::Types::STRUCT, :name => 'success', :class => ::TGetQueryIdResp}
+    }
+
+    def struct_fields; FIELDS; end
+
+    def validate
+    end
+
+    ::Thrift::Struct.generate_accessors self
+  end
+
 end
 
diff --git a/service-rpc/src/gen/thrift/gen-rb/t_c_l_i_service_types.rb b/service-rpc/src/gen/thrift/gen-rb/t_c_l_i_service_types.rb
index 6695aee298..994df1efca 100644
--- a/service-rpc/src/gen/thrift/gen-rb/t_c_l_i_service_types.rb
+++ b/service-rpc/src/gen/thrift/gen-rb/t_c_l_i_service_types.rb
@@ -1917,3 +1917,37 @@ class TProgressUpdateResp
   ::Thrift::Struct.generate_accessors self
 end
 
+class TGetQueryIdReq
+  include ::Thrift::Struct, ::Thrift::Struct_Union
+  OPERATIONHANDLE = 1
+
+  FIELDS = {
+    OPERATIONHANDLE => {:type => ::Thrift::Types::STRUCT, :name => 'operationHandle', :class => ::TOperationHandle}
+  }
+
+  def struct_fields; FIELDS; end
+
+  def validate
+    raise ::Thrift::ProtocolException.new(::Thrift::ProtocolException::UNKNOWN, 'Required field operationHandle is unset!') unless @operationHandle
+  end
+
+  ::Thrift::Struct.generate_accessors self
+end
+
+class TGetQueryIdResp
+  include ::Thrift::Struct, ::Thrift::Struct_Union
+  QUERYID = 1
+
+  FIELDS = {
+    QUERYID => {:type => ::Thrift::Types::STRING, :name => 'queryId'}
+  }
+
+  def struct_fields; FIELDS; end
+
+  def validate
+    raise ::Thrift::ProtocolException.new(::Thrift::ProtocolException::UNKNOWN, 'Required field queryId is unset!') unless @queryId
+  end
+
+  ::Thrift::Struct.generate_accessors self
+end
+
diff --git a/service/src/java/org/apache/hive/service/cli/CLIService.java b/service/src/java/org/apache/hive/service/cli/CLIService.java
index 689b948a87..9b13ea7be8 100644
--- a/service/src/java/org/apache/hive/service/cli/CLIService.java
+++ b/service/src/java/org/apache/hive/service/cli/CLIService.java
@@ -43,6 +43,7 @@
 import org.apache.hive.service.auth.HiveAuthFactory;
 import org.apache.hive.service.cli.operation.Operation;
 import org.apache.hive.service.cli.session.SessionManager;
+import org.apache.hive.service.rpc.thrift.TOperationHandle;
 import org.apache.hive.service.rpc.thrift.TProtocolVersion;
 import org.apache.hive.service.server.HiveServer2;
 import org.slf4j.Logger;
@@ -606,6 +607,15 @@ public void renewDelegationToken(SessionHandle sessionHandle, HiveAuthFactory au
     LOG.info(sessionHandle  + ": renewDelegationToken()");
   }
 
+  @Override
+  public String getQueryId(TOperationHandle opHandle) throws HiveSQLException {
+    Operation operation = sessionManager.getOperationManager().getOperation(
+        new OperationHandle(opHandle));
+    final String queryId = operation.getParentSession().getHiveConf().getVar(ConfVars.HIVEQUERYID);
+    LOG.debug(opHandle + ": getQueryId() " + queryId);
+    return queryId;
+  }
+
   public SessionManager getSessionManager() {
     return sessionManager;
   }
diff --git a/service/src/java/org/apache/hive/service/cli/EmbeddedCLIServiceClient.java b/service/src/java/org/apache/hive/service/cli/EmbeddedCLIServiceClient.java
index 43fbb00e32..98125d3c3e 100644
--- a/service/src/java/org/apache/hive/service/cli/EmbeddedCLIServiceClient.java
+++ b/service/src/java/org/apache/hive/service/cli/EmbeddedCLIServiceClient.java
@@ -23,6 +23,7 @@
 
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hive.service.auth.HiveAuthFactory;
+import org.apache.hive.service.rpc.thrift.TOperationHandle;
 
 
 /**
@@ -226,4 +227,9 @@ public OperationHandle getCrossReference(SessionHandle sessionHandle,
     return cliService.getCrossReference(sessionHandle, primaryCatalog, primarySchema,
       primaryTable, foreignCatalog, foreignSchema, foreignTable);
   }
+
+  @Override
+  public String getQueryId(TOperationHandle operationHandle) throws HiveSQLException {
+    return cliService.getQueryId(operationHandle);
+  }
 }
diff --git a/service/src/java/org/apache/hive/service/cli/ICLIService.java b/service/src/java/org/apache/hive/service/cli/ICLIService.java
index 9f2039c971..8c993a5d85 100644
--- a/service/src/java/org/apache/hive/service/cli/ICLIService.java
+++ b/service/src/java/org/apache/hive/service/cli/ICLIService.java
@@ -21,6 +21,7 @@
 import java.util.Map;
 
 import org.apache.hive.service.auth.HiveAuthFactory;
+import org.apache.hive.service.rpc.thrift.TOperationHandle;
 
 public interface ICLIService {
 
@@ -78,6 +79,8 @@ OperationHandle getFunctions(SessionHandle sessionHandle,
   OperationStatus getOperationStatus(OperationHandle opHandle, boolean getProgressUpdate)
       throws HiveSQLException;
 
+  String getQueryId(TOperationHandle operationHandle) throws HiveSQLException;
+
   void cancelOperation(OperationHandle opHandle)
       throws HiveSQLException;
 
diff --git a/service/src/java/org/apache/hive/service/cli/operation/OperationManager.java b/service/src/java/org/apache/hive/service/cli/operation/OperationManager.java
index 46f524d17d..1cf43922ed 100644
--- a/service/src/java/org/apache/hive/service/cli/operation/OperationManager.java
+++ b/service/src/java/org/apache/hive/service/cli/operation/OperationManager.java
@@ -39,6 +39,7 @@
 import org.apache.hadoop.hive.ql.log.LogDivertAppender;
 import org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest;
 import org.apache.hadoop.hive.ql.session.OperationLog;
+import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hive.service.AbstractService;
 import org.apache.hive.service.cli.FetchOrientation;
 import org.apache.hive.service.cli.HiveSQLException;
@@ -49,6 +50,12 @@
 import org.apache.hive.service.cli.RowSetFactory;
 import org.apache.hive.service.cli.TableSchema;
 import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.server.KillQueryImpl;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.core.Appender;
+import org.apache.logging.log4j.core.LoggerContext;
+import org.apache.logging.log4j.core.config.Configuration;
+import org.apache.logging.log4j.core.config.LoggerConfig;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -60,6 +67,8 @@ public class OperationManager extends AbstractService {
   private final Logger LOG = LoggerFactory.getLogger(OperationManager.class.getName());
   private final ConcurrentHashMap<OperationHandle, Operation> handleToOperation =
       new ConcurrentHashMap<OperationHandle, Operation>();
+  private final ConcurrentHashMap<String, Operation> queryIdOperation =
+      new ConcurrentHashMap<String, Operation>();
 
   //Following fields for displaying queries on WebUI
   private Object webuiLock = new Object();
@@ -183,8 +192,13 @@ private Operation getOperationInternal(OperationHandle operationHandle) {
     return handleToOperation.get(operationHandle);
   }
 
+  private String getQueryId(Operation operation) {
+    return operation.getParentSession().getHiveConf().getVar(ConfVars.HIVEQUERYID);
+  }
+
   private void addOperation(Operation operation) {
     LOG.info("Adding operation: " + operation.getHandle());
+    queryIdOperation.put(getQueryId(operation), operation);
     handleToOperation.put(operation.getHandle(), operation);
     if (operation instanceof SQLOperation) {
       synchronized (webuiLock) {
@@ -196,6 +210,7 @@ private void addOperation(Operation operation) {
 
   private Operation removeOperation(OperationHandle opHandle) {
     Operation operation = handleToOperation.remove(opHandle);
+    queryIdOperation.remove(getQueryId(operation));
     if (operation instanceof SQLOperation) {
       removeSafeQueryInfo(opHandle);
     }
@@ -215,11 +230,7 @@ private Operation removeTimedOutOperation(OperationHandle operationHandle) {
         }
       }
 
-      handleToOperation.remove(operationHandle, operation);
-      if (operation instanceof SQLOperation) {
-        removeSafeQueryInfo(operationHandle);
-      }
-      return operation;
+      return removeOperation(operationHandle);
     }
     return null;
   }
@@ -400,4 +411,8 @@ public QueryInfo getQueryInfo(String handle) {
       return historicalQueryInfos.get(handle);
     }
   }
+
+  public Operation getOperationByQueryId(String queryId) {
+    return queryIdOperation.get(queryId);
+  }
 }
diff --git a/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java b/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java
index 906565c1ce..02efc19245 100644
--- a/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java
+++ b/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java
@@ -73,6 +73,7 @@
 import org.apache.hive.service.cli.operation.Operation;
 import org.apache.hive.service.cli.operation.OperationManager;
 import org.apache.hive.service.rpc.thrift.TProtocolVersion;
+import org.apache.hive.service.server.KillQueryImpl;
 import org.apache.hive.service.server.ThreadWithGarbageCleanup;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -160,6 +161,14 @@ public void open(Map<String, String> sessionConfMap) throws HiveSQLException {
     sessionState.setIsHiveServerQuery(true);
     sessionState.setForwardedAddresses(SessionManager.getForwardedAddresses());
     sessionState.setIsUsingThriftJDBCBinarySerDe(updateIsUsingThriftJDBCBinarySerDe());
+    try {
+      if (sessionManager != null) {
+        sessionState.setHiveServer2Host(sessionManager.getHiveServer2HostName());
+      }
+    } catch (Exception e) {
+      throw new HiveSQLException(e);
+    }
+    sessionState.setKillQuery(new KillQueryImpl(operationManager));
     SessionState.start(sessionState);
     try {
       sessionState.loadAuxJars();
diff --git a/service/src/java/org/apache/hive/service/cli/session/SessionManager.java b/service/src/java/org/apache/hive/service/cli/session/SessionManager.java
index 50826890da..9b2ae57ee4 100644
--- a/service/src/java/org/apache/hive/service/cli/session/SessionManager.java
+++ b/service/src/java/org/apache/hive/service/cli/session/SessionManager.java
@@ -571,5 +571,12 @@ public Collection<HiveSession> getSessions() {
   public int getOpenSessionCount() {
     return handleToSession.size();
   }
+
+  public String getHiveServer2HostName() throws Exception {
+    if (hiveServer2 == null) {
+      return null;
+    }
+    return hiveServer2.getServerHost();
+  }
 }
 
diff --git a/service/src/java/org/apache/hive/service/cli/thrift/RetryingThriftCLIServiceClient.java b/service/src/java/org/apache/hive/service/cli/thrift/RetryingThriftCLIServiceClient.java
index 0e76c91520..71e53b7cc6 100644
--- a/service/src/java/org/apache/hive/service/cli/thrift/RetryingThriftCLIServiceClient.java
+++ b/service/src/java/org/apache/hive/service/cli/thrift/RetryingThriftCLIServiceClient.java
@@ -47,6 +47,7 @@
 import org.apache.hive.service.cli.SessionHandle;
 import org.apache.hive.service.cli.TableSchema;
 import org.apache.hive.service.rpc.thrift.TCLIService;
+import org.apache.hive.service.rpc.thrift.TOperationHandle;
 import org.apache.thrift.TApplicationException;
 import org.apache.thrift.protocol.TBinaryProtocol;
 import org.apache.thrift.protocol.TProtocol;
@@ -194,6 +195,11 @@ public OperationStatus getOperationStatus(OperationHandle opHandle, boolean getP
       return cliService.getOperationStatus(opHandle, getProgressUpdate);
     }
 
+    @Override
+    public String getQueryId(TOperationHandle operationHandle) throws HiveSQLException {
+      return cliService.getQueryId(operationHandle);
+    }
+
     @Override
     public void cancelOperation(OperationHandle opHandle) throws HiveSQLException {
       cliService.cancelOperation(opHandle);
diff --git a/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIService.java b/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIService.java
index 9880fc6082..7012a25ac2 100644
--- a/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIService.java
+++ b/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIService.java
@@ -88,6 +88,8 @@
 import org.apache.hive.service.rpc.thrift.TGetOperationStatusResp;
 import org.apache.hive.service.rpc.thrift.TGetPrimaryKeysReq;
 import org.apache.hive.service.rpc.thrift.TGetPrimaryKeysResp;
+import org.apache.hive.service.rpc.thrift.TGetQueryIdReq;
+import org.apache.hive.service.rpc.thrift.TGetQueryIdResp;
 import org.apache.hive.service.rpc.thrift.TGetResultSetMetadataReq;
 import org.apache.hive.service.rpc.thrift.TGetResultSetMetadataResp;
 import org.apache.hive.service.rpc.thrift.TGetSchemasReq;
@@ -801,6 +803,15 @@ public TGetCrossReferenceResp GetCrossReference(TGetCrossReferenceReq req)
     return resp;
   }
 
+  @Override
+  public TGetQueryIdResp GetQueryId(TGetQueryIdReq req) throws TException {
+    try {
+      return new TGetQueryIdResp(cliService.getQueryId(req.getOperationHandle()));
+    } catch (HiveSQLException e) {
+      throw new TException(e);
+    }
+  }
+
   @Override
   public abstract void run();
 
diff --git a/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIServiceClient.java b/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIServiceClient.java
index 617bc40952..d43f1254c5 100644
--- a/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIServiceClient.java
+++ b/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIServiceClient.java
@@ -65,6 +65,7 @@
 import org.apache.hive.service.rpc.thrift.TGetOperationStatusResp;
 import org.apache.hive.service.rpc.thrift.TGetPrimaryKeysReq;
 import org.apache.hive.service.rpc.thrift.TGetPrimaryKeysResp;
+import org.apache.hive.service.rpc.thrift.TGetQueryIdReq;
 import org.apache.hive.service.rpc.thrift.TGetResultSetMetadataReq;
 import org.apache.hive.service.rpc.thrift.TGetResultSetMetadataResp;
 import org.apache.hive.service.rpc.thrift.TGetSchemasReq;
@@ -77,6 +78,7 @@
 import org.apache.hive.service.rpc.thrift.TGetTypeInfoResp;
 import org.apache.hive.service.rpc.thrift.TOpenSessionReq;
 import org.apache.hive.service.rpc.thrift.TOpenSessionResp;
+import org.apache.hive.service.rpc.thrift.TOperationHandle;
 import org.apache.hive.service.rpc.thrift.TProtocolVersion;
 import org.apache.hive.service.rpc.thrift.TRenewDelegationTokenReq;
 import org.apache.hive.service.rpc.thrift.TRenewDelegationTokenResp;
@@ -553,4 +555,13 @@ public OperationHandle getCrossReference(SessionHandle sessionHandle,
       throw new HiveSQLException(e);
     }
   }
+
+  @Override
+  public String getQueryId(TOperationHandle operationHandle) throws HiveSQLException {
+    try {
+      return cliService.GetQueryId(new TGetQueryIdReq(operationHandle)).getQueryId();
+    } catch (TException e) {
+      throw new HiveSQLException(e);
+    }
+  }
 }
diff --git a/service/src/java/org/apache/hive/service/server/HiveServer2.java b/service/src/java/org/apache/hive/service/server/HiveServer2.java
index e5f449122b..a55cf594c3 100644
--- a/service/src/java/org/apache/hive/service/server/HiveServer2.java
+++ b/service/src/java/org/apache/hive/service/server/HiveServer2.java
@@ -481,7 +481,7 @@ private String getServerInstanceURI() throws Exception {
         + thriftCLIService.getPortNumber();
   }
 
-  private String getServerHost() throws Exception {
+  public String getServerHost() throws Exception {
     if ((thriftCLIService == null) || (thriftCLIService.getServerIPAddress() == null)) {
       throw new Exception("Unable to get the server address; it hasn't been initialized yet.");
     }
diff --git a/service/src/java/org/apache/hive/service/server/KillQueryImpl.java b/service/src/java/org/apache/hive/service/server/KillQueryImpl.java
new file mode 100644
index 0000000000..5412371fa9
--- /dev/null
+++ b/service/src/java/org/apache/hive/service/server/KillQueryImpl.java
@@ -0,0 +1,53 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hive.service.server;
+
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.session.KillQuery;
+import org.apache.hive.service.cli.HiveSQLException;
+import org.apache.hive.service.cli.OperationHandle;
+import org.apache.hive.service.cli.operation.Operation;
+import org.apache.hive.service.cli.operation.OperationManager;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class KillQueryImpl implements KillQuery {
+  private final static Logger LOG = LoggerFactory.getLogger(KillQueryImpl.class);
+
+  private final OperationManager operationManager;
+
+  public KillQueryImpl(OperationManager operationManager) {
+    this.operationManager = operationManager;
+  }
+
+  @Override
+  public void killQuery(String queryId) throws HiveException {
+    try {
+      Operation operation = operationManager.getOperationByQueryId(queryId);
+      if (operation == null) {
+        LOG.info("Query not found: " + queryId);
+      } else {
+        OperationHandle handle = operation.getHandle();
+        operationManager.cancelOperation(handle);
+      }
+    } catch (HiveSQLException e) {
+      throw new HiveException(e);
+    }
+  }
+}
diff --git a/service/src/test/org/apache/hive/service/cli/session/TestSessionManagerMetrics.java b/service/src/test/org/apache/hive/service/cli/session/TestSessionManagerMetrics.java
index efc2e1a9d6..5f418c70cb 100644
--- a/service/src/test/org/apache/hive/service/cli/session/TestSessionManagerMetrics.java
+++ b/service/src/test/org/apache/hive/service/cli/session/TestSessionManagerMetrics.java
@@ -78,8 +78,7 @@ public void setup() throws Exception {
     conf.setBoolVar(HiveConf.ConfVars.HIVEOPTIMIZEMETADATAQUERIES, false);
     MetricsFactory.init(conf);
 
-    HiveServer2 hs2 = new HiveServer2();
-    sm = new SessionManager(hs2);
+    sm = new SessionManager(null);
     sm.init(conf);
 
     metrics = (CodahaleMetrics) MetricsFactory.getInstance();
