diff --git a/hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/HCatLoader.java b/hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/HCatLoader.java
index a32149c676..e085cd7a19 100644
--- a/hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/HCatLoader.java
+++ b/hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/HCatLoader.java
@@ -177,7 +177,8 @@ public String[] getPartitionKeys(String location, Job job)
     throws IOException {
     Table table = phutil.getTable(location,
       hcatServerUri != null ? hcatServerUri : PigHCatUtil.getHCatServerUri(job),
-      PigHCatUtil.getHCatServerPrincipal(job));
+      PigHCatUtil.getHCatServerPrincipal(job),
+          job);   // Pass job to initialize metastore conf overrides
     List<FieldSchema> tablePartitionKeys = table.getPartitionKeys();
     String[] partitionKeys = new String[tablePartitionKeys.size()];
     for (int i = 0; i < tablePartitionKeys.size(); i++) {
@@ -193,7 +194,9 @@ public ResourceSchema getSchema(String location, Job job) throws IOException {
 
     Table table = phutil.getTable(location,
       hcatServerUri != null ? hcatServerUri : PigHCatUtil.getHCatServerUri(job),
-      PigHCatUtil.getHCatServerPrincipal(job));
+      // Pass job to initialize metastore conf overrides for embedded metastore case
+      // (hive.metastore.uris = "").
+      PigHCatUtil.getHCatServerPrincipal(job), job);
     HCatSchema hcatTableSchema = HCatUtil.getTableSchemaWithPtnCols(table);
     try {
       PigHCatUtil.validateHCatTableSchemaFollowsPigRules(hcatTableSchema);
diff --git a/hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/PigHCatUtil.java b/hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/PigHCatUtil.java
index a01d9e398e..af3aaf8bf3 100644
--- a/hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/PigHCatUtil.java
+++ b/hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/PigHCatUtil.java
@@ -133,8 +133,16 @@ static public String getHCatServerPrincipal(Job job) {
   }
 
   private static HiveMetaStoreClient getHiveMetaClient(String serverUri,
-                             String serverKerberosPrincipal, Class<?> clazz) throws Exception {
-    HiveConf hiveConf = new HiveConf(clazz);
+                             String serverKerberosPrincipal,
+                             Class<?> clazz,
+                             Job job) throws Exception {
+
+    // The job configuration is passed in so the configuration will be cloned
+    // from the pig job configuration. This is necessary for overriding
+    // metastore configuration arguments like the metastore jdbc connection string
+    // and password, in the case of an embedded metastore, which you get when
+    // hive.metastore.uris = "".
+    HiveConf hiveConf = new HiveConf(job.getConfiguration(), clazz);
 
     if (serverUri != null) {
       hiveConf.set("hive.metastore.local", "false");
@@ -170,7 +178,13 @@ HCatSchema getHCatSchema(List<RequiredField> fields, String signature, Class<?>
     return new HCatSchema(fcols);
   }
 
-  public Table getTable(String location, String hcatServerUri, String hcatServerPrincipal) throws IOException {
+  /*
+  * The job argument is passed so that configuration overrides can be used to initialize
+  * the metastore configuration in the special case of an embedded metastore
+  * (hive.metastore.uris = "").
+  */
+  public Table getTable(String location, String hcatServerUri, String hcatServerPrincipal,
+      Job job) throws IOException {
     Pair<String, String> loc_server = new Pair<String, String>(location, hcatServerUri);
     Table hcatTable = hcatTableCache.get(loc_server);
     if (hcatTable != null) {
@@ -183,7 +197,7 @@ public Table getTable(String location, String hcatServerUri, String hcatServerPr
     Table table = null;
     HiveMetaStoreClient client = null;
     try {
-      client = getHiveMetaClient(hcatServerUri, hcatServerPrincipal, PigHCatUtil.class);
+      client = getHiveMetaClient(hcatServerUri, hcatServerPrincipal, PigHCatUtil.class, job);
       table = HCatUtil.getTable(client, dbName, tableName);
     } catch (NoSuchObjectException nsoe) {
       throw new PigException("Table not found : " + nsoe.getMessage(), PIG_EXCEPTION_CODE); // prettier error messages to frontend
