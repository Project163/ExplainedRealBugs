diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/BucketMapJoinOptimizer.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/BucketMapJoinOptimizer.java
index d9354f39d0..f679a7ee66 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/BucketMapJoinOptimizer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/BucketMapJoinOptimizer.java
@@ -40,10 +40,10 @@
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.ErrorMsg;
 import org.apache.hadoop.hive.ql.exec.MapJoinOperator;
-import org.apache.hadoop.hive.ql.exec.UnionOperator;
-import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;
 import org.apache.hadoop.hive.ql.exec.Operator;
+import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;
 import org.apache.hadoop.hive.ql.exec.TableScanOperator;
+import org.apache.hadoop.hive.ql.exec.UnionOperator;
 import org.apache.hadoop.hive.ql.lib.DefaultGraphWalker;
 import org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher;
 import org.apache.hadoop.hive.ql.lib.Dispatcher;
@@ -351,6 +351,8 @@ private boolean convertBucketMapJoin(Node nd, Stack<Node> stack, NodeProcessorCt
       if (bigTablePartitioned) {
         desc.setBigTablePartSpecToFileMapping(convert(bigTblPartsToBucketFileNames));
       }
+      // successfully convert to bucket map join
+      desc.setBucketMapJoin(true);
 
       return true;
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
index edde378627..919e0a0f6f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
@@ -288,7 +288,11 @@ private static void setupBucketMapJoinInfo(MapredWork plan,
         bucketMJCxt.setBucketMatcherClass(org.apache.hadoop.hive.ql.exec.DefaultBucketMatcher.class);
         bucketMJCxt.setBigTablePartSpecToFileMapping(
           currMapJoinOp.getConf().getBigTablePartSpecToFileMapping());
-        plan.setUseBucketizedHiveInputFormat(currMapJoinOp instanceof SMBMapJoinOperator);
+        // BucketizedHiveInputFormat should be used for either sort merge join or bucket map join
+        if ((currMapJoinOp instanceof SMBMapJoinOperator)
+            || (currMapJoinOp.getConf().isBucketMapJoin())) {
+          plan.setUseBucketizedHiveInputFormat(true);
+        }
       }
     }
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/MapJoinDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/MapJoinDesc.java
index d55a8c4e04..f5de289ab1 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/MapJoinDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/MapJoinDesc.java
@@ -54,6 +54,9 @@ public class MapJoinDesc extends JoinDesc implements Serializable {
   //map join dump file name
   private String dumpFilePrefix;
 
+  // flag for bucket map join. One usage is to set BucketizedHiveInputFormat
+  private boolean isBucketMapJoin;
+
   public MapJoinDesc() {
     bigTableBucketNumMapping = new LinkedHashMap<String, Integer>();
   }
@@ -233,4 +236,12 @@ public Map<String, List<String>> getBigTablePartSpecToFileMapping() {
   public void setBigTablePartSpecToFileMapping(Map<String, List<String>> partToFileMapping) {
     this.bigTablePartSpecToFileMapping = partToFileMapping;
   }
+
+  public boolean isBucketMapJoin() {
+    return isBucketMapJoin;
+  }
+
+  public void setBucketMapJoin(boolean isBucketMapJoin) {
+    this.isBucketMapJoin = isBucketMapJoin;
+  }
 }
diff --git a/ql/src/test/queries/clientpositive/bucket_map_join_1.q b/ql/src/test/queries/clientpositive/bucket_map_join_1.q
index 4c55d956af..33dd5d5cd2 100644
--- a/ql/src/test/queries/clientpositive/bucket_map_join_1.q
+++ b/ql/src/test/queries/clientpositive/bucket_map_join_1.q
@@ -14,7 +14,6 @@ load data local inpath '../data/files/SortCol2Col1.txt' overwrite into table tab
 
 set hive.optimize.bucketmapjoin = true;
 set hive.optimize.bucketmapjoin.sortedmerge = true;
-set hive.input.format = org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;
 
 -- The tables are bucketed in same columns in different order,
 -- but sorted in different column orders
diff --git a/ql/src/test/queries/clientpositive/bucket_map_join_2.q b/ql/src/test/queries/clientpositive/bucket_map_join_2.q
index fcbfd918f3..d1097e70a9 100644
--- a/ql/src/test/queries/clientpositive/bucket_map_join_2.q
+++ b/ql/src/test/queries/clientpositive/bucket_map_join_2.q
@@ -14,7 +14,6 @@ load data local inpath '../data/files/SortCol2Col1.txt' overwrite into table tab
 
 set hive.optimize.bucketmapjoin = true;
 set hive.optimize.bucketmapjoin.sortedmerge = true;
-set hive.input.format = org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;
 
 -- The tables are bucketed in same columns in different order,
 -- but sorted in different column orders
diff --git a/ql/src/test/queries/clientpositive/bucketmapjoin13.q b/ql/src/test/queries/clientpositive/bucketmapjoin13.q
index aa09b73391..f01c43e569 100644
--- a/ql/src/test/queries/clientpositive/bucketmapjoin13.q
+++ b/ql/src/test/queries/clientpositive/bucketmapjoin13.q
@@ -22,7 +22,6 @@ CLUSTERED BY (key) INTO 2 BUCKETS;
 INSERT OVERWRITE TABLE srcbucket_mapjoin_part_2 PARTITION (part='1')
 SELECT * FROM src;
 
-set hive.input.format=org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;
 set hive.optimize.bucketmapjoin=true;
 
 -- part=1 partition for srcbucket_mapjoin_part_1 is bucketed by 'value'
diff --git a/ql/src/test/queries/clientpositive/bucketmapjoin6.q b/ql/src/test/queries/clientpositive/bucketmapjoin6.q
index 2161dcecf7..2998d7ccf1 100644
--- a/ql/src/test/queries/clientpositive/bucketmapjoin6.q
+++ b/ql/src/test/queries/clientpositive/bucketmapjoin6.q
@@ -15,8 +15,6 @@ insert overwrite table tmp2 select * from src where key < 50;
 set hive.optimize.bucketmapjoin = true;
 set hive.optimize.bucketmapjoin.sortedmerge = true;
 set hive.merge.mapfiles=false;
-set hive.input.format=org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;
-
 create table tmp3 (a string, b string, c string) clustered by (a) sorted by (a) into 10 buckets;
 
 
