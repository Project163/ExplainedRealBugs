diff --git a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java
index 7fe2a374ff..86dc6a8526 100644
--- a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java
+++ b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java
@@ -215,41 +215,41 @@ private static boolean getOutputDirMarking(Configuration conf) {
 
   @Override
   public void commitJob(JobContext jobContext) throws IOException {
-    try {
-      if (dynamicPartitioningUsed) {
-        discoverPartitions(jobContext);
-        // Commit each partition so it gets moved out of the job work
-        // dir
-        for (JobContext context : contextDiscoveredByPath.values()) {
-          new JobConf(context.getConfiguration())
-              .getOutputCommitter().commitJob(context);
-        }
-      }
-      if (getBaseOutputCommitter() != null && !dynamicPartitioningUsed) {
-        getBaseOutputCommitter().commitJob(
-            HCatMapRedUtil.createJobContext(jobContext));
+    if (dynamicPartitioningUsed) {
+      discoverPartitions(jobContext);
+      // Commit each partition so it gets moved out of the job work
+      // dir
+      for (JobContext context : contextDiscoveredByPath.values()) {
+        new JobConf(context.getConfiguration())
+            .getOutputCommitter().commitJob(context);
       }
-      registerPartitions(jobContext);
-      // create _SUCCESS FILE if so requested.
-      OutputJobInfo jobInfo = HCatOutputFormat.getJobInfo(jobContext);
-      if (getOutputDirMarking(jobContext.getConfiguration())) {
-        Path outputPath = new Path(jobInfo.getLocation());
-        FileSystem fileSys = outputPath.getFileSystem(jobContext
-            .getConfiguration());
-        // create a file in the folder to mark it
-        if (fileSys.exists(outputPath)) {
-          Path filePath = new Path(outputPath,
-              SUCCEEDED_FILE_NAME);
-          if (!fileSys.exists(filePath)) { // may have been
-                           // created by
-                           // baseCommitter.commitJob()
-            fileSys.create(filePath).close();
-          }
+    }
+    if (getBaseOutputCommitter() != null && !dynamicPartitioningUsed) {
+      getBaseOutputCommitter().commitJob(
+          HCatMapRedUtil.createJobContext(jobContext));
+    }
+    registerPartitions(jobContext);
+    // create _SUCCESS FILE if so requested.
+    OutputJobInfo jobInfo = HCatOutputFormat.getJobInfo(jobContext);
+    if (getOutputDirMarking(jobContext.getConfiguration())) {
+      Path outputPath = new Path(jobInfo.getLocation());
+      FileSystem fileSys = outputPath.getFileSystem(jobContext
+          .getConfiguration());
+      // create a file in the folder to mark it
+      if (fileSys.exists(outputPath)) {
+        Path filePath = new Path(outputPath,
+            SUCCEEDED_FILE_NAME);
+        if (!fileSys.exists(filePath)) { // may have been
+                         // created by
+                         // baseCommitter.commitJob()
+          fileSys.create(filePath).close();
         }
       }
-    } finally {
-      cancelDelegationTokens(jobContext);
     }
+
+    // Commit has succeeded (since no exceptions have been thrown.)
+    // Safe to cancel delegation tokens now.
+    cancelDelegationTokens(jobContext);
   }
 
   @Override
@@ -970,7 +970,7 @@ private void moveCustomLocationTaskOutputs(FileSystem fs, Table table, Configura
   }
 
   private void cancelDelegationTokens(JobContext context) throws IOException{
-    LOG.info("Cancelling deletgation token for the job.");
+    LOG.info("Cancelling delegation token for the job.");
     HiveMetaStoreClient client = null;
     try {
       HiveConf hiveConf = HCatUtil
