diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/avro/AvroGenericRecordReader.java b/ql/src/java/org/apache/hadoop/hive/ql/io/avro/AvroGenericRecordReader.java
index 056127a503..67e167eac6 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/avro/AvroGenericRecordReader.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/avro/AvroGenericRecordReader.java
@@ -89,21 +89,37 @@ public AvroGenericRecordReader(JobConf job, FileSplit split, Reporter reporter)
     }
 
     if (split.getLength() == 0) {
-      this.isEmptyInput = true;
-      this.start = 0;
       this.reader = null;
-    }
-    else {
-      this.isEmptyInput = false;
+      this.isEmptyInput = true;
+    } else {
       this.reader = new DataFileReader<GenericRecord>(new FsInput(split.getPath(), job), gdr);
-      this.reader.sync(split.getStart());
-      this.start = reader.tell();
+      this.isEmptyInput = false;
     }
-    this.stop = split.getStart() + split.getLength();
-    this.recordReaderID = new UID();
 
-    this.writerTimezone = extractWriterTimezoneFromMetadata(job, split, gdr);
-    this.writerProleptic = extractWriterProlepticFromMetadata(job, split, gdr);
+    try {
+      if (this.isEmptyInput) {
+        this.start = 0;
+      } else {
+        this.reader.sync(split.getStart());
+        this.start = reader.tell();
+      }
+      this.stop = split.getStart() + split.getLength();
+      this.recordReaderID = new UID();
+
+      this.writerTimezone = extractWriterTimezoneFromMetadata(job, split, gdr);
+      this.writerProleptic = extractWriterProlepticFromMetadata(job, split, gdr);
+    } catch (Exception e) {
+      if (this.reader != null) {
+        try {
+          this.reader.close();
+        } catch (Exception closeException) {
+          if (closeException != e) {
+            e.addSuppressed(closeException);
+          }
+        }
+      }
+      throw e;
+    }
   }
 
   /**
