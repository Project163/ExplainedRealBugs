diff --git a/CHANGES.txt b/CHANGES.txt
index 62eeadee07..e6a48c1995 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -105,6 +105,9 @@ Trunk - unreleased changes
     HIVE-442. Move the data before creating the partition.
     (Prasad Chakka via zshao)
 
+    HIVE-395. Fix build problems with eclipse and 0.19 hadoop.
+    (Neil Conway via athusoo)
+
 Release 0.3.0 - Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/build.xml b/build.xml
index e59d8c57c5..61bfe04741 100644
--- a/build.xml
+++ b/build.xml
@@ -298,7 +298,7 @@
       <packageset dir="metastore/src/gen-javabean"/>
       <packageset dir="metastore/src/model"/>
       <packageset dir="cli/src/java"/>
-      <packageset dir="${build.dir.hive}/ql/java"/>
+      <packageset dir="ql/src/java"/>
       <packageset dir="${build.dir.hive}/ql/gen-java"/>
 
       <link href="${javadoc.link.java}"/>
diff --git a/ql/build.xml b/ql/build.xml
index 9e0d9aa722..4679958aa1 100644
--- a/ql/build.xml
+++ b/ql/build.xml
@@ -99,36 +99,11 @@
     <mkdir dir="${build.dir}/gen-java/org/apache/hadoop/hive/ql/parse"/>
   </target>
 
-  <target name="configure" depends="deploy-ant-tasks">
-    <!-- If not set already make sure that they are defined but empty -->
-    <taskdef name="getversionpref" classname="org.apache.hadoop.hive.ant.GetVersionPref"
-             classpath="${build.dir.hive}/anttasks/hive_anttasks.jar"/>
-
-    <getversionpref property="hadoop.version.prefix" input="${hadoop.version}"/>
-
-    <condition property="exclude_0_19.token" value="/*" else="">
-      <equals arg1="${hadoop.version.prefix}" arg2="0.19"/>
-    </condition>
-    <condition property="endexclude_0_19.token" value="*/" else="">
-      <equals arg1="${hadoop.version.prefix}" arg2="0.19"/>
-    </condition>
-
-    <copy todir="${build.dir}/java">
-      <fileset dir="${src.dir}">
-        <include name="**/*.java"/>
-      </fileset>
-      <filterset begintoken="//[" endtoken="]">
-        <filter token="exclude_0_19" value="${exclude_0_19.token}"/>
-        <filter token="endexclude_0_19" value="${endexclude_0_19.token}"/>
-      </filterset>
-    </copy> 
-  </target>
-
-  <target name="compile" depends="init, ql-init, build-grammar, configure">
+  <target name="compile" depends="init, ql-init, build-grammar">
     <echo message="Compiling: ${name}"/>
     <javac
      encoding="${build.encoding}"
-     srcdir="${build.dir}/java:${build.dir}/gen-java"
+     srcdir="${src.dir}:${build.dir}/gen-java"
      includes="**/*.java"
      destdir="${build.classes}"
      debug="${javac.debug}"
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java b/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java
index 21cf30d4f3..f0b04927a4 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java
@@ -21,6 +21,7 @@
 import java.io.DataInput;
 import java.io.DataOutput;
 import java.io.IOException;
+import java.lang.reflect.Method;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Map;
@@ -179,7 +180,7 @@ public RecordReader getRecordReader(InputSplit split, JobConf job,
     }
 
     InputFormat inputFormat = getInputFormatFromCache(inputFormatClass);
-    
+
     return new HiveRecordReader(inputFormat.getRecordReader(inputSplit, job, reporter));
   }
 
@@ -219,7 +220,6 @@ public InputSplit[] getSplits(JobConf job, int numSplits) throws IOException {
     return result.toArray(new HiveInputSplit[result.size()]);
   }
 
-//[exclude_0_19]
   public void validateInput(JobConf job) throws IOException {
 
     init(job);
@@ -231,17 +231,20 @@ public void validateInput(JobConf job) throws IOException {
     JobConf newjob = new JobConf(job);
 
     // for each dir, get the InputFormat, and do validateInput.
-    for(Path dir: dirs) {
+    for (Path dir: dirs) {
       tableDesc table = getTableDescFromPath(dir);
       // create a new InputFormat instance if this is the first time to see this class
       InputFormat inputFormat = getInputFormatFromCache(table.getInputFileFormatClass());
 
       FileInputFormat.setInputPaths(newjob, dir);
       newjob.setInputFormat(inputFormat.getClass());
-      inputFormat.validateInput(newjob);
+      try {
+        Method validateInput = inputFormat.getClass().getDeclaredMethod("validateInput", newjob.getClass());
+        validateInput.setAccessible(true);
+        validateInput.invoke(inputFormat, newjob);
+      } catch (Exception e) {}
     }
   }
-//[endexclude_0_19]
 
   private tableDesc getTableDescFromPath(Path dir) throws IOException {
 
