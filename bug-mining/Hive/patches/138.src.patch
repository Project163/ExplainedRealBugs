diff --git a/CHANGES.txt b/CHANGES.txt
index aea9f1abfb..c83887d1f3 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -99,6 +99,9 @@ Trunk - unreleased changes
     HIVE-433. Fixed union18 and union19 tests.
     (athusoo via johan)
 
+    HIVE-324. Fix AccessControlException when loading data.
+    (Ashish Thusoo via zshao)
+
 Release 0.3.0 - Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java
index dcb66a8a1d..0abef97588 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java
@@ -124,11 +124,11 @@ public int execute() {
         }
 
         if(tbd.getPartitionSpec().size() == 0) {
-          db.loadTable(new Path(tbd.getSourceDir()), tbd.getTable().getTableName(), tbd.getReplace());
+          db.loadTable(new Path(tbd.getSourceDir()), tbd.getTable().getTableName(), tbd.getReplace(), new Path(tbd.getTmpDir()));
         } else {
           LOG.info("Partition is: " + tbd.getPartitionSpec().toString());
           db.loadPartition(new Path(tbd.getSourceDir()), tbd.getTable().getTableName(),
-              tbd.getPartitionSpec(), tbd.getReplace());
+              tbd.getPartitionSpec(), tbd.getReplace(), new Path(tbd.getTmpDir()));
         }
       }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
index 382cc74f18..6026df7f2f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
@@ -505,14 +505,16 @@ protected boolean dropDatabase(String name) throws MetaException, TException {
    * @param tableName name of table to be loaded.
    * @param partSpec defines which partition needs to be loaded
    * @param replace if true - replace files in the partition, otherwise add files to the partition
+   * @param tmpDirPath The temporary directory.
    */
   public void loadPartition(Path loadPath, String tableName,
-      AbstractMap<String, String> partSpec, boolean replace)
+      AbstractMap<String, String> partSpec, boolean replace,
+      Path tmpDirPath)
   throws HiveException {
     Table tbl = getTable(tableName);
     Partition part = getPartition(tbl, partSpec, true);
     if(replace) {
-      part.replaceFiles(loadPath);
+      part.replaceFiles(loadPath, tmpDirPath);
     } else {
       part.copyFiles(loadPath);
     }
@@ -527,11 +529,14 @@ public void loadPartition(Path loadPath, String tableName,
    * @param loadPath Directory containing files to load into Table
    * @param tableName name of table to be loaded.
    * @param replace if true - replace files in the table, otherwise add files to table
+   * @param tmpDirPath The temporary directory.
    */
-  public void loadTable(Path loadPath, String tableName, boolean replace) throws HiveException {
+  public void loadTable(Path loadPath, String tableName, 
+       boolean replace,
+       Path tmpDirPath) throws HiveException {
     Table tbl = getTable(tableName);
     if(replace) {
-      tbl.replaceFiles(loadPath);
+      tbl.replaceFiles(loadPath, tmpDirPath);
     } else {
       tbl.copyFiles(loadPath);
     }
@@ -732,8 +737,12 @@ protected void copyFiles(Path srcf, Path destf, FileSystem fs) throws HiveExcept
    * Replaces files in the partition with new data set specifed by srcf. Works by moving files
    *
    * @param srcf Files to be moved. Leaf Directories or Globbed File Paths
+   * @param dest The directory where the final data needs to go
+   * @param fs The filesystem handle
+   * @param tmppath Temporary directory
    */
-  protected void replaceFiles(Path srcf, Path destf, FileSystem fs) throws HiveException {
+  protected void replaceFiles(Path srcf, Path destf, FileSystem fs,
+      Path tmppath) throws HiveException {
       FileStatus [] srcs;
       try {
           srcs = fs.globStatus(srcf);
@@ -747,8 +756,6 @@ protected void replaceFiles(Path srcf, Path destf, FileSystem fs) throws HiveExc
       }
       checkPaths(fs, srcs, destf, true);
 
-      Random randGen = new Random();
-      Path tmppath = new Path("/tmp/"+randGen.nextInt());
       try {
           fs.mkdirs(tmppath);
           for(int i=0; i<srcs.length; i++) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java
index ddfaad7d20..e619f3e71f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java
@@ -303,13 +303,14 @@ public LinkedHashMap<String, String> getSpec() {
    * Replaces files in the partition with new data set specified by srcf. Works by moving files
    *
    * @param srcf Files to be moved. Leaf Directories or Globbed File Paths
+   * @param tmpd Temporary directory
    */
   @SuppressWarnings("nls")
-  protected void replaceFiles(Path srcf) throws HiveException {
+  protected void replaceFiles(Path srcf, Path tmpd) throws HiveException {
     FileSystem fs;
     try {
       fs = FileSystem.get(table.getDataLocation(), Hive.get().getConf());
-      Hive.get().replaceFiles(srcf, partPath, fs);
+      Hive.get().replaceFiles(srcf, partPath, fs, tmpd);
     } catch (IOException e) {
       throw new HiveException("addFiles: filesystem error in check phase", e);
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java
index 43c0ef0f81..c92fc290c1 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java
@@ -445,12 +445,13 @@ public int getNumBuckets() {
   /**
    * Replaces files in the partition with new data set specified by srcf. Works by moving files
    * @param srcf Files to be replaced. Leaf directories or globbed file paths
+   * @param tmpd Temporary directory
    */
-  protected void replaceFiles(Path srcf) throws HiveException {
+  protected void replaceFiles(Path srcf, Path tmpd) throws HiveException {
     FileSystem fs;
     try {
       fs = FileSystem.get(getDataLocation(), Hive.get().getConf());
-      Hive.get().replaceFiles(srcf, new Path(getDataLocation().getPath()), fs);
+      Hive.get().replaceFiles(srcf, new Path(getDataLocation().getPath()), fs, tmpd);
     } catch (IOException e) {
       throw new HiveException("addFiles: filesystem error in check phase", e);
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
index d4891606fa..159b10f1a6 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
@@ -208,7 +208,7 @@ public void analyzeInternal(ASTNode ast, Context ctx) throws SemanticException {
     List<loadTableDesc> loadTableWork =  new ArrayList<loadTableDesc>();
     List<loadFileDesc> loadFileWork = new ArrayList<loadFileDesc>();
 
-    loadTableWork.add(new loadTableDesc(fromURI.toString(), Utilities.getTableDesc(ts.tableHandle),
+    loadTableWork.add(new loadTableDesc(fromURI.toString(), getTmpFileName(), Utilities.getTableDesc(ts.tableHandle),
                                         (ts.partSpec != null) ? ts.partSpec : new HashMap<String, String> (),
                                         isOverWrite));
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index fd27b8f94f..1b16141396 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -2206,7 +2206,7 @@ private Operator genFileSinkPlan(String dest, QB qb,
 
         dest_path = dest_tab.getPath().toString();
         // Create the work for moving the table
-        this.loadTableWork.add(new loadTableDesc(queryTmpdir,
+        this.loadTableWork.add(new loadTableDesc(queryTmpdir, getTmpFileName(),
                                             table_desc,
                                             new HashMap<String, String>()));
         break;
@@ -2221,7 +2221,7 @@ private Operator genFileSinkPlan(String dest, QB qb,
         currentTableId = this.destTableId;
         this.destTableId ++;
         
-        this.loadTableWork.add(new loadTableDesc(queryTmpdir, table_desc, dest_part.getSpec()));
+        this.loadTableWork.add(new loadTableDesc(queryTmpdir, getTmpFileName(), table_desc, dest_part.getSpec()));
         break;
       }
     case QBMetaData.DEST_LOCAL_FILE:
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/loadTableDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/loadTableDesc.java
index 84abb220b9..c51eff8a94 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/loadTableDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/loadTableDesc.java
@@ -24,6 +24,7 @@
 public class loadTableDesc extends org.apache.hadoop.hive.ql.plan.loadDesc implements Serializable {
   private static final long serialVersionUID = 1L;
   private boolean replace;
+  private String tmpDir;
 
   // TODO: the below seems like they should just be combined into partitionDesc
   private org.apache.hadoop.hive.ql.plan.tableDesc table;
@@ -32,20 +33,31 @@ public class loadTableDesc extends org.apache.hadoop.hive.ql.plan.loadDesc imple
   public loadTableDesc() { }
   public loadTableDesc(
     final String sourceDir,
+    final String tmpDir,
     final org.apache.hadoop.hive.ql.plan.tableDesc table,
     final HashMap<String, String> partitionSpec,
     final boolean replace) {
 
     super(sourceDir);
+    this.tmpDir = tmpDir;
     this.table = table;
     this.partitionSpec = partitionSpec;
     this.replace = replace;
   }
   public loadTableDesc(
     final String sourceDir,
+    final String tmpDir,
     final org.apache.hadoop.hive.ql.plan.tableDesc table,
     final HashMap<String, String> partitionSpec) {
-    this(sourceDir, table, partitionSpec, true);
+    this(sourceDir, tmpDir, table, partitionSpec, true);
+  }
+
+  @explain(displayName="tmp directory", normalExplain=false)
+  public String getTmpDir() {
+    return this.tmpDir;
+  }
+  public void setTmpDir(final String tmp) {
+    this.tmpDir = tmp;
   }
 
   @explain(displayName="table")
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java b/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
index 4a293259d3..711e1ec29a 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
@@ -209,6 +209,16 @@ public void cleanUp() throws Exception {
     }
   }
 
+  private void runLoadCmd(String loadCmd) throws Exception {
+    int ecode = 0;
+    ecode = drv.run(loadCmd);
+    if(ecode != 0) {
+       throw new Exception("load command: " + loadCmd + " failed with exit code= " + ecode);
+    }
+
+    return;
+  }
+
   public void createSources() throws Exception {
     // Next create the three tables src, dest1 and dest2 each with two columns
     // key and value
@@ -227,7 +237,6 @@ public void createSources() throws Exception {
     Path newfpath;
     HashMap<String, String> part_spec = new HashMap<String, String>();
     String loadCmd;
-    int ecode = 0;
     for (String ds: new String[]{"2008-04-08", "2008-04-09"}) {
       for (String hr: new String[]{"11", "12"}) {
         part_spec.clear();
@@ -240,12 +249,8 @@ public void createSources() throws Exception {
         fs.copyFromLocalFile(false, true, fpath, newfpath);
         fpath = newfpath;
         //db.loadPartition(fpath, srcpart.getName(), part_spec, true);
-        loadCmd = "LOAD DATA INPATH '" +  newfpath.toString() +
-          "' INTO TABLE srcpart PARTITION (ds='" + ds + "',hr='" + hr +"')";
-        ecode = drv.run(loadCmd);
-        if(ecode != 0) {
-          throw new Exception("load command: " + loadCmd + " failed with exit code= " + ecode);
-        }
+        runLoadCmd("LOAD DATA INPATH '" +  newfpath.toString() +
+                   "' INTO TABLE srcpart PARTITION (ds='" + ds + "',hr='" + hr +"')");
       }
     }
     ArrayList<String> bucketCols = new ArrayList<String>();
@@ -256,11 +261,7 @@ public void createSources() throws Exception {
       fpath = new Path(testFiles, fname);
       newfpath = new Path(tmppath, fname);
       fs.copyFromLocalFile(false, true, fpath, newfpath);
-      loadCmd = "LOAD DATA INPATH '" +  newfpath.toString() + "' INTO TABLE srcbucket";
-      ecode = drv.run(loadCmd);
-      if(ecode != 0) {
-        throw new Exception("load command: " + loadCmd + " failed with exit code= " + ecode);
-      }
+      runLoadCmd("LOAD DATA INPATH '" +  newfpath.toString() + "' INTO TABLE srcbucket");
     }
     
     for (String tname: new String [] {"src", "src1"}) {
@@ -289,35 +290,35 @@ public void createSources() throws Exception {
     newfpath = new Path(tmppath, "kv1.txt");
     fs.copyFromLocalFile(false, true, fpath, newfpath);
     //db.loadTable(newfpath, "src", false);
-    loadCmd = "LOAD DATA INPATH '" +  newfpath.toString() + "' INTO TABLE src";
-    ecode = drv.run(loadCmd);
-    if(ecode != 0) {
-      throw new Exception("load command: " + loadCmd + " failed with exit code= " + ecode);
-    }
+    runLoadCmd("LOAD DATA INPATH '" +  newfpath.toString() + "' INTO TABLE src");
     
     // load the input data into the src table
     fpath = new Path(testFiles, "kv3.txt");
     newfpath = new Path(tmppath, "kv3.txt");
     fs.copyFromLocalFile(false, true, fpath, newfpath);
-    db.loadTable(newfpath, "src1", false);
+    //db.loadTable(newfpath, "src1", false);
+    runLoadCmd("LOAD DATA INPATH '" +  newfpath.toString() + "' INTO TABLE src1");
     
     // load the input data into the src_sequencefile table
     fpath = new Path(testFiles, "kv1.seq");
     newfpath = new Path(tmppath, "kv1.seq");
     fs.copyFromLocalFile(false, true, fpath, newfpath);
-    db.loadTable(newfpath, "src_sequencefile", true);
+    //db.loadTable(newfpath, "src_sequencefile", true);
+    runLoadCmd("LOAD DATA INPATH '" +  newfpath.toString() + "' INTO TABLE src_sequencefile");
     
     // load the input data into the src_thrift table
     fpath = new Path(testFiles, "complex.seq");
     newfpath = new Path(tmppath, "complex.seq");
     fs.copyFromLocalFile(false, true, fpath, newfpath);
-    db.loadTable(newfpath, "src_thrift", true);    
+    //db.loadTable(newfpath, "src_thrift", true);    
+    runLoadCmd("LOAD DATA INPATH '" +  newfpath.toString() + "' INTO TABLE src_thrift");
     
     // load the json data into the src_json table
     fpath = new Path(testFiles, "json.txt");
     newfpath = new Path(tmppath, "json.txt");
     fs.copyFromLocalFile(false, true, fpath, newfpath);
-    db.loadTable(newfpath, "src_json", false);
+    //db.loadTable(newfpath, "src_json", false);
+    runLoadCmd("LOAD DATA INPATH '" +  newfpath.toString() + "' INTO TABLE src_json");
  
   }
 
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
index 634bc41634..35830dd051 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
@@ -105,7 +105,7 @@ public class TestExecDriver extends TestCase {
       for(String src: srctables) {
         db.dropTable(src, true, true);
         db.createTable(src, cols, null, TextInputFormat.class, IgnoreKeyTextOutputFormat.class);
-        db.loadTable(hadoopDataFile[i], src, false);
+        db.loadTable(hadoopDataFile[i], src, false, null);
         i++;
       }
 
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/history/TestHiveHistory.java b/ql/src/test/org/apache/hadoop/hive/ql/history/TestHiveHistory.java
index 715dffaf7d..70cd5a3380 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/history/TestHiveHistory.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/history/TestHiveHistory.java
@@ -96,7 +96,7 @@ protected void setUp(){
         db.dropTable(src, true, true);
         db.createTable(src, cols, null, TextInputFormat.class,
             IgnoreKeyTextOutputFormat.class);
-        db.loadTable(hadoopDataFile[i], src, false);
+        db.loadTable(hadoopDataFile[i], src, false, null);
         i++;
       }
 
diff --git a/ql/src/test/results/compiler/plan/case_sensitivity.q.xml b/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
index eb3c40b8e5..58dcc8c169 100644
--- a/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
+++ b/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/823955998.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/groupby1.q.xml b/ql/src/test/results/compiler/plan/groupby1.q.xml
index 55c7257f7f..3572f4530f 100755
--- a/ql/src/test/results/compiler/plan/groupby1.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby1.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/390951103/204238523.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/input1.q.xml b/ql/src/test/results/compiler/plan/input1.q.xml
index 713e381a2b..a11463defa 100755
--- a/ql/src/test/results/compiler/plan/input1.q.xml
+++ b/ql/src/test/results/compiler/plan/input1.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/15406173/10216775.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/input2.q.xml b/ql/src/test/results/compiler/plan/input2.q.xml
index f86ad90111..a1f3297599 100755
--- a/ql/src/test/results/compiler/plan/input2.q.xml
+++ b/ql/src/test/results/compiler/plan/input2.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/53728112/1166708610.10001</string> 
+            </void> 
            </object> 
           </void> 
           <void method="add"> 
@@ -166,6 +169,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/53728112/1166708610.10003</string> 
+            </void> 
            </object> 
           </void> 
           <void method="add"> 
@@ -252,6 +258,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/53728112/1166708610.10005</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/input3.q.xml b/ql/src/test/results/compiler/plan/input3.q.xml
index cd3d73f8d1..4152e03320 100755
--- a/ql/src/test/results/compiler/plan/input3.q.xml
+++ b/ql/src/test/results/compiler/plan/input3.q.xml
@@ -110,6 +110,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/124974398/210301626.10001</string> 
+            </void> 
            </object> 
           </void> 
           <void method="add"> 
@@ -183,6 +186,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/124974398/210301626.10003</string> 
+            </void> 
            </object> 
           </void> 
           <void method="add"> 
@@ -269,6 +275,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/124974398/210301626.10005</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/input4.q.xml b/ql/src/test/results/compiler/plan/input4.q.xml
index 16070d7853..c3852429da 100755
--- a/ql/src/test/results/compiler/plan/input4.q.xml
+++ b/ql/src/test/results/compiler/plan/input4.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/258804439/588812485.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/input5.q.xml b/ql/src/test/results/compiler/plan/input5.q.xml
index e95edb31a0..3e99d77aca 100644
--- a/ql/src/test/results/compiler/plan/input5.q.xml
+++ b/ql/src/test/results/compiler/plan/input5.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/142551517.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/input6.q.xml b/ql/src/test/results/compiler/plan/input6.q.xml
index 81fc58e0f5..dc2680e444 100644
--- a/ql/src/test/results/compiler/plan/input6.q.xml
+++ b/ql/src/test/results/compiler/plan/input6.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/431259598/1210412976.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/input7.q.xml b/ql/src/test/results/compiler/plan/input7.q.xml
index f6d3857aaa..851e201711 100644
--- a/ql/src/test/results/compiler/plan/input7.q.xml
+++ b/ql/src/test/results/compiler/plan/input7.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/175377627.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/input9.q.xml b/ql/src/test/results/compiler/plan/input9.q.xml
index 8a7b0ec1f9..4f35f8c4c4 100644
--- a/ql/src/test/results/compiler/plan/input9.q.xml
+++ b/ql/src/test/results/compiler/plan/input9.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/488279506.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml b/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
index 1bdc5a6018..f306c940b9 100644
--- a/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
+++ b/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/528170912/226274005.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/join1.q.xml b/ql/src/test/results/compiler/plan/join1.q.xml
index 4ac5542f8c..1c48e0fe31 100644
--- a/ql/src/test/results/compiler/plan/join1.q.xml
+++ b/ql/src/test/results/compiler/plan/join1.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/1222524974.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/join2.q.xml b/ql/src/test/results/compiler/plan/join2.q.xml
index 3308fb179d..a2494b4fad 100644
--- a/ql/src/test/results/compiler/plan/join2.q.xml
+++ b/ql/src/test/results/compiler/plan/join2.q.xml
@@ -97,6 +97,9 @@
                   </void> 
                  </object> 
                 </void> 
+                <void property="tmpDir"> 
+                 <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/94029820.10001</string> 
+                </void> 
                </object> 
               </void> 
              </object> 
diff --git a/ql/src/test/results/compiler/plan/join3.q.xml b/ql/src/test/results/compiler/plan/join3.q.xml
index 3e0358d5a5..e35b9268c8 100644
--- a/ql/src/test/results/compiler/plan/join3.q.xml
+++ b/ql/src/test/results/compiler/plan/join3.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/750826390.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/sample2.q.xml b/ql/src/test/results/compiler/plan/sample2.q.xml
index 266e97a4ee..d6be16e6ed 100644
--- a/ql/src/test/results/compiler/plan/sample2.q.xml
+++ b/ql/src/test/results/compiler/plan/sample2.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/1019605995/847108844.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/sample3.q.xml b/ql/src/test/results/compiler/plan/sample3.q.xml
index d05c5ddbce..417bd7ef51 100644
--- a/ql/src/test/results/compiler/plan/sample3.q.xml
+++ b/ql/src/test/results/compiler/plan/sample3.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/285088828/920051529.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/sample4.q.xml b/ql/src/test/results/compiler/plan/sample4.q.xml
index 595f97695f..ec7bbce890 100644
--- a/ql/src/test/results/compiler/plan/sample4.q.xml
+++ b/ql/src/test/results/compiler/plan/sample4.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/18829701/27117893.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/sample5.q.xml b/ql/src/test/results/compiler/plan/sample5.q.xml
index 6c324a083c..c299d98535 100644
--- a/ql/src/test/results/compiler/plan/sample5.q.xml
+++ b/ql/src/test/results/compiler/plan/sample5.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/83476196/1532819303.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/sample6.q.xml b/ql/src/test/results/compiler/plan/sample6.q.xml
index ebaaf2855e..c112a2b1be 100644
--- a/ql/src/test/results/compiler/plan/sample6.q.xml
+++ b/ql/src/test/results/compiler/plan/sample6.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/61425565/17389492.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
diff --git a/ql/src/test/results/compiler/plan/sample7.q.xml b/ql/src/test/results/compiler/plan/sample7.q.xml
index f4b141b1f8..5669168452 100644
--- a/ql/src/test/results/compiler/plan/sample7.q.xml
+++ b/ql/src/test/results/compiler/plan/sample7.q.xml
@@ -93,6 +93,9 @@
               </void> 
              </object> 
             </void> 
+            <void property="tmpDir"> 
+             <string>/data/users/athusoo/commits/hive_trunk_ws9/ql/../build/ql/tmp/1894315848/355605785.10001</string> 
+            </void> 
            </object> 
           </void> 
          </object> 
