diff --git a/CHANGES.txt b/CHANGES.txt
index cbb3b6b9d8..f8dffc3436 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -31,7 +31,7 @@ Trunk - Unreleased
     (Ashish Thusoo via prasadc)
 
     HIVE-476. Add getTable and getPartition calls to the ReadEntity and
-     WriteEntity objects in PreExecute hooks. (Ashish Thsoo via prasadc) 
+     WriteEntity objects in PreExecute hooks. (Ashish Thsoo via prasadc)
 
   IMPROVEMENTS
     HIVE-389. Option to build without ivy (jssarma)
@@ -126,6 +126,9 @@ Trunk - Unreleased
     HIVE-442. Create partitions after data is moved in the query
     in order to close out an inconsistent window. (Prasad Chakka via athusoo)
 
+    HIVE-483. Fix incorect handling of comments in middle of a query
+    (Namit Jain via athusoo)
+
 Release 0.3.1 - Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/build-common.xml b/build-common.xml
index d097be0765..52869eff5d 100644
--- a/build-common.xml
+++ b/build-common.xml
@@ -54,7 +54,7 @@
   <property name="test.include" value="Test*"/>
   <property name="test.classpath.id" value="test.classpath"/>
   <property name="test.output" value="true"/>
-  <property name="test.timeout" value="2700000"/>
+  <property name="test.timeout" value="5400000"/>
   <property name="test.junit.output.format" value="xml"/>
   <property name="test.junit.output.usefile" value="true"/>
   <property name="test.silent" value="true"/>
diff --git a/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java b/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java
index 3bc8d92006..f698d88098 100644
--- a/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java
+++ b/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java
@@ -213,7 +213,7 @@ public int processLine(String line) {
       if(StringUtils.isBlank(oneCmd))
         continue;
       
-      ret = processCmd(removeComments(oneCmd));
+      ret = processCmd(oneCmd);
       lastRet = ret;
       boolean ignoreErrors = HiveConf.getBoolVar(conf, HiveConf.ConfVars.CLIIGNOREERRORS);
       if(ret != 0 && !ignoreErrors) {
@@ -223,10 +223,6 @@ public int processLine(String line) {
     return lastRet;
   }
 
-  private String removeComments(String oneCmd) {
-    return oneCmd.replaceAll("(?m)--.*\n", "\n");
-  }
-
   public int processReader(BufferedReader r) throws IOException {
     String line;
     StringBuffer qsb = new StringBuffer();
diff --git a/ql/src/test/results/clientnegative/load_wrong_fileformat.q.out b/ql/src/test/results/clientnegative/load_wrong_fileformat.q.out
index 73f3bd2b97..3f6360d4f9 100644
--- a/ql/src/test/results/clientnegative/load_wrong_fileformat.q.out
+++ b/ql/src/test/results/clientnegative/load_wrong_fileformat.q.out
@@ -1,4 +1,7 @@
-query: DROP TABLE T1
+query: -- test for loading into tables with the correct file format
+-- test for loading into partitions with the correct file format
+
+DROP TABLE T1
 query: CREATE TABLE T1(name STRING) STORED AS SEQUENCEFILE
 query: LOAD DATA LOCAL INPATH '../data/files/kv1.txt' INTO TABLE T1
 Failed with exception Cannot load text files into a table stored as SequenceFile.
diff --git a/ql/src/test/results/clientpositive/describe_xpath.q.out b/ql/src/test/results/clientpositive/describe_xpath.q.out
index 7b95c37296..18f95d1819 100644
--- a/ql/src/test/results/clientpositive/describe_xpath.q.out
+++ b/ql/src/test/results/clientpositive/describe_xpath.q.out
@@ -1,13 +1,19 @@
-query: describe src_thrift.lint
+query: -- Describe a list structure in a thrift table
+describe src_thrift.lint
 lint	array<int>	from deserializer
-query: describe src_thrift.lint.$elem$
+query: -- Describe the element of a list
+describe src_thrift.lint.$elem$
 $elem$	int	from deserializer
-query: describe src_thrift.mStringString.$key$
+query: -- Describe the key of a map
+describe src_thrift.mStringString.$key$
 $key$	string	from deserializer
-query: describe src_thrift.mStringString.$value$
+query: -- Describe the value of a map
+describe src_thrift.mStringString.$value$
 $value$	string	from deserializer
-query: describe src_thrift.lintString.$elem$
+query: -- Describe a complex element of a list
+describe src_thrift.lintString.$elem$
 myint	int	from deserializer
 mystring	string	from deserializer
-query: describe src_thrift.lintString.$elem$.myint
+query: -- Describe a member of an element of a list
+describe src_thrift.lintString.$elem$.myint
 myint	int	from deserializer
diff --git a/ql/src/test/results/clientpositive/input16.q.out b/ql/src/test/results/clientpositive/input16.q.out
index f5b19843d6..31ada276f2 100644
--- a/ql/src/test/results/clientpositive/input16.q.out
+++ b/ql/src/test/results/clientpositive/input16.q.out
@@ -1,9 +1,10 @@
-query: DROP TABLE INPUT16
+query: -- TestSerDe is a user defined serde where the default delimiter is Ctrl-B
+DROP TABLE INPUT16
 query: CREATE TABLE INPUT16(KEY STRING, VALUE STRING) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.TestSerDe' STORED AS TEXTFILE
 query: LOAD DATA LOCAL INPATH '../data/files/kv1_cb.txt' INTO TABLE INPUT16
 query: SELECT INPUT16.VALUE, INPUT16.KEY FROM INPUT16
 Input: default/input16
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/62593409/1607071713.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/36406161/418277026.10000
 val_238	238
 val_86	86
 val_311	311
diff --git a/ql/src/test/results/clientpositive/input16_cc.q.out b/ql/src/test/results/clientpositive/input16_cc.q.out
index 82e154d29b..4547df3640 100644
--- a/ql/src/test/results/clientpositive/input16_cc.q.out
+++ b/ql/src/test/results/clientpositive/input16_cc.q.out
@@ -1,9 +1,11 @@
-query: DROP TABLE INPUT16_CC
+query: -- TestSerDe is a user defined serde where the default delimiter is Ctrl-B
+-- the user is overwriting it with ctrlC
+DROP TABLE INPUT16_CC
 query: CREATE TABLE INPUT16_CC(KEY STRING, VALUE STRING) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.TestSerDe'  with serdeproperties ('testserde.default.serialization.format'='\003', 'dummy.prop.not.used'='dummyy.val') STORED AS TEXTFILE
 query: LOAD DATA LOCAL INPATH '../data/files/kv1_cc.txt' INTO TABLE INPUT16_CC
 query: SELECT INPUT16_CC.VALUE, INPUT16_CC.KEY FROM INPUT16_CC
 Input: default/input16_cc
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/505022158/998217510.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/9032620/482125623.10000
 val_238	238
 val_86	86
 val_311	311
diff --git a/ql/src/test/results/clientpositive/inputddl4.q.out b/ql/src/test/results/clientpositive/inputddl4.q.out
index f14b257ea1..bdc8137c0b 100644
--- a/ql/src/test/results/clientpositive/inputddl4.q.out
+++ b/ql/src/test/results/clientpositive/inputddl4.q.out
@@ -1,4 +1,5 @@
-query: DROP TABLE INPUTDDL4
+query: -- a simple test to test sorted/clustered syntax
+DROP TABLE INPUTDDL4
 query: CREATE TABLE INPUTDDL4(viewTime STRING, userid INT,
                        page_url STRING, referrer_url STRING, 
                        friends ARRAY<BIGINT>, properties MAP<STRING, STRING>,
@@ -27,5 +28,5 @@ ip	string	IP Address of the User
 ds	datetime	
 country	string	
 	 	 
-Detailed Table Information	Table(tableName:inputddl4,dbName:default,owner:athusoo,createTime:1241278343,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:viewtime,type:string,comment:null), FieldSchema(name:userid,type:int,comment:null), FieldSchema(name:page_url,type:string,comment:null), FieldSchema(name:referrer_url,type:string,comment:null), FieldSchema(name:friends,type:array<bigint>,comment:null), FieldSchema(name:properties,type:map<string,string>,comment:null), FieldSchema(name:ip,type:string,comment:IP Address of the User)],location:file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/inputddl4,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat,compressed:false,numBuckets:32,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[userid],sortCols:[Order(col:viewtime,order:1)],parameters:{}),partitionKeys:[FieldSchema(name:ds,type:datetime,comment:null), FieldSchema(name:country,type:string,comment:null)],parameters:{comment=This is the page view table})	
+Detailed Table Information	Table(tableName:inputddl4,dbName:default,owner:njain,createTime:1242172799,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:viewtime,type:string,comment:null), FieldSchema(name:userid,type:int,comment:null), FieldSchema(name:page_url,type:string,comment:null), FieldSchema(name:referrer_url,type:string,comment:null), FieldSchema(name:friends,type:array<bigint>,comment:null), FieldSchema(name:properties,type:map<string,string>,comment:null), FieldSchema(name:ip,type:string,comment:IP Address of the User)],location:file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/inputddl4,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat,compressed:false,numBuckets:32,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[userid],sortCols:[Order(col:viewtime,order:1)],parameters:{}),partitionKeys:[FieldSchema(name:ds,type:datetime,comment:null), FieldSchema(name:country,type:string,comment:null)],parameters:{comment=This is the page view table})	
 query: DROP TABLE INPUTDDL4
diff --git a/ql/src/test/results/clientpositive/inputddl5.q.out b/ql/src/test/results/clientpositive/inputddl5.q.out
index bf49f8df71..18326db22d 100644
--- a/ql/src/test/results/clientpositive/inputddl5.q.out
+++ b/ql/src/test/results/clientpositive/inputddl5.q.out
@@ -1,13 +1,15 @@
-query: CREATE TABLE INPUTDDL5(name STRING) STORED AS TEXTFILE
+query: -- test for internationalization
+-- kv4.txt contains the utf-8 character 0xE982B5E993AE which we are verifying later on
+CREATE TABLE INPUTDDL5(name STRING) STORED AS TEXTFILE
 query: LOAD DATA LOCAL INPATH '../data/files/kv4.txt' INTO TABLE INPUTDDL5
 query: DESCRIBE INPUTDDL5
 name	string	
 query: SELECT INPUTDDL5.name from INPUTDDL5
 Input: default/inputddl5
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/15516876/1568818554.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/347511721/10010959.10000
 邵铮
 query: SELECT count(1) FROM INPUTDDL5 WHERE INPUTDDL5.name = _UTF-8 0xE982B5E993AE
 Input: default/inputddl5
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/106730807/9468444.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/363368800/365120763.10000
 1
 query: DROP TABLE INPUTDDL5
diff --git a/ql/src/test/results/clientpositive/inputddl6.q.out b/ql/src/test/results/clientpositive/inputddl6.q.out
index 8fc2674ff5..c760bf6ada 100644
--- a/ql/src/test/results/clientpositive/inputddl6.q.out
+++ b/ql/src/test/results/clientpositive/inputddl6.q.out
@@ -1,4 +1,7 @@
-query: DROP TABLE INPUTDDL6
+query: -- test for describe extended table
+-- test for describe extended table partition
+-- test for alter table drop partition
+DROP TABLE INPUTDDL6
 query: CREATE TABLE INPUTDDL6(KEY STRING, VALUE STRING) PARTITIONED BY(ds DATETIME) STORED AS TEXTFILE
 query: LOAD DATA LOCAL INPATH '../data/files/kv1.txt' INTO TABLE INPUTDDL6 PARTITION (ds='2008-04-09')
 query: LOAD DATA LOCAL INPATH '../data/files/kv1.txt' INTO TABLE INPUTDDL6 PARTITION (ds='2008-04-08')
@@ -7,13 +10,13 @@ key	string
 value	string	
 ds	datetime	
 	 	 
-Detailed Table Information	Table(tableName:inputddl6,dbName:default,owner:athusoo,createTime:1241278353,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:key,type:string,comment:null), FieldSchema(name:value,type:string,comment:null)],location:file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/inputddl6,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),partitionKeys:[FieldSchema(name:ds,type:datetime,comment:null)],parameters:{})	
+Detailed Table Information	Table(tableName:inputddl6,dbName:default,owner:njain,createTime:1242172817,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:key,type:string,comment:null), FieldSchema(name:value,type:string,comment:null)],location:file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/inputddl6,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),partitionKeys:[FieldSchema(name:ds,type:datetime,comment:null)],parameters:{})	
 query: DESCRIBE EXTENDED INPUTDDL6 PARTITION (ds='2008-04-08')
 key	string	
 value	string	
 ds	datetime	
 	 	 
-Detailed Partition Information	Partition(values:[2008-04-08],dbName:default,tableName:inputddl6,createTime:0,lastAccessTime:0,sd:StorageDescriptor(cols:[FieldSchema(name:key,type:string,comment:null), FieldSchema(name:value,type:string,comment:null)],location:file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/inputddl6/ds=2008-04-08,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),parameters:{})	
+Detailed Partition Information	Partition(values:[2008-04-08],dbName:default,tableName:inputddl6,createTime:0,lastAccessTime:0,sd:StorageDescriptor(cols:[FieldSchema(name:key,type:string,comment:null), FieldSchema(name:value,type:string,comment:null)],location:file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/inputddl6/ds=2008-04-08,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),parameters:{})	
 query: SHOW PARTITIONS INPUTDDL6
 ds=2008-04-08
 ds=2008-04-09
diff --git a/ql/src/test/results/clientpositive/inputddl7.q.out b/ql/src/test/results/clientpositive/inputddl7.q.out
index 889313c588..146f21adff 100644
--- a/ql/src/test/results/clientpositive/inputddl7.q.out
+++ b/ql/src/test/results/clientpositive/inputddl7.q.out
@@ -1,49 +1,52 @@
-query: DROP TABLE T1
+query: -- test for loading into tables with the correct file format
+-- test for loading into partitions with the correct file format
+
+DROP TABLE T1
 query: CREATE TABLE T1(name STRING) STORED AS TEXTFILE
 query: LOAD DATA LOCAL INPATH '../data/files/kv1.txt' INTO TABLE T1
 query: SELECT COUNT(1) FROM T1
 Input: default/t1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/15999523/83038071.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/481089091/6749578.10000
 500
 query: DROP TABLE T2
 query: CREATE TABLE T2(name STRING) STORED AS SEQUENCEFILE
 query: LOAD DATA LOCAL INPATH '../data/files/kv1.seq' INTO TABLE T2
 query: SELECT COUNT(1) FROM T2
 Input: default/t2
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/346849950/36939746.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/270146214/416573491.10000
 500
 query: DROP TABLE T3
 query: CREATE TABLE T3(name STRING) PARTITIONED BY(ds STRING) STORED AS TEXTFILE
 query: LOAD DATA LOCAL INPATH '../data/files/kv1.txt' INTO TABLE T3 PARTITION (ds='2008-04-09')
 query: SELECT COUNT(1) FROM T3 where T3.ds='2008-04-09'
 Input: default/t3/ds=2008-04-09
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1393596681/420008462.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/244295858/783017444.10000
 500
 query: DROP TABLE T4
 query: CREATE TABLE T4(name STRING) PARTITIONED BY(ds STRING) STORED AS SEQUENCEFILE
 query: LOAD DATA LOCAL INPATH '../data/files/kv1.seq' INTO TABLE T4 PARTITION (ds='2008-04-09')
 query: SELECT COUNT(1) FROM T4 where T4.ds='2008-04-09'
 Input: default/t4/ds=2008-04-09
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1014261192/72527210.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/32294603/204394858.10000
 500
 query: DESCRIBE EXTENDED T1
 name	string	
 	 	 
-Detailed Table Information	Table(tableName:t1,dbName:default,owner:athusoo,createTime:1241278356,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:name,type:string,comment:null)],location:file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/t1,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),partitionKeys:[],parameters:{})	
+Detailed Table Information	Table(tableName:t1,dbName:default,owner:njain,createTime:1242172820,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:name,type:string,comment:null)],location:file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/t1,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),partitionKeys:[],parameters:{})	
 query: DESCRIBE EXTENDED T2
 name	string	
 	 	 
-Detailed Table Information	Table(tableName:t2,dbName:default,owner:athusoo,createTime:1241278359,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:name,type:string,comment:null)],location:file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/t2,inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),partitionKeys:[],parameters:{})	
+Detailed Table Information	Table(tableName:t2,dbName:default,owner:njain,createTime:1242172823,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:name,type:string,comment:null)],location:file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/t2,inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),partitionKeys:[],parameters:{})	
 query: DESCRIBE EXTENDED T3 PARTITION (ds='2008-04-09')
 name	string	
 ds	string	
 	 	 
-Detailed Partition Information	Partition(values:[2008-04-09],dbName:default,tableName:t3,createTime:0,lastAccessTime:0,sd:StorageDescriptor(cols:[FieldSchema(name:name,type:string,comment:null)],location:file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/t3/ds=2008-04-09,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),parameters:{})	
+Detailed Partition Information	Partition(values:[2008-04-09],dbName:default,tableName:t3,createTime:0,lastAccessTime:0,sd:StorageDescriptor(cols:[FieldSchema(name:name,type:string,comment:null)],location:file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/t3/ds=2008-04-09,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),parameters:{})	
 query: DESCRIBE EXTENDED T4 PARTITION (ds='2008-04-09')
 name	string	
 ds	string	
 	 	 
-Detailed Partition Information	Partition(values:[2008-04-09],dbName:default,tableName:t4,createTime:0,lastAccessTime:0,sd:StorageDescriptor(cols:[FieldSchema(name:name,type:string,comment:null)],location:file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/t4/ds=2008-04-09,inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),parameters:{})	
+Detailed Partition Information	Partition(values:[2008-04-09],dbName:default,tableName:t4,createTime:0,lastAccessTime:0,sd:StorageDescriptor(cols:[FieldSchema(name:name,type:string,comment:null)],location:file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/t4/ds=2008-04-09,inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),parameters:{})	
 query: DROP TABLE T1
 query: DROP TABLE T2
 query: DROP TABLE T3
diff --git a/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out b/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out
index 7744f82887..2f4f82e5fd 100644
--- a/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out
+++ b/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out
@@ -1,4 +1,5 @@
-query: explain extended select * from src where rand(1) < 0.1
+query: -- scanning un-partitioned data
+explain extended select * from src where rand(1) < 0.1
 ABSTRACT SYNTAX TREE:
   (TOK_QUERY (TOK_FROM (TOK_TABREF src)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_WHERE (< (TOK_FUNCTION rand 1) 0.1))))
 
@@ -24,7 +25,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1633457978/568179219.10001.insclause-0
+                  directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/552086915/1424484527.10001.insclause-0
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -33,9 +34,9 @@ STAGE PLANS:
                         serialization.format 1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/src 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/src 
       Path -> Partition:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/src 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/src 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -50,7 +51,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/src
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/src
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
 
@@ -61,7 +62,7 @@ STAGE PLANS:
 
 query: select * from src where rand(1) < 0.1
 Input: default/src
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1121250794/356279934.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/258191470/334752323.10000
 409	val_409
 429	val_429
 209	val_209
diff --git a/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out b/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out
index e864505fe8..25b5b56aeb 100644
--- a/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out
+++ b/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out
@@ -1,4 +1,5 @@
-query: drop table tmptable
+query: -- scanning partitioned data
+drop table tmptable
 query: create table tmptable(key string, value string, hr string, ds string)
 query: explain extended 
 insert overwrite table tmptable
@@ -32,7 +33,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/10675457/692984549.10000.insclause-0
+                  directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/193426468/98433997.10000.insclause-0
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -46,15 +47,15 @@ STAGE PLANS:
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/tmptable
+                        location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/tmptable
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
       Path -> Partition:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             partition values:
               ds 2008-04-08
@@ -73,10 +74,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             partition values:
               ds 2008-04-08
@@ -95,7 +96,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
 
@@ -103,7 +104,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/10675457/692984549.10000.insclause-0
+            source: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/193426468/98433997.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -117,10 +118,10 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/tmptable
+                  location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/tmptable
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: tmptable
-            tmp directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/10675457/692984549.10001
+            tmp directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/193426468/98433997.10001
 
 
 query: insert overwrite table tmptable
@@ -130,7 +131,7 @@ Input: default/srcpart/ds=2008-04-08/hr=12
 Output: default/tmptable
 query: select * from tmptable x sort by x.key
 Input: default/tmptable
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/215840330/359161528.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/20138045/311110484.10000
 103	val_103	2008-04-08	11
 103	val_103	2008-04-08	12
 133	val_133	2008-04-08	12
diff --git a/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out b/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
index 6e01b38fb9..048697691d 100644
--- a/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
+++ b/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
@@ -1,4 +1,5 @@
-query: explain extended select a.* from srcpart a where rand(1) < 0.1 and a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
+query: -- complex predicates in the where clause
+explain extended select a.* from srcpart a where rand(1) < 0.1 and a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 ABSTRACT SYNTAX TREE:
   (TOK_QUERY (TOK_FROM (TOK_TABREF srcpart a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_ALLCOLREF a))) (TOK_WHERE (and (and (and (< (TOK_FUNCTION rand 1) 0.1) (= (. (TOK_TABLE_OR_COL a) ds) '2008-04-08')) (not (or (> (TOK_TABLE_OR_COL key) 50) (< (TOK_TABLE_OR_COL key) 10)))) (like (. (TOK_TABLE_OR_COL a) hr) '%2')))))
 
@@ -28,7 +29,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/770982235/339058649.10001.insclause-0
+                  directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/45335645/29239923.10001.insclause-0
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -37,9 +38,9 @@ STAGE PLANS:
                         serialization.format 1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
       Path -> Partition:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             partition values:
               ds 2008-04-08
@@ -58,7 +59,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
 
@@ -69,13 +70,14 @@ STAGE PLANS:
 
 query: select a.* from srcpart a where rand(1) < 0.1 and a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 Input: default/srcpart/ds=2008-04-08/hr=12
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/461813857/72994216.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/47920681/27148542.10000
 42	val_42	2008-04-08	12
 44	val_44	2008-04-08	12
 26	val_26	2008-04-08	12
 18	val_18	2008-04-08	12
 37	val_37	2008-04-08	12
-query: explain extended select a.* from srcpart a where a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
+query: -- without rand for comparison
+explain extended select a.* from srcpart a where a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 ABSTRACT SYNTAX TREE:
   (TOK_QUERY (TOK_FROM (TOK_TABREF srcpart a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_ALLCOLREF a))) (TOK_WHERE (and (and (= (. (TOK_TABLE_OR_COL a) ds) '2008-04-08') (not (or (> (TOK_TABLE_OR_COL key) 50) (< (TOK_TABLE_OR_COL key) 10)))) (like (. (TOK_TABLE_OR_COL a) hr) '%2')))))
 
@@ -105,7 +107,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/203819110/60154549.10001.insclause-0
+                  directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/1286189180/888381841.10001.insclause-0
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -114,9 +116,9 @@ STAGE PLANS:
                         serialization.format 1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
       Path -> Partition:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             partition values:
               ds 2008-04-08
@@ -135,7 +137,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
 
@@ -146,7 +148,7 @@ STAGE PLANS:
 
 query: select a.* from srcpart a where a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 Input: default/srcpart/ds=2008-04-08/hr=12
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/306669229/518134414.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/249549357/307540214.10000
 27	val_27	2008-04-08	12
 37	val_37	2008-04-08	12
 15	val_15	2008-04-08	12
diff --git a/ql/src/test/results/clientpositive/sample1.q.out b/ql/src/test/results/clientpositive/sample1.q.out
index c53fcc7778..61816332fc 100644
--- a/ql/src/test/results/clientpositive/sample1.q.out
+++ b/ql/src/test/results/clientpositive/sample1.q.out
@@ -1,5 +1,6 @@
 query: CREATE TABLE dest1(key INT, value STRING, dt STRING, hr STRING) STORED AS TEXTFILE
-query: EXPLAIN EXTENDED
+query: -- no input pruning, no sample filter
+EXPLAIN EXTENDED
 INSERT OVERWRITE TABLE dest1 SELECT s.*
 FROM srcpart TABLESAMPLE (BUCKET 1 OUT OF 1 ON rand()) s
 WHERE s.ds='2008-04-08' and s.hr='11'
@@ -46,7 +47,7 @@ STAGE PLANS:
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/139440119/111511740.10000.insclause-0
+                      directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/151429807/960604309.10000.insclause-0
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -60,14 +61,14 @@ STAGE PLANS:
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                            location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
       Path -> Partition:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             partition values:
               ds 2008-04-08
@@ -86,7 +87,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
 
@@ -94,7 +95,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/139440119/111511740.10000.insclause-0
+            source: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/151429807/960604309.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -108,10 +109,10 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
-            tmp directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/139440119/111511740.10001
+            tmp directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/151429807/960604309.10001
 
 
 query: INSERT OVERWRITE TABLE dest1 SELECT s.*
@@ -121,7 +122,7 @@ Input: default/srcpart/ds=2008-04-08/hr=11
 Output: default/dest1
 query: SELECT dest1.* FROM dest1
 Input: default/dest1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/52723391/39379816.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/383189915/1659525718.10000
 238	val_238	2008-04-08	11
 86	val_86	2008-04-08	11
 311	val_311	2008-04-08	11
diff --git a/ql/src/test/results/clientpositive/sample2.q.out b/ql/src/test/results/clientpositive/sample2.q.out
index de96c52061..f5717f96cc 100644
--- a/ql/src/test/results/clientpositive/sample2.q.out
+++ b/ql/src/test/results/clientpositive/sample2.q.out
@@ -1,5 +1,7 @@
 query: CREATE TABLE dest1(key INT, value STRING) STORED AS TEXTFILE
-query: EXPLAIN EXTENDED
+query: -- input pruning, no sample filter
+-- default table sample columns
+EXPLAIN EXTENDED
 INSERT OVERWRITE TABLE dest1 SELECT s.* 
 FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 2) s
 ABSTRACT SYNTAX TREE:
@@ -29,7 +31,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/455891863/11091653.10000.insclause-0
+                  directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/662898810/270584006.10000.insclause-0
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -43,14 +45,14 @@ STAGE PLANS:
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                        location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -66,7 +68,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
 
@@ -74,7 +76,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/455891863/11091653.10000.insclause-0
+            source: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/662898810/270584006.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -88,10 +90,10 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
-            tmp directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/455891863/11091653.10001
+            tmp directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/662898810/270584006.10001
 
 
 query: INSERT OVERWRITE TABLE dest1 SELECT s.* 
@@ -100,7 +102,7 @@ Input: default/srcbucket
 Output: default/dest1
 query: SELECT dest1.* FROM dest1
 Input: default/dest1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/445858413/37931330.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/130193844/914444459.10000
 238	val_238
 86	val_86
 311	val_311
diff --git a/ql/src/test/results/clientpositive/sample3.q.out b/ql/src/test/results/clientpositive/sample3.q.out
index b51584ae06..aa40c6fc54 100644
--- a/ql/src/test/results/clientpositive/sample3.q.out
+++ b/ql/src/test/results/clientpositive/sample3.q.out
@@ -1,4 +1,5 @@
-query: EXPLAIN
+query: -- no input pruning, sample filter
+EXPLAIN
 SELECT s.key
 FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 5 on key) s
 ABSTRACT SYNTAX TREE:
@@ -40,7 +41,7 @@ STAGE PLANS:
 query: SELECT s.key
 FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 5 on key) s SORT BY key
 Input: default/srcbucket
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/785589213/505578835.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/1055187428/602701590.10000
 100
 100
 100
diff --git a/ql/src/test/results/clientpositive/sample4.q.out b/ql/src/test/results/clientpositive/sample4.q.out
index bb4ecc514d..daae074663 100644
--- a/ql/src/test/results/clientpositive/sample4.q.out
+++ b/ql/src/test/results/clientpositive/sample4.q.out
@@ -1,5 +1,7 @@
 query: CREATE TABLE dest1(key INT, value STRING) STORED AS TEXTFILE
-query: EXPLAIN EXTENDED
+query: -- bucket column is the same as table sample
+-- No need for sample filter
+EXPLAIN EXTENDED
 INSERT OVERWRITE TABLE dest1 SELECT s.*
 FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key) s
 ABSTRACT SYNTAX TREE:
@@ -29,7 +31,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/554668367/995098198.10000.insclause-0
+                  directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/1651427598/1472924890.10000.insclause-0
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -43,14 +45,14 @@ STAGE PLANS:
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                        location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -66,7 +68,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
 
@@ -74,7 +76,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/554668367/995098198.10000.insclause-0
+            source: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/1651427598/1472924890.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -88,10 +90,10 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
-            tmp directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/554668367/995098198.10001
+            tmp directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/1651427598/1472924890.10001
 
 
 query: INSERT OVERWRITE TABLE dest1 SELECT s.*
@@ -100,7 +102,7 @@ Input: default/srcbucket
 Output: default/dest1
 query: SELECT dest1.* FROM dest1
 Input: default/dest1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/483056409/195284232.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/19405690/162456281.10000
 238	val_238
 86	val_86
 311	val_311
diff --git a/ql/src/test/results/clientpositive/sample5.q.out b/ql/src/test/results/clientpositive/sample5.q.out
index fd576cbd83..54ea91bee1 100644
--- a/ql/src/test/results/clientpositive/sample5.q.out
+++ b/ql/src/test/results/clientpositive/sample5.q.out
@@ -1,6 +1,7 @@
 query: CREATE TABLE dest1(key INT, value STRING) STORED AS TEXTFILE
-query: EXPLAIN EXTENDED
-INSERT OVERWRITE TABLE dest1 SELECT s.* 
+query: -- no input pruning, sample filter
+EXPLAIN EXTENDED
+INSERT OVERWRITE TABLE dest1 SELECT s.* -- here's another test
 FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 5 on key) s
 ABSTRACT SYNTAX TREE:
   (TOK_QUERY (TOK_FROM (TOK_TABREF srcbucket (TOK_TABLESAMPLE 1 5 (TOK_TABLE_OR_COL key)) s)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB dest1)) (TOK_SELECT (TOK_SELEXPR (TOK_ALLCOLREF s)))))
@@ -33,7 +34,7 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1095779156/1227078175.10000.insclause-0
+                    directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/937153166/420939583.10000.insclause-0
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -47,14 +48,14 @@ STAGE PLANS:
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                          location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket 
       Path -> Partition:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -70,7 +71,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
 
@@ -78,7 +79,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1095779156/1227078175.10000.insclause-0
+            source: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/937153166/420939583.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -92,19 +93,19 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
-            tmp directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1095779156/1227078175.10001
+            tmp directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/937153166/420939583.10001
 
 
-query: INSERT OVERWRITE TABLE dest1 SELECT s.* 
+query: INSERT OVERWRITE TABLE dest1 SELECT s.* -- here's another test
 FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 5 on key) s
 Input: default/srcbucket
 Output: default/dest1
 query: SELECT dest1.* FROM dest1 SORT BY key
 Input: default/dest1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/665499523/380611837.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/567142156/684303413.10000
 2	val_2
 2	val_3
 18	val_18
diff --git a/ql/src/test/results/clientpositive/sample6.q.out b/ql/src/test/results/clientpositive/sample6.q.out
index 1798a0ef84..22f89f755a 100644
--- a/ql/src/test/results/clientpositive/sample6.q.out
+++ b/ql/src/test/results/clientpositive/sample6.q.out
@@ -1,5 +1,6 @@
 query: CREATE TABLE dest1(key INT, value STRING) STORED AS TEXTFILE
-query: EXPLAIN EXTENDED
+query: -- both input pruning and sample filter
+EXPLAIN EXTENDED
 INSERT OVERWRITE TABLE dest1 SELECT s.* 
 FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 4 on key) s
 ABSTRACT SYNTAX TREE:
@@ -33,7 +34,7 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/734546404/326766477.10000.insclause-0
+                    directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/644812951/21988928.10000.insclause-0
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -47,14 +48,14 @@ STAGE PLANS:
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                          location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -70,7 +71,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
 
@@ -78,7 +79,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/734546404/326766477.10000.insclause-0
+            source: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/644812951/21988928.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -92,10 +93,10 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
-            tmp directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/734546404/326766477.10001
+            tmp directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/644812951/21988928.10001
 
 
 query: INSERT OVERWRITE TABLE dest1 SELECT s.* 
@@ -104,7 +105,7 @@ Input: default/srcbucket
 Output: default/dest1
 query: SELECT dest1.* FROM dest1
 Input: default/dest1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/630592516/317470973.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/241022860/87886661.10000
 165	val_165
 484	val_484
 150	val_150
diff --git a/ql/src/test/results/clientpositive/sample7.q.out b/ql/src/test/results/clientpositive/sample7.q.out
index b5d4f93627..3b8ca96a6f 100644
--- a/ql/src/test/results/clientpositive/sample7.q.out
+++ b/ql/src/test/results/clientpositive/sample7.q.out
@@ -1,5 +1,6 @@
 query: CREATE TABLE dest1(key INT, value STRING) STORED AS TEXTFILE
-query: EXPLAIN EXTENDED
+query: -- both input pruning and sample filter
+EXPLAIN EXTENDED
 INSERT OVERWRITE TABLE dest1 SELECT s.* 
 FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 4 on key) s
 WHERE s.key > 100
@@ -38,7 +39,7 @@ STAGE PLANS:
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/92876441/338195813.10000.insclause-0
+                      directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/418752266/1655292388.10000.insclause-0
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -52,14 +53,14 @@ STAGE PLANS:
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                            location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -75,7 +76,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
 
@@ -83,7 +84,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/92876441/338195813.10000.insclause-0
+            source: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/418752266/1655292388.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -97,10 +98,10 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
-            tmp directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/92876441/338195813.10001
+            tmp directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/418752266/1655292388.10001
 
 
 query: INSERT OVERWRITE TABLE dest1 SELECT s.* 
@@ -110,7 +111,7 @@ Input: default/srcbucket
 Output: default/dest1
 query: SELECT dest1.* FROM dest1
 Input: default/dest1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/491534417/37965249.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/920399475/4091792.10000
 165	val_165
 484	val_484
 150	val_150
diff --git a/ql/src/test/results/clientpositive/sample8.q.out b/ql/src/test/results/clientpositive/sample8.q.out
index 4aab8012e0..762ca472db 100644
--- a/ql/src/test/results/clientpositive/sample8.q.out
+++ b/ql/src/test/results/clientpositive/sample8.q.out
@@ -1,4 +1,5 @@
-query: EXPLAIN EXTENDED
+query: -- sampling with join and alias
+EXPLAIN EXTENDED
 SELECT s.*
 FROM srcpart TABLESAMPLE (BUCKET 1 OUT OF 1 ON key) s
 JOIN srcpart TABLESAMPLE (BUCKET 1 OUT OF 10 ON key) t
@@ -55,12 +56,12 @@ STAGE PLANS:
                       type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
       Path -> Partition:
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             partition values:
               ds 2008-04-08
@@ -79,10 +80,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             partition values:
               ds 2008-04-08
@@ -101,10 +102,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             partition values:
               ds 2008-04-09
@@ -123,10 +124,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
-        file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             partition values:
               ds 2008-04-09
@@ -145,7 +146,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/athusoo/commits/hive_trunk_ws8/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/njain/hive5/hive5/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
       Reduce Operator Tree:
@@ -172,7 +173,7 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1701195808/498985582.10002
+                directory: /data/users/njain/hive5/hive5/build/ql/tmp/165890068/705170586.10002
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -185,7 +186,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1701195808/498985582.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/165890068/705170586.10002 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -210,9 +211,9 @@ STAGE PLANS:
                   type: string
       Needs Tagging: false
       Path -> Alias:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1701195808/498985582.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/165890068/705170586.10002 
       Path -> Partition:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1701195808/498985582.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/165890068/705170586.10002 
           Partition
           
               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -227,7 +228,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/535977627.10001.insclause-0
+            directory: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/404663379.10001.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -250,7 +251,7 @@ Input: default/srcpart/ds=2008-04-08/hr=11
 Input: default/srcpart/ds=2008-04-08/hr=12
 Input: default/srcpart/ds=2008-04-09/hr=11
 Input: default/srcpart/ds=2008-04-09/hr=12
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1694621949/361708294.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/68681937/1395083774.10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/union.q.out b/ql/src/test/results/clientpositive/union.q.out
index 53eba39f3c..eee3f2be3c 100644
--- a/ql/src/test/results/clientpositive/union.q.out
+++ b/ql/src/test/results/clientpositive/union.q.out
@@ -1,4 +1,6 @@
-query: EXPLAIN
+query: -- union case: both subqueries are map jobs on same input, followed by filesink
+
+EXPLAIN
 FROM (
   FROM src select src.key, src.value WHERE src.key < 100
   UNION ALL
diff --git a/ql/src/test/results/clientpositive/union10.q.out b/ql/src/test/results/clientpositive/union10.q.out
index e1dcdf2c1c..a789f8b0e7 100644
--- a/ql/src/test/results/clientpositive/union10.q.out
+++ b/ql/src/test/results/clientpositive/union10.q.out
@@ -1,4 +1,6 @@
-query: drop table tmptable
+query: -- union case: all subqueries are a map-reduce jobs, 3 way union, same input for all sub-queries, followed by filesink
+
+drop table tmptable
 query: create table tmptable(key string, value int)
 query: explain 
 insert overwrite table tmptable
@@ -59,7 +61,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/47954573/182017310.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/28088060/1127108958.10002 
           Union
             Select Operator
               expressions:
@@ -81,7 +83,7 @@ STAGE PLANS:
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/47954573/182017310.10003 
+        /data/users/njain/hive5/hive5/build/ql/tmp/28088060/1127108958.10003 
           Union
             Select Operator
               expressions:
@@ -103,7 +105,7 @@ STAGE PLANS:
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/47954573/182017310.10004 
+        /data/users/njain/hive5/hive5/build/ql/tmp/28088060/1127108958.10004 
           Union
             Select Operator
               expressions:
@@ -215,7 +217,7 @@ Input: default/src
 Output: default/tmptable
 query: select * from tmptable x sort by x.key
 Input: default/tmptable
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/230110516/89280832.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/1213068626/1117023264.10000
 tst1	500
 tst2	500
 tst3	500
diff --git a/ql/src/test/results/clientpositive/union11.q.out b/ql/src/test/results/clientpositive/union11.q.out
index ca0f5e8fcd..43fec5be46 100644
--- a/ql/src/test/results/clientpositive/union11.q.out
+++ b/ql/src/test/results/clientpositive/union11.q.out
@@ -1,4 +1,6 @@
-query: explain 
+query: -- union case: all subqueries are a map-reduce jobs, 3 way union, same input for all sub-queries, followed by reducesink
+
+explain 
   select unionsrc.key, count(1) FROM (select 'tst1' as key, count(1) as value from src s1
                                         UNION  ALL  
                                             select 'tst2' as key, count(1) as value from src s2
@@ -54,7 +56,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/7097981/405016190.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/10111128/61373547.10002 
           Union
             Group By Operator
               aggregations:
@@ -75,7 +77,7 @@ STAGE PLANS:
                 value expressions:
                       expr: 1
                       type: bigint
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/7097981/405016190.10003 
+        /data/users/njain/hive5/hive5/build/ql/tmp/10111128/61373547.10003 
           Union
             Group By Operator
               aggregations:
@@ -96,7 +98,7 @@ STAGE PLANS:
                 value expressions:
                       expr: 1
                       type: bigint
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/7097981/405016190.10004 
+        /data/users/njain/hive5/hive5/build/ql/tmp/10111128/61373547.10004 
           Union
             Group By Operator
               aggregations:
@@ -217,7 +219,7 @@ query: select unionsrc.key, count(1) FROM (select 'tst1' as key, count(1) as val
                                         UNION ALL
                                             select 'tst3' as key, count(1) as value from src s3) unionsrc group by unionsrc.key
 Input: default/src
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1498343090/387630909.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/275601658/682160651.10000
 tst1	1
 tst2	1
 tst3	1
diff --git a/ql/src/test/results/clientpositive/union12.q.out b/ql/src/test/results/clientpositive/union12.q.out
index a742218033..0d511b866c 100644
--- a/ql/src/test/results/clientpositive/union12.q.out
+++ b/ql/src/test/results/clientpositive/union12.q.out
@@ -1,4 +1,6 @@
-query: drop table tmptable
+query: -- union case: all subqueries are a map-reduce jobs, 3 way union, different inputs for all sub-queries, followed by filesink
+
+drop table tmptable
 query: create table tmptable(key string, value int)
 query: explain 
 insert overwrite table tmptable
@@ -59,7 +61,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1200507308/759713067.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/57759680/470566404.10002 
           Union
             Select Operator
               expressions:
@@ -81,7 +83,7 @@ STAGE PLANS:
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1200507308/759713067.10003 
+        /data/users/njain/hive5/hive5/build/ql/tmp/57759680/470566404.10003 
           Union
             Select Operator
               expressions:
@@ -103,7 +105,7 @@ STAGE PLANS:
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1200507308/759713067.10004 
+        /data/users/njain/hive5/hive5/build/ql/tmp/57759680/470566404.10004 
           Union
             Select Operator
               expressions:
@@ -217,7 +219,7 @@ Input: default/srcbucket
 Output: default/tmptable
 query: select * from tmptable x sort by x.key
 Input: default/tmptable
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/401912347/42136443.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/270230554/696358836.10000
 tst1	500
 tst2	25
 tst3	1000
diff --git a/ql/src/test/results/clientpositive/union13.q.out b/ql/src/test/results/clientpositive/union13.q.out
index 49e0d22b18..b0c3918d93 100644
--- a/ql/src/test/results/clientpositive/union13.q.out
+++ b/ql/src/test/results/clientpositive/union13.q.out
@@ -1,4 +1,6 @@
-query: explain 
+query: -- union case: both subqueries are a map-only jobs, same input, followed by filesink
+
+explain 
   select unionsrc.key, unionsrc.value FROM (select s1.key as key, s1.value as value from src s1 UNION  ALL  
                                             select s2.key as key, s2.value as value from src s2) unionsrc
 ABSTRACT SYNTAX TREE:
@@ -61,7 +63,7 @@ STAGE PLANS:
 query: select unionsrc.key, unionsrc.value FROM (select s1.key as key, s1.value as value from src s1 UNION  ALL  
                                           select s2.key as key, s2.value as value from src s2) unionsrc
 Input: default/src
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1992052322/24152217.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/289566941/188295561.10000
 238	val_238
 238	val_238
 86	val_86
diff --git a/ql/src/test/results/clientpositive/union14.q.out b/ql/src/test/results/clientpositive/union14.q.out
index a19f109059..ba5eeccde9 100644
--- a/ql/src/test/results/clientpositive/union14.q.out
+++ b/ql/src/test/results/clientpositive/union14.q.out
@@ -1,4 +1,6 @@
-query: explain 
+query: -- union case: 1 subquery is a map-reduce job, different inputs for sub-queries, followed by reducesink
+
+explain 
   select unionsrc.key, count(1) FROM (select s2.key as key, s2.value as value from src1 s2
                                         UNION  ALL  
                                       select 'tst1' as key, cast(count(1) as string) as value from src s1) 
@@ -35,7 +37,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/408002969/2251170.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/446944973/349659273.10002 
           Union
             Group By Operator
               aggregations:
@@ -56,7 +58,7 @@ STAGE PLANS:
                 value expressions:
                       expr: 1
                       type: bigint
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/408002969/2251170.10003 
+        /data/users/njain/hive5/hive5/build/ql/tmp/446944973/349659273.10003 
           Union
             Group By Operator
               aggregations:
@@ -143,7 +145,7 @@ query: select unionsrc.key, count(1) FROM (select s2.key as key, s2.value as val
   unionsrc group by unionsrc.key
 Input: default/src1
 Input: default/src
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/22399937/103465306.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/410052586/217398417.10000
 	10
 128	1
 146	1
diff --git a/ql/src/test/results/clientpositive/union15.q.out b/ql/src/test/results/clientpositive/union15.q.out
index caee4f2212..89cf6b2281 100644
--- a/ql/src/test/results/clientpositive/union15.q.out
+++ b/ql/src/test/results/clientpositive/union15.q.out
@@ -1,4 +1,6 @@
-query: explain 
+query: -- union case: 1 subquery is a map-reduce job, different inputs for sub-queries, followed by reducesink
+
+explain 
   select unionsrc.key, count(1) FROM (select 'tst1' as key, cast(count(1) as string) as value from src s1
                                         UNION  ALL  
                                             select s2.key as key, s2.value as value from src1 s2
@@ -54,7 +56,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1766444/227040434.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/403607265/202607985.10002 
           Union
             Group By Operator
               aggregations:
@@ -75,7 +77,7 @@ STAGE PLANS:
                 value expressions:
                       expr: 1
                       type: bigint
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1766444/227040434.10003 
+        /data/users/njain/hive5/hive5/build/ql/tmp/403607265/202607985.10003 
           Union
             Group By Operator
               aggregations:
@@ -96,7 +98,7 @@ STAGE PLANS:
                 value expressions:
                       expr: 1
                       type: bigint
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1766444/227040434.10004 
+        /data/users/njain/hive5/hive5/build/ql/tmp/403607265/202607985.10004 
           Union
             Group By Operator
               aggregations:
@@ -186,7 +188,7 @@ query: select unionsrc.key, count(1) FROM (select 'tst1' as key, cast(count(1) a
                                             select s3.key as key, s3.value as value from src1 s3) unionsrc group by unionsrc.key
 Input: default/src
 Input: default/src1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/587819082/617717160.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/17726363/27194480.10000
 	20
 128	2
 146	2
diff --git a/ql/src/test/results/clientpositive/union17.q.out b/ql/src/test/results/clientpositive/union17.q.out
index 62ddf7b855..6c2989b3f4 100644
--- a/ql/src/test/results/clientpositive/union17.q.out
+++ b/ql/src/test/results/clientpositive/union17.q.out
@@ -2,7 +2,9 @@ query: drop table DEST1
 query: drop table DEST2
 query: CREATE TABLE DEST1(key STRING, value STRING) STORED AS TEXTFILE
 query: CREATE TABLE DEST2(key STRING, val1 STRING, val2 STRING) STORED AS TEXTFILE
-query: explain 
+query: -- union case:map-reduce sub-queries followed by multi-table insert
+
+explain 
 FROM (select 'tst1' as key, cast(count(1) as string) as value from src s1
                          UNION  ALL  
       select s2.key as key, s2.value as value from src s2) unionsrc
@@ -61,7 +63,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/130091110/149823007.10004 
+        /data/users/njain/hive5/hive5/build/ql/tmp/594528383/398601416.10004 
           Union
             Group By Operator
               aggregations:
@@ -104,7 +106,7 @@ STAGE PLANS:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                     name: binary_table
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/130091110/149823007.10006 
+        /data/users/njain/hive5/hive5/build/ql/tmp/594528383/398601416.10006 
           Union
             Group By Operator
               aggregations:
@@ -189,7 +191,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/130091110/149823007.10005 
+        /data/users/njain/hive5/hive5/build/ql/tmp/594528383/398601416.10005 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -264,7 +266,7 @@ Output: default/dest1
 Output: default/dest2
 query: SELECT DEST1.* FROM DEST1
 Input: default/dest1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/415341533/530713652.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/846588920/478082672.10000
 0	1
 10	1
 100	1
@@ -577,7 +579,7 @@ Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/415341533/
 tst1	0
 query: SELECT DEST2.* FROM DEST2
 Input: default/dest2
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1221535477/121161713.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/513377833/130813712.10000
 0	val_0	1
 10	val_10	1
 100	val_100	1
diff --git a/ql/src/test/results/clientpositive/union18.q.out b/ql/src/test/results/clientpositive/union18.q.out
index 796becc318..925abd98b4 100644
--- a/ql/src/test/results/clientpositive/union18.q.out
+++ b/ql/src/test/results/clientpositive/union18.q.out
@@ -2,7 +2,9 @@ query: drop table DEST1
 query: drop table DEST2
 query: CREATE TABLE DEST1(key STRING, value STRING) STORED AS TEXTFILE
 query: CREATE TABLE DEST2(key STRING, val1 STRING, val2 STRING) STORED AS TEXTFILE
-query: explain 
+query: -- union case:map-reduce sub-queries followed by multi-table insert 
+
+explain 
 FROM (select 'tst1' as key, cast(count(1) as string) as value from src s1
                          UNION  ALL  
       select s2.key as key, s2.value as value from src s2) unionsrc
@@ -57,7 +59,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/926628627/699992620.10004 
+        /data/users/njain/hive5/hive5/build/ql/tmp/85855690/436135691.10004 
           Union
             Select Operator
               expressions:
@@ -89,7 +91,7 @@ STAGE PLANS:
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest2
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/926628627/699992620.10005 
+        /data/users/njain/hive5/hive5/build/ql/tmp/85855690/436135691.10005 
           Union
             Select Operator
               expressions:
@@ -167,7 +169,7 @@ Output: default/dest1
 Output: default/dest2
 query: SELECT DEST1.* FROM DEST1 SORT BY DEST1.key, DEST1.value
 Input: default/dest1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/347590244/841189198.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/513833791/435534847.10000
 0	val_0
 0	val_0
 0	val_0
@@ -671,7 +673,7 @@ Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/347590244/
 tst1	500
 query: SELECT DEST2.* FROM DEST2 SORT BY DEST2.key, DEST2.val1, DEST2.val2
 Input: default/dest2
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/162660494/315114355.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/220258302/955456541.10000
 0	val_0	val_0
 0	val_0	val_0
 0	val_0	val_0
diff --git a/ql/src/test/results/clientpositive/union19.q.out b/ql/src/test/results/clientpositive/union19.q.out
index a4150382ba..63556efdeb 100644
--- a/ql/src/test/results/clientpositive/union19.q.out
+++ b/ql/src/test/results/clientpositive/union19.q.out
@@ -2,7 +2,9 @@ query: drop table DEST1
 query: drop table DEST2
 query: CREATE TABLE DEST1(key STRING, value STRING) STORED AS TEXTFILE
 query: CREATE TABLE DEST2(key STRING, val1 STRING, val2 STRING) STORED AS TEXTFILE
-query: explain 
+query: -- union case:map-reduce sub-queries followed by multi-table insert
+
+explain 
 FROM (select 'tst1' as key, cast(count(1) as string) as value from src s1
                          UNION  ALL  
       select s2.key as key, s2.value as value from src s2) unionsrc
@@ -57,7 +59,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/254461326/1118368198.10004 
+        /data/users/njain/hive5/hive5/build/ql/tmp/72371652/101013737.10004 
           Union
             Group By Operator
               aggregations:
@@ -94,7 +96,7 @@ STAGE PLANS:
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest2
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/254461326/1118368198.10005 
+        /data/users/njain/hive5/hive5/build/ql/tmp/72371652/101013737.10005 
           Union
             Group By Operator
               aggregations:
@@ -199,7 +201,7 @@ Output: default/dest1
 Output: default/dest2
 query: SELECT DEST1.* FROM DEST1 SORT BY DEST1.key, DEST1.value
 Input: default/dest1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/467532129/948299768.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/118273074/1158900774.10000
 0	3
 10	1
 100	2
@@ -512,7 +514,7 @@ Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/467532129/
 tst1	1
 query: SELECT DEST2.* FROM DEST2 SORT BY DEST2.key, DEST2.val1, DEST2.val2
 Input: default/dest2
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/168132316/261490647.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/159391428/263926633.10000
 0	val_0	val_0
 0	val_0	val_0
 0	val_0	val_0
diff --git a/ql/src/test/results/clientpositive/union2.q.out b/ql/src/test/results/clientpositive/union2.q.out
index b9c3e9c2c8..f0cffc5b20 100644
--- a/ql/src/test/results/clientpositive/union2.q.out
+++ b/ql/src/test/results/clientpositive/union2.q.out
@@ -1,4 +1,6 @@
-query: explain 
+query: -- union case: both subqueries are map-reduce jobs on same input, followed by reduce sink
+
+explain 
   select count(1) FROM (select s1.key as key, s1.value as value from src s1 UNION  ALL  
                         select s2.key as key, s2.value as value from src s2) unionsrc
 ABSTRACT SYNTAX TREE:
@@ -72,5 +74,5 @@ STAGE PLANS:
 query: select count(1) FROM (select s1.key as key, s1.value as value from src s1 UNION  ALL  
                       select s2.key as key, s2.value as value from src s2) unionsrc
 Input: default/src
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/403137725/387325757.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/3487986/87097312.10000
 1000
diff --git a/ql/src/test/results/clientpositive/union20.q.out b/ql/src/test/results/clientpositive/union20.q.out
index 60b1ad4859..e2b1432b7a 100644
--- a/ql/src/test/results/clientpositive/union20.q.out
+++ b/ql/src/test/results/clientpositive/union20.q.out
@@ -1,4 +1,6 @@
-query: explain 
+query: -- union :map-reduce sub-queries followed by join
+
+explain 
 SELECT unionsrc1.key, unionsrc1.value, unionsrc2.key, unionsrc2.value
 FROM (select 'tst1' as key, cast(count(1) as string) as value from src s1
                          UNION  ALL  
@@ -62,7 +64,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/172458251/1663645008.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/1191284995/1420085103.10002 
           Union
             Reduce Output Operator
               key expressions:
@@ -78,7 +80,7 @@ STAGE PLANS:
                     type: string
                     expr: 1
                     type: string
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/172458251/1663645008.10003 
+        /data/users/njain/hive5/hive5/build/ql/tmp/1191284995/1420085103.10003 
           Union
             Reduce Output Operator
               key expressions:
@@ -180,7 +182,7 @@ STAGE PLANS:
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/172458251/1663645008.10004 
+        /data/users/njain/hive5/hive5/build/ql/tmp/1191284995/1420085103.10004 
           Union
             File Output Operator
               compressed: false
@@ -189,7 +191,7 @@ STAGE PLANS:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                   name: binary_table
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/172458251/1663645008.10006 
+        /data/users/njain/hive5/hive5/build/ql/tmp/1191284995/1420085103.10006 
           Union
             File Output Operator
               compressed: false
@@ -248,7 +250,7 @@ JOIN
       select s4.key as key, s4.value as value from src s4 where s4.key < 10) unionsrc2
 ON (unionsrc1.key = unionsrc2.key)
 Input: default/src
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1381661483/387712250.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/25295607/330570384.10000
 0	val_0	0	val_0
 0	val_0	0	val_0
 0	val_0	0	val_0
diff --git a/ql/src/test/results/clientpositive/union4.q.out b/ql/src/test/results/clientpositive/union4.q.out
index 75c3b37829..87f94c453b 100644
--- a/ql/src/test/results/clientpositive/union4.q.out
+++ b/ql/src/test/results/clientpositive/union4.q.out
@@ -1,4 +1,6 @@
-query: drop table tmptable
+query: -- union case: both subqueries are map-reduce jobs on same input, followed by filesink
+
+drop table tmptable
 query: create table tmptable(key string, value int)
 query: explain 
 insert overwrite table tmptable
@@ -54,7 +56,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/371236334/463237113.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/895788847/820785077.10002 
           Union
             Select Operator
               expressions:
@@ -76,7 +78,7 @@ STAGE PLANS:
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/371236334/463237113.10003 
+        /data/users/njain/hive5/hive5/build/ql/tmp/895788847/820785077.10003 
           Union
             Select Operator
               expressions:
@@ -152,7 +154,7 @@ Input: default/src
 Output: default/tmptable
 query: select * from tmptable x sort by x.key
 Input: default/tmptable
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/100441451/111422539.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/343973554/1495273603.10000
 tst1	500
 tst2	500
 query: drop table tmptable
diff --git a/ql/src/test/results/clientpositive/union5.q.out b/ql/src/test/results/clientpositive/union5.q.out
index 6c1c3f60a5..8f22148879 100644
--- a/ql/src/test/results/clientpositive/union5.q.out
+++ b/ql/src/test/results/clientpositive/union5.q.out
@@ -1,4 +1,6 @@
-query: explain 
+query: -- union case: both subqueries are map-reduce jobs on same input, followed by reduce sink
+
+explain 
   select unionsrc.key, count(1) FROM (select 'tst1' as key, count(1) as value from src s1
                                     UNION  ALL  
                                       select 'tst2' as key, count(1) as value from src s2) unionsrc group by unionsrc.key
@@ -50,7 +52,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1649113926/399998151.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/446100647/396265268.10002 
           Union
             Group By Operator
               aggregations:
@@ -71,7 +73,7 @@ STAGE PLANS:
                 value expressions:
                       expr: 1
                       type: bigint
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/1649113926/399998151.10003 
+        /data/users/njain/hive5/hive5/build/ql/tmp/446100647/396265268.10003 
           Union
             Group By Operator
               aggregations:
@@ -156,6 +158,6 @@ query: select unionsrc.key, count(1) FROM (select 'tst1' as key, count(1) as val
                                   UNION  ALL  
                                     select 'tst2' as key, count(1) as value from src s2) unionsrc group by unionsrc.key
 Input: default/src
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1203907479/249233034.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/140939267/753633250.10000
 tst1	1
 tst2	1
diff --git a/ql/src/test/results/clientpositive/union6.q.out b/ql/src/test/results/clientpositive/union6.q.out
index 0094d8645f..9f19d20413 100644
--- a/ql/src/test/results/clientpositive/union6.q.out
+++ b/ql/src/test/results/clientpositive/union6.q.out
@@ -1,4 +1,6 @@
-query: drop table tmptable
+query: -- union case: 1 subquery is a map-reduce job, different inputs for sub-queries, followed by filesink
+
+drop table tmptable
 query: create table tmptable(key string, value string)
 query: explain 
 insert overwrite table tmptable
@@ -54,7 +56,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/521174997/29191949.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/1396512145/100703742.10002 
           Union
             Select Operator
               expressions:
@@ -70,7 +72,7 @@ STAGE PLANS:
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: tmptable
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/521174997/29191949.10003 
+        /data/users/njain/hive5/hive5/build/ql/tmp/1396512145/100703742.10003 
           Union
             Select Operator
               expressions:
@@ -125,7 +127,7 @@ Input: default/src1
 Output: default/tmptable
 query: select * from tmptable x sort by x.key
 Input: default/tmptable
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/1147707423/406168765.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/569550431/1373104.10000
 	val_193
 	
 	
diff --git a/ql/src/test/results/clientpositive/union7.q.out b/ql/src/test/results/clientpositive/union7.q.out
index 6547470e29..85310d8525 100644
--- a/ql/src/test/results/clientpositive/union7.q.out
+++ b/ql/src/test/results/clientpositive/union7.q.out
@@ -1,4 +1,6 @@
-query: explain 
+query: -- union case: 1 subquery is a map-reduce job, different inputs for sub-queries, followed by reducesink
+
+explain 
   select unionsrc.key, count(1) FROM (select 'tst1' as key, cast(count(1) as string) as value from src s1
                                         UNION  ALL  
                                             select s2.key as key, s2.value as value from src1 s2) unionsrc group by unionsrc.key
@@ -50,7 +52,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/255905982/946698378.10002 
+        /data/users/njain/hive5/hive5/build/ql/tmp/92765504/90887772.10002 
           Union
             Group By Operator
               aggregations:
@@ -71,7 +73,7 @@ STAGE PLANS:
                 value expressions:
                       expr: 1
                       type: bigint
-        /data/users/athusoo/commits/hive_trunk_ws8/build/ql/tmp/255905982/946698378.10003 
+        /data/users/njain/hive5/hive5/build/ql/tmp/92765504/90887772.10003 
           Union
             Group By Operator
               aggregations:
@@ -141,7 +143,7 @@ query: select unionsrc.key, count(1) FROM (select 'tst1' as key, cast(count(1) a
                                     select s2.key as key, s2.value as value from src1 s2) unionsrc group by unionsrc.key
 Input: default/src
 Input: default/src1
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/584323767/101489285.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/37845718/185211382.10000
 	10
 128	1
 146	1
diff --git a/ql/src/test/results/clientpositive/union8.q.out b/ql/src/test/results/clientpositive/union8.q.out
index 8360890111..230dd65cae 100644
--- a/ql/src/test/results/clientpositive/union8.q.out
+++ b/ql/src/test/results/clientpositive/union8.q.out
@@ -1,4 +1,6 @@
-query: explain 
+query: -- union case: all subqueries are a map-only jobs, 3 way union, same input for all sub-queries, followed by filesink
+
+explain 
   select unionsrc.key, unionsrc.value FROM (select s1.key as key, s1.value as value from src s1 UNION  ALL  
                                             select s2.key as key, s2.value as value from src s2 UNION  ALL  
                                             select s3.key as key, s3.value as value from src s3) unionsrc
@@ -83,7 +85,7 @@ query: select unionsrc.key, unionsrc.value FROM (select s1.key as key, s1.value
                                           select s2.key as key, s2.value as value from src s2 UNION  ALL  
                                           select s3.key as key, s3.value as value from src s3) unionsrc
 Input: default/src
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/158356330/11376793.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/245637407/70399042.10000
 238	val_238
 238	val_238
 238	val_238
diff --git a/ql/src/test/results/clientpositive/union9.q.out b/ql/src/test/results/clientpositive/union9.q.out
index 0901b5eba6..c30ae0d62e 100644
--- a/ql/src/test/results/clientpositive/union9.q.out
+++ b/ql/src/test/results/clientpositive/union9.q.out
@@ -1,4 +1,6 @@
-query: explain 
+query: -- union case: all subqueries are a map-only jobs, 3 way union, same input for all sub-queries, followed by reducesink
+
+explain 
   select count(1) FROM (select s1.key as key, s1.value as value from src s1 UNION  ALL  
                         select s2.key as key, s2.value as value from src s2 UNION ALL
                         select s3.key as key, s3.value as value from src s3) unionsrc
@@ -92,5 +94,5 @@ query: select count(1) FROM (select s1.key as key, s1.value as value from src s1
                         select s2.key as key, s2.value as value from src s2 UNION ALL
                         select s3.key as key, s3.value as value from src s3) unionsrc
 Input: default/src
-Output: /data/users/athusoo/commits/hive_trunk_ws8/ql/../build/ql/tmp/371390513/112754866.10000
+Output: /data/users/njain/hive5/hive5/ql/../build/ql/tmp/280070880/627311455.10000
 1500
