diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/cli/LlapServiceDriver.java b/llap-server/src/java/org/apache/hadoop/hive/llap/cli/LlapServiceDriver.java
index de6d9b8b95..006f70fa3d 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/cli/LlapServiceDriver.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/cli/LlapServiceDriver.java
@@ -236,20 +236,22 @@ private void run(String[] args) throws Exception {
           String.valueOf(options.getIoThreads()));
     }
 
+    long cache = -1, xmx = -1;
     if (options.getCache() != -1) {
-      conf.set(HiveConf.ConfVars.LLAP_IO_MEMORY_MAX_SIZE.varname,
-          Long.toString(options.getCache()));
+      cache = options.getCache();
+      conf.set(HiveConf.ConfVars.LLAP_IO_MEMORY_MAX_SIZE.varname, Long.toString(cache));
       propsDirectOptions.setProperty(HiveConf.ConfVars.LLAP_IO_MEMORY_MAX_SIZE.varname,
-          Long.toString(options.getCache()));
+          Long.toString(cache));
     }
 
     if (options.getXmx() != -1) {
       // Needs more explanation here
-      // Xmx is not the max heap value in JDK8
-      // You need to subtract 50% of the survivor fraction from this, to get actual usable memory before it goes into GC
-      long xmx = (long) (options.getXmx() / (1024 * 1024));
+      // Xmx is not the max heap value in JDK8. You need to subtract 50% of the survivor fraction
+      // from this, to get actual usable  memory before it goes into GC
+      xmx = (long) (options.getXmx() / (1024 * 1024));
       conf.setLong(ConfVars.LLAP_DAEMON_MEMORY_PER_INSTANCE_MB.varname, xmx);
-      propsDirectOptions.setProperty(ConfVars.LLAP_DAEMON_MEMORY_PER_INSTANCE_MB.varname, String.valueOf(xmx));
+      propsDirectOptions.setProperty(ConfVars.LLAP_DAEMON_MEMORY_PER_INSTANCE_MB.varname,
+          String.valueOf(xmx));
     }
 
     if (options.getLlapQueueName() != null && !options.getLlapQueueName().isEmpty()) {
@@ -258,8 +260,6 @@ private void run(String[] args) throws Exception {
           .setProperty(ConfVars.LLAP_DAEMON_QUEUE_NAME.varname, options.getLlapQueueName());
     }
 
-
-
     URL logger = conf.getResource(LlapDaemon.LOG4j2_PROPERTIES_FILE);
 
     if (null == logger) {
@@ -460,6 +460,9 @@ private void run(String[] args) throws Exception {
     configs.put(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES,
         conf.getInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES, -1));
 
+    long maxDirect = (xmx > 0 && cache > 0 && xmx < cache * 1.25) ? (long)(cache * 1.25) : -1;
+    configs.put("max_direct_memory", Long.toString(maxDirect));
+
     FSDataOutputStream os = lfs.create(new Path(tmpDir, "config.json"));
     OutputStreamWriter w = new OutputStreamWriter(os);
     configs.write(w);
diff --git a/llap-server/src/main/resources/package.py b/llap-server/src/main/resources/package.py
index 63c0ef11d1..94c9d1ae96 100644
--- a/llap-server/src/main/resources/package.py
+++ b/llap-server/src/main/resources/package.py
@@ -101,6 +101,10 @@ def main(args):
 		return
 	config = json_parse(open(join(input, "config.json")).read())
 	java_home = config["java.home"]
+	max_direct_memory = config["max_direct_memory"]
+	daemon_args = args.args
+	if max_direct_memory > 0:
+		daemon_args = " -XX:MaxDirectMemorySize=%s %s" % (max_direct_memory, daemon_args)
 	resource = LlapResource(config)
 	# 5% container failure every monkey_interval seconds
 	monkey_percentage = 5 # 5%
@@ -114,7 +118,7 @@ def main(args):
 		"hadoop_home" : os.getenv("HADOOP_HOME"),
 		"java_home" : java_home,
 		"name" : resource.clusterName,
-		"daemon_args" : args.args,
+		"daemon_args" : daemon_args,
 		"daemon_loglevel" : args.loglevel,
 		"queue.string" : resource.queueString,
 		"monkey_interval" : args.chaosmonkey,
