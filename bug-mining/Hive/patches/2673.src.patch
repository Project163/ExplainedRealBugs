diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
index 0f7af9ac46..cbbe78139e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
@@ -1565,6 +1565,7 @@ public void loadTable(Path loadPath, String tableName, boolean replace,
       tbl.replaceFiles(loadPath, isSrcLocal);
     } else {
       tbl.copyFiles(loadPath, isSrcLocal, isAcid);
+      tbl.getParameters().put(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK, "true");
     }
 
     try {
@@ -1678,17 +1679,6 @@ public Partition getPartition(Table tbl, Map<String, String> partSpec,
     return getPartition(tbl, partSpec, forceCreate, null, true);
   }
 
-  private static void clearPartitionStats(org.apache.hadoop.hive.metastore.api.Partition tpart) {
-    Map<String,String> tpartParams = tpart.getParameters();
-    if (tpartParams == null) {
-      return;
-    }
-
-    for (String statType : StatsSetupConst.supportedStats) {
-      tpartParams.remove(statType);
-    }
-  }
-
   /**
    * Returns partition metadata
    *
@@ -1756,7 +1746,7 @@ public Partition getPartition(Table tbl, Map<String, String> partSpec,
             throw new HiveException("new partition path should not be null or empty.");
           }
           tpart.getSd().setLocation(partPath);
-          clearPartitionStats(tpart);
+          tpart.getParameters().put(StatsSetupConst.STATS_GENERATED_VIA_STATS_TASK,"true");
           String fullName = tbl.getTableName();
           if (!org.apache.commons.lang.StringUtils.isEmpty(tbl.getDbName())) {
             fullName = tbl.getDbName() + "." + tbl.getTableName();
diff --git a/ql/src/test/queries/clientpositive/insert_into1.q b/ql/src/test/queries/clientpositive/insert_into1.q
index edc65a442d..f19506abf4 100644
--- a/ql/src/test/queries/clientpositive/insert_into1.q
+++ b/ql/src/test/queries/clientpositive/insert_into1.q
@@ -1,3 +1,4 @@
+set hive.compute.query.using.stats=true;
 DROP TABLE insert_into1;
 
 CREATE TABLE insert_into1 (key int, value string);
@@ -7,14 +8,18 @@ INSERT INTO TABLE insert_into1 SELECT * from src LIMIT 100;
 SELECT SUM(HASH(c)) FROM (
     SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into1
 ) t;
-
+explain 
+select count(*) from insert_into1;
+select count(*) from insert_into1;
 EXPLAIN INSERT INTO TABLE insert_into1 SELECT * FROM src LIMIT 100;
 INSERT INTO TABLE insert_into1 SELECT * FROM src LIMIT 100;
 SELECT SUM(HASH(c)) FROM (
     SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into1
 ) t;
 
+explain
 SELECT COUNT(*) FROM insert_into1;
+select count(*) from insert_into1;
 
 EXPLAIN INSERT OVERWRITE TABLE insert_into1 SELECT * FROM src LIMIT 10;
 INSERT OVERWRITE TABLE insert_into1 SELECT * FROM src LIMIT 10;
@@ -22,5 +27,10 @@ SELECT SUM(HASH(c)) FROM (
     SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into1
 ) t;
 
+explain
+SELECT COUNT(*) FROM insert_into1;
+select count(*) from insert_into1;
 
 DROP TABLE insert_into1;
+
+set hive.compute.query.using.stats=false;
diff --git a/ql/src/test/queries/clientpositive/insert_into2.q b/ql/src/test/queries/clientpositive/insert_into2.q
index 0cce9585a8..1cbe391adf 100644
--- a/ql/src/test/queries/clientpositive/insert_into2.q
+++ b/ql/src/test/queries/clientpositive/insert_into2.q
@@ -1,3 +1,4 @@
+set hive.compute.query.using.stats=true;
 DROP TABLE insert_into2;
 CREATE TABLE insert_into2 (key int, value string) 
   PARTITIONED BY (ds string);
@@ -5,7 +6,12 @@ CREATE TABLE insert_into2 (key int, value string)
 EXPLAIN INSERT INTO TABLE insert_into2 PARTITION (ds='1') 
   SELECT * FROM src LIMIT 100;
 INSERT INTO TABLE insert_into2 PARTITION (ds='1') SELECT * FROM src limit 100;
+explain
+select count (*) from insert_into2 where ds = '1';
+select count (*) from insert_into2 where ds = '1';
 INSERT INTO TABLE insert_into2 PARTITION (ds='1') SELECT * FROM src limit 100;
+explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='1';
 SELECT COUNT(*) FROM insert_into2 WHERE ds='1';
 SELECT SUM(HASH(c)) FROM (
     SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into2
@@ -19,6 +25,9 @@ INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
 SELECT SUM(HASH(c)) FROM (
     SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into2
 ) t;
+explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2';
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2';
 
 EXPLAIN INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
   SELECT * FROM src LIMIT 50;
@@ -27,5 +36,11 @@ INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
 SELECT SUM(HASH(c)) FROM (
     SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into2
 ) t;
+explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2';
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2';
+
 
 DROP TABLE insert_into2;
+
+set hive.compute.query.using.stats=false;
diff --git a/ql/src/test/results/clientpositive/alter_merge_stats_orc.q.out b/ql/src/test/results/clientpositive/alter_merge_stats_orc.q.out
index f3b3e91f4e..f8486ade7d 100644
--- a/ql/src/test/results/clientpositive/alter_merge_stats_orc.q.out
+++ b/ql/src/test/results/clientpositive/alter_merge_stats_orc.q.out
@@ -247,8 +247,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	3                   
-	numRows             	500                 
-	rawDataSize         	47000               
+	numRows             	1500                
+	rawDataSize         	141000              
 	totalSize           	7488                
 #### A masked pattern was here ####
 	 	 
diff --git a/ql/src/test/results/clientpositive/alter_partition_coltype.q.out b/ql/src/test/results/clientpositive/alter_partition_coltype.q.out
index 8fa65cb53d..f71fa05430 100644
--- a/ql/src/test/results/clientpositive/alter_partition_coltype.q.out
+++ b/ql/src/test/results/clientpositive/alter_partition_coltype.q.out
@@ -1007,10 +1007,10 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name pt.alterdynamic_part_table
               numFiles 2
-              numRows 1
+              numRows 2
               partition_columns partcol1/partcol2
               partition_columns.types int:string
-              rawDataSize 2
+              rawDataSize 3
               serialization.ddl struct alterdynamic_part_table { string intcol}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -1039,12 +1039,12 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: alterdynamic_part_table
-          Statistics: Num rows: 1 Data size: 2 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 2 Data size: 3 Basic stats: COMPLETE Column stats: NONE
           GatherStats: false
           Select Operator
             expressions: intcol (type: string)
             outputColumnNames: _col0
-            Statistics: Num rows: 1 Data size: 2 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 2 Data size: 3 Basic stats: COMPLETE Column stats: NONE
             ListSink
 
 PREHOOK: query: explain extended select intcol from pt.alterdynamic_part_table where (partcol1='2' and partcol2='1')or (partcol1='1' and partcol2='__HIVE_DEFAULT_PARTITION__')
diff --git a/ql/src/test/results/clientpositive/auto_sortmerge_join_5.q.out b/ql/src/test/results/clientpositive/auto_sortmerge_join_5.q.out
index 30a8436343..1904cc2467 100644
--- a/ql/src/test/results/clientpositive/auto_sortmerge_join_5.q.out
+++ b/ql/src/test/results/clientpositive/auto_sortmerge_join_5.q.out
@@ -157,8 +157,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.bucket_big
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -179,8 +177,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.bucket_big
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -329,8 +325,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.bucket_big
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -351,8 +345,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.bucket_big
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -532,8 +524,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.bucket_big
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -554,8 +544,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.bucket_big
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -594,8 +582,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.bucket_small
                 numFiles 4
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct bucket_small { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -709,8 +695,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.bucket_big
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -731,8 +715,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.bucket_big
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -771,8 +753,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.bucket_small
                 numFiles 4
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct bucket_small { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -863,8 +843,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.bucket_big
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -885,8 +863,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.bucket_big
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/bucketcontext_5.q.out b/ql/src/test/results/clientpositive/bucketcontext_5.q.out
index 085cce9f89..feb833d16e 100644
--- a/ql/src/test/results/clientpositive/bucketcontext_5.q.out
+++ b/ql/src/test/results/clientpositive/bucketcontext_5.q.out
@@ -200,8 +200,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.bucket_big
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -222,8 +220,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.bucket_big
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -380,8 +376,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.bucket_big
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct bucket_big { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -402,8 +396,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.bucket_big
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct bucket_big { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin1.q.out b/ql/src/test/results/clientpositive/bucketmapjoin1.q.out
index 72a9173776..9a76f9481c 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin1.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin1.q.out
@@ -601,8 +601,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -622,8 +620,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin4.q.out b/ql/src/test/results/clientpositive/bucketmapjoin4.q.out
index 1210bed7ac..2af66a28c2 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin4.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin4.q.out
@@ -292,8 +292,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -313,8 +311,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -783,8 +779,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -804,8 +798,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out b/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out
index 81814980d2..258a9623a5 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out
@@ -288,8 +288,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -309,8 +307,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out b/ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out
index c2abc1c0a9..d99f5b4047 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out
@@ -343,8 +343,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -364,8 +362,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin_negative3.q.out b/ql/src/test/results/clientpositive/bucketmapjoin_negative3.q.out
index c87b857200..40148af6a3 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin_negative3.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin_negative3.q.out
@@ -302,8 +302,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.test1
               numFiles 3
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct test1 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -324,8 +322,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.test1
                 numFiles 3
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct test1 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -501,8 +497,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.test2
               numFiles 3
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct test2 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -523,8 +517,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.test2
                 numFiles 3
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct test2 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -689,8 +681,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.test1
               numFiles 3
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct test1 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -711,8 +701,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.test1
                 numFiles 3
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct test1 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -880,8 +868,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.test1
               numFiles 3
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct test1 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -902,8 +888,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.test1
                 numFiles 3
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct test1 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -1071,8 +1055,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.test1
               numFiles 3
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct test1 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -1093,8 +1075,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.test1
                 numFiles 3
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct test1 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -1262,8 +1242,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.test1
               numFiles 3
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct test1 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -1284,8 +1262,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.test1
                 numFiles 3
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct test1 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -1453,8 +1429,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.test2
               numFiles 3
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct test2 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -1475,8 +1449,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.test2
                 numFiles 3
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct test2 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -1644,8 +1616,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.test2
               numFiles 3
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct test2 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -1666,8 +1636,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.test2
                 numFiles 3
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct test2 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -1835,8 +1803,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.test3
               numFiles 3
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct test3 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -1857,8 +1823,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.test3
                 numFiles 3
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct test3 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/columnstats_tbllvl.q.out b/ql/src/test/results/clientpositive/columnstats_tbllvl.q.out
index d6fd01f1d9..b7987f4e56 100644
--- a/ql/src/test/results/clientpositive/columnstats_tbllvl.q.out
+++ b/ql/src/test/results/clientpositive/columnstats_tbllvl.q.out
@@ -146,8 +146,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.uservisits_web_text_none
               numFiles 1
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct uservisits_web_text_none { string sourceip, string desturl, string visitdate, float adrevenue, string useragent, string ccode, string lcode, string skeyword, i32 avgtimeonsite}
               serialization.format |
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -167,8 +165,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.uservisits_web_text_none
                 numFiles 1
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct uservisits_web_text_none { string sourceip, string desturl, string visitdate, float adrevenue, string useragent, string ccode, string lcode, string skeyword, i32 avgtimeonsite}
                 serialization.format |
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/display_colstats_tbllvl.q.out b/ql/src/test/results/clientpositive/display_colstats_tbllvl.q.out
index 7745be7524..2b26245d1d 100644
--- a/ql/src/test/results/clientpositive/display_colstats_tbllvl.q.out
+++ b/ql/src/test/results/clientpositive/display_colstats_tbllvl.q.out
@@ -162,8 +162,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.uservisits_web_text_none
               numFiles 1
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct uservisits_web_text_none { string sourceip, string desturl, string visitdate, float adrevenue, string useragent, string ccode, string lcode, string skeyword, i32 avgtimeonsite}
               serialization.format |
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -183,8 +181,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.uservisits_web_text_none
                 numFiles 1
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct uservisits_web_text_none { string sourceip, string desturl, string visitdate, float adrevenue, string useragent, string ccode, string lcode, string skeyword, i32 avgtimeonsite}
                 serialization.format |
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/dynpart_sort_opt_vectorization.q.out b/ql/src/test/results/clientpositive/dynpart_sort_opt_vectorization.q.out
index df8ad447f5..4dcbb0fc46 100644
--- a/ql/src/test/results/clientpositive/dynpart_sort_opt_vectorization.q.out
+++ b/ql/src/test/results/clientpositive/dynpart_sort_opt_vectorization.q.out
@@ -878,8 +878,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	16                  
-	rawDataSize         	320                 
+	numRows             	32                  
+	rawDataSize         	640                 
 	totalSize           	1348                
 #### A masked pattern was here ####
 	 	 
@@ -922,8 +922,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	3                   
-	rawDataSize         	60                  
+	numRows             	6                   
+	rawDataSize         	120                 
 	totalSize           	1050                
 #### A masked pattern was here ####
 	 	 
@@ -966,8 +966,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	7                   
-	rawDataSize         	140                 
+	numRows             	14                  
+	rawDataSize         	280                 
 	totalSize           	1166                
 #### A masked pattern was here ####
 	 	 
@@ -1010,8 +1010,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	3                   
-	rawDataSize         	60                  
+	numRows             	6                   
+	rawDataSize         	120                 
 	totalSize           	1050                
 #### A masked pattern was here ####
 	 	 
@@ -1053,8 +1053,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	16                  
-	rawDataSize         	320                 
+	numRows             	32                  
+	rawDataSize         	640                 
 	totalSize           	4340                
 #### A masked pattern was here ####
 	 	 
@@ -1096,8 +1096,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	3                   
-	rawDataSize         	60                  
+	numRows             	6                   
+	rawDataSize         	120                 
 	totalSize           	2094                
 #### A masked pattern was here ####
 	 	 
@@ -1139,8 +1139,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	16                  
-	rawDataSize         	320                 
+	numRows             	32                  
+	rawDataSize         	640                 
 	totalSize           	4326                
 #### A masked pattern was here ####
 	 	 
@@ -1182,8 +1182,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	3                   
-	rawDataSize         	60                  
+	numRows             	6                   
+	rawDataSize         	120                 
 	totalSize           	2094                
 #### A masked pattern was here ####
 	 	 
diff --git a/ql/src/test/results/clientpositive/dynpart_sort_optimization.q.out b/ql/src/test/results/clientpositive/dynpart_sort_optimization.q.out
index 87948840a4..f4b10130c0 100644
--- a/ql/src/test/results/clientpositive/dynpart_sort_optimization.q.out
+++ b/ql/src/test/results/clientpositive/dynpart_sort_optimization.q.out
@@ -783,8 +783,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	16                  
-	rawDataSize         	415                 
+	numRows             	32                  
+	rawDataSize         	830                 
 	totalSize           	862                 
 #### A masked pattern was here ####
 	 	 
@@ -827,8 +827,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	3                   
-	rawDataSize         	78                  
+	numRows             	6                   
+	rawDataSize         	156                 
 	totalSize           	162                 
 #### A masked pattern was here ####
 	 	 
@@ -871,8 +871,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	7                   
-	rawDataSize         	181                 
+	numRows             	14                  
+	rawDataSize         	362                 
 	totalSize           	376                 
 #### A masked pattern was here ####
 	 	 
@@ -915,8 +915,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	3                   
-	rawDataSize         	78                  
+	numRows             	6                   
+	rawDataSize         	156                 
 	totalSize           	162                 
 #### A masked pattern was here ####
 	 	 
@@ -958,8 +958,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	16                  
-	rawDataSize         	415                 
+	numRows             	32                  
+	rawDataSize         	830                 
 	totalSize           	862                 
 #### A masked pattern was here ####
 	 	 
@@ -1001,8 +1001,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	3                   
-	rawDataSize         	78                  
+	numRows             	6                   
+	rawDataSize         	156                 
 	totalSize           	162                 
 #### A masked pattern was here ####
 	 	 
@@ -1044,8 +1044,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	16                  
-	rawDataSize         	415                 
+	numRows             	32                  
+	rawDataSize         	830                 
 	totalSize           	862                 
 #### A masked pattern was here ####
 	 	 
@@ -1087,8 +1087,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	3                   
-	rawDataSize         	78                  
+	numRows             	6                   
+	rawDataSize         	156                 
 	totalSize           	162                 
 #### A masked pattern was here ####
 	 	 
diff --git a/ql/src/test/results/clientpositive/insert_into1.q.out b/ql/src/test/results/clientpositive/insert_into1.q.out
index 9b2517ce26..9e5f3bb92e 100644
--- a/ql/src/test/results/clientpositive/insert_into1.q.out
+++ b/ql/src/test/results/clientpositive/insert_into1.q.out
@@ -94,6 +94,31 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@insert_into1
 #### A masked pattern was here ####
 10226524244
+PREHOOK: query: explain 
+select count(*) from insert_into1
+PREHOOK: type: QUERY
+POSTHOOK: query: explain 
+select count(*) from insert_into1
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: select count(*) from insert_into1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: query: select count(*) from insert_into1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+100
 PREHOOK: query: EXPLAIN INSERT INTO TABLE insert_into1 SELECT * FROM src LIMIT 100
 PREHOOK: type: QUERY
 POSTHOOK: query: EXPLAIN INSERT INTO TABLE insert_into1 SELECT * FROM src LIMIT 100
@@ -178,11 +203,27 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@insert_into1
 #### A masked pattern was here ####
 20453048488
-PREHOOK: query: SELECT COUNT(*) FROM insert_into1
+PREHOOK: query: explain
+SELECT COUNT(*) FROM insert_into1
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT COUNT(*) FROM insert_into1
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: select count(*) from insert_into1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@insert_into1
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT COUNT(*) FROM insert_into1
+POSTHOOK: query: select count(*) from insert_into1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@insert_into1
 #### A masked pattern was here ####
@@ -271,6 +312,31 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@insert_into1
 #### A masked pattern was here ####
 -826625916
+PREHOOK: query: explain
+SELECT COUNT(*) FROM insert_into1
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT COUNT(*) FROM insert_into1
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: select count(*) from insert_into1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: query: select count(*) from insert_into1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+10
 PREHOOK: query: DROP TABLE insert_into1
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@insert_into1
diff --git a/ql/src/test/results/clientpositive/insert_into2.q.out b/ql/src/test/results/clientpositive/insert_into2.q.out
index 4fee0c64df..acbedb5af1 100644
--- a/ql/src/test/results/clientpositive/insert_into2.q.out
+++ b/ql/src/test/results/clientpositive/insert_into2.q.out
@@ -87,6 +87,31 @@ POSTHOOK: Input: default@src
 POSTHOOK: Output: default@insert_into2@ds=1
 POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain
+select count (*) from insert_into2 where ds = '1'
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+select count (*) from insert_into2 where ds = '1'
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: select count (*) from insert_into2 where ds = '1'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+POSTHOOK: query: select count (*) from insert_into2 where ds = '1'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+100
 PREHOOK: query: INSERT INTO TABLE insert_into2 PARTITION (ds='1') SELECT * FROM src limit 100
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -97,15 +122,29 @@ POSTHOOK: Input: default@src
 POSTHOOK: Output: default@insert_into2@ds=1
 POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='1'
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='1'
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
 PREHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='1'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@insert_into2
-PREHOOK: Input: default@insert_into2@ds=1
 #### A masked pattern was here ####
 POSTHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='1'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@insert_into2
-POSTHOOK: Input: default@insert_into2@ds=1
 #### A masked pattern was here ####
 200
 PREHOOK: query: SELECT SUM(HASH(c)) FROM (
@@ -217,6 +256,31 @@ POSTHOOK: Input: default@insert_into2@ds=1
 POSTHOOK: Input: default@insert_into2@ds=2
 #### A masked pattern was here ####
 -36239931656
+PREHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+100
 PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
   SELECT * FROM src LIMIT 50
 PREHOOK: type: QUERY
@@ -311,6 +375,31 @@ POSTHOOK: Input: default@insert_into2@ds=1
 POSTHOOK: Input: default@insert_into2@ds=2
 #### A masked pattern was here ####
 -27100860056
+PREHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+50
 PREHOOK: query: DROP TABLE insert_into2
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@insert_into2
diff --git a/ql/src/test/results/clientpositive/insert_into4.q.out b/ql/src/test/results/clientpositive/insert_into4.q.out
index cecf6b4e65..192e60e2eb 100644
--- a/ql/src/test/results/clientpositive/insert_into4.q.out
+++ b/ql/src/test/results/clientpositive/insert_into4.q.out
@@ -214,14 +214,14 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: insert_into4a
-            Statistics: Num rows: 10 Data size: 104 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 20 Data size: 208 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: key (type: int), value (type: string)
               outputColumnNames: _col0, _col1
-              Statistics: Num rows: 10 Data size: 104 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 20 Data size: 208 Basic stats: COMPLETE Column stats: NONE
               File Output Operator
                 compressed: false
-                Statistics: Num rows: 10 Data size: 104 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 20 Data size: 208 Basic stats: COMPLETE Column stats: NONE
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/insert_into5.q.out b/ql/src/test/results/clientpositive/insert_into5.q.out
index 4e93291f04..490f737d9b 100644
--- a/ql/src/test/results/clientpositive/insert_into5.q.out
+++ b/ql/src/test/results/clientpositive/insert_into5.q.out
@@ -233,14 +233,14 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: insert_into5a
-            Statistics: Num rows: 10 Data size: 50 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 20 Data size: 100 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: key (type: int), value (type: string)
               outputColumnNames: _col0, _col1
-              Statistics: Num rows: 10 Data size: 50 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 20 Data size: 100 Basic stats: COMPLETE Column stats: NONE
               File Output Operator
                 compressed: false
-                Statistics: Num rows: 10 Data size: 50 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 20 Data size: 100 Basic stats: COMPLETE Column stats: NONE
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/mapjoin_test_outer.q.out b/ql/src/test/results/clientpositive/mapjoin_test_outer.q.out
index e77ad1e565..536c92bf2c 100644
--- a/ql/src/test/results/clientpositive/mapjoin_test_outer.q.out
+++ b/ql/src/test/results/clientpositive/mapjoin_test_outer.q.out
@@ -275,7 +275,7 @@ STAGE PLANS:
         src2 
           TableScan
             alias: src2
-            Statistics: Num rows: 1 Data size: 13 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 9 Data size: 40 Basic stats: COMPLETE Column stats: NONE
             HashTable Sink Operator
               condition expressions:
                 0 {value}
@@ -1108,7 +1108,7 @@ STAGE PLANS:
         src2 
           TableScan
             alias: src2
-            Statistics: Num rows: 1 Data size: 13 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 9 Data size: 40 Basic stats: COMPLETE Column stats: NONE
             HashTable Sink Operator
               condition expressions:
                 0 {value}
diff --git a/ql/src/test/results/clientpositive/stats11.q.out b/ql/src/test/results/clientpositive/stats11.q.out
index 11762bdfb8..c7f1abedc7 100644
--- a/ql/src/test/results/clientpositive/stats11.q.out
+++ b/ql/src/test/results/clientpositive/stats11.q.out
@@ -535,8 +535,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.srcbucket_mapjoin
               numFiles 2
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -556,8 +554,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.srcbucket_mapjoin
                 numFiles 2
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/temp_table_display_colstats_tbllvl.q.out b/ql/src/test/results/clientpositive/temp_table_display_colstats_tbllvl.q.out
index b021b7000f..404a9c299f 100644
--- a/ql/src/test/results/clientpositive/temp_table_display_colstats_tbllvl.q.out
+++ b/ql/src/test/results/clientpositive/temp_table_display_colstats_tbllvl.q.out
@@ -171,8 +171,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
               name default.uservisits_web_text_none
               numFiles 1
-              numRows 0
-              rawDataSize 0
               serialization.ddl struct uservisits_web_text_none { string sourceip, string desturl, string visitdate, float adrevenue, string useragent, string ccode, string lcode, string skeyword, i32 avgtimeonsite}
               serialization.format |
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -192,8 +190,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                 name default.uservisits_web_text_none
                 numFiles 1
-                numRows 0
-                rawDataSize 0
                 serialization.ddl struct uservisits_web_text_none { string sourceip, string desturl, string visitdate, float adrevenue, string useragent, string ccode, string lcode, string skeyword, i32 avgtimeonsite}
                 serialization.format |
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/tez/alter_merge_stats_orc.q.out b/ql/src/test/results/clientpositive/tez/alter_merge_stats_orc.q.out
index f3b3e91f4e..f8486ade7d 100644
--- a/ql/src/test/results/clientpositive/tez/alter_merge_stats_orc.q.out
+++ b/ql/src/test/results/clientpositive/tez/alter_merge_stats_orc.q.out
@@ -247,8 +247,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	3                   
-	numRows             	500                 
-	rawDataSize         	47000               
+	numRows             	1500                
+	rawDataSize         	141000              
 	totalSize           	7488                
 #### A masked pattern was here ####
 	 	 
diff --git a/ql/src/test/results/clientpositive/tez/auto_sortmerge_join_5.q.out b/ql/src/test/results/clientpositive/tez/auto_sortmerge_join_5.q.out
index e5e2793f64..d238592665 100644
--- a/ql/src/test/results/clientpositive/tez/auto_sortmerge_join_5.q.out
+++ b/ql/src/test/results/clientpositive/tez/auto_sortmerge_join_5.q.out
@@ -170,8 +170,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                     name default.bucket_big
                     numFiles 2
-                    numRows 0
-                    rawDataSize 0
                     serialization.ddl struct bucket_big { string key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -192,8 +190,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                       name default.bucket_big
                       numFiles 2
-                      numRows 0
-                      rawDataSize 0
                       serialization.ddl struct bucket_big { string key, string value}
                       serialization.format 1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -240,8 +236,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                     name default.bucket_small
                     numFiles 4
-                    numRows 0
-                    rawDataSize 0
                     serialization.ddl struct bucket_small { string key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -262,8 +256,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                       name default.bucket_small
                       numFiles 4
-                      numRows 0
-                      rawDataSize 0
                       serialization.ddl struct bucket_small { string key, string value}
                       serialization.format 1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -409,8 +401,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                     name default.bucket_small
                     numFiles 4
-                    numRows 0
-                    rawDataSize 0
                     serialization.ddl struct bucket_small { string key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -431,8 +421,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                       name default.bucket_small
                       numFiles 4
-                      numRows 0
-                      rawDataSize 0
                       serialization.ddl struct bucket_small { string key, string value}
                       serialization.format 1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -499,8 +487,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                     name default.bucket_big
                     numFiles 2
-                    numRows 0
-                    rawDataSize 0
                     serialization.ddl struct bucket_big { string key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -521,8 +507,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                       name default.bucket_big
                       numFiles 2
-                      numRows 0
-                      rawDataSize 0
                       serialization.ddl struct bucket_big { string key, string value}
                       serialization.format 1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -668,8 +652,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                     name default.bucket_small
                     numFiles 4
-                    numRows 0
-                    rawDataSize 0
                     serialization.ddl struct bucket_small { string key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -690,8 +672,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                       name default.bucket_small
                       numFiles 4
-                      numRows 0
-                      rawDataSize 0
                       serialization.ddl struct bucket_small { string key, string value}
                       serialization.format 1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -758,8 +738,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                     name default.bucket_big
                     numFiles 2
-                    numRows 0
-                    rawDataSize 0
                     serialization.ddl struct bucket_big { string key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
@@ -780,8 +758,6 @@ STAGE PLANS:
 #### A masked pattern was here ####
                       name default.bucket_big
                       numFiles 2
-                      numRows 0
-                      rawDataSize 0
                       serialization.ddl struct bucket_big { string key, string value}
                       serialization.format 1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
diff --git a/ql/src/test/results/clientpositive/tez/dynpart_sort_opt_vectorization.q.out b/ql/src/test/results/clientpositive/tez/dynpart_sort_opt_vectorization.q.out
index d5202172bb..71e3eb5094 100644
--- a/ql/src/test/results/clientpositive/tez/dynpart_sort_opt_vectorization.q.out
+++ b/ql/src/test/results/clientpositive/tez/dynpart_sort_opt_vectorization.q.out
@@ -930,8 +930,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	16                  
-	rawDataSize         	320                 
+	numRows             	32                  
+	rawDataSize         	640                 
 	totalSize           	1348                
 #### A masked pattern was here ####
 	 	 
@@ -974,8 +974,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	3                   
-	rawDataSize         	60                  
+	numRows             	6                   
+	rawDataSize         	120                 
 	totalSize           	1050                
 #### A masked pattern was here ####
 	 	 
@@ -1018,8 +1018,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	7                   
-	rawDataSize         	140                 
+	numRows             	14                  
+	rawDataSize         	280                 
 	totalSize           	1166                
 #### A masked pattern was here ####
 	 	 
@@ -1062,8 +1062,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	3                   
-	rawDataSize         	60                  
+	numRows             	6                   
+	rawDataSize         	120                 
 	totalSize           	1050                
 #### A masked pattern was here ####
 	 	 
@@ -1105,8 +1105,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	16                  
-	rawDataSize         	320                 
+	numRows             	32                  
+	rawDataSize         	640                 
 	totalSize           	4340                
 #### A masked pattern was here ####
 	 	 
@@ -1148,8 +1148,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	3                   
-	rawDataSize         	60                  
+	numRows             	6                   
+	rawDataSize         	120                 
 	totalSize           	2094                
 #### A masked pattern was here ####
 	 	 
@@ -1191,8 +1191,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	16                  
-	rawDataSize         	320                 
+	numRows             	32                  
+	rawDataSize         	640                 
 	totalSize           	4326                
 #### A masked pattern was here ####
 	 	 
@@ -1234,8 +1234,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	3                   
-	rawDataSize         	60                  
+	numRows             	6                   
+	rawDataSize         	120                 
 	totalSize           	2094                
 #### A masked pattern was here ####
 	 	 
diff --git a/ql/src/test/results/clientpositive/tez/dynpart_sort_optimization.q.out b/ql/src/test/results/clientpositive/tez/dynpart_sort_optimization.q.out
index 8c930950ab..a69b814af4 100644
--- a/ql/src/test/results/clientpositive/tez/dynpart_sort_optimization.q.out
+++ b/ql/src/test/results/clientpositive/tez/dynpart_sort_optimization.q.out
@@ -843,8 +843,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	16                  
-	rawDataSize         	415                 
+	numRows             	32                  
+	rawDataSize         	830                 
 	totalSize           	862                 
 #### A masked pattern was here ####
 	 	 
@@ -887,8 +887,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	3                   
-	rawDataSize         	78                  
+	numRows             	6                   
+	rawDataSize         	156                 
 	totalSize           	162                 
 #### A masked pattern was here ####
 	 	 
@@ -931,8 +931,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	7                   
-	rawDataSize         	181                 
+	numRows             	14                  
+	rawDataSize         	362                 
 	totalSize           	376                 
 #### A masked pattern was here ####
 	 	 
@@ -975,8 +975,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	2                   
-	numRows             	3                   
-	rawDataSize         	78                  
+	numRows             	6                   
+	rawDataSize         	156                 
 	totalSize           	162                 
 #### A masked pattern was here ####
 	 	 
@@ -1018,8 +1018,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	16                  
-	rawDataSize         	415                 
+	numRows             	32                  
+	rawDataSize         	830                 
 	totalSize           	862                 
 #### A masked pattern was here ####
 	 	 
@@ -1061,8 +1061,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	3                   
-	rawDataSize         	78                  
+	numRows             	6                   
+	rawDataSize         	156                 
 	totalSize           	162                 
 #### A masked pattern was here ####
 	 	 
@@ -1104,8 +1104,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	16                  
-	rawDataSize         	415                 
+	numRows             	32                  
+	rawDataSize         	830                 
 	totalSize           	862                 
 #### A masked pattern was here ####
 	 	 
@@ -1147,8 +1147,8 @@ Protect Mode:       	None
 Partition Parameters:	 	 
 	COLUMN_STATS_ACCURATE	true                
 	numFiles            	8                   
-	numRows             	3                   
-	rawDataSize         	78                  
+	numRows             	6                   
+	rawDataSize         	156                 
 	totalSize           	162                 
 #### A masked pattern was here ####
 	 	 
diff --git a/ql/src/test/results/clientpositive/tez/insert_into1.q.out b/ql/src/test/results/clientpositive/tez/insert_into1.q.out
index 945d986e5d..359470b7da 100644
--- a/ql/src/test/results/clientpositive/tez/insert_into1.q.out
+++ b/ql/src/test/results/clientpositive/tez/insert_into1.q.out
@@ -104,6 +104,31 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@insert_into1
 #### A masked pattern was here ####
 10226524244
+PREHOOK: query: explain 
+select count(*) from insert_into1
+PREHOOK: type: QUERY
+POSTHOOK: query: explain 
+select count(*) from insert_into1
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: select count(*) from insert_into1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: query: select count(*) from insert_into1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+100
 PREHOOK: query: EXPLAIN INSERT INTO TABLE insert_into1 SELECT * FROM src LIMIT 100
 PREHOOK: type: QUERY
 POSTHOOK: query: EXPLAIN INSERT INTO TABLE insert_into1 SELECT * FROM src LIMIT 100
@@ -198,11 +223,27 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@insert_into1
 #### A masked pattern was here ####
 20453048488
-PREHOOK: query: SELECT COUNT(*) FROM insert_into1
+PREHOOK: query: explain
+SELECT COUNT(*) FROM insert_into1
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT COUNT(*) FROM insert_into1
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: select count(*) from insert_into1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@insert_into1
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT COUNT(*) FROM insert_into1
+POSTHOOK: query: select count(*) from insert_into1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@insert_into1
 #### A masked pattern was here ####
@@ -301,6 +342,31 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@insert_into1
 #### A masked pattern was here ####
 -826625916
+PREHOOK: query: explain
+SELECT COUNT(*) FROM insert_into1
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT COUNT(*) FROM insert_into1
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: select count(*) from insert_into1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: query: select count(*) from insert_into1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+10
 PREHOOK: query: DROP TABLE insert_into1
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@insert_into1
diff --git a/ql/src/test/results/clientpositive/tez/insert_into2.q.out b/ql/src/test/results/clientpositive/tez/insert_into2.q.out
index a24ca973b0..6bfa25728d 100644
--- a/ql/src/test/results/clientpositive/tez/insert_into2.q.out
+++ b/ql/src/test/results/clientpositive/tez/insert_into2.q.out
@@ -97,6 +97,31 @@ POSTHOOK: Input: default@src
 POSTHOOK: Output: default@insert_into2@ds=1
 POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain
+select count (*) from insert_into2 where ds = '1'
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+select count (*) from insert_into2 where ds = '1'
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: select count (*) from insert_into2 where ds = '1'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+POSTHOOK: query: select count (*) from insert_into2 where ds = '1'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+100
 PREHOOK: query: INSERT INTO TABLE insert_into2 PARTITION (ds='1') SELECT * FROM src limit 100
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -107,15 +132,29 @@ POSTHOOK: Input: default@src
 POSTHOOK: Output: default@insert_into2@ds=1
 POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='1'
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='1'
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
 PREHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='1'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@insert_into2
-PREHOOK: Input: default@insert_into2@ds=1
 #### A masked pattern was here ####
 POSTHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='1'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@insert_into2
-POSTHOOK: Input: default@insert_into2@ds=1
 #### A masked pattern was here ####
 200
 PREHOOK: query: SELECT SUM(HASH(c)) FROM (
@@ -237,6 +276,31 @@ POSTHOOK: Input: default@insert_into2@ds=1
 POSTHOOK: Input: default@insert_into2@ds=2
 #### A masked pattern was here ####
 -36239931656
+PREHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+100
 PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
   SELECT * FROM src LIMIT 50
 PREHOOK: type: QUERY
@@ -341,6 +405,31 @@ POSTHOOK: Input: default@insert_into2@ds=1
 POSTHOOK: Input: default@insert_into2@ds=2
 #### A masked pattern was here ####
 -27100860056
+PREHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='2'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into2
+#### A masked pattern was here ####
+50
 PREHOOK: query: DROP TABLE insert_into2
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@insert_into2
diff --git a/ql/src/test/results/clientpositive/tez/vectorized_timestamp_funcs.q.out b/ql/src/test/results/clientpositive/tez/vectorized_timestamp_funcs.q.out
index 6d729bc55d..b5b74fb0c5 100644
--- a/ql/src/test/results/clientpositive/tez/vectorized_timestamp_funcs.q.out
+++ b/ql/src/test/results/clientpositive/tez/vectorized_timestamp_funcs.q.out
@@ -545,15 +545,15 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: alltypesorc_wrong
-                  Statistics: Num rows: 1 Data size: 103 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 3 Data size: 294 Basic stats: COMPLETE Column stats: NONE
                   Select Operator
                     expressions: to_unix_timestamp(stimestamp1) (type: bigint), year(stimestamp1) (type: int), month(stimestamp1) (type: int), day(stimestamp1) (type: int), dayofmonth(stimestamp1) (type: int), weekofyear(stimestamp1) (type: int), hour(stimestamp1) (type: int), minute(stimestamp1) (type: int), second(stimestamp1) (type: int)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                    Statistics: Num rows: 1 Data size: 103 Basic stats: COMPLETE Column stats: NONE
+                    Statistics: Num rows: 3 Data size: 294 Basic stats: COMPLETE Column stats: NONE
                     Reduce Output Operator
                       key expressions: _col0 (type: bigint)
                       sort order: +
-                      Statistics: Num rows: 1 Data size: 103 Basic stats: COMPLETE Column stats: NONE
+                      Statistics: Num rows: 3 Data size: 294 Basic stats: COMPLETE Column stats: NONE
                       value expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: int), _col8 (type: int)
             Execution mode: vectorized
         Reducer 2 
@@ -561,10 +561,10 @@ STAGE PLANS:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: bigint), VALUE._col0 (type: int), VALUE._col1 (type: int), VALUE._col2 (type: int), VALUE._col3 (type: int), VALUE._col4 (type: int), VALUE._col5 (type: int), VALUE._col6 (type: int), VALUE._col7 (type: int)
                 outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-                Statistics: Num rows: 1 Data size: 103 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 3 Data size: 294 Basic stats: COMPLETE Column stats: NONE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 1 Data size: 103 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 3 Data size: 294 Basic stats: COMPLETE Column stats: NONE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/vectorized_timestamp_funcs.q.out b/ql/src/test/results/clientpositive/vectorized_timestamp_funcs.q.out
index a233b87c9e..efde414c79 100644
--- a/ql/src/test/results/clientpositive/vectorized_timestamp_funcs.q.out
+++ b/ql/src/test/results/clientpositive/vectorized_timestamp_funcs.q.out
@@ -519,25 +519,25 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: alltypesorc_wrong
-            Statistics: Num rows: 1 Data size: 103 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 3 Data size: 294 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: to_unix_timestamp(stimestamp1) (type: bigint), year(stimestamp1) (type: int), month(stimestamp1) (type: int), day(stimestamp1) (type: int), dayofmonth(stimestamp1) (type: int), weekofyear(stimestamp1) (type: int), hour(stimestamp1) (type: int), minute(stimestamp1) (type: int), second(stimestamp1) (type: int)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-              Statistics: Num rows: 1 Data size: 103 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 3 Data size: 294 Basic stats: COMPLETE Column stats: NONE
               Reduce Output Operator
                 key expressions: _col0 (type: bigint)
                 sort order: +
-                Statistics: Num rows: 1 Data size: 103 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 3 Data size: 294 Basic stats: COMPLETE Column stats: NONE
                 value expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: int), _col8 (type: int)
       Execution mode: vectorized
       Reduce Operator Tree:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: bigint), VALUE._col0 (type: int), VALUE._col1 (type: int), VALUE._col2 (type: int), VALUE._col3 (type: int), VALUE._col4 (type: int), VALUE._col5 (type: int), VALUE._col6 (type: int), VALUE._col7 (type: int)
           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
-          Statistics: Num rows: 1 Data size: 103 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 3 Data size: 294 Basic stats: COMPLETE Column stats: NONE
           File Output Operator
             compressed: false
-            Statistics: Num rows: 1 Data size: 103 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 3 Data size: 294 Basic stats: COMPLETE Column stats: NONE
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
