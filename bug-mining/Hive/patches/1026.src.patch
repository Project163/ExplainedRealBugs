diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java
index 6918aa6661..e0911fd0a1 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java
@@ -42,13 +42,14 @@
 import org.apache.hadoop.hive.ql.Context;
 import org.apache.hadoop.hive.ql.DriverContext;
 import org.apache.hadoop.hive.ql.hooks.ReadEntity;
+import org.apache.hadoop.hive.ql.metadata.Table;
 import org.apache.hadoop.hive.ql.plan.Explain;
 import org.apache.hadoop.hive.ql.plan.ExplainWork;
 import org.apache.hadoop.hive.ql.plan.OperatorDesc;
 import org.apache.hadoop.hive.ql.plan.api.StageType;
-import org.apache.hadoop.hive.ql.metadata.Table;
 import org.apache.hadoop.io.IOUtils;
 import org.apache.hadoop.util.StringUtils;
+import org.json.JSONArray;
 import org.json.JSONException;
 import org.json.JSONObject;
 
@@ -251,12 +252,13 @@ else if (ent.getValue() instanceof Serializable) {
     return jsonOutput ? json : null;
   }
 
-  private static String outputList(List<?> l, String header, PrintStream out,
+  private static JSONArray outputList(List<?> l, String header, PrintStream out,
       boolean extended, boolean jsonOutput, int indent) throws Exception {
 
     boolean first_el = true;
     boolean nl = false;
-    StringBuffer s = new StringBuffer();
+    JSONArray outputArray = new JSONArray();
+
     for (Object o : l) {
       if (first_el && (out != null)) {
         out.print(header);
@@ -270,8 +272,7 @@ private static String outputList(List<?> l, String header, PrintStream out,
         }
 
         if (jsonOutput) {
-          s.append(delim);
-          s.append(o);
+          outputArray.put(o);
         }
         nl = true;
       }
@@ -282,10 +283,7 @@ else if (o instanceof Serializable) {
         JSONObject jsonOut = outputPlan((Serializable) o, out, extended,
             jsonOutput, jsonOutput ? 0 : indent + 2);
         if (jsonOutput) {
-          if (!first_el) {
-            s.append(", ");
-          }
-          s.append(jsonOut);
+          outputArray.put(jsonOut);
         }
       }
 
@@ -295,7 +293,8 @@ else if (o instanceof Serializable) {
     if (nl && (out != null)) {
       out.println();
     }
-    return jsonOutput ? s.toString() : null;
+
+    return jsonOutput ? outputArray : null;
   }
 
   private static boolean isPrintable(Object val) {
@@ -400,6 +399,7 @@ private static JSONObject outputPlan(Serializable work, PrintStream out,
             header = indentString(prop_indents);
           }
 
+          // Try the output as a primitive object
           if (isPrintable(val)) {
             if (out != null) {
               out.printf("%s ", header);
@@ -428,11 +428,13 @@ private static JSONObject outputPlan(Serializable work, PrintStream out,
           // Try this as a list
           try {
             List<?> l = (List<?>) val;
-            String jsonOut = outputList(l, header, out, extended, jsonOutput,
+            JSONArray jsonOut = outputList(l, header, out, extended, jsonOutput,
                 jsonOutput ? 0 : prop_indents + 2);
+
             if (jsonOutput) {
               json.put(header, jsonOut);
             }
+
             continue;
           }
           catch (ClassCastException ce) {
@@ -468,7 +470,6 @@ private static JSONObject outputPlan(Serializable work, PrintStream out,
 
       return json;
     }
-
     return null;
   }
 
diff --git a/ql/src/test/queries/clientpositive/plan_json.q b/ql/src/test/queries/clientpositive/plan_json.q
new file mode 100644
index 0000000000..0243c99541
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/plan_json.q
@@ -0,0 +1,3 @@
+-- explain plan json:  the query gets the formatted json output of the query plan of the hive query
+
+EXPLAIN FORMATTED SELECT count(1) FROM src;
diff --git a/ql/src/test/results/clientnegative/alter_view_failure5.q.out b/ql/src/test/results/clientnegative/alter_view_failure5.q.out
index 0f1185d6f2..b23ba8abb8 100644
--- a/ql/src/test/results/clientnegative/alter_view_failure5.q.out
+++ b/ql/src/test/results/clientnegative/alter_view_failure5.q.out
@@ -15,4 +15,4 @@ SELECT * FROM src
 POSTHOOK: type: CREATEVIEW
 POSTHOOK: Output: default@xxx6
 #### A masked pattern was here ####
-FAILED: SemanticException value not found in table's partition spec: {v=val_86}
+FAILED: SemanticException [Error 10214]: Invalid partition spec specified value not found in table's partition spec: {v=val_86}
diff --git a/ql/src/test/results/clientnegative/alter_view_failure7.q.out b/ql/src/test/results/clientnegative/alter_view_failure7.q.out
index 1a5c9cd204..768c5b1c12 100644
--- a/ql/src/test/results/clientnegative/alter_view_failure7.q.out
+++ b/ql/src/test/results/clientnegative/alter_view_failure7.q.out
@@ -15,4 +15,4 @@ SELECT key,ds,hr FROM srcpart
 POSTHOOK: type: CREATEVIEW
 POSTHOOK: Output: default@xxx8
 #### A masked pattern was here ####
-FAILED: SemanticException table is partitioned but partition spec is not specified or does not fully match table partitioning: {ds=2011-01-01}
+FAILED: SemanticException [Error 10214]: Invalid partition spec specified table is partitioned but partition spec is not specified or does not fully match table partitioning: {ds=2011-01-01}
diff --git a/ql/src/test/results/clientpositive/plan_json.q.out b/ql/src/test/results/clientpositive/plan_json.q.out
new file mode 100644
index 0000000000..5756a2b7af
--- /dev/null
+++ b/ql/src/test/results/clientpositive/plan_json.q.out
@@ -0,0 +1,9 @@
+PREHOOK: query: -- explain plan json:  the query gets the formatted json output of the query plan of the hive query
+
+EXPLAIN FORMATTED SELECT count(1) FROM src
+PREHOOK: type: QUERY
+POSTHOOK: query: -- explain plan json:  the query gets the formatted json output of the query plan of the hive query
+
+EXPLAIN FORMATTED SELECT count(1) FROM src
+POSTHOOK: type: QUERY
+{"STAGE PLANS":{"Stage-1":{"Map Reduce":{"Reduce Operator Tree:":{"GBY_4":{"SEL_5":{"FS_6":{"File Output Operator":{"GlobalTableId:":"0","compressed:":"false","table:":{"input format:":"org.apache.hadoop.mapred.TextInputFormat","output format:":"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat"}}}}}},"Alias -> Map Operator Tree:":{"src":{"TS_0":{"SEL_1":{"GBY_2":{"RS_3":{"Reduce Output Operator":{"Map-reduce partition columns:":[],"sort order:":"","tag:":"-1","value expressions:":[{"type:":"bigint","expr:":"_col0"}],"key expressions:":[]}}}}}}},"Percentage Sample:":{}}},"Stage-0":{"Fetch Operator":{"limit:":"-1"}}},"STAGE DEPENDENCIES":{"Stage-1":{"ROOT STAGE":"TRUE"},"Stage-0":{"ROOT STAGE":"TRUE"}},"ABSTRACT SYNTAX TREE":"(TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION count 1)))))"}
