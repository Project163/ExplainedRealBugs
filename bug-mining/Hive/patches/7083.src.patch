diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index d48f2c80e0..024f4d38bf 100644
--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -1390,7 +1390,7 @@ public static enum ConfVars {
      * @deprecated Use MetastoreConf.AGGREGATE_STATS_CACHE_ENABLED
      */
     @Deprecated
-    METASTORE_AGGREGATE_STATS_CACHE_ENABLED("hive.metastore.aggregate.stats.cache.enabled", true,
+    METASTORE_AGGREGATE_STATS_CACHE_ENABLED("hive.metastore.aggregate.stats.cache.enabled", false,
         "Whether aggregate stats caching is enabled or not."),
     /**
      * @deprecated Use MetastoreConf.AGGREGATE_STATS_CACHE_SIZE
diff --git a/ql/src/test/results/clientpositive/acid_stats3.q.out b/ql/src/test/results/clientpositive/acid_stats3.q.out
index 2fd9c1c944..e718018ad3 100644
--- a/ql/src/test/results/clientpositive/acid_stats3.q.out
+++ b/ql/src/test/results/clientpositive/acid_stats3.q.out
@@ -233,19 +233,19 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: stats_part
-            Statistics: Num rows: 2 Data size: 8 Basic stats: PARTIAL Column stats: PARTIAL
+            Statistics: Num rows: 2 Data size: 8 Basic stats: PARTIAL Column stats: COMPLETE
             Select Operator
               expressions: key (type: int)
               outputColumnNames: key
-              Statistics: Num rows: 2 Data size: 8 Basic stats: PARTIAL Column stats: PARTIAL
+              Statistics: Num rows: 2 Data size: 8 Basic stats: PARTIAL Column stats: COMPLETE
               Group By Operator
                 aggregations: count(key)
                 mode: hash
                 outputColumnNames: _col0
-                Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
+                Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
                 Reduce Output Operator
                   sort order: 
-                  Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
+                  Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
                   value expressions: _col0 (type: bigint)
       Execution mode: vectorized
       Reduce Operator Tree:
@@ -253,10 +253,10 @@ STAGE PLANS:
           aggregations: count(VALUE._col0)
           mode: mergepartial
           outputColumnNames: _col0
-          Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
+          Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
           File Output Operator
             compressed: false
-            Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
+            Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -340,19 +340,19 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: stats_part
-            Statistics: Num rows: 1 Data size: 4 Basic stats: PARTIAL Column stats: PARTIAL
+            Statistics: Num rows: 1 Data size: 4 Basic stats: PARTIAL Column stats: COMPLETE
             Select Operator
               expressions: key (type: int)
               outputColumnNames: key
-              Statistics: Num rows: 1 Data size: 4 Basic stats: PARTIAL Column stats: PARTIAL
+              Statistics: Num rows: 1 Data size: 4 Basic stats: PARTIAL Column stats: COMPLETE
               Group By Operator
                 aggregations: count(key)
                 mode: hash
                 outputColumnNames: _col0
-                Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
+                Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
                 Reduce Output Operator
                   sort order: 
-                  Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
+                  Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
                   value expressions: _col0 (type: bigint)
       Execution mode: vectorized
       Reduce Operator Tree:
@@ -360,10 +360,10 @@ STAGE PLANS:
           aggregations: count(VALUE._col0)
           mode: mergepartial
           outputColumnNames: _col0
-          Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
+          Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
           File Output Operator
             compressed: false
-            Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
+            Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/acid_stats4.q.out b/ql/src/test/results/clientpositive/acid_stats4.q.out
index b36aa4a9dd..36d7f5f4f2 100644
--- a/ql/src/test/results/clientpositive/acid_stats4.q.out
+++ b/ql/src/test/results/clientpositive/acid_stats4.q.out
@@ -914,29 +914,29 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: stats_part
-            Statistics: Num rows: 2 Data size: 8 Basic stats: PARTIAL Column stats: COMPLETE
+            Statistics: Num rows: 2 Data size: 8 Basic stats: PARTIAL Column stats: PARTIAL
             Select Operator
               expressions: key2 (type: int)
               outputColumnNames: key2
-              Statistics: Num rows: 2 Data size: 8 Basic stats: PARTIAL Column stats: COMPLETE
+              Statistics: Num rows: 2 Data size: 8 Basic stats: PARTIAL Column stats: PARTIAL
               Group By Operator
                 aggregations: count(key2)
                 mode: hash
                 outputColumnNames: _col0
-                Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
                 Reduce Output Operator
                   sort order: 
-                  Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
+                  Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
                   value expressions: _col0 (type: bigint)
       Reduce Operator Tree:
         Group By Operator
           aggregations: count(VALUE._col0)
           mode: mergepartial
           outputColumnNames: _col0
-          Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
+          Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
           File Output Operator
             compressed: false
-            Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: COMPLETE
+            Statistics: Num rows: 1 Data size: 12 Basic stats: PARTIAL Column stats: PARTIAL
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/autoColumnStats_1.q.out b/ql/src/test/results/clientpositive/autoColumnStats_1.q.out
index 4131535972..1f594ddb68 100644
--- a/ql/src/test/results/clientpositive/autoColumnStats_1.q.out
+++ b/ql/src/test/results/clientpositive/autoColumnStats_1.q.out
@@ -578,11 +578,11 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: nzhang_part14_n1
-          Statistics: Num rows: 11 Data size: 946 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 11 Data size: 957 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: key (type: string)
             outputColumnNames: _col0
-            Statistics: Num rows: 11 Data size: 946 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 11 Data size: 957 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
 PREHOOK: query: create table alter5_n0 ( col1 string ) partitioned by (dt string)
diff --git a/ql/src/test/results/clientpositive/autoColumnStats_2.q.out b/ql/src/test/results/clientpositive/autoColumnStats_2.q.out
index a8371236e7..121a10384b 100644
--- a/ql/src/test/results/clientpositive/autoColumnStats_2.q.out
+++ b/ql/src/test/results/clientpositive/autoColumnStats_2.q.out
@@ -575,11 +575,11 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: nzhang_part14
-          Statistics: Num rows: 11 Data size: 946 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 11 Data size: 957 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: key (type: string)
             outputColumnNames: _col0
-            Statistics: Num rows: 11 Data size: 946 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 11 Data size: 957 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
 PREHOOK: query: drop table alter5
@@ -829,11 +829,11 @@ STAGE PLANS:
         TableScan
           alias: alter5
           filterExpr: (dt = 'a') (type: boolean)
-          Statistics: Num rows: 49 Data size: 4263 Basic stats: PARTIAL Column stats: COMPLETE
+          Statistics: Num rows: 49 Data size: 27892 Basic stats: PARTIAL Column stats: NONE
           Select Operator
             expressions: col1 (type: string), 'a' (type: string)
             outputColumnNames: _col0, _col1
-            Statistics: Num rows: 49 Data size: 4263 Basic stats: PARTIAL Column stats: COMPLETE
+            Statistics: Num rows: 49 Data size: 27892 Basic stats: PARTIAL Column stats: NONE
             ListSink
 
 PREHOOK: query: drop table src_stat_part
diff --git a/ql/src/test/results/clientpositive/columnstats_partlvl.q.out b/ql/src/test/results/clientpositive/columnstats_partlvl.q.out
index 431f24ee28..e345841b64 100644
--- a/ql/src/test/results/clientpositive/columnstats_partlvl.q.out
+++ b/ql/src/test/results/clientpositive/columnstats_partlvl.q.out
@@ -813,11 +813,11 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: employee_part
-            Statistics: Num rows: 26 Data size: 2388 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 26 Data size: 2300 Basic stats: COMPLETE Column stats: PARTIAL
             Select Operator
               expressions: employeeid (type: int), employeename (type: string)
               outputColumnNames: employeeid, employeename
-              Statistics: Num rows: 26 Data size: 2388 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 26 Data size: 2300 Basic stats: COMPLETE Column stats: PARTIAL
               Group By Operator
                 aggregations: compute_stats(employeeid, 'hll'), compute_stats(employeename, 'hll')
                 mode: hash
@@ -885,7 +885,7 @@ num_trues
 num_falses          	                    	 	 	 	 	 	 	 	 	 	 
 bitVector           	HL                  	 	 	 	 	 	 	 	 	 	 
 comment             	from deserializer   	 	 	 	 	 	 	 	 	 	 
-COLUMN_STATS_ACCURATE	{\"COLUMN_STATS\":{\"employeename\":\"true\"}}	 	 	 	 	 	 	 	 	 	 
+COLUMN_STATS_ACCURATE	{\"COLUMN_STATS\":{\"employeeid\":\"true\",\"employeename\":\"true\"}}	 	 	 	 	 	 	 	 	 	 
 PREHOOK: query: create database if not exists dummydb
 PREHOOK: type: CREATEDATABASE
 PREHOOK: Output: database:dummydb
diff --git a/ql/src/test/results/clientpositive/dynamic_partition_skip_default.q.out b/ql/src/test/results/clientpositive/dynamic_partition_skip_default.q.out
index 9ec9dca856..0c2ad97bdd 100644
--- a/ql/src/test/results/clientpositive/dynamic_partition_skip_default.q.out
+++ b/ql/src/test/results/clientpositive/dynamic_partition_skip_default.q.out
@@ -320,11 +320,11 @@ STAGE PLANS:
         TableScan
           alias: dynamic_part_table
           filterExpr: ((partcol2) IN ('1', '__HIVE_DEFAULT_PARTITION__') and (partcol1 = '1')) (type: boolean)
-          Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: COMPLETE
           GatherStats: false
           Select Operator
             expressions: intcol (type: string)
             outputColumnNames: _col0
-            Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
diff --git a/ql/src/test/results/clientpositive/extrapolate_part_stats_date.q.out b/ql/src/test/results/clientpositive/extrapolate_part_stats_date.q.out
index d8c24af627..22075f154c 100644
--- a/ql/src/test/results/clientpositive/extrapolate_part_stats_date.q.out
+++ b/ql/src/test/results/clientpositive/extrapolate_part_stats_date.q.out
@@ -334,11 +334,11 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: date_dim_n1
-          Statistics: Num rows: 4 Data size: 224 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 4 Data size: 224 Basic stats: COMPLETE Column stats: COMPLETE
           GatherStats: false
           Select Operator
             expressions: d_date (type: date)
             outputColumnNames: _col0
-            Statistics: Num rows: 4 Data size: 224 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 4 Data size: 224 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
diff --git a/ql/src/test/results/clientpositive/groupby_ppr.q.out b/ql/src/test/results/clientpositive/groupby_ppr.q.out
index d68680c8b0..e9c20af0ef 100644
--- a/ql/src/test/results/clientpositive/groupby_ppr.q.out
+++ b/ql/src/test/results/clientpositive/groupby_ppr.q.out
@@ -41,18 +41,18 @@ STAGE PLANS:
           TableScan
             alias: src
             filterExpr: (ds = '2008-04-08') (type: boolean)
-            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: substr(key, 1, 1) (type: string), substr(value, 5) (type: string)
               outputColumnNames: _col0, _col1
-              Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: _col0 (type: string), _col1 (type: string)
                 null sort order: aa
                 sort order: ++
                 Map-reduce partition columns: _col0 (type: string)
-                Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
                 tag: -1
                 auto parallelism: false
       Execution mode: vectorized
@@ -167,17 +167,17 @@ STAGE PLANS:
           keys: KEY._col0 (type: string)
           mode: complete
           outputColumnNames: _col0, _col1, _col2
-          Statistics: Num rows: 316 Data size: 63200 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 316 Data size: 63200 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: _col0 (type: string), UDFToInteger(_col1) (type: int), concat(_col0, _col2) (type: string)
             outputColumnNames: _col0, _col1, _col2
-            Statistics: Num rows: 316 Data size: 117552 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 316 Data size: 117552 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 1
 #### A masked pattern was here ####
               NumFilesPerFileSink: 1
-              Statistics: Num rows: 316 Data size: 117552 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 316 Data size: 117552 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -208,7 +208,7 @@ STAGE PLANS:
             Select Operator
               expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string)
               outputColumnNames: key, c1, c2
-              Statistics: Num rows: 316 Data size: 117552 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 316 Data size: 117552 Basic stats: COMPLETE Column stats: COMPLETE
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
@@ -275,7 +275,7 @@ STAGE PLANS:
             Reduce Output Operator
               null sort order: 
               sort order: 
-              Statistics: Num rows: 316 Data size: 117552 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 316 Data size: 117552 Basic stats: COMPLETE Column stats: COMPLETE
               tag: -1
               value expressions: key (type: string), c1 (type: int), c2 (type: string)
               auto parallelism: false
@@ -313,13 +313,13 @@ STAGE PLANS:
           aggregations: compute_stats(VALUE._col0, 'hll'), compute_stats(VALUE._col2, 'hll'), compute_stats(VALUE._col3, 'hll')
           mode: complete
           outputColumnNames: _col0, _col1, _col2
-          Statistics: Num rows: 1 Data size: 1320 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 1 Data size: 1320 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 1 Data size: 1320 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1 Data size: 1320 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
diff --git a/ql/src/test/results/clientpositive/groupby_sort_10.q.out b/ql/src/test/results/clientpositive/groupby_sort_10.q.out
index 4bbdca6a41..fb7693d1e6 100644
--- a/ql/src/test/results/clientpositive/groupby_sort_10.q.out
+++ b/ql/src/test/results/clientpositive/groupby_sort_10.q.out
@@ -111,32 +111,32 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: t1_n149
-            Statistics: Num rows: 8 Data size: 680 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 8 Data size: 680 Basic stats: COMPLETE Column stats: COMPLETE
             Select Operator
               expressions: key (type: string)
               outputColumnNames: key
-              Statistics: Num rows: 8 Data size: 680 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 8 Data size: 680 Basic stats: COMPLETE Column stats: COMPLETE
               Group By Operator
                 bucketGroup: true
                 keys: key (type: string)
                 mode: hash
                 outputColumnNames: _col0
-                Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: string)
                   sort order: +
                   Map-reduce partition columns: _col0 (type: string)
-                  Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: COMPLETE
       Execution mode: vectorized
       Reduce Operator Tree:
         Group By Operator
           keys: KEY._col0 (type: string)
           mode: mergepartial
           outputColumnNames: _col0
-          Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
-            Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2 Data size: 170 Basic stats: COMPLETE Column stats: COMPLETE
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/list_bucket_dml_9.q.out b/ql/src/test/results/clientpositive/list_bucket_dml_9.q.out
index 9854283b52..b10aeecbaf 100644
--- a/ql/src/test/results/clientpositive/list_bucket_dml_9.q.out
+++ b/ql/src/test/results/clientpositive/list_bucket_dml_9.q.out
@@ -45,19 +45,19 @@ STAGE PLANS:
           TableScan
             alias: srcpart
             filterExpr: (ds = '2008-04-08') (type: boolean)
-            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: key (type: string), value (type: string)
               outputColumnNames: _col0, _col1
-              Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
 #### A masked pattern was here ####
                 NumFilesPerFileSink: 1
                 Static Partition Specification: ds=2008-04-08/hr=11/
-                Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
                 table:
                     input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
@@ -85,19 +85,19 @@ STAGE PLANS:
               Select Operator
                 expressions: _col0 (type: string), _col1 (type: string), '2008-04-08' (type: string), '11' (type: string)
                 outputColumnNames: key, value, ds, hr
-                Statistics: Num rows: 1000 Data size: 358000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1000 Data size: 358000 Basic stats: COMPLETE Column stats: COMPLETE
                 Group By Operator
                   aggregations: compute_stats(key, 'hll'), compute_stats(value, 'hll')
                   keys: ds (type: string), hr (type: string)
                   mode: hash
                   outputColumnNames: _col0, _col1, _col2, _col3
-                  Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
                   Reduce Output Operator
                     key expressions: _col0 (type: string), _col1 (type: string)
                     null sort order: aa
                     sort order: ++
                     Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
-                    Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
                     tag: -1
                     value expressions: _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
                     auto parallelism: false
@@ -212,17 +212,17 @@ STAGE PLANS:
           keys: KEY._col0 (type: string), KEY._col1 (type: string)
           mode: mergepartial
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col0 (type: string), _col1 (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
 #### A masked pattern was here ####
               NumFilesPerFileSink: 1
-              Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -381,19 +381,19 @@ STAGE PLANS:
           TableScan
             alias: srcpart
             filterExpr: (ds = '2008-04-08') (type: boolean)
-            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: key (type: string), value (type: string)
               outputColumnNames: _col0, _col1
-              Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
 #### A masked pattern was here ####
                 NumFilesPerFileSink: 1
                 Static Partition Specification: ds=2008-04-08/hr=11/
-                Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
                 table:
                     input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
@@ -420,19 +420,19 @@ STAGE PLANS:
               Select Operator
                 expressions: _col0 (type: string), _col1 (type: string), '2008-04-08' (type: string), '11' (type: string)
                 outputColumnNames: key, value, ds, hr
-                Statistics: Num rows: 1000 Data size: 358000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1000 Data size: 358000 Basic stats: COMPLETE Column stats: COMPLETE
                 Group By Operator
                   aggregations: compute_stats(key, 'hll'), compute_stats(value, 'hll')
                   keys: ds (type: string), hr (type: string)
                   mode: hash
                   outputColumnNames: _col0, _col1, _col2, _col3
-                  Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
                   Reduce Output Operator
                     key expressions: _col0 (type: string), _col1 (type: string)
                     null sort order: aa
                     sort order: ++
                     Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
-                    Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
                     tag: -1
                     value expressions: _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
                     auto parallelism: false
@@ -547,17 +547,17 @@ STAGE PLANS:
           keys: KEY._col0 (type: string), KEY._col1 (type: string)
           mode: mergepartial
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col0 (type: string), _col1 (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
 #### A masked pattern was here ####
               NumFilesPerFileSink: 1
-              Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 1 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
diff --git a/ql/src/test/results/clientpositive/llap/acid_no_buckets.q.out b/ql/src/test/results/clientpositive/llap/acid_no_buckets.q.out
index fcd90f7297..ae1d97fa21 100644
--- a/ql/src/test/results/clientpositive/llap/acid_no_buckets.q.out
+++ b/ql/src/test/results/clientpositive/llap/acid_no_buckets.q.out
@@ -318,7 +318,7 @@ num_trues
 num_falses          	                    	 	 	 	 	 	 	 	 	 	 
 bitVector           	HL                  	 	 	 	 	 	 	 	 	 	 
 comment             	from deserializer   	 	 	 	 	 	 	 	 	 	 
-COLUMN_STATS_ACCURATE	{}                  	 	 	 	 	 	 	 	 	 	 
+COLUMN_STATS_ACCURATE	{\"COLUMN_STATS\":{\"key\":\"true\"}}	 	 	 	 	 	 	 	 	 	 
 PREHOOK: query: analyze table srcpart_acid PARTITION(ds, hr) compute statistics
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart_acid
@@ -423,14 +423,14 @@ data_type           	string
 min                 	                    	 	 	 	 	 	 	 	 	 	 
 max                 	                    	 	 	 	 	 	 	 	 	 	 
 num_nulls           	0                   	 	 	 	 	 	 	 	 	 	 
-distinct_count      	316                 	 	 	 	 	 	 	 	 	 	 
-avg_col_len         	2.812               	 	 	 	 	 	 	 	 	 	 
-max_col_len         	3                   	 	 	 	 	 	 	 	 	 	 
+distinct_count      	320                 	 	 	 	 	 	 	 	 	 	 
+avg_col_len         	2.8190854870775346  	 	 	 	 	 	 	 	 	 	 
+max_col_len         	4                   	 	 	 	 	 	 	 	 	 	 
 num_trues           	                    	 	 	 	 	 	 	 	 	 	 
 num_falses          	                    	 	 	 	 	 	 	 	 	 	 
 bitVector           	HL                  	 	 	 	 	 	 	 	 	 	 
 comment             	from deserializer   	 	 	 	 	 	 	 	 	 	 
-COLUMN_STATS_ACCURATE	{}                  	 	 	 	 	 	 	 	 	 	 
+COLUMN_STATS_ACCURATE	{\"COLUMN_STATS\":{\"key\":\"true\"}}	 	 	 	 	 	 	 	 	 	 
 PREHOOK: query: explain delete from srcpart_acid where key in( '1001', '213', '43')
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart_acid
diff --git a/ql/src/test/results/clientpositive/llap/bucket_groupby.q.out b/ql/src/test/results/clientpositive/llap/bucket_groupby.q.out
index 4e6885d9a2..451968ac7e 100644
--- a/ql/src/test/results/clientpositive/llap/bucket_groupby.q.out
+++ b/ql/src/test/results/clientpositive/llap/bucket_groupby.q.out
@@ -736,22 +736,22 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: clustergroupby
-                  Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: key (type: string)
                     outputColumnNames: key
-                    Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                     Group By Operator
                       aggregations: count()
                       keys: key (type: string)
                       mode: hash
                       outputColumnNames: _col0, _col1
-                      Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: COMPLETE
                       Reduce Output Operator
                         key expressions: _col0 (type: string)
                         sort order: +
                         Map-reduce partition columns: _col0 (type: string)
-                        Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: PARTIAL
+                        Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: COMPLETE
                         value expressions: _col1 (type: bigint)
             Execution mode: llap
             LLAP IO: no inputs
@@ -763,10 +763,10 @@ STAGE PLANS:
                 keys: KEY._col0 (type: string)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1129,22 +1129,22 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: clustergroupby
-                  Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: key (type: string)
                     outputColumnNames: key
-                    Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 1000 Data size: 87000 Basic stats: COMPLETE Column stats: COMPLETE
                     Group By Operator
                       aggregations: count()
                       keys: key (type: string)
                       mode: hash
                       outputColumnNames: _col0, _col1
-                      Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: COMPLETE
                       Reduce Output Operator
                         key expressions: _col0 (type: string)
                         sort order: +
                         Map-reduce partition columns: _col0 (type: string)
-                        Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: PARTIAL
+                        Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: COMPLETE
                         value expressions: _col1 (type: bigint)
             Execution mode: llap
             LLAP IO: no inputs
@@ -1156,10 +1156,10 @@ STAGE PLANS:
                 keys: KEY._col0 (type: string)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 316 Data size: 30020 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/bucketsortoptimize_insert_2.q.out b/ql/src/test/results/clientpositive/llap/bucketsortoptimize_insert_2.q.out
index 8039d0f814..425b5c396b 100644
--- a/ql/src/test/results/clientpositive/llap/bucketsortoptimize_insert_2.q.out
+++ b/ql/src/test/results/clientpositive/llap/bucketsortoptimize_insert_2.q.out
@@ -352,14 +352,14 @@ STAGE PLANS:
                 TableScan
                   alias: a
                   filterExpr: key is not null (type: boolean)
-                  Statistics: Num rows: 20 Data size: 1860 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 20 Data size: 1860 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: key is not null (type: boolean)
-                    Statistics: Num rows: 20 Data size: 1860 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 20 Data size: 1860 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: key (type: int), value (type: string)
                       outputColumnNames: _col0, _col1
-                      Statistics: Num rows: 20 Data size: 1860 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 20 Data size: 1860 Basic stats: COMPLETE Column stats: COMPLETE
                       Merge Join Operator
                         condition map:
                              Inner Join 0 to 1
@@ -367,16 +367,16 @@ STAGE PLANS:
                           0 _col0 (type: int)
                           1 _col0 (type: int)
                         outputColumnNames: _col0, _col1, _col3
-                        Statistics: Num rows: 29 Data size: 5307 Basic stats: COMPLETE Column stats: PARTIAL
+                        Statistics: Num rows: 29 Data size: 5307 Basic stats: COMPLETE Column stats: COMPLETE
                         Select Operator
                           expressions: _col0 (type: int), concat(_col1, _col3) (type: string)
                           outputColumnNames: _col0, _col1
-                          Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: PARTIAL
+                          Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: COMPLETE
                           Reduce Output Operator
                             key expressions: _col0 (type: int)
                             sort order: +
                             Map-reduce partition columns: _col0 (type: int)
-                            Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: PARTIAL
+                            Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: COMPLETE
                             value expressions: _col1 (type: string)
             Execution mode: llap
         Reducer 2 
@@ -385,10 +385,10 @@ STAGE PLANS:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -397,18 +397,18 @@ STAGE PLANS:
                 Select Operator
                   expressions: _col0 (type: int), _col1 (type: string), '1' (type: string)
                   outputColumnNames: key, value, ds
-                  Statistics: Num rows: 29 Data size: 7917 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 29 Data size: 7917 Basic stats: COMPLETE Column stats: COMPLETE
                   Group By Operator
                     aggregations: compute_stats(key, 'hll'), compute_stats(value, 'hll')
                     keys: ds (type: string)
                     mode: hash
                     outputColumnNames: _col0, _col1, _col2
-                    Statistics: Num rows: 1 Data size: 949 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 1 Data size: 949 Basic stats: COMPLETE Column stats: COMPLETE
                     Reduce Output Operator
                       key expressions: _col0 (type: string)
                       sort order: +
                       Map-reduce partition columns: _col0 (type: string)
-                      Statistics: Num rows: 1 Data size: 949 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 1 Data size: 949 Basic stats: COMPLETE Column stats: COMPLETE
                       value expressions: _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
         Reducer 3 
             Execution mode: llap
@@ -418,14 +418,14 @@ STAGE PLANS:
                 keys: KEY._col0 (type: string)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col0 (type: string)
                   outputColumnNames: _col0, _col1, _col2
-                  Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: COMPLETE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -586,14 +586,14 @@ STAGE PLANS:
                 TableScan
                   alias: b
                   filterExpr: key is not null (type: boolean)
-                  Statistics: Num rows: 168 Data size: 15792 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 168 Data size: 15792 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: key is not null (type: boolean)
-                    Statistics: Num rows: 168 Data size: 15792 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 168 Data size: 15792 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: key (type: int), value (type: string)
                       outputColumnNames: _col0, _col1
-                      Statistics: Num rows: 168 Data size: 15792 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 168 Data size: 15792 Basic stats: COMPLETE Column stats: COMPLETE
             Map Operator Tree:
                 TableScan
                   alias: a
@@ -613,16 +613,16 @@ STAGE PLANS:
                           0 _col0 (type: int)
                           1 _col0 (type: int)
                         outputColumnNames: _col0, _col1, _col3
-                        Statistics: Num rows: 29 Data size: 5307 Basic stats: COMPLETE Column stats: PARTIAL
+                        Statistics: Num rows: 29 Data size: 5307 Basic stats: COMPLETE Column stats: COMPLETE
                         Select Operator
                           expressions: _col0 (type: int), concat(_col1, _col3) (type: string)
                           outputColumnNames: _col0, _col1
-                          Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: PARTIAL
+                          Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: COMPLETE
                           Reduce Output Operator
                             key expressions: _col0 (type: int)
                             sort order: +
                             Map-reduce partition columns: _col0 (type: int)
-                            Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: PARTIAL
+                            Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: COMPLETE
                             value expressions: _col1 (type: string)
             Execution mode: llap
         Reducer 2 
@@ -631,10 +631,10 @@ STAGE PLANS:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 29 Data size: 5452 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -643,18 +643,18 @@ STAGE PLANS:
                 Select Operator
                   expressions: _col0 (type: int), _col1 (type: string), '1' (type: string)
                   outputColumnNames: key, value, ds
-                  Statistics: Num rows: 29 Data size: 7917 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 29 Data size: 7917 Basic stats: COMPLETE Column stats: COMPLETE
                   Group By Operator
                     aggregations: compute_stats(key, 'hll'), compute_stats(value, 'hll')
                     keys: ds (type: string)
                     mode: hash
                     outputColumnNames: _col0, _col1, _col2
-                    Statistics: Num rows: 1 Data size: 949 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 1 Data size: 949 Basic stats: COMPLETE Column stats: COMPLETE
                     Reduce Output Operator
                       key expressions: _col0 (type: string)
                       sort order: +
                       Map-reduce partition columns: _col0 (type: string)
-                      Statistics: Num rows: 1 Data size: 949 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 1 Data size: 949 Basic stats: COMPLETE Column stats: COMPLETE
                       value expressions: _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,bitvector:binary>), _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
         Reducer 3 
             Execution mode: llap
@@ -664,14 +664,14 @@ STAGE PLANS:
                 keys: KEY._col0 (type: string)
                 mode: mergepartial
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: COMPLETE
                 Select Operator
                   expressions: _col1 (type: struct<columntype:string,min:bigint,max:bigint,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col0 (type: string)
                   outputColumnNames: _col0, _col1, _col2
-                  Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 1 Data size: 965 Basic stats: COMPLETE Column stats: COMPLETE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_sw.q.out b/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_sw.q.out
index c77ebf701b..0a4f06f74f 100644
--- a/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_sw.q.out
+++ b/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_sw.q.out
@@ -291,49 +291,49 @@ STAGE PLANS:
                 TableScan
                   alias: srcpart_small_n2
                   filterExpr: key1 is not null (type: boolean)
-                  Statistics: Num rows: 1 Data size: 87 Basic stats: PARTIAL Column stats: COMPLETE
+                  Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: NONE
                   Filter Operator
                     predicate: key1 is not null (type: boolean)
-                    Statistics: Num rows: 1 Data size: 87 Basic stats: PARTIAL Column stats: COMPLETE
+                    Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: NONE
                     Select Operator
                       expressions: key1 (type: string)
                       outputColumnNames: _col0
-                      Statistics: Num rows: 1 Data size: 87 Basic stats: PARTIAL Column stats: COMPLETE
+                      Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: NONE
                       Reduce Output Operator
                         key expressions: _col0 (type: string)
                         sort order: +
                         Map-reduce partition columns: _col0 (type: string)
-                        Statistics: Num rows: 1 Data size: 87 Basic stats: PARTIAL Column stats: COMPLETE
+                        Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: NONE
                       Select Operator
                         expressions: _col0 (type: string)
                         outputColumnNames: _col0
-                        Statistics: Num rows: 1 Data size: 87 Basic stats: PARTIAL Column stats: COMPLETE
+                        Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: NONE
                         Group By Operator
                           aggregations: min(_col0), max(_col0), bloom_filter(_col0, expectedEntries=1)
                           mode: hash
                           outputColumnNames: _col0, _col1, _col2
-                          Statistics: Num rows: 1 Data size: 639 Basic stats: PARTIAL Column stats: COMPLETE
+                          Statistics: Num rows: 1 Data size: 736 Basic stats: PARTIAL Column stats: NONE
                           Reduce Output Operator
                             sort order: 
-                            Statistics: Num rows: 1 Data size: 639 Basic stats: PARTIAL Column stats: COMPLETE
+                            Statistics: Num rows: 1 Data size: 736 Basic stats: PARTIAL Column stats: NONE
                             value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: binary)
                       Reduce Output Operator
                         key expressions: _col0 (type: string)
                         sort order: +
                         Map-reduce partition columns: _col0 (type: string)
-                        Statistics: Num rows: 1 Data size: 87 Basic stats: PARTIAL Column stats: COMPLETE
+                        Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: NONE
                       Select Operator
                         expressions: _col0 (type: string)
                         outputColumnNames: _col0
-                        Statistics: Num rows: 1 Data size: 87 Basic stats: PARTIAL Column stats: COMPLETE
+                        Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: NONE
                         Group By Operator
                           aggregations: min(_col0), max(_col0), bloom_filter(_col0, expectedEntries=1)
                           mode: hash
                           outputColumnNames: _col0, _col1, _col2
-                          Statistics: Num rows: 1 Data size: 639 Basic stats: PARTIAL Column stats: COMPLETE
+                          Statistics: Num rows: 1 Data size: 736 Basic stats: PARTIAL Column stats: NONE
                           Reduce Output Operator
                             sort order: 
-                            Statistics: Num rows: 1 Data size: 639 Basic stats: PARTIAL Column stats: COMPLETE
+                            Statistics: Num rows: 1 Data size: 736 Basic stats: PARTIAL Column stats: NONE
                             value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: binary)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -344,10 +344,10 @@ STAGE PLANS:
                 aggregations: min(VALUE._col0), max(VALUE._col1), bloom_filter(VALUE._col2, expectedEntries=1)
                 mode: final
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 1 Data size: 639 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 1 Data size: 736 Basic stats: PARTIAL Column stats: NONE
                 Reduce Output Operator
                   sort order: 
-                  Statistics: Num rows: 1 Data size: 639 Basic stats: PARTIAL Column stats: COMPLETE
+                  Statistics: Num rows: 1 Data size: 736 Basic stats: PARTIAL Column stats: NONE
                   value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: binary)
         Reducer 2 
             Execution mode: llap
@@ -419,14 +419,14 @@ STAGE PLANS:
                 aggregations: min(VALUE._col0), max(VALUE._col1), bloom_filter(VALUE._col2, expectedEntries=1)
                 mode: final
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 1 Data size: 639 Basic stats: PARTIAL Column stats: COMPLETE
+                Statistics: Num rows: 1 Data size: 736 Basic stats: PARTIAL Column stats: NONE
                 Reduce Output Operator
                   sort order: 
-                  Statistics: Num rows: 1 Data size: 639 Basic stats: PARTIAL Column stats: COMPLETE
+                  Statistics: Num rows: 1 Data size: 736 Basic stats: PARTIAL Column stats: NONE
                   value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: binary)
                 Reduce Output Operator
                   sort order: 
-                  Statistics: Num rows: 1 Data size: 639 Basic stats: PARTIAL Column stats: COMPLETE
+                  Statistics: Num rows: 1 Data size: 736 Basic stats: PARTIAL Column stats: NONE
                   value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: binary)
         Reducer 8 
             Execution mode: llap
diff --git a/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_sw2.q.out b/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_sw2.q.out
index 6e2ee32ddd..3a02766023 100644
--- a/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_sw2.q.out
+++ b/ql/src/test/results/clientpositive/llap/dynamic_semijoin_reduction_sw2.q.out
@@ -229,19 +229,19 @@ STAGE PLANS:
                 TableScan
                   alias: srcpart_small_n2
                   filterExpr: key1 is not null (type: boolean)
-                  Statistics: Num rows: 1 Data size: 87 Basic stats: PARTIAL Column stats: COMPLETE
+                  Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: NONE
                   Filter Operator
                     predicate: key1 is not null (type: boolean)
-                    Statistics: Num rows: 1 Data size: 87 Basic stats: PARTIAL Column stats: COMPLETE
+                    Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: NONE
                     Select Operator
                       expressions: key1 (type: string)
                       outputColumnNames: _col0
-                      Statistics: Num rows: 1 Data size: 87 Basic stats: PARTIAL Column stats: COMPLETE
+                      Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: NONE
                       Reduce Output Operator
                         key expressions: _col0 (type: string)
                         sort order: +
                         Map-reduce partition columns: _col0 (type: string)
-                        Statistics: Num rows: 1 Data size: 87 Basic stats: PARTIAL Column stats: COMPLETE
+                        Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: NONE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 6 
diff --git a/ql/src/test/results/clientpositive/llap/materialized_view_rewrite_no_join_opt_2.q.out b/ql/src/test/results/clientpositive/llap/materialized_view_rewrite_no_join_opt_2.q.out
index d9a48fb4b9..0fc4d7bd5e 100644
--- a/ql/src/test/results/clientpositive/llap/materialized_view_rewrite_no_join_opt_2.q.out
+++ b/ql/src/test/results/clientpositive/llap/materialized_view_rewrite_no_join_opt_2.q.out
@@ -354,16 +354,16 @@ STAGE PLANS:
                 TableScan
                   alias: default.mv1_part_n2
                   filterExpr: deptno is not null (type: boolean)
-                  Statistics: Num rows: 5 Data size: 505 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 5 Data size: 510 Basic stats: COMPLETE Column stats: COMPLETE
                   Select Operator
                     expressions: name (type: varchar(256)), salary (type: float), commission (type: int), deptno (type: int)
                     outputColumnNames: _col0, _col1, _col2, _col3
-                    Statistics: Num rows: 5 Data size: 505 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 5 Data size: 510 Basic stats: COMPLETE Column stats: COMPLETE
                     Reduce Output Operator
                       key expressions: _col3 (type: int)
                       sort order: +
                       Map-reduce partition columns: _col3 (type: int)
-                      Statistics: Num rows: 5 Data size: 505 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 5 Data size: 510 Basic stats: COMPLETE Column stats: COMPLETE
                       value expressions: _col0 (type: varchar(256)), _col1 (type: float), _col2 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
@@ -408,10 +408,10 @@ STAGE PLANS:
                   0 _col3 (type: int)
                   1 _col0 (type: int)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 5 Data size: 485 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 5 Data size: 490 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 5 Data size: 485 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 5 Data size: 490 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -518,7 +518,7 @@ STAGE PLANS:
                       Statistics: Num rows: 1 Data size: 106 Basic stats: COMPLETE Column stats: COMPLETE
                       File Output Operator
                         compressed: false
-                        Statistics: Num rows: 5 Data size: 526 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 2 Data size: 212 Basic stats: COMPLETE Column stats: COMPLETE
                         table:
                             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -530,17 +530,17 @@ STAGE PLANS:
                 TableScan
                   alias: default.mv1_part_n2
                   filterExpr: (empid < 150) (type: boolean)
-                  Statistics: Num rows: 4 Data size: 420 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 4 Data size: 424 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: (empid < 150) (type: boolean)
-                    Statistics: Num rows: 4 Data size: 420 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1 Data size: 106 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: empid (type: int), deptno (type: int), name (type: varchar(256)), salary (type: float), commission (type: int)
                       outputColumnNames: _col0, _col1, _col2, _col3, _col4
-                      Statistics: Num rows: 4 Data size: 420 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 1 Data size: 106 Basic stats: COMPLETE Column stats: COMPLETE
                       File Output Operator
                         compressed: false
-                        Statistics: Num rows: 5 Data size: 526 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 2 Data size: 212 Basic stats: COMPLETE Column stats: COMPLETE
                         table:
                             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/materialized_view_rewrite_part_1.q.out b/ql/src/test/results/clientpositive/llap/materialized_view_rewrite_part_1.q.out
index 786e2c71a1..ff7a52ef34 100644
--- a/ql/src/test/results/clientpositive/llap/materialized_view_rewrite_part_1.q.out
+++ b/ql/src/test/results/clientpositive/llap/materialized_view_rewrite_part_1.q.out
@@ -448,7 +448,7 @@ STAGE PLANS:
                       Statistics: Num rows: 1 Data size: 106 Basic stats: COMPLETE Column stats: COMPLETE
                       File Output Operator
                         compressed: false
-                        Statistics: Num rows: 5 Data size: 526 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 2 Data size: 212 Basic stats: COMPLETE Column stats: COMPLETE
                         table:
                             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -460,17 +460,17 @@ STAGE PLANS:
                 TableScan
                   alias: default.mv1_part_n2
                   filterExpr: (empid < 150) (type: boolean)
-                  Statistics: Num rows: 4 Data size: 420 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 4 Data size: 424 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: (empid < 150) (type: boolean)
-                    Statistics: Num rows: 4 Data size: 420 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 1 Data size: 106 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: empid (type: int), deptno (type: int), name (type: varchar(256)), salary (type: float), commission (type: int)
                       outputColumnNames: _col0, _col1, _col2, _col3, _col4
-                      Statistics: Num rows: 4 Data size: 420 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 1 Data size: 106 Basic stats: COMPLETE Column stats: COMPLETE
                       File Output Operator
                         compressed: false
-                        Statistics: Num rows: 5 Data size: 526 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 2 Data size: 212 Basic stats: COMPLETE Column stats: COMPLETE
                         table:
                             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part.q.out
index fd27a94d2c..13b1886f12 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part.q.out
@@ -752,14 +752,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_numeric_group_string_group_multi_ints_string_group_n7
-                  Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: string), c2 (type: string), c3 (type: string), c4 (type: string), c5 (type: char(50)), c6 (type: char(50)), c7 (type: char(50)), c8 (type: char(50)), c9 (type: char(5)), c10 (type: char(5)), c11 (type: char(5)), c12 (type: char(5)), c13 (type: varchar(50)), c14 (type: varchar(50)), c15 (type: varchar(50)), c16 (type: varchar(50)), c17 (type: varchar(5)), c18 (type: varchar(5)), c19 (type: varchar(5)), c20 (type: varchar(5)), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22
-                    Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1120,14 +1120,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_string_group_string_group_string_n7
-                  Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: char(50)), c2 (type: char(9)), c3 (type: varchar(50)), c4 (type: char(9)), c5 (type: varchar(50)), c6 (type: varchar(9)), c7 (type: string), c8 (type: char(50)), c9 (type: char(9)), c10 (type: string), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
-                    Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1325,14 +1325,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_lower_to_higher_numeric_group_tinyint_to_bigint_n7
-                  Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: smallint), c2 (type: int), c3 (type: bigint), c4 (type: decimal(38,18)), c5 (type: float), c6 (type: double), c7 (type: int), c8 (type: bigint), c9 (type: decimal(38,18)), c10 (type: float), c11 (type: double), c12 (type: bigint), c13 (type: decimal(38,18)), c14 (type: float), c15 (type: double), c16 (type: decimal(38,18)), c17 (type: float), c18 (type: double), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20
-                    Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_all_primitive.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_all_primitive.q.out
index deb2289b78..81125cb0d5 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_all_primitive.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_all_primitive.q.out
@@ -793,14 +793,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_various_various_date_n6
-                  Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: date), c2 (type: date), c3 (type: date), c4 (type: date), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
-                    Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_all_primitive_llap_io.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_all_primitive_llap_io.q.out
index 4f0080960e..e4c29f77e4 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_all_primitive_llap_io.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_all_primitive_llap_io.q.out
@@ -796,14 +796,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_various_various_date_n5
-                  Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: date), c2 (type: date), c3 (type: date), c4 (type: date), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
-                    Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_llap_io.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_llap_io.q.out
index 79b4adc76e..41b2bc2ec0 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_llap_io.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_orc_nonvec_part_llap_io.q.out
@@ -756,14 +756,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_numeric_group_string_group_multi_ints_string_group_n2
-                  Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: string), c2 (type: string), c3 (type: string), c4 (type: string), c5 (type: char(50)), c6 (type: char(50)), c7 (type: char(50)), c8 (type: char(50)), c9 (type: char(5)), c10 (type: char(5)), c11 (type: char(5)), c12 (type: char(5)), c13 (type: varchar(50)), c14 (type: varchar(50)), c15 (type: varchar(50)), c16 (type: varchar(50)), c17 (type: varchar(5)), c18 (type: varchar(5)), c19 (type: varchar(5)), c20 (type: varchar(5)), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22
-                    Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1126,14 +1126,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_string_group_string_group_string_n2
-                  Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: char(50)), c2 (type: char(9)), c3 (type: varchar(50)), c4 (type: char(9)), c5 (type: varchar(50)), c6 (type: varchar(9)), c7 (type: string), c8 (type: char(50)), c9 (type: char(9)), c10 (type: string), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
-                    Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1332,14 +1332,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_lower_to_higher_numeric_group_tinyint_to_bigint_n2
-                  Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: smallint), c2 (type: int), c3 (type: bigint), c4 (type: decimal(38,18)), c5 (type: float), c6 (type: double), c7 (type: int), c8 (type: bigint), c9 (type: decimal(38,18)), c10 (type: float), c11 (type: double), c12 (type: bigint), c13 (type: decimal(38,18)), c14 (type: float), c15 (type: double), c16 (type: decimal(38,18)), c17 (type: float), c18 (type: double), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20
-                    Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part.q.out
index b13e38b376..f3f567d1c9 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part.q.out
@@ -856,7 +856,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_numeric_group_string_group_multi_ints_string_group_n4
-                  Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:string, 2:c2:string, 3:c3:string, 4:c4:string, 5:c5:char(50), 6:c6:char(50), 7:c7:char(50), 8:c8:char(50), 9:c9:char(5), 10:c10:char(5), 11:c11:char(5), 12:c12:char(5), 13:c13:varchar(50), 14:c14:varchar(50), 15:c15:varchar(50), 16:c16:varchar(50), 17:c17:varchar(5), 18:c18:varchar(5), 19:c19:varchar(5), 20:c20:varchar(5), 21:b:string, 22:part:int, 23:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -867,13 +867,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 22, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
-                    Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1276,7 +1276,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_string_group_string_group_string_n4
-                  Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:char(50), 2:c2:char(9), 3:c3:varchar(50), 4:c4:char(9), 5:c5:varchar(50), 6:c6:varchar(9), 7:c7:string, 8:c8:char(50), 9:c9:char(9), 10:c10:string, 11:b:string, 12:part:int, 13:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -1287,13 +1287,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
-                    Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1507,7 +1507,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_lower_to_higher_numeric_group_tinyint_to_bigint_n4
-                  Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:smallint, 2:c2:int, 3:c3:bigint, 4:c4:decimal(38,18), 5:c5:float, 6:c6:double, 7:c7:int, 8:c8:bigint, 9:c9:decimal(38,18), 10:c10:float, 11:c11:double, 12:c12:bigint, 13:c13:decimal(38,18), 14:c14:float, 15:c15:double, 16:c16:decimal(38,18), 17:c17:float, 18:c18:double, 19:b:string, 20:part:int, 21:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -1518,13 +1518,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
-                    Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part_all_primitive.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part_all_primitive.q.out
index feff579ebe..b334b2d0f6 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part_all_primitive.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part_all_primitive.q.out
@@ -871,7 +871,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_various_various_date_n0
-                  Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:date, 2:c2:date, 3:c3:date, 4:c4:date, 5:b:string, 6:part:int, 7:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -882,13 +882,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 6, 1, 2, 3, 4, 5]
-                    Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part_all_primitive_llap_io.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part_all_primitive_llap_io.q.out
index bd7b4cf5f0..dc401b8986 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part_all_primitive_llap_io.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_orc_vec_part_all_primitive_llap_io.q.out
@@ -874,7 +874,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_various_various_date_n4
-                  Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:date, 2:c2:date, 3:c3:date, 4:c4:date, 5:b:string, 6:part:int, 7:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -885,13 +885,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 6, 1, 2, 3, 4, 5]
-                    Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part.q.out
index 817da4adb6..ffda0a3a0c 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part.q.out
@@ -752,14 +752,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_numeric_group_string_group_multi_ints_string_group_n8
-                  Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: string), c2 (type: string), c3 (type: string), c4 (type: string), c5 (type: char(50)), c6 (type: char(50)), c7 (type: char(50)), c8 (type: char(50)), c9 (type: char(5)), c10 (type: char(5)), c11 (type: char(5)), c12 (type: char(5)), c13 (type: varchar(50)), c14 (type: varchar(50)), c15 (type: varchar(50)), c16 (type: varchar(50)), c17 (type: varchar(5)), c18 (type: varchar(5)), c19 (type: varchar(5)), c20 (type: varchar(5)), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22
-                    Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1120,14 +1120,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_string_group_string_group_string_n8
-                  Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: char(50)), c2 (type: char(9)), c3 (type: varchar(50)), c4 (type: char(9)), c5 (type: varchar(50)), c6 (type: varchar(9)), c7 (type: string), c8 (type: char(50)), c9 (type: char(9)), c10 (type: string), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
-                    Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1325,14 +1325,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_lower_to_higher_numeric_group_tinyint_to_bigint_n8
-                  Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: smallint), c2 (type: int), c3 (type: bigint), c4 (type: decimal(38,18)), c5 (type: float), c6 (type: double), c7 (type: int), c8 (type: bigint), c9 (type: decimal(38,18)), c10 (type: float), c11 (type: double), c12 (type: bigint), c13 (type: decimal(38,18)), c14 (type: float), c15 (type: double), c16 (type: decimal(38,18)), c17 (type: float), c18 (type: double), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20
-                    Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_all_primitive.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_all_primitive.q.out
index 320cf27f55..66c33df8d6 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_all_primitive.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_all_primitive.q.out
@@ -793,14 +793,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_various_various_date_n2
-                  Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: date), c2 (type: date), c3 (type: date), c4 (type: date), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
-                    Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_all_primitive_llap_io.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_all_primitive_llap_io.q.out
index dc54812bdc..41063213ea 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_all_primitive_llap_io.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_all_primitive_llap_io.q.out
@@ -1000,14 +1000,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_various_various_date_n1
-                  Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: date), c2 (type: date), c3 (type: date), c4 (type: date), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
-                    Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_llap_io.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_llap_io.q.out
index b3b6659c4f..2605d5dbc8 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_llap_io.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_text_nonvec_part_llap_io.q.out
@@ -756,14 +756,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_numeric_group_string_group_multi_ints_string_group_n1
-                  Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: string), c2 (type: string), c3 (type: string), c4 (type: string), c5 (type: char(50)), c6 (type: char(50)), c7 (type: char(50)), c8 (type: char(50)), c9 (type: char(5)), c10 (type: char(5)), c11 (type: char(5)), c12 (type: char(5)), c13 (type: varchar(50)), c14 (type: varchar(50)), c15 (type: varchar(50)), c16 (type: varchar(50)), c17 (type: varchar(5)), c18 (type: varchar(5)), c19 (type: varchar(5)), c20 (type: varchar(5)), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22
-                    Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1126,14 +1126,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_string_group_string_group_string_n1
-                  Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: char(50)), c2 (type: char(9)), c3 (type: varchar(50)), c4 (type: char(9)), c5 (type: varchar(50)), c6 (type: varchar(9)), c7 (type: string), c8 (type: char(50)), c9 (type: char(9)), c10 (type: string), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
-                    Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1332,14 +1332,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_lower_to_higher_numeric_group_tinyint_to_bigint_n1
-                  Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: smallint), c2 (type: int), c3 (type: bigint), c4 (type: decimal(38,18)), c5 (type: float), c6 (type: double), c7 (type: int), c8 (type: bigint), c9 (type: decimal(38,18)), c10 (type: float), c11 (type: double), c12 (type: bigint), c13 (type: decimal(38,18)), c14 (type: float), c15 (type: double), c16 (type: decimal(38,18)), c17 (type: float), c18 (type: double), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20
-                    Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part.q.out
index 697206646b..b5a327c229 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part.q.out
@@ -856,7 +856,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_numeric_group_string_group_multi_ints_string_group_n10
-                  Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:string, 2:c2:string, 3:c3:string, 4:c4:string, 5:c5:char(50), 6:c6:char(50), 7:c7:char(50), 8:c8:char(50), 9:c9:char(5), 10:c10:char(5), 11:c11:char(5), 12:c12:char(5), 13:c13:varchar(50), 14:c14:varchar(50), 15:c15:varchar(50), 16:c16:varchar(50), 17:c17:varchar(5), 18:c18:varchar(5), 19:c19:varchar(5), 20:c20:varchar(5), 21:b:string, 22:part:int, 23:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -867,13 +867,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 22, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
-                    Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1276,7 +1276,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_string_group_string_group_string_n10
-                  Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:char(50), 2:c2:char(9), 3:c3:varchar(50), 4:c4:char(9), 5:c5:varchar(50), 6:c6:varchar(9), 7:c7:string, 8:c8:char(50), 9:c9:char(9), 10:c10:string, 11:b:string, 12:part:int, 13:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -1287,13 +1287,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
-                    Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1507,7 +1507,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_lower_to_higher_numeric_group_tinyint_to_bigint_n10
-                  Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:smallint, 2:c2:int, 3:c3:bigint, 4:c4:decimal(38,18), 5:c5:float, 6:c6:double, 7:c7:int, 8:c8:bigint, 9:c9:decimal(38,18), 10:c10:float, 11:c11:double, 12:c12:bigint, 13:c13:decimal(38,18), 14:c14:float, 15:c15:double, 16:c16:decimal(38,18), 17:c17:float, 18:c18:double, 19:b:string, 20:part:int, 21:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -1518,13 +1518,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
-                    Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part_all_primitive.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part_all_primitive.q.out
index 89331389a3..d259074075 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part_all_primitive.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part_all_primitive.q.out
@@ -871,7 +871,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_various_various_date_n8
-                  Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:date, 2:c2:date, 3:c3:date, 4:c4:date, 5:b:string, 6:part:int, 7:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -882,13 +882,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 6, 1, 2, 3, 4, 5]
-                    Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part_all_primitive_llap_io.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part_all_primitive_llap_io.q.out
index 56378df241..bad1f3947a 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part_all_primitive_llap_io.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_text_vec_part_all_primitive_llap_io.q.out
@@ -1119,14 +1119,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_various_various_date_n3
-                  Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: date), c2 (type: date), c3 (type: date), c4 (type: date), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
-                    Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part.q.out
index c9a748c207..805e7d08f4 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part.q.out
@@ -856,7 +856,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_numeric_group_string_group_multi_ints_string_group_n11
-                  Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:string, 2:c2:string, 3:c3:string, 4:c4:string, 5:c5:char(50), 6:c6:char(50), 7:c7:char(50), 8:c8:char(50), 9:c9:char(5), 10:c10:char(5), 11:c11:char(5), 12:c12:char(5), 13:c13:varchar(50), 14:c14:varchar(50), 15:c15:varchar(50), 16:c16:varchar(50), 17:c17:varchar(5), 18:c18:varchar(5), 19:c19:varchar(5), 20:c20:varchar(5), 21:b:string, 22:part:int, 23:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -867,13 +867,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 22, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
-                    Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1276,7 +1276,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_string_group_string_group_string_n11
-                  Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:char(50), 2:c2:char(9), 3:c3:varchar(50), 4:c4:char(9), 5:c5:varchar(50), 6:c6:varchar(9), 7:c7:string, 8:c8:char(50), 9:c9:char(9), 10:c10:string, 11:b:string, 12:part:int, 13:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -1287,13 +1287,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
-                    Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1507,7 +1507,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_lower_to_higher_numeric_group_tinyint_to_bigint_n11
-                  Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:smallint, 2:c2:int, 3:c3:bigint, 4:c4:decimal(38,18), 5:c5:float, 6:c6:double, 7:c7:int, 8:c8:bigint, 9:c9:decimal(38,18), 10:c10:float, 11:c11:double, 12:c12:bigint, 13:c13:decimal(38,18), 14:c14:float, 15:c15:double, 16:c16:decimal(38,18), 17:c17:float, 18:c18:double, 19:b:string, 20:part:int, 21:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -1518,13 +1518,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
-                    Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_all_primitive.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_all_primitive.q.out
index d5836f4570..87fb12525b 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_all_primitive.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_all_primitive.q.out
@@ -871,7 +871,7 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_various_various_date_n7
-                  Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:insert_num:int, 1:c1:date, 2:c2:date, 3:c3:date, 4:c4:date, 5:b:string, 6:part:int, 7:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
@@ -882,13 +882,13 @@ STAGE PLANS:
                         className: VectorSelectOperator
                         native: true
                         projectedOutputColumnNums: [0, 6, 1, 2, 3, 4, 5]
-                    Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
                       File Sink Vectorization:
                           className: VectorFileSinkOperator
                           native: false
-                      Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_all_primitive_llap_io.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_all_primitive_llap_io.q.out
index 06c66ba7c4..3dc7e540d7 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_all_primitive_llap_io.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_all_primitive_llap_io.q.out
@@ -1032,14 +1032,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_various_various_date
-                  Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: date), c2 (type: date), c3 (type: date), c4 (type: date), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
-                    Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_llap_io.q.out b/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_llap_io.q.out
index 4b3406d00d..01a5ba355d 100644
--- a/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_llap_io.q.out
+++ b/ql/src/test/results/clientpositive/llap/schema_evol_text_vecrow_part_llap_io.q.out
@@ -614,14 +614,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_string_group_double
-                  Statistics: Num rows: 5 Data size: 1955 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 5 Data size: 500 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: double), c2 (type: double), c3 (type: double), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                    Statistics: Num rows: 5 Data size: 1955 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 5 Data size: 500 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 5 Data size: 1955 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 5 Data size: 500 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -829,14 +829,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_date_group_string_group_date_timestamp
-                  Statistics: Num rows: 6 Data size: 3480 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: string), c2 (type: char(50)), c3 (type: char(15)), c4 (type: varchar(50)), c5 (type: varchar(15)), c6 (type: string), c7 (type: char(50)), c8 (type: char(15)), c9 (type: varchar(50)), c10 (type: varchar(15)), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
-                    Statistics: Num rows: 6 Data size: 3480 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 3480 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1096,14 +1096,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_numeric_group_string_group_multi_ints_string_group
-                  Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: string), c2 (type: string), c3 (type: string), c4 (type: string), c5 (type: char(50)), c6 (type: char(50)), c7 (type: char(50)), c8 (type: char(50)), c9 (type: char(5)), c10 (type: char(5)), c11 (type: char(5)), c12 (type: char(5)), c13 (type: varchar(50)), c14 (type: varchar(50)), c15 (type: varchar(50)), c16 (type: varchar(50)), c17 (type: varchar(5)), c18 (type: varchar(5)), c19 (type: varchar(5)), c20 (type: varchar(5)), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20, _col21, _col22
-                    Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 1140 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1596,14 +1596,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_string_group_string_group_string
-                  Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: char(50)), c2 (type: char(9)), c3 (type: varchar(50)), c4 (type: char(9)), c5 (type: varchar(50)), c6 (type: varchar(9)), c7 (type: string), c8 (type: char(50)), c9 (type: char(9)), c10 (type: string), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12
-                    Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 2712 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1867,14 +1867,14 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: part_change_lower_to_higher_numeric_group_tinyint_to_bigint
-                  Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                  Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                   Select Operator
                     expressions: insert_num (type: int), part (type: int), c1 (type: smallint), c2 (type: int), c3 (type: bigint), c4 (type: decimal(38,18)), c5 (type: float), c6 (type: double), c7 (type: int), c8 (type: bigint), c9 (type: decimal(38,18)), c10 (type: float), c11 (type: double), c12 (type: bigint), c13 (type: decimal(38,18)), c14 (type: float), c15 (type: double), c16 (type: decimal(38,18)), c17 (type: float), c18 (type: double), b (type: string)
                     outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20
-                    Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                    Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                     File Output Operator
                       compressed: false
-                      Statistics: Num rows: 6 Data size: 1060 Basic stats: COMPLETE Column stats: COMPLETE
+                      Statistics: Num rows: 6 Data size: 600 Basic stats: COMPLETE Column stats: PARTIAL
                       table:
                           input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/load_dyn_part1.q.out b/ql/src/test/results/clientpositive/load_dyn_part1.q.out
index 6739b85520..0f042b9e57 100644
--- a/ql/src/test/results/clientpositive/load_dyn_part1.q.out
+++ b/ql/src/test/results/clientpositive/load_dyn_part1.q.out
@@ -82,17 +82,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             Filter Operator
               predicate: (ds <= '2008-04-08') (type: boolean)
-              Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                 outputColumnNames: _col0, _col1, _col2, _col3
-                Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -101,29 +101,29 @@ STAGE PLANS:
                 Select Operator
                   expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                   outputColumnNames: key, value, ds, hr
-                  Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
                   Group By Operator
                     aggregations: compute_stats(key, 'hll'), compute_stats(value, 'hll')
                     keys: ds (type: string), hr (type: string)
                     mode: hash
                     outputColumnNames: _col0, _col1, _col2, _col3
-                    Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
                     Reduce Output Operator
                       key expressions: _col0 (type: string), _col1 (type: string)
                       sort order: ++
                       Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
-                      Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
                       value expressions: _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
             Filter Operator
               predicate: (ds > '2008-04-08') (type: boolean)
-              Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: string), value (type: string), hr (type: string)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 666 Data size: 241092 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 666 Data size: 241092 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 666 Data size: 241092 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 666 Data size: 241092 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -132,13 +132,13 @@ STAGE PLANS:
                 Select Operator
                   expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)
                   outputColumnNames: key, value, hr
-                  Statistics: Num rows: 666 Data size: 303696 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 666 Data size: 303696 Basic stats: COMPLETE Column stats: COMPLETE
                   Group By Operator
                     aggregations: compute_stats(key, 'hll'), compute_stats(value, 'hll')
                     keys: '2008-12-31' (type: string), hr (type: string)
                     mode: hash
                     outputColumnNames: _col0, _col1, _col2, _col3
-                    Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
                     File Output Operator
                       compressed: false
                       table:
@@ -151,14 +151,14 @@ STAGE PLANS:
           keys: KEY._col0 (type: string), KEY._col1 (type: string)
           mode: mergepartial
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col0 (type: string), _col1 (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -253,7 +253,7 @@ STAGE PLANS:
               key expressions: '2008-12-31' (type: string), _col1 (type: string)
               sort order: ++
               Map-reduce partition columns: '2008-12-31' (type: string), _col1 (type: string)
-              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
               value expressions: _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
       Execution mode: vectorized
       Reduce Operator Tree:
@@ -262,14 +262,14 @@ STAGE PLANS:
           keys: '2008-12-31' (type: string), KEY._col1 (type: string)
           mode: mergepartial
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), '2008-12-31' (type: string), _col1 (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/load_dyn_part2.q.out b/ql/src/test/results/clientpositive/load_dyn_part2.q.out
index caed4e71ce..b50b1c369d 100644
--- a/ql/src/test/results/clientpositive/load_dyn_part2.q.out
+++ b/ql/src/test/results/clientpositive/load_dyn_part2.q.out
@@ -57,25 +57,25 @@ STAGE PLANS:
           TableScan
             alias: srcpart
             filterExpr: (ds is not null and hr is not null) (type: boolean)
-            Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: COMPLETE
             Select Operator
               expressions: key (type: string), value (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2
-              Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 sort order: 
                 Map-reduce partition columns: _col0 (type: string)
-                Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: COMPLETE
                 value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)
       Execution mode: vectorized
       Reduce Operator Tree:
         Select Operator
           expressions: VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string)
           outputColumnNames: _col0, _col1, _col2
-          Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
-            Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: COMPLETE
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -84,13 +84,13 @@ STAGE PLANS:
           Select Operator
             expressions: _col0 (type: string), _col1 (type: string), '2010-03-23' (type: string), _col2 (type: string)
             outputColumnNames: key, value, ds, hr
-            Statistics: Num rows: 2000 Data size: 912000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 912000 Basic stats: COMPLETE Column stats: COMPLETE
             Group By Operator
               aggregations: compute_stats(key, 'hll'), compute_stats(value, 'hll')
               keys: ds (type: string), hr (type: string)
               mode: hash
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
               File Output Operator
                 compressed: false
                 table:
@@ -127,7 +127,7 @@ STAGE PLANS:
               key expressions: _col0 (type: string), _col1 (type: string)
               sort order: ++
               Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
-              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
               value expressions: _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
       Execution mode: vectorized
       Reduce Operator Tree:
@@ -136,14 +136,14 @@ STAGE PLANS:
           keys: KEY._col0 (type: string), KEY._col1 (type: string)
           mode: mergepartial
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col0 (type: string), _col1 (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/load_dyn_part3.q.out b/ql/src/test/results/clientpositive/load_dyn_part3.q.out
index c3f6f26945..cf1ece47eb 100644
--- a/ql/src/test/results/clientpositive/load_dyn_part3.q.out
+++ b/ql/src/test/results/clientpositive/load_dyn_part3.q.out
@@ -62,14 +62,14 @@ STAGE PLANS:
           TableScan
             alias: srcpart
             filterExpr: (ds is not null and hr is not null) (type: boolean)
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             Select Operator
               expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
               File Output Operator
                 compressed: false
-                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -78,18 +78,18 @@ STAGE PLANS:
               Select Operator
                 expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                 outputColumnNames: key, value, ds, hr
-                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
                 Group By Operator
                   aggregations: compute_stats(key, 'hll'), compute_stats(value, 'hll')
                   keys: ds (type: string), hr (type: string)
                   mode: hash
                   outputColumnNames: _col0, _col1, _col2, _col3
-                  Statistics: Num rows: 4 Data size: 4992 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 4 Data size: 4992 Basic stats: COMPLETE Column stats: COMPLETE
                   Reduce Output Operator
                     key expressions: _col0 (type: string), _col1 (type: string)
                     sort order: ++
                     Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
-                    Statistics: Num rows: 4 Data size: 4992 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 4 Data size: 4992 Basic stats: COMPLETE Column stats: COMPLETE
                     value expressions: _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
       Reduce Operator Tree:
         Group By Operator
@@ -97,14 +97,14 @@ STAGE PLANS:
           keys: KEY._col0 (type: string), KEY._col1 (type: string)
           mode: mergepartial
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 4 Data size: 4992 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 4 Data size: 4992 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col0 (type: string), _col1 (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 4 Data size: 4992 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 4 Data size: 4992 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 4 Data size: 4992 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 4 Data size: 4992 Basic stats: COMPLETE Column stats: COMPLETE
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/masking_disablecbo_1.q.out b/ql/src/test/results/clientpositive/masking_disablecbo_1.q.out
index 8f77424e92..fd0e6fbdb9 100644
--- a/ql/src/test/results/clientpositive/masking_disablecbo_1.q.out
+++ b/ql/src/test/results/clientpositive/masking_disablecbo_1.q.out
@@ -271,15 +271,15 @@ STAGE PLANS:
           TableScan
             alias: srcpart
             filterExpr: UDFToDouble(key) is not null (type: boolean)
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             Filter Operator
               predicate: UDFToDouble(key) is not null (type: boolean)
-              Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: UDFToDouble(key) (type: double)
                 sort order: +
                 Map-reduce partition columns: UDFToDouble(key) (type: double)
-                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
                 value expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
       Reduce Operator Tree:
         Join Operator
@@ -289,14 +289,14 @@ STAGE PLANS:
             0 UDFToDouble(_col0) (type: double)
             1 UDFToDouble(key) (type: double)
           outputColumnNames: _col0, _col1, _col5, _col6, _col7, _col8
-          Statistics: Num rows: 525 Data size: 385350 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 525 Data size: 385350 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: _col0 (type: int), _col1 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-            Statistics: Num rows: 525 Data size: 385350 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 525 Data size: 385350 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 525 Data size: 385350 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 525 Data size: 385350 Basic stats: COMPLETE Column stats: COMPLETE
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/nonmr_fetch.q.out b/ql/src/test/results/clientpositive/nonmr_fetch.q.out
index 64875f4059..82ae686fe0 100644
--- a/ql/src/test/results/clientpositive/nonmr_fetch.q.out
+++ b/ql/src/test/results/clientpositive/nonmr_fetch.q.out
@@ -239,20 +239,20 @@ STAGE PLANS:
           TableScan
             alias: srcpart
             filterExpr: (UDFToDouble(key) > 100.0D) (type: boolean)
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             Filter Operator
               predicate: (UDFToDouble(key) > 100.0D) (type: boolean)
-              Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                 outputColumnNames: _col0, _col1, _col2, _col3
-                Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
                 Limit
                   Number of rows: 10
-                  Statistics: Num rows: 10 Data size: 5460 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 10 Data size: 5460 Basic stats: COMPLETE Column stats: COMPLETE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 10 Data size: 5460 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 10 Data size: 5460 Basic stats: COMPLETE Column stats: COMPLETE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/offset_limit_global_optimizer.q.out b/ql/src/test/results/clientpositive/offset_limit_global_optimizer.q.out
index c88346815c..e29ca9d7bc 100644
--- a/ql/src/test/results/clientpositive/offset_limit_global_optimizer.q.out
+++ b/ql/src/test/results/clientpositive/offset_limit_global_optimizer.q.out
@@ -31,17 +31,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: key (type: string), substr(value, 5) (type: string), ds (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                 null sort order: zzzz
                 sort order: ++++
-                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
                 tag: -1
                 TopN: 410
                 TopN Hash Memory Usage: 0.1
@@ -256,17 +256,17 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey3 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
           Limit
             Number of rows: 10
             Offset of rows: 400
-            Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
 #### A masked pattern was here ####
               NumFilesPerFileSink: 1
-              Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -349,17 +349,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: key (type: string), substr(value, 5) (type: string), ds (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                 null sort order: zzzz
                 sort order: ++++
-                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
                 tag: -1
                 TopN: 500
                 TopN Hash Memory Usage: 0.1
@@ -574,17 +574,17 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey3 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
           Limit
             Number of rows: 10
             Offset of rows: 490
-            Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
 #### A masked pattern was here ####
               NumFilesPerFileSink: 1
-              Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -667,17 +667,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: key (type: string), substr(value, 5) (type: string), ds (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                 null sort order: zzzz
                 sort order: ++++
-                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
                 tag: -1
                 TopN: 510
                 TopN Hash Memory Usage: 0.1
@@ -892,17 +892,17 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey3 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
           Limit
             Number of rows: 20
             Offset of rows: 490
-            Statistics: Num rows: 20 Data size: 12780 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 20 Data size: 12780 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
 #### A masked pattern was here ####
               NumFilesPerFileSink: 1
-              Statistics: Num rows: 20 Data size: 12780 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 20 Data size: 12780 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -995,17 +995,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: key (type: string), substr(value, 5) (type: string), ds (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                 null sort order: zzzz
                 sort order: ++++
-                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
                 tag: -1
                 TopN: 1090
                 TopN Hash Memory Usage: 0.1
@@ -1220,17 +1220,17 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey3 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
           Limit
             Number of rows: 600
             Offset of rows: 490
-            Statistics: Num rows: 600 Data size: 383400 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 600 Data size: 383400 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
 #### A masked pattern was here ####
               NumFilesPerFileSink: 1
-              Statistics: Num rows: 600 Data size: 383400 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 600 Data size: 383400 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -1898,17 +1898,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: key (type: string), substr(value, 5) (type: string), ds (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                 null sort order: zzzz
                 sort order: ++++
-                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
                 tag: -1
                 TopN: 410
                 TopN Hash Memory Usage: 0.1
@@ -2123,17 +2123,17 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey3 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
           Limit
             Number of rows: 10
             Offset of rows: 400
-            Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
 #### A masked pattern was here ####
               NumFilesPerFileSink: 1
-              Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -2211,17 +2211,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: key (type: string), substr(value, 5) (type: string), ds (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                 null sort order: zzzz
                 sort order: ++++
-                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
                 tag: -1
                 TopN: 500
                 TopN Hash Memory Usage: 0.1
@@ -2436,17 +2436,17 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey3 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
           Limit
             Number of rows: 10
             Offset of rows: 490
-            Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
 #### A masked pattern was here ####
               NumFilesPerFileSink: 1
-              Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 10 Data size: 6390 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -2524,17 +2524,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: key (type: string), substr(value, 5) (type: string), ds (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                 null sort order: zzzz
                 sort order: ++++
-                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
                 tag: -1
                 TopN: 510
                 TopN Hash Memory Usage: 0.1
@@ -2749,17 +2749,17 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey3 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
           Limit
             Number of rows: 20
             Offset of rows: 490
-            Statistics: Num rows: 20 Data size: 12780 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 20 Data size: 12780 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
 #### A masked pattern was here ####
               NumFilesPerFileSink: 1
-              Statistics: Num rows: 20 Data size: 12780 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 20 Data size: 12780 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -2847,17 +2847,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: key (type: string), substr(value, 5) (type: string), ds (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                 null sort order: zzzz
                 sort order: ++++
-                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
                 tag: -1
                 TopN: 1090
                 TopN Hash Memory Usage: 0.1
@@ -3072,17 +3072,17 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey3 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 1278000 Basic stats: COMPLETE Column stats: COMPLETE
           Limit
             Number of rows: 600
             Offset of rows: 490
-            Statistics: Num rows: 600 Data size: 383400 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 600 Data size: 383400 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
 #### A masked pattern was here ####
               NumFilesPerFileSink: 1
-              Statistics: Num rows: 600 Data size: 383400 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 600 Data size: 383400 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
diff --git a/ql/src/test/results/clientpositive/outer_join_ppr.q.out b/ql/src/test/results/clientpositive/outer_join_ppr.q.out
index 73e696cb41..3fc678d5ca 100644
--- a/ql/src/test/results/clientpositive/outer_join_ppr.q.out
+++ b/ql/src/test/results/clientpositive/outer_join_ppr.q.out
@@ -66,22 +66,22 @@ STAGE PLANS:
           TableScan
             alias: b
             filterExpr: ((UDFToDouble(key) > 15.0D) and (UDFToDouble(key) < 20.0D)) (type: boolean)
-            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: ((UDFToDouble(key) < 20.0D) and (UDFToDouble(key) > 15.0D)) (type: boolean)
-              Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: string), value (type: string)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: string)
                   null sort order: a
                   sort order: +
                   Map-reduce partition columns: _col0 (type: string)
-                  Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: 1
                   value expressions: _col1 (type: string)
                   auto parallelism: false
@@ -247,13 +247,13 @@ STAGE PLANS:
             0 _col0 (type: string)
             1 _col0 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 55 Data size: 19580 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 55 Data size: 19580 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 55 Data size: 19580 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 55 Data size: 19580 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -383,22 +383,22 @@ STAGE PLANS:
           TableScan
             alias: b
             filterExpr: ((UDFToDouble(key) > 15.0D) and (UDFToDouble(key) < 20.0D)) (type: boolean)
-            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: ((UDFToDouble(key) < 20.0D) and (UDFToDouble(key) > 15.0D)) (type: boolean)
-              Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: string), value (type: string)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: string)
                   null sort order: a
                   sort order: +
                   Map-reduce partition columns: _col0 (type: string)
-                  Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 111 Data size: 19758 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: 1
                   value expressions: _col1 (type: string)
                   auto parallelism: false
@@ -564,13 +564,13 @@ STAGE PLANS:
             0 _col0 (type: string)
             1 _col0 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 55 Data size: 19580 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 55 Data size: 19580 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 55 Data size: 19580 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 55 Data size: 19580 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
diff --git a/ql/src/test/results/clientpositive/pcr.q.out b/ql/src/test/results/clientpositive/pcr.q.out
index f8fe477e6b..30177fadc6 100644
--- a/ql/src/test/results/clientpositive/pcr.q.out
+++ b/ql/src/test/results/clientpositive/pcr.q.out
@@ -282,21 +282,21 @@ STAGE PLANS:
           TableScan
             alias: pcr_t1
             filterExpr: ((ds <= '2000-04-09') or (key < 5)) (type: boolean)
-            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: ((ds <= '2000-04-09') or (key < 5)) (type: boolean)
-              Statistics: Num rows: 40 Data size: 11120 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 40 Data size: 11120 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: int), value (type: string)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 40 Data size: 3760 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 40 Data size: 3760 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: int)
                   null sort order: z
                   sort order: +
-                  Statistics: Num rows: 40 Data size: 3760 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 40 Data size: 3760 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: -1
                   value expressions: _col1 (type: string)
                   auto parallelism: false
@@ -457,13 +457,13 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string)
           outputColumnNames: _col0, _col1
-          Statistics: Num rows: 40 Data size: 3760 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 40 Data size: 3760 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 40 Data size: 3760 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 40 Data size: 3760 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -991,21 +991,21 @@ STAGE PLANS:
           TableScan
             alias: pcr_t1
             filterExpr: (((ds < '2000-04-10') and (key < 5)) or ((ds > '2000-04-08') and (value = 'val_5'))) (type: boolean)
-            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: (((ds < '2000-04-10') and (key < 5)) or ((ds > '2000-04-08') and (value = 'val_5'))) (type: boolean)
-              Statistics: Num rows: 8 Data size: 2224 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 8 Data size: 2224 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: int), value (type: string), ds (type: string)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 8 Data size: 2224 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 8 Data size: 2224 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: int), _col2 (type: string)
                   null sort order: zz
                   sort order: ++
-                  Statistics: Num rows: 8 Data size: 2224 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 8 Data size: 2224 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: -1
                   value expressions: _col1 (type: string)
                   auto parallelism: false
@@ -1166,13 +1166,13 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string), KEY.reducesinkkey1 (type: string)
           outputColumnNames: _col0, _col1, _col2
-          Statistics: Num rows: 8 Data size: 2224 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 8 Data size: 2224 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 8 Data size: 2224 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 8 Data size: 2224 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -1261,21 +1261,21 @@ STAGE PLANS:
           TableScan
             alias: pcr_t1
             filterExpr: (((ds < '2000-04-10') or (key < 5)) and ((ds > '2000-04-08') or (value = 'val_5'))) (type: boolean)
-            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: (((ds < '2000-04-10') or (key < 5)) and ((ds > '2000-04-08') or (value = 'val_5'))) (type: boolean)
-              Statistics: Num rows: 16 Data size: 4448 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 16 Data size: 4448 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: int), value (type: string), ds (type: string)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 16 Data size: 4448 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 16 Data size: 4448 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: int), _col2 (type: string)
                   null sort order: zz
                   sort order: ++
-                  Statistics: Num rows: 16 Data size: 4448 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 16 Data size: 4448 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: -1
                   value expressions: _col1 (type: string)
                   auto parallelism: false
@@ -1436,13 +1436,13 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: string), KEY.reducesinkkey1 (type: string)
           outputColumnNames: _col0, _col1, _col2
-          Statistics: Num rows: 16 Data size: 4448 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 16 Data size: 4448 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 16 Data size: 4448 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 16 Data size: 4448 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -1955,17 +1955,17 @@ STAGE PLANS:
           TableScan
             alias: pcr_t1
             filterExpr: ((ds >= '2000-04-08') or ds is not null) (type: boolean)
-            Statistics: Num rows: 60 Data size: 5640 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 5640 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Select Operator
               expressions: key (type: int), value (type: string)
               outputColumnNames: _col0, _col1
-              Statistics: Num rows: 60 Data size: 5640 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 60 Data size: 5640 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: _col0 (type: int), _col1 (type: string)
                 null sort order: zz
                 sort order: ++
-                Statistics: Num rows: 60 Data size: 5640 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 60 Data size: 5640 Basic stats: COMPLETE Column stats: COMPLETE
                 tag: -1
                 auto parallelism: false
       Execution mode: vectorized
@@ -2125,13 +2125,13 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
           outputColumnNames: _col0, _col1
-          Statistics: Num rows: 60 Data size: 5640 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 60 Data size: 5640 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 60 Data size: 5640 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 5640 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -3066,21 +3066,21 @@ STAGE PLANS:
           TableScan
             alias: pcr_t1
             filterExpr: (((ds > '2000-04-08') and (ds < '2000-04-11')) or (key = 2)) (type: boolean)
-            Statistics: Num rows: 80 Data size: 22240 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 80 Data size: 22240 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: (((ds > '2000-04-08') and (ds < '2000-04-11')) or (key = 2)) (type: boolean)
-              Statistics: Num rows: 14 Data size: 3892 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 14 Data size: 3892 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: int), value (type: string), ds (type: string)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 14 Data size: 3892 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 14 Data size: 3892 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
                   null sort order: zzz
                   sort order: +++
-                  Statistics: Num rows: 14 Data size: 3892 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 14 Data size: 3892 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: -1
                   auto parallelism: false
       Execution mode: vectorized
@@ -3289,13 +3289,13 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string)
           outputColumnNames: _col0, _col1, _col2
-          Statistics: Num rows: 14 Data size: 3892 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 14 Data size: 3892 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 14 Data size: 3892 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 14 Data size: 3892 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -3406,21 +3406,21 @@ STAGE PLANS:
           TableScan
             alias: pcr_t1
             filterExpr: ((ds > '2000-04-08') or ((ds <= '2000-04-09') and (key = 2))) (type: boolean)
-            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: (((ds <= '2000-04-09') and (key = 2)) or (ds > '2000-04-08')) (type: boolean)
-              Statistics: Num rows: 22 Data size: 6116 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 22 Data size: 6116 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: int), value (type: string), ds (type: string)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 22 Data size: 6116 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 22 Data size: 6116 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
                   null sort order: zzz
                   sort order: +++
-                  Statistics: Num rows: 22 Data size: 6116 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 22 Data size: 6116 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: -1
                   auto parallelism: false
       Execution mode: vectorized
@@ -3580,13 +3580,13 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string)
           outputColumnNames: _col0, _col1, _col2
-          Statistics: Num rows: 22 Data size: 6116 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 22 Data size: 6116 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 22 Data size: 6116 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 22 Data size: 6116 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -5059,21 +5059,21 @@ STAGE PLANS:
           TableScan
             alias: srcpart
             filterExpr: ((hr) IN ('11', '12') and (ds = '2008-04-08') and (UDFToDouble(key) = 11.0D)) (type: boolean)
-            Statistics: Num rows: 1000 Data size: 362000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1000 Data size: 362000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: (UDFToDouble(key) = 11.0D) (type: boolean)
-              Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: string), value (type: string), hr (type: string)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: string), _col2 (type: string)
                   null sort order: zz
                   sort order: ++
-                  Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: -1
                   value expressions: _col1 (type: string)
                   auto parallelism: false
@@ -5187,13 +5187,13 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string), '2008-04-08' (type: string), KEY.reducesinkkey1 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 500 Data size: 228000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 500 Data size: 228000 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 500 Data size: 228000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 500 Data size: 228000 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -5259,21 +5259,21 @@ STAGE PLANS:
           TableScan
             alias: srcpart
             filterExpr: ((hr = '11') and (UDFToDouble(key) = 11.0D)) (type: boolean)
-            Statistics: Num rows: 1000 Data size: 362000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1000 Data size: 362000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: (UDFToDouble(key) = 11.0D) (type: boolean)
-              Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: string), value (type: string), ds (type: string)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: string), _col2 (type: string)
                   null sort order: zz
                   sort order: ++
-                  Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 500 Data size: 181000 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: -1
                   value expressions: _col1 (type: string)
                   auto parallelism: false
@@ -5387,13 +5387,13 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string), KEY.reducesinkkey1 (type: string), '11' (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 500 Data size: 224000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 500 Data size: 224000 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 500 Data size: 224000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 500 Data size: 224000 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -5682,11 +5682,11 @@ STAGE PLANS:
         TableScan
           alias: srcpart
           filterExpr: (11.0D = 11.0D) (type: boolean)
-          Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: key (type: string), value (type: string)
             outputColumnNames: _col0, _col1
-            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
 PREHOOK: query: explain select key,value from srcpart where hr  = cast(11 as double)
@@ -5712,11 +5712,11 @@ STAGE PLANS:
         TableScan
           alias: srcpart
           filterExpr: (11.0D = 11.0D) (type: boolean)
-          Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: key (type: string), value (type: string)
             outputColumnNames: _col0, _col1
-            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
 PREHOOK: query: explain select key,value from srcpart where cast(hr as double)  = 11
@@ -5742,10 +5742,10 @@ STAGE PLANS:
         TableScan
           alias: srcpart
           filterExpr: (11.0D = 11.0D) (type: boolean)
-          Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: key (type: string), value (type: string)
             outputColumnNames: _col0, _col1
-            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1000 Data size: 178000 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
diff --git a/ql/src/test/results/clientpositive/pcs.q.out b/ql/src/test/results/clientpositive/pcs.q.out
index 1923af78a7..b6c22125f3 100644
--- a/ql/src/test/results/clientpositive/pcs.q.out
+++ b/ql/src/test/results/clientpositive/pcs.q.out
@@ -1560,22 +1560,22 @@ STAGE PLANS:
           TableScan
             alias: pcs_t1
             filterExpr: (struct(key,((ds = '2000-04-08') or (key = 2)))) IN (const struct(2,true), const struct(3,false)) (type: boolean)
-            Statistics: Num rows: 60 Data size: 11280 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 11280 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: (struct(key,((ds = '2000-04-08') or (key = 2)))) IN (const struct(2,true), const struct(3,false)) (type: boolean)
-              Statistics: Num rows: 30 Data size: 5640 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 30 Data size: 5640 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: ds (type: string)
                 outputColumnNames: _col0
-                Statistics: Num rows: 30 Data size: 5520 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 30 Data size: 5520 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
 #### A masked pattern was here ####
                   NumFilesPerFileSink: 1
-                  Statistics: Num rows: 30 Data size: 5520 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 30 Data size: 5520 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -1792,22 +1792,22 @@ STAGE PLANS:
           TableScan
             alias: pcs_t1
             filterExpr: ((key = 3) or ((struct(key,((ds = '2000-04-08') or (key = 2)))) IN (const struct(2,true), const struct(3,false)) and ((key + 5) > 0))) (type: boolean)
-            Statistics: Num rows: 60 Data size: 11280 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 11280 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: (((struct(key,((ds = '2000-04-08') or (key = 2)))) IN (const struct(2,true), const struct(3,false)) and ((key + 5) > 0)) or (key = 3)) (type: boolean)
-              Statistics: Num rows: 15 Data size: 2820 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 15 Data size: 2820 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: ds (type: string)
                 outputColumnNames: _col0
-                Statistics: Num rows: 15 Data size: 2760 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 15 Data size: 2760 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
 #### A masked pattern was here ####
                   NumFilesPerFileSink: 1
-                  Statistics: Num rows: 15 Data size: 2760 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 15 Data size: 2760 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
diff --git a/ql/src/test/results/clientpositive/pointlookup2.q.out b/ql/src/test/results/clientpositive/pointlookup2.q.out
index fcfb40faac..5a1f92758a 100644
--- a/ql/src/test/results/clientpositive/pointlookup2.q.out
+++ b/ql/src/test/results/clientpositive/pointlookup2.q.out
@@ -1172,20 +1172,20 @@ STAGE PLANS:
           TableScan
             alias: t1
             filterExpr: ((key = 1) or (key = 2)) (type: boolean)
-            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: ((key = 1) or (key = 2)) (type: boolean)
-              Statistics: Num rows: 10 Data size: 2780 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 10 Data size: 2780 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: int), value (type: string), ds (type: string), (key = 1) (type: boolean), (key = 2) (type: boolean)
                 outputColumnNames: _col0, _col1, _col2, _col3, _col4
-                Statistics: Num rows: 10 Data size: 2860 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 10 Data size: 2860 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   null sort order: 
                   sort order: 
-                  Statistics: Num rows: 10 Data size: 2860 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 10 Data size: 2860 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: 0
                   value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string), _col3 (type: boolean), _col4 (type: boolean)
                   auto parallelism: false
@@ -1418,15 +1418,15 @@ STAGE PLANS:
             0 
             1 
           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
-          Statistics: Num rows: 10 Data size: 4810 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 10 Data size: 4810 Basic stats: COMPLETE Column stats: COMPLETE
           Filter Operator
             isSamplingPred: false
             predicate: ((_col8 and _col3) or (_col9 and _col4)) (type: boolean)
-            Statistics: Num rows: 4 Data size: 1924 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 4 Data size: 1924 Basic stats: COMPLETE Column stats: COMPLETE
             Select Operator
               expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string), _col5 (type: string), _col6 (type: int), _col7 (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-              Statistics: Num rows: 4 Data size: 1860 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 4 Data size: 1860 Basic stats: COMPLETE Column stats: COMPLETE
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
@@ -1455,7 +1455,7 @@ STAGE PLANS:
               key expressions: _col0 (type: int), _col1 (type: string), _col3 (type: string)
               null sort order: zzz
               sort order: +++
-              Statistics: Num rows: 4 Data size: 1860 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 4 Data size: 1860 Basic stats: COMPLETE Column stats: COMPLETE
               tag: -1
               value expressions: _col2 (type: string), _col4 (type: int), _col5 (type: string)
               auto parallelism: false
@@ -1492,13 +1492,13 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: string), KEY.reducesinkkey2 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-          Statistics: Num rows: 4 Data size: 1860 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 4 Data size: 1860 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 4 Data size: 1860 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 4 Data size: 1860 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -2778,20 +2778,20 @@ STAGE PLANS:
           TableScan
             alias: t1
             filterExpr: (key) IN (1, 2) (type: boolean)
-            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 16680 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: (key) IN (1, 2) (type: boolean)
-              Statistics: Num rows: 9 Data size: 2502 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 9 Data size: 2502 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: int), value (type: string), ds (type: string)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 9 Data size: 2502 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 9 Data size: 2502 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   null sort order: 
                   sort order: 
-                  Statistics: Num rows: 9 Data size: 2502 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 9 Data size: 2502 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: 0
                   value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string)
                   auto parallelism: false
@@ -3024,11 +3024,11 @@ STAGE PLANS:
             0 
             1 
           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-          Statistics: Num rows: 9 Data size: 4185 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 9 Data size: 4185 Basic stats: COMPLETE Column stats: COMPLETE
           Filter Operator
             isSamplingPred: false
             predicate: (struct(_col0,_col3)) IN (const struct(1,'2000-04-08'), const struct(2,'2000-04-09')) (type: boolean)
-            Statistics: Num rows: 9 Data size: 4185 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 9 Data size: 4185 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -3057,7 +3057,7 @@ STAGE PLANS:
               key expressions: _col0 (type: int), _col1 (type: string), _col3 (type: string)
               null sort order: zzz
               sort order: +++
-              Statistics: Num rows: 9 Data size: 4185 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 9 Data size: 4185 Basic stats: COMPLETE Column stats: COMPLETE
               tag: -1
               value expressions: _col2 (type: string), _col4 (type: int), _col5 (type: string)
               auto parallelism: false
@@ -3094,13 +3094,13 @@ STAGE PLANS:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: string), KEY.reducesinkkey2 (type: string), VALUE._col1 (type: int), VALUE._col2 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-          Statistics: Num rows: 9 Data size: 4185 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 9 Data size: 4185 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 9 Data size: 4185 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 9 Data size: 4185 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
diff --git a/ql/src/test/results/clientpositive/pointlookup3.q.out b/ql/src/test/results/clientpositive/pointlookup3.q.out
index 438bd09353..469a460773 100644
--- a/ql/src/test/results/clientpositive/pointlookup3.q.out
+++ b/ql/src/test/results/clientpositive/pointlookup3.q.out
@@ -954,20 +954,20 @@ STAGE PLANS:
           TableScan
             alias: t2
             filterExpr: ((key = 1) or (key = 2)) (type: boolean)
-            Statistics: Num rows: 60 Data size: 27720 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 27720 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: ((key = 1) or (key = 2)) (type: boolean)
-              Statistics: Num rows: 10 Data size: 4620 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 10 Data size: 4620 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: int), value (type: string), ds1 (type: string), ds2 (type: string), (key = 1) (type: boolean), (key = 2) (type: boolean)
                 outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                Statistics: Num rows: 10 Data size: 4700 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 10 Data size: 4700 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   null sort order: 
                   sort order: 
-                  Statistics: Num rows: 10 Data size: 4700 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 10 Data size: 4700 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: 1
                   value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: boolean), _col5 (type: boolean)
                   auto parallelism: false
@@ -1134,15 +1134,15 @@ STAGE PLANS:
             0 
             1 
           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11
-          Statistics: Num rows: 400 Data size: 376000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 400 Data size: 376000 Basic stats: COMPLETE Column stats: COMPLETE
           Filter Operator
             isSamplingPred: false
             predicate: ((_col4 and _col10) or (_col5 and _col11)) (type: boolean)
-            Statistics: Num rows: 200 Data size: 188000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 200 Data size: 188000 Basic stats: COMPLETE Column stats: COMPLETE
             Select Operator
               expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col6 (type: int), _col7 (type: string), _col8 (type: string), _col9 (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
-              Statistics: Num rows: 200 Data size: 184800 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 200 Data size: 184800 Basic stats: COMPLETE Column stats: COMPLETE
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
@@ -1171,7 +1171,7 @@ STAGE PLANS:
               key expressions: _col4 (type: int), _col5 (type: string), _col2 (type: string)
               null sort order: zzz
               sort order: +++
-              Statistics: Num rows: 200 Data size: 184800 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 200 Data size: 184800 Basic stats: COMPLETE Column stats: COMPLETE
               tag: -1
               value expressions: _col0 (type: int), _col1 (type: string), _col3 (type: string), _col6 (type: string), _col7 (type: string)
               auto parallelism: false
@@ -1208,13 +1208,13 @@ STAGE PLANS:
         Select Operator
           expressions: VALUE._col0 (type: int), VALUE._col1 (type: string), KEY.reducesinkkey2 (type: string), VALUE._col2 (type: string), KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), VALUE._col3 (type: string), VALUE._col4 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
-          Statistics: Num rows: 200 Data size: 184800 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 200 Data size: 184800 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 200 Data size: 184800 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 200 Data size: 184800 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -2369,20 +2369,20 @@ STAGE PLANS:
           TableScan
             alias: t2
             filterExpr: (key) IN (1, 2) (type: boolean)
-            Statistics: Num rows: 60 Data size: 27720 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 60 Data size: 27720 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: (key) IN (1, 2) (type: boolean)
-              Statistics: Num rows: 9 Data size: 4158 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 9 Data size: 4158 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: int), value (type: string), ds1 (type: string), ds2 (type: string)
                 outputColumnNames: _col0, _col1, _col2, _col3
-                Statistics: Num rows: 9 Data size: 4158 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 9 Data size: 4158 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   null sort order: 
                   sort order: 
-                  Statistics: Num rows: 9 Data size: 4158 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 9 Data size: 4158 Basic stats: COMPLETE Column stats: COMPLETE
                   tag: 1
                   value expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                   auto parallelism: false
@@ -2549,11 +2549,11 @@ STAGE PLANS:
             0 
             1 
           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
-          Statistics: Num rows: 360 Data size: 332640 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 360 Data size: 332640 Basic stats: COMPLETE Column stats: COMPLETE
           Filter Operator
             isSamplingPred: false
             predicate: (struct(_col2,_col4)) IN (const struct('2000-04-08',1), const struct('2000-04-09',2)) (type: boolean)
-            Statistics: Num rows: 180 Data size: 166320 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 180 Data size: 166320 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -2582,7 +2582,7 @@ STAGE PLANS:
               key expressions: _col4 (type: int), _col5 (type: string), _col2 (type: string)
               null sort order: zzz
               sort order: +++
-              Statistics: Num rows: 180 Data size: 166320 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 180 Data size: 166320 Basic stats: COMPLETE Column stats: COMPLETE
               tag: -1
               value expressions: _col0 (type: int), _col1 (type: string), _col3 (type: string), _col6 (type: string), _col7 (type: string)
               auto parallelism: false
@@ -2619,13 +2619,13 @@ STAGE PLANS:
         Select Operator
           expressions: VALUE._col0 (type: int), VALUE._col1 (type: string), KEY.reducesinkkey2 (type: string), VALUE._col2 (type: string), KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string), VALUE._col3 (type: string), VALUE._col4 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
-          Statistics: Num rows: 180 Data size: 166320 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 180 Data size: 166320 Basic stats: COMPLETE Column stats: COMPLETE
           File Output Operator
             compressed: false
             GlobalTableId: 0
 #### A masked pattern was here ####
             NumFilesPerFileSink: 1
-            Statistics: Num rows: 180 Data size: 166320 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 180 Data size: 166320 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
diff --git a/ql/src/test/results/clientpositive/ppd2.q.out b/ql/src/test/results/clientpositive/ppd2.q.out
index deb6bd9810..11ce89f9d8 100644
--- a/ql/src/test/results/clientpositive/ppd2.q.out
+++ b/ql/src/test/results/clientpositive/ppd2.q.out
@@ -300,17 +300,17 @@ STAGE PLANS:
           TableScan
             alias: srcpart
             filterExpr: ((value like 'aaa%') or (value like 'vvv%')) (type: boolean)
-            Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: COMPLETE
             Filter Operator
               predicate: ((value like 'aaa%') or (value like 'vvv%')) (type: boolean)
-              Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: UDFToInteger(key) (type: int)
                 outputColumnNames: _col0
-                Statistics: Num rows: 2000 Data size: 8000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 8000 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 2000 Data size: 8000 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 2000 Data size: 8000 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/ppr_allchildsarenull.q.out b/ql/src/test/results/clientpositive/ppr_allchildsarenull.q.out
index 44729042ba..5f63ac7a0e 100644
--- a/ql/src/test/results/clientpositive/ppr_allchildsarenull.q.out
+++ b/ql/src/test/results/clientpositive/ppr_allchildsarenull.q.out
@@ -249,22 +249,22 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate: (((value like 'aaa%') or (value like 'vvv%')) and (ds = '2008-04-08')) (type: boolean)
-              Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: UDFToInteger(key) (type: int), value (type: string)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 2000 Data size: 190000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 190000 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
 #### A masked pattern was here ####
                   NumFilesPerFileSink: 1
-                  Statistics: Num rows: 2000 Data size: 190000 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 2000 Data size: 190000 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
diff --git a/ql/src/test/results/clientpositive/regex_col.q.out b/ql/src/test/results/clientpositive/regex_col.q.out
index 693213ba11..38362962a0 100644
--- a/ql/src/test/results/clientpositive/regex_col.q.out
+++ b/ql/src/test/results/clientpositive/regex_col.q.out
@@ -26,11 +26,11 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: srcpart
-          Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
 PREHOOK: query: EXPLAIN
@@ -134,36 +134,36 @@ STAGE PLANS:
           TableScan
             alias: a
             filterExpr: (key is not null and value is not null) (type: boolean)
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             Filter Operator
               predicate: (key is not null and value is not null) (type: boolean)
-              Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                 outputColumnNames: _col0, _col1, _col2, _col3
-                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: string), _col1 (type: string)
                   sort order: ++
                   Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
-                  Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
                   value expressions: _col2 (type: string), _col3 (type: string)
           TableScan
             alias: b
             filterExpr: (key is not null and value is not null) (type: boolean)
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             Filter Operator
               predicate: (key is not null and value is not null) (type: boolean)
-              Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                 outputColumnNames: _col0, _col1, _col2, _col3
-                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
                 Reduce Output Operator
                   key expressions: _col0 (type: string), _col1 (type: string)
                   sort order: ++
                   Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
-                  Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
                   value expressions: _col2 (type: string), _col3 (type: string)
       Reduce Operator Tree:
         Join Operator
@@ -173,14 +173,14 @@ STAGE PLANS:
             0 _col0 (type: string), _col1 (type: string)
             1 _col0 (type: string), _col1 (type: string)
           outputColumnNames: _col2, _col3, _col6, _col7
-          Statistics: Num rows: 12658 Data size: 9316288 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 12658 Data size: 9316288 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: _col2 (type: string), _col3 (type: string), _col6 (type: string), _col7 (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 12658 Data size: 9316288 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 12658 Data size: 9316288 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 12658 Data size: 9316288 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 12658 Data size: 9316288 Basic stats: COMPLETE Column stats: COMPLETE
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -437,11 +437,11 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: srcpart
-          Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: key (type: string), value (type: string), hr (type: string)
             outputColumnNames: _col0, _col1, _col2
-            Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 724000 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
 PREHOOK: query: EXPLAIN
@@ -472,28 +472,28 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: COMPLETE
             Select Operator
               expressions: key (type: string), value (type: string)
               outputColumnNames: _col0, _col1
-              Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: _col0 (type: string), _col1 (type: string)
                 sort order: ++
-                Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: COMPLETE
                 TopN Hash Memory Usage: 0.1
       Execution mode: vectorized
       Reduce Operator Tree:
         Select Operator
           expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string)
           outputColumnNames: _col0, _col1
-          Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: COMPLETE
           Limit
             Number of rows: 10
-            Statistics: Num rows: 10 Data size: 1780 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 10 Data size: 1780 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 10 Data size: 1780 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 10 Data size: 1780 Basic stats: COMPLETE Column stats: COMPLETE
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/sample8.q.out b/ql/src/test/results/clientpositive/sample8.q.out
index c6ee59bb31..8c24451027 100644
--- a/ql/src/test/results/clientpositive/sample8.q.out
+++ b/ql/src/test/results/clientpositive/sample8.q.out
@@ -49,18 +49,18 @@ STAGE PLANS:
                 auto parallelism: false
           TableScan
             alias: t
-            Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: COMPLETE
             GatherStats: false
             Filter Operator
               isSamplingPred: true
               predicate: ((((hash(key) & 2147483647) % 1) = 0) and (((hash(key) & 2147483647) % 10) = 0) and value is not null) (type: boolean)
-              Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
               Reduce Output Operator
                 key expressions: key (type: string), value (type: string)
                 null sort order: aa
                 sort order: ++
                 Map-reduce partition columns: key (type: string), value (type: string)
-                Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
                 tag: 1
                 auto parallelism: false
       Path -> Alias:
@@ -276,21 +276,21 @@ STAGE PLANS:
             0 key (type: string), value (type: string)
             1 key (type: string), value (type: string)
           outputColumnNames: _col0, _col1, _col7, _col8
-          Statistics: Num rows: 197 Data size: 70132 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 197 Data size: 70132 Basic stats: COMPLETE Column stats: COMPLETE
           Filter Operator
             isSamplingPred: false
             predicate: ((_col7 = _col0) and (_col8 = _col1)) (type: boolean)
-            Statistics: Num rows: 49 Data size: 17444 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 49 Data size: 17444 Basic stats: COMPLETE Column stats: COMPLETE
             Select Operator
               expressions: _col0 (type: string), _col1 (type: string), '2008-04-08' (type: string), '11' (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 49 Data size: 17444 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 49 Data size: 17444 Basic stats: COMPLETE Column stats: COMPLETE
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
 #### A masked pattern was here ####
                 NumFilesPerFileSink: 1
-                Statistics: Num rows: 49 Data size: 17444 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 49 Data size: 17444 Basic stats: COMPLETE Column stats: COMPLETE
 #### A masked pattern was here ####
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
diff --git a/ql/src/test/results/clientpositive/stats2.q.out b/ql/src/test/results/clientpositive/stats2.q.out
index bc8b4181e5..e1bd37f393 100644
--- a/ql/src/test/results/clientpositive/stats2.q.out
+++ b/ql/src/test/results/clientpositive/stats2.q.out
@@ -34,14 +34,14 @@ STAGE PLANS:
           TableScan
             alias: srcpart
             filterExpr: ds is not null (type: boolean)
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             Select Operator
               expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
               File Output Operator
                 compressed: false
-                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/stats4.q.out b/ql/src/test/results/clientpositive/stats4.q.out
index c8497ef600..0d48786859 100644
--- a/ql/src/test/results/clientpositive/stats4.q.out
+++ b/ql/src/test/results/clientpositive/stats4.q.out
@@ -73,17 +73,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: srcpart
-            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000 Data size: 1092000 Basic stats: COMPLETE Column stats: COMPLETE
             Filter Operator
               predicate: (ds <= '2008-04-08') (type: boolean)
-              Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: string), value (type: string), ds (type: string), hr (type: string)
                 outputColumnNames: _col0, _col1, _col2, _col3
-                Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -92,29 +92,29 @@ STAGE PLANS:
                 Select Operator
                   expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string)
                   outputColumnNames: key, value, ds, hr
-                  Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
                   Group By Operator
                     aggregations: compute_stats(key, 'hll'), compute_stats(value, 'hll')
                     keys: ds (type: string), hr (type: string)
                     mode: hash
                     outputColumnNames: _col0, _col1, _col2, _col3
-                    Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
                     Reduce Output Operator
                       key expressions: _col0 (type: string), _col1 (type: string)
                       sort order: ++
                       Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
-                      Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
                       value expressions: _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
             Filter Operator
               predicate: (ds > '2008-04-08') (type: boolean)
-              Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 666 Data size: 363636 Basic stats: COMPLETE Column stats: COMPLETE
               Select Operator
                 expressions: key (type: string), value (type: string), hr (type: string)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 666 Data size: 241092 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 666 Data size: 241092 Basic stats: COMPLETE Column stats: COMPLETE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 666 Data size: 241092 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 666 Data size: 241092 Basic stats: COMPLETE Column stats: COMPLETE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -123,13 +123,13 @@ STAGE PLANS:
                 Select Operator
                   expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)
                   outputColumnNames: key, value, hr
-                  Statistics: Num rows: 666 Data size: 303696 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 666 Data size: 303696 Basic stats: COMPLETE Column stats: COMPLETE
                   Group By Operator
                     aggregations: compute_stats(key, 'hll'), compute_stats(value, 'hll')
                     keys: '2008-12-31' (type: string), hr (type: string)
                     mode: hash
                     outputColumnNames: _col0, _col1, _col2, _col3
-                    Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
                     File Output Operator
                       compressed: false
                       table:
@@ -142,14 +142,14 @@ STAGE PLANS:
           keys: KEY._col0 (type: string), KEY._col1 (type: string)
           mode: mergepartial
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col0 (type: string), _col1 (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2 Data size: 2496 Basic stats: COMPLETE Column stats: COMPLETE
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -244,7 +244,7 @@ STAGE PLANS:
               key expressions: '2008-12-31' (type: string), _col1 (type: string)
               sort order: ++
               Map-reduce partition columns: '2008-12-31' (type: string), _col1 (type: string)
-              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
               value expressions: _col2 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,sumlength:bigint,count:bigint,countnulls:bigint,bitvector:binary>)
       Execution mode: vectorized
       Reduce Operator Tree:
@@ -253,14 +253,14 @@ STAGE PLANS:
           keys: '2008-12-31' (type: string), KEY._col1 (type: string)
           mode: mergepartial
           outputColumnNames: _col0, _col1, _col2, _col3
-          Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: _col2 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), _col3 (type: struct<columntype:string,maxlength:bigint,avglength:double,countnulls:bigint,numdistinctvalues:bigint,ndvbitvector:binary>), '2008-12-31' (type: string), _col1 (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: PARTIAL
+              Statistics: Num rows: 2 Data size: 2316 Basic stats: COMPLETE Column stats: COMPLETE
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/updateBasicStats.q.out b/ql/src/test/results/clientpositive/updateBasicStats.q.out
index b3a97dcb33..162114b575 100644
--- a/ql/src/test/results/clientpositive/updateBasicStats.q.out
+++ b/ql/src/test/results/clientpositive/updateBasicStats.q.out
@@ -311,11 +311,11 @@ STAGE PLANS:
         TableScan
           alias: src_stat_part_two_n0
           filterExpr: (px = 1) (type: boolean)
-          Statistics: Num rows: 11 Data size: 3982 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 11 Data size: 3982 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: key (type: string), value (type: string), 1 (type: int), py (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 11 Data size: 4026 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 11 Data size: 4026 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
 PREHOOK: query: alter table src_stat_part_two_n0 partition (px=1, py='a') update statistics set('numRows'='1000020000', 'rawDataSize'='300040000')
@@ -378,11 +378,11 @@ STAGE PLANS:
         TableScan
           alias: src_stat_part_two_n0
           filterExpr: (px = 1) (type: boolean)
-          Statistics: Num rows: 1000020010 Data size: 362007243620 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 1000020010 Data size: 362007243620 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: key (type: string), value (type: string), 1 (type: int), py (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 1000020010 Data size: 366007323660 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 1000020010 Data size: 366007323660 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
 PREHOOK: query: alter table src_stat_part_two_n0 partition (px=1) update statistics set('numRows'='1000020000', 'rawDataSize'='300040000')
@@ -448,10 +448,10 @@ STAGE PLANS:
         TableScan
           alias: src_stat_part_two_n0
           filterExpr: (px = 1) (type: boolean)
-          Statistics: Num rows: 2000040000 Data size: 724014480000 Basic stats: COMPLETE Column stats: PARTIAL
+          Statistics: Num rows: 2000040000 Data size: 724014480000 Basic stats: COMPLETE Column stats: COMPLETE
           Select Operator
             expressions: key (type: string), value (type: string), 1 (type: int), py (type: string)
             outputColumnNames: _col0, _col1, _col2, _col3
-            Statistics: Num rows: 2000040000 Data size: 732014640000 Basic stats: COMPLETE Column stats: PARTIAL
+            Statistics: Num rows: 2000040000 Data size: 732014640000 Basic stats: COMPLETE Column stats: COMPLETE
             ListSink
 
diff --git a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java
index ce352e5b40..c918e2b51f 100644
--- a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java
+++ b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java
@@ -266,7 +266,7 @@ public enum ConfVars {
         "hive.metastore.aggregate.stats.cache.clean.until", 0.8,
         "The cleaner thread cleans until cache reaches this % full size."),
     AGGREGATE_STATS_CACHE_ENABLED("metastore.aggregate.stats.cache.enabled",
-        "hive.metastore.aggregate.stats.cache.enabled", true,
+        "hive.metastore.aggregate.stats.cache.enabled", false,
         "Whether aggregate stats caching is enabled or not."),
     AGGREGATE_STATS_CACHE_FPP("metastore.aggregate.stats.cache.fpp",
         "hive.metastore.aggregate.stats.cache.fpp", 0.01,
