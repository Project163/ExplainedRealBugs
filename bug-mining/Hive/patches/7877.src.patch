diff --git a/llap-server/pom.xml b/llap-server/pom.xml
index 9460805cc6..68db7579ed 100644
--- a/llap-server/pom.xml
+++ b/llap-server/pom.xml
@@ -259,6 +259,12 @@
       <classifier>tests</classifier>
       <scope>test</scope>
     </dependency>
+    <dependency>
+      <groupId>org.apache.hive</groupId>
+      <artifactId>hive-testutils</artifactId>
+      <version>${project.version}</version>
+      <scope>test</scope>
+    </dependency>
     <!-- test inter-project -->
     <dependency>
       <groupId>org.apache.hadoop</groupId>
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/LlapConstants.java b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/LlapConstants.java
index b421e0bd51..a960c4c887 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/LlapConstants.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/LlapConstants.java
@@ -23,11 +23,4 @@ public class LlapConstants {
   public static final String LLAP_HADOOP_METRICS2_PROPERTIES_FILE = "hadoop-metrics2-llapdaemon.properties";
   public static final String HADOOP_METRICS2_PROPERTIES_FILE = "hadoop-metrics2.properties";
 
-  // Note: Do not change without changing the corresponding reference in llap-daemon-log4j2.properties
-  public static final String LLAP_LOG4j2_PURGE_POLICY_NAME_DAG_ROUTING =
-      "llapLogPurgerDagRouting";
-  // Note: Do not change without changing the corresponding reference in llap-daemon-log4j2.properties
-  public static final String LLAP_LOG4j2_PURGE_POLICY_NAME_QUERY_ROUTING =
-      "llapLogPurgerQueryRouting";
-
 }
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryTracker.java b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryTracker.java
index 40e921f4fa..24f52ce791 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryTracker.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryTracker.java
@@ -143,11 +143,8 @@ public QueryTracker(Configuration conf, String[] localDirsBase, String clusterId
         new ThreadFactoryBuilder().setDaemon(true).setNameFormat("QueryCompletionThread %d").build());
 
     String logger = HiveConf.getVar(conf, ConfVars.LLAP_DAEMON_LOGGER);
-    if (logger != null && (logger.equalsIgnoreCase(LogHelpers.LLAP_LOGGER_NAME_QUERY_ROUTING))) {
-      routeBasedLoggingEnabled = true;
-    } else {
-      routeBasedLoggingEnabled = false;
-    }
+    routeBasedLoggingEnabled =
+        logger != null && (logger.equalsIgnoreCase(LogHelpers.LLAP_LOGGER_NAME_QUERY_ROUTING));
     LOG.info(
         "QueryTracker setup with numCleanerThreads={}, defaultCleanupDelay(s)={}, routeBasedLogging={}",
         numCleanerThreads, defaultDeleteDelaySeconds, routeBasedLoggingEnabled);
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/log/LlapRandomAccessFileAppender.java b/llap-server/src/java/org/apache/hadoop/hive/llap/log/LlapRandomAccessFileAppender.java
new file mode 100644
index 0000000000..d5c1174a3c
--- /dev/null
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/log/LlapRandomAccessFileAppender.java
@@ -0,0 +1,185 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.llap.log;
+
+import org.apache.logging.log4j.core.Appender;
+import org.apache.logging.log4j.core.Core;
+import org.apache.logging.log4j.core.Filter;
+import org.apache.logging.log4j.core.Layout;
+import org.apache.logging.log4j.core.LogEvent;
+import org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender;
+import org.apache.logging.log4j.core.appender.RandomAccessFileManager;
+import org.apache.logging.log4j.core.config.Property;
+import org.apache.logging.log4j.core.config.plugins.Plugin;
+import org.apache.logging.log4j.core.config.plugins.PluginBuilderAttribute;
+import org.apache.logging.log4j.core.config.plugins.PluginBuilderFactory;
+
+import java.io.IOException;
+import java.io.Serializable;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicBoolean;
+
+/**
+ * A random access file appender that conditionally renames the file when the appender is stopped.
+ *
+ * If the appender receives an event with a {@link Log4jQueryCompleteMarker} then the underlying file will be renamed
+ * (using the ".done" suffix) when the appender is stopped. 
+ *
+ * Moreover, the appender filters events with {@link Log4jQueryCompleteMarker} so they never appear in the logs.
+ */
+@Plugin(name = "LlapRandomAccessFileAppender", category = Core.CATEGORY_NAME, elementType = Appender.ELEMENT_TYPE, printObject = true)
+public final class LlapRandomAccessFileAppender extends AbstractOutputStreamAppender<RandomAccessFileManager> {
+
+  /**
+   * Warning: Changing the file suffix may break external clients if it is not accompanied by appropriate changes.
+   * Two known dependencies are the following:
+   * <li>
+   *   <ul>YARN rolling log aggregation relies on this naming convention to function correctly (see HIVE-14225)</ul>
+   *   <ul>Tez UI checks files with these ending to display certain information to the user (TEZ-3629)</ul>
+   * </li>
+   */
+  private static final String RENAME_SUFFIX = ".done";
+  private final AtomicBoolean renameOnStop = new AtomicBoolean(false);
+
+  protected LlapRandomAccessFileAppender(String name, Layout<? extends Serializable> layout, Filter filter,
+      boolean ignoreExceptions, boolean immediateFlush, Property[] properties, RandomAccessFileManager manager) {
+    super(name, layout, filter, ignoreExceptions, immediateFlush, properties, manager);
+  }
+
+  /**
+   * Builds LlapRandomAccessFileAppender instances.
+   */
+  public static class Builder<B extends LlapRandomAccessFileAppender.Builder<B>>
+      extends AbstractOutputStreamAppender.Builder<B>
+      implements org.apache.logging.log4j.core.util.Builder<LlapRandomAccessFileAppender> {
+
+    @PluginBuilderAttribute("fileName")
+    private String fileName;
+
+    @PluginBuilderAttribute("append")
+    private boolean append = true;
+
+    @Override
+    public LlapRandomAccessFileAppender build() {
+      final String name = getName();
+      if (name == null) {
+        LOGGER.error("No name provided for FileAppender");
+        return null;
+      }
+
+      if (fileName == null) {
+        LOGGER.error("No filename provided for FileAppender with name " + name);
+        return null;
+      }
+      final Layout<? extends Serializable> layout = getOrCreateLayout();
+      final boolean immediateFlush = isImmediateFlush();
+      final RandomAccessFileManager manager =
+          RandomAccessFileManager.getFileManager(fileName, append, immediateFlush, getBufferSize(), null, layout, null);
+      if (manager == null) {
+        return null;
+      }
+
+      return new LlapRandomAccessFileAppender(name, layout, getFilter(), isIgnoreExceptions(), immediateFlush,
+          getPropertyArray(), manager);
+    }
+
+    public B setFileName(final String fileName) {
+      this.fileName = fileName;
+      return asBuilder();
+    }
+
+    public B setAppend(final boolean append) {
+      this.append = append;
+      return asBuilder();
+    }
+
+  }
+
+  @Override
+  public boolean stop(final long timeout, final TimeUnit timeUnit) {
+    setStopping();
+    super.stop(timeout, timeUnit, false);
+    if (renameOnStop.get()) {
+      rename();
+    }
+    setStopped();
+    return true;
+  }
+
+  private void rename() {
+    String currentName = getManager().getFileName();
+    Path newFileName = findRenamePath();
+    try {
+      LOGGER.trace("Renaming file: {} to {}", currentName, newFileName);
+      Files.move(Paths.get(currentName), newFileName);
+    } catch (IOException e) {
+      LOGGER.error("Failed to rename file: " + currentName + " to " + newFileName, e);
+    }
+  }
+
+  /**
+   * Returns an available path to rename the current file.
+   *
+   * It avoids the case where the file exists already in the current directory that would lead to the logger 
+   * failing miserably.
+   */
+  private Path findRenamePath() {
+    Path renamedPath;
+    int i = 0;
+    do {
+      String suffix = i == 0 ? RENAME_SUFFIX : i + RENAME_SUFFIX;
+      renamedPath = Paths.get(getManager().getFileName() + suffix);
+      i++;
+    } while (Files.exists(renamedPath));
+    return renamedPath;
+  }
+
+  /**
+   * Appends the log entry to the file when required.
+   *
+   * @param event The LogEvent.
+   */
+  @Override
+  public void append(final LogEvent event) {
+    if (event.getMarker() != null && event.getMarker().getName().equals(Log4jQueryCompleteMarker.EOF_MARKER)) {
+      renameOnStop.set(true);
+      return;
+    }
+    // Leverage the nice batching behaviour of async Loggers/Appenders:
+    // we can signal the file manager that it needs to flush the buffer
+    // to disk at the end of a batch.
+    // From a user's point of view, this means that all log events are
+    // _always_ available in the log file, without incurring the overhead
+    // of immediateFlush=true.
+    getManager().setEndOfBatch(event.isEndOfBatch()); // FIXME manager's EndOfBatch threadlocal can be deleted
+    // LOG4J2-1292 utilize gc-free Layout.encode() method: taken care of in superclass
+    super.append(event);
+  }
+
+  /**
+   * Returns a builder for a LlapRandomAccessFileAppender.
+   */
+  @PluginBuilderFactory
+  public static <B extends LlapRandomAccessFileAppender.Builder<B>> B newBuilder() {
+    return new LlapRandomAccessFileAppender.Builder<B>().asBuilder();
+  }
+
+}
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/log/LlapRoutingAppenderPurgePolicy.java b/llap-server/src/java/org/apache/hadoop/hive/llap/log/LlapRoutingAppenderPurgePolicy.java
deleted file mode 100644
index f47815ea0b..0000000000
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/log/LlapRoutingAppenderPurgePolicy.java
+++ /dev/null
@@ -1,128 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.hive.llap.log;
-
-import java.util.Collections;
-import java.util.Set;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
-
-import com.google.common.base.Preconditions;
-import org.apache.logging.log4j.Logger;
-import org.apache.logging.log4j.Marker;
-import org.apache.logging.log4j.core.LogEvent;
-import org.apache.logging.log4j.core.appender.routing.PurgePolicy;
-import org.apache.logging.log4j.core.appender.routing.RoutingAppender;
-import org.apache.logging.log4j.core.config.plugins.Plugin;
-import org.apache.logging.log4j.core.config.plugins.PluginAttribute;
-import org.apache.logging.log4j.core.config.plugins.PluginFactory;
-import org.apache.logging.log4j.status.StatusLogger;
-
-/**
- * A purge policy for the {@link RoutingAppender} which awaits a notification from the application
- * about a key no longer being required, before it purges it.
- */
-@Plugin(name = "LlapRoutingAppenderPurgePolicy", category = "Core", printObject = true)
-public class LlapRoutingAppenderPurgePolicy implements PurgePolicy {
-
-  private static final Logger LOGGER = StatusLogger.getLogger();
-
-  private static final ConcurrentMap<String, LlapRoutingAppenderPurgePolicy> INSTANCES =
-      new ConcurrentHashMap<>();
-
-  private final Set<String> knownAppenders =
-      Collections.newSetFromMap(new ConcurrentHashMap<String, Boolean>());
-  private final String name;
-
-  // The Routing appender, which manages underlying appenders
-  private RoutingAppender routingAppender;
-
-  public LlapRoutingAppenderPurgePolicy(String name) {
-    LOGGER.trace("Created " + LlapRoutingAppenderPurgePolicy.class.getName() + " with name=" + name);
-    this.name=name;
-  }
-
-  private LlapRoutingAppenderPurgePolicy() {
-    this("_NOOP_");
-  }
-
-  @Override
-  public void initialize(RoutingAppender routingAppender) {
-    this.routingAppender = routingAppender;
-  }
-
-  @Override
-  public void purge() {
-    // Nothing to do here. This is not invoked by the log4j framework. Should likely not be in
-    // the log4j interface
-  }
-
-  @Override
-  public void update(String key, LogEvent event) {
-    Marker marker = event.getMarker();
-    if (marker != null && marker.getName() != null && marker.getName().equals(Log4jQueryCompleteMarker.EOF_MARKER)) {
-      LOGGER.debug("Received " + Log4jQueryCompleteMarker.EOF_MARKER + " for key. Attempting cleanup.");
-      keyComplete(key);
-    }
-    else {
-      if (knownAppenders.add(key)) {
-        if (LOGGER.isDebugEnabled()) {
-          LOGGER.debug("Registered key: [" + key + "] on purgePolicyWithName=" + name +
-              ", thisAddress=" + System.identityHashCode(this));
-        }
-      }
-    }
-  }
-
-  /**
-   * Indicate that the specified key is no longer used.
-   * @param key
-   */
-  private void keyComplete(String key) {
-    Preconditions.checkNotNull(key, "Key must be specified");
-    boolean removed = knownAppenders.remove(key);
-    if (removed) {
-      if (LOGGER.isDebugEnabled()) {
-        LOGGER.debug("Deleting Appender for key: " + key);
-      }
-      routingAppender.deleteAppender(key);
-    } else {
-      LOGGER.trace("Ignoring call to remove unknown key: " + key);
-    }
-  }
-
-
-  @PluginFactory
-  public static PurgePolicy createPurgePolicy(
-      @PluginAttribute("name") final String name) {
-
-    // Name required for routing. Error out if it is not set.
-    Preconditions.checkNotNull(name,
-        "Name must be specified for " + LlapRoutingAppenderPurgePolicy.class.getName());
-    LlapRoutingAppenderPurgePolicy llapRoutingAppenderPurgePolicy =
-        new LlapRoutingAppenderPurgePolicy(name);
-    LlapRoutingAppenderPurgePolicy old = INSTANCES.putIfAbsent(name, llapRoutingAppenderPurgePolicy);
-    if (old != null) {
-      LOGGER.debug("Attempt to create multiple instances of " +
-          LlapRoutingAppenderPurgePolicy.class.getName() + " with the name " + name +
-          ". Using original instance");
-      llapRoutingAppenderPurgePolicy = old;
-    }
-    return llapRoutingAppenderPurgePolicy;
-  }
-}
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/log/LlapWrappedAppender.java b/llap-server/src/java/org/apache/hadoop/hive/llap/log/LlapWrappedAppender.java
deleted file mode 100644
index f35d244794..0000000000
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/log/LlapWrappedAppender.java
+++ /dev/null
@@ -1,221 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.hive.llap.log;
-
-import java.io.IOException;
-import java.nio.file.Files;
-import java.nio.file.Path;
-import java.nio.file.Paths;
-import java.util.concurrent.atomic.AtomicReference;
-
-import org.apache.logging.log4j.core.Appender;
-import org.apache.logging.log4j.core.LogEvent;
-import org.apache.logging.log4j.core.appender.AbstractAppender;
-import org.apache.logging.log4j.core.appender.RandomAccessFileAppender;
-import org.apache.logging.log4j.core.config.AppenderControl;
-import org.apache.logging.log4j.core.config.Configuration;
-import org.apache.logging.log4j.core.config.Node;
-import org.apache.logging.log4j.core.config.plugins.Plugin;
-import org.apache.logging.log4j.core.config.plugins.PluginAttribute;
-import org.apache.logging.log4j.core.config.plugins.PluginConfiguration;
-import org.apache.logging.log4j.core.config.plugins.PluginFactory;
-import org.apache.logging.log4j.core.config.plugins.PluginNode;
-import org.apache.logging.log4j.util.Strings;
-
-/**
- * An appender to wrap around RandomAccessFileAppender, and rename the file once the appender is
- * closed.
- * Could be potentially extended to other appenders by special casing them to figure out how files
- * are to be handled.
- */
-@Plugin(name = "LlapWrappedAppender", category = "Core",
-    elementType = "appender", printObject = true, deferChildren = true)
-public class LlapWrappedAppender extends AbstractAppender {
-
-  private static final boolean DEFAULT_RENAME_FILES_ON_CLOSE = true;
-  private static final String DEFAULT_RENAMED_FILE_SUFFIX = ".done";
-
-  private final Node node;
-  private final Configuration config;
-  private final boolean renameFileOnClose;
-  private final String renamedFileSuffix;
-
-  private AtomicReference<Appender> realAppender = new AtomicReference<>();
-  private AtomicReference<AppenderControl> appenderControl = new AtomicReference<>();
-
-  public LlapWrappedAppender(final String name, final Node node, final Configuration config,
-                             boolean renameOnClose, String renamedFileSuffix) {
-    super(name, null, null);
-    this.node = node;
-    this.config = config;
-    this.renameFileOnClose = renameOnClose;
-    this.renamedFileSuffix = renamedFileSuffix;
-    if (LOGGER.isDebugEnabled()) {
-      LOGGER.debug(
-          LlapWrappedAppender.class.getName() + " created with name=" + name + ", renameOnClose=" +
-              renameOnClose + ", renamedFileSuffix=" + renamedFileSuffix);
-    }
-  }
-
-  @Override
-  public void start() {
-    super.start();
-  }
-
-  @Override
-  public void append(LogEvent event) {
-    setupAppenderIfRequired(event);
-    if (appenderControl.get() != null) {
-      if (!(event.getMarker() != null && event.getMarker().getName() != null &&
-          event.getMarker().getName().equals(Log4jQueryCompleteMarker.EOF_MARKER))) {
-        appenderControl.get().callAppender(event);
-      } else {
-        LOGGER.debug("Not forwarding message with maker={}, marker.getName={}", event.getMarker(),
-            (event.getMarker() == null ? "nullMarker" : event.getMarker().getName()));
-      }
-    }
-  }
-
-  private void setupAppenderIfRequired(LogEvent event) {
-    if (appenderControl.get() == null) {
-      if (node.getType().getElementName().equalsIgnoreCase("appender")) {
-        for (final Node cnode : node.getChildren()) {
-          final Node appNode = new Node(cnode);
-          config.createConfiguration(appNode, event);
-          if (appNode.getObject() instanceof Appender) {
-            final Appender app = appNode.getObject();
-            app.start();
-            if (!(app instanceof RandomAccessFileAppender)) {
-              String message =
-                  "Cannot handle appenders other than " + RandomAccessFileAppender.class.getName() +
-                      ". Found: " + app.getClass().getName();
-              LOGGER.error(message);
-              throw new IllegalStateException(message);
-            }
-            realAppender.set(app);
-            appenderControl.set(new AppenderControl(app, null, null));
-            if (LOGGER.isDebugEnabled()) {
-              RandomAccessFileAppender raf = (RandomAccessFileAppender) app;
-              LOGGER.debug(
-                  "Setup new appender to write to file: " + raf.getFileName() + ", appenderName=" +
-                      raf.getName() + ", appenderManagerName=" + raf.getManager().getName());
-
-            }
-            break;
-          }
-        }
-        if (appenderControl.get() == null) {
-          // Fail if mis-configured.
-          throw new RuntimeException(LlapWrappedAppender.class.getSimpleName() +
-              "name=" + getName() + " unable to setup actual appender." +
-              "Could not find child appender");
-        }
-      } else {
-        // Fail if mis-configured.
-        throw new RuntimeException(LlapWrappedAppender.class.getSimpleName() +
-            "name=" + getName() + " unable to setup actual appender." +
-            "Could not find child appender");
-      }
-    }
-  }
-
-
-  @Override
-  public void stop() {
-    if (!(this.isStopping() || this.isStopped())) {
-      super.stop();
-      if (appenderControl.get() != null) {
-        appenderControl.get().stop();
-        realAppender.get().stop();
-      }
-
-      if (LOGGER.isDebugEnabled()) {
-        LOGGER.debug(
-            "Stop invoked for " + ((RandomAccessFileAppender) realAppender.get()).getFileName());
-      }
-      if (realAppender.get() == null) {
-        LOGGER.info("RealAppender is null. Ignoring stop");
-        return;
-      }
-
-      RandomAccessFileAppender raf = (RandomAccessFileAppender) realAppender.get();
-      Path renamedPath = null;
-      if (renameFileOnClose) {
-        try {
-          // Look for a file to which we can move the existing file. With external services,
-          // it's possible for the service to be marked complete after each fragment.
-          int counter = 0;
-          while(true) {
-            renamedPath = getRenamedPath(raf.getFileName(), counter);
-            if (!Files.exists(renamedPath)) {
-              if (LOGGER.isTraceEnabled()) {
-                LOGGER.trace("Renaming file: " + raf.getFileName() + " to " + renamedPath);
-              }
-              Files.move(Paths.get(raf.getFileName()), renamedPath);
-              break;
-            }
-            counter++;
-          }
-        } catch (IOException e) {
-          // Bail on an exception - out of the loop.
-          LOGGER.warn("Failed to rename file: " + raf.getFileName() + " to " + renamedPath, e);
-        }
-      }
-    }
-  }
-
-  private Path getRenamedPath(String originalFileName, int iteration) {
-    Path renamedPath;
-    if (iteration == 0) {
-      renamedPath = Paths.get(originalFileName + renamedFileSuffix);
-    } else {
-      renamedPath = Paths.get(originalFileName + "." + iteration + renamedFileSuffix);
-    }
-    return renamedPath;
-  }
-
-  @PluginFactory
-  public static LlapWrappedAppender createAppender(
-      @PluginAttribute("name") final String name, // This isn't really used for anything.
-      @PluginAttribute("renameFileOnClose") final String renameFileOnCloseProvided,
-      @PluginAttribute("renamedFileSuffix") final String renamedFileSuffixProvided,
-      @PluginNode final Node node,
-      @PluginConfiguration final Configuration config
-  ) {
-    if (config == null) {
-      LOGGER.error("PluginConfiguration not expected to be null");
-      return null;
-    }
-    if (node == null) {
-      LOGGER.error("Node must be specified as an appender specification");
-      return null;
-    }
-
-    boolean renameFileOnClose = DEFAULT_RENAME_FILES_ON_CLOSE;
-    if (Strings.isNotBlank(renameFileOnCloseProvided)) {
-      renameFileOnClose = Boolean.parseBoolean(renameFileOnCloseProvided);
-    }
-    String renamedFileSuffix = DEFAULT_RENAMED_FILE_SUFFIX;
-    if (Strings.isNotBlank(renamedFileSuffixProvided)) {
-      renamedFileSuffix = renamedFileSuffixProvided;
-    }
-
-    return new LlapWrappedAppender(name, node, config, renameFileOnClose, renamedFileSuffix);
-  }
-
-}
\ No newline at end of file
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/log/Log4jQueryCompleteMarker.java b/llap-server/src/java/org/apache/hadoop/hive/llap/log/Log4jQueryCompleteMarker.java
index 97ffea305e..808f43e4e9 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/log/Log4jQueryCompleteMarker.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/log/Log4jQueryCompleteMarker.java
@@ -54,7 +54,7 @@ public boolean isInstanceOf(Marker m) {
 
   @Override
   public boolean isInstanceOf(String name) {
-    return false;
+    return EOF_MARKER.equals(name);
   }
 
   @Override
diff --git a/llap-server/src/main/resources/llap-daemon-log4j2.properties b/llap-server/src/main/resources/llap-daemon-log4j2.properties
index 7cf688da6b..5da0c8d31d 100644
--- a/llap-server/src/main/resources/llap-daemon-log4j2.properties
+++ b/llap-server/src/main/resources/llap-daemon-log4j2.properties
@@ -81,23 +81,21 @@ appender.query-routing.type = Routing
 appender.query-routing.name = query-routing
 appender.query-routing.routes.type = Routes
 appender.query-routing.routes.pattern = $${ctx:queryId}
-#Purge polciy for query-based Routing Appender
-appender.query-routing.purgePolicy.type = LlapRoutingAppenderPurgePolicy
-# Note: Do not change this name without changing the corresponding entry in LlapConstants
-appender.query-routing.purgePolicy.name = llapLogPurgerQueryRouting
+#Purge policy for query-based Routing Appender
+appender.query-routing.purgePolicy.type = IdlePurgePolicy
+appender.query-routing.purgePolicy.timeToLive = 60
+appender.query-routing.purgePolicy.timeUnit = SECONDS
 # default route
 appender.query-routing.routes.route-default.type = Route
 appender.query-routing.routes.route-default.key = $${ctx:queryId}
 appender.query-routing.routes.route-default.ref = RFA
 # queryId based route
 appender.query-routing.routes.route-mdc.type = Route
-appender.query-routing.routes.route-mdc.file-mdc.type = LlapWrappedAppender
-appender.query-routing.routes.route-mdc.file-mdc.name = IrrelevantName-query-routing
-appender.query-routing.routes.route-mdc.file-mdc.app.type = RandomAccessFile
-appender.query-routing.routes.route-mdc.file-mdc.app.name = file-mdc
-appender.query-routing.routes.route-mdc.file-mdc.app.fileName = ${sys:llap.daemon.log.dir}/${ctx:queryId}-${ctx:dagId}.log
-appender.query-routing.routes.route-mdc.file-mdc.app.layout.type = PatternLayout
-appender.query-routing.routes.route-mdc.file-mdc.app.layout.pattern = %d{ISO8601} %5p [%t (%X{fragmentId})] %c{2}: %m%n
+appender.query-routing.routes.route-mdc.file-mdc.type = LlapRandomAccessFileAppender
+appender.query-routing.routes.route-mdc.file-mdc.name = query-file-appender
+appender.query-routing.routes.route-mdc.file-mdc.fileName = ${sys:llap.daemon.log.dir}/${ctx:queryId}-${ctx:dagId}.log
+appender.query-routing.routes.route-mdc.file-mdc.layout.type = PatternLayout
+appender.query-routing.routes.route-mdc.file-mdc.layout.pattern = %d{ISO8601} %5p [%t (%X{fragmentId})] %c{2}: %m%n
 
 # list of all loggers
 loggers = PerfLogger, EncodedReader, NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, HistoryLogger, LlapIoImpl, LlapIoOrc, LlapIoCache, LlapIoLocking, TezSM, TezSS, TezHC, LlapDaemon, TaskExecutorService
diff --git a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/LlapDaemonExtension.java b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/LlapDaemonExtension.java
new file mode 100644
index 0000000000..c180a3860f
--- /dev/null
+++ b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/LlapDaemonExtension.java
@@ -0,0 +1,98 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.llap.daemon;
+
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.llap.LlapDaemonInfo;
+import org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon;
+import org.apache.hadoop.hive.llap.metrics.LlapMetricsSystem;
+import org.apache.hadoop.hive.llap.metrics.MetricsUtils;
+import org.junit.jupiter.api.extension.AfterEachCallback;
+import org.junit.jupiter.api.extension.BeforeEachCallback;
+import org.junit.jupiter.api.extension.ExtensionContext;
+import org.junit.jupiter.api.extension.ParameterContext;
+import org.junit.jupiter.api.extension.ParameterResolutionException;
+import org.junit.jupiter.api.extension.ParameterResolver;
+
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.locks.ReentrantLock;
+
+/**
+ * A JUnit Jupiter extension providing ready to use {@link LlapDaemon} for the duration of a test when the test method
+ * has a parameter of the respective type.
+ * 
+ * A new daemon is created before each test and destroyed afterwards. The daemons rely on various static constructs so
+ * we cannot have many in the same JVM. If there are many {@link LlapDaemon} parameters in the same test method the same
+ * object is returned for all of them.
+ * 
+ * The class is thread-safe but there cannot be two tests using LLAP daemons concurrently for the reasons mentioned
+ * previously.
+ */
+public class LlapDaemonExtension implements ParameterResolver, BeforeEachCallback, AfterEachCallback {
+
+  private static final ReentrantLock LOCK = new ReentrantLock();
+  private static final String[] METRICS_SOURCES = new String[] { 
+          "JvmMetrics", 
+          "LlapDaemonExecutorMetrics-" + MetricsUtils.getHostName(),
+          "LlapDaemonJvmMetrics-" + MetricsUtils.getHostName(),
+          MetricsUtils.METRICS_PROCESS_NAME };
+  private static LlapDaemon daemon = null;
+
+  @Override
+  public void beforeEach(ExtensionContext context) throws Exception {
+    if (!LOCK.tryLock(1, TimeUnit.MINUTES)) {
+      throw new IllegalStateException("Lock acquisition failed cause another test is using the LlapDaemon.");
+    }
+    final String appName = "testLlapDaemon" + context.getUniqueId();
+    HiveConf conf = new HiveConf();
+    HiveConf.setVar(conf, HiveConf.ConfVars.LLAP_DAEMON_SERVICE_HOSTS, "llap");
+    LlapDaemonInfo.initialize(appName, conf);
+    daemon =
+        new LlapDaemon(conf, 1, LlapDaemon.getTotalHeapSize(), false, false, -1, new String[1], 0, false, 0, 0, 0, 0,
+            appName);
+    daemon.init(conf);
+    daemon.start();
+  }
+
+  @Override
+  public void afterEach(ExtensionContext context) {
+    try {
+      daemon.stop();
+      for (String ms : METRICS_SOURCES) {
+        LlapMetricsSystem.instance().unregisterSource(ms);
+      }
+      daemon = null;
+    } finally {
+      LOCK.unlock();
+    }
+  }
+
+  @Override
+  public boolean supportsParameter(ParameterContext parameterContext, ExtensionContext extensionContext)
+      throws ParameterResolutionException {
+    return parameterContext.getParameter().getType() == LlapDaemon.class;
+  }
+
+  @Override
+  public Object resolveParameter(ParameterContext parameterContext, ExtensionContext context)
+      throws ParameterResolutionException {
+    assert daemon != null;
+    return daemon;
+  }
+
+}
diff --git a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/LlapDaemonTestUtils.java b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/LlapDaemonTestUtils.java
index 83ee1e9a09..12429c6280 100644
--- a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/LlapDaemonTestUtils.java
+++ b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/LlapDaemonTestUtils.java
@@ -27,6 +27,68 @@
 public class LlapDaemonTestUtils {
   private LlapDaemonTestUtils() {}
 
+  public static SubmitWorkRequestProto buildSubmitProtoRequest(String appId, int dagId, String dagName, int amPort,
+      Credentials credentials) throws IOException {
+    LlapDaemonProtocolProtos.QueryIdentifierProto qrId = LlapDaemonProtocolProtos.QueryIdentifierProto.newBuilder()
+        .setApplicationIdString(appId)
+        .setAppAttemptNumber(0)
+        .setDagIndex(dagId)
+        .build();
+    LlapDaemonProtocolProtos.SignableVertexSpec vSpec = LlapDaemonProtocolProtos.SignableVertexSpec.newBuilder()
+        .setQueryIdentifier(qrId)
+        .setVertexIndex(1)
+        .setDagName(dagName)
+        .setHiveQueryId(dagName)
+        .setVertexName("MockVertex")
+        .setUser("MockUser")
+        .setTokenIdentifier("MockToken_1")
+        .setProcessorDescriptor(LlapDaemonProtocolProtos.EntityDescriptorProto.newBuilder().setClassName("MockProcessor").build())
+        .build();
+    LlapDaemonProtocolProtos.FragmentRuntimeInfo frInfo = LlapDaemonProtocolProtos.FragmentRuntimeInfo.newBuilder()
+        .setDagStartTime(0)
+        .setFirstAttemptStartTime(0)
+        .setNumSelfAndUpstreamTasks(0)
+        .setNumSelfAndUpstreamCompletedTasks(0)
+        .setWithinDagPriority(1)
+        .build();
+    return SubmitWorkRequestProto.newBuilder()
+        .setAttemptNumber(0)
+        .setFragmentNumber(1)
+        .setWorkSpec(LlapDaemonProtocolProtos.VertexOrBinary.newBuilder().setVertex(vSpec).build())
+        .setAmHost("localhost")
+        .setAmPort(amPort)
+        .setCredentialsBinary(ByteString.copyFrom(LlapTezUtils.serializeCredentials(credentials)))
+        .setContainerIdString("MockContainer_1")
+        .setFragmentRuntimeInfo(frInfo)
+        .build();
+  }
+
+  public static LlapDaemonProtocolProtos.QueryCompleteRequestProto buildQueryCompleteRequest(String appId, int dagId) {
+    LlapDaemonProtocolProtos.QueryIdentifierProto qrId = LlapDaemonProtocolProtos.QueryIdentifierProto.newBuilder()
+        .setApplicationIdString(appId)
+        .setAppAttemptNumber(0)
+        .setDagIndex(dagId)
+        .build();
+    return LlapDaemonProtocolProtos.QueryCompleteRequestProto.newBuilder()
+        .setQueryIdentifier(qrId)
+        .setDeleteDelay(0)
+        .build();
+  }
+
+  public static LlapDaemonProtocolProtos.RegisterDagRequestProto buildRegisterDagRequest(String appId, int dagId,
+      Credentials credentials) throws IOException {
+    LlapDaemonProtocolProtos.QueryIdentifierProto qrId = LlapDaemonProtocolProtos.QueryIdentifierProto.newBuilder()
+        .setApplicationIdString(appId)
+        .setAppAttemptNumber(0)
+        .setDagIndex(dagId)
+        .build();
+    return LlapDaemonProtocolProtos.RegisterDagRequestProto.newBuilder()
+        .setQueryIdentifier(qrId)
+        .setUser("MockUser")
+        .setCredentialsBinary(ByteString.copyFrom(LlapTezUtils.serializeCredentials(credentials)))
+        .build();
+  }
+  
   public static SubmitWorkRequestProto buildSubmitProtoRequest(int fragmentNumber,
                                                                String appId, int dagId, int vId, String dagName,
                                                                int dagStartTime, int attemptStartTime, int numSelfAndUpstreamTasks, int numSelfAndUpstreamComplete,
diff --git a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TestLlapDaemonLogging.java b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TestLlapDaemonLogging.java
new file mode 100644
index 0000000000..467961a2c4
--- /dev/null
+++ b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TestLlapDaemonLogging.java
@@ -0,0 +1,151 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.llap.daemon.impl;
+
+import org.apache.hadoop.hive.llap.daemon.LlapDaemonExtension;
+import org.apache.hadoop.hive.llap.daemon.LlapDaemonTestUtils;
+import org.apache.hadoop.hive.llap.security.LlapTokenIdentifier;
+import org.apache.hadoop.io.Text;
+import org.apache.hadoop.security.Credentials;
+import org.apache.hadoop.security.token.Token;
+import org.apache.hive.testutils.junit.extensions.DoNothingTCPServer;
+import org.apache.hive.testutils.junit.extensions.DoNothingTCPServerExtension;
+import org.apache.hive.testutils.junit.extensions.Log4jConfig;
+import org.apache.tez.common.security.TokenCache;
+import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.extension.ExtendWith;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.util.regex.Pattern;
+import java.util.stream.Stream;
+
+import static org.junit.jupiter.api.Assertions.assertEquals;
+import static org.junit.jupiter.api.Assertions.assertTrue;
+
+/**
+ * Tests for the log4j configuration of the LLAP daemons.
+ */
+public class TestLlapDaemonLogging {
+
+  @Test
+  @Log4jConfig("llap-daemon-routing-log4j2.properties")
+  @ExtendWith(LlapDaemonExtension.class)
+  @ExtendWith(DoNothingTCPServerExtension.class)
+  void testQueryRoutingNoLeakFileDescriptors(LlapDaemon daemon, DoNothingTCPServer amMockServer)
+      throws IOException, InterruptedException {
+    final int amPort = amMockServer.port();
+    Credentials credentials = validSessionCredentials();
+    String appId = "application_1540489363818_0021";
+    for (int i = 0; i < 10; i++) {
+      String queryId = "query" + i;
+      int dagId = 1000 + i;
+      daemon.registerDag(LlapDaemonTestUtils.buildRegisterDagRequest(appId, dagId, credentials));
+      daemon.submitWork(LlapDaemonTestUtils.buildSubmitProtoRequest(appId, dagId, queryId, amPort, credentials));
+      daemon.queryComplete(LlapDaemonTestUtils.buildQueryCompleteRequest(appId, dagId));
+    }
+    // Busy wait till all daemon tasks are treated 
+    while (!daemon.getExecutorsStatus().isEmpty()) {
+      Thread.sleep(100);
+    }
+    // The IdlePurgePolicy used should close appenders after 5 seconds of inactivity.
+    // Wait for 8 sec to give some margin. 
+    Thread.sleep(8000);
+    Pattern pn = Pattern.compile("query\\d++-dag_1540489363818_0021_\\d{4}\\.log");
+    assertEquals(0, findOpenFileDescriptors(pn).count());
+  }
+
+  @Test
+  @Log4jConfig("llap-daemon-routing-log4j2.properties")
+  @ExtendWith(LlapDaemonExtension.class)
+  @ExtendWith(DoNothingTCPServerExtension.class)
+  void testQueryRoutingLogFileNameOnIncompleteQuery(LlapDaemon daemon, DoNothingTCPServer amMockServer)
+      throws IOException, InterruptedException {
+    final int amPort = amMockServer.port();
+    Credentials credentials = validSessionCredentials();
+    String appId = "application_2500489363818_0021";
+    String queryId = "query0";
+    int dagId = 2000;
+    daemon.registerDag(LlapDaemonTestUtils.buildRegisterDagRequest(appId, dagId, credentials));
+    daemon.submitWork(LlapDaemonTestUtils.buildSubmitProtoRequest(appId, dagId, queryId, amPort, credentials));
+    // Busy wait till all daemon tasks are treated 
+    while (!daemon.getExecutorsStatus().isEmpty()) {
+      Thread.sleep(100);
+    }
+    // The IdlePurgePolicy used should close appenders after 5 seconds of inactivity.
+    // Wait for 8 sec to give some margin. 
+    Thread.sleep(8000);
+    assertFileExists("query0-dag_2500489363818_0021_2000.log");
+  }
+
+  @Test
+  @Log4jConfig("llap-daemon-routing-log4j2.properties")
+  @ExtendWith(LlapDaemonExtension.class)
+  @ExtendWith(DoNothingTCPServerExtension.class)
+  void testQueryRoutingLogFileNameOnCompleteQuery(LlapDaemon daemon, DoNothingTCPServer amMockServer)
+      throws IOException, InterruptedException {
+    final int amPort = amMockServer.port();
+    Credentials credentials = validSessionCredentials();
+    String appId = "application_3500489363818_0021";
+    String queryId = "query0";
+    int dagId = 3000;
+    daemon.registerDag(LlapDaemonTestUtils.buildRegisterDagRequest(appId, dagId, credentials));
+    daemon.submitWork(LlapDaemonTestUtils.buildSubmitProtoRequest(appId, dagId, queryId, amPort, credentials));
+    daemon.queryComplete(LlapDaemonTestUtils.buildQueryCompleteRequest(appId, dagId));
+    // Busy wait till all daemon tasks are treated 
+    while (!daemon.getExecutorsStatus().isEmpty()) {
+      Thread.sleep(100);
+    }
+    // The IdlePurgePolicy used should close appenders after 5 seconds of inactivity.
+    // Wait for 8 sec to give some margin. 
+    Thread.sleep(8000);
+    // A complete query should always have a corresponding log file with ".done" suffix
+    assertFileExists("query0-dag_3500489363818_0021_3000.log.done");
+  }
+
+  private static Credentials validSessionCredentials() {
+    Credentials credentials = new Credentials();
+    Token<LlapTokenIdentifier> sessionToken =
+        new Token<>("foo".getBytes(), "bar".getBytes(), new Text("kind"), new Text("service"));
+    TokenCache.setSessionToken(sessionToken, credentials);
+    return credentials;
+  }
+
+  private static Stream<Path> findOpenFileDescriptors(Pattern searchPattern) throws IOException {
+    return Files.walk(Paths.get("/proc/self/fd")).filter(p -> {
+      Path resolved = p;
+      if (Files.isSymbolicLink(p)) {
+        try {
+          resolved = Files.readSymbolicLink(p);
+        } catch (IOException exception) {
+          throw new UncheckedIOException(exception);
+        }
+      }
+      return searchPattern.matcher(resolved.toString()).find();
+    });
+  }
+
+  private static void assertFileExists(String fileName) throws IOException {
+    boolean found = Files.walk(Paths.get(System.getProperty("java.io.tmpdir"))).anyMatch(p -> p.endsWith(fileName));
+    assertTrue(found, "File " + fileName + " was not found under " + System.getProperty("java.io.tmpdir"));
+  }
+
+}
diff --git a/llap-server/src/test/resources/llap-daemon-routing-log4j2.properties b/llap-server/src/test/resources/llap-daemon-routing-log4j2.properties
new file mode 100644
index 0000000000..c791ca71c1
--- /dev/null
+++ b/llap-server/src/test/resources/llap-daemon-routing-log4j2.properties
@@ -0,0 +1,160 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# This is an almost identical copy of llap-server/src/main/resources/llap-daemon-log4j2.properties file. 
+# Differences with the original file:
+# - Global configuration name to be able to distinguish easily
+# - Default value for llap.daemon.root.logger is set to query-routing which is the main appender under test  
+# - Default value for llap.daemon.log.dir is java.io.tmpdir to avoid polluting the current directory when running tests
+# - purgePolicy.timeToLive is set to 5 sec so that tests finish faster (value should be much bigger in prod) 
+
+status = INFO
+name = TestLlapDaemonRoutingLog4j2
+packages = org.apache.hadoop.hive.ql.log
+
+# list of properties
+property.llap.daemon.log.level = INFO
+property.llap.daemon.root.logger = query-routing
+property.llap.daemon.log.dir = ${sys:java.io.tmpdir}
+property.llap.daemon.log.file = llapdaemon.log
+property.llap.daemon.historylog.file = llapdaemon_history.log
+property.llap.daemon.log.maxfilesize = 256MB
+property.llap.daemon.log.maxbackupindex = 240
+
+# list of all appenders
+appenders = console, RFA, HISTORYAPPENDER, query-routing
+
+# console appender
+appender.console.type = Console
+appender.console.name = console
+appender.console.target = SYSTEM_ERR
+appender.console.layout.type = PatternLayout
+appender.console.layout.pattern = %d{ISO8601} %5p [%t (%X{fragmentId})] %c{2}: %m%n
+
+# rolling file appender
+appender.RFA.type = RollingRandomAccessFile
+appender.RFA.name = RFA
+appender.RFA.fileName = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.log.file}
+appender.RFA.filePattern = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.log.file}_%d{yyyy-MM-dd-HH}_%i.done
+appender.RFA.layout.type = PatternLayout
+appender.RFA.layout.pattern = %d{ISO8601} %-5p [%t (%X{fragmentId})] %c: %m%n
+appender.RFA.policies.type = Policies
+appender.RFA.policies.time.type = TimeBasedTriggeringPolicy
+appender.RFA.policies.time.interval = 1
+appender.RFA.policies.time.modulate = true
+appender.RFA.policies.size.type = SizeBasedTriggeringPolicy
+appender.RFA.policies.size.size = ${sys:llap.daemon.log.maxfilesize}
+appender.RFA.strategy.type = DefaultRolloverStrategy
+appender.RFA.strategy.max = ${sys:llap.daemon.log.maxbackupindex}
+
+# history file appender
+appender.HISTORYAPPENDER.type = RollingRandomAccessFile
+appender.HISTORYAPPENDER.name = HISTORYAPPENDER
+appender.HISTORYAPPENDER.fileName = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.historylog.file}
+appender.HISTORYAPPENDER.filePattern = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.historylog.file}_%d{yyyy-MM-dd-HH}_%i.done
+appender.HISTORYAPPENDER.layout.type = PatternLayout
+appender.HISTORYAPPENDER.layout.pattern = %m%n
+appender.HISTORYAPPENDER.policies.type = Policies
+appender.HISTORYAPPENDER.policies.size.type = SizeBasedTriggeringPolicy
+appender.HISTORYAPPENDER.policies.size.size = ${sys:llap.daemon.log.maxfilesize}
+appender.HISTORYAPPENDER.policies.time.type = TimeBasedTriggeringPolicy
+appender.HISTORYAPPENDER.policies.time.interval = 1
+appender.HISTORYAPPENDER.policies.time.modulate = true
+appender.HISTORYAPPENDER.strategy.type = DefaultRolloverStrategy
+appender.HISTORYAPPENDER.strategy.max = ${sys:llap.daemon.log.maxbackupindex}
+
+# queryId based routing file appender
+appender.query-routing.type = Routing
+appender.query-routing.name = query-routing
+appender.query-routing.routes.type = Routes
+appender.query-routing.routes.pattern = $${ctx:queryId}
+#Purge policy for query-based Routing Appender
+appender.query-routing.purgePolicy.type = IdlePurgePolicy
+appender.query-routing.purgePolicy.timeToLive = 5
+appender.query-routing.purgePolicy.timeUnit = SECONDS
+# default route
+appender.query-routing.routes.route-default.type = Route
+appender.query-routing.routes.route-default.key = $${ctx:queryId}
+appender.query-routing.routes.route-default.ref = RFA
+# queryId based route
+appender.query-routing.routes.route-mdc.type = Route
+appender.query-routing.routes.route-mdc.file-mdc.type = LlapRandomAccessFileAppender
+appender.query-routing.routes.route-mdc.file-mdc.name = query-file-appender
+appender.query-routing.routes.route-mdc.file-mdc.fileName = ${sys:llap.daemon.log.dir}/${ctx:queryId}-${ctx:dagId}.log
+appender.query-routing.routes.route-mdc.file-mdc.layout.type = PatternLayout
+appender.query-routing.routes.route-mdc.file-mdc.layout.pattern = %d{ISO8601} %5p [%t (%X{fragmentId})] %c{2}: %m%n
+
+# list of all loggers
+loggers = PerfLogger, EncodedReader, NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, HistoryLogger, LlapIoImpl, LlapIoOrc, LlapIoCache, LlapIoLocking, TezSM, TezSS, TezHC, LlapDaemon, TaskExecutorService
+
+logger.LlapDaemon.name = org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon
+logger.LlapDaemon.level = INFO
+
+logger.TaskExecutorService.name = org.apache.hadoop.hive.llap.daemon.impl.TaskExecutorService
+logger.TaskExecutorService.level = INFO
+
+# shut up the Tez logs that log debug-level stuff on INFO
+
+logger.TezSM.name = org.apache.tez.runtime.library.common.shuffle.impl.ShuffleManager.fetch
+logger.TezSM.level = WARN
+logger.TezSS.name = org.apache.tez.runtime.library.common.shuffle.orderedgrouped.ShuffleScheduler.fetch
+logger.TezSS.level = WARN
+logger.TezHC.name = org.apache.tez.http.HttpConnection.url
+logger.TezHC.level = WARN
+
+logger.PerfLogger.name = org.apache.hadoop.hive.ql.log.PerfLogger
+logger.PerfLogger.level = DEBUG
+
+logger.EncodedReader.name = org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl
+logger.EncodedReader.level = INFO
+
+logger.LlapIoImpl.name = LlapIoImpl
+logger.LlapIoImpl.level = INFO
+
+logger.LlapIoOrc.name = LlapIoOrc
+logger.LlapIoOrc.level = WARN
+
+logger.LlapIoCache.name = LlapIoCache
+logger.LlapIoCache.level = WARN
+
+logger.LlapIoLocking.name = LlapIoLocking
+logger.LlapIoLocking.level = WARN
+
+logger.NIOServerCnxn.name = org.apache.zookeeper.server.NIOServerCnxn
+logger.NIOServerCnxn.level = WARN
+
+logger.ClientCnxnSocketNIO.name = org.apache.zookeeper.ClientCnxnSocketNIO
+logger.ClientCnxnSocketNIO.level = WARN
+
+logger.DataNucleus.name = DataNucleus
+logger.DataNucleus.level = ERROR
+
+logger.Datastore.name = Datastore
+logger.Datastore.level = ERROR
+
+logger.JPOX.name = JPOX
+logger.JPOX.level = ERROR
+
+logger.HistoryLogger.name = org.apache.hadoop.hive.llap.daemon.HistoryLogger
+logger.HistoryLogger.level = INFO
+logger.HistoryLogger.additivity = false
+logger.HistoryLogger.appenderRefs = HistoryAppender
+logger.HistoryLogger.appenderRef.HistoryAppender.ref = HISTORYAPPENDER
+
+# root logger
+rootLogger.level = ${sys:llap.daemon.log.level}
+rootLogger.appenderRefs = root
+rootLogger.appenderRef.root.ref = ${sys:llap.daemon.root.logger}
diff --git a/testutils/src/java/org/apache/hive/testutils/junit/extensions/DoNothingTCPServer.java b/testutils/src/java/org/apache/hive/testutils/junit/extensions/DoNothingTCPServer.java
new file mode 100644
index 0000000000..58da3cf3aa
--- /dev/null
+++ b/testutils/src/java/org/apache/hive/testutils/junit/extensions/DoNothingTCPServer.java
@@ -0,0 +1,58 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hive.testutils.junit.extensions;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.net.ServerSocket;
+import java.net.Socket;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * A TCP server that accepts a client connection and closes it immediately.
+ */
+public class DoNothingTCPServer {
+  private static final AtomicInteger ID = new AtomicInteger(0);
+  private final ServerSocket socket;
+
+  DoNothingTCPServer() throws IOException {
+    this.socket = new ServerSocket();
+  }
+
+  void start() throws IOException {
+    socket.bind(null);
+    Thread t = new Thread(() -> {
+      while (true) {
+        try (@SuppressWarnings("unused") Socket clientSocket = socket.accept()) {
+        } catch (IOException exception) {
+          throw new UncheckedIOException(exception);
+        }
+      }
+    }, "ListeningServer-" + socket.getLocalPort() + "-" + ID.getAndIncrement());
+    t.start();
+  }
+
+  public int port() {
+    return socket.getLocalPort();
+  }
+
+  void stop() throws IOException {
+    socket.close();
+  }
+
+}
diff --git a/testutils/src/java/org/apache/hive/testutils/junit/extensions/DoNothingTCPServerExtension.java b/testutils/src/java/org/apache/hive/testutils/junit/extensions/DoNothingTCPServerExtension.java
new file mode 100644
index 0000000000..c90e1e92a5
--- /dev/null
+++ b/testutils/src/java/org/apache/hive/testutils/junit/extensions/DoNothingTCPServerExtension.java
@@ -0,0 +1,67 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hive.testutils.junit.extensions;
+
+import org.junit.jupiter.api.extension.AfterEachCallback;
+import org.junit.jupiter.api.extension.ExtensionContext;
+import org.junit.jupiter.api.extension.ParameterContext;
+import org.junit.jupiter.api.extension.ParameterResolutionException;
+import org.junit.jupiter.api.extension.ParameterResolver;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * A JUnit Jupiter extension for creating and destroying TCP servers.
+ *
+ * @see DoNothingTCPServer
+ */
+public class DoNothingTCPServerExtension implements ParameterResolver, AfterEachCallback {
+  
+  @Override
+  public boolean supportsParameter(ParameterContext parameterContext, ExtensionContext extensionContext)
+      throws ParameterResolutionException {
+    return parameterContext.getParameter().getType() == DoNothingTCPServer.class;
+  }
+
+  @Override
+  public Object resolveParameter(ParameterContext parameterContext, ExtensionContext context)
+      throws ParameterResolutionException {
+    List<DoNothingTCPServer> servers = (List<DoNothingTCPServer>) context.getStore(ExtensionContext.Namespace.GLOBAL)
+        .getOrComputeIfAbsent(context.getUniqueId(), (id) -> new ArrayList<DoNothingTCPServer>());
+    try {
+      DoNothingTCPServer server = new DoNothingTCPServer();
+      server.start();
+      servers.add(server);
+      return server;
+    } catch (IOException e) {
+      throw new ParameterResolutionException("Problem when initialising the server; see cause for details.", e);
+    }
+  }
+
+  @Override
+  public void afterEach(ExtensionContext context) throws Exception {
+    List<DoNothingTCPServer> servers =
+        (List<DoNothingTCPServer>) context.getStore(ExtensionContext.Namespace.GLOBAL).remove(context.getUniqueId());
+    for (DoNothingTCPServer s : servers) {
+      s.stop();
+    }
+  }
+
+}
diff --git a/testutils/src/test/java/org/apache/hive/testutils/junit/extensions/TestDoNothingTCPServerExtension.java b/testutils/src/test/java/org/apache/hive/testutils/junit/extensions/TestDoNothingTCPServerExtension.java
new file mode 100644
index 0000000000..295603a386
--- /dev/null
+++ b/testutils/src/test/java/org/apache/hive/testutils/junit/extensions/TestDoNothingTCPServerExtension.java
@@ -0,0 +1,58 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hive.testutils.junit.extensions;
+
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.extension.ExtendWith;
+
+import java.io.IOException;
+import java.net.InetSocketAddress;
+import java.net.Socket;
+import java.util.Arrays;
+
+/**
+ * Tests for {@link DoNothingTCPServerExtension}.
+ */
+public class TestDoNothingTCPServerExtension {
+
+  @Test
+  @ExtendWith(DoNothingTCPServerExtension.class)
+  void testSingleServerListening(DoNothingTCPServer server) throws IOException {
+    try (Socket socket = new Socket()) {
+      socket.connect(new InetSocketAddress("localhost", server.port()), 1000);
+    }
+  }
+
+  @Test
+  @ExtendWith(DoNothingTCPServerExtension.class)
+  void testMultipleServersListening(DoNothingTCPServer s1, DoNothingTCPServer s2) throws IOException {
+    for (DoNothingTCPServer s : Arrays.asList(s1, s2)) {
+      try (Socket socket = new Socket()) {
+        socket.connect(new InetSocketAddress("localhost", s.port()), 1000);
+      }
+    }
+  }
+
+  @Test
+  @ExtendWith(DoNothingTCPServerExtension.class)
+  void testMultipleServersDistinct(DoNothingTCPServer s1, DoNothingTCPServer s2) {
+    Assertions.assertNotEquals(s1, s2);
+    Assertions.assertNotEquals(s1.port(), s2.port());
+  }
+}
