diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/OptimisedBootstrapUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/OptimisedBootstrapUtils.java
index 13ecf25571..c621194963 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/OptimisedBootstrapUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/OptimisedBootstrapUtils.java
@@ -24,6 +24,7 @@
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.fs.RemoteIterator;
 import org.apache.hadoop.hive.common.FileUtils;
+import org.apache.hadoop.hive.conf.Constants;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.api.Database;
 import org.apache.hadoop.hive.metastore.api.NotificationEvent;
@@ -258,9 +259,10 @@ public static Long createAndGetEventAckFile(Path currentDumpPath, DumpMetaData d
     Path filePath = new Path(currentDumpPath, EVENT_ACK_FILE);
     Utils.writeOutput(dbEventId + FILE_ENTRY_SEPARATOR + targetDbEventId, filePath, conf);
     LOG.info("Created event_ack file at {} with source eventId {} and target eventId {}", filePath, dbEventId,
-        targetDbEventId);
+            targetDbEventId);
     work.setResultValues(Arrays.asList(currentDumpPath.toUri().toString(), String.valueOf(lastReplId)));
-    dmd.setDump(DumpType.PRE_OPTIMIZED_BOOTSTRAP, work.eventFrom, lastReplId, cmRoot, -1L, false);
+    long executionId = conf.getLong(Constants.SCHEDULED_QUERY_EXECUTIONID, 0L);
+    dmd.setDump(DumpType.PRE_OPTIMIZED_BOOTSTRAP, work.eventFrom, lastReplId, cmRoot, executionId, false);
     dmd.write(true);
     return lastReplId;
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadWork.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadWork.java
index 6ef95ea55e..2f9214f707 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadWork.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadWork.java
@@ -93,7 +93,7 @@ public class ReplLoadWork implements Serializable, ReplLoadWorkMBean {
   private Iterator<String> externalTableDataCopyItr;
   private ReplStatsTracker replStatsTracker;
   private String scheduledQueryName;
-  private String executionId;
+  private Long executionId;
   private boolean shouldFailover;
   public boolean isFirstFailover;
   public boolean isSecondFailover;
@@ -205,7 +205,7 @@ private ObjectName initializeMetricsMBeans(HiveConf hiveConf, String dbNameToLoa
       scheduledQueryName = hiveConf.get(SCHEDULED_QUERY_SCHEDULENAME, "");
       // If the scheduled query name isn't available we don't enable JMX.
       if (!StringUtils.isEmpty(scheduledQueryName) || enableMBeansRegistrationForTests) {
-        executionId = hiveConf.get(SCHEDULED_QUERY_EXECUTIONID, "N/A");
+        executionId = hiveConf.getLong(SCHEDULED_QUERY_EXECUTIONID, 0L);
         String metricsName = "Database-" + dbNameToLoadIn + " Policy-" + scheduledQueryName;
         // Clean-up any MBean registered previously, which couldn't be cleaned up due to some previous error.
         unRegisterMBeanIfRegistered("HiveServer2", metricsName, Collections.emptyMap());
@@ -378,7 +378,7 @@ public String getScheduledQueryName() {
   }
 
   @Override
-  public String getExecutionId() {
+  public Long getExecutionId() {
     return executionId;
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadWorkMBean.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadWorkMBean.java
index 602d5f7b2e..404cc52494 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadWorkMBean.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplLoadWorkMBean.java
@@ -45,9 +45,10 @@ public interface ReplLoadWorkMBean {
 
   /**
    * Gets the execution id of the policy.
+   *
    * @return the execution id.
    */
-  public String getExecutionId();
+  public Long getExecutionId();
 
   /**
    * Gets the dump directory.
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/ReplicationSemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/ReplicationSemanticAnalyzer.java
index 1a58664610..f4514d700c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/ReplicationSemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/ReplicationSemanticAnalyzer.java
@@ -25,6 +25,7 @@
 import org.apache.hadoop.hive.common.ValidTxnList;
 import org.apache.hadoop.hive.common.repl.ReplConst;
 import org.apache.hadoop.hive.common.repl.ReplScope;
+import org.apache.hadoop.hive.conf.Constants;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.api.Database;
 import org.apache.hadoop.hive.metastore.utils.MetaStoreUtils;
@@ -368,7 +369,7 @@ private void analyzeReplLoad(ASTNode ast) throws SemanticException {
                 metricCollector, dmd.isReplScopeModified());
         rootTasks.add(TaskFactory.get(replLoadWork, conf));
         if (dmd.isPreOptimizedBootstrapDump()) {
-          dmd.setOptimizedBootstrapToDumpMetadataFile();
+          dmd.setOptimizedBootstrapToDumpMetadataFile(conf.getLong(Constants.SCHEDULED_QUERY_EXECUTIONID, 0L));
         }
       } else {
         ReplUtils.reportStatusInReplicationMetrics("REPL_LOAD", Status.SKIPPED, null, conf,  sourceDbNameOrPattern, null);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/load/DumpMetaData.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/load/DumpMetaData.java
index 669ecc639b..e99caecd8a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/load/DumpMetaData.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/load/DumpMetaData.java
@@ -214,10 +214,10 @@ public boolean isOptimizedBootstrapDump() throws SemanticException {
     return (this.dumpType == DumpType.OPTIMIZED_BOOTSTRAP);
   }
 
-  public void setOptimizedBootstrapToDumpMetadataFile() throws SemanticException {
+  public void setOptimizedBootstrapToDumpMetadataFile(long executionId) throws SemanticException {
 
     assert (this.getDumpType() == DumpType.PRE_OPTIMIZED_BOOTSTRAP);
-    this.setDump(DumpType.OPTIMIZED_BOOTSTRAP, -1L, -1L, null, -1L, false);
+    this.setDump(DumpType.OPTIMIZED_BOOTSTRAP, -1L, -1L, null, executionId, false);
     this.write(true);
   }
 
