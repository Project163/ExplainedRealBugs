diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java
index 8f0ca290eb..c20edd8037 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java
@@ -87,7 +87,7 @@ public void processOp(Object row, int tag) throws HiveException {
       }
 
       // number of rows for the key in the given table
-      int sz = storage[alias].size();
+      long sz = storage[alias].size();
       StructObjectInspector soi = (StructObjectInspector) inputObjInspectors[tag];
       StructField sf = soi.getStructFieldRef(Utilities.ReduceField.KEY
           .toString());
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/AbstractRowContainer.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/AbstractRowContainer.java
index 00021c9147..d927a8074f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/AbstractRowContainer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/AbstractRowContainer.java
@@ -38,7 +38,7 @@ public AbstractRowContainer() {
    * @return number of elements in the RowContainer
    */
 
-  public abstract int size();
+  public abstract long size();
 
   /**
    * Remove all elements in the RowContainer.
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinObjectValue.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinObjectValue.java
index e9e7d5c8ff..58a9dc00a6 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinObjectValue.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinObjectValue.java
@@ -140,7 +140,7 @@ public void writeExternal(ObjectOutput out) throws IOException {
 
       // Different processing for key and value
       MapJoinRowContainer<Object[]> v = obj;
-      out.writeInt(v.size());
+      out.writeInt((int)v.size());
       if (v.size() > 0) {
         Object[] row = v.first();
         out.writeInt(row.length);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinRowContainer.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinRowContainer.java
index 67aa1080ab..c4c1629ed2 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinRowContainer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinRowContainer.java
@@ -65,7 +65,7 @@ public Row next() throws HiveException {
    * @return number of elements in the RowContainer
    */
   @Override
-  public int size() {
+  public long size() {
     return list.size();
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java
index 193b290408..1c7ab7a9ec 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java
@@ -86,7 +86,7 @@ public class RowContainer<Row extends List<Object>> extends AbstractRowContainer
   private int blockSize; // number of objects in the block before it is spilled
   // to disk
   private int numFlushedBlocks; // total # of blocks
-  private int size; // total # of elements in the RowContainer
+  private long size;    // total # of elements in the RowContainer
   private File tmpFile; // temporary file holding the spilled blocks
   Path tempOutPath = null;
   private File parentFile;
@@ -283,7 +283,7 @@ private void removeKeys(Row ret) {
     }
   }
 
-  ArrayList<Object> row = new ArrayList<Object>(2);
+  private final ArrayList<Object> row = new ArrayList<Object>(2);
 
   private void spillBlock(Row[] block, int length) throws HiveException {
     try {
@@ -360,7 +360,7 @@ private void spillBlock(Row[] block, int length) throws HiveException {
    * @return number of elements in the RowContainer
    */
   @Override
-  public int size() {
+  public long size() {
     return size;
   }
 
