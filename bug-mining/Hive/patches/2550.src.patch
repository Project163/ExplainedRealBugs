diff --git a/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStorePartitionSpecs.java b/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStorePartitionSpecs.java
index 64f18ec8fd..17a57f08c7 100644
--- a/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStorePartitionSpecs.java
+++ b/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStorePartitionSpecs.java
@@ -11,7 +11,6 @@
 import org.apache.hadoop.hive.metastore.partition.spec.CompositePartitionSpecProxy;
 import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;
 import org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe;
-import org.apache.hadoop.util.ExitUtil;
 import org.junit.AfterClass;
 import org.junit.Assert;
 import org.junit.BeforeClass;
@@ -52,7 +51,7 @@ public void checkPermission(Permission perm, Object context) {
     public void checkExit(int status) {
 
       super.checkExit(status);
-      throw new ExitUtil.ExitException(status, "System.exit() was called. Raising exception. ");
+      throw new RuntimeException("System.exit() was called. Raising exception. ");
     }
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/CustomPartitionEdge.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/CustomPartitionEdge.java
index 359a4d224e..6c3ba3aa71 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/CustomPartitionEdge.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/CustomPartitionEdge.java
@@ -26,7 +26,6 @@
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.hadoop.io.DataInputByteBuffer;
 import org.apache.tez.dag.api.EdgeManagerPlugin;
 import org.apache.tez.dag.api.EdgeManagerPluginContext;
 import org.apache.tez.runtime.api.events.DataMovementEvent;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/DataInputByteBuffer.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/DataInputByteBuffer.java
new file mode 100644
index 0000000000..f278b4b6f0
--- /dev/null
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/DataInputByteBuffer.java
@@ -0,0 +1,98 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.exec.tez;
+
+import java.io.DataInputStream;
+import java.io.InputStream;
+import java.nio.ByteBuffer;
+
+public class DataInputByteBuffer extends DataInputStream {
+
+  private static class Buffer extends InputStream {
+    private final byte[] scratch = new byte[1];
+    ByteBuffer[] buffers = new ByteBuffer[0];
+    int bidx, pos, length;
+    @Override
+    public int read() {
+      if (-1 == read(scratch, 0, 1)) {
+        return -1;
+      }
+      return scratch[0] & 0xFF;
+    }
+    @Override
+    public int read(byte[] b, int off, int len) {
+      if (bidx >= buffers.length) {
+        return -1;
+      }
+      int cur = 0;
+      do {
+        int rem = Math.min(len, buffers[bidx].remaining());
+        buffers[bidx].get(b, off, rem);
+        cur += rem;
+        off += rem;
+        len -= rem;
+      } while (len > 0 && ++bidx < buffers.length);
+      pos += cur;
+      return cur;
+    }
+    public void reset(ByteBuffer[] buffers) {
+      bidx = pos = length = 0;
+      this.buffers = buffers;
+      for (ByteBuffer b : buffers) {
+        length += b.remaining();
+      }
+    }
+    public int getPosition() {
+      return pos;
+    }
+    public int getLength() {
+      return length;
+    }
+    public ByteBuffer[] getData() {
+      return buffers;
+    }
+  }
+
+  private Buffer buffers;
+
+  public DataInputByteBuffer() {
+    this(new Buffer());
+  }
+
+  private DataInputByteBuffer(Buffer buffers) {
+    super(buffers);
+    this.buffers = buffers;
+  }
+
+  public void reset(ByteBuffer... input) {
+    buffers.reset(input);
+  }
+
+  public ByteBuffer[] getData() {
+    return buffers.getData();
+  }
+
+  public int getPosition() {
+    return buffers.getPosition();
+  }
+
+  public int getLength() {
+    return buffers.getLength();
+  }
+}
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java
index a9bb143e97..ca86ef6cda 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java
@@ -311,7 +311,7 @@ public static boolean isAcid(Path directory,
       String filename = file.getPath().getName();
       if (filename.startsWith(BASE_PREFIX) ||
           filename.startsWith(DELTA_PREFIX)) {
-        if (file.isDirectory()) {
+        if (file.isDir()) {
           return true;
         }
       }
