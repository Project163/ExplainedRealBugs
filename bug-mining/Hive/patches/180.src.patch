diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java
index 373094a72f..ae00ae282c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java
@@ -124,7 +124,7 @@ public void map(Object key, Object value,
         }
 
         rp = reporter;
-      } catch (HiveException e) {
+      } catch (Exception e) {
         abort = true;
         e.printStackTrace();
         throw new RuntimeException ("Map operator initialization failed", e);
@@ -137,10 +137,10 @@ public void map(Object key, Object value,
       else
         // Since there is no concept of a group, we don't invoke startGroup/endGroup for a mapper
         mo.process((Writable)value);
-    } catch (HiveException e) {
+    } catch (Exception e) {
       abort = true;
       e.printStackTrace();
-      throw new RuntimeException (e.getMessage(), e);
+      throw new RuntimeException ("Map operator process failed", e);
     }
   }
 
@@ -151,7 +151,7 @@ public void close() {
         l4j.trace("Close called no row");
         mo.initialize(jc, null, null);
         rp = null;
-      } catch (HiveException e) {
+      } catch (Exception e) {
         abort = true;
         e.printStackTrace();
         throw new RuntimeException ("Map operator close failed during initialize", e);
@@ -177,11 +177,11 @@ public void close() {
       reportStats rps = new reportStats (rp);
       mo.preorderMap(rps);
       return;
-    } catch (HiveException e) {
+    } catch (Exception e) {
       if(!abort) {
         // signal new failure to map-reduce
         l4j.error("Hit error while closing operators - failing tree");
-        throw new RuntimeException ("Error while closing operators");
+        throw new RuntimeException ("Error while closing operators", e);
       }
     }
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecReducer.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecReducer.java
index 9ed8798839..073009de66 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecReducer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecReducer.java
@@ -93,7 +93,7 @@ public void configure(JobConf job) {
         rowObjectInspector[tag] = ObjectInspectorFactory.getStandardStructObjectInspector(
             Arrays.asList(fieldNames), ois);
       }
-    } catch (SerDeException e) {
+    } catch (Exception e) {
       throw new RuntimeException(e);
     }    
   }
@@ -118,10 +118,10 @@ public void reduce(Object key, Iterator values,
         reducer.setOutputCollector(oc);
         reducer.initialize(jc, reporter, rowObjectInspector);
         rp = reporter;
-      } catch (HiveException e) {
+      } catch (Exception e) {
         abort = true;
         e.printStackTrace();
-        throw new RuntimeException ("Reduce operator initialization failed");
+        throw new RuntimeException ("Reduce operator process failed", e);
       }
     }
 
@@ -150,7 +150,7 @@ public void reduce(Object key, Iterator values,
       }
       try {
         keyObject = inputKeyDeserializer.deserialize(keyWritable);
-      } catch (SerDeException e) {
+      } catch (Exception e) {
         throw new HiveException(e);
       }
       // System.err.print(keyObject.toString());
@@ -175,7 +175,7 @@ public void reduce(Object key, Iterator values,
         reducer.process(row, rowObjectInspector[tag.get()], tag.get());
       }
 
-    } catch (HiveException e) {
+    } catch (Exception e) {
       abort = true;
       throw new IOException (e);
     }
@@ -198,7 +198,7 @@ public void close() {
         l4j.trace("Close called no row");
         reducer.initialize(jc, null, rowObjectInspector);
         rp = null;
-      } catch (HiveException e) {
+      } catch (Exception e) {
         abort = true;
         e.printStackTrace();
         throw new RuntimeException ("Reduce operator close failed during initialize", e);
@@ -216,7 +216,7 @@ public void close() {
       reportStats rps = new reportStats (rp);
       reducer.preorderMap(rps);
       return;
-    } catch (HiveException e) {
+    } catch (Exception e) {
       if(!abort) {
         // signal new failure to map-reduce
         l4j.error("Hit error while closing operators - failing tree");
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
index 09d31160a4..963e5fcf09 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
@@ -79,17 +79,18 @@ public void close(boolean abort) throws HiveException {
       return;
 
     state = state.CLOSE;
-    if(!abort) {
+    if (!abort) {
       if (outWriter != null) {
         try {
           outWriter.close(abort);
           commit();
         } catch (IOException e) {
-          // Don't throw an exception, just ignore and return
-          return;
+          throw new HiveException(e);
         }
       }
     } else {
+      // Will come here if an Exception was thrown in map() or reduce().
+      // Hadoop always call close() even if an Exception was thrown in map() or reduce(). 
       try {
         outWriter.close(abort);
         if(!autoDelete)
