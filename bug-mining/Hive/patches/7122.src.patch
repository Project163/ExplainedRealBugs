diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersWorkloadManager.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersWorkloadManager.java
index 6a59ff1161..06dd6d04a7 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersWorkloadManager.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersWorkloadManager.java
@@ -17,6 +17,7 @@
 package org.apache.hive.jdbc;
 
 import java.io.File;
+import java.io.FileWriter;
 import java.net.URL;
 import java.util.HashMap;
 import java.util.List;
@@ -57,6 +58,12 @@ public static void beforeTest() throws Exception {
 
     String confDir = "../../data/conf/llap/";
     HiveConf.setHiveSiteLocation(new URL("file://" + new File(confDir).toURI().getPath() + "/hive-site.xml"));
+    conf = new HiveConf();
+    conf.setVar(ConfVars.HIVE_AUTHENTICATOR_MANAGER, "org.apache.hadoop.hive.ql.security.SessionStateUserAuthenticator");
+    java.nio.file.Path confPath = File.createTempFile("hive", "test").toPath();
+    conf.writeXml(new FileWriter(confPath.toFile()));
+    HiveConf.setHiveSiteLocation(new URL("file://" + confPath.toString()));
+
     System.out.println("Setting hive-site: " + HiveConf.getHiveSiteLocation());
 
     conf = new HiveConf();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/KillTriggerActionHandler.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/KillTriggerActionHandler.java
index 06e9ff6d66..cb279987a0 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/KillTriggerActionHandler.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/KillTriggerActionHandler.java
@@ -16,6 +16,7 @@
 
 package org.apache.hadoop.hive.ql.exec.tez;
 
+import java.io.IOException;
 import java.util.Map;
 
 import org.apache.hadoop.hive.conf.HiveConf;
@@ -24,6 +25,7 @@
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.hive.ql.wm.Trigger;
 import org.apache.hadoop.hive.ql.wm.TriggerActionHandler;
+import org.apache.hadoop.security.UserGroupInformation;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -41,7 +43,8 @@ public void applyAction(final Map<TezSessionState, Trigger> queriesViolated) {
         TezSessionState sessionState = entry.getKey();
         String queryId = sessionState.getWmContext().getQueryId();
         try {
-          SessionState ss = new SessionState(new HiveConf());
+          UserGroupInformation ugi = UserGroupInformation.getCurrentUser();
+          SessionState ss = new SessionState(new HiveConf(), ugi.getShortUserName());
           ss.setIsHiveServerQuery(true);
           SessionState.start(ss);
           KillQuery killQuery = sessionState.getKillQuery();
@@ -50,7 +53,7 @@ public void applyAction(final Map<TezSessionState, Trigger> queriesViolated) {
             sessionState.getKillQuery().killQuery(queryId, entry.getValue().getViolationMsg(),
                       sessionState.getConf());
           }
-        } catch (HiveException e) {
+        } catch (HiveException|IOException e) {
           LOG.warn("Unable to kill query {} for trigger violation", queryId);
         }
         break;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/WorkloadManager.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/WorkloadManager.java
index f8fa0cd1dd..7ede4c8dd9 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/WorkloadManager.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/WorkloadManager.java
@@ -30,6 +30,7 @@
 import com.google.common.util.concurrent.SettableFuture;
 import com.google.common.util.concurrent.ThreadFactoryBuilder;
 
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
@@ -76,6 +77,7 @@
 import org.apache.hadoop.hive.ql.wm.WmContext;
 import org.apache.hadoop.metrics2.MetricsSystem;
 import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
+import org.apache.hadoop.security.UserGroupInformation;
 import org.apache.hive.common.util.Ref;
 import org.apache.tez.dag.api.TezConfiguration;
 import org.codehaus.jackson.annotate.JsonAutoDetect;
@@ -427,9 +429,6 @@ private void scheduleWork(WmThreadSyncWork context) {
       final String reason = killCtx.reason;
       LOG.info("Killing query for {}", toKill);
       workPool.submit(() -> {
-        SessionState ss = new SessionState(new HiveConf());
-        ss.setIsHiveServerQuery(true);
-        SessionState.start(ss);
         // Note: we get query ID here, rather than in the caller, where it would be more correct
         //       because we know which exact query we intend to kill. This is valid because we
         //       are not expecting query ID to change - we never reuse the session for which a
@@ -441,13 +440,17 @@ private void scheduleWork(WmThreadSyncWork context) {
             WmEvent wmEvent = new WmEvent(WmEvent.EventType.KILL);
             LOG.info("Invoking KillQuery for " + queryId + ": " + reason);
             try {
+              UserGroupInformation ugi = UserGroupInformation.getCurrentUser();
+              SessionState ss = new SessionState(new HiveConf(), ugi.getShortUserName());
+              ss.setIsHiveServerQuery(true);
+              SessionState.start(ss);
               kq.killQuery(queryId, reason, toKill.getConf());
               addKillQueryResult(toKill, true);
               killCtx.killSessionFuture.set(true);
               wmEvent.endEvent(toKill);
               LOG.debug("Killed " + queryId);
               return;
-            } catch (HiveException ex) {
+            } catch (HiveException|IOException ex) {
               LOG.error("Failed to kill " + queryId + "; will try to restart AM instead" , ex);
             }
           } else {
