diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java b/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java
index a6d2a0497c..9219d282d6 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java
@@ -752,14 +752,21 @@ private OrcProto.StripeFooter getStripeFooterFromCacheOrDisk(
     CompressionKind kind = orcReader.getCompressionKind();
     boolean isPool = useCodecPool;
     CompressionCodec codec = isPool ? OrcCodecPool.getCodec(kind) : WriterImpl.createCodec(kind);
+    boolean isCodecError = true;
     try {
-      return buildStripeFooter(Lists.<DiskRange>newArrayList(new BufferChunk(bb, 0)),
-          bb.remaining(), codec, orcReader.getCompressionSize());
+      OrcProto.StripeFooter result = buildStripeFooter(Lists.<DiskRange>newArrayList(
+          new BufferChunk(bb, 0)), bb.remaining(), codec, orcReader.getCompressionSize());
+      isCodecError = false;
+      return result;
     } finally {
-      if (isPool) {
-        OrcCodecPool.returnCodec(kind, codec);
-      } else {
-        codec.close();
+      try {
+        if (isPool && !isCodecError) {
+          OrcCodecPool.returnCodec(kind, codec);
+        } else {
+          codec.close();
+        }
+      } catch (Exception ex) {
+        LOG.error("Ignoring codec cleanup error", ex);
       }
     }
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
index 32bdf6e68e..893a2bbf79 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
@@ -130,6 +130,7 @@ public DiskRangeList createCacheChunk(MemoryBuffer buffer, long offset, long end
   private boolean isDataReaderOpen = false;
   private final CompressionCodec codec;
   private final boolean isCodecFromPool;
+  private boolean isCodecFailure = false;
   private final boolean isCompressed;
   private final org.apache.orc.CompressionKind compressionKind;
   private final int bufferSize;
@@ -677,12 +678,17 @@ public void setTracing(boolean isEnabled) {
 
   @Override
   public void close() throws IOException {
-    if (isCodecFromPool) {
-      OrcCodecPool.returnCodec(compressionKind, codec);
-    } else {
-      codec.close();
+    try {
+      if (isCodecFromPool && !isCodecFailure) {
+        OrcCodecPool.returnCodec(compressionKind, codec);
+      } else {
+        codec.close();
+      }
+    } catch (Exception ex) {
+      LOG.error("Ignoring error from codec", ex);
+    } finally {
+      dataReader.close();
     }
-    dataReader.close();
   }
 
   /**
@@ -870,7 +876,15 @@ public DiskRangeList readEncodedStream(long baseOffset, DiskRangeList start, lon
     for (ProcCacheChunk chunk : toDecompress) {
       ByteBuffer dest = chunk.getBuffer().getByteBufferRaw();
       if (chunk.isOriginalDataCompressed) {
-        decompressChunk(chunk.originalData, codec, dest);
+        boolean isOk = false;
+        try {
+          decompressChunk(chunk.originalData, codec, dest);
+          isOk = true;
+        } finally {
+          if (!isOk) {
+            isCodecFailure = true;
+          }
+        }
       } else {
         copyUncompressedChunk(chunk.originalData, dest);
       }
