diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java
index cc9d872467..db17999f64 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java
@@ -419,6 +419,8 @@ public void closeOp(boolean abort) throws HiveException {
         tableContainer.dumpMetrics();
 
         if (tableContainer instanceof HybridHashTableContainer) {
+          // TODO: most of the below code should be moved inside HybridHashTableContainer.
+          //       Ideally, even the instanceof should not exist; instead, an API on MJTC.
           HybridHashTableContainer hybridHtContainer = (HybridHashTableContainer) tableContainer;
           hybridHtContainer.dumpStats();
 
@@ -429,7 +431,7 @@ public void closeOp(boolean abort) throws HiveException {
               hybridHtContainer.setTotalInMemRowCount(
                   hybridHtContainer.getTotalInMemRowCount() -
                       hashPartitions[i].getHashMapFromMemory().getNumValues());
-              hashPartitions[i].getHashMapFromMemory().clear();
+              hashPartitions[i].getHashMapFromMemory().discardData();
             }
           }
           assert hybridHtContainer.getTotalInMemRowCount() == 0;
@@ -464,6 +466,7 @@ public void closeOp(boolean abort) throws HiveException {
         }
       }
     }
+    mapJoinTables = null;
     cache.release(cacheKey);
     super.closeOp(abort);
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/BytesBytesMultiHashMap.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/BytesBytesMultiHashMap.java
index 05974155e9..591ac84272 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/BytesBytesMultiHashMap.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/BytesBytesMultiHashMap.java
@@ -353,11 +353,11 @@ public void seal() {
     writeBuffers.seal();
   }
 
-  public void clear() {
-    // This will make the object completely unusable. Semantics of clear are not defined...
-    this.writeBuffers.clear();
-    this.refs = new long[1];
-    this.keysAssigned = 0;
+  public void discardData() {
+    // This will make the object completely unusable. We could reset to default state instead...
+    writeBuffers.clear();
+    refs = new long[1];
+    keysAssigned = numValues = 0;
   }
 
   public void expandAndRehashToTarget(int estimateNewRowCount) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/HybridHashTableContainer.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/HybridHashTableContainer.java
index 3ad7655e0b..284b128a71 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/HybridHashTableContainer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/HybridHashTableContainer.java
@@ -386,7 +386,7 @@ private void spillPartition(int partitionId) throws IOException {
     LOG.info("Memory usage after spilling: " + (size - inMemSize));
 
     totalInMemRowCount -= inMemRowCount;
-    partition.hashMap.clear();
+    partition.hashMap.discardData();
   }
 
   /**
@@ -457,14 +457,9 @@ public int getToSpillPartitionId() {
     return toSpillPartitionId;
   }
 
-  /* Clean up in memory hashtables */
   @Override
   public void clear() {
-    for (HashPartition hp : hashPartitions) {
-      if (hp.hashMap != null) {
-        hp.hashMap.clear();
-      }
-    }
+    // Don't clear in-memory hashtables - they might be cached.
   }
 
   @Override
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java
index a4363adb16..40c3361d1d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java
@@ -321,7 +321,7 @@ public MapJoinKey putRow(MapJoinObjectSerDeContext keyContext, Writable currentK
 
   @Override
   public void clear() {
-    hashMap.clear();
+    // Don't clear the hash table - reuse is possible. GC will take care of it.
   }
 
   @Override
