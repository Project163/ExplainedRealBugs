diff --git a/CHANGES.txt b/CHANGES.txt
index 8ba77c2c21..345d7b23a4 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -381,6 +381,9 @@ Trunk -  Unreleased
     HIVE-986 Ant "eclipse-files" target is broken for Hadoop 0.20
     (Zheng Shao via namit)
 
+    HIVE-1017 || and && are not supported currently
+    (Ning Zhang via namit)
+
 Release 0.4.0 -  Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
index 4fb10212be..b05e5581a4 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
@@ -157,9 +157,7 @@ public class FunctionRegistry {
     registerUDF(">=", UDFOPEqualOrGreaterThan.class, true);
 
     registerUDF("and", UDFOPAnd.class, true);
-    registerUDF("&&", UDFOPAnd.class, true, "and");
     registerUDF("or", UDFOPOr.class, true);
-    registerUDF("||", UDFOPOr.class, true, "or");
     registerUDF("not", UDFOPNot.class, true);
     registerUDF("!", UDFOPNot.class, true, "not");
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPAnd.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPAnd.java
index 27b465bc3a..9cc070581d 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPAnd.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPAnd.java
@@ -25,7 +25,7 @@
 import org.apache.hadoop.io.BooleanWritable;
 
 @description(
-    name = "and,&&",
+    name = "and",
     value = "a _FUNC_ b - Logical and",
     extended = "Example:\n" +
         "  > SELECT * FROM srcpart WHERE src.hr=12 _FUNC_ " +
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPOr.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPOr.java
index 47704b2473..2277e53c0f 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPOr.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPOr.java
@@ -25,7 +25,7 @@
 import org.apache.hadoop.io.BooleanWritable;
 
 @description(
-    name = "or,||",
+    name = "or",
     value = "a _FUNC_ b - Logical or"
 )
 public class UDFOPOr extends UDF {
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
index 094375966d..b003464d9b 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
@@ -88,7 +88,7 @@ public void testBaseFilterOperator() throws Throwable {
       exprNodeDesc zero = new exprNodeConstantDesc("0");
       exprNodeDesc func1 = TypeCheckProcFactory.DefaultExprProcessor.getFuncExprNodeDesc(">", col2, col1);
       exprNodeDesc func2 = TypeCheckProcFactory.DefaultExprProcessor.getFuncExprNodeDesc("==", col0, zero);
-      exprNodeDesc func3 = TypeCheckProcFactory.DefaultExprProcessor.getFuncExprNodeDesc("&&", func1, func2); 
+      exprNodeDesc func3 = TypeCheckProcFactory.DefaultExprProcessor.getFuncExprNodeDesc("and", func1, func2);
       assert(func3 != null);
       filterDesc filterCtx = new filterDesc(func3, false);
 
@@ -148,7 +148,7 @@ public void testFileSinkOperator() throws Throwable {
       //fileSinkDesc fsd = new fileSinkDesc ("file:///tmp" + File.separator + System.getProperty("user.name") + File.separator + "TestFileSinkOperator",
       //                                     Utilities.defaultTd, false);
       //Operator<fileSinkDesc> flop = OperatorFactory.getAndMakeChild(fsd, op);
-      
+
       op.initialize(new JobConf(TestOperators.class), new ObjectInspector[]{r[0].oi});
 
       // evaluate on row
@@ -244,7 +244,7 @@ public void testMapOperator() throws Throwable {
       pathToAliases.put("/testDir", aliases);
 
       // initialize pathToTableInfo
-      // Default: treat the table as a single column "col" 
+      // Default: treat the table as a single column "col"
       tableDesc td = Utilities.defaultTd;
       partitionDesc pd = new partitionDesc(td, null);
       LinkedHashMap<String,org.apache.hadoop.hive.ql.plan.partitionDesc> pathToPartitionInfo = new
@@ -276,7 +276,7 @@ public void testMapOperator() throws Throwable {
       InspectableObject io2 = new InspectableObject();
       for(int i=0; i<5; i++) {
         String answer = "[[" + i + ", " + (i+1) + ", " + (i+2) + "]]";
-        
+
         tw.set("" + i + "\u0001" + (i+1) + "\u0001"+ (i+2));
         mo.process((Writable)tw);
         cdop1.retrieve(io1);
diff --git a/ql/src/test/results/clientpositive/show_functions.q.out b/ql/src/test/results/clientpositive/show_functions.q.out
index bc8fa8fb17..fe02505e24 100644
--- a/ql/src/test/results/clientpositive/show_functions.q.out
+++ b/ql/src/test/results/clientpositive/show_functions.q.out
@@ -5,7 +5,6 @@ POSTHOOK: type: SHOWFUNCTIONS
 !
 %
 &
-&&
 *
 +
 -
@@ -124,7 +123,6 @@ weekofyear
 when
 year
 |
-||
 ~
 PREHOOK: query: SHOW FUNCTIONS '^c.*'
 PREHOOK: type: SHOWFUNCTIONS
