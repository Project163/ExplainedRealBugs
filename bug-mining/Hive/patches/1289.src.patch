diff --git a/build-common.xml b/build-common.xml
index 43d8e9cdf6..d642b5132b 100644
--- a/build-common.xml
+++ b/build-common.xml
@@ -59,7 +59,7 @@
   <property name="test.output" value="true"/>
   <property name="test.junit.output.format" value="xml"/>
   <property name="test.junit.output.usefile" value="true"/>
-  <property name="minimr.query.files" value="list_bucket_dml_10.q,input16_cc.q,scriptfile1.q,bucket4.q,bucketmapjoin6.q,disable_merge_for_bucketing.q,reduce_deduplicate.q,smb_mapjoin_8.q,join1.q,groupby2.q,bucketizedhiveinputformat.q,bucketmapjoin7.q,optrstat_groupby.q,bucket_num_reducers.q,bucket5.q,load_fs2.q,bucket_num_reducers2.q,infer_bucket_sort_merge.q,infer_bucket_sort_reducers_power_two.q,infer_bucket_sort_dyn_part.q,infer_bucket_sort_bucketed_table.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_num_buckets.q,schemeAuthority.q,truncate_column_buckets.q,remote_script.q"/>
+  <property name="minimr.query.files" value="list_bucket_dml_10.q,input16_cc.q,scriptfile1.q,bucket4.q,bucketmapjoin6.q,disable_merge_for_bucketing.q,reduce_deduplicate.q,smb_mapjoin_8.q,join1.q,groupby2.q,bucketizedhiveinputformat.q,bucketmapjoin7.q,optrstat_groupby.q,bucket_num_reducers.q,bucket5.q,load_fs2.q,bucket_num_reducers2.q,infer_bucket_sort_merge.q,infer_bucket_sort_reducers_power_two.q,infer_bucket_sort_dyn_part.q,infer_bucket_sort_bucketed_table.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_num_buckets.q,schemeAuthority.q,truncate_column_buckets.q,remote_script.q,load_hdfs_file_with_space_in_the_name.q"/>
   <property name="minimr.query.negative.files" value="cluster_tasklog_retrieval.q,minimr_broken_pipe.q,mapreduce_stack_trace.q,mapreduce_stack_trace_turnoff.q,mapreduce_stack_trace_hadoop20.q,mapreduce_stack_trace_turnoff_hadoop20.q" />
   <property name="test.silent" value="true"/>
   <property name="hadoopVersion" value="${hadoop.version.ant-internal}"/>
diff --git a/data/files/person age.txt b/data/files/person age.txt
new file mode 100644
index 0000000000..c902284c11
--- /dev/null
+++ b/data/files/person age.txt	
@@ -0,0 +1,5 @@
+John	23
+Tom	17
+Jim	31
+Boby	9
+Paul	51
\ No newline at end of file
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
index bd8d25206f..c2981e855b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
@@ -27,6 +27,8 @@
 import java.util.Map;
 
 import org.antlr.runtime.tree.Tree;
+import org.apache.commons.httpclient.URIException;
+import org.apache.commons.httpclient.util.URIUtil;
 import org.apache.commons.lang.StringUtils;
 import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
@@ -82,7 +84,7 @@ private URI initializeFromURI(String fromPath) throws IOException,
     // directory
     if (!path.startsWith("/")) {
       if (isLocal) {
-        path = new Path(System.getProperty("user.dir"), path).toUri().toString();
+        path = URIUtil.decode( new Path(System.getProperty("user.dir"), path).toUri().toString() );
       } else {
         path = new Path(new Path("/user/" + System.getProperty("user.name")),
           path).toString();
@@ -231,8 +233,13 @@ public void analyzeInternal(ASTNode ast) throws SemanticException {
       // that's just a test case.
       String copyURIStr = ctx.getExternalTmpFileURI(toURI);
       URI copyURI = URI.create(copyURIStr);
-      rTask = TaskFactory.get(new CopyWork(fromURI.toString(), copyURIStr),
-          conf);
+      try {
+        rTask = TaskFactory.get(new CopyWork(URIUtil.decode(fromURI.toString()), copyURIStr),
+            conf);
+      } catch (URIException e) {
+        throw new SemanticException(ErrorMsg.INVALID_PATH.getMsg(fromTree, e
+            .getMessage()), e);
+      }
       fromURI = copyURI;
     }
 
@@ -261,8 +268,14 @@ public void analyzeInternal(ASTNode ast) throws SemanticException {
     }
 
 
-    LoadTableDesc loadTableWork = new LoadTableDesc(fromURI.toString(),
-        loadTmpPath, Utilities.getTableDesc(ts.tableHandle), partSpec, isOverWrite);
+    LoadTableDesc loadTableWork;
+    try {
+      loadTableWork = new LoadTableDesc(URIUtil.decode(fromURI.toString()),
+          loadTmpPath, Utilities.getTableDesc(ts.tableHandle), partSpec, isOverWrite);
+    } catch (URIException e1) {
+      throw new SemanticException(ErrorMsg.INVALID_PATH.getMsg(fromTree, e1
+          .getMessage()), e1);
+    }
 
     Task<? extends Serializable> childTask = TaskFactory.get(new MoveWork(getInputs(),
         getOutputs(), loadTableWork, null, true), conf);
diff --git a/ql/src/test/queries/clientpositive/load_file_with_space_in_the_name.q b/ql/src/test/queries/clientpositive/load_file_with_space_in_the_name.q
new file mode 100644
index 0000000000..3b8951a1a7
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/load_file_with_space_in_the_name.q
@@ -0,0 +1,5 @@
+-- test for loading into tables with the file with space in the name
+
+
+CREATE TABLE load_file_with_space_in_the_name(name STRING, age INT);
+LOAD DATA LOCAL INPATH '../data/files/person age.txt' INTO TABLE load_file_with_space_in_the_name;
diff --git a/ql/src/test/queries/clientpositive/load_hdfs_file_with_space_in_the_name.q b/ql/src/test/queries/clientpositive/load_hdfs_file_with_space_in_the_name.q
new file mode 100644
index 0000000000..e7eb8d921d
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/load_hdfs_file_with_space_in_the_name.q
@@ -0,0 +1,9 @@
+dfs -mkdir hdfs:///tmp/test/load_file_with_space_in_the_name;
+
+dfs -copyFromLocal ../data/files hdfs:///tmp/test/load_file_with_space_in_the_name;
+
+CREATE TABLE load_file_with_space_in_the_name(name STRING, age INT);
+LOAD DATA INPATH 'hdfs:///tmp/test/load_file_with_space_in_the_name/files/person age.txt' INTO TABLE load_file_with_space_in_the_name;
+
+dfs -rmr hdfs:///tmp/test;
+
diff --git a/ql/src/test/results/clientpositive/load_file_with_space_in_the_name.q.out b/ql/src/test/results/clientpositive/load_file_with_space_in_the_name.q.out
new file mode 100644
index 0000000000..b159114853
--- /dev/null
+++ b/ql/src/test/results/clientpositive/load_file_with_space_in_the_name.q.out
@@ -0,0 +1,17 @@
+PREHOOK: query: -- test for loading into tables with the file with space in the name
+
+
+CREATE TABLE load_file_with_space_in_the_name(name STRING, age INT)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: -- test for loading into tables with the file with space in the name
+
+
+CREATE TABLE load_file_with_space_in_the_name(name STRING, age INT)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@load_file_with_space_in_the_name
+PREHOOK: query: LOAD DATA LOCAL INPATH '../data/files/person age.txt' INTO TABLE load_file_with_space_in_the_name
+PREHOOK: type: LOAD
+PREHOOK: Output: default@load_file_with_space_in_the_name
+POSTHOOK: query: LOAD DATA LOCAL INPATH '../data/files/person age.txt' INTO TABLE load_file_with_space_in_the_name
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@load_file_with_space_in_the_name
diff --git a/ql/src/test/results/clientpositive/load_hdfs_file_with_space_in_the_name.q.out b/ql/src/test/results/clientpositive/load_hdfs_file_with_space_in_the_name.q.out
new file mode 100644
index 0000000000..1e7fa33ff4
--- /dev/null
+++ b/ql/src/test/results/clientpositive/load_hdfs_file_with_space_in_the_name.q.out
@@ -0,0 +1,12 @@
+PREHOOK: query: CREATE TABLE load_file_with_space_in_the_name(name STRING, age INT)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE load_file_with_space_in_the_name(name STRING, age INT)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@load_file_with_space_in_the_name
+#### A masked pattern was here ####
+PREHOOK: type: LOAD
+PREHOOK: Output: default@load_file_with_space_in_the_name
+#### A masked pattern was here ####
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@load_file_with_space_in_the_name
+#### A masked pattern was here ####
