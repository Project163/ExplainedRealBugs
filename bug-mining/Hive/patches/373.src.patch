diff --git a/CHANGES.txt b/CHANGES.txt
index 7e6ec6a0f7..1064999c87 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -336,6 +336,9 @@ Trunk -  Unreleased
     HIVE-1253. Fix Date_sub and Date_add in case of daylight saving.
     (Bryan Talbot via zshao)
 
+    HIVE-1290. Sort merge join does not work with bucketizedhiveinputformat.
+    (Namit Jain via Ning Zhang)
+
 Release 0.5.0 -  Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/BucketMatcher.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/BucketMatcher.java
index dc9c35525d..01809395c3 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/BucketMatcher.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/BucketMatcher.java
@@ -25,10 +25,13 @@
 import org.apache.hadoop.fs.Path;
 
 public interface BucketMatcher {
-  
+
   public List<Path> getAliasBucketFiles(String currentInputFile, String refTableAlias, String alias);
-  
+
   public void setAliasBucketFileNameMapping(
       LinkedHashMap<String, LinkedHashMap<String, ArrayList<String>>> aliasBucketFileNameMapping);
 
-}
\ No newline at end of file
+  public LinkedHashMap<String, Integer> getBucketFileNameMapping();
+
+  public void setBucketFileNameMapping(LinkedHashMap<String, Integer> bucketFileNameMapping);
+}
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/DefaultBucketMatcher.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/DefaultBucketMatcher.java
index f2de7b2fad..6b57b71ac2 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/DefaultBucketMatcher.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/DefaultBucketMatcher.java
@@ -28,13 +28,16 @@
 import org.apache.hadoop.fs.Path;
 
 public class DefaultBucketMatcher implements BucketMatcher {
-  
+
   protected Log LOG = LogFactory.getLog(this.getClass().getName());
 
-  //MAPPING: bucket_file_name_in_big_tble->{alias_table->corresonding_bucket_file_names}
+  //MAPPING: bucket_file_name_in_big_table->{alias_table->corresonding_bucket_file_names}
   private LinkedHashMap<String, LinkedHashMap<String, ArrayList<String>>> aliasBucketMapping;
-  
+
+  private LinkedHashMap<String, Integer> bucketFileNameMapping;
+
   public DefaultBucketMatcher(){
+    bucketFileNameMapping = new LinkedHashMap<String, Integer>();
   }
 
   public List<Path> getAliasBucketFiles(String refTableInputFile, String refTableAlias, String alias) {
@@ -48,10 +51,18 @@ public List<Path> getAliasBucketFiles(String refTableInputFile, String refTableA
     }
     return paths;
   }
-  
+
   public void setAliasBucketFileNameMapping(
       LinkedHashMap<String, LinkedHashMap<String, ArrayList<String>>> aliasBucketFileNameMapping) {
     this.aliasBucketMapping = aliasBucketFileNameMapping;
   }
-  
+
+  public LinkedHashMap<String, Integer> getBucketFileNameMapping() {
+    return bucketFileNameMapping;
+  }
+
+  public void setBucketFileNameMapping(LinkedHashMap<String, Integer> bucketFileNameMapping) {
+    this.bucketFileNameMapping = bucketFileNameMapping;
+  }
+
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java
index 04bdea1ab0..2c72077360 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java
@@ -69,12 +69,14 @@ public class ExecMapper extends MapReduceBase implements Mapper {
   private long nextCntr = 1;
   private String lastInputFile = null;
   private MapredLocalWork localWork = null;
-  
+
   private ExecMapperContext execContext = new ExecMapperContext();
-  
+
   public static class ExecMapperContext {
     boolean inputFileChanged = false;
     String currentInputFile;
+    Integer fileId = new Integer(-1);
+
     JobConf jc;
     public boolean isInputFileChanged() {
       return inputFileChanged;
@@ -94,6 +96,14 @@ public JobConf getJc() {
     public void setJc(JobConf jc) {
       this.jc = jc;
     }
+
+    public Integer getFileId() {
+      return fileId;
+    }
+    public void setFileId(Integer fileId) {
+      this.fileId = fileId;
+    }
+
   }
 
   @Override
@@ -124,7 +134,7 @@ public void configure(JobConf job) {
       mo.setExecContext(execContext);
       mo.initializeLocalWork(jc);
       mo.initialize(jc, null);
-      
+
       // initialize map local work
       localWork = mrwork.getMapLocalWork();
       if (localWork == null) {
@@ -171,7 +181,7 @@ public void map(Object key, Object value, OutputCollector output,
       mo.setOutputCollector(oc);
       mo.setReporter(rp);
     }
-    
+
     if(inputFileChanged()) {
       if (this.localWork != null
           && (localWork.getInputFileChangeSensitive() || this.lastInputFile == null)) {
@@ -179,7 +189,7 @@ public void map(Object key, Object value, OutputCollector output,
       }
       this.lastInputFile = HiveConf.getVar(jc, HiveConf.ConfVars.HADOOPMAPFILENAME);
     }
-    
+
     try {
       if (mo.getDone()) {
         done = true;
@@ -215,7 +225,7 @@ public void map(Object key, Object value, OutputCollector output,
    * mapper's input file, the work need to clear context and re-initialization
    * after the input file changed. This is first introduced to process bucket
    * map join.
-   * 
+   *
    * @return
    */
   private boolean inputFileChanged() {
@@ -240,12 +250,12 @@ private void processMapLocalWork(boolean inputFileChangeSenstive) {
           int fetchOpRows = 0;
           String alias = entry.getKey();
           FetchOperator fetchOp = entry.getValue();
-          
+
           if(inputFileChangeSenstive) {
             fetchOp.clearFetchContext();
             setUpFetchOpContext(fetchOp, alias);
           }
-          
+
           Operator<? extends Serializable> forwardOp = localWork
               .getAliasToWork().get(alias);
 
@@ -283,7 +293,7 @@ private void processMapLocalWork(boolean inputFileChangeSenstive) {
       }
     }
   }
-  
+
   private void setUpFetchOpContext(FetchOperator fetchOp, String alias)
       throws Exception {
     String currentInputFile = HiveConf.getVar(jc, HiveConf.ConfVars.HADOOPMAPFILENAME);
@@ -291,13 +301,14 @@ private void setUpFetchOpContext(FetchOperator fetchOp, String alias)
     Class<? extends BucketMatcher> bucketMatcherCls = bucketMatcherCxt.getBucketMatcherClass();
     BucketMatcher bucketMatcher = (BucketMatcher) ReflectionUtils.newInstance(bucketMatcherCls, null);
     bucketMatcher.setAliasBucketFileNameMapping(bucketMatcherCxt.getAliasBucketFileNameMapping());
+
     List<Path> aliasFiles = bucketMatcher.getAliasBucketFiles(currentInputFile,
         bucketMatcherCxt.getMapJoinBigTableAlias(),
         alias);
     Iterator<Path> iter = aliasFiles.iterator();
     fetchOp.setupContext(iter, null);
   }
-  
+
 
   private long getNextCntr(long cntr) {
     // A very simple counter to keep track of number of rows processed by the
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
index ecb10e60c7..e19f0a45b0 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
@@ -118,48 +118,18 @@ public static enum TableIdEnum {
   private void commit(int idx) throws IOException {
     if (isNativeTable) {
       if (!fs.rename(outPaths[idx], finalPaths[idx])) {
-        throw new IOException("Unable to rename output to: " 
+        throw new IOException("Unable to rename output to: "
           + finalPaths[idx]);
       }
     }
     LOG.info("Committed " + outPaths[idx] + " to output file: " + finalPaths[idx]);
   }
 
-  @Override
-  protected void initializeOp(Configuration hconf) throws HiveException {
+  private boolean filesCreated = false;
+  private void openFiles(Configuration hconf) throws HiveException {
+    if (filesCreated)
+      return;
     try {
-      serializer = (Serializer) conf.getTableInfo().getDeserializerClass()
-          .newInstance();
-      serializer.initialize(null, conf.getTableInfo().getProperties());
-      isNativeTable = !conf.getTableInfo().isNonNative();
-
-      JobConf jc;
-      if (hconf instanceof JobConf) {
-        jc = (JobConf) hconf;
-      } else {
-        // test code path
-        jc = new JobConf(hconf, ExecDriver.class);
-      }
-
-      multiFileSpray = conf.isMultiFileSpray();
-      totalFiles = conf.getTotalFiles();
-      numFiles   = conf.getNumFiles();
-
-      if (multiFileSpray) {
-        partitionEval = new ExprNodeEvaluator[conf.getPartitionCols().size()];
-        int i = 0;
-        for (ExprNodeDesc e : conf.getPartitionCols()) {
-          partitionEval[i++] = ExprNodeEvaluatorFactory.get(e);
-        }
-
-        partitionObjectInspectors = initEvaluators(partitionEval, outputObjInspector);
-        prtner = (HivePartitioner<HiveKey, Object>)ReflectionUtils.newInstance(jc.getPartitionerClass(), null);
-      }
-
-      outWriters = new RecordWriter[numFiles];
-      outPaths   = new Path[numFiles];
-      finalPaths = new Path[numFiles];
-
       String specPath = conf.getDirName();
       Path tmpPath = Utilities.toTempPath(specPath);
       Set<Integer> seenBuckets = new HashSet<Integer>();
@@ -175,6 +145,17 @@ protected void initializeOp(Configuration hconf) throws HiveException {
       for (int idx = 0; idx < totalFiles; idx++) {
         String taskId = Utilities.getTaskId(hconf);
 
+        if (this.getExecContext() != null && this.getExecContext().getFileId() != -1) {
+          LOG.info("replace taskId from execContext ");
+
+          taskId = Utilities.replaceTaskIdFromFilename(taskId, this.getExecContext().getFileId());
+
+          LOG.info("new taskId: FS " + taskId);
+
+          assert !multiFileSpray;
+          assert totalFiles == 1;
+        }
+
         if (multiFileSpray) {
           key.setHashCode(idx);
 
@@ -227,9 +208,57 @@ protected void initializeOp(Configuration hconf) throws HiveException {
       // in recent hadoop versions, use deleteOnExit to clean tmp files.
       if (isNativeTable) {
         autoDelete = ShimLoader.getHadoopShims().fileSystemDeleteOnExit(fs,
-          outPaths[0]);
+                                                                        outPaths[0]);
+      }
+    } catch (HiveException e) {
+      throw e;
+    } catch (Exception e) {
+      e.printStackTrace();
+      throw new HiveException(e);
+    }
+
+    filesCreated = true;
+  }
+
+  private Configuration hconf;
+  private JobConf jc;
+
+  @Override
+  protected void initializeOp(Configuration hconf) throws HiveException {
+    try {
+      filesCreated = false;
+      this.hconf = hconf;
+      serializer = (Serializer) conf.getTableInfo().getDeserializerClass()
+          .newInstance();
+      serializer.initialize(null, conf.getTableInfo().getProperties());
+      isNativeTable = !conf.getTableInfo().isNonNative();
+
+      if (hconf instanceof JobConf) {
+        jc = (JobConf) hconf;
+      } else {
+        // test code path
+        jc = new JobConf(hconf, ExecDriver.class);
       }
 
+      multiFileSpray = conf.isMultiFileSpray();
+      totalFiles = conf.getTotalFiles();
+      numFiles   = conf.getNumFiles();
+
+      if (multiFileSpray) {
+        partitionEval = new ExprNodeEvaluator[conf.getPartitionCols().size()];
+        int i = 0;
+        for (ExprNodeDesc e : conf.getPartitionCols()) {
+          partitionEval[i++] = ExprNodeEvaluatorFactory.get(e);
+        }
+
+        partitionObjectInspectors = initEvaluators(partitionEval, outputObjInspector);
+        prtner = (HivePartitioner<HiveKey, Object>)ReflectionUtils.newInstance(jc.getPartitionerClass(), null);
+      }
+
+      outWriters = new RecordWriter[numFiles];
+      outPaths   = new Path[numFiles];
+      finalPaths = new Path[numFiles];
+
       int id = conf.getDestTableId();
       if ((id != 0) && (id <= TableIdEnum.values().length)) {
         String enumName = "TABLE_ID_" + String.valueOf(id) + "_ROWCOUNT";
@@ -251,6 +280,9 @@ protected void initializeOp(Configuration hconf) throws HiveException {
 
   @Override
   public void processOp(Object row, int tag) throws HiveException {
+    if (!filesCreated)
+      openFiles(hconf);
+
     // Since File Sink is a terminal operator, forward is not called - so,
     // maintain the number of output rows explicitly
     if (counterNameToEnum != null) {
@@ -295,6 +327,8 @@ public void processOp(Object row, int tag) throws HiveException {
 
   @Override
   public void closeOp(boolean abort) throws HiveException {
+    if (!filesCreated)
+      openFiles(hconf);
 
     if (!abort) {
       for (int idx = 0; idx < numFiles; idx++) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
index cd71c99693..2793bd3a4a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
@@ -61,7 +61,7 @@ public class SMBMapJoinOperator extends AbstractMapJoinOperator<SMBJoinDesc> imp
   transient Map<Byte, ArrayList<Object>> nextKeyWritables;
   HashMap<Byte, RowContainer<ArrayList<Object>>> nextGroupStorage;
   HashMap<Byte, RowContainer<ArrayList<Object>>> candidateStorage;
-  
+
   transient HashMap<Byte, String> tagToAlias;
   private transient HashMap<Byte, Boolean> fetchOpDone = new HashMap<Byte, Boolean>();
   private transient HashMap<Byte, Boolean> foundNextKeyGroup = new HashMap<Byte, Boolean>();
@@ -70,19 +70,19 @@ public class SMBMapJoinOperator extends AbstractMapJoinOperator<SMBJoinDesc> imp
 
   public SMBMapJoinOperator() {
   }
-  
+
   public SMBMapJoinOperator(AbstractMapJoinOperator<? extends MapJoinDesc> mapJoinOp) {
     super(mapJoinOp);
   }
-  
+
   @Override
   protected void initializeOp(Configuration hconf) throws HiveException {
     super.initializeOp(hconf);
-    
+
     firstRow = true;
-    
+
     closeCalled = false;
-    
+
     this.firstFetchHappened = false;
 
     nextGroupStorage = new HashMap<Byte, RowContainer<ArrayList<Object>>>();
@@ -101,7 +101,7 @@ protected void initializeOp(Configuration hconf) throws HiveException {
     tagToAlias = conf.getTagToAlias();
     keyWritables = new HashMap<Byte, ArrayList<Object>>();
     nextKeyWritables = new HashMap<Byte, ArrayList<Object>>();
-    
+
     for (Byte alias : order) {
       if(alias != (byte) posBigTable) {
         fetchOpDone.put(alias, Boolean.FALSE);;
@@ -109,7 +109,7 @@ protected void initializeOp(Configuration hconf) throws HiveException {
       foundNextKeyGroup.put(alias, Boolean.FALSE);
     }
   }
-  
+
   @Override
   public void initializeLocalWork(Configuration hconf) throws HiveException {
     initializeMapredLocalWork(this.getConf(), hconf, this.getConf().getLocalWork(), LOG);
@@ -133,7 +133,7 @@ public void initializeMapredLocalWork(MapJoinDesc conf, Configuration hconf,
         l4j.info("fetchoperator for " + entry.getKey() + " created");
       }
     }
-    
+
     for (Map.Entry<String, FetchOperator> entry : fetchOperators.entrySet()) {
       Operator<? extends Serializable> forwardOp = localWork.getAliasToWork()
           .get(entry.getKey());
@@ -144,14 +144,14 @@ public void initializeMapredLocalWork(MapJoinDesc conf, Configuration hconf,
       l4j.info("fetchoperator for " + entry.getKey() + " initialized");
     }
   }
-  
+
   @Override
   public void processOp(Object row, int tag) throws HiveException {
 
     if (this.getExecContext().inputFileChanged) {
       if(firstFetchHappened) {
-        //we need to first join and flush out data left by the previous file. 
-        joinFinalLeftData();        
+        //we need to first join and flush out data left by the previous file.
+        joinFinalLeftData();
       }
       //set up the fetch operator for the new input file.
       for (Map.Entry<String, FetchOperator> entry : fetchOperators.entrySet()) {
@@ -163,13 +163,13 @@ public void processOp(Object row, int tag) throws HiveException {
       this.getExecContext().inputFileChanged = false;
       firstFetchHappened = false;
     }
-    
+
     if (!firstFetchHappened) {
       firstFetchHappened = true;
       // fetch the first group for all small table aliases
       for (Byte t : order) {
         if(t != (byte)posBigTable) {
-          fetchNextGroup(t);            
+          fetchNextGroup(t);
         }
       }
     }
@@ -191,7 +191,7 @@ public void processOp(Object row, int tag) throws HiveException {
         return;
       }
     }
-    
+
     reportProgress();
 
     // the big table has reached a new key group. try to let the small tables
@@ -204,10 +204,10 @@ public void processOp(Object row, int tag) throws HiveException {
         //jump out the loop if we need input from the big table
       } while (smallestPos != null && smallestPos.size() > 0
           && !smallestPos.contains((byte)this.posBigTable));
-      
+
       return;
     }
-    
+
     assert !nextKeyGroup;
     candidateStorage.get((byte) tag).add(value);
   }
@@ -219,7 +219,7 @@ public void processOp(Object row, int tag) throws HiveException {
    */
   private void joinFinalLeftData() throws HiveException {
     RowContainer bigTblRowContainer = this.candidateStorage.get((byte)this.posBigTable);
-    
+
     boolean allFetchOpDone = allFetchOpDone();
     // if all left data in small tables are less than and equal to the left data
     // in big table, let's them catch up
@@ -229,11 +229,11 @@ private void joinFinalLeftData() throws HiveException {
       bigTblRowContainer = this.candidateStorage.get((byte)this.posBigTable);
       allFetchOpDone = allFetchOpDone();
     }
-    
+
     if (allFetchOpDone
         && this.candidateStorage.get((byte) this.posBigTable).size() > 0) {
       // if all fetch operator for small tables are done and there are data left
-      // in big table 
+      // in big table
       for (byte t : order) {
         if(this.foundNextKeyGroup.get(t) && this.nextKeyWritables.get(t) != null) {
           promoteNextGroupToCandidate(t);
@@ -246,9 +246,9 @@ private void joinFinalLeftData() throws HiveException {
         if (ret == null || ret.size() == 0) {
           break;
         }
-        
+
         reportProgress();
-        
+
         allFetchOpDone = allFetchOpDone();
       }
       //one final table left
@@ -322,7 +322,7 @@ private List<Byte> joinObject(int smallestPos) throws HiveException {
     }
     return needFetchList;
   }
-  
+
   private void fetchNextGroup(Byte t) throws HiveException {
     if (foundNextKeyGroup.get(t)) {
       // first promote the next group to be the current group if we reached a
@@ -340,7 +340,7 @@ private void fetchNextGroup(Byte t) throws HiveException {
     if(t == (byte)posBigTable) {
       return;
     }
-    
+
     //for tables other than the big table, we need to fetch more data until reach a new group or done.
     while (!foundNextKeyGroup.get(t)) {
       if (fetchOpDone.get(t)) {
@@ -361,7 +361,7 @@ private void promoteNextGroupToCandidate(Byte t) throws HiveException {
     this.candidateStorage.put(t, this.nextGroupStorage.get(t));
     this.nextGroupStorage.put(t, oldRowContainer);
   }
-  
+
   private int compareKeys (ArrayList<Object> k1, ArrayList<Object> k2) {
     int ret = 0;
     for (int i = 0; i < k1.size() && i < k1.size(); i++) {
@@ -433,6 +433,9 @@ private void setUpFetchOpContext(FetchOperator fetchOp, String alias) {
         .getBucketMatcherClass();
     BucketMatcher bucketMatcher = (BucketMatcher) ReflectionUtils.newInstance(
         bucketMatcherCls, null);
+    this.getExecContext().setFileId(bucketMatcherCxt.getBucketFileNameMapping().get(currentInputFile));
+    LOG.info("set task id: " + this.getExecContext().getFileId());
+
     bucketMatcher.setAliasBucketFileNameMapping(bucketMatcherCxt
         .getAliasBucketFileNameMapping());
     List<Path> aliasFiles = bucketMatcher.getAliasBucketFiles(currentInputFile,
@@ -445,7 +448,7 @@ private void fetchOneRow(byte tag) {
     if (fetchOperators != null) {
       String tble = this.tagToAlias.get(tag);
       FetchOperator fetchOp = fetchOperators.get(tble);
-      
+
       Operator<? extends Serializable> forwardOp = localWork.getAliasToWork()
           .get(tble);
       try {
@@ -470,7 +473,7 @@ private void fetchOneRow(byte tag) {
       }
     }
   }
-  
+
   transient boolean closeCalled = false;
   @Override
   public void closeOp(boolean abort) throws HiveException {
@@ -478,7 +481,7 @@ public void closeOp(boolean abort) throws HiveException {
       return;
     }
     closeCalled = true;
-    
+
     if ((this.getExecContext() != null && this.getExecContext().inputFileChanged)
         || !firstFetchHappened) {
       //set up the fetch operator for the new input file.
@@ -492,23 +495,23 @@ public void closeOp(boolean abort) throws HiveException {
       firstFetchHappened = true;
       for (Byte t : order) {
         if(t != (byte)posBigTable) {
-          fetchNextGroup(t);            
+          fetchNextGroup(t);
         }
       }
     }
-    
+
     joinFinalLeftData();
-    
-    //clean up 
+
+    //clean up
     for (Byte alias : order) {
       if(alias != (byte) posBigTable) {
         fetchOpDone.put(alias, Boolean.FALSE);;
       }
       foundNextKeyGroup.put(alias, Boolean.FALSE);
     }
-    
+
     localWorkInited = false;
-    
+
     super.closeOp(abort);
     if (fetchOperators != null) {
       for (Map.Entry<String, FetchOperator> entry : fetchOperators.entrySet()) {
@@ -518,14 +521,14 @@ public void closeOp(boolean abort) throws HiveException {
       }
     }
   }
-  
+
   protected boolean allInitializedParentsAreClosed() {
     return true;
   }
 
   /**
    * Implements the getName function for the Node Interface.
-   * 
+   *
    * @return the name of the operator
    */
   @Override
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
index 8227caa33c..ff5007a06d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
@@ -225,7 +225,7 @@ protected void initialize(Class<?> type, Object oldInstance, Object newInstance,
       }
     }
   }
-  
+
   public static class SetDelegate extends DefaultPersistenceDelegate {
     @Override
     protected Expression instantiate(Object oldInstance, Encoder out) {
@@ -248,9 +248,9 @@ protected void initialize(Class<?> type, Object oldInstance, Object newInstance,
         out.writeStatement(new Statement(oldInstance, "add", new Object[]{i.next()}));
       }
     }
-    
+
   }
-  
+
   public static class ListDelegate extends DefaultPersistenceDelegate {
     @Override
     protected Expression instantiate(Object oldInstance, Encoder out) {
@@ -273,9 +273,9 @@ protected void initialize(Class<?> type, Object oldInstance, Object newInstance,
         out.writeStatement(new Statement(oldInstance, "add", new Object[]{i.next()}));
       }
     }
-    
+
   }
-  
+
   public static void setMapRedWork(Configuration job, MapredWork w) {
     try {
       // use the default file system of the job
@@ -355,7 +355,7 @@ protected void initialize(Class type, Object oldInstance, Object newInstance,
         }
     }
   }
-  
+
   /**
    * Serialize the whole query plan.
    */
@@ -372,10 +372,10 @@ public void exceptionThrown(Exception e) {
     e.setPersistenceDelegate(GroupByDesc.Mode.class, new EnumDelegate());
     e.setPersistenceDelegate(Operator.ProgressCounter.class,
         new EnumDelegate());
-    
+
     e.setPersistenceDelegate(org.datanucleus.sco.backed.Map.class, new MapDelegate());
     e.setPersistenceDelegate(org.datanucleus.sco.backed.List.class, new ListDelegate());
-    
+
     e.writeObject(plan);
     e.close();
   }
@@ -390,9 +390,9 @@ public static QueryPlan deserializeQueryPlan(InputStream in,
     d.close();
     return (ret);
   }
-  
+
   /**
-   * Serialize the mapredWork object to an output stream. DO NOT use this to 
+   * Serialize the mapredWork object to an output stream. DO NOT use this to
    * write to standard output since it closes the output stream.
    * DO USE mapredWork.toXML() instead.
    */
@@ -681,7 +681,7 @@ public static StreamStatus readColumn(DataInput in, OutputStream out)
   /**
    * Convert an output stream to a compressed output stream based on codecs and
    * compression options specified in the Job Configuration.
-   * 
+   *
    * @param jc
    *          Job Configuration
    * @param out
@@ -698,7 +698,7 @@ public static OutputStream createCompressedStream(JobConf jc, OutputStream out)
    * Convert an output stream to a compressed output stream based on codecs
    * codecs in the Job Configuration. Caller specifies directly whether file is
    * compressed or not
-   * 
+   *
    * @param jc
    *          Job Configuration
    * @param out
@@ -723,7 +723,7 @@ public static OutputStream createCompressedStream(JobConf jc,
   /**
    * Based on compression option and configured output codec - get extension for
    * output file. This is only required for text files - not sequencefiles
-   * 
+   *
    * @param jc
    *          Job Configuration
    * @param isCompressed
@@ -744,7 +744,7 @@ public static String getFileExtension(JobConf jc, boolean isCompressed) {
 
   /**
    * Create a sequencefile output stream based on job configuration.
-   * 
+   *
    * @param jc
    *          Job configuration
    * @param fs
@@ -768,7 +768,7 @@ public static SequenceFile.Writer createSequenceWriter(JobConf jc,
    * Create a sequencefile output stream based on job configuration Uses user
    * supplied compression flag (rather than obtaining it from the Job
    * Configuration).
-   * 
+   *
    * @param jc
    *          Job configuration
    * @param fs
@@ -801,7 +801,7 @@ public static SequenceFile.Writer createSequenceWriter(JobConf jc,
   /**
    * Create a RCFile output stream based on job configuration Uses user supplied
    * compression flag (rather than obtaining it from the Job Configuration).
-   * 
+   *
    * @param jc
    *          Job configuration
    * @param fs
@@ -903,7 +903,7 @@ public static boolean isTempPath(FileStatus file) {
    * Rename src to dst, or in the case dst already exists, move files in src to
    * dst. If there is an existing file with the same name, the new file's name
    * will be appended with "_1", "_2", etc.
-   * 
+   *
    * @param fs
    *          the FileSystem where src and dst are on.
    * @param src
@@ -923,7 +923,7 @@ public static void rename(FileSystem fs, Path src, Path dst)
    * Rename src to dst, or in the case dst already exists, move files in src to
    * dst. If there is an existing file with the same name, the new file's name
    * will be appended with "_1", "_2", etc.
-   * 
+   *
    * @param fs
    *          the FileSystem where src and dst are on.
    * @param src
@@ -997,10 +997,25 @@ public static String replaceTaskIdFromFilename(String filename, int bucketNum) {
     for (int i = 0; i < taskIdLen - bucketNumLen; i++) {
         s.append("0");
     }
-    String newTaskId = s.toString() + strBucketNum; 
-    return filename.replaceAll(taskId, newTaskId);
+    String newTaskId = s.toString() + strBucketNum;
+    String[] spl = filename.split(taskId);
+
+    if ((spl.length == 0) || (spl.length == 1)) {
+      return filename.replaceAll(taskId, newTaskId);
+    }
+
+    StringBuffer snew = new StringBuffer();
+    for (int idx = 0; idx < spl.length-1; idx++) {
+      if (idx > 0) {
+        snew.append(taskId);
+      }
+      snew.append(spl[idx]);
+    }
+    snew.append(newTaskId);
+    snew.append(spl[spl.length-1]);
+    return snew.toString();
   }
-  
+
   /**
    * Remove all temporary files and duplicate (double-committed) files from a
    * given directory.
@@ -1046,7 +1061,7 @@ public static String getNameMessage(Exception e) {
 
   /**
    * Add new elements to the classpath.
-   * 
+   *
    * @param newPaths
    *          Array of classpath elements
    */
@@ -1079,7 +1094,7 @@ public static ClassLoader addToClassPath(ClassLoader cloader,
 
   /**
    * remove elements from the classpath.
-   * 
+   *
    * @param pathsToRemove
    *          Array of classpath elements
    */
@@ -1180,7 +1195,7 @@ public static void validateColumnNames(List<String> colNames,
   /**
    * Gets the default notification interval to send progress updates to the
    * tracker. Useful for operators that may not output data for a while.
-   * 
+   *
    * @param hconf
    * @return the interval in milliseconds
    */
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/BucketMapJoinOptimizer.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/BucketMapJoinOptimizer.java
index ae57cf2935..d737454813 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/BucketMapJoinOptimizer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/BucketMapJoinOptimizer.java
@@ -67,7 +67,7 @@
  *this transformation does bucket map join optimization.
  */
 public class BucketMapJoinOptimizer implements Transform {
-  
+
   private static final Log LOG = LogFactory.getLog(GroupByOptimizer.class
       .getName());
 
@@ -130,11 +130,11 @@ public Object process(Node nd, Stack<Node> stack,
       }
     };
   }
-  
+
   class BucketMapjoinOptProc implements NodeProcessor {
-    
+
     protected ParseContext pGraphContext;
-    
+
     public BucketMapjoinOptProc(ParseContext pGraphContext) {
       super();
       this.pGraphContext = pGraphContext;
@@ -148,11 +148,11 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
 
       if(context.getListOfRejectedMapjoins().contains(mapJoinOp))
         return null;
-      
+
       QBJoinTree joinCxt = this.pGraphContext.getMapJoinContext().get(mapJoinOp);
       if(joinCxt == null)
         return null;
-      
+
       List<String> joinAliases = new ArrayList<String>();
       String[] srcs = joinCxt.getBaseSrc();
       String[] left = joinCxt.getLeftAliases();
@@ -174,7 +174,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
           }
         }
       }
-      
+
       MapJoinDesc mjDecs = mapJoinOp.getConf();
       LinkedHashMap<String, Integer> aliasToBucketNumberMapping = new LinkedHashMap<String, Integer>();
       LinkedHashMap<String, List<String>> aliasToBucketFileNamesMapping = new LinkedHashMap<String, List<String>>();
@@ -183,12 +183,12 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
       // with only one partition presents in each join source tables.
       Map<String, Operator<? extends Serializable>> topOps = this.pGraphContext.getTopOps();
       Map<TableScanOperator, Table> topToTable = this.pGraphContext.getTopToTable();
-      
+
       // (partition to bucket file names) and (partition to bucket number) for
       // the big table;
       LinkedHashMap<Partition, List<String>> bigTblPartsToBucketFileNames = new LinkedHashMap<Partition, List<String>>();
       LinkedHashMap<Partition, Integer> bigTblPartsToBucketNumber = new LinkedHashMap<Partition, Integer>();
-      
+
       for (int index = 0; index < joinAliases.size(); index++) {
         String alias = joinAliases.get(index);
         TableScanOperator tso = (TableScanOperator) topOps.get(alias);
@@ -208,9 +208,9 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
           }
           int partNumber = prunedParts.getConfirmedPartns().size()
               + prunedParts.getUnknownPartns().size();
-          
+
           if (partNumber > 1) {
-            // only allow one partition for small tables 
+            // only allow one partition for small tables
             if(alias != baseBigAlias) {
               return null;
             }
@@ -243,7 +243,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
             // not contain mappings for the big table. Instead, the mappings are
             // contained in bigTblPartsToBucketFileNames and
             // bigTblPartsToBucketNumber
-            
+
           } else {
             Partition part = null;
             Iterator<Partition> iter = prunedParts.getConfirmedPartns()
@@ -286,7 +286,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
           aliasToBucketFileNamesMapping.put(alias, fileNames);
         }
       }
-      
+
       // All tables or partitions are bucketed, and their bucket number is
       // stored in 'bucketNumbers', we need to check if the number of buckets in
       // the big table can be divided by no of buckets in small tables.
@@ -307,24 +307,24 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
           return null;
         }
       }
-      
+
       MapJoinDesc desc = mapJoinOp.getConf();
-      
-      LinkedHashMap<String, LinkedHashMap<String, ArrayList<String>>> aliasBucketFileNameMapping = 
+
+      LinkedHashMap<String, LinkedHashMap<String, ArrayList<String>>> aliasBucketFileNameMapping =
         new LinkedHashMap<String, LinkedHashMap<String, ArrayList<String>>>();
-      
-      //sort bucket names for the big table 
+
+      //sort bucket names for the big table
       if(bigTblPartsToBucketNumber.size() > 0) {
         Collection<List<String>> bucketNamesAllParts = bigTblPartsToBucketFileNames.values();
         for(List<String> partBucketNames : bucketNamesAllParts) {
           Collections.sort(partBucketNames);
         }
       } else {
-        Collections.sort(aliasToBucketFileNamesMapping.get(baseBigAlias));        
+        Collections.sort(aliasToBucketFileNamesMapping.get(baseBigAlias));
       }
-      
+
       // go through all small tables and get the mapping from bucket file name
-      // in the big table to bucket file names in small tables. 
+      // in the big table to bucket file names in small tables.
       for (int j = 0; j < joinAliases.size(); j++) {
         String alias = joinAliases.get(j);
         if(alias.equals(baseBigAlias))
@@ -332,7 +332,7 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
         Collections.sort(aliasToBucketFileNamesMapping.get(alias));
         LinkedHashMap<String, ArrayList<String>> mapping = new LinkedHashMap<String, ArrayList<String>>();
         aliasBucketFileNameMapping.put(alias, mapping);
-        
+
         // for each bucket file in big table, get the corresponding bucket file
         // name in the small table.
         if (bigTblPartsToBucketNumber.size() > 0) {
@@ -347,14 +347,14 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,
             List<String> bigTblBucketNameList = bigTblPartToBucketNames.next().getValue();
             fillMapping(baseBigAlias, aliasToBucketNumberMapping,
                 aliasToBucketFileNamesMapping, alias, mapping, bigTblBucketNum,
-                bigTblBucketNameList);
+                bigTblBucketNameList, desc.getBucketFileNameMapping());
           }
         } else {
           List<String> bigTblBucketNameList = aliasToBucketFileNamesMapping.get(baseBigAlias);
           int bigTblBucketNum =  aliasToBucketNumberMapping.get(baseBigAlias);
           fillMapping(baseBigAlias, aliasToBucketNumberMapping,
               aliasToBucketFileNamesMapping, alias, mapping, bigTblBucketNum,
-              bigTblBucketNameList);
+              bigTblBucketNameList, desc.getBucketFileNameMapping());
         }
       }
       desc.setAliasBucketFileNameMapping(aliasBucketFileNameMapping);
@@ -366,7 +366,8 @@ private void fillMapping(String baseBigAlias,
         LinkedHashMap<String, Integer> aliasToBucketNumberMapping,
         LinkedHashMap<String, List<String>> aliasToBucketFileNamesMapping,
         String alias, LinkedHashMap<String, ArrayList<String>> mapping,
-        int bigTblBucketNum, List<String> bigTblBucketNameList) {
+        int bigTblBucketNum, List<String> bigTblBucketNameList,
+        LinkedHashMap<String, Integer> bucketFileNameMapping) {
       for (int index = 0; index < bigTblBucketNameList.size(); index++) {
         String inputBigTBLBucket = bigTblBucketNameList.get(index);
         int smallTblBucketNum = aliasToBucketNumberMapping.get(alias);
@@ -389,6 +390,7 @@ private void fillMapping(String baseBigAlias,
           }
         }
         mapping.put(inputBigTBLBucket, resultFileNames);
+        bucketFileNameMapping.put(inputBigTBLBucket, index);
       }
     }
 
@@ -423,12 +425,12 @@ private List<String> getOnePartitionBucketFileNames(Partition part)
       }
       return fileNames;
     }
-    
+
     private boolean checkBucketColumns(List<String> bucketColumns, MapJoinDesc mjDesc, int index) {
       List<ExprNodeDesc> keys = mjDesc.getKeys().get((byte)index);
       if (keys == null || bucketColumns == null || bucketColumns.size() == 0)
         return false;
-      
+
       //get all join columns from join keys stored in MapJoinDesc
       List<String> joinCols = new ArrayList<String>();
       List<ExprNodeDesc> joinKeys = new ArrayList<ExprNodeDesc>();
@@ -450,30 +452,30 @@ private boolean checkBucketColumns(List<String> bucketColumns, MapJoinDesc mjDes
       }
 
       // to see if the join columns from a table is exactly this same as its
-      // bucket columns 
+      // bucket columns
       if (joinCols.size() == 0 || joinCols.size() != bucketColumns.size()) {
         return false;
       }
-      
+
       for (String col : joinCols) {
         if (!bucketColumns.contains(col))
           return false;
       }
-      
+
       return true;
     }
-    
+
   }
-  
+
   class BucketMapjoinOptProcCtx implements NodeProcessorCtx {
     // we only convert map joins that follows a root table scan in the same
     // mapper. That means there is no reducer between the root table scan and
     // mapjoin.
     Set<MapJoinOperator> listOfRejectedMapjoins = new HashSet<MapJoinOperator>();
-    
+
     public Set<MapJoinOperator> getListOfRejectedMapjoins() {
       return listOfRejectedMapjoins;
     }
-    
+
   }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
index b8c5707e40..d72e448ba5 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
@@ -272,6 +272,7 @@ private static void setupBucketMapJoinInfo(MapredWork plan,
         BucketMapJoinContext bucketMJCxt = new BucketMapJoinContext();
         localPlan.setBucketMapjoinContext(bucketMJCxt);
         bucketMJCxt.setAliasBucketFileNameMapping(aliasBucketFileNameMapping);
+        bucketMJCxt.setBucketFileNameMapping(currMapJoinOp.getConf().getBucketFileNameMapping());
         localPlan.setInputFileChangeSensitive(true);
         bucketMJCxt.setMapJoinBigTableAlias(currMapJoinOp.getConf().getBigTableAlias());
         bucketMJCxt.setBucketMatcherClass(org.apache.hadoop.hive.ql.exec.DefaultBucketMatcher.class);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/MapJoinDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/MapJoinDesc.java
index 486baba8ea..4b9af8e132 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/MapJoinDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/MapJoinDesc.java
@@ -30,7 +30,7 @@
 
 /**
  * Map Join operator Descriptor implementation.
- * 
+ *
  */
 @Explain(displayName = "Common Join Operator")
 public class MapJoinDesc extends JoinDesc implements Serializable {
@@ -43,14 +43,16 @@ public class MapJoinDesc extends JoinDesc implements Serializable {
   private int posBigTable;
 
   private Map<Byte, List<Integer>> retainList;
-  
+
   private transient String bigTableAlias;
-  
+
   private LinkedHashMap<String, LinkedHashMap<String, ArrayList<String>>> aliasBucketFileNameMapping;
+  private LinkedHashMap<String, Integer> bucketFileNameMapping;
 
   public MapJoinDesc() {
+    bucketFileNameMapping = new LinkedHashMap<String, Integer>();
   }
-  
+
   public MapJoinDesc(MapJoinDesc clone) {
     super(clone);
     this.keys = clone.keys;
@@ -60,6 +62,7 @@ public MapJoinDesc(MapJoinDesc clone) {
     this.retainList = clone.retainList;
     this.bigTableAlias = clone.bigTableAlias;
     this.aliasBucketFileNameMapping = clone.aliasBucketFileNameMapping;
+    this.bucketFileNameMapping = clone.bucketFileNameMapping;
   }
 
   public MapJoinDesc(final Map<Byte, List<ExprNodeDesc>> keys,
@@ -71,6 +74,7 @@ public MapJoinDesc(final Map<Byte, List<ExprNodeDesc>> keys,
     this.keyTblDesc = keyTblDesc;
     this.valueTblDescs = valueTblDescs;
     this.posBigTable = posBigTable;
+    this.bucketFileNameMapping = new LinkedHashMap<String, Integer>();
     initRetainExprList();
   }
 
@@ -180,4 +184,12 @@ public void setAliasBucketFileNameMapping(
       LinkedHashMap<String, LinkedHashMap<String, ArrayList<String>>> aliasBucketFileNameMapping) {
     this.aliasBucketFileNameMapping = aliasBucketFileNameMapping;
   }
+
+  public LinkedHashMap<String, Integer> getBucketFileNameMapping() {
+    return bucketFileNameMapping;
+  }
+
+  public void setBucketFileNameMapping(LinkedHashMap<String, Integer> bucketFileNameMapping) {
+    this.bucketFileNameMapping = bucketFileNameMapping;
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/MapredLocalWork.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/MapredLocalWork.java
index 8b45949ed5..867d4b069d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/MapredLocalWork.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/MapredLocalWork.java
@@ -119,6 +119,7 @@ public static class BucketMapJoinContext implements Serializable {
     private Class<? extends BucketMatcher> bucketMatcherClass;
 
     private LinkedHashMap<String, LinkedHashMap<String, ArrayList<String>>> aliasBucketBaseFileNameMapping;
+    private LinkedHashMap<String, Integer> bucketFileNameMapping;
 
     public void setMapJoinBigTableAlias(String bigTableAlias) {
       this.mapJoinBigTableAlias = bigTableAlias;
@@ -214,5 +215,15 @@ public void setAliasBucketBaseFileNameMapping(
         LinkedHashMap<String, LinkedHashMap<String, ArrayList<String>>> aliasBucketBaseFileNameMapping) {
       this.aliasBucketBaseFileNameMapping = aliasBucketBaseFileNameMapping;
     }
+
+    @Explain(displayName = "Alias Bucket Output File Name Mapping", normalExplain = false)
+    public LinkedHashMap<String, Integer> getBucketFileNameMapping() {
+      return bucketFileNameMapping;
+    }
+
+    public void setBucketFileNameMapping(LinkedHashMap<String, Integer> bucketFileNameMapping) {
+      this.bucketFileNameMapping = bucketFileNameMapping;
+    }
+
   }
 }
diff --git a/ql/src/test/queries/clientpositive/bucketmapjoin6.q b/ql/src/test/queries/clientpositive/bucketmapjoin6.q
new file mode 100644
index 0000000000..829b06ade3
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/bucketmapjoin6.q
@@ -0,0 +1,32 @@
+drop table tmp1;
+create table tmp1 (a string, b string) clustered by (a) sorted by (a) into 10 buckets;
+
+drop table tmp2;
+create table tmp2 (a string, b string) clustered by (a) sorted by (a) into 10 buckets;
+
+
+set hive.enforce.bucketing = true;
+set hive.enforce.sorting = true;
+
+
+insert overwrite table tmp1 select * from src where key < 50;
+insert overwrite table tmp2 select * from src where key < 50;
+
+set hive.optimize.bucketmapjoin = true;
+set hive.optimize.bucketmapjoin.sortedmerge = true;
+set hive.merge.mapfiles=false;
+set hive.input.format=org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;
+
+drop table tmp3;
+create table tmp3 (a string, b string, c string) clustered by (a) sorted by (a) into 10 buckets;
+
+
+insert overwrite table tmp3
+  select /*+ MAPJOIN(l) */ i.a, i.b, l.b
+  from tmp1 i join tmp2 l ON i.a = l.a;
+
+select * from tmp3;
+
+drop table tmp1;
+drop table tmp2;
+drop table tmp3;
diff --git a/ql/src/test/queries/clientpositive/smb_mapjoin_7.q b/ql/src/test/queries/clientpositive/smb_mapjoin_7.q
index 248849ce47..405e261dbd 100644
--- a/ql/src/test/queries/clientpositive/smb_mapjoin_7.q
+++ b/ql/src/test/queries/clientpositive/smb_mapjoin_7.q
@@ -30,7 +30,7 @@ select /*+mapjoin(b)*/ * from smb_bucket4_1 a full outer join smb_bucket4_2 b on
 insert overwrite table smb_join_results_empty_bigtable
 select /*+mapjoin(b)*/ * from smb_bucket4_1 a full outer join smb_bucket4_2 b on a.key = b.key;
 
-select * from smb_join_results_empty_bigtable order by k1;
+select * from smb_join_results_empty_bigtable order by k1, v1, k2, v2;
 
 explain
 insert overwrite table smb_join_results
@@ -39,7 +39,7 @@ select /*+mapjoin(a)*/ * from smb_bucket4_1 a full outer join smb_bucket4_2 b on
 insert overwrite table smb_join_results
 select /*+mapjoin(a)*/ * from smb_bucket4_1 a full outer join smb_bucket4_2 b on a.key = b.key;
 
-select * from smb_join_results order by k1;
+select * from smb_join_results order by k1, v1, k2, v2;
 
 insert overwrite table normal_join_results select * from smb_bucket4_1 a full outer join smb_bucket4_2 b on a.key = b.key;
 
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin1.q.out b/ql/src/test/results/clientpositive/bucketmapjoin1.q.out
index 0b281e564b..ed3707c774 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin1.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin1.q.out
@@ -161,7 +161,7 @@ STAGE PLANS:
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-24_320_7804903070266586536/10002
+                      directory: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-37-51_124_5304744619994590803/10002
                       NumFilesPerFileSink: 1
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
@@ -172,12 +172,12 @@ STAGE PLANS:
                             columns.types string:string:string
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                            location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                             name bucketmapjoin_tmp_result
                             serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1268348784
+                            transient_lastDdlTime 1270492671
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: bucketmapjoin_tmp_result
                       TotalFiles: 1
@@ -237,7 +237,7 @@ STAGE PLANS:
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-24_320_7804903070266586536/10002
+                            directory: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-37-51_124_5304744619994590803/10002
                             NumFilesPerFileSink: 1
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -248,12 +248,12 @@ STAGE PLANS:
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1268348784
+                                  transient_lastDdlTime 1270492671
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
@@ -262,12 +262,15 @@ STAGE PLANS:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket20.txt=[srcbucket20.txt, srcbucket22.txt], srcbucket21.txt=[srcbucket21.txt, srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                b {file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
+                b {file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
+              Alias Bucket Output File Name Mapping:
+                file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -279,12 +282,12 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348782
+              transient_lastDdlTime 1270492668
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -296,12 +299,12 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348782
+                transient_lastDdlTime 1270492668
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
@@ -313,14 +316,14 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-24_320_7804903070266586536/10002
-          destination: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-24_320_7804903070266586536/10000
+          source: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-37-51_124_5304744619994590803/10002
+          destination: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-37-51_124_5304744619994590803/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-24_320_7804903070266586536/10000
+          source: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-37-51_124_5304744619994590803/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -330,20 +333,20 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348784
+                transient_lastDdlTime 1270492671
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-24_320_7804903070266586536/10001
+          tmp directory: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-37-51_124_5304744619994590803/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-24_320_7804903070266586536/10002 
+        file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-37-51_124_5304744619994590803/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -359,9 +362,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-24_320_7804903070266586536/10002 [file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-24_320_7804903070266586536/10002]
+        file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-37-51_124_5304744619994590803/10002 [file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-37-51_124_5304744619994590803/10002]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-24_320_7804903070266586536/10002 
+        file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-37-51_124_5304744619994590803/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -372,12 +375,12 @@ STAGE PLANS:
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348784
+              transient_lastDdlTime 1270492671
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -388,12 +391,12 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348784
+                transient_lastDdlTime 1270492671
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -402,7 +405,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-24_320_7804903070266586536/10000
+            directory: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-37-51_124_5304744619994590803/10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -413,12 +416,12 @@ STAGE PLANS:
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1268348784
+                  transient_lastDdlTime 1270492671
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
@@ -444,11 +447,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-32_954_8069950489380829899/10000
+PREHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-00_833_4934747158815120399/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-32_954_8069950489380829899/10000
+POSTHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-00_833_4934747158815120399/10000
 464
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -479,11 +482,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-49_054_4090200478765355576/10000
+PREHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-17_257_5555997609290633171/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-49_054_4090200478765355576/10000
+POSTHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-17_257_5555997609290633171/10000
 464
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -501,14 +504,14 @@ on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-56_624_3600396860306016630/10000
+PREHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-24_468_3503403929229761174/10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-06-56_624_3600396860306016630/10000
+POSTHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-24_468_3503403929229761174/10000
 0	0	0
 PREHOOK: query: explain extended
 insert overwrite table bucketmapjoin_tmp_result 
@@ -584,7 +587,7 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-01_012_3767509085170715505/10002
+                        directory: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-28_297_6620917679758077647/10002
                         NumFilesPerFileSink: 1
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -595,12 +598,12 @@ STAGE PLANS:
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1268348784
+                              transient_lastDdlTime 1270492671
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
@@ -655,7 +658,7 @@ STAGE PLANS:
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-01_012_3767509085170715505/10002
+                          directory: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-28_297_6620917679758077647/10002
                           NumFilesPerFileSink: 1
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -666,12 +669,12 @@ STAGE PLANS:
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                 name bucketmapjoin_tmp_result
                                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1268348784
+                                transient_lastDdlTime 1270492671
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: bucketmapjoin_tmp_result
                           TotalFiles: 1
@@ -680,12 +683,17 @@ STAGE PLANS:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt], srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+              Alias Bucket Output File Name Mapping:
+                file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
+                file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
+                file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
+                file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
+        file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
+        file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -699,13 +707,13 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348782
+              transient_lastDdlTime 1270492669
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -717,13 +725,13 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348782
+                transient_lastDdlTime 1270492669
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
@@ -735,14 +743,14 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-01_012_3767509085170715505/10002
-          destination: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-01_012_3767509085170715505/10000
+          source: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-28_297_6620917679758077647/10002
+          destination: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-28_297_6620917679758077647/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-01_012_3767509085170715505/10000
+          source: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-28_297_6620917679758077647/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -752,20 +760,20 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348784
+                transient_lastDdlTime 1270492671
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-01_012_3767509085170715505/10001
+          tmp directory: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-28_297_6620917679758077647/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-01_012_3767509085170715505/10002 
+        file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-28_297_6620917679758077647/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -781,9 +789,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-01_012_3767509085170715505/10002 [file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-01_012_3767509085170715505/10002]
+        file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-28_297_6620917679758077647/10002 [file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-28_297_6620917679758077647/10002]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-01_012_3767509085170715505/10002 
+        file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-28_297_6620917679758077647/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -794,12 +802,12 @@ STAGE PLANS:
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348784
+              transient_lastDdlTime 1270492671
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -810,12 +818,12 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348784
+                transient_lastDdlTime 1270492671
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -824,7 +832,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-01_012_3767509085170715505/10000
+            directory: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-28_297_6620917679758077647/10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -835,12 +843,12 @@ STAGE PLANS:
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1268348784
+                  transient_lastDdlTime 1270492671
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
@@ -866,11 +874,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-10_899_5943241423234312650/10000
+PREHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-37_665_1360583148724299888/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-10_899_5943241423234312650/10000
+POSTHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-37_665_1360583148724299888/10000
 464
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -901,11 +909,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-28_066_1208658957261253807/10000
+PREHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-54_047_7919202086234490141/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-28_066_1208658957261253807/10000
+POSTHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-38-54_047_7919202086234490141/10000
 464
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -923,14 +931,14 @@ on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-36_714_9051036103640437662/10000
+PREHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-39-01_488_7836991632267919786/10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-36_714_9051036103640437662/10000
+POSTHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_11-39-01_488_7836991632267919786/10000
 0	0	0
 PREHOOK: query: drop table bucketmapjoin_hash_result_2
 PREHOOK: type: DROPTABLE
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin2.q.out b/ql/src/test/results/clientpositive/bucketmapjoin2.q.out
index 3b7e9e99cb..04336a009e 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin2.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin2.q.out
@@ -154,7 +154,7 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-44_937_1252971228120031368/10002
+                    directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-43_344_3171193469789811826/10002
                     NumFilesPerFileSink: 1
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
@@ -165,12 +165,12 @@ STAGE PLANS:
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1268348864
+                          transient_lastDdlTime 1270505023
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
@@ -228,7 +228,7 @@ STAGE PLANS:
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-44_937_1252971228120031368/10002
+                            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-43_344_3171193469789811826/10002
                             NumFilesPerFileSink: 1
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -239,12 +239,12 @@ STAGE PLANS:
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1268348864
+                                  transient_lastDdlTime 1270505023
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
@@ -253,12 +253,15 @@ STAGE PLANS:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket20.txt=[srcbucket22.txt], srcbucket21.txt=[srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                b {file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
+                b {file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
+              Alias Bucket Output File Name Mapping:
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -270,12 +273,12 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348863
+              transient_lastDdlTime 1270505022
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -287,12 +290,12 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348863
+                transient_lastDdlTime 1270505022
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
@@ -304,14 +307,14 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-44_937_1252971228120031368/10002
-          destination: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-44_937_1252971228120031368/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-43_344_3171193469789811826/10002
+          destination: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-43_344_3171193469789811826/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-44_937_1252971228120031368/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-43_344_3171193469789811826/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -321,20 +324,20 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348864
+                transient_lastDdlTime 1270505023
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-44_937_1252971228120031368/10001
+          tmp directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-43_344_3171193469789811826/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-44_937_1252971228120031368/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-43_344_3171193469789811826/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -350,9 +353,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-44_937_1252971228120031368/10002 [file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-44_937_1252971228120031368/10002]
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-43_344_3171193469789811826/10002 [file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-43_344_3171193469789811826/10002]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-44_937_1252971228120031368/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-43_344_3171193469789811826/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -363,12 +366,12 @@ STAGE PLANS:
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348864
+              transient_lastDdlTime 1270505023
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -379,12 +382,12 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348864
+                transient_lastDdlTime 1270505023
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -393,7 +396,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-44_937_1252971228120031368/10000
+            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-43_344_3171193469789811826/10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -404,12 +407,12 @@ STAGE PLANS:
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1268348864
+                  transient_lastDdlTime 1270505023
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
@@ -435,11 +438,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-53_282_7600912700619071025/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-49_373_2482761069773109990/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-07-53_282_7600912700619071025/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-03-49_373_2482761069773109990/10000
 0
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -470,11 +473,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-09_508_5485100783825645091/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-00_476_777369355970216911/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-09_508_5485100783825645091/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-00_476_777369355970216911/10000
 0
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -492,14 +495,14 @@ on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-17_606_4918360383772438343/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-06_139_5168565533826100370/10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-17_606_4918360383772438343/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-06_139_5168565533826100370/10000
 NULL	NULL	NULL
 PREHOOK: query: explain extended
 insert overwrite table bucketmapjoin_tmp_result 
@@ -573,7 +576,7 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-21_630_2117412984874359610/10002
+                        directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-09_151_1812827090817829115/10002
                         NumFilesPerFileSink: 1
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -584,12 +587,12 @@ STAGE PLANS:
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1268348864
+                              transient_lastDdlTime 1270505023
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
@@ -637,7 +640,7 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-21_630_2117412984874359610/10002
+                        directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-09_151_1812827090817829115/10002
                         NumFilesPerFileSink: 1
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -648,12 +651,12 @@ STAGE PLANS:
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1268348864
+                              transient_lastDdlTime 1270505023
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
@@ -662,12 +665,15 @@ STAGE PLANS:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+              Alias Bucket Output File Name Mapping:
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -681,13 +687,13 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348864
+              transient_lastDdlTime 1270505022
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -699,13 +705,13 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348864
+                transient_lastDdlTime 1270505022
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
@@ -717,14 +723,14 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-21_630_2117412984874359610/10002
-          destination: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-21_630_2117412984874359610/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-09_151_1812827090817829115/10002
+          destination: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-09_151_1812827090817829115/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-21_630_2117412984874359610/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-09_151_1812827090817829115/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -734,20 +740,20 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348864
+                transient_lastDdlTime 1270505023
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-21_630_2117412984874359610/10001
+          tmp directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-09_151_1812827090817829115/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-21_630_2117412984874359610/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-09_151_1812827090817829115/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -763,9 +769,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-21_630_2117412984874359610/10002 [file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-21_630_2117412984874359610/10002]
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-09_151_1812827090817829115/10002 [file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-09_151_1812827090817829115/10002]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-21_630_2117412984874359610/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-09_151_1812827090817829115/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -776,12 +782,12 @@ STAGE PLANS:
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348864
+              transient_lastDdlTime 1270505023
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -792,12 +798,12 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348864
+                transient_lastDdlTime 1270505023
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -806,7 +812,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-21_630_2117412984874359610/10000
+            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-09_151_1812827090817829115/10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -817,12 +823,12 @@ STAGE PLANS:
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1268348864
+                  transient_lastDdlTime 1270505023
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
@@ -848,11 +854,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-29_750_208622254935871953/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-16_134_903553875132159287/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-29_750_208622254935871953/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-16_134_903553875132159287/10000
 0
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -883,11 +889,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-55_601_5325555544277093581/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-27_467_4515603506993588732/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-08-55_601_5325555544277093581/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-27_467_4515603506993588732/10000
 0
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -905,14 +911,14 @@ on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-08_351_4983436337832635001/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-33_587_7721898732688560493/10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-08_351_4983436337832635001/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-33_587_7721898732688560493/10000
 NULL	NULL	NULL
 PREHOOK: query: drop table bucketmapjoin_hash_result_2
 PREHOOK: type: DROPTABLE
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin3.q.out b/ql/src/test/results/clientpositive/bucketmapjoin3.q.out
index c2863c2caf..cfe331ecd5 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin3.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin3.q.out
@@ -164,7 +164,7 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-24_901_6063628844240471022/10002
+                        directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-40_539_1761804645954704945/10002
                         NumFilesPerFileSink: 1
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -175,12 +175,12 @@ STAGE PLANS:
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1268348964
+                              transient_lastDdlTime 1270505080
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
@@ -238,7 +238,7 @@ STAGE PLANS:
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-24_901_6063628844240471022/10002
+                            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-40_539_1761804645954704945/10002
                             NumFilesPerFileSink: 1
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -249,12 +249,12 @@ STAGE PLANS:
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1268348964
+                                  transient_lastDdlTime 1270505080
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
@@ -263,12 +263,15 @@ STAGE PLANS:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket22.txt=[srcbucket20.txt, srcbucket22.txt], srcbucket23.txt=[srcbucket21.txt, srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                b {file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
+                b {file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
+              Alias Bucket Output File Name Mapping:
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [a]
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [a]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -282,13 +285,13 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348964
+              transient_lastDdlTime 1270505080
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -300,13 +303,13 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348964
+                transient_lastDdlTime 1270505080
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
@@ -318,14 +321,14 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-24_901_6063628844240471022/10002
-          destination: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-24_901_6063628844240471022/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-40_539_1761804645954704945/10002
+          destination: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-40_539_1761804645954704945/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-24_901_6063628844240471022/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-40_539_1761804645954704945/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -335,20 +338,20 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348964
+                transient_lastDdlTime 1270505080
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-24_901_6063628844240471022/10001
+          tmp directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-40_539_1761804645954704945/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-24_901_6063628844240471022/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-40_539_1761804645954704945/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -364,9 +367,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-24_901_6063628844240471022/10002 [file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-24_901_6063628844240471022/10002]
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-40_539_1761804645954704945/10002 [file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-40_539_1761804645954704945/10002]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-24_901_6063628844240471022/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-40_539_1761804645954704945/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -377,12 +380,12 @@ STAGE PLANS:
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348964
+              transient_lastDdlTime 1270505080
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -393,12 +396,12 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348964
+                transient_lastDdlTime 1270505080
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -407,7 +410,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-24_901_6063628844240471022/10000
+            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-40_539_1761804645954704945/10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -418,12 +421,12 @@ STAGE PLANS:
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1268348964
+                  transient_lastDdlTime 1270505080
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
@@ -449,11 +452,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-39_901_7647152158354564599/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-46_562_5875427649270592251/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-09-39_901_7647152158354564599/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-46_562_5875427649270592251/10000
 564
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -484,11 +487,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-13_576_719486557407694216/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-57_804_715897868482138512/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-13_576_719486557407694216/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-04-57_804_715897868482138512/10000
 564
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -506,14 +509,14 @@ on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-31_144_5464392401940092975/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-03_403_793509935969231446/10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-31_144_5464392401940092975/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-03_403_793509935969231446/10000
 0	0	0
 PREHOOK: query: explain extended 
 insert overwrite table bucketmapjoin_tmp_result 
@@ -587,7 +590,7 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-41_922_1679197703118787011/10002
+                        directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-06_982_5951123687253059920/10002
                         NumFilesPerFileSink: 1
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -598,12 +601,12 @@ STAGE PLANS:
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1268348964
+                              transient_lastDdlTime 1270505080
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
@@ -661,7 +664,7 @@ STAGE PLANS:
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-41_922_1679197703118787011/10002
+                            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-06_982_5951123687253059920/10002
                             NumFilesPerFileSink: 1
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -672,12 +675,12 @@ STAGE PLANS:
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1268348964
+                                  transient_lastDdlTime 1270505080
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
@@ -686,12 +689,17 @@ STAGE PLANS:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket22.txt], srcbucket21.txt=[srcbucket23.txt], srcbucket22.txt=[srcbucket22.txt], srcbucket23.txt=[srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                a {file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
+                a {file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
+              Alias Bucket Output File Name Mapping:
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -705,13 +713,13 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348963
+              transient_lastDdlTime 1270505079
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -723,13 +731,13 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348963
+                transient_lastDdlTime 1270505079
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
@@ -741,14 +749,14 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-41_922_1679197703118787011/10002
-          destination: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-41_922_1679197703118787011/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-06_982_5951123687253059920/10002
+          destination: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-06_982_5951123687253059920/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-41_922_1679197703118787011/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-06_982_5951123687253059920/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -758,20 +766,20 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348964
+                transient_lastDdlTime 1270505080
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-41_922_1679197703118787011/10001
+          tmp directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-06_982_5951123687253059920/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-41_922_1679197703118787011/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-06_982_5951123687253059920/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -787,9 +795,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-41_922_1679197703118787011/10002 [file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-41_922_1679197703118787011/10002]
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-06_982_5951123687253059920/10002 [file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-06_982_5951123687253059920/10002]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-41_922_1679197703118787011/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-06_982_5951123687253059920/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -800,12 +808,12 @@ STAGE PLANS:
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268348964
+              transient_lastDdlTime 1270505080
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -816,12 +824,12 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268348964
+                transient_lastDdlTime 1270505080
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -830,7 +838,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-41_922_1679197703118787011/10000
+            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-06_982_5951123687253059920/10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -841,12 +849,12 @@ STAGE PLANS:
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1268348964
+                  transient_lastDdlTime 1270505080
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
@@ -872,11 +880,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-57_875_3330503946722950502/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-15_154_8249394447363199649/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-10-57_875_3330503946722950502/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-15_154_8249394447363199649/10000
 564
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -907,11 +915,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-35_292_959880905039693104/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-29_458_6246753488992453680/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-35_292_959880905039693104/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-29_458_6246753488992453680/10000
 564
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -929,14 +937,14 @@ on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-48_717_4508199287729084294/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-35_234_1052698096096185255/10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-48_717_4508199287729084294/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-35_234_1052698096096185255/10000
 0	0	0
 PREHOOK: query: drop table bucketmapjoin_hash_result_2
 PREHOOK: type: DROPTABLE
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin4.q.out b/ql/src/test/results/clientpositive/bucketmapjoin4.q.out
index c32d0322d9..724f3d5733 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin4.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin4.q.out
@@ -154,7 +154,7 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-57_871_4266823850494267817/10002
+                    directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002
                     NumFilesPerFileSink: 1
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
@@ -165,12 +165,12 @@ STAGE PLANS:
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1268349117
+                          transient_lastDdlTime 1270505141
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
@@ -218,7 +218,7 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-57_871_4266823850494267817/10002
+                        directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002
                         NumFilesPerFileSink: 1
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -229,12 +229,12 @@ STAGE PLANS:
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1268349117
+                              transient_lastDdlTime 1270505141
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
@@ -243,12 +243,15 @@ STAGE PLANS:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                b {file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                b {file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+              Alias Bucket Output File Name Mapping:
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -260,12 +263,12 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268349116
+              transient_lastDdlTime 1270505140
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -277,12 +280,12 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349116
+                transient_lastDdlTime 1270505140
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
@@ -294,14 +297,14 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-57_871_4266823850494267817/10002
-          destination: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-57_871_4266823850494267817/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002
+          destination: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-57_871_4266823850494267817/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -311,20 +314,20 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349117
+                transient_lastDdlTime 1270505141
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-57_871_4266823850494267817/10001
+          tmp directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-57_871_4266823850494267817/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -340,9 +343,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-57_871_4266823850494267817/10002 [file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-57_871_4266823850494267817/10002]
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002 [file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-57_871_4266823850494267817/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -353,12 +356,12 @@ STAGE PLANS:
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268349117
+              transient_lastDdlTime 1270505141
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -369,12 +372,12 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349117
+                transient_lastDdlTime 1270505141
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -383,7 +386,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-11-57_871_4266823850494267817/10000
+            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -394,12 +397,12 @@ STAGE PLANS:
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1268349117
+                  transient_lastDdlTime 1270505141
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
@@ -423,11 +426,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-12-17_712_4521395371986247985/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-47_572_2716519961288565209/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-12-17_712_4521395371986247985/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-47_572_2716519961288565209/10000
 464
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -456,11 +459,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-12-52_889_4116073570307788189/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-58_635_263344841467156716/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-12-52_889_4116073570307788189/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-58_635_263344841467156716/10000
 464
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -478,14 +481,14 @@ on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-04_092_1313750161468604354/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-04_288_4499541346186910760/10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-04_092_1313750161468604354/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-04_288_4499541346186910760/10000
 0	0	0
 PREHOOK: query: explain extended
 insert overwrite table bucketmapjoin_tmp_result 
@@ -549,7 +552,7 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-12_006_272548200483203179/10002
+                    directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002
                     NumFilesPerFileSink: 1
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
@@ -560,12 +563,12 @@ STAGE PLANS:
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1268349117
+                          transient_lastDdlTime 1270505141
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
@@ -613,7 +616,7 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-12_006_272548200483203179/10002
+                        directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002
                         NumFilesPerFileSink: 1
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -624,12 +627,12 @@ STAGE PLANS:
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1268349117
+                              transient_lastDdlTime 1270505141
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
@@ -638,12 +641,15 @@ STAGE PLANS:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+              Alias Bucket Output File Name Mapping:
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin [b]
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [b]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -655,12 +661,12 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268349116
+              transient_lastDdlTime 1270505140
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -672,12 +678,12 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349116
+                transient_lastDdlTime 1270505140
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
@@ -689,14 +695,14 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-12_006_272548200483203179/10002
-          destination: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-12_006_272548200483203179/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002
+          destination: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-12_006_272548200483203179/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -706,20 +712,20 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349117
+                transient_lastDdlTime 1270505141
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-12_006_272548200483203179/10001
+          tmp directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-12_006_272548200483203179/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -735,9 +741,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-12_006_272548200483203179/10002 [file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-12_006_272548200483203179/10002]
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002 [file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-12_006_272548200483203179/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -748,12 +754,12 @@ STAGE PLANS:
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268349117
+              transient_lastDdlTime 1270505141
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -764,12 +770,12 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349117
+                transient_lastDdlTime 1270505141
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -778,7 +784,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-12_006_272548200483203179/10000
+            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -789,12 +795,12 @@ STAGE PLANS:
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1268349117
+                  transient_lastDdlTime 1270505141
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
@@ -818,11 +824,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-33_739_668909043295636185/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-12_917_4419238107961618871/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-13-33_739_668909043295636185/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-12_917_4419238107961618871/10000
 464
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -851,11 +857,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-08_792_6803659313012587054/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-24_098_3327514646758498260/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-08_792_6803659313012587054/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-24_098_3327514646758498260/10000
 464
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -873,14 +879,14 @@ on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-23_718_2718303906358656762/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-29_679_7550371653184314434/10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-23_718_2718303906358656762/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-29_679_7550371653184314434/10000
 0	0	0
 PREHOOK: query: drop table bucketmapjoin_hash_result_2
 PREHOOK: type: DROPTABLE
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin5.q.out b/ql/src/test/results/clientpositive/bucketmapjoin5.q.out
index 5ef89ea1a9..50b5d70305 100644
--- a/ql/src/test/results/clientpositive/bucketmapjoin5.q.out
+++ b/ql/src/test/results/clientpositive/bucketmapjoin5.q.out
@@ -184,7 +184,7 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-37_967_2403296250341215969/10002
+                    directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-37_193_2256011415562190121/10002
                     NumFilesPerFileSink: 1
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
@@ -195,12 +195,12 @@ STAGE PLANS:
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1268349277
+                          transient_lastDdlTime 1270505197
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
@@ -248,7 +248,7 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-37_967_2403296250341215969/10002
+                        directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-37_193_2256011415562190121/10002
                         NumFilesPerFileSink: 1
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -259,12 +259,12 @@ STAGE PLANS:
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1268349277
+                              transient_lastDdlTime 1270505197
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
@@ -273,13 +273,22 @@ STAGE PLANS:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt], srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket20.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket21.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket22.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+              Alias Bucket Output File Name Mapping:
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt 0
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt 1
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt 2
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt 3
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 [b]
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 [b]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -293,13 +302,13 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268349275
+              transient_lastDdlTime 1270505195
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -311,17 +320,17 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349275
+                transient_lastDdlTime 1270505195
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 
           Partition
             base file name: ds=2008-04-09
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -335,13 +344,13 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268349275
+              transient_lastDdlTime 1270505195
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -353,13 +362,13 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349275
+                transient_lastDdlTime 1270505195
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
@@ -371,14 +380,14 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-37_967_2403296250341215969/10002
-          destination: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-37_967_2403296250341215969/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-37_193_2256011415562190121/10002
+          destination: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-37_193_2256011415562190121/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-37_967_2403296250341215969/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-37_193_2256011415562190121/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -388,20 +397,20 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349277
+                transient_lastDdlTime 1270505197
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-37_967_2403296250341215969/10001
+          tmp directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-37_193_2256011415562190121/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-37_967_2403296250341215969/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-37_193_2256011415562190121/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -417,9 +426,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-37_967_2403296250341215969/10002 [file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-37_967_2403296250341215969/10002]
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-37_193_2256011415562190121/10002 [file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-37_193_2256011415562190121/10002]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-37_967_2403296250341215969/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-37_193_2256011415562190121/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -430,12 +439,12 @@ STAGE PLANS:
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268349277
+              transient_lastDdlTime 1270505197
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -446,12 +455,12 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349277
+                transient_lastDdlTime 1270505197
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -460,7 +469,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-37_967_2403296250341215969/10000
+            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-37_193_2256011415562190121/10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -471,12 +480,12 @@ STAGE PLANS:
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1268349277
+                  transient_lastDdlTime 1270505197
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
@@ -504,11 +513,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-57_195_783118113166525087/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-44_038_5470605936092974356/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-14-57_195_783118113166525087/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-44_038_5470605936092974356/10000
 928
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -541,11 +550,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-30_661_8767326236900506639/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-57_332_1637293370572782645/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-30_661_8767326236900506639/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-57_332_1637293370572782645/10000
 928
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -563,14 +572,14 @@ on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-45_205_4618777774183767354/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-02_848_5796815132179396168/10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-45_205_4618777774183767354/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-02_848_5796815132179396168/10000
 0	0	0
 PREHOOK: query: explain extended
 insert overwrite table bucketmapjoin_tmp_result 
@@ -634,7 +643,7 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-53_656_392872046099932790/10002
+                    directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-05_759_853074240268559837/10002
                     NumFilesPerFileSink: 1
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
@@ -645,12 +654,12 @@ STAGE PLANS:
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1268349277
+                          transient_lastDdlTime 1270505197
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
@@ -698,7 +707,7 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-53_656_392872046099932790/10002
+                        directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-05_759_853074240268559837/10002
                         NumFilesPerFileSink: 1
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -709,12 +718,12 @@ STAGE PLANS:
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1268349277
+                              transient_lastDdlTime 1270505197
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
@@ -723,13 +732,18 @@ STAGE PLANS:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket22.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt=[file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+              Alias Bucket Output File Name Mapping:
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt 0
+                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt 1
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 [b]
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 [b]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -743,13 +757,13 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268349277
+              transient_lastDdlTime 1270505196
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -761,17 +775,17 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349277
+                transient_lastDdlTime 1270505196
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 
+        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 
           Partition
             base file name: ds=2008-04-09
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -785,13 +799,13 @@ STAGE PLANS:
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268349277
+              transient_lastDdlTime 1270505196
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -803,13 +817,13 @@ STAGE PLANS:
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349277
+                transient_lastDdlTime 1270505196
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
@@ -821,14 +835,14 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-53_656_392872046099932790/10002
-          destination: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-53_656_392872046099932790/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-05_759_853074240268559837/10002
+          destination: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-05_759_853074240268559837/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-53_656_392872046099932790/10000
+          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-05_759_853074240268559837/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -838,20 +852,20 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349277
+                transient_lastDdlTime 1270505197
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-53_656_392872046099932790/10001
+          tmp directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-05_759_853074240268559837/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-53_656_392872046099932790/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-05_759_853074240268559837/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -867,9 +881,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-53_656_392872046099932790/10002 [file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-53_656_392872046099932790/10002]
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-05_759_853074240268559837/10002 [file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-05_759_853074240268559837/10002]
       Path -> Partition:
-        file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-53_656_392872046099932790/10002 
+        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-05_759_853074240268559837/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -880,12 +894,12 @@ STAGE PLANS:
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1268349277
+              transient_lastDdlTime 1270505197
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -896,12 +910,12 @@ STAGE PLANS:
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1268349277
+                transient_lastDdlTime 1270505197
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -910,7 +924,7 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-15-53_656_392872046099932790/10000
+            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-05_759_853074240268559837/10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -921,12 +935,12 @@ STAGE PLANS:
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1268349277
+                  transient_lastDdlTime 1270505197
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
@@ -954,11 +968,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-16-08_365_5770438645965845579/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-11_645_4717455330924893580/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-16-08_365_5770438645965845579/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-11_645_4717455330924893580/10000
 0
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -991,11 +1005,11 @@ POSTHOOK: Output: default@bucketmapjoin_tmp_result
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-16-45_334_7493762164796370268/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-22_798_1947603819974079537/10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-16-45_334_7493762164796370268/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-22_798_1947603819974079537/10000
 0
 PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
 select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
@@ -1013,14 +1027,14 @@ on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-16-58_278_4065823787826103572/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-28_358_8877457430636328384/10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive-460/build/ql/scratchdir/hive_2010-03-11_15-16-58_278_4065823787826103572/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-07-28_358_8877457430636328384/10000
 NULL	NULL	NULL
 PREHOOK: query: drop table bucketmapjoin_hash_result_2
 PREHOOK: type: DROPTABLE
diff --git a/ql/src/test/results/clientpositive/bucketmapjoin6.q.out b/ql/src/test/results/clientpositive/bucketmapjoin6.q.out
new file mode 100644
index 0000000000..d7426ae97e
--- /dev/null
+++ b/ql/src/test/results/clientpositive/bucketmapjoin6.q.out
@@ -0,0 +1,153 @@
+PREHOOK: query: drop table tmp1
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table tmp1
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: create table tmp1 (a string, b string) clustered by (a) sorted by (a) into 10 buckets
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table tmp1 (a string, b string) clustered by (a) sorted by (a) into 10 buckets
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@tmp1
+PREHOOK: query: drop table tmp2
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table tmp2
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: create table tmp2 (a string, b string) clustered by (a) sorted by (a) into 10 buckets
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table tmp2 (a string, b string) clustered by (a) sorted by (a) into 10 buckets
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@tmp2
+PREHOOK: query: insert overwrite table tmp1 select * from src where key < 50
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@tmp1
+POSTHOOK: query: insert overwrite table tmp1 select * from src where key < 50
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@tmp1
+PREHOOK: query: insert overwrite table tmp2 select * from src where key < 50
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@tmp2
+POSTHOOK: query: insert overwrite table tmp2 select * from src where key < 50
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@tmp2
+PREHOOK: query: drop table tmp3
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table tmp3
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: create table tmp3 (a string, b string, c string) clustered by (a) sorted by (a) into 10 buckets
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table tmp3 (a string, b string, c string) clustered by (a) sorted by (a) into 10 buckets
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@tmp3
+PREHOOK: query: insert overwrite table tmp3
+  select /*+ MAPJOIN(l) */ i.a, i.b, l.b
+  from tmp1 i join tmp2 l ON i.a = l.a
+PREHOOK: type: QUERY
+PREHOOK: Input: default@tmp2
+PREHOOK: Input: default@tmp1
+PREHOOK: Output: default@tmp3
+POSTHOOK: query: insert overwrite table tmp3
+  select /*+ MAPJOIN(l) */ i.a, i.b, l.b
+  from tmp1 i join tmp2 l ON i.a = l.a
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@tmp2
+POSTHOOK: Input: default@tmp1
+POSTHOOK: Output: default@tmp3
+PREHOOK: query: select * from tmp3
+PREHOOK: type: QUERY
+PREHOOK: Input: default@tmp3
+PREHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_10-57-23_607_4359908197804700708/10000
+POSTHOOK: query: select * from tmp3
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@tmp3
+POSTHOOK: Output: file:/data/users/njain/deploy/deploy1/trunk/VENDOR.hive/trunk/build/ql/scratchdir/hive_2010-04-05_10-57-23_607_4359908197804700708/10000
+0	val_0	val_0
+0	val_0	val_0
+0	val_0	val_0
+0	val_0	val_0
+0	val_0	val_0
+0	val_0	val_0
+0	val_0	val_0
+0	val_0	val_0
+0	val_0	val_0
+10	val_10	val_10
+11	val_11	val_11
+12	val_12	val_12
+12	val_12	val_12
+12	val_12	val_12
+12	val_12	val_12
+15	val_15	val_15
+15	val_15	val_15
+15	val_15	val_15
+15	val_15	val_15
+17	val_17	val_17
+18	val_18	val_18
+18	val_18	val_18
+18	val_18	val_18
+18	val_18	val_18
+19	val_19	val_19
+2	val_2	val_2
+20	val_20	val_20
+24	val_24	val_24
+24	val_24	val_24
+24	val_24	val_24
+24	val_24	val_24
+26	val_26	val_26
+26	val_26	val_26
+26	val_26	val_26
+26	val_26	val_26
+27	val_27	val_27
+28	val_28	val_28
+30	val_30	val_30
+33	val_33	val_33
+34	val_34	val_34
+35	val_35	val_35
+35	val_35	val_35
+35	val_35	val_35
+35	val_35	val_35
+35	val_35	val_35
+35	val_35	val_35
+35	val_35	val_35
+35	val_35	val_35
+35	val_35	val_35
+37	val_37	val_37
+37	val_37	val_37
+37	val_37	val_37
+37	val_37	val_37
+4	val_4	val_4
+41	val_41	val_41
+42	val_42	val_42
+42	val_42	val_42
+42	val_42	val_42
+42	val_42	val_42
+43	val_43	val_43
+44	val_44	val_44
+47	val_47	val_47
+5	val_5	val_5
+5	val_5	val_5
+5	val_5	val_5
+5	val_5	val_5
+5	val_5	val_5
+5	val_5	val_5
+5	val_5	val_5
+5	val_5	val_5
+5	val_5	val_5
+8	val_8	val_8
+9	val_9	val_9
+PREHOOK: query: drop table tmp1
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table tmp1
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Output: default@tmp1
+PREHOOK: query: drop table tmp2
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table tmp2
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Output: default@tmp2
+PREHOOK: query: drop table tmp3
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table tmp3
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Output: default@tmp3
diff --git a/ql/src/test/results/clientpositive/smb_mapjoin_7.q.out b/ql/src/test/results/clientpositive/smb_mapjoin_7.q.out
index 963290f720..e05d3304f6 100644
--- a/ql/src/test/results/clientpositive/smb_mapjoin_7.q.out
+++ b/ql/src/test/results/clientpositive/smb_mapjoin_7.q.out
@@ -87,41 +87,68 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_bucket4_2
 POSTHOOK: Input: default@smb_bucket4_1
 POSTHOOK: Output: default@smb_join_results_empty_bigtable
-PREHOOK: query: select * from smb_join_results_empty_bigtable order by k1
+PREHOOK: query: select * from smb_join_results_empty_bigtable order by k1, v1, k2, v2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_join_results_empty_bigtable
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive_RCFile/build/ql/scratchdir/hive_2010-03-23_17-43-07_414_9075895455978344401/10000
-POSTHOOK: query: select * from smb_join_results_empty_bigtable order by k1
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_18-33-12_819_2480962660545851877/10000
+POSTHOOK: query: select * from smb_join_results_empty_bigtable order by k1, v1, k2, v2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_join_results_empty_bigtable
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive_RCFile/build/ql/scratchdir/hive_2010-03-23_17-43-07_414_9075895455978344401/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_18-33-12_819_2480962660545851877/10000
 NULL	NULL	0	val_0
 NULL	NULL	0	val_0
 NULL	NULL	0	val_0
 NULL	NULL	2	val_2
 NULL	NULL	4	val_4
+NULL	NULL	5	val_5
+NULL	NULL	5	val_5
+NULL	NULL	5	val_5
 NULL	NULL	8	val_8
+NULL	NULL	9	val_9
 NULL	NULL	10	val_10
+NULL	NULL	11	val_11
 NULL	NULL	12	val_12
 NULL	NULL	12	val_12
+NULL	NULL	15	val_15
+NULL	NULL	15	val_15
+NULL	NULL	17	val_17
 NULL	NULL	18	val_18
 NULL	NULL	18	val_18
+NULL	NULL	19	val_19
 NULL	NULL	20	val_20
 NULL	NULL	24	val_24
 NULL	NULL	24	val_24
 NULL	NULL	26	val_26
 NULL	NULL	26	val_26
+NULL	NULL	27	val_27
 NULL	NULL	28	val_28
 NULL	NULL	30	val_30
+NULL	NULL	33	val_33
 NULL	NULL	34	val_34
+NULL	NULL	35	val_35
+NULL	NULL	35	val_35
+NULL	NULL	35	val_35
+NULL	NULL	37	val_37
+NULL	NULL	37	val_37
+NULL	NULL	41	val_41
 NULL	NULL	42	val_42
 NULL	NULL	42	val_42
+NULL	NULL	43	val_43
 NULL	NULL	44	val_44
+NULL	NULL	47	val_47
+NULL	NULL	51	val_51
+NULL	NULL	51	val_51
+NULL	NULL	53	val_53
 NULL	NULL	54	val_54
+NULL	NULL	57	val_57
 NULL	NULL	58	val_58
 NULL	NULL	58	val_58
 NULL	NULL	64	val_64
+NULL	NULL	65	val_65
 NULL	NULL	66	val_66
+NULL	NULL	67	val_67
+NULL	NULL	67	val_67
+NULL	NULL	69	val_69
 NULL	NULL	70	val_70
 NULL	NULL	70	val_70
 NULL	NULL	70	val_70
@@ -130,471 +157,444 @@ NULL	NULL	72	val_72
 NULL	NULL	74	val_74
 NULL	NULL	76	val_76
 NULL	NULL	76	val_76
+NULL	NULL	77	val_77
 NULL	NULL	78	val_78
 NULL	NULL	80	val_80
 NULL	NULL	82	val_82
+NULL	NULL	83	val_83
+NULL	NULL	83	val_83
 NULL	NULL	84	val_84
 NULL	NULL	84	val_84
+NULL	NULL	85	val_85
 NULL	NULL	86	val_86
+NULL	NULL	87	val_87
 NULL	NULL	90	val_90
 NULL	NULL	90	val_90
 NULL	NULL	90	val_90
 NULL	NULL	92	val_92
+NULL	NULL	95	val_95
+NULL	NULL	95	val_95
 NULL	NULL	96	val_96
+NULL	NULL	97	val_97
+NULL	NULL	97	val_97
 NULL	NULL	98	val_98
 NULL	NULL	98	val_98
 NULL	NULL	100	val_100
 NULL	NULL	100	val_100
+NULL	NULL	103	val_103
+NULL	NULL	103	val_103
 NULL	NULL	104	val_104
 NULL	NULL	104	val_104
+NULL	NULL	105	val_105
+NULL	NULL	111	val_111
+NULL	NULL	113	val_113
+NULL	NULL	113	val_113
 NULL	NULL	114	val_114
 NULL	NULL	116	val_116
 NULL	NULL	118	val_118
 NULL	NULL	118	val_118
+NULL	NULL	119	val_119
+NULL	NULL	119	val_119
+NULL	NULL	119	val_119
 NULL	NULL	120	val_120
 NULL	NULL	120	val_120
+NULL	NULL	125	val_125
+NULL	NULL	125	val_125
 NULL	NULL	126	val_126
 NULL	NULL	128	val_128
 NULL	NULL	128	val_128
 NULL	NULL	128	val_128
+NULL	NULL	129	val_129
+NULL	NULL	129	val_129
+NULL	NULL	131	val_131
+NULL	NULL	133	val_133
 NULL	NULL	134	val_134
 NULL	NULL	134	val_134
 NULL	NULL	136	val_136
+NULL	NULL	137	val_137
+NULL	NULL	137	val_137
 NULL	NULL	138	val_138
 NULL	NULL	138	val_138
 NULL	NULL	138	val_138
 NULL	NULL	138	val_138
+NULL	NULL	143	val_143
+NULL	NULL	145	val_145
 NULL	NULL	146	val_146
 NULL	NULL	146	val_146
+NULL	NULL	149	val_149
+NULL	NULL	149	val_149
 NULL	NULL	150	val_150
 NULL	NULL	152	val_152
 NULL	NULL	152	val_152
+NULL	NULL	153	val_153
+NULL	NULL	155	val_155
 NULL	NULL	156	val_156
+NULL	NULL	157	val_157
 NULL	NULL	158	val_158
 NULL	NULL	160	val_160
 NULL	NULL	162	val_162
+NULL	NULL	163	val_163
 NULL	NULL	164	val_164
 NULL	NULL	164	val_164
+NULL	NULL	165	val_165
+NULL	NULL	165	val_165
 NULL	NULL	166	val_166
+NULL	NULL	167	val_167
+NULL	NULL	167	val_167
+NULL	NULL	167	val_167
 NULL	NULL	168	val_168
+NULL	NULL	169	val_169
+NULL	NULL	169	val_169
+NULL	NULL	169	val_169
+NULL	NULL	169	val_169
 NULL	NULL	170	val_170
 NULL	NULL	172	val_172
 NULL	NULL	172	val_172
 NULL	NULL	174	val_174
 NULL	NULL	174	val_174
+NULL	NULL	175	val_175
+NULL	NULL	175	val_175
 NULL	NULL	176	val_176
 NULL	NULL	176	val_176
+NULL	NULL	177	val_177
 NULL	NULL	178	val_178
+NULL	NULL	179	val_179
+NULL	NULL	179	val_179
 NULL	NULL	180	val_180
+NULL	NULL	181	val_181
+NULL	NULL	183	val_183
 NULL	NULL	186	val_186
+NULL	NULL	187	val_187
+NULL	NULL	187	val_187
+NULL	NULL	187	val_187
+NULL	NULL	189	val_189
 NULL	NULL	190	val_190
+NULL	NULL	191	val_191
+NULL	NULL	191	val_191
 NULL	NULL	192	val_192
+NULL	NULL	193	val_193
+NULL	NULL	193	val_193
+NULL	NULL	193	val_193
 NULL	NULL	194	val_194
+NULL	NULL	195	val_195
+NULL	NULL	195	val_195
 NULL	NULL	196	val_196
+NULL	NULL	197	val_197
+NULL	NULL	197	val_197
+NULL	NULL	199	val_199
+NULL	NULL	199	val_199
+NULL	NULL	199	val_199
 NULL	NULL	200	val_200
 NULL	NULL	200	val_200
+NULL	NULL	201	val_201
 NULL	NULL	202	val_202
+NULL	NULL	203	val_203
+NULL	NULL	203	val_203
+NULL	NULL	205	val_205
+NULL	NULL	205	val_205
+NULL	NULL	207	val_207
+NULL	NULL	207	val_207
 NULL	NULL	208	val_208
 NULL	NULL	208	val_208
 NULL	NULL	208	val_208
+NULL	NULL	209	val_209
+NULL	NULL	209	val_209
+NULL	NULL	213	val_213
+NULL	NULL	213	val_213
 NULL	NULL	214	val_214
 NULL	NULL	216	val_216
 NULL	NULL	216	val_216
+NULL	NULL	217	val_217
+NULL	NULL	217	val_217
 NULL	NULL	218	val_218
+NULL	NULL	219	val_219
+NULL	NULL	219	val_219
+NULL	NULL	221	val_221
+NULL	NULL	221	val_221
 NULL	NULL	222	val_222
+NULL	NULL	223	val_223
+NULL	NULL	223	val_223
 NULL	NULL	224	val_224
 NULL	NULL	224	val_224
 NULL	NULL	226	val_226
 NULL	NULL	228	val_228
+NULL	NULL	229	val_229
+NULL	NULL	229	val_229
 NULL	NULL	230	val_230
 NULL	NULL	230	val_230
 NULL	NULL	230	val_230
 NULL	NULL	230	val_230
 NULL	NULL	230	val_230
+NULL	NULL	233	val_233
+NULL	NULL	233	val_233
+NULL	NULL	235	val_235
+NULL	NULL	237	val_237
+NULL	NULL	237	val_237
 NULL	NULL	238	val_238
 NULL	NULL	238	val_238
+NULL	NULL	239	val_239
+NULL	NULL	239	val_239
+NULL	NULL	241	val_241
 NULL	NULL	242	val_242
 NULL	NULL	242	val_242
 NULL	NULL	244	val_244
+NULL	NULL	247	val_247
 NULL	NULL	248	val_248
+NULL	NULL	249	val_249
 NULL	NULL	252	val_252
+NULL	NULL	255	val_255
+NULL	NULL	255	val_255
 NULL	NULL	256	val_256
 NULL	NULL	256	val_256
+NULL	NULL	257	val_257
 NULL	NULL	258	val_258
 NULL	NULL	260	val_260
 NULL	NULL	262	val_262
+NULL	NULL	263	val_263
+NULL	NULL	265	val_265
+NULL	NULL	265	val_265
 NULL	NULL	266	val_266
 NULL	NULL	272	val_272
 NULL	NULL	272	val_272
+NULL	NULL	273	val_273
+NULL	NULL	273	val_273
+NULL	NULL	273	val_273
 NULL	NULL	274	val_274
+NULL	NULL	275	val_275
+NULL	NULL	277	val_277
+NULL	NULL	277	val_277
+NULL	NULL	277	val_277
+NULL	NULL	277	val_277
 NULL	NULL	278	val_278
 NULL	NULL	278	val_278
 NULL	NULL	280	val_280
 NULL	NULL	280	val_280
+NULL	NULL	281	val_281
+NULL	NULL	281	val_281
 NULL	NULL	282	val_282
 NULL	NULL	282	val_282
+NULL	NULL	283	val_283
 NULL	NULL	284	val_284
+NULL	NULL	285	val_285
 NULL	NULL	286	val_286
+NULL	NULL	287	val_287
 NULL	NULL	288	val_288
 NULL	NULL	288	val_288
+NULL	NULL	289	val_289
+NULL	NULL	291	val_291
 NULL	NULL	292	val_292
 NULL	NULL	296	val_296
 NULL	NULL	298	val_298
 NULL	NULL	298	val_298
 NULL	NULL	298	val_298
 NULL	NULL	302	val_302
+NULL	NULL	305	val_305
 NULL	NULL	306	val_306
+NULL	NULL	307	val_307
+NULL	NULL	307	val_307
 NULL	NULL	308	val_308
+NULL	NULL	309	val_309
+NULL	NULL	309	val_309
 NULL	NULL	310	val_310
+NULL	NULL	311	val_311
+NULL	NULL	311	val_311
+NULL	NULL	311	val_311
+NULL	NULL	315	val_315
 NULL	NULL	316	val_316
 NULL	NULL	316	val_316
 NULL	NULL	316	val_316
+NULL	NULL	317	val_317
+NULL	NULL	317	val_317
 NULL	NULL	318	val_318
 NULL	NULL	318	val_318
 NULL	NULL	318	val_318
+NULL	NULL	321	val_321
+NULL	NULL	321	val_321
 NULL	NULL	322	val_322
 NULL	NULL	322	val_322
+NULL	NULL	323	val_323
+NULL	NULL	325	val_325
+NULL	NULL	325	val_325
+NULL	NULL	327	val_327
+NULL	NULL	327	val_327
+NULL	NULL	327	val_327
+NULL	NULL	331	val_331
+NULL	NULL	331	val_331
 NULL	NULL	332	val_332
+NULL	NULL	333	val_333
+NULL	NULL	333	val_333
+NULL	NULL	335	val_335
 NULL	NULL	336	val_336
 NULL	NULL	338	val_338
+NULL	NULL	339	val_339
+NULL	NULL	341	val_341
 NULL	NULL	342	val_342
 NULL	NULL	342	val_342
 NULL	NULL	344	val_344
 NULL	NULL	344	val_344
+NULL	NULL	345	val_345
 NULL	NULL	348	val_348
 NULL	NULL	348	val_348
 NULL	NULL	348	val_348
 NULL	NULL	348	val_348
 NULL	NULL	348	val_348
+NULL	NULL	351	val_351
+NULL	NULL	353	val_353
+NULL	NULL	353	val_353
 NULL	NULL	356	val_356
 NULL	NULL	360	val_360
 NULL	NULL	362	val_362
 NULL	NULL	364	val_364
+NULL	NULL	365	val_365
 NULL	NULL	366	val_366
+NULL	NULL	367	val_367
+NULL	NULL	367	val_367
 NULL	NULL	368	val_368
+NULL	NULL	369	val_369
+NULL	NULL	369	val_369
+NULL	NULL	369	val_369
+NULL	NULL	373	val_373
 NULL	NULL	374	val_374
+NULL	NULL	375	val_375
+NULL	NULL	377	val_377
 NULL	NULL	378	val_378
+NULL	NULL	379	val_379
 NULL	NULL	382	val_382
 NULL	NULL	382	val_382
 NULL	NULL	384	val_384
 NULL	NULL	384	val_384
 NULL	NULL	384	val_384
 NULL	NULL	386	val_386
+NULL	NULL	389	val_389
 NULL	NULL	392	val_392
+NULL	NULL	393	val_393
 NULL	NULL	394	val_394
+NULL	NULL	395	val_395
+NULL	NULL	395	val_395
 NULL	NULL	396	val_396
 NULL	NULL	396	val_396
 NULL	NULL	396	val_396
+NULL	NULL	397	val_397
+NULL	NULL	397	val_397
+NULL	NULL	399	val_399
+NULL	NULL	399	val_399
 NULL	NULL	400	val_400
+NULL	NULL	401	val_401
+NULL	NULL	401	val_401
+NULL	NULL	401	val_401
+NULL	NULL	401	val_401
+NULL	NULL	401	val_401
 NULL	NULL	402	val_402
+NULL	NULL	403	val_403
+NULL	NULL	403	val_403
+NULL	NULL	403	val_403
 NULL	NULL	404	val_404
 NULL	NULL	404	val_404
 NULL	NULL	406	val_406
 NULL	NULL	406	val_406
 NULL	NULL	406	val_406
 NULL	NULL	406	val_406
+NULL	NULL	407	val_407
+NULL	NULL	409	val_409
+NULL	NULL	409	val_409
+NULL	NULL	409	val_409
+NULL	NULL	411	val_411
+NULL	NULL	413	val_413
+NULL	NULL	413	val_413
 NULL	NULL	414	val_414
 NULL	NULL	414	val_414
+NULL	NULL	417	val_417
+NULL	NULL	417	val_417
+NULL	NULL	417	val_417
 NULL	NULL	418	val_418
+NULL	NULL	419	val_419
+NULL	NULL	421	val_421
 NULL	NULL	424	val_424
 NULL	NULL	424	val_424
+NULL	NULL	427	val_427
+NULL	NULL	429	val_429
+NULL	NULL	429	val_429
 NULL	NULL	430	val_430
 NULL	NULL	430	val_430
 NULL	NULL	430	val_430
+NULL	NULL	431	val_431
+NULL	NULL	431	val_431
+NULL	NULL	431	val_431
 NULL	NULL	432	val_432
+NULL	NULL	435	val_435
 NULL	NULL	436	val_436
+NULL	NULL	437	val_437
 NULL	NULL	438	val_438
 NULL	NULL	438	val_438
 NULL	NULL	438	val_438
+NULL	NULL	439	val_439
+NULL	NULL	439	val_439
+NULL	NULL	443	val_443
 NULL	NULL	444	val_444
 NULL	NULL	446	val_446
 NULL	NULL	448	val_448
+NULL	NULL	449	val_449
 NULL	NULL	452	val_452
+NULL	NULL	453	val_453
 NULL	NULL	454	val_454
 NULL	NULL	454	val_454
 NULL	NULL	454	val_454
+NULL	NULL	455	val_455
+NULL	NULL	457	val_457
 NULL	NULL	458	val_458
 NULL	NULL	458	val_458
+NULL	NULL	459	val_459
+NULL	NULL	459	val_459
 NULL	NULL	460	val_460
 NULL	NULL	462	val_462
 NULL	NULL	462	val_462
+NULL	NULL	463	val_463
+NULL	NULL	463	val_463
 NULL	NULL	466	val_466
 NULL	NULL	466	val_466
 NULL	NULL	466	val_466
+NULL	NULL	467	val_467
 NULL	NULL	468	val_468
 NULL	NULL	468	val_468
 NULL	NULL	468	val_468
 NULL	NULL	468	val_468
+NULL	NULL	469	val_469
+NULL	NULL	469	val_469
+NULL	NULL	469	val_469
+NULL	NULL	469	val_469
+NULL	NULL	469	val_469
 NULL	NULL	470	val_470
 NULL	NULL	472	val_472
+NULL	NULL	475	val_475
+NULL	NULL	477	val_477
 NULL	NULL	478	val_478
 NULL	NULL	478	val_478
+NULL	NULL	479	val_479
 NULL	NULL	480	val_480
 NULL	NULL	480	val_480
 NULL	NULL	480	val_480
+NULL	NULL	481	val_481
 NULL	NULL	482	val_482
+NULL	NULL	483	val_483
 NULL	NULL	484	val_484
+NULL	NULL	485	val_485
+NULL	NULL	487	val_487
+NULL	NULL	489	val_489
+NULL	NULL	489	val_489
+NULL	NULL	489	val_489
+NULL	NULL	489	val_489
 NULL	NULL	490	val_490
+NULL	NULL	491	val_491
 NULL	NULL	492	val_492
 NULL	NULL	492	val_492
+NULL	NULL	493	val_493
 NULL	NULL	494	val_494
+NULL	NULL	495	val_495
 NULL	NULL	496	val_496
+NULL	NULL	497	val_497
 NULL	NULL	498	val_498
 NULL	NULL	498	val_498
 NULL	NULL	498	val_498
-NULL	NULL	5	val_5
-NULL	NULL	5	val_5
-NULL	NULL	5	val_5
-NULL	NULL	9	val_9
-NULL	NULL	11	val_11
-NULL	NULL	15	val_15
-NULL	NULL	15	val_15
-NULL	NULL	17	val_17
-NULL	NULL	19	val_19
-NULL	NULL	27	val_27
-NULL	NULL	33	val_33
-NULL	NULL	35	val_35
-NULL	NULL	35	val_35
-NULL	NULL	35	val_35
-NULL	NULL	37	val_37
-NULL	NULL	37	val_37
-NULL	NULL	41	val_41
-NULL	NULL	43	val_43
-NULL	NULL	47	val_47
-NULL	NULL	51	val_51
-NULL	NULL	51	val_51
-NULL	NULL	53	val_53
-NULL	NULL	57	val_57
-NULL	NULL	65	val_65
-NULL	NULL	67	val_67
-NULL	NULL	67	val_67
-NULL	NULL	69	val_69
-NULL	NULL	77	val_77
-NULL	NULL	83	val_83
-NULL	NULL	83	val_83
-NULL	NULL	85	val_85
-NULL	NULL	87	val_87
-NULL	NULL	95	val_95
-NULL	NULL	95	val_95
-NULL	NULL	97	val_97
-NULL	NULL	97	val_97
-NULL	NULL	103	val_103
-NULL	NULL	103	val_103
-NULL	NULL	105	val_105
-NULL	NULL	111	val_111
-NULL	NULL	113	val_113
-NULL	NULL	113	val_113
-NULL	NULL	119	val_119
-NULL	NULL	119	val_119
-NULL	NULL	119	val_119
-NULL	NULL	125	val_125
-NULL	NULL	125	val_125
-NULL	NULL	129	val_129
-NULL	NULL	129	val_129
-NULL	NULL	131	val_131
-NULL	NULL	133	val_133
-NULL	NULL	137	val_137
-NULL	NULL	137	val_137
-NULL	NULL	143	val_143
-NULL	NULL	145	val_145
-NULL	NULL	149	val_149
-NULL	NULL	149	val_149
-NULL	NULL	153	val_153
-NULL	NULL	155	val_155
-NULL	NULL	157	val_157
-NULL	NULL	163	val_163
-NULL	NULL	165	val_165
-NULL	NULL	165	val_165
-NULL	NULL	167	val_167
-NULL	NULL	167	val_167
-NULL	NULL	167	val_167
-NULL	NULL	169	val_169
-NULL	NULL	169	val_169
-NULL	NULL	169	val_169
-NULL	NULL	169	val_169
-NULL	NULL	175	val_175
-NULL	NULL	175	val_175
-NULL	NULL	177	val_177
-NULL	NULL	179	val_179
-NULL	NULL	179	val_179
-NULL	NULL	181	val_181
-NULL	NULL	183	val_183
-NULL	NULL	187	val_187
-NULL	NULL	187	val_187
-NULL	NULL	187	val_187
-NULL	NULL	189	val_189
-NULL	NULL	191	val_191
-NULL	NULL	191	val_191
-NULL	NULL	193	val_193
-NULL	NULL	193	val_193
-NULL	NULL	193	val_193
-NULL	NULL	195	val_195
-NULL	NULL	195	val_195
-NULL	NULL	197	val_197
-NULL	NULL	197	val_197
-NULL	NULL	199	val_199
-NULL	NULL	199	val_199
-NULL	NULL	199	val_199
-NULL	NULL	201	val_201
-NULL	NULL	203	val_203
-NULL	NULL	203	val_203
-NULL	NULL	205	val_205
-NULL	NULL	205	val_205
-NULL	NULL	207	val_207
-NULL	NULL	207	val_207
-NULL	NULL	209	val_209
-NULL	NULL	209	val_209
-NULL	NULL	213	val_213
-NULL	NULL	213	val_213
-NULL	NULL	217	val_217
-NULL	NULL	217	val_217
-NULL	NULL	219	val_219
-NULL	NULL	219	val_219
-NULL	NULL	221	val_221
-NULL	NULL	221	val_221
-NULL	NULL	223	val_223
-NULL	NULL	223	val_223
-NULL	NULL	229	val_229
-NULL	NULL	229	val_229
-NULL	NULL	233	val_233
-NULL	NULL	233	val_233
-NULL	NULL	235	val_235
-NULL	NULL	237	val_237
-NULL	NULL	237	val_237
-NULL	NULL	239	val_239
-NULL	NULL	239	val_239
-NULL	NULL	241	val_241
-NULL	NULL	247	val_247
-NULL	NULL	249	val_249
-NULL	NULL	255	val_255
-NULL	NULL	255	val_255
-NULL	NULL	257	val_257
-NULL	NULL	263	val_263
-NULL	NULL	265	val_265
-NULL	NULL	265	val_265
-NULL	NULL	273	val_273
-NULL	NULL	273	val_273
-NULL	NULL	273	val_273
-NULL	NULL	275	val_275
-NULL	NULL	277	val_277
-NULL	NULL	277	val_277
-NULL	NULL	277	val_277
-NULL	NULL	277	val_277
-NULL	NULL	281	val_281
-NULL	NULL	281	val_281
-NULL	NULL	283	val_283
-NULL	NULL	285	val_285
-NULL	NULL	287	val_287
-NULL	NULL	289	val_289
-NULL	NULL	291	val_291
-NULL	NULL	305	val_305
-NULL	NULL	307	val_307
-NULL	NULL	307	val_307
-NULL	NULL	309	val_309
-NULL	NULL	309	val_309
-NULL	NULL	311	val_311
-NULL	NULL	311	val_311
-NULL	NULL	311	val_311
-NULL	NULL	315	val_315
-NULL	NULL	317	val_317
-NULL	NULL	317	val_317
-NULL	NULL	321	val_321
-NULL	NULL	321	val_321
-NULL	NULL	323	val_323
-NULL	NULL	325	val_325
-NULL	NULL	325	val_325
-NULL	NULL	327	val_327
-NULL	NULL	327	val_327
-NULL	NULL	327	val_327
-NULL	NULL	331	val_331
-NULL	NULL	331	val_331
-NULL	NULL	333	val_333
-NULL	NULL	333	val_333
-NULL	NULL	335	val_335
-NULL	NULL	339	val_339
-NULL	NULL	341	val_341
-NULL	NULL	345	val_345
-NULL	NULL	351	val_351
-NULL	NULL	353	val_353
-NULL	NULL	353	val_353
-NULL	NULL	365	val_365
-NULL	NULL	367	val_367
-NULL	NULL	367	val_367
-NULL	NULL	369	val_369
-NULL	NULL	369	val_369
-NULL	NULL	369	val_369
-NULL	NULL	373	val_373
-NULL	NULL	375	val_375
-NULL	NULL	377	val_377
-NULL	NULL	379	val_379
-NULL	NULL	389	val_389
-NULL	NULL	393	val_393
-NULL	NULL	395	val_395
-NULL	NULL	395	val_395
-NULL	NULL	397	val_397
-NULL	NULL	397	val_397
-NULL	NULL	399	val_399
-NULL	NULL	399	val_399
-NULL	NULL	401	val_401
-NULL	NULL	401	val_401
-NULL	NULL	401	val_401
-NULL	NULL	401	val_401
-NULL	NULL	401	val_401
-NULL	NULL	403	val_403
-NULL	NULL	403	val_403
-NULL	NULL	403	val_403
-NULL	NULL	407	val_407
-NULL	NULL	409	val_409
-NULL	NULL	409	val_409
-NULL	NULL	409	val_409
-NULL	NULL	411	val_411
-NULL	NULL	413	val_413
-NULL	NULL	413	val_413
-NULL	NULL	417	val_417
-NULL	NULL	417	val_417
-NULL	NULL	417	val_417
-NULL	NULL	419	val_419
-NULL	NULL	421	val_421
-NULL	NULL	427	val_427
-NULL	NULL	429	val_429
-NULL	NULL	429	val_429
-NULL	NULL	431	val_431
-NULL	NULL	431	val_431
-NULL	NULL	431	val_431
-NULL	NULL	435	val_435
-NULL	NULL	437	val_437
-NULL	NULL	439	val_439
-NULL	NULL	439	val_439
-NULL	NULL	443	val_443
-NULL	NULL	449	val_449
-NULL	NULL	453	val_453
-NULL	NULL	455	val_455
-NULL	NULL	457	val_457
-NULL	NULL	459	val_459
-NULL	NULL	459	val_459
-NULL	NULL	463	val_463
-NULL	NULL	463	val_463
-NULL	NULL	467	val_467
-NULL	NULL	469	val_469
-NULL	NULL	469	val_469
-NULL	NULL	469	val_469
-NULL	NULL	469	val_469
-NULL	NULL	469	val_469
-NULL	NULL	475	val_475
-NULL	NULL	477	val_477
-NULL	NULL	479	val_479
-NULL	NULL	481	val_481
-NULL	NULL	483	val_483
-NULL	NULL	485	val_485
-NULL	NULL	487	val_487
-NULL	NULL	489	val_489
-NULL	NULL	489	val_489
-NULL	NULL	489	val_489
-NULL	NULL	489	val_489
-NULL	NULL	491	val_491
-NULL	NULL	493	val_493
-NULL	NULL	495	val_495
-NULL	NULL	497	val_497
 PREHOOK: query: explain
 insert overwrite table smb_join_results
 select /*+mapjoin(a)*/ * from smb_bucket4_1 a full outer join smb_bucket4_2 b on a.key = b.key
@@ -678,424 +678,336 @@ PREHOOK: Input: default@smb_bucket4_2
 PREHOOK: Input: default@smb_bucket4_1
 PREHOOK: Output: default@smb_join_results
 POSTHOOK: query: insert overwrite table smb_join_results
-select /*+mapjoin(a)*/ * from smb_bucket4_1 a full outer join smb_bucket4_2 b on a.key = b.key
-POSTHOOK: type: QUERY
-POSTHOOK: Input: default@smb_bucket4_2
-POSTHOOK: Input: default@smb_bucket4_1
-POSTHOOK: Output: default@smb_join_results
-PREHOOK: query: select * from smb_join_results order by k1
-PREHOOK: type: QUERY
-PREHOOK: Input: default@smb_join_results
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive_RCFile/build/ql/scratchdir/hive_2010-03-23_17-43-20_724_8972446774229078097/10000
-POSTHOOK: query: select * from smb_join_results order by k1
-POSTHOOK: type: QUERY
-POSTHOOK: Input: default@smb_join_results
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive_RCFile/build/ql/scratchdir/hive_2010-03-23_17-43-20_724_8972446774229078097/10000
-NULL	NULL	0	val_0
-NULL	NULL	0	val_0
-NULL	NULL	0	val_0
-NULL	NULL	2	val_2
-NULL	NULL	4	val_4
-NULL	NULL	8	val_8
-NULL	NULL	10	val_10
-NULL	NULL	12	val_12
-NULL	NULL	12	val_12
-NULL	NULL	18	val_18
-NULL	NULL	18	val_18
-NULL	NULL	20	val_20
-NULL	NULL	24	val_24
-NULL	NULL	24	val_24
-NULL	NULL	26	val_26
-NULL	NULL	26	val_26
-NULL	NULL	28	val_28
-NULL	NULL	30	val_30
-NULL	NULL	34	val_34
-NULL	NULL	42	val_42
-NULL	NULL	42	val_42
-NULL	NULL	44	val_44
-NULL	NULL	54	val_54
-NULL	NULL	58	val_58
-NULL	NULL	58	val_58
-NULL	NULL	64	val_64
-NULL	NULL	66	val_66
-NULL	NULL	70	val_70
-NULL	NULL	70	val_70
-NULL	NULL	70	val_70
-NULL	NULL	72	val_72
-NULL	NULL	72	val_72
-NULL	NULL	74	val_74
-NULL	NULL	76	val_76
-NULL	NULL	76	val_76
-NULL	NULL	78	val_78
-NULL	NULL	80	val_80
-NULL	NULL	82	val_82
-NULL	NULL	84	val_84
-NULL	NULL	84	val_84
-NULL	NULL	86	val_86
-NULL	NULL	90	val_90
-NULL	NULL	90	val_90
-NULL	NULL	90	val_90
-NULL	NULL	92	val_92
-NULL	NULL	96	val_96
-NULL	NULL	98	val_98
-NULL	NULL	98	val_98
-NULL	NULL	100	val_100
-NULL	NULL	100	val_100
-NULL	NULL	104	val_104
-NULL	NULL	104	val_104
-NULL	NULL	114	val_114
-NULL	NULL	116	val_116
-NULL	NULL	118	val_118
-NULL	NULL	118	val_118
-NULL	NULL	120	val_120
-NULL	NULL	120	val_120
-NULL	NULL	126	val_126
-NULL	NULL	128	val_128
-NULL	NULL	128	val_128
-NULL	NULL	128	val_128
-NULL	NULL	134	val_134
-NULL	NULL	134	val_134
-NULL	NULL	136	val_136
-NULL	NULL	138	val_138
-NULL	NULL	138	val_138
-NULL	NULL	138	val_138
-NULL	NULL	138	val_138
-NULL	NULL	146	val_146
-NULL	NULL	146	val_146
-NULL	NULL	150	val_150
-NULL	NULL	152	val_152
-NULL	NULL	152	val_152
-NULL	NULL	156	val_156
-NULL	NULL	158	val_158
-NULL	NULL	160	val_160
-NULL	NULL	162	val_162
-NULL	NULL	164	val_164
-NULL	NULL	164	val_164
-NULL	NULL	166	val_166
-NULL	NULL	168	val_168
-NULL	NULL	170	val_170
-NULL	NULL	172	val_172
-NULL	NULL	172	val_172
-NULL	NULL	174	val_174
-NULL	NULL	174	val_174
-NULL	NULL	176	val_176
-NULL	NULL	176	val_176
-NULL	NULL	178	val_178
-NULL	NULL	180	val_180
-NULL	NULL	186	val_186
-NULL	NULL	190	val_190
-NULL	NULL	192	val_192
-NULL	NULL	194	val_194
-NULL	NULL	196	val_196
-NULL	NULL	200	val_200
-NULL	NULL	200	val_200
-NULL	NULL	202	val_202
-NULL	NULL	208	val_208
-NULL	NULL	208	val_208
-NULL	NULL	208	val_208
-NULL	NULL	214	val_214
-NULL	NULL	216	val_216
-NULL	NULL	216	val_216
-NULL	NULL	218	val_218
-NULL	NULL	222	val_222
-NULL	NULL	224	val_224
-NULL	NULL	224	val_224
-NULL	NULL	226	val_226
-NULL	NULL	228	val_228
-NULL	NULL	230	val_230
-NULL	NULL	230	val_230
-NULL	NULL	230	val_230
-NULL	NULL	230	val_230
-NULL	NULL	230	val_230
-NULL	NULL	238	val_238
-NULL	NULL	238	val_238
-NULL	NULL	242	val_242
-NULL	NULL	242	val_242
-NULL	NULL	244	val_244
-NULL	NULL	248	val_248
-NULL	NULL	252	val_252
-NULL	NULL	256	val_256
-NULL	NULL	256	val_256
-NULL	NULL	258	val_258
-NULL	NULL	260	val_260
-NULL	NULL	262	val_262
-NULL	NULL	266	val_266
-NULL	NULL	272	val_272
-NULL	NULL	272	val_272
-NULL	NULL	274	val_274
-NULL	NULL	278	val_278
-NULL	NULL	278	val_278
-NULL	NULL	280	val_280
-NULL	NULL	280	val_280
-NULL	NULL	282	val_282
-NULL	NULL	282	val_282
-NULL	NULL	284	val_284
-NULL	NULL	286	val_286
-NULL	NULL	288	val_288
-NULL	NULL	288	val_288
-NULL	NULL	292	val_292
-NULL	NULL	296	val_296
-NULL	NULL	298	val_298
-NULL	NULL	298	val_298
-NULL	NULL	298	val_298
-NULL	NULL	302	val_302
-NULL	NULL	306	val_306
-NULL	NULL	308	val_308
-NULL	NULL	310	val_310
-NULL	NULL	316	val_316
-NULL	NULL	316	val_316
-NULL	NULL	316	val_316
-NULL	NULL	318	val_318
-NULL	NULL	318	val_318
-NULL	NULL	318	val_318
-NULL	NULL	322	val_322
-NULL	NULL	322	val_322
-NULL	NULL	332	val_332
-NULL	NULL	336	val_336
-NULL	NULL	338	val_338
-NULL	NULL	342	val_342
-NULL	NULL	342	val_342
-NULL	NULL	344	val_344
-NULL	NULL	344	val_344
-NULL	NULL	348	val_348
-NULL	NULL	348	val_348
-NULL	NULL	348	val_348
-NULL	NULL	348	val_348
-NULL	NULL	348	val_348
-NULL	NULL	356	val_356
-NULL	NULL	360	val_360
-NULL	NULL	362	val_362
-NULL	NULL	364	val_364
-NULL	NULL	366	val_366
-NULL	NULL	368	val_368
-NULL	NULL	374	val_374
-NULL	NULL	378	val_378
-NULL	NULL	382	val_382
-NULL	NULL	382	val_382
-NULL	NULL	384	val_384
-NULL	NULL	384	val_384
-NULL	NULL	384	val_384
-NULL	NULL	386	val_386
-NULL	NULL	392	val_392
-NULL	NULL	394	val_394
-NULL	NULL	396	val_396
-NULL	NULL	396	val_396
-NULL	NULL	396	val_396
-NULL	NULL	400	val_400
-NULL	NULL	402	val_402
-NULL	NULL	404	val_404
-NULL	NULL	404	val_404
-NULL	NULL	406	val_406
-NULL	NULL	406	val_406
-NULL	NULL	406	val_406
-NULL	NULL	406	val_406
-NULL	NULL	414	val_414
-NULL	NULL	414	val_414
-NULL	NULL	418	val_418
-NULL	NULL	424	val_424
-NULL	NULL	424	val_424
-NULL	NULL	430	val_430
-NULL	NULL	430	val_430
-NULL	NULL	430	val_430
-NULL	NULL	432	val_432
-NULL	NULL	436	val_436
-NULL	NULL	438	val_438
-NULL	NULL	438	val_438
-NULL	NULL	438	val_438
-NULL	NULL	444	val_444
-NULL	NULL	446	val_446
-NULL	NULL	448	val_448
-NULL	NULL	452	val_452
-NULL	NULL	454	val_454
-NULL	NULL	454	val_454
-NULL	NULL	454	val_454
-NULL	NULL	458	val_458
-NULL	NULL	458	val_458
-NULL	NULL	460	val_460
-NULL	NULL	462	val_462
-NULL	NULL	462	val_462
-NULL	NULL	466	val_466
-NULL	NULL	466	val_466
-NULL	NULL	466	val_466
-NULL	NULL	468	val_468
-NULL	NULL	468	val_468
-NULL	NULL	468	val_468
-NULL	NULL	468	val_468
-NULL	NULL	470	val_470
-NULL	NULL	472	val_472
-NULL	NULL	478	val_478
-NULL	NULL	478	val_478
-NULL	NULL	480	val_480
-NULL	NULL	480	val_480
-NULL	NULL	480	val_480
-NULL	NULL	482	val_482
-NULL	NULL	484	val_484
-NULL	NULL	490	val_490
-NULL	NULL	492	val_492
-NULL	NULL	492	val_492
-NULL	NULL	494	val_494
-NULL	NULL	496	val_496
-NULL	NULL	498	val_498
-NULL	NULL	498	val_498
-NULL	NULL	498	val_498
+select /*+mapjoin(a)*/ * from smb_bucket4_1 a full outer join smb_bucket4_2 b on a.key = b.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@smb_bucket4_2
+POSTHOOK: Input: default@smb_bucket4_1
+POSTHOOK: Output: default@smb_join_results
+PREHOOK: query: select * from smb_join_results order by k1, v1, k2, v2
+PREHOOK: type: QUERY
+PREHOOK: Input: default@smb_join_results
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_18-33-19_000_3282437314854908032/10000
+POSTHOOK: query: select * from smb_join_results order by k1, v1, k2, v2
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@smb_join_results
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_18-33-19_000_3282437314854908032/10000
+NULL	NULL	0	val_0
+NULL	NULL	0	val_0
+NULL	NULL	0	val_0
+NULL	NULL	2	val_2
+NULL	NULL	4	val_4
 NULL	NULL	5	val_5
 NULL	NULL	5	val_5
 NULL	NULL	5	val_5
+NULL	NULL	8	val_8
 NULL	NULL	9	val_9
+NULL	NULL	10	val_10
 NULL	NULL	11	val_11
+NULL	NULL	12	val_12
+NULL	NULL	12	val_12
 NULL	NULL	15	val_15
 NULL	NULL	15	val_15
 NULL	NULL	17	val_17
+NULL	NULL	18	val_18
+NULL	NULL	18	val_18
 NULL	NULL	19	val_19
+NULL	NULL	20	val_20
+NULL	NULL	24	val_24
+NULL	NULL	24	val_24
+NULL	NULL	26	val_26
+NULL	NULL	26	val_26
 NULL	NULL	27	val_27
+NULL	NULL	28	val_28
+NULL	NULL	30	val_30
 NULL	NULL	33	val_33
+NULL	NULL	34	val_34
 NULL	NULL	35	val_35
 NULL	NULL	35	val_35
 NULL	NULL	35	val_35
 NULL	NULL	37	val_37
 NULL	NULL	37	val_37
 NULL	NULL	41	val_41
+NULL	NULL	42	val_42
+NULL	NULL	42	val_42
 NULL	NULL	43	val_43
+NULL	NULL	44	val_44
 NULL	NULL	47	val_47
 NULL	NULL	51	val_51
 NULL	NULL	51	val_51
 NULL	NULL	53	val_53
+NULL	NULL	54	val_54
 NULL	NULL	57	val_57
+NULL	NULL	58	val_58
+NULL	NULL	58	val_58
+NULL	NULL	64	val_64
 NULL	NULL	65	val_65
+NULL	NULL	66	val_66
 NULL	NULL	67	val_67
 NULL	NULL	67	val_67
 NULL	NULL	69	val_69
+NULL	NULL	70	val_70
+NULL	NULL	70	val_70
+NULL	NULL	70	val_70
+NULL	NULL	72	val_72
+NULL	NULL	72	val_72
+NULL	NULL	74	val_74
+NULL	NULL	76	val_76
+NULL	NULL	76	val_76
 NULL	NULL	77	val_77
+NULL	NULL	78	val_78
+NULL	NULL	80	val_80
+NULL	NULL	82	val_82
 NULL	NULL	83	val_83
 NULL	NULL	83	val_83
+NULL	NULL	84	val_84
+NULL	NULL	84	val_84
 NULL	NULL	85	val_85
+NULL	NULL	86	val_86
 NULL	NULL	87	val_87
+NULL	NULL	90	val_90
+NULL	NULL	90	val_90
+NULL	NULL	90	val_90
+NULL	NULL	92	val_92
 NULL	NULL	95	val_95
 NULL	NULL	95	val_95
+NULL	NULL	96	val_96
 NULL	NULL	97	val_97
 NULL	NULL	97	val_97
+NULL	NULL	98	val_98
+NULL	NULL	98	val_98
+NULL	NULL	100	val_100
+NULL	NULL	100	val_100
 NULL	NULL	103	val_103
 NULL	NULL	103	val_103
+NULL	NULL	104	val_104
+NULL	NULL	104	val_104
 NULL	NULL	105	val_105
 NULL	NULL	111	val_111
 NULL	NULL	113	val_113
 NULL	NULL	113	val_113
+NULL	NULL	114	val_114
+NULL	NULL	116	val_116
+NULL	NULL	118	val_118
+NULL	NULL	118	val_118
 NULL	NULL	119	val_119
 NULL	NULL	119	val_119
 NULL	NULL	119	val_119
+NULL	NULL	120	val_120
+NULL	NULL	120	val_120
 NULL	NULL	125	val_125
 NULL	NULL	125	val_125
+NULL	NULL	126	val_126
+NULL	NULL	128	val_128
+NULL	NULL	128	val_128
+NULL	NULL	128	val_128
 NULL	NULL	129	val_129
 NULL	NULL	129	val_129
 NULL	NULL	131	val_131
 NULL	NULL	133	val_133
+NULL	NULL	134	val_134
+NULL	NULL	134	val_134
+NULL	NULL	136	val_136
 NULL	NULL	137	val_137
 NULL	NULL	137	val_137
+NULL	NULL	138	val_138
+NULL	NULL	138	val_138
+NULL	NULL	138	val_138
+NULL	NULL	138	val_138
 NULL	NULL	143	val_143
 NULL	NULL	145	val_145
+NULL	NULL	146	val_146
+NULL	NULL	146	val_146
 NULL	NULL	149	val_149
 NULL	NULL	149	val_149
+NULL	NULL	150	val_150
+NULL	NULL	152	val_152
+NULL	NULL	152	val_152
 NULL	NULL	153	val_153
 NULL	NULL	155	val_155
+NULL	NULL	156	val_156
 NULL	NULL	157	val_157
+NULL	NULL	158	val_158
+NULL	NULL	160	val_160
+NULL	NULL	162	val_162
 NULL	NULL	163	val_163
+NULL	NULL	164	val_164
+NULL	NULL	164	val_164
 NULL	NULL	165	val_165
 NULL	NULL	165	val_165
+NULL	NULL	166	val_166
 NULL	NULL	167	val_167
 NULL	NULL	167	val_167
 NULL	NULL	167	val_167
+NULL	NULL	168	val_168
 NULL	NULL	169	val_169
 NULL	NULL	169	val_169
 NULL	NULL	169	val_169
 NULL	NULL	169	val_169
+NULL	NULL	170	val_170
+NULL	NULL	172	val_172
+NULL	NULL	172	val_172
+NULL	NULL	174	val_174
+NULL	NULL	174	val_174
 NULL	NULL	175	val_175
 NULL	NULL	175	val_175
+NULL	NULL	176	val_176
+NULL	NULL	176	val_176
 NULL	NULL	177	val_177
+NULL	NULL	178	val_178
 NULL	NULL	179	val_179
 NULL	NULL	179	val_179
+NULL	NULL	180	val_180
 NULL	NULL	181	val_181
 NULL	NULL	183	val_183
+NULL	NULL	186	val_186
 NULL	NULL	187	val_187
 NULL	NULL	187	val_187
 NULL	NULL	187	val_187
 NULL	NULL	189	val_189
+NULL	NULL	190	val_190
 NULL	NULL	191	val_191
 NULL	NULL	191	val_191
+NULL	NULL	192	val_192
 NULL	NULL	193	val_193
 NULL	NULL	193	val_193
 NULL	NULL	193	val_193
+NULL	NULL	194	val_194
 NULL	NULL	195	val_195
 NULL	NULL	195	val_195
+NULL	NULL	196	val_196
 NULL	NULL	197	val_197
 NULL	NULL	197	val_197
 NULL	NULL	199	val_199
 NULL	NULL	199	val_199
 NULL	NULL	199	val_199
+NULL	NULL	200	val_200
+NULL	NULL	200	val_200
 NULL	NULL	201	val_201
+NULL	NULL	202	val_202
 NULL	NULL	203	val_203
 NULL	NULL	203	val_203
 NULL	NULL	205	val_205
 NULL	NULL	205	val_205
 NULL	NULL	207	val_207
 NULL	NULL	207	val_207
+NULL	NULL	208	val_208
+NULL	NULL	208	val_208
+NULL	NULL	208	val_208
 NULL	NULL	209	val_209
 NULL	NULL	209	val_209
 NULL	NULL	213	val_213
 NULL	NULL	213	val_213
+NULL	NULL	214	val_214
+NULL	NULL	216	val_216
+NULL	NULL	216	val_216
 NULL	NULL	217	val_217
 NULL	NULL	217	val_217
+NULL	NULL	218	val_218
 NULL	NULL	219	val_219
 NULL	NULL	219	val_219
 NULL	NULL	221	val_221
 NULL	NULL	221	val_221
+NULL	NULL	222	val_222
 NULL	NULL	223	val_223
 NULL	NULL	223	val_223
+NULL	NULL	224	val_224
+NULL	NULL	224	val_224
+NULL	NULL	226	val_226
+NULL	NULL	228	val_228
 NULL	NULL	229	val_229
 NULL	NULL	229	val_229
+NULL	NULL	230	val_230
+NULL	NULL	230	val_230
+NULL	NULL	230	val_230
+NULL	NULL	230	val_230
+NULL	NULL	230	val_230
 NULL	NULL	233	val_233
 NULL	NULL	233	val_233
 NULL	NULL	235	val_235
 NULL	NULL	237	val_237
 NULL	NULL	237	val_237
+NULL	NULL	238	val_238
+NULL	NULL	238	val_238
 NULL	NULL	239	val_239
 NULL	NULL	239	val_239
 NULL	NULL	241	val_241
+NULL	NULL	242	val_242
+NULL	NULL	242	val_242
+NULL	NULL	244	val_244
 NULL	NULL	247	val_247
+NULL	NULL	248	val_248
 NULL	NULL	249	val_249
+NULL	NULL	252	val_252
 NULL	NULL	255	val_255
 NULL	NULL	255	val_255
+NULL	NULL	256	val_256
+NULL	NULL	256	val_256
 NULL	NULL	257	val_257
+NULL	NULL	258	val_258
+NULL	NULL	260	val_260
+NULL	NULL	262	val_262
 NULL	NULL	263	val_263
 NULL	NULL	265	val_265
 NULL	NULL	265	val_265
+NULL	NULL	266	val_266
+NULL	NULL	272	val_272
+NULL	NULL	272	val_272
 NULL	NULL	273	val_273
 NULL	NULL	273	val_273
 NULL	NULL	273	val_273
+NULL	NULL	274	val_274
 NULL	NULL	275	val_275
 NULL	NULL	277	val_277
 NULL	NULL	277	val_277
 NULL	NULL	277	val_277
 NULL	NULL	277	val_277
+NULL	NULL	278	val_278
+NULL	NULL	278	val_278
+NULL	NULL	280	val_280
+NULL	NULL	280	val_280
 NULL	NULL	281	val_281
 NULL	NULL	281	val_281
+NULL	NULL	282	val_282
+NULL	NULL	282	val_282
 NULL	NULL	283	val_283
+NULL	NULL	284	val_284
 NULL	NULL	285	val_285
+NULL	NULL	286	val_286
 NULL	NULL	287	val_287
+NULL	NULL	288	val_288
+NULL	NULL	288	val_288
 NULL	NULL	289	val_289
 NULL	NULL	291	val_291
+NULL	NULL	292	val_292
+NULL	NULL	296	val_296
+NULL	NULL	298	val_298
+NULL	NULL	298	val_298
+NULL	NULL	298	val_298
+NULL	NULL	302	val_302
 NULL	NULL	305	val_305
+NULL	NULL	306	val_306
 NULL	NULL	307	val_307
 NULL	NULL	307	val_307
+NULL	NULL	308	val_308
 NULL	NULL	309	val_309
 NULL	NULL	309	val_309
+NULL	NULL	310	val_310
 NULL	NULL	311	val_311
 NULL	NULL	311	val_311
 NULL	NULL	311	val_311
 NULL	NULL	315	val_315
+NULL	NULL	316	val_316
+NULL	NULL	316	val_316
+NULL	NULL	316	val_316
 NULL	NULL	317	val_317
 NULL	NULL	317	val_317
+NULL	NULL	318	val_318
+NULL	NULL	318	val_318
+NULL	NULL	318	val_318
 NULL	NULL	321	val_321
 NULL	NULL	321	val_321
+NULL	NULL	322	val_322
+NULL	NULL	322	val_322
 NULL	NULL	323	val_323
 NULL	NULL	325	val_325
 NULL	NULL	325	val_325
@@ -1104,41 +1016,80 @@ NULL	NULL	327	val_327
 NULL	NULL	327	val_327
 NULL	NULL	331	val_331
 NULL	NULL	331	val_331
+NULL	NULL	332	val_332
 NULL	NULL	333	val_333
 NULL	NULL	333	val_333
 NULL	NULL	335	val_335
+NULL	NULL	336	val_336
+NULL	NULL	338	val_338
 NULL	NULL	339	val_339
 NULL	NULL	341	val_341
+NULL	NULL	342	val_342
+NULL	NULL	342	val_342
+NULL	NULL	344	val_344
+NULL	NULL	344	val_344
 NULL	NULL	345	val_345
+NULL	NULL	348	val_348
+NULL	NULL	348	val_348
+NULL	NULL	348	val_348
+NULL	NULL	348	val_348
+NULL	NULL	348	val_348
 NULL	NULL	351	val_351
 NULL	NULL	353	val_353
 NULL	NULL	353	val_353
+NULL	NULL	356	val_356
+NULL	NULL	360	val_360
+NULL	NULL	362	val_362
+NULL	NULL	364	val_364
 NULL	NULL	365	val_365
+NULL	NULL	366	val_366
 NULL	NULL	367	val_367
 NULL	NULL	367	val_367
+NULL	NULL	368	val_368
 NULL	NULL	369	val_369
 NULL	NULL	369	val_369
 NULL	NULL	369	val_369
 NULL	NULL	373	val_373
+NULL	NULL	374	val_374
 NULL	NULL	375	val_375
 NULL	NULL	377	val_377
+NULL	NULL	378	val_378
 NULL	NULL	379	val_379
+NULL	NULL	382	val_382
+NULL	NULL	382	val_382
+NULL	NULL	384	val_384
+NULL	NULL	384	val_384
+NULL	NULL	384	val_384
+NULL	NULL	386	val_386
 NULL	NULL	389	val_389
+NULL	NULL	392	val_392
 NULL	NULL	393	val_393
+NULL	NULL	394	val_394
 NULL	NULL	395	val_395
 NULL	NULL	395	val_395
+NULL	NULL	396	val_396
+NULL	NULL	396	val_396
+NULL	NULL	396	val_396
 NULL	NULL	397	val_397
 NULL	NULL	397	val_397
 NULL	NULL	399	val_399
 NULL	NULL	399	val_399
+NULL	NULL	400	val_400
 NULL	NULL	401	val_401
 NULL	NULL	401	val_401
 NULL	NULL	401	val_401
 NULL	NULL	401	val_401
 NULL	NULL	401	val_401
+NULL	NULL	402	val_402
 NULL	NULL	403	val_403
 NULL	NULL	403	val_403
 NULL	NULL	403	val_403
+NULL	NULL	404	val_404
+NULL	NULL	404	val_404
+NULL	NULL	406	val_406
+NULL	NULL	406	val_406
+NULL	NULL	406	val_406
+NULL	NULL	406	val_406
 NULL	NULL	407	val_407
 NULL	NULL	409	val_409
 NULL	NULL	409	val_409
@@ -1146,51 +1097,100 @@ NULL	NULL	409	val_409
 NULL	NULL	411	val_411
 NULL	NULL	413	val_413
 NULL	NULL	413	val_413
+NULL	NULL	414	val_414
+NULL	NULL	414	val_414
 NULL	NULL	417	val_417
 NULL	NULL	417	val_417
 NULL	NULL	417	val_417
+NULL	NULL	418	val_418
 NULL	NULL	419	val_419
 NULL	NULL	421	val_421
+NULL	NULL	424	val_424
+NULL	NULL	424	val_424
 NULL	NULL	427	val_427
 NULL	NULL	429	val_429
 NULL	NULL	429	val_429
+NULL	NULL	430	val_430
+NULL	NULL	430	val_430
+NULL	NULL	430	val_430
 NULL	NULL	431	val_431
 NULL	NULL	431	val_431
 NULL	NULL	431	val_431
+NULL	NULL	432	val_432
 NULL	NULL	435	val_435
+NULL	NULL	436	val_436
 NULL	NULL	437	val_437
+NULL	NULL	438	val_438
+NULL	NULL	438	val_438
+NULL	NULL	438	val_438
 NULL	NULL	439	val_439
 NULL	NULL	439	val_439
 NULL	NULL	443	val_443
+NULL	NULL	444	val_444
+NULL	NULL	446	val_446
+NULL	NULL	448	val_448
 NULL	NULL	449	val_449
+NULL	NULL	452	val_452
 NULL	NULL	453	val_453
+NULL	NULL	454	val_454
+NULL	NULL	454	val_454
+NULL	NULL	454	val_454
 NULL	NULL	455	val_455
 NULL	NULL	457	val_457
+NULL	NULL	458	val_458
+NULL	NULL	458	val_458
 NULL	NULL	459	val_459
 NULL	NULL	459	val_459
+NULL	NULL	460	val_460
+NULL	NULL	462	val_462
+NULL	NULL	462	val_462
 NULL	NULL	463	val_463
 NULL	NULL	463	val_463
+NULL	NULL	466	val_466
+NULL	NULL	466	val_466
+NULL	NULL	466	val_466
 NULL	NULL	467	val_467
+NULL	NULL	468	val_468
+NULL	NULL	468	val_468
+NULL	NULL	468	val_468
+NULL	NULL	468	val_468
 NULL	NULL	469	val_469
 NULL	NULL	469	val_469
 NULL	NULL	469	val_469
 NULL	NULL	469	val_469
 NULL	NULL	469	val_469
+NULL	NULL	470	val_470
+NULL	NULL	472	val_472
 NULL	NULL	475	val_475
 NULL	NULL	477	val_477
+NULL	NULL	478	val_478
+NULL	NULL	478	val_478
 NULL	NULL	479	val_479
+NULL	NULL	480	val_480
+NULL	NULL	480	val_480
+NULL	NULL	480	val_480
 NULL	NULL	481	val_481
+NULL	NULL	482	val_482
 NULL	NULL	483	val_483
+NULL	NULL	484	val_484
 NULL	NULL	485	val_485
 NULL	NULL	487	val_487
 NULL	NULL	489	val_489
 NULL	NULL	489	val_489
 NULL	NULL	489	val_489
 NULL	NULL	489	val_489
+NULL	NULL	490	val_490
 NULL	NULL	491	val_491
+NULL	NULL	492	val_492
+NULL	NULL	492	val_492
 NULL	NULL	493	val_493
+NULL	NULL	494	val_494
 NULL	NULL	495	val_495
+NULL	NULL	496	val_496
 NULL	NULL	497	val_497
+NULL	NULL	498	val_498
+NULL	NULL	498	val_498
+NULL	NULL	498	val_498
 PREHOOK: query: insert overwrite table normal_join_results select * from smb_bucket4_1 a full outer join smb_bucket4_2 b on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_bucket4_2
@@ -1204,29 +1204,29 @@ POSTHOOK: Output: default@normal_join_results
 PREHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from normal_join_results
 PREHOOK: type: QUERY
 PREHOOK: Input: default@normal_join_results
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive_RCFile/build/ql/scratchdir/hive_2010-03-23_17-43-32_487_8597548153798727757/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_18-33-25_922_8963899750473921731/10000
 POSTHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from normal_join_results
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@normal_join_results
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive_RCFile/build/ql/scratchdir/hive_2010-03-23_17-43-32_487_8597548153798727757/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_18-33-25_922_8963899750473921731/10000
 0	130091	0	36210398070
 PREHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_join_results
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive_RCFile/build/ql/scratchdir/hive_2010-03-23_17-43-38_536_6150065360796623962/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_18-33-28_859_756911741105962638/10000
 POSTHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_join_results
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive_RCFile/build/ql/scratchdir/hive_2010-03-23_17-43-38_536_6150065360796623962/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_18-33-28_859_756911741105962638/10000
 0	130091	0	36210398070
 PREHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results_empty_bigtable
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_join_results_empty_bigtable
-PREHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive_RCFile/build/ql/scratchdir/hive_2010-03-23_17-43-42_746_6078097413289235679/10000
+PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_18-33-31_791_1136562844998184899/10000
 POSTHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results_empty_bigtable
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_join_results_empty_bigtable
-POSTHOOK: Output: file:/Users/heyongqiang/Documents/workspace/Hive_RCFile/build/ql/scratchdir/hive_2010-03-23_17-43-42_746_6078097413289235679/10000
+POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_18-33-31_791_1136562844998184899/10000
 0	130091	0	36210398070
 PREHOOK: query: drop table smb_join_results
 PREHOOK: type: DROPTABLE
