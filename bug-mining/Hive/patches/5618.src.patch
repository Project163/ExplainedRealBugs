diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/EvictingPriorityBlockingQueue.java b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/EvictingPriorityBlockingQueue.java
index 8fe59d48b5..75a65db107 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/EvictingPriorityBlockingQueue.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/EvictingPriorityBlockingQueue.java
@@ -22,6 +22,8 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import com.google.common.base.Function;
+
 /**
  * Bounded priority queue that evicts the last element based on priority order specified
  * through comparator. Elements that are added to the queue are sorted based on the specified
@@ -46,6 +48,18 @@ public EvictingPriorityBlockingQueue(Comparator<E> comparator, int maxSize) {
     this.comparator = comparator;
   }
 
+  public synchronized void apply(Function<E, Boolean> fn) {
+    for (E item : deque) {
+      boolean isOk = fn.apply(item);
+      if (!isOk) return;
+    }
+  }
+
+  public synchronized void forceOffer(E e) {
+    offerToDequeueInternal(e);
+    currentSize++;
+  }
+
   public synchronized E offer(E e, int additionalElementsAllowed) {
     if (currentSize < waitQueueSize + additionalElementsAllowed) {
       // Capacity exists.
@@ -91,21 +105,6 @@ public synchronized boolean remove(E e) {
     return removed;
   }
 
-  /**
-   * Re-insert an element if it exists (mainly to force a re-order)
-   * @param e
-   * @return false if the element was not found. true otherwise.
-   */
-  public synchronized boolean reinsertIfExists(E e) {
-    if (remove(e)) {
-      offerToDequeueInternal(e);
-      currentSize++;
-      return true;
-    } else {
-      return false;
-    }
-  }
-
   private void offerToDequeueInternal(E e) {
     boolean result = deque.offer(e);
     if (!result) {
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryFragmentInfo.java b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryFragmentInfo.java
index 195775e719..6f0630c3dc 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryFragmentInfo.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryFragmentInfo.java
@@ -37,6 +37,7 @@ public class QueryFragmentInfo {
   private final int attemptNumber;
   private final SignableVertexSpec vertexSpec;
   private final String fragmentIdString;
+  private boolean canFinishForPriority;
 
   public QueryFragmentInfo(QueryInfo queryInfo, String vertexName, int fragmentNumber,
       int attemptNumber, SignableVertexSpec vertexSpec, String fragmentIdString) {
@@ -49,6 +50,7 @@ public QueryFragmentInfo(QueryInfo queryInfo, String vertexName, int fragmentNum
     this.attemptNumber = attemptNumber;
     this.vertexSpec = vertexSpec;
     this.fragmentIdString = fragmentIdString;
+    this.canFinishForPriority = false; // Updated when we add this to the queue.
   }
 
   // Only meant for use by the QueryTracker
@@ -76,6 +78,21 @@ public String getFragmentIdentifierString() {
     return fragmentIdString;
   }
 
+  /**
+   * Unlike canFinish, this CANNOT be derived dynamically; a change without a reinsert will
+   * cause the queue order to become incorrect.
+   */
+  public boolean canFinishForPriority() {
+    return canFinishForPriority;
+  }
+
+  /**
+   * This MUST be called when the fragment is NOT in wait queue.
+   */
+  public void setCanFinishForPriority(boolean value) {
+    canFinishForPriority = value;
+  }
+
   /**
    * Check whether a task can run to completion or may end up blocking on it's sources.
    * This currently happens via looking up source state.
@@ -85,7 +102,12 @@ public String getFragmentIdentifierString() {
    *
    * @return true if the task can finish, false otherwise
    */
-  public boolean canFinish() {
+  public static boolean canFinish(QueryFragmentInfo fragment) {
+    return fragment.canFinish();
+  }
+
+  // Hide this so it doesn't look like a simple property.
+  private boolean canFinish() {
     List<IOSpecProto> inputSpecList = vertexSpec.getInputSpecsList();
     boolean canFinish = true;
     if (inputSpecList != null && !inputSpecList.isEmpty()) {
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryInfo.java b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryInfo.java
index 6c891c9a6e..d2e93963e0 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryInfo.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/QueryInfo.java
@@ -236,11 +236,12 @@ boolean registerForUpdates(FinishableStateUpdateHandler handler,
           sourceToEntity.put(source, entityInfo);
         }
 
-        if (lastFinishableState == fragmentInfo.canFinish()) {
+        boolean canFinish = QueryFragmentInfo.canFinish(fragmentInfo);
+        if (lastFinishableState == canFinish) {
           // State has not changed.
           return true;
         } else {
-          entityInfo.setLastFinishableState(fragmentInfo.canFinish());
+          entityInfo.setLastFinishableState(canFinish);
           return false;
         }
       } finally {
@@ -276,7 +277,7 @@ void sourceStateUpdated(String sourceName) {
       }
       if (interestedEntityInfos != null) {
         for (EntityInfo entityInfo : interestedEntityInfos) {
-          boolean newFinishState = entityInfo.getFragmentInfo().canFinish();
+          boolean newFinishState = QueryFragmentInfo.canFinish(entityInfo.getFragmentInfo());
           if (newFinishState != entityInfo.getLastFinishableState()) {
             // State changed. Callback
             entityInfo.setLastFinishableState(newFinishState);
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskExecutorService.java b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskExecutorService.java
index dd459b1b0b..047c504131 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskExecutorService.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskExecutorService.java
@@ -20,9 +20,12 @@
 import java.lang.reflect.Constructor;
 import java.lang.reflect.InvocationTargetException;
 import java.text.SimpleDateFormat;
+import java.util.ArrayList;
 import java.util.Comparator;
 import java.util.Date;
+import java.util.HashSet;
 import java.util.LinkedHashSet;
+import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.BlockingQueue;
@@ -55,6 +58,7 @@
 import org.slf4j.LoggerFactory;
 
 import com.google.common.annotations.VisibleForTesting;
+import com.google.common.base.Function;
 import com.google.common.util.concurrent.FutureCallback;
 import com.google.common.util.concurrent.Futures;
 import com.google.common.util.concurrent.ListenableFuture;
@@ -219,40 +223,31 @@ public Set<String> getExecutorsStatus() {
     Set<String> running = new LinkedHashSet<>();
     Set<String> waiting = new LinkedHashSet<>();
     StringBuilder value = new StringBuilder();
+
+    final List<TaskWrapper> queueState = new ArrayList<>();
+    // Note: we don't take the scheduling lock here, although the call to queue is still
+    //       synchronized. Best-effort to display the queue in order.
+    waitQueue.apply(new Function<TaskWrapper, Boolean>() {
+      public Boolean apply(TaskWrapper input) {
+        queueState.add(input);
+        return true;
+      }});
+
+    HashSet<TaskWrapper> queueHs = new HashSet<>();
+    for (TaskWrapper task : queueState) {
+      describeTask(value, task.getRequestId(), task, true);
+      waiting.add(value.toString());
+      queueHs.add(task);
+    }
+
     for (Map.Entry<String, TaskWrapper> e : knownTasks.entrySet()) {
-      boolean isWaiting;
-      value.setLength(0);
-      value.append(e.getKey());
+      String attemptId = e.getKey();
       TaskWrapper task = e.getValue();
-      boolean isFirst = true;
-      TaskRunnerCallable c = task.getTaskRunnerCallable();
-      if (c != null && c.getVertexSpec() != null) {
-        SignableVertexSpec fs = c.getVertexSpec();
-        value.append(isFirst ? " (" : ", ").append(c.getQueryId())
-          .append("/").append(fs.getVertexName());
-        isFirst = false;
-      }
-      value.append(isFirst ? " (" : ", ");
-      if (task.isInWaitQueue()) {
-        isWaiting = true;
-        value.append("in queue");
-      } else if (c != null) {
-        long startTime = c.getStartTime();
-        if (startTime != 0) {
-          isWaiting = false;
-          value.append("started at ").append(sdf.get().format(new Date(startTime)));
-        } else {
-          isWaiting = false;
-          value.append("not started");
-        }
-      } else {
-        isWaiting = true;
-        value.append("has no callable");
+      if (queueHs.contains(task)) {
+        // Even if the state has changed, don't log it twice.
+        continue;
       }
-      if (task.isInPreemptionQueue()) {
-        value.append(", ").append("preemptable");
-      }
-      value.append(")");
+      boolean isWaiting = describeTask(value, attemptId, task, false);
       if (isWaiting) {
         waiting.add(value.toString());
       } else {
@@ -264,27 +259,78 @@ public Set<String> getExecutorsStatus() {
     return result;
   }
 
+  private boolean describeTask(
+      StringBuilder value, String attemptId, TaskWrapper task, boolean fromQueue) {
+    value.setLength(0);
+    boolean isFirst = true;
+    TaskRunnerCallable c = task.getTaskRunnerCallable();
+    value.append(attemptId);
+    if (c != null && c.getVertexSpec() != null) {
+      SignableVertexSpec fs = c.getVertexSpec();
+      value.append(isFirst ? " (" : ", ").append(c.getQueryId())
+        .append("/").append(fs.getVertexName());
+      isFirst = false;
+    }
+    value.append(isFirst ? " (" : ", ");
+    if (fromQueue) {
+      value.append("in queue (in order)");
+    }
+    boolean isWaiting;
+    if (task.isInWaitQueue()) {
+      isWaiting = true;
+      if (!fromQueue) {
+        value.append("in queue (not in order)");
+      }
+    } else if (c != null) {
+      long startTime = c.getStartTime();
+      isWaiting = false;
+      if (startTime != 0) {
+        value.append("started at ").append(sdf.get().format(new Date(startTime)));
+      } else {
+        value.append("not started");
+      }
+    } else {
+      isWaiting = true;
+      value.append("has no callable");
+    }
+    if (task.isInPreemptionQueue()) {
+      value.append(", ").append("in preemption queue");
+    }
+    boolean canFinish = c.canFinish();
+    value.append(", ").append(canFinish ? "can" : "cannot").append(" finish");
+    if (canFinish != c.canFinishForPriority()) {
+      value.append(" (not updated in queue)");
+    }
+    value.append(")");
+    return isWaiting;
+  }
+
   /**
    * Worker that takes tasks from wait queue and schedule it for execution.
    */
   private final class WaitQueueWorker implements Runnable {
+    private static final long SANITY_CHECK_TIMEOUT_MS = 1000;
     private TaskWrapper task;
+    private Long nextSanityCheck = null;
 
     @Override
     public void run() {
       try {
         Long lastKillTimeMs = null;
+        SanityChecker sc = null;
         while (!isShutdown.get()) {
           RejectedExecutionException rejectedException = null;
+          if (nextSanityCheck != null && ((nextSanityCheck - System.nanoTime()) <= 0)) {
+            sc = sanityCheckQueue(sc);
+            nextSanityCheck = null;
+          }
           synchronized (lock) {
             // Since schedule() can be called from multiple threads, we peek the wait queue, try
             // scheduling the task and then remove the task if scheduling is successful. This
             // will make sure the task's place in the wait queue is held until it gets scheduled.
             task = waitQueue.peek();
             if (task == null) {
-              if (!isShutdown.get()) {
-                lock.wait();
-              }
+              waitOnLock();
               continue;
             }
             // If the task cannot finish and if no slots are available then don't schedule it.
@@ -301,13 +347,12 @@ public void run() {
               shouldWait = shouldWait && (enablePreemption == false || preemptionQueue.isEmpty());
             }
             if (shouldWait) {
-              if (!isShutdown.get()) {
-                lock.wait();
-              }
+              waitOnLock();
               // Another task at a higher priority may have come in during the wait. Lookup the
               // queue again to pick up the task at the highest priority.
               continue;
             }
+            nextSanityCheck = null; // We are going to do something useful now.
             try {
               tryScheduleUnderLock(task);
               // Wait queue could have been re-ordered in the mean time because of concurrent task
@@ -352,6 +397,12 @@ public void run() {
         }
       }
     }
+
+    private void waitOnLock() throws InterruptedException {
+      if (isShutdown.get()) return;
+      nextSanityCheck = System.nanoTime() + SANITY_CHECK_TIMEOUT_MS * 1000000L;
+      lock.wait(SANITY_CHECK_TIMEOUT_MS);
+    }
   }
 
   private class WaitQueueWorkerCallback implements FutureCallback {
@@ -395,6 +446,7 @@ public SubmissionState schedule(TaskRunnerCallable task) {
       }
 
       canFinish = taskWrapper.getTaskRunnerCallable().canFinish();
+      taskWrapper.updateCanFinishForPriority(canFinish); // Update the property before offering.
       evictedTask = waitQueue.offer(taskWrapper, maxParallelExecutors - runningFragmentCount.get());
       // Finishable state is checked on the task, via an explicit query to the TaskRunnerCallable
 
@@ -623,16 +675,71 @@ private boolean handleScheduleAttemptedRejection(TaskWrapper taskWrapper) {
     return false;
   }
 
+  private static class SanityChecker implements Function<TaskWrapper, Boolean> {
+    private TaskWrapper firstCannotFinish = null;
+    private TaskWrapper firstProblematic = null;
+    private final EvictingPriorityBlockingQueue<TaskWrapper> queue;
+
+    public SanityChecker(EvictingPriorityBlockingQueue<TaskWrapper> queue) {
+      this.queue = queue;
+    }
+
+    @Override
+    public Boolean apply(TaskWrapper input) {
+      if (input == null) return true;
+      boolean canFinish = input.getTaskRunnerCallable().canFinishForPriority();
+      if (firstCannotFinish == null && !canFinish) {
+        firstCannotFinish = input;
+        return true;
+      }
+      if (firstCannotFinish != null && canFinish) {
+        firstProblematic = input;
+        return false;
+      }
+      return true;
+    }
+
+    void run() {
+      queue.apply(this);
+      if (firstProblematic != null) {
+        final StringBuilder sb = new StringBuilder(
+            "Found finishable task behind non-finishable in the queue: ");
+        sb.append(firstProblematic).append(" was after ").append(firstCannotFinish).append("; ");
+        queue.apply(new Function<TaskExecutorService.TaskWrapper, Boolean>() {
+          @Override
+          public Boolean apply(TaskWrapper input) {
+            sb.append(input).append(", ");
+            return true;
+          }
+        });
+        LOG.error(sb.toString());
+      }
+      firstCannotFinish = firstProblematic = null;
+    }
+  }
+
+  private SanityChecker sanityCheckQueue(SanityChecker sc) {
+    if (sc == null) {
+      sc = new SanityChecker(waitQueue);
+    }
+    sc.run();
+    return sc;
+  }
+
   private void finishableStateUpdated(TaskWrapper taskWrapper, boolean newFinishableState) {
     synchronized (lock) {
       if (taskWrapper.isInWaitQueue()) {
-        // Re-order the wait queue
+        // Re-order the wait queue. Note: we assume that noone will take our capacity based
+        // on the fact that we are doing this under the epic lock. If the epic lock is removed,
+        // we'd need to do the steps under the queue lock; we could pass in a f() to update state.
         LOG.debug("Re-ordering the wait queue since {} finishable state moved to {}",
             taskWrapper.getRequestId(), newFinishableState);
-        boolean reInserted = waitQueue.reinsertIfExists(taskWrapper);
-        if (!reInserted) {
-          LOG.warn("Failed to remove {} from waitQueue",
-              taskWrapper.getTaskRunnerCallable().getRequestId());
+        boolean isRemoved = waitQueue.remove(taskWrapper);
+        taskWrapper.updateCanFinishForPriority(newFinishableState);
+        if (!isRemoved) {
+          LOG.warn("Failed to remove {} from waitQueue", taskWrapper.getTaskRunnerCallable());
+        } else {
+          waitQueue.forceOffer(taskWrapper);
         }
       }
 
@@ -893,8 +1000,13 @@ public TaskWrapper(TaskRunnerCallable taskRunnerCallable, TaskExecutorService ta
       this.taskExecutorService = taskExecutorService;
     }
 
+    public void updateCanFinishForPriority(boolean newFinishableState) {
+      taskRunnerCallable.updateCanFinishForPriority(newFinishableState);
+    }
+
     // Don't invoke from within a scheduler lock
 
+
     /**
      *
      * @param currentFinishableState
@@ -950,6 +1062,7 @@ public String toString() {
           ", inPreemptionQueue=" + inPreemptionQueue.get() +
           ", registeredForNotifications=" + registeredForNotifications.get() +
           ", canFinish=" + taskRunnerCallable.canFinish() +
+          ", canFinish(in queue)=" + taskRunnerCallable.canFinishForPriority() +
           ", firstAttemptStartTime=" + taskRunnerCallable.getFragmentRuntimeInfo().getFirstAttemptStartTime() +
           ", dagStartTime=" + taskRunnerCallable.getFragmentRuntimeInfo().getDagStartTime() +
           ", withinDagPriority=" + taskRunnerCallable.getFragmentRuntimeInfo().getWithinDagPriority() +
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskRunnerCallable.java b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskRunnerCallable.java
index ceca1ad5ad..5159e2dcbd 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskRunnerCallable.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskRunnerCallable.java
@@ -395,7 +395,15 @@ public void reportTaskKilled() {
   }
 
   public boolean canFinish() {
-    return fragmentInfo.canFinish();
+    return QueryFragmentInfo.canFinish(fragmentInfo);
+  }
+
+  public boolean canFinishForPriority() {
+    return fragmentInfo.canFinishForPriority();
+  }
+
+  public void updateCanFinishForPriority(boolean value) {
+    fragmentInfo.setCanFinishForPriority(value);
   }
 
   private static Multimap<String, String> createStartedInputMap(SignableVertexSpec vertex) {
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/comparator/FirstInFirstOutComparator.java b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/comparator/FirstInFirstOutComparator.java
index ae1ca5db50..8beb47ce6d 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/comparator/FirstInFirstOutComparator.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/comparator/FirstInFirstOutComparator.java
@@ -32,8 +32,8 @@ public class FirstInFirstOutComparator implements Comparator<TaskWrapper> {
   public int compare(TaskWrapper t1, TaskWrapper t2) {
     TaskRunnerCallable o1 = t1.getTaskRunnerCallable();
     TaskRunnerCallable o2 = t2.getTaskRunnerCallable();
-    boolean o1CanFinish = o1.canFinish();
-    boolean o2CanFinish = o2.canFinish();
+    boolean o1CanFinish = o1.canFinishForPriority();
+    boolean o2CanFinish = o2.canFinishForPriority();
     if (o1CanFinish == true && o2CanFinish == false) {
       return -1;
     } else if (o1CanFinish == false && o2CanFinish == true) {
diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/comparator/ShortestJobFirstComparator.java b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/comparator/ShortestJobFirstComparator.java
index b54f74021b..e09b7e8797 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/comparator/ShortestJobFirstComparator.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/comparator/ShortestJobFirstComparator.java
@@ -28,8 +28,8 @@ public class ShortestJobFirstComparator implements Comparator<TaskWrapper> {
   public int compare(TaskWrapper t1, TaskWrapper t2) {
     TaskRunnerCallable o1 = t1.getTaskRunnerCallable();
     TaskRunnerCallable o2 = t2.getTaskRunnerCallable();
-    boolean o1CanFinish = o1.canFinish();
-    boolean o2CanFinish = o2.canFinish();
+    boolean o1CanFinish = o1.canFinishForPriority();
+    boolean o2CanFinish = o2.canFinishForPriority();
     if (o1CanFinish == true && o2CanFinish == false) {
       return -1;
     } else if (o1CanFinish == false && o2CanFinish == true) {
diff --git a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TaskExecutorTestHelpers.java b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TaskExecutorTestHelpers.java
index e3edf79d29..1fa76102a3 100644
--- a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TaskExecutorTestHelpers.java
+++ b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TaskExecutorTestHelpers.java
@@ -56,7 +56,7 @@ public static MockRequest createMockRequest(int fragmentNum, int parallelism, lo
     long currentAttemptStartTime, boolean canFinish, long workTime) {
     SubmitWorkRequestProto
         request = createSubmitWorkRequestProto(fragmentNum, parallelism, firstAttemptStartTime, currentAttemptStartTime);
-    return createMockRequest(canFinish, workTime, request);
+    return createMockRequest(canFinish, canFinish, workTime, request);
   }
 
   public static MockRequest createMockRequest(int fragmentNum, int parallelism,
@@ -68,20 +68,25 @@ public static MockRequest createMockRequest(int fragmentNum, int parallelism,
     SubmitWorkRequestProto
         request = createSubmitWorkRequestProto(fragmentNum, parallelism, 0,
         firstAttemptStartTime, currentAttemptStartTime, withinDagPriority);
-    return createMockRequest(canFinish, workTime, request);
+    return createMockRequest(canFinish, canFinish, workTime, request);
   }
 
-  private static MockRequest createMockRequest(boolean canFinish,
+  private static MockRequest createMockRequest(boolean canFinish, boolean canFinishQueue,
       long workTime, SubmitWorkRequestProto request) {
     QueryFragmentInfo queryFragmentInfo = createQueryFragmentInfo(
         request.getWorkSpec().getVertex(), request.getFragmentNumber());
-    return new MockRequest(request, queryFragmentInfo, canFinish, workTime, null);
+    return new MockRequest(request, queryFragmentInfo, canFinish, canFinishQueue, workTime, null);
   }
 
   public static TaskExecutorService.TaskWrapper createTaskWrapper(
-      SubmitWorkRequestProto request, boolean canFinish, int workTime) {
+      SubmitWorkRequestProto request, boolean canFinish, boolean canFinishQueue, int workTime) {
     return new TaskExecutorService.TaskWrapper(
-        createMockRequest(canFinish, workTime, request), null);
+        createMockRequest(canFinish, canFinishQueue, workTime, request), null);
+  }
+  
+  public static TaskExecutorService.TaskWrapper createTaskWrapper(
+      SubmitWorkRequestProto request, boolean canFinish, int workTime) {
+    return createTaskWrapper(request, canFinish, canFinish, workTime);
   }
 
   public static QueryFragmentInfo createQueryFragmentInfo(
@@ -169,7 +174,7 @@ public static SubmitWorkRequestProto createSubmitWorkRequestProto(
 
   public static class MockRequest extends TaskRunnerCallable {
     private final long workTime;
-    private final boolean canFinish;
+    private final boolean canFinish, canFinishQueue;
 
     private final AtomicBoolean isStarted = new AtomicBoolean(false);
     private final AtomicBoolean isFinished = new AtomicBoolean(false);
@@ -185,7 +190,8 @@ public static class MockRequest extends TaskRunnerCallable {
     private boolean isOkToFinish = true;
 
     public MockRequest(SubmitWorkRequestProto requestProto, QueryFragmentInfo fragmentInfo,
-                       boolean canFinish, long workTime, TezEvent initialEvent) {
+                       boolean canFinish, boolean canFinishQueue, long workTime,
+                       TezEvent initialEvent) {
       super(requestProto, fragmentInfo, new Configuration(),
           new ExecutionContextImpl("localhost"), null, new Credentials(), 0, mock(AMReporter.class), null, mock(
               LlapDaemonExecutorMetrics.class),
@@ -195,6 +201,7 @@ public MockRequest(SubmitWorkRequestProto requestProto, QueryFragmentInfo fragme
               SchedulerFragmentCompletingListener.class), mock(SocketFactory.class));
       this.workTime = workTime;
       this.canFinish = canFinish;
+      this.canFinishQueue = canFinishQueue;
     }
 
     @Override
@@ -327,6 +334,11 @@ public boolean canFinish() {
       return canFinish;
     }
 
+    @Override
+    public boolean canFinishForPriority() {
+      return canFinishQueue;
+    }
+
     public void setSleepAfterKill() {
       isOkToFinish = false;
     }
diff --git a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TestEvictingPriorityBlockingQueue.java b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TestEvictingPriorityBlockingQueue.java
index 62407b54cb..900b66c615 100644
--- a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TestEvictingPriorityBlockingQueue.java
+++ b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TestEvictingPriorityBlockingQueue.java
@@ -69,10 +69,10 @@ public void test() throws InterruptedException {
     assertEquals(elements[0], e); // Rejected
     //1,2,3,4
 
-    assertTrue(queue.reinsertIfExists(elements[2]));
+    assertTrue(reinsertIfExists(queue, elements[2]));
     assertEquals(4, queue.size());
 
-    assertFalse(queue.reinsertIfExists(elements[5]));
+    assertFalse(reinsertIfExists(queue, elements[5]));
     assertEquals(4, queue.size());
 
     //1,2,3,4
@@ -117,6 +117,14 @@ public int hashCode() {
     }
   }
 
+  public static <T> boolean reinsertIfExists(EvictingPriorityBlockingQueue<T> queue, T e) {
+    if (queue.remove(e)) {
+      queue.forceOffer(e);
+      return true;
+    }
+    return false;
+  }
+
   private static class ElementComparator implements Comparator<Element> {
 
     @Override
diff --git a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestFirstInFirstOutComparator.java b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestFirstInFirstOutComparator.java
index 62b90d64b7..8b72a51b62 100644
--- a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestFirstInFirstOutComparator.java
+++ b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestFirstInFirstOutComparator.java
@@ -17,6 +17,7 @@
  */
 package org.apache.hadoop.hive.llap.daemon.impl.comparator;
 
+import static org.apache.hadoop.hive.llap.daemon.impl.TaskExecutorTestHelpers.createSubmitWorkRequestProto;
 import static org.apache.hadoop.hive.llap.daemon.impl.TaskExecutorTestHelpers.createTaskWrapper;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNull;
@@ -31,8 +32,6 @@
 import org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.VertexOrBinary;
 import org.apache.hadoop.yarn.api.records.ApplicationId;
 import org.apache.tez.dag.records.TezDAGID;
-import org.apache.tez.dag.records.TezTaskAttemptID;
-import org.apache.tez.dag.records.TezTaskID;
 import org.apache.tez.dag.records.TezVertexID;
 import org.junit.Test;
 
@@ -59,8 +58,6 @@ private SubmitWorkRequestProto createRequest(int fragmentNumber, int numSelfAndU
     ApplicationId appId = ApplicationId.newInstance(9999, 72);
     TezDAGID dagId = TezDAGID.getInstance(appId, 1);
     TezVertexID vId = TezVertexID.getInstance(dagId, 35);
-    TezTaskID tId = TezTaskID.getInstance(vId, 389);
-    TezTaskAttemptID taId = TezTaskAttemptID.getInstance(tId, fragmentNumber);
     return SubmitWorkRequestProto
         .newBuilder()
         .setAttemptNumber(0)
@@ -128,7 +125,7 @@ public void testWaitQueueComparator() throws InterruptedException {
     r3 = createTaskWrapper(createRequest(3, 6, 3, 300), true, 1000000);
     r4 = createTaskWrapper(createRequest(4, 8, 2, 400), true, 1000000);
     r5 = createTaskWrapper(createRequest(5, 10, 1, 500), true, 1000000);
-    queue = new EvictingPriorityBlockingQueue(
+    queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
         new FirstInFirstOutComparator(), 4);
     assertNull(queue.offer(r1, 0));
     assertEquals(r1, queue.peek());
@@ -150,7 +147,7 @@ public void testWaitQueueComparator() throws InterruptedException {
     r3 = createTaskWrapper(createRequest(3, 1, 3, 300), true, 1000000);
     r4 = createTaskWrapper(createRequest(4, 1, 2, 400), false, 1000000);
     r5 = createTaskWrapper(createRequest(5, 10, 1, 500), true, 1000000);
-    queue = new EvictingPriorityBlockingQueue(
+    queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
         new FirstInFirstOutComparator(), 4);
     assertNull(queue.offer(r1, 0));
     assertEquals(r1, queue.peek());
@@ -172,7 +169,7 @@ public void testWaitQueueComparator() throws InterruptedException {
     r3 = createTaskWrapper(createRequest(3, 6, 3, 300), true, 1000000);
     r4 = createTaskWrapper(createRequest(4, 8, 2, 400), false, 1000000);
     r5 = createTaskWrapper(createRequest(5, 10, 1, 500), true, 1000000);
-    queue = new EvictingPriorityBlockingQueue(
+    queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
         new FirstInFirstOutComparator(), 4);
     assertNull(queue.offer(r1, 0));
     assertEquals(r1, queue.peek());
@@ -194,7 +191,7 @@ public void testWaitQueueComparator() throws InterruptedException {
     r3 = createTaskWrapper(createRequest(3, 6, 3, 300), false, 1000000);
     r4 = createTaskWrapper(createRequest(4, 8, 2, 400), false, 1000000);
     r5 = createTaskWrapper(createRequest(5, 10, 1, 500), true, 1000000);
-    queue = new EvictingPriorityBlockingQueue(
+    queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
         new FirstInFirstOutComparator(), 4);
     assertNull(queue.offer(r1, 0));
     assertEquals(r1, queue.peek());
@@ -216,7 +213,7 @@ public void testWaitQueueComparator() throws InterruptedException {
     r3 = createTaskWrapper(createRequest(3, 6, 3, 300), true, 1000000);
     r4 = createTaskWrapper(createRequest(4, 8, 2, 400), true, 1000000);
     r5 = createTaskWrapper(createRequest(5, 10, 1, 500), true, 1000000);
-    queue = new EvictingPriorityBlockingQueue(
+    queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
         new FirstInFirstOutComparator(), 4);
     assertNull(queue.offer(r1, 0));
     assertEquals(r1, queue.peek());
@@ -238,7 +235,7 @@ public void testWaitQueueComparator() throws InterruptedException {
     r3 = createTaskWrapper(createRequest(3, 6, 3, 300), true, 1000000);
     r4 = createTaskWrapper(createRequest(4, 8, 2, 400), true, 1000000);
     r5 = createTaskWrapper(createRequest(5, 10, 2, 500), true, 1000000);
-    queue = new EvictingPriorityBlockingQueue(
+    queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
         new FirstInFirstOutComparator(), 4);
     assertNull(queue.offer(r1, 0));
     assertEquals(r1, queue.peek());
@@ -256,6 +253,25 @@ public void testWaitQueueComparator() throws InterruptedException {
     assertEquals(r2, queue.take());
   }
 
+  @Test(timeout = 60000)
+  public void testWaitQueueComparatorCanFinish() throws InterruptedException {
+    // Test that only the fixed property (...ForQueue) is used in order determination, not the dynamic call.
+    TaskWrapper r1 = createTaskWrapper(createSubmitWorkRequestProto(1, 1, 0, 10, 100, 2), true, false, 100000);
+    TaskWrapper r2 = createTaskWrapper(createSubmitWorkRequestProto(2, 1, 0, 10, 100, 1), false, true, 100000);
+    TaskWrapper r3 = createTaskWrapper(createSubmitWorkRequestProto(3, 1, 0, 10, 100, 5), true, true, 100000);
+
+    EvictingPriorityBlockingQueue<TaskWrapper> queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
+        new FirstInFirstOutComparator(), 4);
+
+    assertNull(queue.offer(r1, 0));
+    assertNull(queue.offer(r2, 0));
+    assertNull(queue.offer(r3, 0));
+
+    assertEquals(r2, queue.take());
+    assertEquals(r3, queue.take());
+    assertEquals(r1, queue.take());
+  }
+  
   @Test(timeout = 60000)
   public void testWaitQueueComparatorWithinDagPriority() throws InterruptedException {
     TaskWrapper r1 = createTaskWrapper(createRequest(1, 1, 0, 100, 100, 10), false, 100000);
diff --git a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestShortestJobFirstComparator.java b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestShortestJobFirstComparator.java
index b348bd6a82..a210499a2e 100644
--- a/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestShortestJobFirstComparator.java
+++ b/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestShortestJobFirstComparator.java
@@ -55,7 +55,7 @@ public void testWaitQueueComparator() throws InterruptedException {
     r3 = createTaskWrapper(createSubmitWorkRequestProto(3, 6, 300, 400, "q3"), true, 1000000);
     r4 = createTaskWrapper(createSubmitWorkRequestProto(4, 8, 400, 500, "q4"), true, 1000000);
     r5 = createTaskWrapper(createSubmitWorkRequestProto(5, 10, 500, 600, "q5"), true, 1000000);
-    queue = new EvictingPriorityBlockingQueue(
+    queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
         new ShortestJobFirstComparator(), 4);
     assertNull(queue.offer(r1, 0));
     assertEquals(r1, queue.peek());
@@ -77,7 +77,7 @@ public void testWaitQueueComparator() throws InterruptedException {
     r3 = createTaskWrapper(createSubmitWorkRequestProto(3, 1, 300, 800, "q3"), true, 1000000);
     r4 = createTaskWrapper(createSubmitWorkRequestProto(4, 1, 400, 700, "q4"), false, 1000000);
     r5 = createTaskWrapper(createSubmitWorkRequestProto(5, 10, 500, 600, "q5"), true, 1000000);
-    queue = new EvictingPriorityBlockingQueue(
+    queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
         new ShortestJobFirstComparator(), 4);
     assertNull(queue.offer(r1, 0));
     assertEquals(r1, queue.peek());
@@ -99,7 +99,7 @@ public void testWaitQueueComparator() throws InterruptedException {
     r3 = createTaskWrapper(createSubmitWorkRequestProto(3, 6, 300, 400, "q3"), true, 1000000);
     r4 = createTaskWrapper(createSubmitWorkRequestProto(4, 8, 400, 500, "q4"), false, 1000000);
     r5 = createTaskWrapper(createSubmitWorkRequestProto(5, 10, 500, 600, "q5"), true, 1000000);
-    queue = new EvictingPriorityBlockingQueue(
+    queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
         new ShortestJobFirstComparator(), 4);
     assertNull(queue.offer(r1, 0));
     assertEquals(r1, queue.peek());
@@ -121,7 +121,7 @@ public void testWaitQueueComparator() throws InterruptedException {
     r3 = createTaskWrapper(createSubmitWorkRequestProto(3, 6, 300, 400, "q3"), false, 1000000);
     r4 = createTaskWrapper(createSubmitWorkRequestProto(4, 8, 400, 500, "q4"), false, 1000000);
     r5 = createTaskWrapper(createSubmitWorkRequestProto(5, 10, 500, 600, "q5"), true, 1000000);
-    queue = new EvictingPriorityBlockingQueue(
+    queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
         new ShortestJobFirstComparator(), 4);
     assertNull(queue.offer(r1, 0));
     assertEquals(r1, queue.peek());
@@ -143,7 +143,7 @@ public void testWaitQueueComparator() throws InterruptedException {
     r3 = createTaskWrapper(createSubmitWorkRequestProto(3, 6, 300, 400, "q3"), true, 1000000);
     r4 = createTaskWrapper(createSubmitWorkRequestProto(4, 8, 400, 500, "q4"), true, 1000000);
     r5 = createTaskWrapper(createSubmitWorkRequestProto(5, 10, 500, 600, "q5"), true, 1000000);
-    queue = new EvictingPriorityBlockingQueue(
+    queue = new EvictingPriorityBlockingQueue<TaskWrapper>(
         new ShortestJobFirstComparator(), 4);
     assertNull(queue.offer(r1, 0));
     assertEquals(r1, queue.peek());
@@ -179,6 +179,25 @@ public void testWaitQueueComparatorWithinDagPriority() throws InterruptedExcepti
     assertEquals(r1, queue.take());
   }
 
+  @Test(timeout = 60000)
+  public void testWaitQueueComparatorCanFinish() throws InterruptedException {
+    // Test that only the fixed property (...ForQueue) is used in order determination, not the dynamic call.
+    TaskWrapper r1 = createTaskWrapper(createSubmitWorkRequestProto(1, 1, 0, 10, 100, 2), true, false, 100000);
+    TaskWrapper r2 = createTaskWrapper(createSubmitWorkRequestProto(2, 1, 0, 10, 100, 1), false, true, 100000);
+    TaskWrapper r3 = createTaskWrapper(createSubmitWorkRequestProto(3, 1, 0, 10, 100, 5), true, true, 100000);
+
+    EvictingPriorityBlockingQueue<TaskWrapper> queue = new EvictingPriorityBlockingQueue<>(
+        new ShortestJobFirstComparator(), 4);
+
+    assertNull(queue.offer(r1, 0));
+    assertNull(queue.offer(r2, 0));
+    assertNull(queue.offer(r3, 0));
+
+    assertEquals(r2, queue.take());
+    assertEquals(r3, queue.take());
+    assertEquals(r1, queue.take());
+  }
+
   @Test(timeout = 60000)
   public void testWaitQueueComparatorWithinSameDagPriority() throws InterruptedException {
     TaskWrapper r1 = createTaskWrapper(createSubmitWorkRequestProto(1, 1, 0, 10, 100, 10), true, 100000);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LlapDecider.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LlapDecider.java
index 38e4b94afe..ae05bd52fe 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LlapDecider.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LlapDecider.java
@@ -129,7 +129,7 @@ public LlapDecisionDispatcher(PhysicalContext pctx, LlapMode mode) {
       shouldUber = HiveConf.getBoolVar(conf, ConfVars.LLAP_AUTO_ALLOW_UBER) && (mode != all);
       minReducersPerExec = HiveConf.getFloatVar(
           conf, ConfVars.TEZ_LLAP_MIN_REDUCER_PER_EXECUTOR);
-      executorsPerNode = HiveConf.getIntVar(conf, ConfVars.LLAP_DAEMON_NUM_EXECUTORS); // TODO# hmm
+      executorsPerNode = HiveConf.getIntVar(conf, ConfVars.LLAP_DAEMON_NUM_EXECUTORS);
       mapJoinOpList = new ArrayList<MapJoinOperator>();
       rules = getRules();
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezUtils.java
index a9c1e61ba9..ca544b4549 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezUtils.java
@@ -105,7 +105,6 @@ public static ReduceWork createReduceWork(
       final int maxReducers = context.conf.getIntVar(HiveConf.ConfVars.MAXREDUCERS);
       // estimated number of reducers
       final int nReducers = reduceSink.getConf().getNumReducers();
-      // TODO# HERE
 
       // min we allow tez to pick
       int minPartition = Math.max(1, (int) (nReducers * minPartitionFactor));
