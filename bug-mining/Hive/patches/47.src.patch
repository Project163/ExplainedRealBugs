diff --git a/CHANGES.txt b/CHANGES.txt
index 8383da79f6..e2b4e66ea4 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -185,3 +185,6 @@ Trunk (unreleased changes)
 
     HIVE-84.  Make MetaStore Client thread safe.  (Prasad Chakka via dhruba)
 
+    HIVE-203. Fix eclipse templates to get junit tests to run.
+    (Ashish Thusoo via dhruba)
+
diff --git a/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java b/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java
index 008e3d7611..882ec2a065 100644
--- a/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java
+++ b/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java
@@ -58,6 +58,8 @@ public boolean accept(File fpath) {
  
   protected String resultsDirectory;
 
+  protected String logDirectory;
+
   protected String template;
 
   protected String className;
@@ -121,6 +123,14 @@ public String getOutputDirectory() {
     return outputDirectory;
   }
 
+  public void setLogDirectory(String logDirectory) {
+    this.logDirectory = logDirectory;
+  }
+
+  public String getLogDirectory() {
+    return this.logDirectory;
+  }
+
   public void setResultsDirectory(String resultsDirectory) {
     this.resultsDirectory = resultsDirectory;
   }
@@ -167,6 +177,10 @@ public void execute() throws BuildException {
       throw new BuildException("No queryDirectory or queryFile specified");
     }
 
+    if (logDirectory == null) {
+      throw new BuildException("No logDirectory specified");
+    }
+
     if (resultsDirectory == null) {
       throw new BuildException("No resultsDirectory specified");
     }
@@ -178,6 +192,7 @@ public void execute() throws BuildException {
     File [] qFiles = null;
     File outDir = null;
     File resultsDir = null;
+    File logDir = null;
     
     try {
       File inpDir = null;
@@ -199,6 +214,11 @@ public void execute() throws BuildException {
       if (!outDir.exists()) {
         outDir.mkdirs();
       }
+
+      logDir = new File(logDirectory);
+      if (!logDir.exists()) {
+        throw new BuildException("Log Directory " + logDir.getCanonicalPath() + " does not exist");
+      }
       
       resultsDir = new File(resultsDirectory);
       if (!resultsDir.exists()) {
@@ -232,6 +252,7 @@ public void execute() throws BuildException {
       ctx.put("className", className);
       ctx.put("qfiles", qFiles);
       ctx.put("resultsDir", resultsDir);
+      ctx.put("logDir", logDir);
 
       File outFile = new File(outDir, className + ".java");
       FileWriter writer = new FileWriter(outFile);
diff --git a/build-common.xml b/build-common.xml
index f1f155d96f..48fb9e2ca4 100644
--- a/build-common.xml
+++ b/build-common.xml
@@ -132,6 +132,10 @@
 
   <target name="test-init">
     <mkdir dir="${test.data.dir}"/>
+    <mkdir dir="${test.log.dir}/clientpositive"/>
+    <mkdir dir="${test.log.dir}/clientnegative"/>
+    <mkdir dir="${test.log.dir}/positive"/>
+    <mkdir dir="${test.log.dir}/negative"/>
     <copy todir="${test.data.dir}">
       <fileset dir="${test.src.data.dir}">
         <exclude name="**/.svn"/>
@@ -230,8 +234,6 @@
   <!-- target to run the tests -->
   <target name="test"
   	depends="test-conditions,gen-test,compile-test,test-jar,test-init">
-    <delete dir="${test.log.dir}"/>
-    <mkdir dir="${test.log.dir}"/>
     <junit showoutput="${test.output}" printsummary="yes" haltonfailure="no"
            fork="yes" maxmemory="256m" dir="${basedir}" timeout="${test.timeout}"
            errorProperty="tests.failed" failureProperty="tests.failed" filtertrace="off">
diff --git a/build.xml b/build.xml
index 2355c38c52..ebdd94426d 100644
--- a/build.xml
+++ b/build.xml
@@ -184,6 +184,14 @@
 
   <target name="eclipse-files" depends="init"
           description="Generate files for Eclipse">
+
+    <condition property="hadoop.version" value="0.19">
+      <not>
+        <isset property="hadoop.version"/>
+      </not>
+    </condition>
+    <echo message="Using hadoop version ${hadoop.version}"/>
+
     <pathconvert property="eclipse.project">
       <path path="${basedir}"/>
       <regexpmapper from="^.*/([^/]+)$$" to="\1" handledirsep="yes"/>
@@ -195,8 +203,16 @@
       </fileset>
       <filterset>
         <filter token="PROJECT" value="${eclipse.project}"/>
+        <filter token="HADOOPVER" value="${hadoop.version}"/>
       </filterset>
     </copy>
+    <move todir="." includeemptydirs="false">
+      <fileset dir=".">
+        <include name="*.launchtemplate"/>
+      </fileset>
+      <mapper type="glob" from="*.launchtemplate" to="*.launch"/>
+    </move>
+
   </target>
 
   <target name="clean-eclipse-files"
diff --git a/eclipse-templates/.classpath b/eclipse-templates/.classpath
index 119db13dd4..dca9ae772f 100644
--- a/eclipse-templates/.classpath
+++ b/eclipse-templates/.classpath
@@ -1,42 +1,42 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <classpath>
+	<classpathentry exported="true" kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER"/>
+	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-@HADOOPVER@/hadoop-@HADOOPVER@-core.jar"/>
+	<classpathentry exported="true" kind="lib" path="cli/lib/jline-0.9.94.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/asm-3.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-cli-2.0-SNAPSHOT.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-lang-2.4.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-logging-1.0.4.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-logging-api-1.0.4.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/derby.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/jdo2-api-2.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/jpox-core-1.2.2.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/jpox-enhancer-1.2.2.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/jpox-rdbms-1.2.2.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/libfb303.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/libthrift.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/log4j-1.2.15.jar"/>
+	<classpathentry exported="true" kind="lib" path="ql/lib/antlr-3.0.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="ql/lib/antlr-runtime-3.0.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="ql/lib/commons-jexl-1.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="testlibs/junit-3.8.1.jar"/>
+	<classpathentry kind="src" path="build/ql/gen-java"/>
+	<classpathentry kind="src" path="build/ql/test/src"/>
+	<classpathentry kind="src" path="cli/src/java"/>
+	<classpathentry kind="src" path="common/src/java"/>
+	<classpathentry kind="src" path="metastore/src/gen-javabean"/>
 	<classpathentry kind="src" path="metastore/src/java"/>
-	<classpathentry kind="src" path="metastore/src/test"/>
 	<classpathentry kind="src" path="metastore/src/model"/>
-	<classpathentry kind="src" path="metastore/src/gen-javabean"/>
-	<classpathentry kind="src" path="serde/src/java"/>
-	<classpathentry kind="src" path="serde/src/test"/>
-	<classpathentry kind="src" path="serde/src/gen-java"/>
-	<classpathentry kind="src" path="cli/src/java"/>
-	<classpathentry kind="src" path="build/ql/gen-java"/>
+	<classpathentry kind="src" path="metastore/src/test"/>
 	<classpathentry kind="src" path="ql/src/java"/>
 	<classpathentry kind="src" path="ql/src/test"/>
-	<classpathentry kind="src" path="common/src/java"/>
+	<classpathentry kind="src" path="serde/src/gen-java"/>
+	<classpathentry kind="src" path="serde/src/java"/>
+	<classpathentry kind="src" path="serde/src/test"/>
+	<classpathentry kind="src" path="service/src/gen-javabean"/>
 	<classpathentry kind="src" path="service/src/java"/>
 	<classpathentry kind="src" path="service/src/test"/>
-	<classpathentry kind="src" path="service/src/gen-javabean"/>
-	<classpathentry kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER"/>
-	<classpathentry kind="lib" path="lib/asm-3.1.jar"/>
-	<classpathentry kind="lib" path="lib/commons-cli-2.0-SNAPSHOT.jar"/>
-	<classpathentry kind="lib" path="lib/commons-collections-3.2.1.jar"/>
-	<classpathentry kind="lib" path="lib/commons-lang-2.4.jar"/>
-	<classpathentry kind="lib" path="lib/commons-logging-1.0.4.jar"/>
-	<classpathentry kind="lib" path="lib/commons-logging-api-1.0.4.jar"/>
-	<classpathentry kind="lib" path="lib/derby.jar"/>
-	<classpathentry kind="lib" path="lib/jdo2-api-2.1.jar"/>
-	<classpathentry kind="lib" path="lib/jpox-core-1.2.2.jar"/>
-	<classpathentry kind="lib" path="lib/jpox-enhancer-1.2.2.jar"/>
-	<classpathentry kind="lib" path="lib/jpox-rdbms-1.2.2.jar"/>
-	<classpathentry kind="lib" path="lib/libfb303.jar"/>
-	<classpathentry kind="lib" path="lib/libthrift.jar"/>
-	<classpathentry kind="lib" path="lib/log4j-1.2.15.jar"/>
-	<classpathentry kind="lib" path="lib/velocity-1.5.jar"/>
-	<classpathentry kind="lib" path="ql/lib/antlr-3.0.1.jar"/>
-	<classpathentry kind="lib" path="ql/lib/antlr-runtime-3.0.1.jar"/>
-	<classpathentry kind="lib" path="ql/lib/commons-jexl-1.1.jar"/>
-	<classpathentry kind="lib" path="ql/lib/stringtemplate-3.1b1.jar"/>
-	<classpathentry kind="lib" path="cli/lib/jline-0.9.94.jar"/>
-	<classpathentry kind="lib" path="build/hadoopcore/hadoop-0.19.0/hadoop-0.19.0-core.jar"/>
-	<classpathentry kind="lib" path="testlibs/junit-3.8.1.jar"/>
+	<classpathentry kind="src" path="jdbc/src/java"/>
+	<classpathentry kind="src" path="jdbc/src/test"/>
 	<classpathentry kind="output" path="build/eclipse-classes"/>
 </classpath>
diff --git a/eclipse-templates/.externalToolBuilders/Hive_Ant_Builder.launch b/eclipse-templates/.externalToolBuilders/Hive_Ant_Builder.launch
index f67185333e..a28f0afaa2 100644
--- a/eclipse-templates/.externalToolBuilders/Hive_Ant_Builder.launch
+++ b/eclipse-templates/.externalToolBuilders/Hive_Ant_Builder.launch
@@ -7,7 +7,7 @@
 <booleanAttribute key="org.eclipse.ant.ui.DEFAULT_VM_INSTALL" value="false"/>
 <stringAttribute key="org.eclipse.debug.core.ATTR_REFRESH_SCOPE" value="${project}"/>
 <listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_PATHS">
-<listEntry value="/hive_ws3/build.xml"/>
+<listEntry value="/@PROJECT@/build.xml"/>
 </listAttribute>
 <listAttribute key="org.eclipse.debug.core.MAPPED_RESOURCE_TYPES">
 <listEntry value="1"/>
@@ -16,8 +16,8 @@
 <booleanAttribute key="org.eclipse.debug.ui.ATTR_LAUNCH_IN_BACKGROUND" value="false"/>
 <stringAttribute key="org.eclipse.jdt.launching.CLASSPATH_PROVIDER" value="org.eclipse.ant.ui.AntClasspathProvider"/>
 <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="true"/>
-<stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="hive_ws3"/>
-<stringAttribute key="org.eclipse.ui.externaltools.ATTR_LOCATION" value="${workspace_loc:/hive_ws3/build.xml}"/>
+<stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
+<stringAttribute key="org.eclipse.ui.externaltools.ATTR_LOCATION" value="${workspace_loc:/@PROJECT@/build.xml}"/>
 <stringAttribute key="org.eclipse.ui.externaltools.ATTR_RUN_BUILD_KINDS" value="incremental,auto,clean"/>
 <booleanAttribute key="org.eclipse.ui.externaltools.ATTR_TRIGGERS_CONFIGURED" value="true"/>
 </launchConfiguration>
diff --git a/eclipse-templates/.project b/eclipse-templates/.project
index 19daba08a0..846dc9c0d3 100644
--- a/eclipse-templates/.project
+++ b/eclipse-templates/.project
@@ -5,6 +5,11 @@
 	<projects>
 	</projects>
 	<buildSpec>
+		<buildCommand>
+			<name>org.eclipse.jdt.core.javabuilder</name>
+			<arguments>
+			</arguments>
+		</buildCommand>
 		<buildCommand>
 			<name>org.eclipse.ui.externaltools.ExternalToolBuilder</name>
 			<triggers>auto,clean,incremental,</triggers>
@@ -15,6 +20,7 @@
 				</dictionary>
 			</arguments>
 		</buildCommand>
+
 	</buildSpec>
 	<natures>
 		<nature>org.eclipse.jdt.core.javanature</nature>
diff --git a/eclipse-templates/TestCliDriver.launchtemplate b/eclipse-templates/TestCliDriver.launchtemplate
new file mode 100644
index 0000000000..5e95246c93
--- /dev/null
+++ b/eclipse-templates/TestCliDriver.launchtemplate
@@ -0,0 +1,23 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
+<mapAttribute key="org.eclipse.debug.core.environmentVariables">
+<mapEntry key="HADOOP_HOME" value="${workspace_loc:@PROJECT@}/build/hadoopcore/hadoop-@HADOOPVER@"/>
+</mapAttribute>
+<stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
+<booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
+<stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
+<stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
+<listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/metastore_model.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/hadoopcore/hadoop-@HADOOPVER@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+</listAttribute>
+<booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
+<stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.cli.TestCliDriver"/>
+<stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
+<stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
+</launchConfiguration>
diff --git a/eclipse-templates/TestHive.launchtemplate b/eclipse-templates/TestHive.launchtemplate
new file mode 100644
index 0000000000..36bf134937
--- /dev/null
+++ b/eclipse-templates/TestHive.launchtemplate
@@ -0,0 +1,23 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
+<mapAttribute key="org.eclipse.debug.core.environmentVariables">
+<mapEntry key="HADOOP_HOME" value="${workspace_loc:@PROJECT@}/build/hadoopcore/hadoop-@HADOOPVER@"/>
+</mapAttribute>
+<stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
+<booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
+<stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
+<stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
+<listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/metastore_model.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/hadoopcore/hadoop-@HADOOPVER@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+</listAttribute>
+<booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
+<stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.ql.metadata.TestHive"/>
+<stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
+<stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
+</launchConfiguration>
diff --git a/eclipse-templates/TestJdbc.launchtemplate b/eclipse-templates/TestJdbc.launchtemplate
new file mode 100644
index 0000000000..eb740737a5
--- /dev/null
+++ b/eclipse-templates/TestJdbc.launchtemplate
@@ -0,0 +1,23 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
+<mapAttribute key="org.eclipse.debug.core.environmentVariables">
+<mapEntry key="HADOOP_HOME" value="${workspace_loc:@PROJECT@}/build/hadoopcore/hadoop-@HADOOPVER@"/>
+</mapAttribute>
+<stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
+<booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
+<stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
+<stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
+<listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/metastore_model.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/hadoopcore/hadoop-@HADOOPVER@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
+<listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+</listAttribute>
+<booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
+<stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.jdbc.TestJdbcDriver"/>
+<stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
+<stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
+</launchConfiguration>
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/FileStore.java b/metastore/src/java/org/apache/hadoop/hive/metastore/FileStore.java
index 9d61538ca1..29d691c8de 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/FileStore.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/FileStore.java
@@ -55,13 +55,11 @@ public class FileStore implements RawStore {
 
   private Configuration conf;
 
-  @Override
   public Configuration getConf() {
     // TODO Auto-generated method stub
     return null;
   }
 
-  @Override
   public void setConf(Configuration conf) {
     this.conf = conf;
     String msRootPath = HiveConf.getVar(conf, HiveConf.ConfVars.METASTOREDIRECTORY);
@@ -105,7 +103,6 @@ private File getDBDir(String dbName) {
     return f;
   }
 
-  @Override
   public boolean createDatabase(Database db) throws MetaException {
     // ignores the location param
     boolean mkdir = getDBDir(db.getName()).mkdir();
@@ -115,7 +112,6 @@ public boolean createDatabase(Database db) throws MetaException {
     return mkdir;
   }
 
-  @Override
   public boolean createDatabase(String name) throws MetaException {
     return this.createDatabase(new Database(name, "ignored param"));
   }
@@ -220,7 +216,6 @@ public ArrayList<String> getTablesByPattern(DB parent, String tablePattern) thro
     return names;
   }
 
-  @Override
   public List<String> getTables(String dbName, String pattern) throws MetaException {
     try {
       return this.getTablesByPattern(new DB(dbName, conf), pattern);
@@ -243,12 +238,10 @@ public boolean dbExists(String dbName) throws MetaException {
     return dbName.equals(MetaStore.DefaultDB) || f.isDirectory();
   }
 
-  @Override
   public boolean dropDatabase(String dbname) {
     return true; // no-op
   }
 
-  @Override
   public Database getDatabase(String name) throws NoSuchObjectException {
     try {
       DB db = new DB(name, conf);
@@ -259,7 +252,6 @@ public Database getDatabase(String name) throws NoSuchObjectException {
     }
   }
 
-  @Override
   /**
    * getDatabases
    *
@@ -292,14 +284,12 @@ public boolean tableExists(String dbName, String tableName) {
     return getSchemaFile(dbName, tableName).exists();
   }
 
-  @Override
   public void alterTable(String dbname, String name, Table newTable) throws InvalidObjectException,
       MetaException {
     // TODO Auto-generated method stub
     throw new MetaException("Not yet implemented");
   }
 
-  @Override
   public void createTable(Table tbl) throws InvalidObjectException, MetaException {
     Properties p = MetaStoreUtils.getSchema(tbl);
     try {
@@ -310,7 +300,6 @@ public void createTable(Table tbl) throws InvalidObjectException, MetaException
     }
   }
 
-  @Override
   public boolean dropTable(String dbName, String tableName) throws MetaException {
     try {
       new DB(dbName, conf).getTable(tableName, false).drop();
@@ -321,7 +310,6 @@ public boolean dropTable(String dbName, String tableName) throws MetaException {
     return true;
   }
 
-  @Override
   public Table getTable(String dbName, String tableName) throws MetaException {
     try {
       Properties p = new DB(dbName, conf).getTable(tableName, true).getSchema();
@@ -332,67 +320,55 @@ public Table getTable(String dbName, String tableName) throws MetaException {
     }
   }
 
-  @Override
   public boolean createType(Type type) {
     return true; // no-op
   }
 
-  @Override
   public boolean dropType(String typeName) {
     return true; // no-op
   }
 
-  @Override
   public boolean addPartition(Partition part) throws InvalidObjectException, MetaException {
     return true; // no-op as there is no metadata 
   }
 
-  @Override
   public boolean dropPartition(String dbName, String tableName, List<String> part_vals)
       throws MetaException {
     return true; // no-op
   }
 
-  @Override
   public Partition getPartition(String dbName, String tableName, List<String> part_vals)
       throws MetaException {
     // TODO Auto-generated method stub
     throw new MetaException("Not yet implemented");
   }
 
-  @Override
   public List<Partition> getPartitions(String dbName, String tableName, int max)
       throws MetaException {
     // TODO Auto-generated method stub
     throw new MetaException("Not yet implemented");
   }
 
-  @Override
   public Type getType(String typeName) {
     return null; // no-op
   }
 
-  @Override
   public boolean openTransaction() {
     return true;
   }
 
-  @Override
   public void rollbackTransaction() {
     // no-op
   }
 
-  @Override
   public boolean commitTransaction() {
     return true; // no-op
   }
 
-  @Override
   public void shutdown() {
     // no-op
   }
 
-  @Override
   public List<String> listPartitionNames(String db_name, String tbl_name, short max_parts)
       throws MetaException {
     // TODO Auto-generated method stub
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
index 6aa3006c3a..5e6f1dbed6 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
@@ -581,7 +581,6 @@ public void alter_table(String dbname, String name, Table newTable) throws Inval
         }
       }
 
-      @Override
       public List<String> get_tables(String dbname, String pattern) throws MetaException {
         this.incrementCounter("get_tables");
         logStartFunction("get_tables: db=" + dbname + " pat=" + pattern);
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
index 58e920b677..5825f6a019 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
@@ -472,7 +472,6 @@ public Table getTable(String tableName) throws MetaException, TException, NoSuch
     return getTable(MetaStoreUtils.DEFAULT_DATABASE_NAME, tableName);
   }
 
-  @Override
   public List<String> listPartitionNames(String dbName, String tblName, short max)
       throws MetaException, TException {
     // TODO Auto-generated method stub
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreClient.java b/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreClient.java
index 10e59eb234..7a0e7d3fa1 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreClient.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreClient.java
@@ -335,14 +335,12 @@ public Table getTable(String dbName, String tableName) throws MetaException,
   
 
   //These will disappear when the server is unified for both filestore and dbstore
-  @Override
   public List<Partition> listPartitions(String dbName, String tableName, short max_parts)
       throws NoSuchObjectException, MetaException, TException {
     //TODO: move the code from Table.getPartitions() to here
     return new ArrayList<Partition>();
   }
 
-  @Override
   public Partition getPartition(String dbName, String tableName, List<String> partVals)
       throws MetaException, TException {
     if(partVals.size() == 0) {
@@ -362,7 +360,6 @@ public Partition getPartition(String dbName, String tableName, List<String> part
     }
   }
 
-  @Override
   public void createTable(Table tbl) throws AlreadyExistsException, InvalidObjectException,
       MetaException, NoSuchObjectException, TException {
     Properties schema = MetaStoreUtils.getSchema(tbl);
@@ -425,26 +422,22 @@ private Partition getPartitionObject(String dbName, String tableName, List<Strin
     return tPartition;
   }
 
-  @Override
   public void alter_table(String defaultDatabaseName, String tblName, Table table)
       throws InvalidOperationException, MetaException, TException {
     throw new MetaException("Not yet implementd in filestore");
   }
 
-  @Override
   public boolean createDatabase(String name, String location_uri) throws AlreadyExistsException,
       MetaException, TException {
     // TODO Auto-generated method stub
     return false;
   }
 
-  @Override
   public boolean dropDatabase(String name) throws MetaException, TException {
     // TODO Auto-generated method stub
     return false;
   }
 
-  @Override
   public List<String> listPartitionNames(String db_name, String tbl_name, short max_parts)
       throws MetaException, TException {
     // TODO Auto-generated method stub
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java b/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
index b25368d846..062cbe64ee 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
@@ -90,12 +90,10 @@ private static enum TXN_STATUS {
   
   public ObjectStore() {}
 
-  @Override
   public Configuration getConf() {
     return hiveConf;
   }
 
-  @Override
   @SuppressWarnings("nls")
   public void setConf(Configuration conf) {
     this.hiveConf = conf;
diff --git a/ql/build.xml b/ql/build.xml
index 5203fd5abc..445fe65c8a 100644
--- a/ql/build.xml
+++ b/ql/build.xml
@@ -43,7 +43,7 @@
   </path>
 
 
-  <target name="gen-test" depends="deploy-ant-tasks, test-conditions" >
+  <target name="gen-test" depends="deploy-ant-tasks, test-conditions, test-init" >
     <taskdef name="qtestgen" classname="org.apache.hadoop.hive.ant.QTestGenTask"
              classpath="${build.dir.hive}/hive_anttasks.jar:${hive.root}/lib/velocity-1.5.jar:${hive.root}/lib/commons-collections-3.2.1.jar:${hive.root}/lib/commons-lang-2.4.jar"/>
     
@@ -52,28 +52,32 @@
               queryDirectory="${ql.test.query.dir}/positive"
               queryFile="${qfile}"
               resultsDirectory="${ql.test.results.dir}/compiler" className="TestParse"
-              logFile="${test.log.dir}/testparsegen.log"/>
+              logFile="${test.log.dir}/testparsegen.log"
+              logDirectory="${test.log.dir}/positive"/>
     
     <qtestgen outputDirectory="${test.build.src}/org/apache/hadoop/hive/ql/parse" 
               templatePath="${ql.test.template.dir}" template="TestParseNegative.vm" 
               queryDirectory="${ql.test.query.dir}/negative" 
               queryFile="${qfile}"
               resultsDirectory="${ql.test.results.dir}/compiler/errors" className="TestParseNegative"
-              logFile="${test.log.dir}/testparseneggen.log"/>
+              logFile="${test.log.dir}/testparseneggen.log"
+              logDirectory="${test.log.dir}/negative"/>
 
     <qtestgen outputDirectory="${test.build.src}/org/apache/hadoop/hive/cli" 
               templatePath="${ql.test.template.dir}" template="TestCliDriver.vm" 
               queryDirectory="${ql.test.query.clientpositive.dir}" 
               queryFile="${qfile}"
               resultsDirectory="${ql.test.results.clientpositive.dir}" className="TestCliDriver"
-              logFile="${test.log.dir}/testclidrivergen.log"/>
+              logFile="${test.log.dir}/testclidrivergen.log"
+              logDirectory="${test.log.dir}/clientpositive"/>
 
     <qtestgen outputDirectory="${test.build.src}/org/apache/hadoop/hive/cli" 
               templatePath="${ql.test.template.dir}" template="TestNegativeCliDriver.vm" 
               queryDirectory="${ql.test.query.dir}/clientnegative" 
               queryFile="${qfile}"
               resultsDirectory="${ql.test.results.dir}/clientnegative" className="TestNegativeCliDriver"
-              logFile="${test.log.dir}/testnegclidrivergen.log"/>
+              logFile="${test.log.dir}/testnegclidrivergen.log"
+              logDirectory="${test.log.dir}/clientnegative"/>
 
   </target>
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTNode.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTNode.java
index 14c3610a5e..4cc3073c2e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTNode.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTNode.java
@@ -40,7 +40,6 @@ public ASTNode(Token t) {
   /* (non-Javadoc)
    * @see org.apache.hadoop.hive.ql.lib.Node#getChildren()
    */
-  @Override
   public Vector<Node> getChildren() {
     if (super.getChildCount() == 0) {
       return null;
@@ -57,7 +56,6 @@ public Vector<Node> getChildren() {
   /* (non-Javadoc)
    * @see org.apache.hadoop.hive.ql.lib.Node#getName()
    */
-  @Override
   public String getName() {
     return (new Integer(super.getToken().getType())).toString();
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/tools/LineageInfo.java b/ql/src/java/org/apache/hadoop/hive/ql/tools/LineageInfo.java
index 73ad2e9456..5d8a2c8790 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/tools/LineageInfo.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/tools/LineageInfo.java
@@ -76,7 +76,6 @@ public TreeSet<String> getOutputTableList() {
   /**
    * Implements the process method for the NodeProcessor interface.
    */
-  @Override
   public void process(Node nd, NodeProcessorCtx procCtx)
   throws SemanticException {
     ASTNode pt = (ASTNode)nd;
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java b/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
index 7a4cd4eec0..28d39385a9 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
@@ -154,13 +154,13 @@ public void normalizeNames(File path) throws Exception {
     }
   }
 
-  public QTestUtil(String outDir) throws Exception {
+  public QTestUtil(String outDir, String logDir) throws Exception {
     this.outDir = outDir;
+    this.logDir = logDir;
     conf = new HiveConf(Driver.class);
 
     // System.out.println(conf.toString());
     testFiles = conf.get("test.data.files").replace('\\', '/').replace("c:", "");
-    logDir = conf.get("test.log.dir");
 
     String ow = System.getProperty("test.output.overwrite");
     overWrite = false;
@@ -724,15 +724,16 @@ public void run() {
    * In multithreaded mode each query file is run in a separate thread. the caller has to 
    * arrange that different query files do not collide (in terms of destination tables)
    */
-  public static boolean queryListRunner(File [] qfiles, String [] resDirs, boolean mt) {
+  public static boolean queryListRunner(File [] qfiles, String [] resDirs, String[] logDirs, boolean mt) {
 
     assert(qfiles.length == resDirs.length);
+    assert(qfiles.length == logDirs.length);
     boolean failed = false;        
 
     try {
       QTestUtil[] qt = new QTestUtil [qfiles.length];
       for(int i=0; i<qfiles.length; i++) {
-        qt[i] = new QTestUtil(resDirs[i]);
+        qt[i] = new QTestUtil(resDirs[i], logDirs[i]);
         qt[i].addFile(qfiles[i]);
       }
 
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestMTQueries.java b/ql/src/test/org/apache/hadoop/hive/ql/TestMTQueries.java
index d272f83531..c107e93c19 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/TestMTQueries.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestMTQueries.java
@@ -35,17 +35,20 @@ public class TestMTQueries extends TestCase {
 
   private String inpDir = System.getProperty("ql.test.query.clientpositive.dir");
   private String resDir = System.getProperty("ql.test.results.clientpositive.dir");
+  private String logDir = System.getProperty("test.log.dir"+"/clientpositive");
 
   public void testMTQueries1()  throws Exception {
     String[] testNames = new String [] {"join1.q", "join2.q", "groupby1.q", "groupby2.q", "join3.q", "input1.q", "input19.q"};
+    String [] logDirs = new String [testNames.length];
     String [] resDirs = new String [testNames.length];
     File [] qfiles = new File [testNames.length];
     for(int i=0; i<resDirs.length; i++) {
+      logDirs[i] = logDir;
       resDirs[i] = resDir;
       qfiles[i] = new File(inpDir, testNames[i]);
     }
 
-    boolean success = QTestUtil.queryListRunner(qfiles, resDirs, true);
+    boolean success = QTestUtil.queryListRunner(qfiles, resDirs, logDirs, true);
     if(!success)
       fail ("One or more queries failed");
   }
diff --git a/ql/src/test/templates/TestCliDriver.vm b/ql/src/test/templates/TestCliDriver.vm
index 7c85190480..f168f6201c 100644
--- a/ql/src/test/templates/TestCliDriver.vm
+++ b/ql/src/test/templates/TestCliDriver.vm
@@ -25,7 +25,7 @@ public class $className extends TestCase {
   @Override
   protected void setUp() {
     try {
-      qt = new QTestUtil("$resultsDir.getCanonicalPath()");
+      qt = new QTestUtil("$resultsDir.getCanonicalPath()", "$logDir.getCanonicalPath()");
 
 #foreach ($qf in $qfiles)
       qt.addFile("$qf.getCanonicalPath()");
diff --git a/ql/src/test/templates/TestNegativeCliDriver.vm b/ql/src/test/templates/TestNegativeCliDriver.vm
index 6f7c3c0dd1..01131e6fb0 100644
--- a/ql/src/test/templates/TestNegativeCliDriver.vm
+++ b/ql/src/test/templates/TestNegativeCliDriver.vm
@@ -25,7 +25,7 @@ public class $className extends TestCase {
   @Override
   protected void setUp() {
     try {
-      qt = new QTestUtil("$resultsDir.getCanonicalPath()");
+      qt = new QTestUtil("$resultsDir.getCanonicalPath()", "$logDir.getCanonicalPath()");
 
 #foreach ($qf in $qfiles)
       qt.addFile("$qf.getCanonicalPath()");
diff --git a/ql/src/test/templates/TestParse.vm b/ql/src/test/templates/TestParse.vm
index 26cbf32e44..807d715f4c 100644
--- a/ql/src/test/templates/TestParse.vm
+++ b/ql/src/test/templates/TestParse.vm
@@ -22,7 +22,7 @@ public class $className extends TestCase {
   @Override
   protected void setUp() {
     try {
-      qt = new QTestUtil("$resultsDir.getCanonicalPath()");
+      qt = new QTestUtil("$resultsDir.getCanonicalPath()", "$logDir.getCanonicalPath()");
 
 #foreach ($qf in $qfiles)
       qt.addFile("$qf.getCanonicalPath()");
diff --git a/ql/src/test/templates/TestParseNegative.vm b/ql/src/test/templates/TestParseNegative.vm
index 225357e525..e40e604625 100755
--- a/ql/src/test/templates/TestParseNegative.vm
+++ b/ql/src/test/templates/TestParseNegative.vm
@@ -22,7 +22,7 @@ public class $className extends TestCase {
   @Override
   protected void setUp() {
     try {
-      qt = new QTestUtil("$resultsDir.getCanonicalPath()");
+      qt = new QTestUtil("$resultsDir.getCanonicalPath()", "$logDir.getCanonicalPath()");
 
 #foreach ($qf in $qfiles)
       qt.addFile("$qf.getCanonicalPath()");
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDe.java b/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDe.java
index 4ccbd4d9ec..281b177280 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDe.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDe.java
@@ -158,18 +158,15 @@ public static ObjectInspector dynamicSerDeStructBaseToObjectInspector(DynamicSer
     }
   }
 
-  @Override
   public ObjectInspector getObjectInspector() throws SerDeException {
     return dynamicSerDeStructBaseToObjectInspector(this.bt);
   }
 
-  @Override
   public Class<? extends Writable> getSerializedClass() {
     return BytesWritable.class;
   }
 
   BytesWritable ret = new BytesWritable();
-  @Override
   public Writable serialize(Object obj, ObjectInspector objInspector)
   throws SerDeException {
     try {
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/thrift/TBinarySortableProtocol.java b/serde/src/java/org/apache/hadoop/hive/serde2/thrift/TBinarySortableProtocol.java
index a61c9bf1c4..6aa5986463 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/thrift/TBinarySortableProtocol.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/thrift/TBinarySortableProtocol.java
@@ -104,7 +104,6 @@ public TBinarySortableProtocol(TTransport trans) {
    */
   boolean ascending; 
   
-  @Override
   public void initialize(Configuration conf, Properties tbl) throws TException {
     sortOrder = tbl.getProperty(Constants.SERIALIZATION_SORT_ORDER);
     if (sortOrder == null) {
@@ -534,12 +533,10 @@ public byte[] readBinary() throws TException {
   }
 
   boolean lastPrimitiveWasNull;
-  @Override
   public boolean lastPrimitiveWasNull() throws TException {
     return lastPrimitiveWasNull;
   }
 
-  @Override
   public void writeNull() throws TException {
     writeRawBytes(nullByte, 0, 1);
   }
diff --git a/service/src/java/org/apache/hadoop/hive/service/HiveServer.java b/service/src/java/org/apache/hadoop/hive/service/HiveServer.java
index 68f5079e54..ea73bd915f 100644
--- a/service/src/java/org/apache/hadoop/hive/service/HiveServer.java
+++ b/service/src/java/org/apache/hadoop/hive/service/HiveServer.java
@@ -99,7 +99,6 @@ public HiveServerHandler() throws MetaException {
      *
      * @param query HiveQL query to execute
      */
-    @Override
     public void execute(String query) throws HiveServerException, TException {
       HiveServerHandler.LOG.info("Running the query: " + query);
       int rc = 0;
@@ -117,7 +116,6 @@ public void execute(String query) throws HiveServerException, TException {
     /**
      * Return the schema of the query result
      */
-    @Override
     public String getSchema() throws HiveServerException, TException {
       try {
         return driver.getSchema();
@@ -132,7 +130,6 @@ public String getSchema() throws HiveServerException, TException {
      * 
      * @return the next row in a query result set. null if there is no more row to fetch.
      */
-    @Override
     public String fetchOne() throws HiveServerException, TException {
       driver.setMaxRows(1);
       Vector<String> result = new Vector<String>();
@@ -155,7 +152,6 @@ public String fetchOne() throws HiveServerException, TException {
      *         row to fetch or numRows == 0. 
      * @throws HiveServerException Invalid value for numRows (numRows < 0)
      */
-    @Override
     public List<String> fetchN(int numRows) throws HiveServerException, TException {
       if (numRows < 0) {
         throw new HiveServerException("Invalid argument for number of rows: " + numRows);
@@ -174,7 +170,6 @@ public List<String> fetchN(int numRows) throws HiveServerException, TException {
      * TODO: Currently the server buffers all the rows before returning them 
      * to the client. Decide whether the buffering should be done in the client.
      */
-    @Override
     public List<String> fetchAll() throws HiveServerException, TException {
       Vector<String> rows = new Vector<String>();
       Vector<String> result = new Vector<String>();
