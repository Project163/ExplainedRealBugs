diff --git a/CHANGES.txt b/CHANGES.txt
index 5a8d1b98b3..1a9150218b 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -695,6 +695,9 @@ Trunk -  Unreleased
     HIVE-1903 Can't join HBase tables if one's name is the beginning of
     the other (John Sichi via namit)
 
+    HIVE-1912 Double escaping special chars when removing old partitions
+    in rmr (Ning Zhang via namit)
+
   TESTS
 
     HIVE-1464. improve  test query performance
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
index 69512cb10f..bf2fec008a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
@@ -95,7 +95,7 @@ public class Hive {
   private HiveConf conf = null;
   private IMetaStoreClient metaStoreClient;
   private String currentDatabase;
-  
+
   private static ThreadLocal<Hive> hiveDB = new ThreadLocal() {
     @Override
     protected synchronized Object initialValue() {
@@ -965,7 +965,7 @@ public boolean revokePrivileges(PrivilegeBag privileges)
       throw new HiveException(e);
     }
   }
-  
+
   /**
    * Query metadata to see if a database with the given name already exists.
    *
@@ -1134,7 +1134,7 @@ public ArrayList<LinkedHashMap<String, String>> loadDynamicPartitions(Path loadP
   public void loadTable(Path loadPath, String tableName, boolean replace,
       boolean holdDDLTime) throws HiveException {
     Table tbl = getTable(tableName);
-    
+
     if (replace) {
       tbl.replaceFiles(loadPath);
     } else {
@@ -1459,7 +1459,7 @@ public String getCurrentDatabase() {
   public void setCurrentDatabase(String currentDatabase) {
     this.currentDatabase = currentDatabase;
   }
-  
+
   public void createRole(String roleName, String ownerName)
       throws HiveException {
     try {
@@ -1476,7 +1476,7 @@ public void dropRole(String roleName) throws HiveException {
       throw new HiveException(e);
     }
   }
-  
+
   public List<Role> showRoleGrant(String principalName, PrincipalType principalType) throws HiveException {
     try {
       return getMSC().list_roles(principalName, principalType);
@@ -1484,7 +1484,7 @@ public List<Role> showRoleGrant(String principalName, PrincipalType principalTyp
       throw new HiveException(e);
     }
   }
-  
+
   public boolean grantRole(String roleName, String userName,
       PrincipalType principalType, String grantor, PrincipalType grantorType,
       boolean grantOption) throws HiveException {
@@ -1504,7 +1504,7 @@ public boolean revokeRole(String roleName, String userName,
       throw new HiveException(e);
     }
   }
-  
+
   public List<Role> listRoles(String userName,  PrincipalType principalType)
       throws HiveException {
     try {
@@ -1513,7 +1513,7 @@ public List<Role> listRoles(String userName,  PrincipalType principalType)
       throw new HiveException(e);
     }
   }
-  
+
   /**
    * @param objectType
    *          hive object type
@@ -1717,7 +1717,7 @@ static protected void replaceFiles(Path srcf, Path destf, Path oldPath,
             // use FsShell to move data to .Trash first rather than delete permanently
             FsShell fshell = new FsShell();
             fshell.setConf(conf);
-            fshell.run(new String[]{"-rmr", oldPath.toUri().toString()});
+            fshell.run(new String[]{"-rmr", oldPath.toString()});
           }
         } catch (Exception e) {
           //swallow the exception
@@ -1734,7 +1734,7 @@ static protected void replaceFiles(Path srcf, Path destf, Path oldPath,
       	if (fs.exists(destf)) {
       	  fs.delete(destf, true);
       	}
-      	
+
       	boolean b = fs.rename(srcs[0].getPath(), destf);
       	if (!b) {
       	  throw new HiveException("Unable to move results from " + srcs[0].getPath()
@@ -1806,7 +1806,7 @@ private IMetaStoreClient getMSC() throws MetaException {
     }
     return metaStoreClient;
   }
-  
+
   private String getUserName() {
     SessionState ss = SessionState.get();
     if (ss != null && ss.getAuthenticator() != null) {
@@ -1814,7 +1814,7 @@ private String getUserName() {
     }
     return null;
   }
-  
+
   private List<String> getGroupNames() {
     SessionState ss = SessionState.get();
     if (ss != null && ss.getAuthenticator() != null) {
diff --git a/ql/src/test/queries/clientpositive/partition_special_char.q b/ql/src/test/queries/clientpositive/partition_special_char.q
new file mode 100644
index 0000000000..81344334df
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/partition_special_char.q
@@ -0,0 +1,19 @@
+create table sc as select * 
+from (select '2011-01-11', '2011-01-11+14:18:26' from src limit 1 
+      union all 
+      select '2011-01-11', '2011-01-11+15:18:26' from src limit 1 
+      union all 
+      select '2011-01-11', '2011-01-11+16:18:26' from src limit 1 ) s;
+
+create table sc_part (key string) partitioned by (ts string) stored as rcfile;
+
+set hive.exec.dynamic.partition=true;
+set hive.exec.dynamic.partition.mode=nonstrict;
+
+insert overwrite table sc_part partition(ts) select * from sc;
+show partitions sc_part;
+select count(*) from sc_part where ts is not null;
+
+insert overwrite table sc_part partition(ts) select * from sc;
+show partitions sc_part;
+select count(*) from sc_part where ts is not null;
diff --git a/ql/src/test/results/clientpositive/partition_special_char.q.out b/ql/src/test/results/clientpositive/partition_special_char.q.out
new file mode 100644
index 0000000000..da8ab6904e
--- /dev/null
+++ b/ql/src/test/results/clientpositive/partition_special_char.q.out
@@ -0,0 +1,109 @@
+PREHOOK: query: create table sc as select * 
+from (select '2011-01-11', '2011-01-11+14:18:26' from src limit 1 
+      union all 
+      select '2011-01-11', '2011-01-11+15:18:26' from src limit 1 
+      union all 
+      select '2011-01-11', '2011-01-11+16:18:26' from src limit 1 ) s
+PREHOOK: type: CREATETABLE_AS_SELECT
+PREHOOK: Input: default@src
+POSTHOOK: query: create table sc as select * 
+from (select '2011-01-11', '2011-01-11+14:18:26' from src limit 1 
+      union all 
+      select '2011-01-11', '2011-01-11+15:18:26' from src limit 1 
+      union all 
+      select '2011-01-11', '2011-01-11+16:18:26' from src limit 1 ) s
+POSTHOOK: type: CREATETABLE_AS_SELECT
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@sc
+PREHOOK: query: create table sc_part (key string) partitioned by (ts string) stored as rcfile
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table sc_part (key string) partitioned by (ts string) stored as rcfile
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@sc_part
+PREHOOK: query: insert overwrite table sc_part partition(ts) select * from sc
+PREHOOK: type: QUERY
+PREHOOK: Input: default@sc
+PREHOOK: Output: default@sc_part
+POSTHOOK: query: insert overwrite table sc_part partition(ts) select * from sc
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@sc
+POSTHOOK: Output: default@sc_part@ts=2011-01-11+14%3A18%3A26
+POSTHOOK: Output: default@sc_part@ts=2011-01-11+15%3A18%3A26
+POSTHOOK: Output: default@sc_part@ts=2011-01-11+16%3A18%3A26
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+14:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+15:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+16:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+PREHOOK: query: show partitions sc_part
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions sc_part
+POSTHOOK: type: SHOWPARTITIONS
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+14:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+15:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+16:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+ts=2011-01-11+14%3A18%3A26
+ts=2011-01-11+15%3A18%3A26
+ts=2011-01-11+16%3A18%3A26
+PREHOOK: query: select count(*) from sc_part where ts is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@sc_part@ts=2011-01-11+14%3A18%3A26
+PREHOOK: Input: default@sc_part@ts=2011-01-11+15%3A18%3A26
+PREHOOK: Input: default@sc_part@ts=2011-01-11+16%3A18%3A26
+PREHOOK: Output: file:/tmp/nzhang/hive_2011-01-13_11-13-08_667_3825187877309649250/-mr-10000
+POSTHOOK: query: select count(*) from sc_part where ts is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@sc_part@ts=2011-01-11+14%3A18%3A26
+POSTHOOK: Input: default@sc_part@ts=2011-01-11+15%3A18%3A26
+POSTHOOK: Input: default@sc_part@ts=2011-01-11+16%3A18%3A26
+POSTHOOK: Output: file:/tmp/nzhang/hive_2011-01-13_11-13-08_667_3825187877309649250/-mr-10000
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+14:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+15:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+16:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+3
+PREHOOK: query: insert overwrite table sc_part partition(ts) select * from sc
+PREHOOK: type: QUERY
+PREHOOK: Input: default@sc
+PREHOOK: Output: default@sc_part
+POSTHOOK: query: insert overwrite table sc_part partition(ts) select * from sc
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@sc
+POSTHOOK: Output: default@sc_part@ts=2011-01-11+14%3A18%3A26
+POSTHOOK: Output: default@sc_part@ts=2011-01-11+15%3A18%3A26
+POSTHOOK: Output: default@sc_part@ts=2011-01-11+16%3A18%3A26
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+14:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+14:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+15:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+15:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+16:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+16:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+PREHOOK: query: show partitions sc_part
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions sc_part
+POSTHOOK: type: SHOWPARTITIONS
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+14:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+14:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+15:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+15:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+16:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+16:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+ts=2011-01-11+14%3A18%3A26
+ts=2011-01-11+15%3A18%3A26
+ts=2011-01-11+16%3A18%3A26
+PREHOOK: query: select count(*) from sc_part where ts is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@sc_part@ts=2011-01-11+14%3A18%3A26
+PREHOOK: Input: default@sc_part@ts=2011-01-11+15%3A18%3A26
+PREHOOK: Input: default@sc_part@ts=2011-01-11+16%3A18%3A26
+PREHOOK: Output: file:/tmp/nzhang/hive_2011-01-13_11-13-17_403_2722288816258097447/-mr-10000
+POSTHOOK: query: select count(*) from sc_part where ts is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@sc_part@ts=2011-01-11+14%3A18%3A26
+POSTHOOK: Input: default@sc_part@ts=2011-01-11+15%3A18%3A26
+POSTHOOK: Input: default@sc_part@ts=2011-01-11+16%3A18%3A26
+POSTHOOK: Output: file:/tmp/nzhang/hive_2011-01-13_11-13-17_403_2722288816258097447/-mr-10000
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+14:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+14:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+15:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+15:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+16:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+POSTHOOK: Lineage: sc_part PARTITION(ts=2011-01-11+16:18:26).key SIMPLE [(sc)sc.FieldSchema(name:_c0, type:string, comment:null), ]
+3
