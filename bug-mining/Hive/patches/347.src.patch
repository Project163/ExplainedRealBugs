diff --git a/CHANGES.txt b/CHANGES.txt
index 832016c300..8d8954238c 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -166,6 +166,10 @@ Trunk -  Unreleased
 
     HIVE-1164. Fix drop_partition_by_name. (Paul Yang via zshao)
 
+    HIVE-1167. Use TreeMap instead of Property to make explain extended
+    deterministic
+    (Zheng Shao via Ning Zhang)
+
 Release 0.5.0 -  Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/contrib/src/test/results/clientnegative/serde_regex.q.out b/contrib/src/test/results/clientnegative/serde_regex.q.out
index 0b4c5f07e4..d51ba29d1a 100644
--- a/contrib/src/test/results/clientnegative/serde_regex.q.out
+++ b/contrib/src/test/results/clientnegative/serde_regex.q.out
@@ -52,8 +52,8 @@ STAGE PLANS:
           if not exists: false
           input format: org.apache.hadoop.mapred.TextInputFormat
           serde properties:
-            output.format.string %1$s %2$s %3$s %4$s %5$s %6$s %7$s %8$s %9$s
             input.regex ([^ ]*) ([^ ]*) ([^ ]*) (-|\[[^\]]*\]) ([^ "]*|"[^"]*") (-|[0-9]*) (-|[0-9]*)(?: ([^ "]*|"[^"]*") ([^ "]*|"[^"]*"))?
+            output.format.string %1$s %2$s %3$s %4$s %5$s %6$s %7$s %8$s %9$s
           # buckets: -1
           output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
           serde name: org.apache.hadoop.hive.contrib.serde2.RegexSerDe
diff --git a/contrib/src/test/results/clientpositive/serde_regex.q.out b/contrib/src/test/results/clientpositive/serde_regex.q.out
index 28824451f5..c62fb24a79 100644
--- a/contrib/src/test/results/clientpositive/serde_regex.q.out
+++ b/contrib/src/test/results/clientpositive/serde_regex.q.out
@@ -52,8 +52,8 @@ STAGE PLANS:
           if not exists: false
           input format: org.apache.hadoop.mapred.TextInputFormat
           serde properties:
-            output.format.string %1$s %2$s %3$s %4$s %5$s %6$s %7$s %8$s %9$s
             input.regex ([^ ]*) ([^ ]*) ([^ ]*) (-|\[[^\]]*\]) ([^ "]*|"[^"]*") (-|[0-9]*) (-|[0-9]*)(?: ([^ "]*|"[^"]*") ([^ "]*|"[^"]*"))?
+            output.format.string %1$s %2$s %3$s %4$s %5$s %6$s %7$s %8$s %9$s
           # buckets: -1
           output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
           serde name: org.apache.hadoop.hive.contrib.serde2.RegexSerDe
@@ -109,11 +109,11 @@ POSTHOOK: Output: default@serde_regex
 PREHOOK: query: SELECT * FROM serde_regex ORDER BY time
 PREHOOK: type: QUERY
 PREHOOK: Input: default@serde_regex
-PREHOOK: Output: file:/data/users/njain/hive5/hive5/build/ql/tmp/569581247/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/contrib/scratchdir/hive_2010-02-12_22-33-19_616_3967776384774299534/10000
 POSTHOOK: query: SELECT * FROM serde_regex ORDER BY time
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@serde_regex
-POSTHOOK: Output: file:/data/users/njain/hive5/hive5/build/ql/tmp/569581247/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/contrib/scratchdir/hive_2010-02-12_22-33-19_616_3967776384774299534/10000
 127.0.0.1	-	frank	[10/Oct/2000:13:55:36 -0700]	"GET /apache_pb.gif HTTP/1.0"	200	2326	NULL	NULL
 127.0.0.1	-	-	[26/May/2009:00:00:00 +0000]	"GET /someurl/?track=Blabla(Main) HTTP/1.1"	200	5864	-	"Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/525.19 (KHTML, like Gecko) Chrome/1.0.154.65 Safari/525.19"
 PREHOOK: query: DROP TABLE serde_regex
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java
index cdd73a2bd1..252f8f8d7c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java
@@ -29,6 +29,7 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
+import java.util.TreeMap;
 import java.util.Map.Entry;
 
 import org.apache.hadoop.fs.Path;
@@ -88,7 +89,9 @@ private void outputMap(Map<?, ?> mp, String header, PrintStream out,
       boolean extended, int indent) throws Exception {
 
     boolean first_el = true;
-    for (Entry<?, ?> ent : mp.entrySet()) {
+    TreeMap<Object, Object> tree = new TreeMap<Object, Object>();
+    tree.putAll(mp);
+    for (Entry<?, ?> ent : tree.entrySet()) {
       if (first_el) {
         out.println(header);
       }
diff --git a/ql/src/test/results/clientpositive/binary_output_format.q.out b/ql/src/test/results/clientpositive/binary_output_format.q.out
index 58d54e4f45..a9cd232670 100644
--- a/ql/src/test/results/clientpositive/binary_output_format.q.out
+++ b/ql/src/test/results/clientpositive/binary_output_format.q.out
@@ -83,71 +83,71 @@ STAGE PLANS:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
-                      field.delim 9
                       columns _col0
-                      serialization.use.json.object true
-                      serialization.format 9
                       columns.types string
+                      field.delim 9
+                      serialization.format 9
                       serialization.last.column.takes.rest true
+                      serialization.use.json.object true
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1286801631/10002
+                  directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-15-58_271_3464965796195557656/10002
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
                       properties:
-                        name dest1
+                        bucket_count -1
+                        columns mydata
                         columns.types string
+                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                        file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
+                        location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                        name dest1
                         serialization.ddl struct dest1 { string mydata}
-                        columns mydata
                         serialization.format 1
                         serialization.last.column.takes.rest true
-                        bucket_count -1
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                        location file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/dest1
-                        transient_lastDdlTime 1264211336
+                        transient_lastDdlTime 1266041758
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/src [src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1264211335
+              transient_lastDdlTime 1266041757
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1264211335
+                transient_lastDdlTime 1266041757
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -159,38 +159,38 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1286801631/10002
-          destination: file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1065869242/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-15-58_271_3464965796195557656/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-15-58_271_3464965796195557656/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1065869242/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-15-58_271_3464965796195557656/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns mydata
                 columns.types string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { string mydata}
-                columns mydata
                 serialization.format 1
                 serialization.last.column.takes.rest true
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                location file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1264211336
+                transient_lastDdlTime 1266041758
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1065869242/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-15-58_271_3464965796195557656/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1286801631/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-15-58_271_3464965796195557656/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -202,43 +202,43 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1286801631/10002 [file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1286801631/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-15-58_271_3464965796195557656/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-15-58_271_3464965796195557656/10002]
       Path -> Partition:
-        file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1286801631/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-15-58_271_3464965796195557656/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
             properties:
-              name dest1
+              bucket_count -1
+              columns mydata
               columns.types string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+              name dest1
               serialization.ddl struct dest1 { string mydata}
-              columns mydata
               serialization.format 1
               serialization.last.column.takes.rest true
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-              location file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/dest1
-              transient_lastDdlTime 1264211336
+              transient_lastDdlTime 1266041758
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns mydata
                 columns.types string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { string mydata}
-                columns mydata
                 serialization.format 1
                 serialization.last.column.takes.rest true
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                location file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1264211336
+                transient_lastDdlTime 1266041758
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -247,23 +247,23 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1065869242/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-15-58_271_3464965796195557656/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
                 properties:
-                  name dest1
+                  bucket_count -1
+                  columns mydata
                   columns.types string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                  name dest1
                   serialization.ddl struct dest1 { string mydata}
                   serialization.format 1
-                  columns mydata
                   serialization.last.column.takes.rest true
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/test/data/warehouse/dest1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                  transient_lastDdlTime 1264211336
+                  transient_lastDdlTime 1266041758
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
@@ -300,12 +300,12 @@ PREHOOK: query: -- Test the result
 SELECT * FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1904733215/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-16-03_636_3562459403060191123/10000
 POSTHOOK: query: -- Test the result
 SELECT * FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/zshao/svnhive_hadoop/trunk/VENDOR.hive/trunk/build/ql/scratchdir/1904733215/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-16-03_636_3562459403060191123/10000
 238	val_238
 86	val_86
 311	val_311
diff --git a/ql/src/test/results/clientpositive/cluster.q.out b/ql/src/test/results/clientpositive/cluster.q.out
index 8768ac2a96..2633a7ba80 100644
--- a/ql/src/test/results/clientpositive/cluster.q.out
+++ b/ql/src/test/results/clientpositive/cluster.q.out
@@ -64,11 +64,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT * FROM SRC x where x.key = 10 CLUSTER BY x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/666819916/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-30_987_946002006407811313/10000
 POSTHOOK: query: SELECT * FROM SRC x where x.key = 10 CLUSTER BY x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/666819916/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-30_987_946002006407811313/10000
 10	val_10
 PREHOOK: query: EXPLAIN
 SELECT * FROM SRC x  where x.key = 20 CLUSTER BY key
@@ -136,11 +136,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT * FROM SRC x where x.key = 20 CLUSTER BY key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/437686258/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-36_798_7722926056682905425/10000
 POSTHOOK: query: SELECT * FROM SRC x where x.key = 20 CLUSTER BY key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/437686258/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-36_798_7722926056682905425/10000
 20	val_20
 PREHOOK: query: EXPLAIN
 SELECT x.* FROM SRC x where x.key = 20 CLUSTER BY key
@@ -208,11 +208,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT x.* FROM SRC x where x.key = 20 CLUSTER BY key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/479850350/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-43_717_6012279607867421749/10000
 POSTHOOK: query: SELECT x.* FROM SRC x where x.key = 20 CLUSTER BY key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/479850350/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-43_717_6012279607867421749/10000
 20	val_20
 PREHOOK: query: EXPLAIN
 SELECT x.*  FROM SRC x where x.key = 20 CLUSTER BY x.key
@@ -280,11 +280,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT x.*  FROM SRC x where x.key = 20 CLUSTER BY x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/261160281/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-49_882_6526844180884182893/10000
 POSTHOOK: query: SELECT x.*  FROM SRC x where x.key = 20 CLUSTER BY x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/261160281/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-49_882_6526844180884182893/10000
 20	val_20
 PREHOOK: query: EXPLAIN
 SELECT x.key, x.value as v1 FROM SRC x where x.key = 20 CLUSTER BY key
@@ -352,11 +352,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT x.key, x.value as v1 FROM SRC x where x.key = 20 CLUSTER BY key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/327824513/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-54_276_5516587198210822350/10000
 POSTHOOK: query: SELECT x.key, x.value as v1 FROM SRC x where x.key = 20 CLUSTER BY key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/327824513/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-54_276_5516587198210822350/10000
 20	val_20
 PREHOOK: query: EXPLAIN
 SELECT x.key, x.value as v1 FROM SRC x where x.key = 20 CLUSTER BY x.key
@@ -424,11 +424,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT x.key, x.value as v1 FROM SRC x where x.key = 20 CLUSTER BY x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/714056259/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-59_582_505878830166802854/10000
 POSTHOOK: query: SELECT x.key, x.value as v1 FROM SRC x where x.key = 20 CLUSTER BY x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/714056259/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-17-59_582_505878830166802854/10000
 20	val_20
 PREHOOK: query: EXPLAIN
 SELECT x.key, x.value as v1  FROM SRC x where x.key = 20 CLUSTER BY v1
@@ -496,11 +496,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT x.key, x.value as v1  FROM SRC x where x.key = 20 CLUSTER BY v1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/407934629/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-04_613_2939682790554351791/10000
 POSTHOOK: query: SELECT x.key, x.value as v1  FROM SRC x where x.key = 20 CLUSTER BY v1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/407934629/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-04_613_2939682790554351791/10000
 20	val_20
 PREHOOK: query: EXPLAIN
 SELECT y.* from (SELECT x.* FROM SRC x CLUSTER BY x.key) y where y.key = 20
@@ -571,11 +571,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT y.* from (SELECT x.* FROM SRC x CLUSTER BY x.key) y where y.key = 20
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1402413625/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-10_209_6387108226324326472/10000
 POSTHOOK: query: SELECT y.* from (SELECT x.* FROM SRC x CLUSTER BY x.key) y where y.key = 20
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1402413625/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-10_209_6387108226324326472/10000
 20	val_20
 PREHOOK: query: EXPLAIN 
 SELECT x.key, x.value as v1, y.key  FROM SRC x JOIN SRC y ON (x.key = y.key)  where x.key = 20 CLUSTER BY v1
@@ -595,21 +595,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        y 
-          TableScan
-            alias: y
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 1
-              value expressions:
-                    expr: key
-                    type: string
         x 
           TableScan
             alias: x
@@ -631,6 +616,21 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
+        y 
+          TableScan
+            alias: y
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: key
+                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -663,7 +663,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1916601962/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-16_334_2245182201779291081/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col1
@@ -697,11 +697,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT x.key, x.value as v1, y.key  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY v1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/700452873/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-16_594_5072146069194835371/10000
 POSTHOOK: query: SELECT x.key, x.value as v1, y.key  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY v1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/700452873/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-16_594_5072146069194835371/10000
 20	val_20	20
 PREHOOK: query: EXPLAIN 
 SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY v1
@@ -721,23 +721,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        y 
-          TableScan
-            alias: y
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 1
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
         x 
           TableScan
             alias: x
@@ -759,6 +742,23 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
+        y 
+          TableScan
+            alias: y
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -793,7 +793,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2139418033/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-27_948_1334626995431478594/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col1
@@ -829,11 +829,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY v1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1827492210/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-28_074_5978892602968822143/10000
 POSTHOOK: query: SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY v1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1827492210/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-28_074_5978892602968822143/10000
 20	val_20	20	val_20
 PREHOOK: query: EXPLAIN
 SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY x.key
@@ -853,23 +853,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        y 
-          TableScan
-            alias: y
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 1
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
         x 
           TableScan
             alias: x
@@ -891,6 +874,23 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
+        y 
+          TableScan
+            alias: y
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -925,7 +925,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1673626041/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-38_372_3122728094689915036/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -961,11 +961,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1237573825/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-38_466_4207748081161799368/10000
 POSTHOOK: query: SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1237573825/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-38_466_4207748081161799368/10000
 20	val_20	20	val_20
 PREHOOK: query: EXPLAIN
 SELECT x.key, x.value as v1, y.key as yk  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY key
@@ -985,21 +985,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        y 
-          TableScan
-            alias: y
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 1
-              value expressions:
-                    expr: key
-                    type: string
         x 
           TableScan
             alias: x
@@ -1021,6 +1006,21 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
+        y 
+          TableScan
+            alias: y
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: key
+                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -1053,7 +1053,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1226988138/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-47_950_4989736117672479003/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1087,11 +1087,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT x.key, x.value as v1, y.key as yk  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/302591922/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-48_073_5743203719731796760/10000
 POSTHOOK: query: SELECT x.key, x.value as v1, y.key as yk  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/302591922/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-48_073_5743203719731796760/10000
 20	val_20	20
 PREHOOK: query: EXPLAIN
 SELECT unioninput.*
@@ -1225,7 +1225,7 @@ FROM (
 CLUSTER BY unioninput.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/205488295/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-57_574_7730562904986793585/10000
 POSTHOOK: query: SELECT unioninput.*
 FROM (
   FROM src select src.key, src.value WHERE src.key < 100
@@ -1235,7 +1235,7 @@ FROM (
 CLUSTER BY unioninput.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/205488295/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-18-57_574_7730562904986793585/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/ctas.q.out b/ql/src/test/results/clientpositive/ctas.q.out
index 3d8a86ba30..38ca43be6e 100644
--- a/ql/src/test/results/clientpositive/ctas.q.out
+++ b/ql/src/test/results/clientpositive/ctas.q.out
@@ -26,11 +26,11 @@ POSTHOOK: Output: default@nzhang_Tmp
 PREHOOK: query: select * from nzhang_Tmp
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_tmp
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/817024620/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-20_613_7362872865462991076/10000
 POSTHOOK: query: select * from nzhang_Tmp
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_tmp
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/817024620/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-20_613_7362872865462991076/10000
 PREHOOK: query: explain create table nzhang_CTAS1 as select key k, value from src sort by k, value limit 10
 PREHOOK: type: CREATETABLE
 POSTHOOK: query: explain create table nzhang_CTAS1 as select key k, value from src sort by k, value limit 10
@@ -84,7 +84,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/2138410252/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-20_644_5490073691155494254/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -112,7 +112,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:///data/users/jsichi/open/hive-trunk/ql/../build/ql/test/data/warehouse/nzhang_ctas1
+          destination: file:///data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/nzhang_ctas1
 
   Stage: Stage-3
       Create Table Operator:
@@ -136,11 +136,11 @@ POSTHOOK: Output: default@nzhang_CTAS1
 PREHOOK: query: select * from nzhang_CTAS1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_ctas1
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/710958471/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-30_158_5988163105550483771/10000
 POSTHOOK: query: select * from nzhang_CTAS1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_ctas1
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/710958471/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-30_158_5988163105550483771/10000
 0	val_0
 0	val_0
 0	val_0
@@ -204,7 +204,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/305880921/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-30_194_8489626264254862078/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -232,7 +232,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:///data/users/jsichi/open/hive-trunk/ql/../build/ql/test/data/warehouse/nzhang_ctas2
+          destination: file:///data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/nzhang_ctas2
 
   Stage: Stage-3
       Create Table Operator:
@@ -256,11 +256,11 @@ POSTHOOK: Output: default@nzhang_ctas2
 PREHOOK: query: select * from nzhang_ctas2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_ctas2
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1731188757/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-39_797_5455952305307754482/10000
 POSTHOOK: query: select * from nzhang_ctas2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_ctas2
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1731188757/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-39_797_5455952305307754482/10000
 0	val_0
 0	val_0
 0	val_0
@@ -324,7 +324,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/564962024/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-39_831_4392155595765824679/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -352,7 +352,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:///data/users/jsichi/open/hive-trunk/ql/../build/ql/test/data/warehouse/nzhang_ctas3
+          destination: file:///data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/nzhang_ctas3
 
   Stage: Stage-3
       Create Table Operator:
@@ -377,11 +377,11 @@ POSTHOOK: Output: default@nzhang_ctas3
 PREHOOK: query: select * from nzhang_ctas3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_ctas3
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/535377929/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-51_297_1404107458733070450/10000
 POSTHOOK: query: select * from nzhang_ctas3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_ctas3
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/535377929/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-51_297_1404107458733070450/10000
 0.0	val_0_con
 0.0	val_0_con
 0.0	val_0_con
@@ -410,11 +410,11 @@ POSTHOOK: type: CREATETABLE
 PREHOOK: query: select * from nzhang_ctas3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_ctas3
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1725800016/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-51_421_411454597887039980/10000
 POSTHOOK: query: select * from nzhang_ctas3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_ctas3
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1725800016/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-51_421_411454597887039980/10000
 0.0	val_0_con
 0.0	val_0_con
 0.0	val_0_con
@@ -478,7 +478,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/633210786/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-17-51_456_7736262908389950265/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -506,7 +506,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:///data/users/jsichi/open/hive-trunk/ql/../build/ql/test/data/warehouse/nzhang_ctas4
+          destination: file:///data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/nzhang_ctas4
 
   Stage: Stage-3
       Create Table Operator:
@@ -531,11 +531,11 @@ POSTHOOK: Output: default@nzhang_ctas4
 PREHOOK: query: select * from nzhang_ctas4
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_ctas4
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1216389488/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-18-04_556_491115919333585412/10000
 POSTHOOK: query: select * from nzhang_ctas4
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_ctas4
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1216389488/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-18-04_556_491115919333585412/10000
 0	val_0
 0	val_0
 0	val_0
@@ -588,41 +588,41 @@ STAGE PLANS:
                       type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1262135512
+              transient_lastDdlTime 1266041840
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1262135512
+                transient_lastDdlTime 1266041840
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -632,7 +632,7 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1017044863/10002
+              directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-18-04_591_5195160466418251956/10002
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -644,7 +644,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1017044863/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-18-04_591_5195160466418251956/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -660,9 +660,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1017044863/10002 [file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1017044863/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-18-04_591_5195160466418251956/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-18-04_591_5195160466418251956/10002]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1017044863/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-18-04_591_5195160466418251956/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -684,24 +684,24 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1017044863/10001
+              directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-18-04_591_5195160466418251956/10001
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                   properties:
+                    columns _col0,_col1
+                    columns.types string:string
                     field.delim ,
                     line.delim 
 
-                    columns _col0,_col1
                     serialization.format ,
-                    columns.types string:string
 
   Stage: Stage-0
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1017044863/10001
-          destination: file:///data/users/jsichi/open/hive-trunk/ql/../build/ql/test/data/warehouse/nzhang_ctas5
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-18-04_591_5195160466418251956/10001
+          destination: file:///data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/nzhang_ctas5
 
   Stage: Stage-3
       Create Table Operator:
diff --git a/ql/src/test/results/clientpositive/groupby_map_ppr.q.out b/ql/src/test/results/clientpositive/groupby_map_ppr.q.out
index 97b95b1e1d..ae7c18e1d1 100644
--- a/ql/src/test/results/clientpositive/groupby_map_ppr.q.out
+++ b/ql/src/test/results/clientpositive/groupby_map_ppr.q.out
@@ -78,10 +78,10 @@ STAGE PLANS:
                             type: double
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [src]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -90,39 +90,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262135893
+              transient_lastDdlTime 1266042054
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262135893
+                transient_lastDdlTime 1266042054
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -131,35 +131,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262135893
+              transient_lastDdlTime 1266042054
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262135893
+                transient_lastDdlTime 1266042054
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -195,22 +195,22 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
-                directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1077000950/10000
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-20-56_866_3346083160698669953/10000
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
-                      name dest1
+                      bucket_count -1
+                      columns key,c1,c2
                       columns.types string:int:string
+                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                      name dest1
                       serialization.ddl struct dest1 { string key, i32 c1, string c2}
                       serialization.format 1
-                      columns key,c1,c2
-                      bucket_count -1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest1
-                      transient_lastDdlTime 1262135895
+                      transient_lastDdlTime 1266042056
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
@@ -218,25 +218,25 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1077000950/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-20-56_866_3346083160698669953/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,c1,c2
                 columns.types string:int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { string key, i32 c1, string c2}
                 serialization.format 1
-                columns key,c1,c2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1262135895
+                transient_lastDdlTime 1266042056
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1077000950/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-20-56_866_3346083160698669953/10001
 
 
 PREHOOK: query: FROM srcpart src
@@ -260,11 +260,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1579733451/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-21-02_407_3581752610986474753/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1579733451/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-21-02_407_3581752610986474753/10000
 0	1	00.0
 1	71	132828.0
 2	69	251142.0
diff --git a/ql/src/test/results/clientpositive/groupby_ppr.q.out b/ql/src/test/results/clientpositive/groupby_ppr.q.out
index c4b2ba425a..b1030d12f9 100644
--- a/ql/src/test/results/clientpositive/groupby_ppr.q.out
+++ b/ql/src/test/results/clientpositive/groupby_ppr.q.out
@@ -61,10 +61,10 @@ STAGE PLANS:
                     tag: -1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [src]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -73,39 +73,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262135908
+              transient_lastDdlTime 1266042341
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262135908
+                transient_lastDdlTime 1266042341
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -114,35 +114,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262135908
+              transient_lastDdlTime 1266042341
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262135908
+                transient_lastDdlTime 1266042341
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -178,22 +178,22 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
-                directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1636998037/10000
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-25-43_755_1556731248680627580/10000
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
-                      name dest1
+                      bucket_count -1
+                      columns key,c1,c2
                       columns.types string:int:string
+                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                      name dest1
                       serialization.ddl struct dest1 { string key, i32 c1, string c2}
                       serialization.format 1
-                      columns key,c1,c2
-                      bucket_count -1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest1
-                      transient_lastDdlTime 1262135909
+                      transient_lastDdlTime 1266042343
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
@@ -201,25 +201,25 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1636998037/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-25-43_755_1556731248680627580/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,c1,c2
                 columns.types string:int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { string key, i32 c1, string c2}
                 serialization.format 1
-                columns key,c1,c2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1262135909
+                transient_lastDdlTime 1266042343
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1636998037/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-25-43_755_1556731248680627580/10001
 
 
 PREHOOK: query: FROM srcpart src
@@ -243,11 +243,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1831892895/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-25-50_172_6197779811255758201/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1831892895/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-25-50_172_6197779811255758201/10000
 0	1	00.0
 1	71	132828.0
 2	69	251142.0
diff --git a/ql/src/test/results/clientpositive/input23.q.out b/ql/src/test/results/clientpositive/input23.q.out
index df33d4baca..918fffc4a5 100644
--- a/ql/src/test/results/clientpositive/input23.q.out
+++ b/ql/src/test/results/clientpositive/input23.q.out
@@ -15,17 +15,17 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Filter Operator
               isSamplingPred: false
               predicate:
-                  expr: ((ds = '2008-04-08') and (hr = '14'))
+                  expr: ((ds = '2008-04-08') and (hr = '11'))
                   type: boolean
               Reduce Output Operator
                 sort order: 
-                tag: 1
+                tag: 0
                 value expressions:
                       expr: key
                       type: string
@@ -35,17 +35,17 @@ STAGE PLANS:
                       type: string
                       expr: hr
                       type: string
-        a 
+        b 
           TableScan
-            alias: a
+            alias: b
             Filter Operator
               isSamplingPred: false
               predicate:
-                  expr: ((ds = '2008-04-08') and (hr = '11'))
+                  expr: ((ds = '2008-04-08') and (hr = '14'))
                   type: boolean
               Reduce Output Operator
                 sort order: 
-                tag: 0
+                tag: 1
                 value expressions:
                       expr: key
                       type: string
@@ -57,9 +57,9 @@ STAGE PLANS:
                       type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -68,35 +68,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263594755
+              transient_lastDdlTime 1266042110
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263594755
+                transient_lastDdlTime 1266042110
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -137,14 +137,14 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/321107929/10001
+                  directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-21-51_437_3744755035114363805/10001
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       properties:
                         columns _col0,_col1,_col2,_col3,_col4,_col5,_col6,_col7
-                        serialization.format 1
                         columns.types string:string:string:string:string:string:string:string
+                        serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -154,8 +154,8 @@ STAGE PLANS:
 PREHOOK: query: select * from srcpart a join srcpart b where a.ds = '2008-04-08' and a.hr = '11' and b.ds = '2008-04-08' and b.hr = '14' limit 5
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1197797457/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-21-51_620_3570960369359064166/10000
 POSTHOOK: query: select * from srcpart a join srcpart b where a.ds = '2008-04-08' and a.hr = '11' and b.ds = '2008-04-08' and b.hr = '14' limit 5
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1197797457/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-21-51_620_3570960369359064166/10000
diff --git a/ql/src/test/results/clientpositive/input39.q.out b/ql/src/test/results/clientpositive/input39.q.out
index 550ce39a52..c6f74533ad 100644
--- a/ql/src/test/results/clientpositive/input39.q.out
+++ b/ql/src/test/results/clientpositive/input39.q.out
@@ -64,9 +64,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        t2 
+        t1 
           TableScan
-            alias: t2
+            alias: t1
             Filter Operator
               predicate:
                   expr: (((hash(rand(460476415)) & 2147483647) % 32) = 0)
@@ -83,13 +83,13 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 1
+                  tag: 0
                   value expressions:
                         expr: ds
                         type: string
-        t1 
+        t2 
           TableScan
-            alias: t1
+            alias: t2
             Filter Operator
               predicate:
                   expr: (((hash(rand(460476415)) & 2147483647) % 32) = 0)
@@ -106,7 +106,7 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 0
+                  tag: 1
                   value expressions:
                         expr: ds
                         type: string
@@ -140,7 +140,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/746143150/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-21-55_234_8836849389177124348/10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -175,12 +175,12 @@ PREHOOK: query: select count(1) from t1 join t2 on t1.key=t2.key where t1.ds='1'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2@ds=1
 PREHOOK: Input: default@t1@ds=1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/140719442/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-21-55_400_7420820799771241077/10000
 POSTHOOK: query: select count(1) from t1 join t2 on t1.key=t2.key where t1.ds='1' and t2.ds='1'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2@ds=1
 POSTHOOK: Input: default@t1@ds=1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/140719442/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-21-55_400_7420820799771241077/10000
 18
 PREHOOK: query: drop table t1
 PREHOOK: type: DROPTABLE
diff --git a/ql/src/test/results/clientpositive/input42.q.out b/ql/src/test/results/clientpositive/input42.q.out
index d6abcd0d76..2e60aaffba 100644
--- a/ql/src/test/results/clientpositive/input42.q.out
+++ b/ql/src/test/results/clientpositive/input42.q.out
@@ -58,10 +58,10 @@ STAGE PLANS:
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -70,39 +70,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262136165
+              transient_lastDdlTime 1266042168
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262136165
+                transient_lastDdlTime 1266042168
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -111,35 +111,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262136165
+              transient_lastDdlTime 1266042168
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262136165
+                transient_lastDdlTime 1266042168
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -148,14 +148,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/653384588/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-22-50_083_5987307287075246292/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1,_col2,_col3
-                  serialization.format 1
                   columns.types string:string:string:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -166,12 +166,12 @@ PREHOOK: query: select * from srcpart a where a.ds='2008-04-08' order by a.key,
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/660496483/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-22-50_187_1404839540483324648/10000
 POSTHOOK: query: select * from srcpart a where a.ds='2008-04-08' order by a.key, a.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/660496483/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-22-50_187_1404839540483324648/10000
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
@@ -1232,10 +1232,10 @@ STAGE PLANS:
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1244,39 +1244,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262136165
+              transient_lastDdlTime 1266042168
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262136165
+                transient_lastDdlTime 1266042168
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1285,35 +1285,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262136165
+              transient_lastDdlTime 1266042168
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262136165
+                transient_lastDdlTime 1266042168
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -1322,14 +1322,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/137926888/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-22-56_387_6212070635864335639/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1,_col2,_col3
-                  serialization.format 1
                   columns.types string:string:string:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -1340,12 +1340,12 @@ PREHOOK: query: select * from srcpart a where a.ds='2008-04-08' and key < 200 or
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1707392084/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-22-56_499_8219799063447345560/10000
 POSTHOOK: query: select * from srcpart a where a.ds='2008-04-08' and key < 200 order by a.key, a.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1707392084/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-22-56_499_8219799063447345560/10000
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
@@ -1779,10 +1779,10 @@ STAGE PLANS:
                         type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1791,39 +1791,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262136165
+              transient_lastDdlTime 1266042168
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262136165
+                transient_lastDdlTime 1266042168
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1832,35 +1832,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262136165
+              transient_lastDdlTime 1266042168
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262136165
+                transient_lastDdlTime 1266042168
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -1869,14 +1869,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1192619899/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-02_909_2142528471344135922/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1,_col2,_col3
-                  serialization.format 1
                   columns.types string:string:string:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -1887,12 +1887,12 @@ PREHOOK: query: select * from srcpart a where a.ds='2008-04-08' and rand(100) <
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1759846223/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-03_038_191916518361575959/10000
 POSTHOOK: query: select * from srcpart a where a.ds='2008-04-08' and rand(100) < 0.1 order by a.key, a.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1759846223/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-03_038_191916518361575959/10000
 113	val_113	2008-04-08	11
 113	val_113	2008-04-08	12
 118	val_118	2008-04-08	11
diff --git a/ql/src/test/results/clientpositive/input_part1.q.out b/ql/src/test/results/clientpositive/input_part1.q.out
index e94bfbac86..029ed5f90d 100644
--- a/ql/src/test/results/clientpositive/input_part1.q.out
+++ b/ql/src/test/results/clientpositive/input_part1.q.out
@@ -63,29 +63,29 @@ STAGE PLANS:
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/831288775/10002
+                      directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-39_461_7543094684598327579/10002
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                           properties:
-                            name dest1
+                            bucket_count -1
+                            columns key,value,hr,ds
                             columns.types int:string:string:string
+                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                            location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                            name dest1
                             serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                             serialization.format 1
-                            columns key,value,hr,ds
-                            bucket_count -1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                            transient_lastDdlTime 1263594847
+                            transient_lastDdlTime 1266042219
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -94,35 +94,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263594846
+              transient_lastDdlTime 1266042217
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263594846
+                transient_lastDdlTime 1266042217
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -134,37 +134,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/831288775/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1796306525/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-39_461_7543094684598327579/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-39_461_7543094684598327579/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1796306525/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-39_461_7543094684598327579/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value,hr,ds
                 columns.types int:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
-                columns key,value,hr,ds
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263594847
+                transient_lastDdlTime 1266042219
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1796306525/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-39_461_7543094684598327579/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/831288775/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-39_461_7543094684598327579/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -182,41 +182,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/831288775/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/831288775/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-39_461_7543094684598327579/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-39_461_7543094684598327579/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/831288775/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-39_461_7543094684598327579/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest1
+              bucket_count -1
+              columns key,value,hr,ds
               columns.types int:string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+              name dest1
               serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
               serialization.format 1
-              columns key,value,hr,ds
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-              transient_lastDdlTime 1263594847
+              transient_lastDdlTime 1266042219
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value,hr,ds
                 columns.types int:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
-                columns key,value,hr,ds
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263594847
+                transient_lastDdlTime 1266042219
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -225,22 +225,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1796306525/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-39_461_7543094684598327579/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest1
+                  bucket_count -1
+                  columns key,value,hr,ds
                   columns.types int:string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                  name dest1
                   serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                   serialization.format 1
-                  columns key,value,hr,ds
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263594847
+                  transient_lastDdlTime 1266042219
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
@@ -258,11 +258,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1962721854/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-44_035_5017810519060059335/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1962721854/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-44_035_5017810519060059335/10000
 86	val_86	12	2008-04-08
 27	val_27	12	2008-04-08
 98	val_98	12	2008-04-08
diff --git a/ql/src/test/results/clientpositive/input_part2.q.out b/ql/src/test/results/clientpositive/input_part2.q.out
index 2ad5baab66..f8751e39e2 100644
--- a/ql/src/test/results/clientpositive/input_part2.q.out
+++ b/ql/src/test/results/clientpositive/input_part2.q.out
@@ -69,22 +69,22 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10004
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10004
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                         properties:
-                          name dest1
+                          bucket_count -1
+                          columns key,value,hr,ds
                           columns.types int:string:string:string
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+                          name dest1
                           serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                           serialization.format 1
-                          columns key,value,hr,ds
-                          bucket_count -1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-                          transient_lastDdlTime 1263594987
+                          transient_lastDdlTime 1266042178
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
             Filter Operator
@@ -117,30 +117,30 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 2
-                    directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10005
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10005
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                         properties:
-                          name dest2
+                          bucket_count -1
+                          columns key,value,hr,ds
                           columns.types int:string:string:string
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest2
+                          name dest2
                           serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                           serialization.format 1
-                          columns key,value,hr,ds
-                          bucket_count -1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest2
-                          transient_lastDdlTime 1263594987
+                          transient_lastDdlTime 1266042178
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest2
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [srcpart]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [srcpart]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -149,39 +149,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263594985
+              transient_lastDdlTime 1266042176
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263594985
+                transient_lastDdlTime 1266042176
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -190,35 +190,35 @@ STAGE PLANS:
               ds 2008-04-09
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263594985
+              transient_lastDdlTime 1266042176
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263594985
+                transient_lastDdlTime 1266042176
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -230,37 +230,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10004
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1001617674/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10004
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1001617674/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value,hr,ds
                 columns.types int:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
-                columns key,value,hr,ds
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263594987
+                transient_lastDdlTime 1266042178
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1001617674/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10001
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -278,41 +278,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10004 [file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10004]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10004 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10004]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10004 
           Partition
             base file name: 10004
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest1
+              bucket_count -1
+              columns key,value,hr,ds
               columns.types int:string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+              name dest1
               serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
               serialization.format 1
-              columns key,value,hr,ds
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-              transient_lastDdlTime 1263594987
+              transient_lastDdlTime 1266042178
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value,hr,ds
                 columns.types int:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
-                columns key,value,hr,ds
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263594987
+                transient_lastDdlTime 1266042178
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -321,22 +321,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1001617674/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest1
+                  bucket_count -1
+                  columns key,value,hr,ds
                   columns.types int:string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+                  name dest1
                   serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                   serialization.format 1
-                  columns key,value,hr,ds
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263594987
+                  transient_lastDdlTime 1266042178
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
@@ -347,37 +347,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10005
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1001617674/10002
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10005
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10002
 
   Stage: Stage-1
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1001617674/10002
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10002
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest2
+                bucket_count -1
+                columns key,value,hr,ds
                 columns.types int:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest2
+                name dest2
                 serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                 serialization.format 1
-                columns key,value,hr,ds
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest2
-                transient_lastDdlTime 1263594987
+                transient_lastDdlTime 1266042178
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1001617674/10003
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10003
 
   Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10005 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10005 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -395,41 +395,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10005 [file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10005]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10005 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10005]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/107755536/10005 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10005 
           Partition
             base file name: 10005
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest2
+              bucket_count -1
+              columns key,value,hr,ds
               columns.types int:string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest2
+              name dest2
               serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
               serialization.format 1
-              columns key,value,hr,ds
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest2
-              transient_lastDdlTime 1263594987
+              transient_lastDdlTime 1266042178
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest2
+                bucket_count -1
+                columns key,value,hr,ds
                 columns.types int:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest2
+                name dest2
                 serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                 serialization.format 1
-                columns key,value,hr,ds
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest2
-                transient_lastDdlTime 1263594987
+                transient_lastDdlTime 1266042178
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
             name: dest2
@@ -438,22 +438,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1001617674/10002
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-22-58_160_3290303906361814910/10002
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest2
+                  bucket_count -1
+                  columns key,value,hr,ds
                   columns.types int:string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest2
+                  name dest2
                   serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                   serialization.format 1
-                  columns key,value,hr,ds
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest2
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263594987
+                  transient_lastDdlTime 1266042178
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest2
 
@@ -477,11 +477,11 @@ POSTHOOK: Output: default@dest2
 PREHOOK: query: SELECT dest1.* FROM dest1 sort by key,value,ds,hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1922156340/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-23-14_844_814948034581628114/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1 sort by key,value,ds,hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1922156340/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-23-14_844_814948034581628114/10000
 0	val_0	12	2008-04-08
 0	val_0	12	2008-04-08
 0	val_0	12	2008-04-08
@@ -569,11 +569,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/
 PREHOOK: query: SELECT dest2.* FROM dest2 sort by key,value,ds,hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1870373570/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-23-19_982_419302536607069375/10000
 POSTHOOK: query: SELECT dest2.* FROM dest2 sort by key,value,ds,hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1870373570/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-23-19_982_419302536607069375/10000
 0	val_0	12	2008-04-09
 0	val_0	12	2008-04-09
 0	val_0	12	2008-04-09
diff --git a/ql/src/test/results/clientpositive/input_part7.q.out b/ql/src/test/results/clientpositive/input_part7.q.out
index 92ef94a8d8..eaa0065c29 100644
--- a/ql/src/test/results/clientpositive/input_part7.q.out
+++ b/ql/src/test/results/clientpositive/input_part7.q.out
@@ -129,10 +129,10 @@ STAGE PLANS:
                               type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -141,39 +141,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262136303
+              transient_lastDdlTime 1266042226
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262136303
+                transient_lastDdlTime 1266042226
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -182,35 +182,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262136303
+              transient_lastDdlTime 1266042226
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262136303
+                transient_lastDdlTime 1266042226
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -219,14 +219,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/203670455/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-47_452_4084577658557420368/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1,_col2,_col3
-                  serialization.format 1
                   columns.types string:string:string:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -242,7 +242,7 @@ SORT BY A.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/15075603/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-47_642_435591487763370334/10000
 POSTHOOK: query: SELECT * FROM (
   SELECT X.* FROM SRCPART X WHERE X.ds = '2008-04-08' and X.key < 100
   UNION ALL
@@ -252,7 +252,7 @@ SORT BY A.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/15075603/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-23-47_642_435591487763370334/10000
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
diff --git a/ql/src/test/results/clientpositive/input_part9.q.out b/ql/src/test/results/clientpositive/input_part9.q.out
index 2ff537ba76..f6f1e2bc73 100644
--- a/ql/src/test/results/clientpositive/input_part9.q.out
+++ b/ql/src/test/results/clientpositive/input_part9.q.out
@@ -58,10 +58,10 @@ STAGE PLANS:
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [x]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [x]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [x]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [x]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -70,39 +70,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262136311
+              transient_lastDdlTime 1266042561
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262136311
+                transient_lastDdlTime 1266042561
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -111,35 +111,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262136311
+              transient_lastDdlTime 1266042561
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262136311
+                transient_lastDdlTime 1266042561
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -148,14 +148,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1850835970/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-29-22_816_350956197159514250/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1,_col2,_col3
-                  serialization.format 1
                   columns.types string:string:string:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -166,12 +166,12 @@ PREHOOK: query: SELECT x.* FROM SRCPART x WHERE key IS NOT NULL AND ds = '2008-0
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/830534543/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-29-22_924_7820685479167429194/10000
 POSTHOOK: query: SELECT x.* FROM SRCPART x WHERE key IS NOT NULL AND ds = '2008-04-08' order by x.key, x.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/830534543/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-29-22_924_7820685479167429194/10000
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
diff --git a/ql/src/test/results/clientpositive/join0.q.out b/ql/src/test/results/clientpositive/join0.q.out
index 97050a9f50..ba74bcbe68 100644
--- a/ql/src/test/results/clientpositive/join0.q.out
+++ b/ql/src/test/results/clientpositive/join0.q.out
@@ -26,7 +26,7 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2:src 
+        src1:src 
           TableScan
             alias: src
             Filter Operator
@@ -46,13 +46,13 @@ STAGE PLANS:
                   outputColumnNames: _col0, _col1
                   Reduce Output Operator
                     sort order: 
-                    tag: 1
+                    tag: 0
                     value expressions:
                           expr: _col0
                           type: string
                           expr: _col1
                           type: string
-        src1:src 
+        src2:src 
           TableScan
             alias: src
             Filter Operator
@@ -72,7 +72,7 @@ STAGE PLANS:
                   outputColumnNames: _col0, _col1
                   Reduce Output Operator
                     sort order: 
-                    tag: 0
+                    tag: 1
                     value expressions:
                           expr: _col0
                           type: string
@@ -108,7 +108,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1360687261/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-30-01_987_378847351452813940/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -152,7 +152,7 @@ PREHOOK: query: SELECT src1.key as k1, src1.value as v1,
   SORT BY k1, v1, k2, v2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/750163014/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-30-02_064_6413795495820436196/10000
 POSTHOOK: query: SELECT src1.key as k1, src1.value as v1, 
        src2.key as k2, src2.value as v2 FROM 
   (SELECT * FROM src WHERE src.key < 10) src1 
@@ -161,7 +161,7 @@ POSTHOOK: query: SELECT src1.key as k1, src1.value as v1,
   SORT BY k1, v1, k2, v2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/750163014/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-30-02_064_6413795495820436196/10000
 0	val_0	0	val_0
 0	val_0	0	val_0
 0	val_0	0	val_0
diff --git a/ql/src/test/results/clientpositive/join1.q.out b/ql/src/test/results/clientpositive/join1.q.out
index db847ebe2a..b03ae3fedc 100644
--- a/ql/src/test/results/clientpositive/join1.q.out
+++ b/ql/src/test/results/clientpositive/join1.q.out
@@ -22,9 +22,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -33,13 +33,13 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
-                    expr: value
+                    expr: key
                     type: string
-        src1 
+        src2 
           TableScan
-            alias: src1
+            alias: src2
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -48,9 +48,9 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
-                    expr: key
+                    expr: value
                     type: string
       Reduce Operator Tree:
         Join Operator
@@ -108,11 +108,11 @@ POSTHOOK: Output: default@dest_j1
 PREHOOK: query: SELECT dest_j1.* FROM dest_j1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/1811838516/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-17-40_804_3249986716900995170/10000
 POSTHOOK: query: SELECT dest_j1.* FROM dest_j1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/1811838516/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-17-40_804_3249986716900995170/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join11.q.out b/ql/src/test/results/clientpositive/join11.q.out
index 820a287539..4949de7219 100644
--- a/ql/src/test/results/clientpositive/join11.q.out
+++ b/ql/src/test/results/clientpositive/join11.q.out
@@ -25,28 +25,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2:src 
-          TableScan
-            alias: src
-            Select Operator
-              expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
-              outputColumnNames: _col0, _col1
-              Reduce Output Operator
-                key expressions:
-                      expr: _col0
-                      type: string
-                sort order: +
-                Map-reduce partition columns:
-                      expr: _col0
-                      type: string
-                tag: 1
-                value expressions:
-                      expr: _col1
-                      type: string
         src1:src 
           TableScan
             alias: src
@@ -75,6 +53,28 @@ STAGE PLANS:
                     value expressions:
                           expr: _col0
                           type: string
+        src2:src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Reduce Output Operator
+                key expressions:
+                      expr: _col0
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: _col0
+                      type: string
+                tag: 1
+                value expressions:
+                      expr: _col1
+                      type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -111,7 +111,7 @@ JOIN
 ON src1.c1 = src2.c3 AND src1.c1 < 100
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/260035292/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-24-36_568_3358492834632483667/10000
 POSTHOOK: query: SELECT src1.c1, src2.c4 
 FROM
 (SELECT src.key as c1, src.value as c2 from src) src1
@@ -120,7 +120,7 @@ JOIN
 ON src1.c1 = src2.c3 AND src1.c1 < 100
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/260035292/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-24-36_568_3358492834632483667/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join12.q.out b/ql/src/test/results/clientpositive/join12.q.out
index b2ae2c5cde..49cb9ea408 100644
--- a/ql/src/test/results/clientpositive/join12.q.out
+++ b/ql/src/test/results/clientpositive/join12.q.out
@@ -31,28 +31,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2:src 
-          TableScan
-            alias: src
-            Select Operator
-              expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
-              outputColumnNames: _col0, _col1
-              Reduce Output Operator
-                key expressions:
-                      expr: _col0
-                      type: string
-                sort order: +
-                Map-reduce partition columns:
-                      expr: _col0
-                      type: string
-                tag: 1
-                value expressions:
-                      expr: _col1
-                      type: string
         src1:src 
           TableScan
             alias: src
@@ -81,6 +59,28 @@ STAGE PLANS:
                     value expressions:
                           expr: _col0
                           type: string
+        src2:src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Reduce Output Operator
+                key expressions:
+                      expr: _col0
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: _col0
+                      type: string
+                tag: 1
+                value expressions:
+                      expr: _col1
+                      type: string
         src3:src 
           TableScan
             alias: src
@@ -147,7 +147,7 @@ JOIN
 ON src1.c1 = src3.c5 AND src3.c5 < 80
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1310440418/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-30-14_483_6279763267526568065/10000
 POSTHOOK: query: SELECT src1.c1, src2.c4 
 FROM
 (SELECT src.key as c1, src.value as c2 from src) src1
@@ -159,7 +159,7 @@ JOIN
 ON src1.c1 = src3.c5 AND src3.c5 < 80
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1310440418/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-30-14_483_6279763267526568065/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join13.q.out b/ql/src/test/results/clientpositive/join13.q.out
index 56bd75ce32..96402bf4d8 100644
--- a/ql/src/test/results/clientpositive/join13.q.out
+++ b/ql/src/test/results/clientpositive/join13.q.out
@@ -32,30 +32,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2:src 
-          TableScan
-            alias: src
-            Select Operator
-              expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
-              outputColumnNames: _col0, _col1
-              Reduce Output Operator
-                key expressions:
-                      expr: _col0
-                      type: string
-                sort order: +
-                Map-reduce partition columns:
-                      expr: _col0
-                      type: string
-                tag: 1
-                value expressions:
-                      expr: _col0
-                      type: string
-                      expr: _col1
-                      type: string
         src1:src 
           TableScan
             alias: src
@@ -84,6 +60,30 @@ STAGE PLANS:
                     value expressions:
                           expr: _col0
                           type: string
+        src2:src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Reduce Output Operator
+                key expressions:
+                      expr: _col0
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: _col0
+                      type: string
+                tag: 1
+                value expressions:
+                      expr: _col0
+                      type: string
+                      expr: _col1
+                      type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -182,7 +182,7 @@ JOIN
 ON src1.c1 + src2.c3 = src3.c5 AND src3.c5 < 200
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1529824154/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-24-22_511_6362399474373258851/10000
 POSTHOOK: query: SELECT src1.c1, src2.c4 
 FROM
 (SELECT src.key as c1, src.value as c2 from src) src1
@@ -194,7 +194,7 @@ JOIN
 ON src1.c1 + src2.c3 = src3.c5 AND src3.c5 < 200
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1529824154/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-24-22_511_6362399474373258851/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join14.q.out b/ql/src/test/results/clientpositive/join14.q.out
index ebaa288ca9..154ca2ab8d 100644
--- a/ql/src/test/results/clientpositive/join14.q.out
+++ b/ql/src/test/results/clientpositive/join14.q.out
@@ -22,16 +22,16 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        srcpart 
+        src 
           TableScan
-            alias: srcpart
+            alias: src
             Filter Operator
               predicate:
-                  expr: (ds = '2008-04-08')
+                  expr: (key > 100)
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (ds = '2008-04-08')
+                    expr: (key > 100)
                     type: boolean
                 Reduce Output Operator
                   key expressions:
@@ -41,20 +41,20 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 1
+                  tag: 0
                   value expressions:
-                        expr: value
+                        expr: key
                         type: string
-        src 
+        srcpart 
           TableScan
-            alias: src
+            alias: srcpart
             Filter Operator
               predicate:
-                  expr: (key > 100)
+                  expr: (ds = '2008-04-08')
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (key > 100)
+                    expr: (ds = '2008-04-08')
                     type: boolean
                 Reduce Output Operator
                   key expressions:
@@ -64,9 +64,9 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 0
+                  tag: 1
                   value expressions:
-                        expr: key
+                        expr: value
                         type: string
       Reduce Operator Tree:
         Join Operator
@@ -128,11 +128,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: select dest1.* from dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1542443503/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-24-57_029_61831322772510839/10000
 POSTHOOK: query: select dest1.* from dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1542443503/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-24-57_029_61831322772510839/10000
 103	val_103
 103	val_103
 103	val_103
diff --git a/ql/src/test/results/clientpositive/join15.q.out b/ql/src/test/results/clientpositive/join15.q.out
index eb461d885e..58084336a5 100644
--- a/ql/src/test/results/clientpositive/join15.q.out
+++ b/ql/src/test/results/clientpositive/join15.q.out
@@ -16,9 +16,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -27,15 +27,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
                     expr: value
                     type: string
-        src1 
+        src2 
           TableScan
-            alias: src1
+            alias: src2
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -44,7 +44,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
@@ -80,7 +80,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/212163259/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-30-21_183_948882797719366544/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -119,11 +119,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT * FROM src src1 JOIN src src2 ON (src1.key = src2.key) SORT BY src1.key, src1.value, src2.key, src2.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/2059374846/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-30-21_248_3435930164448606808/10000
 POSTHOOK: query: SELECT * FROM src src1 JOIN src src2 ON (src1.key = src2.key) SORT BY src1.key, src1.value, src2.key, src2.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/2059374846/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-30-21_248_3435930164448606808/10000
 0	val_0	0	val_0
 0	val_0	0	val_0
 0	val_0	0	val_0
diff --git a/ql/src/test/results/clientpositive/join17.q.out b/ql/src/test/results/clientpositive/join17.q.out
index 84d192d3d0..c5d7b10dc6 100644
--- a/ql/src/test/results/clientpositive/join17.q.out
+++ b/ql/src/test/results/clientpositive/join17.q.out
@@ -22,9 +22,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -33,15 +33,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
                     expr: value
                     type: string
-        src1 
+        src2 
           TableScan
-            alias: src1
+            alias: src2
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -50,7 +50,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
@@ -58,41 +58,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src [src2, src1]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src [src2, src1]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595094
+              transient_lastDdlTime 1266042298
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595094
+                transient_lastDdlTime 1266042298
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -130,22 +130,22 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2068626019/10000
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-24-58_888_2283102940218435935/10000
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
-                      name dest1
+                      bucket_count -1
+                      columns key1,value1,key2,value2
                       columns.types int:string:int:string
+                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+                      name dest1
                       serialization.ddl struct dest1 { i32 key1, string value1, i32 key2, string value2}
                       serialization.format 1
-                      columns key1,value1,key2,value2
-                      bucket_count -1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-                      transient_lastDdlTime 1263595094
+                      transient_lastDdlTime 1266042298
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
@@ -153,25 +153,25 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2068626019/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-24-58_888_2283102940218435935/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key1,value1,key2,value2
                 columns.types int:string:int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key1, string value1, i32 key2, string value2}
                 serialization.format 1
-                columns key1,value1,key2,value2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595094
+                transient_lastDdlTime 1266042298
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2068626019/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-24-58_888_2283102940218435935/10001
 
 
 PREHOOK: query: FROM src src1 JOIN src src2 ON (src1.key = src2.key)
@@ -187,11 +187,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/239373431/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-07_300_5780434119628581188/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/239373431/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-07_300_5780434119628581188/10000
 0	val_0	0	val_0
 0	val_0	0	val_0
 0	val_0	0	val_0
diff --git a/ql/src/test/results/clientpositive/join19.q.out b/ql/src/test/results/clientpositive/join19.q.out
index eb7ec199f7..93b86c61fa 100644
--- a/ql/src/test/results/clientpositive/join19.q.out
+++ b/ql/src/test/results/clientpositive/join19.q.out
@@ -132,24 +132,22 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        t22:t2 
+        t11:t1 
           TableScan
-            alias: t2
+            alias: t1
             Filter Operator
               predicate:
-                  expr: (predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL')
+                  expr: ((predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') and (object = 'http://ontos/OntosMiner/Common.English/ontology#Citation'))
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL')
+                    expr: ((predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') and (object = 'http://ontos/OntosMiner/Common.English/ontology#Citation'))
                     type: boolean
                 Select Operator
                   expressions:
                         expr: subject
                         type: string
-                        expr: object
-                        type: string
-                  outputColumnNames: _col0, _col1
+                  outputColumnNames: _col0
                   Reduce Output Operator
                     key expressions:
                           expr: _col0
@@ -158,20 +156,20 @@ STAGE PLANS:
                     Map-reduce partition columns:
                           expr: _col0
                           type: string
-                    tag: 1
+                    tag: 0
                     value expressions:
-                          expr: _col1
+                          expr: _col0
                           type: string
-        t33:t3 
+        t22:t2 
           TableScan
-            alias: t3
+            alias: t2
             Filter Operator
               predicate:
-                  expr: (predicate = 'http://www.ontosearch.com/2007/12/ontosofa-ns#_from')
+                  expr: (predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL')
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (predicate = 'http://www.ontosearch.com/2007/12/ontosofa-ns#_from')
+                    expr: (predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL')
                     type: boolean
                 Select Operator
                   expressions:
@@ -182,41 +180,43 @@ STAGE PLANS:
                   outputColumnNames: _col0, _col1
                   Reduce Output Operator
                     key expressions:
-                          expr: _col1
+                          expr: _col0
                           type: string
                     sort order: +
                     Map-reduce partition columns:
-                          expr: _col1
+                          expr: _col0
                           type: string
-                    tag: 2
+                    tag: 1
                     value expressions:
-                          expr: _col0
+                          expr: _col1
                           type: string
-        t11:t1 
+        t33:t3 
           TableScan
-            alias: t1
+            alias: t3
             Filter Operator
               predicate:
-                  expr: ((predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') and (object = 'http://ontos/OntosMiner/Common.English/ontology#Citation'))
+                  expr: (predicate = 'http://www.ontosearch.com/2007/12/ontosofa-ns#_from')
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: ((predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') and (object = 'http://ontos/OntosMiner/Common.English/ontology#Citation'))
+                    expr: (predicate = 'http://www.ontosearch.com/2007/12/ontosofa-ns#_from')
                     type: boolean
                 Select Operator
                   expressions:
                         expr: subject
                         type: string
-                  outputColumnNames: _col0
+                        expr: object
+                        type: string
+                  outputColumnNames: _col0, _col1
                   Reduce Output Operator
                     key expressions:
-                          expr: _col0
+                          expr: _col1
                           type: string
                     sort order: +
                     Map-reduce partition columns:
-                          expr: _col0
+                          expr: _col1
                           type: string
-                    tag: 0
+                    tag: 2
                     value expressions:
                           expr: _col0
                           type: string
@@ -258,24 +258,22 @@ STAGE PLANS:
                     type: string
                     expr: _col2
                     type: string
-        t55:t5 
+        t44:t4 
           TableScan
-            alias: t5
+            alias: t4
             Filter Operator
               predicate:
-                  expr: (predicate = 'http://www.ontosearch.com/2007/12/ontosofa-ns#_to')
+                  expr: ((predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') and (object = 'http://ontos/OntosMiner/Common.English/ontology#Author'))
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (predicate = 'http://www.ontosearch.com/2007/12/ontosofa-ns#_to')
+                    expr: ((predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') and (object = 'http://ontos/OntosMiner/Common.English/ontology#Author'))
                     type: boolean
                 Select Operator
                   expressions:
                         expr: subject
                         type: string
-                        expr: object
-                        type: string
-                  outputColumnNames: _col0, _col1
+                  outputColumnNames: _col0
                   Reduce Output Operator
                     key expressions:
                           expr: _col0
@@ -284,26 +282,25 @@ STAGE PLANS:
                     Map-reduce partition columns:
                           expr: _col0
                           type: string
-                    tag: 2
-                    value expressions:
-                          expr: _col1
-                          type: string
-        t44:t4 
+                    tag: 1
+        t55:t5 
           TableScan
-            alias: t4
+            alias: t5
             Filter Operator
               predicate:
-                  expr: ((predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') and (object = 'http://ontos/OntosMiner/Common.English/ontology#Author'))
+                  expr: (predicate = 'http://www.ontosearch.com/2007/12/ontosofa-ns#_to')
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: ((predicate = 'http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') and (object = 'http://ontos/OntosMiner/Common.English/ontology#Author'))
+                    expr: (predicate = 'http://www.ontosearch.com/2007/12/ontosofa-ns#_to')
                     type: boolean
                 Select Operator
                   expressions:
                         expr: subject
                         type: string
-                  outputColumnNames: _col0
+                        expr: object
+                        type: string
+                  outputColumnNames: _col0, _col1
                   Reduce Output Operator
                     key expressions:
                           expr: _col0
@@ -312,7 +309,10 @@ STAGE PLANS:
                     Map-reduce partition columns:
                           expr: _col0
                           type: string
-                    tag: 1
+                    tag: 2
+                    value expressions:
+                          expr: _col1
+                          type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -334,6 +334,25 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        $INTNAME 
+            Reduce Output Operator
+              key expressions:
+                    expr: _col7
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: _col7
+                    type: string
+              tag: 0
+              value expressions:
+                    expr: _col0
+                    type: string
+                    expr: _col2
+                    type: string
+                    expr: _col4
+                    type: string
+                    expr: _col7
+                    type: string
         t66:t6 
           TableScan
             alias: t6
@@ -364,25 +383,6 @@ STAGE PLANS:
                     value expressions:
                           expr: _col1
                           type: string
-        $INTNAME 
-            Reduce Output Operator
-              key expressions:
-                    expr: _col7
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: _col7
-                    type: string
-              tag: 0
-              value expressions:
-                    expr: _col0
-                    type: string
-                    expr: _col2
-                    type: string
-                    expr: _col4
-                    type: string
-                    expr: _col7
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
diff --git a/ql/src/test/results/clientpositive/join2.q.out b/ql/src/test/results/clientpositive/join2.q.out
index f436ff2b28..384d536633 100644
--- a/ql/src/test/results/clientpositive/join2.q.out
+++ b/ql/src/test/results/clientpositive/join2.q.out
@@ -23,9 +23,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -34,13 +34,13 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
-        src1 
+        src2 
           TableScan
-            alias: src1
+            alias: src2
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -49,7 +49,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
@@ -156,11 +156,11 @@ POSTHOOK: Output: default@dest_j2
 PREHOOK: query: SELECT dest_j2.* FROM dest_j2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/1881195843/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-17-58_450_8546758638899574985/10000
 POSTHOOK: query: SELECT dest_j2.* FROM dest_j2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/1881195843/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-17-58_450_8546758638899574985/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join20.q.out b/ql/src/test/results/clientpositive/join20.q.out
index 622539fa0b..5be4e528a0 100644
--- a/ql/src/test/results/clientpositive/join20.q.out
+++ b/ql/src/test/results/clientpositive/join20.q.out
@@ -18,6 +18,31 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        src1 
+          TableScan
+            alias: src1
+            Filter Operator
+              predicate:
+                  expr: (key < 10)
+                  type: boolean
+              Filter Operator
+                predicate:
+                    expr: (key < 10)
+                    type: boolean
+                Reduce Output Operator
+                  key expressions:
+                        expr: key
+                        type: string
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: key
+                        type: string
+                  tag: 0
+                  value expressions:
+                        expr: key
+                        type: string
+                        expr: value
+                        type: string
         src2 
           TableScan
             alias: src2
@@ -60,31 +85,6 @@ STAGE PLANS:
                         type: string
                         expr: value
                         type: string
-        src1 
-          TableScan
-            alias: src1
-            Filter Operator
-              predicate:
-                  expr: (key < 10)
-                  type: boolean
-              Filter Operator
-                predicate:
-                    expr: (key < 10)
-                    type: boolean
-                Reduce Output Operator
-                  key expressions:
-                        expr: key
-                        type: string
-                  sort order: +
-                  Map-reduce partition columns:
-                        expr: key
-                        type: string
-                  tag: 0
-                  value expressions:
-                        expr: key
-                        type: string
-                        expr: value
-                        type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -121,7 +121,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/594913173/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-09_103_5553608276311636631/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -169,12 +169,12 @@ PREHOOK: query: SELECT * FROM src src1 JOIN src src2 ON (src1.key = src2.key AND
 SORT BY src1.key, src1.value, src2.key, src2.value, src3.key, src3.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1700561117/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-09_304_7244044251030204334/10000
 POSTHOOK: query: SELECT * FROM src src1 JOIN src src2 ON (src1.key = src2.key AND src1.key < 10) RIGHT OUTER JOIN src src3 ON (src1.key = src3.key AND src3.key < 20)
 SORT BY src1.key, src1.value, src2.key, src2.value, src3.key, src3.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1700561117/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-09_304_7244044251030204334/10000
 NULL	NULL	NULL	NULL	10	val_10
 NULL	NULL	NULL	NULL	11	val_11
 NULL	NULL	NULL	NULL	12	val_12
@@ -263,16 +263,16 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Filter Operator
               predicate:
-                  expr: (key < 15)
+                  expr: (key < 10)
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (key < 15)
+                    expr: (key < 10)
                     type: boolean
                 Reduce Output Operator
                   key expressions:
@@ -282,22 +282,22 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 1
+                  tag: 0
                   value expressions:
                         expr: key
                         type: string
                         expr: value
                         type: string
-        src3 
+        src2 
           TableScan
-            alias: src3
+            alias: src2
             Filter Operator
               predicate:
-                  expr: (key < 20)
+                  expr: (key < 15)
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (key < 20)
+                    expr: (key < 15)
                     type: boolean
                 Reduce Output Operator
                   key expressions:
@@ -307,22 +307,22 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 2
+                  tag: 1
                   value expressions:
                         expr: key
                         type: string
                         expr: value
                         type: string
-        src1 
+        src3 
           TableScan
-            alias: src1
+            alias: src3
             Filter Operator
               predicate:
-                  expr: (key < 10)
+                  expr: (key < 20)
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (key < 10)
+                    expr: (key < 20)
                     type: boolean
                 Reduce Output Operator
                   key expressions:
@@ -332,7 +332,7 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 0
+                  tag: 2
                   value expressions:
                         expr: key
                         type: string
@@ -374,7 +374,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/242851899/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-22_555_4999429669680122202/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -422,12 +422,12 @@ PREHOOK: query: SELECT * FROM src src1 JOIN src src2 ON (src1.key = src2.key AND
 SORT BY src1.key, src1.value, src2.key, src2.value, src3.key, src3.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/199285759/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-23_062_6871589272542309559/10000
 POSTHOOK: query: SELECT * FROM src src1 JOIN src src2 ON (src1.key = src2.key AND src1.key < 10 AND src2.key < 15) RIGHT OUTER JOIN src src3 ON (src1.key = src3.key AND src3.key < 20)
 SORT BY src1.key, src1.value, src2.key, src2.value, src3.key, src3.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/199285759/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-23_062_6871589272542309559/10000
 NULL	NULL	NULL	NULL	10	val_10
 NULL	NULL	NULL	NULL	11	val_11
 NULL	NULL	NULL	NULL	12	val_12
diff --git a/ql/src/test/results/clientpositive/join21.q.out b/ql/src/test/results/clientpositive/join21.q.out
index 3b8c5c5f7c..c752186c3e 100644
--- a/ql/src/test/results/clientpositive/join21.q.out
+++ b/ql/src/test/results/clientpositive/join21.q.out
@@ -16,16 +16,16 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Filter Operator
               predicate:
-                  expr: (key > 10)
+                  expr: (key < 10)
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (key > 10)
+                    expr: (key < 10)
                     type: boolean
                 Reduce Output Operator
                   key expressions:
@@ -35,22 +35,22 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 1
+                  tag: 0
                   value expressions:
                         expr: key
                         type: string
                         expr: value
                         type: string
-        src3 
+        src2 
           TableScan
-            alias: src3
+            alias: src2
             Filter Operator
               predicate:
-                  expr: (key < 10)
+                  expr: (key > 10)
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (key < 10)
+                    expr: (key > 10)
                     type: boolean
                 Reduce Output Operator
                   key expressions:
@@ -60,15 +60,15 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 2
+                  tag: 1
                   value expressions:
                         expr: key
                         type: string
                         expr: value
                         type: string
-        src1 
+        src3 
           TableScan
-            alias: src1
+            alias: src3
             Filter Operator
               predicate:
                   expr: (key < 10)
@@ -85,7 +85,7 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 0
+                  tag: 2
                   value expressions:
                         expr: key
                         type: string
@@ -127,7 +127,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/620739292/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-30-50_757_6674241851636354509/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -174,11 +174,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT * FROM src src1 LEFT OUTER JOIN src src2 ON (src1.key = src2.key AND src1.key < 10 AND src2.key > 10) RIGHT OUTER JOIN src src3 ON (src2.key = src3.key AND src3.key < 10) SORT BY src1.key, src1.value, src2.key, src2.value, src3.key, src3.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1999188733/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-30-50_859_8353481196273925065/10000
 POSTHOOK: query: SELECT * FROM src src1 LEFT OUTER JOIN src src2 ON (src1.key = src2.key AND src1.key < 10 AND src2.key > 10) RIGHT OUTER JOIN src src3 ON (src2.key = src3.key AND src3.key < 10) SORT BY src1.key, src1.value, src2.key, src2.value, src3.key, src3.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1999188733/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-30-50_859_8353481196273925065/10000
 NULL	NULL	NULL	NULL	0	val_0
 NULL	NULL	NULL	NULL	0	val_0
 NULL	NULL	NULL	NULL	0	val_0
diff --git a/ql/src/test/results/clientpositive/join22.q.out b/ql/src/test/results/clientpositive/join22.q.out
index 8776d7872e..3c77191b2e 100644
--- a/ql/src/test/results/clientpositive/join22.q.out
+++ b/ql/src/test/results/clientpositive/join22.q.out
@@ -16,9 +16,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src5:src3:src2 
+        src5:src3:src1 
           TableScan
-            alias: src2
+            alias: src1
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -27,10 +27,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
-        src5:src3:src1 
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+        src5:src3:src2 
           TableScan
-            alias: src1
+            alias: src2
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -39,12 +44,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
+              tag: 1
       Reduce Operator Tree:
         Join Operator
           condition map:
diff --git a/ql/src/test/results/clientpositive/join23.q.out b/ql/src/test/results/clientpositive/join23.q.out
index 184b51065e..862c088644 100644
--- a/ql/src/test/results/clientpositive/join23.q.out
+++ b/ql/src/test/results/clientpositive/join23.q.out
@@ -16,31 +16,31 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Filter Operator
               predicate:
                   expr: (key < 10)
                   type: boolean
               Reduce Output Operator
                 sort order: 
-                tag: 1
+                tag: 0
                 value expressions:
                       expr: key
                       type: string
                       expr: value
                       type: string
-        src1 
+        src2 
           TableScan
-            alias: src1
+            alias: src2
             Filter Operator
               predicate:
                   expr: (key < 10)
                   type: boolean
               Reduce Output Operator
                 sort order: 
-                tag: 0
+                tag: 1
                 value expressions:
                       expr: key
                       type: string
@@ -80,7 +80,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/940616134/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-36_446_1826455278011043613/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -119,11 +119,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT *  FROM src src1 JOIN src src2 WHERE src1.key < 10 and src2.key < 10 SORT BY src1.key, src1.value, src2.key, src2.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1998501029/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-36_531_8232686612566853333/10000
 POSTHOOK: query: SELECT *  FROM src src1 JOIN src src2 WHERE src1.key < 10 and src2.key < 10 SORT BY src1.key, src1.value, src2.key, src2.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1998501029/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-36_531_8232686612566853333/10000
 0	val_0	0	val_0
 0	val_0	0	val_0
 0	val_0	0	val_0
diff --git a/ql/src/test/results/clientpositive/join26.q.out b/ql/src/test/results/clientpositive/join26.q.out
index 731f10a27f..931201c863 100644
--- a/ql/src/test/results/clientpositive/join26.q.out
+++ b/ql/src/test/results/clientpositive/join26.q.out
@@ -83,37 +83,37 @@ STAGE PLANS:
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1528572413/10002
+                          directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10002
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                               properties:
-                                name dest_j1
+                                bucket_count -1
+                                columns key,value,val2
                                 columns.types string:string:string
+                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                                name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
-                                columns key,value,val2
-                                bucket_count -1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                                transient_lastDdlTime 1263595132
+                                transient_lastDdlTime 1266042347
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
-            y 
+            x 
               Fetch Operator
                 limit: -1
-            x 
+            y 
               Fetch Operator
                 limit: -1
           Alias -> Map Local Operator Tree:
-            y 
+            x 
               TableScan
-                alias: y
+                alias: x
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -150,27 +150,27 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1528572413/10002
+                        directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10002
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                             properties:
-                              name dest_j1
+                              bucket_count -1
+                              columns key,value,val2
                               columns.types string:string:string
+                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                              name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
-                              columns key,value,val2
-                              bucket_count -1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                              transient_lastDdlTime 1263595132
+                              transient_lastDdlTime 1266042347
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
-            x 
+            y 
               TableScan
-                alias: x
+                alias: y
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -207,29 +207,29 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1528572413/10002
+                        directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10002
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                             properties:
-                              name dest_j1
+                              bucket_count -1
+                              columns key,value,val2
                               columns.types string:string:string
+                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                              name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
-                              columns key,value,val2
-                              bucket_count -1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                              transient_lastDdlTime 1263595132
+                              transient_lastDdlTime 1266042347
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -238,35 +238,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595131
+              transient_lastDdlTime 1266042345
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595131
+                transient_lastDdlTime 1266042345
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -278,37 +278,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1528572413/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/903798776/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/903798776/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263595132
+                transient_lastDdlTime 1266042347
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/903798776/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1528572413/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -324,41 +324,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1528572413/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1528572413/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1528572413/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest_j1
+              bucket_count -1
+              columns key,value,val2
               columns.types string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+              name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
-              columns key,value,val2
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-              transient_lastDdlTime 1263595132
+              transient_lastDdlTime 1266042347
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263595132
+                transient_lastDdlTime 1266042347
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -367,22 +367,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/903798776/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-47_168_8539251329177814415/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest_j1
+                  bucket_count -1
+                  columns key,value,val2
                   columns.types string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                  name dest_j1
                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                   serialization.format 1
-                  columns key,value,val2
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595132
+                  transient_lastDdlTime 1266042347
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
 
@@ -408,11 +408,11 @@ POSTHOOK: Output: default@dest_j1
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1540819743/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-54_275_1841484256774557968/10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1540819743/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-25-54_275_1841484256774557968/10000
 128	val_128	val_128
 128	val_128	val_128
 128	val_128	val_128
diff --git a/ql/src/test/results/clientpositive/join3.q.out b/ql/src/test/results/clientpositive/join3.q.out
index 87630b946e..4e12f48404 100644
--- a/ql/src/test/results/clientpositive/join3.q.out
+++ b/ql/src/test/results/clientpositive/join3.q.out
@@ -22,9 +22,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -33,10 +33,13 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
-        src3 
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: string
+        src2 
           TableScan
-            alias: src3
+            alias: src2
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -45,13 +48,10 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 2
-              value expressions:
-                    expr: value
-                    type: string
-        src1 
+              tag: 1
+        src3 
           TableScan
-            alias: src1
+            alias: src3
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -60,9 +60,9 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 2
               value expressions:
-                    expr: key
+                    expr: value
                     type: string
       Reduce Operator Tree:
         Join Operator
@@ -122,11 +122,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/1795601827/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-11_028_5305709121053771635/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/1795601827/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-11_028_5305709121053771635/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join32.q.out b/ql/src/test/results/clientpositive/join32.q.out
index 670420486b..ee5340f4ce 100644
--- a/ql/src/test/results/clientpositive/join32.q.out
+++ b/ql/src/test/results/clientpositive/join32.q.out
@@ -48,7 +48,7 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10003
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10003
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -81,7 +81,7 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10003
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10003
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -91,41 +91,41 @@ STAGE PLANS:
                           escape.delim \
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src [y]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src [y]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595164
+              transient_lastDdlTime 1266042380
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595164
+                transient_lastDdlTime 1266042380
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -133,7 +133,7 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10003 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10003 
           Select Operator
             expressions:
                   expr: _col0
@@ -176,22 +176,22 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10002
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10002
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                         properties:
-                          name dest_j1
+                          bucket_count -1
+                          columns key,value,val2
                           columns.types string:string:string
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                          name dest_j1
                           serialization.ddl struct dest_j1 { string key, string value, string val2}
                           serialization.format 1
-                          columns key,value,val2
-                          bucket_count -1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                          transient_lastDdlTime 1263595164
+                          transient_lastDdlTime 1266042381
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest_j1
       Local Work:
@@ -252,29 +252,29 @@ STAGE PLANS:
                             File Output Operator
                               compressed: false
                               GlobalTableId: 1
-                              directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10002
+                              directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10002
                               table:
                                   input format: org.apache.hadoop.mapred.TextInputFormat
                                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                   properties:
-                                    name dest_j1
+                                    bucket_count -1
+                                    columns key,value,val2
                                     columns.types string:string:string
+                                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                    location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                                    name dest_j1
                                     serialization.ddl struct dest_j1 { string key, string value, string val2}
                                     serialization.format 1
-                                    columns key,value,val2
-                                    bucket_count -1
                                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                    location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                                    transient_lastDdlTime 1263595164
+                                    transient_lastDdlTime 1266042381
                                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                   name: dest_j1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10003 [file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10003]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10003 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10003]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10003 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10003 
           Partition
             base file name: 10003
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -298,37 +298,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1239641781/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1239641781/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263595164
+                transient_lastDdlTime 1266042381
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1239641781/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -344,41 +344,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1756119899/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest_j1
+              bucket_count -1
+              columns key,value,val2
               columns.types string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+              name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
-              columns key,value,val2
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-              transient_lastDdlTime 1263595164
+              transient_lastDdlTime 1266042381
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263595164
+                transient_lastDdlTime 1266042381
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -387,22 +387,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1239641781/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-21_312_667079337759159900/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest_j1
+                  bucket_count -1
+                  columns key,value,val2
                   columns.types string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                  name dest_j1
                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                   serialization.format 1
-                  columns key,value,val2
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595164
+                  transient_lastDdlTime 1266042381
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
 
@@ -428,11 +428,11 @@ POSTHOOK: Output: default@dest_j1
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1862420925/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-34_536_8912960588309137072/10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1862420925/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-34_536_8912960588309137072/10000
 146	val_146	val_146
 146	val_146	val_146
 146	val_146	val_146
diff --git a/ql/src/test/results/clientpositive/join33.q.out b/ql/src/test/results/clientpositive/join33.q.out
index f485bc37f7..2fad0f82a6 100644
--- a/ql/src/test/results/clientpositive/join33.q.out
+++ b/ql/src/test/results/clientpositive/join33.q.out
@@ -45,7 +45,7 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1171659403/10002
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-31-47_413_4824327140450726271/10002
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -78,7 +78,7 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1171659403/10002
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-31-47_413_4824327140450726271/10002
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -88,41 +88,41 @@ STAGE PLANS:
                           escape.delim \
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src [y]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src [y]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595101
+              transient_lastDdlTime 1266042707
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595101
+                transient_lastDdlTime 1266042707
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -130,6 +130,30 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-31-47_413_4824327140450726271/10002 
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: string
+                  expr: _col3
+                  type: string
+            outputColumnNames: _col0, _col1, _col3
+            Reduce Output Operator
+              key expressions:
+                    expr: _col1
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: _col1
+                    type: string
+              tag: 0
+              value expressions:
+                    expr: _col3
+                    type: string
+                    expr: _col0
+                    type: string
         z 
           TableScan
             alias: z
@@ -160,36 +184,28 @@ STAGE PLANS:
                     value expressions:
                           expr: value
                           type: string
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1171659403/10002 
-          Select Operator
-            expressions:
-                  expr: _col0
-                  type: string
-                  expr: _col1
-                  type: string
-                  expr: _col3
-                  type: string
-            outputColumnNames: _col0, _col1, _col3
-            Reduce Output Operator
-              key expressions:
-                    expr: _col1
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: _col1
-                    type: string
-              tag: 0
-              value expressions:
-                    expr: _col3
-                    type: string
-                    expr: _col0
-                    type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1171659403/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1171659403/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-31-47_413_4824327140450726271/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-31-47_413_4824327140450726271/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-31-47_413_4824327140450726271/10002 
+          Partition
+            base file name: 10002
+            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+            properties:
+              columns _col0,_col1,_col3
+              columns.types string,string,string
+              escape.delim \
+          
+              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+              properties:
+                columns _col0,_col1,_col3
+                columns.types string,string,string
+                escape.delim \
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -198,54 +214,38 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595100
+              transient_lastDdlTime 1266042706
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595100
+                transient_lastDdlTime 1266042706
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1171659403/10002 
-          Partition
-            base file name: 10002
-            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-            properties:
-              columns _col0,_col1,_col3
-              columns.types string,string,string
-              escape.delim \
-          
-              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-              properties:
-                columns _col0,_col1,_col3
-                columns.types string,string,string
-                escape.delim \
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -267,22 +267,22 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/919822712/10000
+              directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-31-47_413_4824327140450726271/10000
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                   properties:
-                    name dest_j1
+                    bucket_count -1
+                    columns key,value,val2
                     columns.types string:string:string
+                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                    name dest_j1
                     serialization.ddl struct dest_j1 { string key, string value, string val2}
                     serialization.format 1
-                    columns key,value,val2
-                    bucket_count -1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                    transient_lastDdlTime 1263595101
+                    transient_lastDdlTime 1266042707
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest_j1
 
@@ -290,25 +290,25 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/919822712/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-31-47_413_4824327140450726271/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263595101
+                transient_lastDdlTime 1266042707
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/919822712/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-31-47_413_4824327140450726271/10001
 
 
 PREHOOK: query: INSERT OVERWRITE TABLE dest_j1
@@ -332,11 +332,11 @@ POSTHOOK: Output: default@dest_j1
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/707876168/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-31-58_456_5777333185975150161/10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/707876168/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-31-58_456_5777333185975150161/10000
 146	val_146	val_146
 146	val_146	val_146
 146	val_146	val_146
diff --git a/ql/src/test/results/clientpositive/join34.q.out b/ql/src/test/results/clientpositive/join34.q.out
index be6d493d6b..0c84a3deec 100644
--- a/ql/src/test/results/clientpositive/join34.q.out
+++ b/ql/src/test/results/clientpositive/join34.q.out
@@ -95,22 +95,22 @@ STAGE PLANS:
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2117134462/10002
+                            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10002
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                 properties:
-                                  name dest_j1
+                                  bucket_count -1
+                                  columns key,value,val2
                                   columns.types string:string:string
+                                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest_j1
+                                  name dest_j1
                                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                                   serialization.format 1
-                                  columns key,value,val2
-                                  bucket_count -1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest_j1
-                                  transient_lastDdlTime 1263594960
+                                  transient_lastDdlTime 1266042355
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: dest_j1
         null-subquery2:subq1-subquery2:x1 
@@ -167,22 +167,22 @@ STAGE PLANS:
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2117134462/10002
+                            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10002
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                 properties:
-                                  name dest_j1
+                                  bucket_count -1
+                                  columns key,value,val2
                                   columns.types string:string:string
+                                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest_j1
+                                  name dest_j1
                                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                                   serialization.format 1
-                                  columns key,value,val2
-                                  bucket_count -1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest_j1
-                                  transient_lastDdlTime 1263594960
+                                  transient_lastDdlTime 1266042355
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: dest_j1
       Local Work:
@@ -228,61 +228,61 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2117134462/10002
+                        directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10002
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                             properties:
-                              name dest_j1
+                              bucket_count -1
+                              columns key,value,val2
                               columns.types string:string:string
+                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest_j1
+                              name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
-                              columns key,value,val2
-                              bucket_count -1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest_j1
-                              transient_lastDdlTime 1263594960
+                              transient_lastDdlTime 1266042355
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x, null-subquery2:subq1-subquery2:x1]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x, null-subquery2:subq1-subquery2:x1]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263594959
+              transient_lastDdlTime 1266042355
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263594959
+                transient_lastDdlTime 1266042355
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -294,37 +294,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2117134462/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1735776239/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1735776239/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263594960
+                transient_lastDdlTime 1266042355
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1735776239/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2117134462/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -340,41 +340,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2117134462/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2117134462/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2117134462/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest_j1
+              bucket_count -1
+              columns key,value,val2
               columns.types string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest_j1
+              name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
-              columns key,value,val2
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest_j1
-              transient_lastDdlTime 1263594960
+              transient_lastDdlTime 1266042355
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263594960
+                transient_lastDdlTime 1266042355
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -383,22 +383,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1735776239/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-25-55_529_1278857091346859060/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest_j1
+                  bucket_count -1
+                  columns key,value,val2
                   columns.types string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest_j1
+                  name dest_j1
                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                   serialization.format 1
-                  columns key,value,val2
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest_j1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263594960
+                  transient_lastDdlTime 1266042355
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
 
@@ -430,11 +430,11 @@ POSTHOOK: Output: default@dest_j1
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2143694309/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-01_734_5254976174840967601/10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2143694309/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-01_734_5254976174840967601/10000
 128		val_128
 128		val_128
 128		val_128
diff --git a/ql/src/test/results/clientpositive/join35.q.out b/ql/src/test/results/clientpositive/join35.q.out
index bf51f9d5f1..c68d8da7a9 100644
--- a/ql/src/test/results/clientpositive/join35.q.out
+++ b/ql/src/test/results/clientpositive/join35.q.out
@@ -84,41 +84,41 @@ STAGE PLANS:
                             type: bigint
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595178
+              transient_lastDdlTime 1266042400
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595178
+                transient_lastDdlTime 1266042400
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -142,7 +142,7 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10002
+              directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10002
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -154,7 +154,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10002 
           Union
             Common Join Operator
               condition map:
@@ -198,25 +198,25 @@ STAGE PLANS:
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10003
+                      directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10003
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                           properties:
-                            name dest_j1
+                            bucket_count -1
+                            columns key,value,val2
                             columns.types string:string:int
+                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                            location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                            name dest_j1
                             serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                             serialization.format 1
-                            columns key,value,val2
-                            bucket_count -1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                            transient_lastDdlTime 1263595178
+                            transient_lastDdlTime 1266042401
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest_j1
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10004 
           Union
             Common Join Operator
               condition map:
@@ -260,22 +260,22 @@ STAGE PLANS:
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10003
+                      directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10003
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                           properties:
-                            name dest_j1
+                            bucket_count -1
+                            columns key,value,val2
                             columns.types string:string:int
+                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                            location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                            name dest_j1
                             serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                             serialization.format 1
-                            columns key,value,val2
-                            bucket_count -1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                            transient_lastDdlTime 1263595178
+                            transient_lastDdlTime 1266042401
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest_j1
       Local Work:
@@ -330,30 +330,30 @@ STAGE PLANS:
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10003
+                          directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10003
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                               properties:
-                                name dest_j1
+                                bucket_count -1
+                                columns key,value,val2
                                 columns.types string:string:int
+                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                                name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                                 serialization.format 1
-                                columns key,value,val2
-                                bucket_count -1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                                transient_lastDdlTime 1263595178
+                                transient_lastDdlTime 1266042401
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10002]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10004 [file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10004]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10004 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10004]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -369,7 +369,7 @@ STAGE PLANS:
                 columns _col0,_col1
                 columns.types string,bigint
                 escape.delim \
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10004 
           Partition
             base file name: 10004
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -393,37 +393,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10003
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/604913670/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10003
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/604913670/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:int
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263595178
+                transient_lastDdlTime 1266042401
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/604913670/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10001
 
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10003 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10003 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -439,41 +439,41 @@ STAGE PLANS:
                     type: int
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10003 [file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10003]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10003 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10003]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10003 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10003 
           Partition
             base file name: 10003
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest_j1
+              bucket_count -1
+              columns key,value,val2
               columns.types string:string:int
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+              name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, i32 val2}
               serialization.format 1
-              columns key,value,val2
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-              transient_lastDdlTime 1263595178
+              transient_lastDdlTime 1266042401
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:int
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263595178
+                transient_lastDdlTime 1266042401
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -482,22 +482,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/604913670/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest_j1
+                  bucket_count -1
+                  columns key,value,val2
                   columns.types string:string:int
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest_j1
+                  name dest_j1
                   serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                   serialization.format 1
-                  columns key,value,val2
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest_j1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595178
+                  transient_lastDdlTime 1266042401
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
 
@@ -545,41 +545,41 @@ STAGE PLANS:
                             type: bigint
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src [null-subquery2:subq1-subquery2:x1]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src [null-subquery2:subq1-subquery2:x1]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595178
+              transient_lastDdlTime 1266042400
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595178
+                transient_lastDdlTime 1266042400
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -603,7 +603,7 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1737821238/10004
+              directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-26-41_348_1323659698923150253/10004
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -640,11 +640,11 @@ POSTHOOK: Output: default@dest_j1
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/942115762/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-27-04_511_3697707095560966784/10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/942115762/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-27-04_511_3697707095560966784/10000
 128		3
 146	val_146	2
 150	val_150	1
diff --git a/ql/src/test/results/clientpositive/join40.q.out b/ql/src/test/results/clientpositive/join40.q.out
index f39460a5dc..d594006003 100644
--- a/ql/src/test/results/clientpositive/join40.q.out
+++ b/ql/src/test/results/clientpositive/join40.q.out
@@ -100,12 +100,12 @@ PREHOOK: query: SELECT x.key, x.value, y.key, y.value
 FROM src x left outer JOIN (select * from src where key <= 100) y ON (x.key = y.key)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1249230133/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-20_375_8739608897771687968/10000
 POSTHOOK: query: SELECT x.key, x.value, y.key, y.value
 FROM src x left outer JOIN (select * from src where key <= 100) y ON (x.key = y.key)
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1249230133/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-20_375_8739608897771687968/10000
 0	val_0	0	val_0
 0	val_0	0	val_0
 0	val_0	0	val_0
@@ -689,9 +689,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -700,13 +700,13 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
-                    expr: value
+                    expr: key
                     type: string
-        src1 
+        src2 
           TableScan
-            alias: src1
+            alias: src2
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -715,9 +715,9 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
-                    expr: key
+                    expr: value
                     type: string
       Reduce Operator Tree:
         Join Operator
@@ -751,12 +751,12 @@ PREHOOK: query: select src1.key, src2.value
 FROM src src1 JOIN src src2 ON (src1.key = src2.key)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1169404066/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-28_099_8963486530334152093/10000
 POSTHOOK: query: select src1.key, src2.value 
 FROM src src1 JOIN src src2 ON (src1.key = src2.key)
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1169404066/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-28_099_8963486530334152093/10000
 0	val_0
 0	val_0
 0	val_0
@@ -1805,6 +1805,31 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        src1 
+          TableScan
+            alias: src1
+            Filter Operator
+              predicate:
+                  expr: (key < 10)
+                  type: boolean
+              Filter Operator
+                predicate:
+                    expr: (key < 10)
+                    type: boolean
+                Reduce Output Operator
+                  key expressions:
+                        expr: key
+                        type: string
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: key
+                        type: string
+                  tag: 0
+                  value expressions:
+                        expr: key
+                        type: string
+                        expr: value
+                        type: string
         src2 
           TableScan
             alias: src2
@@ -1847,31 +1872,6 @@ STAGE PLANS:
                         type: string
                         expr: value
                         type: string
-        src1 
-          TableScan
-            alias: src1
-            Filter Operator
-              predicate:
-                  expr: (key < 10)
-                  type: boolean
-              Filter Operator
-                predicate:
-                    expr: (key < 10)
-                    type: boolean
-                Reduce Output Operator
-                  key expressions:
-                        expr: key
-                        type: string
-                  sort order: +
-                  Map-reduce partition columns:
-                        expr: key
-                        type: string
-                  tag: 0
-                  value expressions:
-                        expr: key
-                        type: string
-                        expr: value
-                        type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -1908,7 +1908,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1836147411/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-35_615_2133554865043548038/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1956,12 +1956,12 @@ PREHOOK: query: SELECT * FROM src src1 JOIN src src2 ON (src1.key = src2.key AND
 SORT BY src1.key, src1.value, src2.key, src2.value, src3.key, src3.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/561269019/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-35_711_5635391210022763694/10000
 POSTHOOK: query: SELECT * FROM src src1 JOIN src src2 ON (src1.key = src2.key AND src1.key < 10) RIGHT OUTER JOIN src src3 ON (src1.key = src3.key AND src3.key < 20)
 SORT BY src1.key, src1.value, src2.key, src2.value, src3.key, src3.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/561269019/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-35_711_5635391210022763694/10000
 NULL	NULL	NULL	NULL	10	val_10
 NULL	NULL	NULL	NULL	11	val_11
 NULL	NULL	NULL	NULL	12	val_12
@@ -2050,16 +2050,16 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Filter Operator
               predicate:
-                  expr: (key < 15)
+                  expr: (key < 10)
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (key < 15)
+                    expr: (key < 10)
                     type: boolean
                 Reduce Output Operator
                   key expressions:
@@ -2069,22 +2069,22 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 1
+                  tag: 0
                   value expressions:
                         expr: key
                         type: string
                         expr: value
                         type: string
-        src3 
+        src2 
           TableScan
-            alias: src3
+            alias: src2
             Filter Operator
               predicate:
-                  expr: (key < 20)
+                  expr: (key < 15)
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (key < 20)
+                    expr: (key < 15)
                     type: boolean
                 Reduce Output Operator
                   key expressions:
@@ -2094,22 +2094,22 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 2
+                  tag: 1
                   value expressions:
                         expr: key
                         type: string
                         expr: value
                         type: string
-        src1 
+        src3 
           TableScan
-            alias: src1
+            alias: src3
             Filter Operator
               predicate:
-                  expr: (key < 10)
+                  expr: (key < 20)
                   type: boolean
               Filter Operator
                 predicate:
-                    expr: (key < 10)
+                    expr: (key < 20)
                     type: boolean
                 Reduce Output Operator
                   key expressions:
@@ -2119,7 +2119,7 @@ STAGE PLANS:
                   Map-reduce partition columns:
                         expr: key
                         type: string
-                  tag: 0
+                  tag: 2
                   value expressions:
                         expr: key
                         type: string
@@ -2161,7 +2161,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1889892039/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-47_526_7396170302427973294/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -2209,12 +2209,12 @@ PREHOOK: query: SELECT * FROM src src1 JOIN src src2 ON (src1.key = src2.key AND
 SORT BY src1.key, src1.value, src2.key, src2.value, src3.key, src3.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1597568732/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-47_626_1855366263501057105/10000
 POSTHOOK: query: SELECT * FROM src src1 JOIN src src2 ON (src1.key = src2.key AND src1.key < 10 AND src2.key < 15) RIGHT OUTER JOIN src src3 ON (src1.key = src3.key AND src3.key < 20)
 SORT BY src1.key, src1.value, src2.key, src2.value, src3.key, src3.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1597568732/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-47_626_1855366263501057105/10000
 NULL	NULL	NULL	NULL	10	val_10
 NULL	NULL	NULL	NULL	11	val_11
 NULL	NULL	NULL	NULL	12	val_12
@@ -2420,12 +2420,12 @@ PREHOOK: query: SELECT /*+ MAPJOIN(y) */ x.key, x.value, y.key, y.value
 FROM src x left outer JOIN (select * from src where key <= 100) y ON (x.key = y.key)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/302774741/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-58_663_5257751854137888714/10000
 POSTHOOK: query: SELECT /*+ MAPJOIN(y) */ x.key, x.value, y.key, y.value
 FROM src x left outer JOIN (select * from src where key <= 100) y ON (x.key = y.key)
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/302774741/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-26-58_663_5257751854137888714/10000
 238	val_238	NULL	NULL
 86	val_86	86	val_86
 311	val_311	NULL	NULL
@@ -3010,9 +3010,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -3021,10 +3021,10 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
-        a 
+              tag: 0
+        b 
           TableScan
-            alias: a
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -3033,7 +3033,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -3059,7 +3059,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1375711979/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-07_552_3382271159548134599/10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -3093,9 +3093,9 @@ STAGE PLANS:
 PREHOOK: query: SELECT COUNT(1) FROM SRC A JOIN SRC B ON (A.KEY=B.KEY)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/991321663/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-07_618_4569452327751615405/10000
 POSTHOOK: query: SELECT COUNT(1) FROM SRC A JOIN SRC B ON (A.KEY=B.KEY)
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/991321663/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-07_618_4569452327751615405/10000
 1028
diff --git a/ql/src/test/results/clientpositive/join9.q.out b/ql/src/test/results/clientpositive/join9.q.out
index 31e09ba415..fc7506fa60 100644
--- a/ql/src/test/results/clientpositive/join9.q.out
+++ b/ql/src/test/results/clientpositive/join9.q.out
@@ -22,21 +22,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
-          TableScan
-            alias: src2
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 1
-              value expressions:
-                    expr: value
-                    type: string
         src1 
           TableScan
             alias: src1
@@ -61,48 +46,63 @@ STAGE PLANS:
                       type: string
                       expr: hr
                       type: string
+        src2 
+          TableScan
+            alias: src2
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: value
+                    type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/src [src2]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src1]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src [src2]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src1]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595040
+              transient_lastDdlTime 1266042448
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595040
+                transient_lastDdlTime 1266042448
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -111,35 +111,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595039
+              transient_lastDdlTime 1266042447
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595039
+                transient_lastDdlTime 1266042447
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -174,22 +174,22 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1485975294/10000
+                  directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-29_246_1645987373446132683/10000
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       properties:
-                        name dest1
+                        bucket_count -1
+                        columns key,value
                         columns.types int:string
+                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                        file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                        location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                        name dest1
                         serialization.ddl struct dest1 { i32 key, string value}
                         serialization.format 1
-                        columns key,value
-                        bucket_count -1
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                        transient_lastDdlTime 1263595040
+                        transient_lastDdlTime 1266042449
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
 
@@ -197,25 +197,25 @@ STAGE PLANS:
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1485975294/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-29_246_1645987373446132683/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value
                 columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595040
+                transient_lastDdlTime 1266042449
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1485975294/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-29_246_1645987373446132683/10001
 
 
 PREHOOK: query: FROM srcpart src1 JOIN src src2 ON (src1.key = src2.key)
@@ -233,11 +233,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1050075230/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-36_266_8910979444835173818/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1050075230/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-36_266_8910979444835173818/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join_hive_626.q.out b/ql/src/test/results/clientpositive/join_hive_626.q.out
index 7712ce5974..d4eb21f680 100644
--- a/ql/src/test/results/clientpositive/join_hive_626.q.out
+++ b/ql/src/test/results/clientpositive/join_hive_626.q.out
@@ -70,9 +70,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        hive_foo 
+        hive_bar 
           TableScan
-            alias: hive_foo
+            alias: hive_bar
             Reduce Output Operator
               key expressions:
                     expr: foo_id
@@ -81,13 +81,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: foo_id
                     type: int
-              tag: 0
+              tag: 1
               value expressions:
-                    expr: foo_name
+                    expr: bar_id
+                    type: int
+                    expr: bar_name
                     type: string
-        hive_bar 
+        hive_foo 
           TableScan
-            alias: hive_bar
+            alias: hive_foo
             Reduce Output Operator
               key expressions:
                     expr: foo_id
@@ -96,11 +98,9 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: foo_id
                     type: int
-              tag: 1
+              tag: 0
               value expressions:
-                    expr: bar_id
-                    type: int
-                    expr: bar_name
+                    expr: foo_name
                     type: string
       Reduce Operator Tree:
         Join Operator
@@ -187,14 +187,14 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@hive_foo
 PREHOOK: Input: default@hive_count
 PREHOOK: Input: default@hive_bar
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/462225223/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-27-47_249_881439767445940507/10000
 POSTHOOK: query: select hive_foo.foo_name, hive_bar.bar_name, n from hive_foo join hive_bar on hive_foo.foo_id =
 hive_bar.foo_id join hive_count on hive_count.bar_id = hive_bar.bar_id
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@hive_foo
 POSTHOOK: Input: default@hive_count
 POSTHOOK: Input: default@hive_bar
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/462225223/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-27-47_249_881439767445940507/10000
 foo1	bar10	2
 PREHOOK: query: drop table hive_foo
 PREHOOK: type: DROPTABLE
diff --git a/ql/src/test/results/clientpositive/join_map_ppr.q.out b/ql/src/test/results/clientpositive/join_map_ppr.q.out
index 8c11eba4c6..f33e8f4f95 100644
--- a/ql/src/test/results/clientpositive/join_map_ppr.q.out
+++ b/ql/src/test/results/clientpositive/join_map_ppr.q.out
@@ -84,37 +84,37 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1886349005/10002
+                        directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10002
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                             properties:
-                              name dest_j1
+                              bucket_count -1
+                              columns key,value,val2
                               columns.types string:string:string
+                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                              name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
-                              columns key,value,val2
-                              bucket_count -1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                              transient_lastDdlTime 1263595165
+                              transient_lastDdlTime 1266042780
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
-            y 
+            x 
               Fetch Operator
                 limit: -1
-            x 
+            y 
               Fetch Operator
                 limit: -1
           Alias -> Map Local Operator Tree:
-            y 
+            x 
               TableScan
-                alias: y
+                alias: x
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -160,27 +160,27 @@ STAGE PLANS:
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1886349005/10002
+                          directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10002
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                               properties:
-                                name dest_j1
+                                bucket_count -1
+                                columns key,value,val2
                                 columns.types string:string:string
+                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                                name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
-                                columns key,value,val2
-                                bucket_count -1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                                transient_lastDdlTime 1263595165
+                                transient_lastDdlTime 1266042780
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
-            x 
+            y 
               TableScan
-                alias: x
+                alias: y
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -226,29 +226,29 @@ STAGE PLANS:
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1886349005/10002
+                          directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10002
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                               properties:
-                                name dest_j1
+                                bucket_count -1
+                                columns key,value,val2
                                 columns.types string:string:string
+                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                                name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
-                                columns key,value,val2
-                                bucket_count -1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                                transient_lastDdlTime 1263595165
+                                transient_lastDdlTime 1266042780
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -257,35 +257,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595164
+              transient_lastDdlTime 1266042778
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595164
+                transient_lastDdlTime 1266042778
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -297,37 +297,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1886349005/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/141026855/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/141026855/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263595165
+                transient_lastDdlTime 1266042780
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/141026855/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1886349005/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -343,41 +343,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1886349005/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1886349005/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1886349005/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest_j1
+              bucket_count -1
+              columns key,value,val2
               columns.types string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+              name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
-              columns key,value,val2
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-              transient_lastDdlTime 1263595165
+              transient_lastDdlTime 1266042780
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263595165
+                transient_lastDdlTime 1266042780
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -386,22 +386,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/141026855/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-00_399_352290245960327717/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest_j1
+                  bucket_count -1
+                  columns key,value,val2
                   columns.types string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                  name dest_j1
                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                   serialization.format 1
-                  columns key,value,val2
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595165
+                  transient_lastDdlTime 1266042780
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
 
@@ -429,11 +429,11 @@ POSTHOOK: Output: default@dest_j1
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/886762969/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-06_516_3338852843532728387/10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/886762969/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-06_516_3338852843532728387/10000
 128	val_128	val_128
 128	val_128	val_128
 128	val_128	val_128
@@ -648,37 +648,37 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1775434766/10002
+                        directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10002
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                             properties:
-                              name dest_j1
+                              bucket_count -1
+                              columns key,value,val2
                               columns.types string:string:string
+                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                              name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
-                              columns key,value,val2
-                              bucket_count -1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                              transient_lastDdlTime 1263595165
+                              transient_lastDdlTime 1266042780
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
-            y 
+            x 
               Fetch Operator
                 limit: -1
-            x 
+            y 
               Fetch Operator
                 limit: -1
           Alias -> Map Local Operator Tree:
-            y 
+            x 
               TableScan
-                alias: y
+                alias: x
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -724,27 +724,27 @@ STAGE PLANS:
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1775434766/10002
+                          directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10002
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                               properties:
-                                name dest_j1
+                                bucket_count -1
+                                columns key,value,val2
                                 columns.types string:string:string
+                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                                name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
-                                columns key,value,val2
-                                bucket_count -1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                                transient_lastDdlTime 1263595165
+                                transient_lastDdlTime 1266042780
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
-            x 
+            y 
               TableScan
-                alias: x
+                alias: y
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -790,29 +790,29 @@ STAGE PLANS:
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1775434766/10002
+                          directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10002
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                               properties:
-                                name dest_j1
+                                bucket_count -1
+                                columns key,value,val2
                                 columns.types string:string:string
+                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                                name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
-                                columns key,value,val2
-                                bucket_count -1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                                transient_lastDdlTime 1263595165
+                                transient_lastDdlTime 1266042780
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -821,35 +821,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595164
+              transient_lastDdlTime 1266042778
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595164
+                transient_lastDdlTime 1266042778
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -861,37 +861,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1775434766/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1505671688/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1505671688/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263595165
+                transient_lastDdlTime 1266042780
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1505671688/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1775434766/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -907,41 +907,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1775434766/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1775434766/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1775434766/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest_j1
+              bucket_count -1
+              columns key,value,val2
               columns.types string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+              name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
-              columns key,value,val2
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-              transient_lastDdlTime 1263595165
+              transient_lastDdlTime 1266042780
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest_j1
+                bucket_count -1
+                columns key,value,val2
                 columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
-                columns key,value,val2
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                transient_lastDdlTime 1263595165
+                transient_lastDdlTime 1266042780
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -950,22 +950,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1505671688/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-20_130_2089622276113662506/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest_j1
+                  bucket_count -1
+                  columns key,value,val2
                   columns.types string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest_j1
+                  name dest_j1
                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                   serialization.format 1
-                  columns key,value,val2
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest_j1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595165
+                  transient_lastDdlTime 1266042780
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
 
@@ -993,11 +993,11 @@ POSTHOOK: Output: default@dest_j1
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/877753191/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-26_697_820182467019293566/10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/877753191/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-26_697_820182467019293566/10000
 128	val_128	val_128
 128	val_128	val_128
 128	val_128	val_128
diff --git a/ql/src/test/results/clientpositive/join_rc.q.out b/ql/src/test/results/clientpositive/join_rc.q.out
index 33112da23b..059ce0fac8 100644
--- a/ql/src/test/results/clientpositive/join_rc.q.out
+++ b/ql/src/test/results/clientpositive/join_rc.q.out
@@ -51,9 +51,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        join_rc2 
+        join_rc1 
           TableScan
-            alias: join_rc2
+            alias: join_rc1
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -62,13 +62,13 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
-                    expr: value
+                    expr: key
                     type: string
-        join_rc1 
+        join_rc2 
           TableScan
-            alias: join_rc1
+            alias: join_rc2
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -77,9 +77,9 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
-                    expr: key
+                    expr: value
                     type: string
       Reduce Operator Tree:
         Join Operator
@@ -114,13 +114,13 @@ FROM join_rc1 JOIN join_rc2 ON join_rc1.key = join_rc2.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@join_rc2
 PREHOOK: Input: default@join_rc1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1138840055/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-47_640_1441550174396831657/10000
 POSTHOOK: query: select join_rc1.key, join_rc2.value
 FROM join_rc1 JOIN join_rc2 ON join_rc1.key = join_rc2.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@join_rc2
 POSTHOOK: Input: default@join_rc1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1138840055/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-47_640_1441550174396831657/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join_reorder.q.out b/ql/src/test/results/clientpositive/join_reorder.q.out
index ec8f38f1cf..895de9fc36 100644
--- a/ql/src/test/results/clientpositive/join_reorder.q.out
+++ b/ql/src/test/results/clientpositive/join_reorder.q.out
@@ -57,38 +57,38 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        c 
+        a 
           TableScan
-            alias: c
+            alias: a
             Reduce Output Operator
               key expressions:
-                    expr: (key + 1)
+                    expr: UDFToDouble(key)
                     type: double
               sort order: +
               Map-reduce partition columns:
-                    expr: (key + 1)
+                    expr: UDFToDouble(key)
                     type: double
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
-        a 
+                    expr: val
+                    type: string
+        c 
           TableScan
-            alias: a
+            alias: c
             Reduce Output Operator
               key expressions:
-                    expr: UDFToDouble(key)
+                    expr: (key + 1)
                     type: double
               sort order: +
               Map-reduce partition columns:
-                    expr: UDFToDouble(key)
+                    expr: (key + 1)
                     type: double
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
-                    expr: val
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -136,38 +136,38 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        c 
+        a 
           TableScan
-            alias: c
+            alias: a
             Reduce Output Operator
               key expressions:
-                    expr: (key + 1)
+                    expr: UDFToDouble(key)
                     type: double
               sort order: +
               Map-reduce partition columns:
-                    expr: (key + 1)
+                    expr: UDFToDouble(key)
                     type: double
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
-        a 
+                    expr: val
+                    type: string
+        c 
           TableScan
-            alias: a
+            alias: c
             Reduce Output Operator
               key expressions:
-                    expr: UDFToDouble(key)
+                    expr: (key + 1)
                     type: double
               sort order: +
               Map-reduce partition columns:
-                    expr: UDFToDouble(key)
+                    expr: (key + 1)
                     type: double
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
-                    expr: val
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -203,13 +203,13 @@ SELECT a.key, a.val, c.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1966956520/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-56_522_2427479678690495417/10000
 POSTHOOK: query: FROM T1 a JOIN src c ON c.key+1=a.key
 SELECT a.key, a.val, c.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1966956520/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-27-56_522_2427479678690495417/10000
 1	11	0
 1	11	0
 1	11	0
@@ -219,13 +219,13 @@ SELECT /*+ STREAMTABLE(a) */ a.key, a.val, c.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2092123428/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-28-01_499_4645186819885871483/10000
 POSTHOOK: query: FROM T1 a JOIN src c ON c.key+1=a.key
 SELECT /*+ STREAMTABLE(a) */ a.key, a.val, c.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2092123428/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-28-01_499_4645186819885871483/10000
 1	11	0
 1	11	0
 1	11	0
@@ -252,9 +252,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -263,13 +263,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
-        a 
+                    expr: val
+                    type: string
+        b 
           TableScan
-            alias: a
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -278,12 +280,10 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
-                    expr: val
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -389,9 +389,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -400,13 +400,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
-        a 
+                    expr: val
+                    type: string
+        b 
           TableScan
-            alias: a
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -415,12 +417,10 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
-                    expr: val
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -512,7 +512,7 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1966669209/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-28-07_922_2294786151582488765/10000
 POSTHOOK: query: FROM T1 a
   LEFT OUTER JOIN T2 b ON (b.key=a.key)
   RIGHT OUTER JOIN T3 c ON (c.val = a.val)
@@ -521,7 +521,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1966669209/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-28-07_922_2294786151582488765/10000
 2	2	12	12
 NULL	NULL	NULL	14
 NULL	NULL	NULL	16
@@ -534,7 +534,7 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2040128444/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-28-20_301_8638454003102682278/10000
 POSTHOOK: query: FROM T1 a
   LEFT OUTER JOIN T2 b ON (b.key=a.key)
   RIGHT OUTER JOIN T3 c ON (c.val = a.val)
@@ -543,7 +543,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2040128444/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-28-20_301_8638454003102682278/10000
 2	2	12	12
 NULL	NULL	NULL	14
 NULL	NULL	NULL	16
@@ -571,9 +571,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -586,13 +586,13 @@ STAGE PLANS:
                     type: string
                     expr: val
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
-        c 
+        b 
           TableScan
-            alias: c
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -605,13 +605,13 @@ STAGE PLANS:
                     type: string
                     expr: val
                     type: string
-              tag: 2
+              tag: 1
               value expressions:
                     expr: key
                     type: string
-        a 
+        c 
           TableScan
-            alias: a
+            alias: c
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -624,7 +624,7 @@ STAGE PLANS:
                     type: string
                     expr: val
                     type: string
-              tag: 0
+              tag: 2
               value expressions:
                     expr: key
                     type: string
@@ -683,9 +683,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -698,13 +698,13 @@ STAGE PLANS:
                     type: string
                     expr: val
                     type: string
-              tag: 2
+              tag: 0
               value expressions:
                     expr: key
                     type: string
-        c 
+        b 
           TableScan
-            alias: c
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -717,13 +717,13 @@ STAGE PLANS:
                     type: string
                     expr: val
                     type: string
-              tag: 1
+              tag: 2
               value expressions:
                     expr: key
                     type: string
-        a 
+        c 
           TableScan
-            alias: a
+            alias: c
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -736,7 +736,7 @@ STAGE PLANS:
                     type: string
                     expr: val
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
@@ -781,7 +781,7 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/685649783/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-28-31_833_1632343405751503469/10000
 POSTHOOK: query: FROM UNIQUEJOIN
   PRESERVE T1 a (a.key, a.val),
   PRESERVE T2 b (b.key, b.val),
@@ -791,7 +791,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/685649783/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-28-31_833_1632343405751503469/10000
 1	NULL	NULL
 2	NULL	2
 NULL	2	NULL
@@ -812,7 +812,7 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1834964794/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-28-38_626_3188343531104185080/10000
 POSTHOOK: query: FROM UNIQUEJOIN
   PRESERVE T1 a (a.key, a.val),
   PRESERVE T2 b (b.key, b.val),
@@ -822,7 +822,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1834964794/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-28-38_626_3188343531104185080/10000
 1	NULL	NULL
 2	NULL	2
 NULL	2	NULL
diff --git a/ql/src/test/results/clientpositive/join_reorder2.q.out b/ql/src/test/results/clientpositive/join_reorder2.q.out
index 0d2cd45742..a67aacfb26 100644
--- a/ql/src/test/results/clientpositive/join_reorder2.q.out
+++ b/ql/src/test/results/clientpositive/join_reorder2.q.out
@@ -77,9 +77,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        d 
+        a 
           TableScan
-            alias: d
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -88,7 +88,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 3
               value expressions:
                     expr: key
                     type: string
@@ -128,9 +128,9 @@ STAGE PLANS:
                     type: string
                     expr: val
                     type: string
-        a 
+        d 
           TableScan
-            alias: a
+            alias: d
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -139,7 +139,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 3
+              tag: 0
               value expressions:
                     expr: key
                     type: string
@@ -198,7 +198,7 @@ PREHOOK: Input: default@t4
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1499291437/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-28-02_101_1898487455882506837/10000
 POSTHOOK: query: SELECT /*+ STREAMTABLE(a) */ *
 FROM T1 a JOIN T2 b ON a.key = b.key
           JOIN T3 c ON b.key = c.key
@@ -208,7 +208,7 @@ POSTHOOK: Input: default@t4
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1499291437/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-28-02_101_1898487455882506837/10000
 2	12	2	22	2	12	2	12
 PREHOOK: query: EXPLAIN
 SELECT /*+ STREAMTABLE(a) */ *
@@ -235,9 +235,9 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -246,15 +246,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
                     expr: val
                     type: string
-        a 
+        b 
           TableScan
-            alias: a
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -263,7 +263,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
@@ -343,23 +343,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        d 
-          TableScan
-            alias: d
-            Reduce Output Operator
-              key expressions:
-                    expr: (key + 1)
-                    type: double
-              sort order: +
-              Map-reduce partition columns:
-                    expr: (key + 1)
-                    type: double
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: val
-                    type: string
         $INTNAME 
             Reduce Output Operator
               key expressions:
@@ -383,6 +366,23 @@ STAGE PLANS:
                     type: string
                     expr: _col3
                     type: string
+        d 
+          TableScan
+            alias: d
+            Reduce Output Operator
+              key expressions:
+                    expr: (key + 1)
+                    type: double
+              sort order: +
+              Map-reduce partition columns:
+                    expr: (key + 1)
+                    type: double
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: val
+                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -431,7 +431,7 @@ PREHOOK: Input: default@t4
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/347443381/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-28-09_022_5817489663400235377/10000
 POSTHOOK: query: SELECT /*+ STREAMTABLE(a) */ *
 FROM T1 a JOIN T2 b ON a.key = b.key
           JOIN T3 c ON a.val = c.val
@@ -441,7 +441,7 @@ POSTHOOK: Input: default@t4
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/347443381/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-28-09_022_5817489663400235377/10000
 2	22	2	12	2	12	2	12
 PREHOOK: query: DROP TABLE T1
 PREHOOK: type: DROPTABLE
diff --git a/ql/src/test/results/clientpositive/join_reorder3.q.out b/ql/src/test/results/clientpositive/join_reorder3.q.out
index 8bf692337a..566719cc1b 100644
--- a/ql/src/test/results/clientpositive/join_reorder3.q.out
+++ b/ql/src/test/results/clientpositive/join_reorder3.q.out
@@ -77,9 +77,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        d 
+        a 
           TableScan
-            alias: d
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -88,7 +88,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 3
               value expressions:
                     expr: key
                     type: string
@@ -128,9 +128,9 @@ STAGE PLANS:
                     type: string
                     expr: val
                     type: string
-        a 
+        d 
           TableScan
-            alias: a
+            alias: d
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -139,7 +139,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 3
+              tag: 0
               value expressions:
                     expr: key
                     type: string
@@ -198,7 +198,7 @@ PREHOOK: Input: default@t4
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/922482225/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-34_907_1935969450376975821/10000
 POSTHOOK: query: SELECT /*+ STREAMTABLE(a,c) */ *
 FROM T1 a JOIN T2 b ON a.key = b.key
           JOIN T3 c ON b.key = c.key
@@ -208,7 +208,7 @@ POSTHOOK: Input: default@t4
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/922482225/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-34_907_1935969450376975821/10000
 2	12	2	22	2	12	2	12
 PREHOOK: query: EXPLAIN
 SELECT /*+ STREAMTABLE(a,c) */ *
@@ -235,9 +235,9 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -246,15 +246,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
                     expr: val
                     type: string
-        a 
+        b 
           TableScan
-            alias: a
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -263,7 +263,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
@@ -343,23 +343,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        d 
-          TableScan
-            alias: d
-            Reduce Output Operator
-              key expressions:
-                    expr: (key + 1)
-                    type: double
-              sort order: +
-              Map-reduce partition columns:
-                    expr: (key + 1)
-                    type: double
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: val
-                    type: string
         $INTNAME 
             Reduce Output Operator
               key expressions:
@@ -383,6 +366,23 @@ STAGE PLANS:
                     type: string
                     expr: _col3
                     type: string
+        d 
+          TableScan
+            alias: d
+            Reduce Output Operator
+              key expressions:
+                    expr: (key + 1)
+                    type: double
+              sort order: +
+              Map-reduce partition columns:
+                    expr: (key + 1)
+                    type: double
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: val
+                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -431,7 +431,7 @@ PREHOOK: Input: default@t4
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/831264775/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-41_586_5996486802122601404/10000
 POSTHOOK: query: SELECT /*+ STREAMTABLE(a,c) */ *
 FROM T1 a JOIN T2 b ON a.key = b.key
           JOIN T3 c ON a.val = c.val
@@ -441,7 +441,7 @@ POSTHOOK: Input: default@t4
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/831264775/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-33-41_586_5996486802122601404/10000
 2	22	2	12	2	12	2	12
 PREHOOK: query: DROP TABLE T1
 PREHOOK: type: DROPTABLE
diff --git a/ql/src/test/results/clientpositive/join_thrift.q.out b/ql/src/test/results/clientpositive/join_thrift.q.out
index bbdf94c111..da506e581c 100644
--- a/ql/src/test/results/clientpositive/join_thrift.q.out
+++ b/ql/src/test/results/clientpositive/join_thrift.q.out
@@ -31,9 +31,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        s2 
+        s1 
           TableScan
-            alias: s2
+            alias: s1
             Reduce Output Operator
               key expressions:
                     expr: aint
@@ -42,13 +42,13 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: aint
                     type: int
-              tag: 1
+              tag: 0
               value expressions:
-                    expr: lintstring
-                    type: array<struct<myint:int,mystring:string,underscore_int:int>>
-        s1 
+                    expr: aint
+                    type: int
+        s2 
           TableScan
-            alias: s1
+            alias: s2
             Reduce Output Operator
               key expressions:
                     expr: aint
@@ -57,10 +57,10 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: aint
                     type: int
-              tag: 0
+              tag: 1
               value expressions:
-                    expr: aint
-                    type: int
+                    expr: lintstring
+                    type: array<struct<myint:int,mystring:string,underscore_int:int>>
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -95,14 +95,14 @@ JOIN src_thrift s2
 ON s1.aint = s2.aint
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_thrift
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1362622837/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-28-28_139_5468299142078849499/10000
 POSTHOOK: query: SELECT s1.aint, s2.lintstring
 FROM src_thrift s1
 JOIN src_thrift s2
 ON s1.aint = s2.aint
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_thrift
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1362622837/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-28-28_139_5468299142078849499/10000
 -1952710710	[{"myint":25,"mystring":"125","underscore_int":5}]
 -1461153973	[{"myint":49,"mystring":"343","underscore_int":7}]
 -751827638	[{"myint":4,"mystring":"8","underscore_int":2}]
diff --git a/ql/src/test/results/clientpositive/louter_join_ppr.q.out b/ql/src/test/results/clientpositive/louter_join_ppr.q.out
index 0bbe786c1c..099da9e328 100644
--- a/ql/src/test/results/clientpositive/louter_join_ppr.q.out
+++ b/ql/src/test/results/clientpositive/louter_join_ppr.q.out
@@ -27,6 +27,28 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Filter Operator
+              isSamplingPred: false
+              predicate:
+                  expr: ((key > 10) and (key < 20))
+                  type: boolean
+              Reduce Output Operator
+                key expressions:
+                      expr: key
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: key
+                      type: string
+                tag: 0
+                value expressions:
+                      expr: key
+                      type: string
+                      expr: value
+                      type: string
         b 
           TableScan
             alias: b
@@ -54,152 +76,130 @@ STAGE PLANS:
                         type: string
                         expr: value
                         type: string
-        a 
-          TableScan
-            alias: a
-            Filter Operator
-              isSamplingPred: false
-              predicate:
-                  expr: ((key > 10) and (key < 20))
-                  type: boolean
-              Reduce Output Operator
-                key expressions:
-                      expr: key
-                      type: string
-                sort order: +
-                Map-reduce partition columns:
-                      expr: key
-                      type: string
-                tag: 0
-                value expressions:
-                      expr: key
-                      type: string
-                      expr: value
-                      type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src 
           Partition
-            base file name: hr=11
+            base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            partition values:
-              ds 2008-04-08
-              hr 11
             properties:
-              name srcpart
-              columns.types string:string
-              serialization.ddl struct srcpart { string key, string value}
-              serialization.format 1
-              columns key,value
-              partition_columns ds/hr
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595239
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+              name src
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042866
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
-                columns.types string:string
-                serialization.ddl struct srcpart { string key, string value}
-                serialization.format 1
-                columns key,value
-                partition_columns ds/hr
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595239
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+                name src
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042866
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: srcpart
-            name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+              name: src
+            name: src
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
-            base file name: hr=12
+            base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             partition values:
               ds 2008-04-08
-              hr 12
+              hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595239
+              transient_lastDdlTime 1266042865
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595239
+                transient_lastDdlTime 1266042865
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
-            base file name: src
+            base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+              hr 12
             properties:
-              name src
-              columns.types string:string
-              serialization.ddl struct src { string key, string value}
-              serialization.format 1
-              columns key,value
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595240
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042865
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
-                columns.types string:string
-                serialization.ddl struct src { string key, string value}
-                serialization.format 1
-                columns key,value
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595240
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042865
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: src
-            name: src
+              name: srcpart
+            name: srcpart
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -228,14 +228,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/376752385/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-26_561_4175109917627852440/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1,_col2,_col3
-                      serialization.format 1
                       columns.types string:string:string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -253,7 +253,7 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/2103185832/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-26_685_6226317093446828977/10000
 POSTHOOK: query: FROM 
   src a
  LEFT OUTER JOIN 
@@ -265,7 +265,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/2103185832/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-26_685_6226317093446828977/10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -307,23 +307,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
-          TableScan
-            alias: b
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 1
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
         a 
           TableScan
             alias: a
@@ -351,49 +334,66 @@ STAGE PLANS:
                         type: string
                         expr: value
                         type: string
+        b 
+          TableScan
+            alias: b
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595240
+              transient_lastDdlTime 1266042866
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595240
+                transient_lastDdlTime 1266042866
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -402,39 +402,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595239
+              transient_lastDdlTime 1266042865
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595239
+                transient_lastDdlTime 1266042865
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -443,35 +443,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595239
+              transient_lastDdlTime 1266042865
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595239
+                transient_lastDdlTime 1266042865
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -503,14 +503,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/271241973/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-32_350_2893002848397872281/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1,_col2,_col3
-                      serialization.format 1
                       columns.types string:string:string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -528,7 +528,7 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1391949996/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-32_486_5323995982695277907/10000
 POSTHOOK: query: FROM 
   srcpart a
  LEFT OUTER JOIN 
@@ -540,7 +540,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1391949996/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-32_486_5323995982695277907/10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -582,26 +582,7 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
-          TableScan
-            alias: b
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 1
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
-                    expr: ds
-                    type: string
-        a 
+        a 
           TableScan
             alias: a
             Filter Operator
@@ -623,214 +604,233 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
+        b 
+          TableScan
+            alias: b
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+                    expr: ds
+                    type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src 
           Partition
-            base file name: hr=11
+            base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            partition values:
-              ds 2008-04-08
-              hr 11
             properties:
-              name srcpart
-              columns.types string:string
-              serialization.ddl struct srcpart { string key, string value}
-              serialization.format 1
-              columns key,value
-              partition_columns ds/hr
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595239
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+              name src
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042866
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
-                columns.types string:string
-                serialization.ddl struct srcpart { string key, string value}
-                serialization.format 1
-                columns key,value
-                partition_columns ds/hr
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595239
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+                name src
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042866
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: srcpart
-            name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+              name: src
+            name: src
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
-            base file name: hr=12
+            base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             partition values:
               ds 2008-04-08
-              hr 12
+              hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595239
+              transient_lastDdlTime 1266042865
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595239
+                transient_lastDdlTime 1266042865
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
-            base file name: hr=11
+            base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             partition values:
-              ds 2008-04-09
-              hr 11
+              ds 2008-04-08
+              hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595239
+              transient_lastDdlTime 1266042865
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595239
+                transient_lastDdlTime 1266042865
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
-            base file name: hr=12
+            base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             partition values:
               ds 2008-04-09
-              hr 12
+              hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595239
+              transient_lastDdlTime 1266042865
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595239
+                transient_lastDdlTime 1266042865
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
-            base file name: src
+            base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-09
+              hr 12
             properties:
-              name src
-              columns.types string:string
-              serialization.ddl struct src { string key, string value}
-              serialization.format 1
-              columns key,value
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595240
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042865
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
-                columns.types string:string
-                serialization.ddl struct src { string key, string value}
-                serialization.format 1
-                columns key,value
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595240
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042865
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: src
-            name: src
+              name: srcpart
+            name: srcpart
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -859,14 +859,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1774792968/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-39_495_2425883203412805550/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1,_col2,_col3
-                      serialization.format 1
                       columns.types string:string:string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -886,7 +886,7 @@ PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/242309432/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-39_649_6587378504601699293/10000
 POSTHOOK: query: FROM 
   src a
  LEFT OUTER JOIN 
@@ -900,7 +900,7 @@ POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/242309432/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-39_649_6587378504601699293/10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -942,23 +942,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
-          TableScan
-            alias: b
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 1
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
         a 
           TableScan
             alias: a
@@ -983,49 +966,66 @@ STAGE PLANS:
                       type: string
                       expr: ds
                       type: string
+        b 
+          TableScan
+            alias: b
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595240
+              transient_lastDdlTime 1266042866
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595240
+                transient_lastDdlTime 1266042866
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1034,39 +1034,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595239
+              transient_lastDdlTime 1266042865
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595239
+                transient_lastDdlTime 1266042865
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1075,35 +1075,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595239
+              transient_lastDdlTime 1266042865
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595239
+                transient_lastDdlTime 1266042865
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -1135,14 +1135,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/402950005/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-47_727_4554374875584732613/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1,_col2,_col3
-                      serialization.format 1
                       columns.types string:string:string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -1160,7 +1160,7 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1482301529/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-47_983_6270732933735864876/10000
 POSTHOOK: query: FROM 
   srcpart a
  LEFT OUTER JOIN 
@@ -1172,7 +1172,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1482301529/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-34-47_983_6270732933735864876/10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
diff --git a/ql/src/test/results/clientpositive/multi_insert.q.out b/ql/src/test/results/clientpositive/multi_insert.q.out
index ef9471be58..a8dca8bcaf 100644
--- a/ql/src/test/results/clientpositive/multi_insert.q.out
+++ b/ql/src/test/results/clientpositive/multi_insert.q.out
@@ -118,11 +118,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/431669224/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-29_447_2036367580743875308/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/431669224/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-29_447_2036367580743875308/10000
 0	val_0
 0	val_0
 0	val_0
@@ -136,11 +136,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1660399866/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-35_523_32784124749201803/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1660399866/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-35_523_32784124749201803/10000
 11	val_11
 12	val_12
 12	val_12
@@ -227,7 +227,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/412930117/10000
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-39_460_4688171279166647380/10000
 
   Stage: Stage-0
     Move Operator
@@ -242,7 +242,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1197621803/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-39_460_4688171279166647380/10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -272,7 +272,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/412930117/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-39_460_4688171279166647380/10002
 
   Stage: Stage-1
     Move Operator
@@ -287,7 +287,7 @@ STAGE PLANS:
   Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1197621803/10005 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-39_460_4688171279166647380/10005 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -328,11 +328,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1021534480/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-44_471_7177072664819434808/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1021534480/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-44_471_7177072664819434808/10000
 0	val_0
 0	val_0
 0	val_0
@@ -346,11 +346,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1868854677/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-48_776_4746714833769657150/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1868854677/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-48_776_4746714833769657150/10000
 11	val_11
 12	val_12
 12	val_12
@@ -462,11 +462,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1886571656/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-57_603_1895139113884971235/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1886571656/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-29-57_603_1895139113884971235/10000
 0	val_0
 0	val_0
 0	val_0
@@ -480,11 +480,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/886279091/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-01_874_6248094955310923547/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/886279091/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-01_874_6248094955310923547/10000
 11	val_11
 12	val_12
 12	val_12
@@ -571,7 +571,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/83924830/10000
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-07_533_8338685977513653800/10000
 
   Stage: Stage-0
     Move Operator
@@ -586,7 +586,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/538217516/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-07_533_8338685977513653800/10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -616,7 +616,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/83924830/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-07_533_8338685977513653800/10002
 
   Stage: Stage-1
     Move Operator
@@ -631,7 +631,7 @@ STAGE PLANS:
   Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/538217516/10005 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-07_533_8338685977513653800/10005 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -672,11 +672,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/658703846/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-11_925_7317892190390720566/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/658703846/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-11_925_7317892190390720566/10000
 0	val_0
 0	val_0
 0	val_0
@@ -690,11 +690,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1256145276/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-15_939_7123575127159240513/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1256145276/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-15_939_7123575127159240513/10000
 11	val_11
 12	val_12
 12	val_12
@@ -828,7 +828,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1983593088/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-21_064_1493440255317625555/10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -896,11 +896,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/991025002/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-31_604_6854725471079318857/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/991025002/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-31_604_6854725471079318857/10000
 0	val_0
 2	val_2
 4	val_4
@@ -910,11 +910,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1442414699/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-35_764_8471657074667538067/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1442414699/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-35_764_8471657074667538067/10000
 11	val_11
 12	val_12
 15	val_15
@@ -1045,7 +1045,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/255677337/10000
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-40_143_8909646046511921825/10000
 
   Stage: Stage-0
     Move Operator
@@ -1060,7 +1060,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2102317593/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-40_143_8909646046511921825/10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -1086,7 +1086,7 @@ STAGE PLANS:
   Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2102317593/10005 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-40_143_8909646046511921825/10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1133,7 +1133,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/255677337/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-40_143_8909646046511921825/10002
 
   Stage: Stage-1
     Move Operator
@@ -1148,7 +1148,7 @@ STAGE PLANS:
   Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2102317593/10006 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-40_143_8909646046511921825/10006 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -1189,11 +1189,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1456253532/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-50_895_7913352536521390096/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1456253532/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-50_895_7913352536521390096/10000
 0	val_0
 2	val_2
 4	val_4
@@ -1203,11 +1203,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1011160059/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-56_590_2617976148457105571/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1011160059/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-30-56_590_2617976148457105571/10000
 11	val_11
 12	val_12
 15	val_15
@@ -1338,7 +1338,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1356555878/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-01_349_1128452962511025567/10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1406,11 +1406,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/802713188/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-10_709_7113379560787468211/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/802713188/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-10_709_7113379560787468211/10000
 0	val_0
 2	val_2
 4	val_4
@@ -1420,11 +1420,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1830997643/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-15_222_6577306322581832665/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1830997643/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-15_222_6577306322581832665/10000
 11	val_11
 12	val_12
 15	val_15
@@ -1555,7 +1555,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/34043806/10000
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-19_213_675301272582900632/10000
 
   Stage: Stage-0
     Move Operator
@@ -1570,7 +1570,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/870862402/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-19_213_675301272582900632/10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -1596,7 +1596,7 @@ STAGE PLANS:
   Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/870862402/10005 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-19_213_675301272582900632/10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1643,7 +1643,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/34043806/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-19_213_675301272582900632/10002
 
   Stage: Stage-1
     Move Operator
@@ -1658,7 +1658,7 @@ STAGE PLANS:
   Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/870862402/10006 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-19_213_675301272582900632/10006 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -1699,11 +1699,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1326354495/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-29_456_7869097210136503483/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1326354495/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-29_456_7869097210136503483/10000
 0	val_0
 2	val_2
 4	val_4
@@ -1713,11 +1713,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1620537338/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-33_739_9167469421754848388/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1620537338/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-33_739_9167469421754848388/10000
 11	val_11
 12	val_12
 15	val_15
@@ -1746,7 +1746,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        null-subquery2:s-subquery2:src 
+        null-subquery1:s-subquery1:src 
           TableScan
             alias: src
             Select Operator
@@ -1795,7 +1795,7 @@ STAGE PLANS:
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: src_multi2
-        null-subquery1:s-subquery1:src 
+        null-subquery2:s-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -1883,11 +1883,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/643053521/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-43_798_871047497263397499/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/643053521/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-43_798_871047497263397499/10000
 0	val_0
 0	val_0
 0	val_0
@@ -1911,11 +1911,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1689259781/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-47_915_3175955014497083648/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1689259781/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-47_915_3175955014497083648/10000
 11	val_11
 11	val_11
 12	val_12
@@ -1962,7 +1962,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        null-subquery2:s-subquery2:src 
+        null-subquery1:s-subquery1:src 
           TableScan
             alias: src
             Select Operator
@@ -2011,7 +2011,7 @@ STAGE PLANS:
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: src_multi2
-        null-subquery1:s-subquery1:src 
+        null-subquery2:s-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -2068,7 +2068,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/269303231/10000
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-52_263_6047051261705597781/10000
 
   Stage: Stage-0
     Move Operator
@@ -2083,7 +2083,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2037406660/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-52_263_6047051261705597781/10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -2113,7 +2113,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/269303231/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-52_263_6047051261705597781/10002
 
   Stage: Stage-1
     Move Operator
@@ -2128,7 +2128,7 @@ STAGE PLANS:
   Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2037406660/10005 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-52_263_6047051261705597781/10005 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -2169,11 +2169,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2006157081/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-57_008_8643336423808686678/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2006157081/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-31-57_008_8643336423808686678/10000
 0	val_0
 0	val_0
 0	val_0
@@ -2197,11 +2197,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1093041493/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-00_850_1477714547871107054/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1093041493/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-00_850_1477714547871107054/10000
 11	val_11
 11	val_11
 12	val_12
@@ -2242,7 +2242,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        null-subquery2:s-subquery2:src 
+        null-subquery1:s-subquery1:src 
           TableScan
             alias: src
             Select Operator
@@ -2291,7 +2291,7 @@ STAGE PLANS:
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: src_multi2
-        null-subquery1:s-subquery1:src 
+        null-subquery2:s-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -2379,11 +2379,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1099073265/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-10_489_5856917420683506649/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1099073265/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-10_489_5856917420683506649/10000
 0	val_0
 0	val_0
 0	val_0
@@ -2407,11 +2407,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1497830799/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-14_242_705177908534153271/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1497830799/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-14_242_705177908534153271/10000
 11	val_11
 11	val_11
 12	val_12
@@ -2458,7 +2458,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        null-subquery2:s-subquery2:src 
+        null-subquery1:s-subquery1:src 
           TableScan
             alias: src
             Select Operator
@@ -2507,7 +2507,7 @@ STAGE PLANS:
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: src_multi2
-        null-subquery1:s-subquery1:src 
+        null-subquery2:s-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -2564,7 +2564,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/894474/10000
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-19_769_955320895324958853/10000
 
   Stage: Stage-0
     Move Operator
@@ -2579,7 +2579,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/348733677/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-19_769_955320895324958853/10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -2609,7 +2609,7 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/894474/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-19_769_955320895324958853/10002
 
   Stage: Stage-1
     Move Operator
@@ -2624,7 +2624,7 @@ STAGE PLANS:
   Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/348733677/10005 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-19_769_955320895324958853/10005 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -2665,11 +2665,11 @@ POSTHOOK: Output: default@src_multi2
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/666154363/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-24_858_7815198886293357837/10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/666154363/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-24_858_7815198886293357837/10000
 0	val_0
 0	val_0
 0	val_0
@@ -2693,11 +2693,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1934688356/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-29_369_2079249453992062976/10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1934688356/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-32-29_369_2079249453992062976/10000
 11	val_11
 11	val_11
 12	val_12
diff --git a/ql/src/test/results/clientpositive/no_hooks.q.out b/ql/src/test/results/clientpositive/no_hooks.q.out
index 6c4ecd8d1e..81eb7d69a9 100644
--- a/ql/src/test/results/clientpositive/no_hooks.q.out
+++ b/ql/src/test/results/clientpositive/no_hooks.q.out
@@ -13,31 +13,31 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Filter Operator
               predicate:
                   expr: (key < 10)
                   type: boolean
               Reduce Output Operator
                 sort order: 
-                tag: 1
+                tag: 0
                 value expressions:
                       expr: key
                       type: string
                       expr: value
                       type: string
-        src1 
+        src2 
           TableScan
-            alias: src1
+            alias: src2
             Filter Operator
               predicate:
                   expr: (key < 10)
                   type: boolean
               Reduce Output Operator
                 sort order: 
-                tag: 0
+                tag: 1
                 value expressions:
                       expr: key
                       type: string
@@ -77,7 +77,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/841057520/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-35-43_800_8890099663901992008/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -116,7 +116,7 @@ STAGE PLANS:
 POSTHOOK: query: SELECT *  FROM src src1 JOIN src src2 WHERE src1.key < 10 and src2.key < 10 SORT BY src1.key, src1.value, src2.key, src2.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1350656798/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-35-43_867_4010997272104504835/10000
 0	val_0	0	val_0
 0	val_0	0	val_0
 0	val_0	0	val_0
diff --git a/ql/src/test/results/clientpositive/outer_join_ppr.q.out b/ql/src/test/results/clientpositive/outer_join_ppr.q.out
index 970a95b81f..a2df06fe7e 100644
--- a/ql/src/test/results/clientpositive/outer_join_ppr.q.out
+++ b/ql/src/test/results/clientpositive/outer_join_ppr.q.out
@@ -27,6 +27,23 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -54,147 +71,130 @@ STAGE PLANS:
                         type: string
                         expr: value
                         type: string
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src 
           Partition
-            base file name: hr=11
+            base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            partition values:
-              ds 2008-04-08
-              hr 11
             properties:
-              name srcpart
-              columns.types string:string
-              serialization.ddl struct srcpart { string key, string value}
-              serialization.format 1
-              columns key,value
-              partition_columns ds/hr
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595384
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+              name src
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266043023
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
-                columns.types string:string
-                serialization.ddl struct srcpart { string key, string value}
-                serialization.format 1
-                columns key,value
-                partition_columns ds/hr
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595384
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+                name src
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266043023
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: srcpart
-            name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+              name: src
+            name: src
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
-            base file name: hr=12
+            base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             partition values:
               ds 2008-04-08
-              hr 12
+              hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595384
+              transient_lastDdlTime 1266043022
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595384
+                transient_lastDdlTime 1266043022
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
-            base file name: src
+            base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+              hr 12
             properties:
-              name src
-              columns.types string:string
-              serialization.ddl struct src { string key, string value}
-              serialization.format 1
-              columns key,value
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595385
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266043022
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
-                columns.types string:string
-                serialization.ddl struct src { string key, string value}
-                serialization.format 1
-                columns key,value
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595385
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266043022
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: src
-            name: src
+              name: srcpart
+            name: srcpart
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -223,14 +223,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1888027458/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-37-03_961_972039196360785311/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1,_col2,_col3
-                      serialization.format 1
                       columns.types string:string:string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -248,7 +248,7 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/408375670/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-37-04_100_4238879101636844017/10000
 POSTHOOK: query: FROM 
   src a
  FULL OUTER JOIN 
@@ -260,7 +260,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/408375670/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-37-04_100_4238879101636844017/10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -302,9 +302,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -313,17 +313,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
                     expr: value
                     type: string
-                    expr: ds
-                    type: string
-        a 
+        b 
           TableScan
-            alias: a
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -332,220 +330,222 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
                     expr: value
                     type: string
+                    expr: ds
+                    type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src 
           Partition
-            base file name: hr=11
+            base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            partition values:
-              ds 2008-04-08
-              hr 11
             properties:
-              name srcpart
-              columns.types string:string
-              serialization.ddl struct srcpart { string key, string value}
-              serialization.format 1
-              columns key,value
-              partition_columns ds/hr
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595384
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+              name src
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266043023
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
-                columns.types string:string
-                serialization.ddl struct srcpart { string key, string value}
-                serialization.format 1
-                columns key,value
-                partition_columns ds/hr
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595384
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+                name src
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266043023
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: srcpart
-            name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+              name: src
+            name: src
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
-            base file name: hr=12
+            base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             partition values:
               ds 2008-04-08
-              hr 12
+              hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595384
+              transient_lastDdlTime 1266043022
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595384
+                transient_lastDdlTime 1266043022
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
-            base file name: hr=11
+            base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             partition values:
-              ds 2008-04-09
-              hr 11
+              ds 2008-04-08
+              hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595384
+              transient_lastDdlTime 1266043022
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595384
+                transient_lastDdlTime 1266043022
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
-            base file name: hr=12
+            base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             partition values:
               ds 2008-04-09
-              hr 12
+              hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595384
+              transient_lastDdlTime 1266043022
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595384
+                transient_lastDdlTime 1266043022
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
-            base file name: src
+            base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-09
+              hr 12
             properties:
-              name src
-              columns.types string:string
-              serialization.ddl struct src { string key, string value}
-              serialization.format 1
-              columns key,value
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595385
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266043022
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
-                columns.types string:string
-                serialization.ddl struct src { string key, string value}
-                serialization.format 1
-                columns key,value
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595385
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266043022
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: src
-            name: src
+              name: srcpart
+            name: srcpart
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -574,14 +574,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/911941642/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-37-11_127_7101156364959078287/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1,_col2,_col3
-                      serialization.format 1
                       columns.types string:string:string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -601,7 +601,7 @@ PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/783945948/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-37-11_331_2099079248054865792/10000
 POSTHOOK: query: FROM 
   src a
  FULL OUTER JOIN 
@@ -615,7 +615,7 @@ POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/783945948/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-37-11_331_2099079248054865792/10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
diff --git a/ql/src/test/results/clientpositive/ppd_clusterby.q.out b/ql/src/test/results/clientpositive/ppd_clusterby.q.out
index b96e2ccd66..722613c982 100644
--- a/ql/src/test/results/clientpositive/ppd_clusterby.q.out
+++ b/ql/src/test/results/clientpositive/ppd_clusterby.q.out
@@ -64,11 +64,11 @@ STAGE PLANS:
 PREHOOK: query: SELECT * FROM SRC x where x.key = 10 CLUSTER BY x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/513562540/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-16_047_4683196037570603682/10000
 POSTHOOK: query: SELECT * FROM SRC x where x.key = 10 CLUSTER BY x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/513562540/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-16_047_4683196037570603682/10000
 10	val_10
 PREHOOK: query: EXPLAIN 
 SELECT x.key, x.value as v1, y.key  FROM SRC x JOIN SRC y ON (x.key = y.key)  where x.key = 20 CLUSTER BY v1
@@ -88,21 +88,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        y 
-          TableScan
-            alias: y
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 1
-              value expressions:
-                    expr: key
-                    type: string
         x 
           TableScan
             alias: x
@@ -124,6 +109,21 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
+        y 
+          TableScan
+            alias: y
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: key
+                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -156,7 +156,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/940478027/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-20_551_7196490252663379904/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col1
@@ -190,9 +190,9 @@ STAGE PLANS:
 PREHOOK: query: SELECT x.key, x.value as v1, y.key  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY v1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/799360183/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-20_625_5790090204623358419/10000
 POSTHOOK: query: SELECT x.key, x.value as v1, y.key  FROM SRC x JOIN SRC y ON (x.key = y.key) where x.key = 20 CLUSTER BY v1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/799360183/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-20_625_5790090204623358419/10000
 20	val_20	20
diff --git a/ql/src/test/results/clientpositive/ppd_gby_join.q.out b/ql/src/test/results/clientpositive/ppd_gby_join.q.out
index 1599bbacd1..a60f425d2c 100644
--- a/ql/src/test/results/clientpositive/ppd_gby_join.q.out
+++ b/ql/src/test/results/clientpositive/ppd_gby_join.q.out
@@ -30,34 +30,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2:src 
-          TableScan
-            alias: src
-            Filter Operator
-              predicate:
-                  expr: ((key > '2') and (key <> '4'))
-                  type: boolean
-              Filter Operator
-                predicate:
-                    expr: (key > '2')
-                    type: boolean
-                Select Operator
-                  expressions:
-                        expr: key
-                        type: string
-                  outputColumnNames: _col0
-                  Reduce Output Operator
-                    key expressions:
-                          expr: _col0
-                          type: string
-                    sort order: +
-                    Map-reduce partition columns:
-                          expr: _col0
-                          type: string
-                    tag: 1
-                    value expressions:
-                          expr: _col0
-                          type: string
         src1:src 
           TableScan
             alias: src
@@ -94,6 +66,34 @@ STAGE PLANS:
                             type: string
                             expr: _col1
                             type: string
+        src2:src 
+          TableScan
+            alias: src
+            Filter Operator
+              predicate:
+                  expr: ((key > '2') and (key <> '4'))
+                  type: boolean
+              Filter Operator
+                predicate:
+                    expr: (key > '2')
+                    type: boolean
+                Select Operator
+                  expressions:
+                        expr: key
+                        type: string
+                  outputColumnNames: _col0
+                  Reduce Output Operator
+                    key expressions:
+                          expr: _col0
+                          type: string
+                    sort order: +
+                    Map-reduce partition columns:
+                          expr: _col0
+                          type: string
+                    tag: 1
+                    value expressions:
+                          expr: _col0
+                          type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -131,7 +131,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1369857917/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-33_117_3293352701491643084/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
diff --git a/ql/src/test/results/clientpositive/ppd_join.q.out b/ql/src/test/results/clientpositive/ppd_join.q.out
index eb49027e19..a498ad97fb 100644
--- a/ql/src/test/results/clientpositive/ppd_join.q.out
+++ b/ql/src/test/results/clientpositive/ppd_join.q.out
@@ -27,38 +27,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2:src 
-          TableScan
-            alias: src
-            Filter Operator
-              predicate:
-                  expr: ((key > '2') and (key <> '4'))
-                  type: boolean
-              Filter Operator
-                predicate:
-                    expr: (key > '2')
-                    type: boolean
-                Select Operator
-                  expressions:
-                        expr: key
-                        type: string
-                        expr: value
-                        type: string
-                  outputColumnNames: _col0, _col1
-                  Reduce Output Operator
-                    key expressions:
-                          expr: _col0
-                          type: string
-                    sort order: +
-                    Map-reduce partition columns:
-                          expr: _col0
-                          type: string
-                    tag: 1
-                    value expressions:
-                          expr: _col0
-                          type: string
-                          expr: _col1
-                          type: string
         src1:src 
           TableScan
             alias: src
@@ -95,6 +63,38 @@ STAGE PLANS:
                             type: string
                             expr: _col1
                             type: string
+        src2:src 
+          TableScan
+            alias: src
+            Filter Operator
+              predicate:
+                  expr: ((key > '2') and (key <> '4'))
+                  type: boolean
+              Filter Operator
+                predicate:
+                    expr: (key > '2')
+                    type: boolean
+                Select Operator
+                  expressions:
+                        expr: key
+                        type: string
+                        expr: value
+                        type: string
+                  outputColumnNames: _col0, _col1
+                  Reduce Output Operator
+                    key expressions:
+                          expr: _col0
+                          type: string
+                    sort order: +
+                    Map-reduce partition columns:
+                          expr: _col0
+                          type: string
+                    tag: 1
+                    value expressions:
+                          expr: _col0
+                          type: string
+                          expr: _col1
+                          type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -136,7 +136,7 @@ ON src1.c1 = src2.c3 AND src1.c1 < '400'
 WHERE src1.c1 > '20' and (src1.c2 < 'val_50' or src1.c1 > '2') and (src2.c3 > '50' or src1.c1 < '50') and (src2.c3 <> '4')
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1175949676/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-37-40_005_1029039505427371825/10000
 POSTHOOK: query: SELECT src1.c1, src2.c4 
 FROM
 (SELECT src.key as c1, src.value as c2 from src where src.key > '1' ) src1
@@ -146,7 +146,7 @@ ON src1.c1 = src2.c3 AND src1.c1 < '400'
 WHERE src1.c1 > '20' and (src1.c2 < 'val_50' or src1.c1 > '2') and (src2.c3 > '50' or src1.c1 < '50') and (src2.c3 <> '4')
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1175949676/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-37-40_005_1029039505427371825/10000
 200	val_200
 200	val_200
 200	val_200
diff --git a/ql/src/test/results/clientpositive/ppd_join2.q.out b/ql/src/test/results/clientpositive/ppd_join2.q.out
index 8d79a2d1af..dd17b96c31 100644
--- a/ql/src/test/results/clientpositive/ppd_join2.q.out
+++ b/ql/src/test/results/clientpositive/ppd_join2.q.out
@@ -34,38 +34,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2:src 
-          TableScan
-            alias: src
-            Filter Operator
-              predicate:
-                  expr: ((key <> '305') and (key <> '14'))
-                  type: boolean
-              Filter Operator
-                predicate:
-                    expr: (key <> '305')
-                    type: boolean
-                Select Operator
-                  expressions:
-                        expr: key
-                        type: string
-                        expr: value
-                        type: string
-                  outputColumnNames: _col0, _col1
-                  Reduce Output Operator
-                    key expressions:
-                          expr: _col0
-                          type: string
-                    sort order: +
-                    Map-reduce partition columns:
-                          expr: _col0
-                          type: string
-                    tag: 1
-                    value expressions:
-                          expr: _col0
-                          type: string
-                          expr: _col1
-                          type: string
         src1:src 
           TableScan
             alias: src
@@ -102,6 +70,38 @@ STAGE PLANS:
                             type: string
                             expr: _col1
                             type: string
+        src2:src 
+          TableScan
+            alias: src
+            Filter Operator
+              predicate:
+                  expr: ((key <> '305') and (key <> '14'))
+                  type: boolean
+              Filter Operator
+                predicate:
+                    expr: (key <> '305')
+                    type: boolean
+                Select Operator
+                  expressions:
+                        expr: key
+                        type: string
+                        expr: value
+                        type: string
+                  outputColumnNames: _col0, _col1
+                  Reduce Output Operator
+                    key expressions:
+                          expr: _col0
+                          type: string
+                    sort order: +
+                    Map-reduce partition columns:
+                          expr: _col0
+                          type: string
+                    tag: 1
+                    value expressions:
+                          expr: _col0
+                          type: string
+                          expr: _col1
+                          type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -214,7 +214,7 @@ ON src1.c2 = src3.c6
 WHERE src1.c1 <> '311' and (src1.c2 <> 'val_50' or src1.c1 > '1') and (src2.c3 <> '10' or src1.c1 <> '10') and (src2.c3 <> '14') and (sqrt(src3.c5) <> 13)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/230944714/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-15_476_5954728281587155008/10000
 POSTHOOK: query: SELECT src1.c1, src2.c4 
 FROM
 (SELECT src.key as c1, src.value as c2 from src where src.key <> '302' ) src1
@@ -227,7 +227,7 @@ ON src1.c2 = src3.c6
 WHERE src1.c1 <> '311' and (src1.c2 <> 'val_50' or src1.c1 > '1') and (src2.c3 <> '10' or src1.c1 <> '10') and (src2.c3 <> '14') and (sqrt(src3.c5) <> 13)
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/230944714/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-15_476_5954728281587155008/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/ppd_join3.q.out b/ql/src/test/results/clientpositive/ppd_join3.q.out
index 03f9574150..c8df4af0a2 100644
--- a/ql/src/test/results/clientpositive/ppd_join3.q.out
+++ b/ql/src/test/results/clientpositive/ppd_join3.q.out
@@ -33,38 +33,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2:src 
-          TableScan
-            alias: src
-            Filter Operator
-              predicate:
-                  expr: ((key <> '12') and (key <> '4'))
-                  type: boolean
-              Filter Operator
-                predicate:
-                    expr: (key <> '12')
-                    type: boolean
-                Select Operator
-                  expressions:
-                        expr: key
-                        type: string
-                        expr: value
-                        type: string
-                  outputColumnNames: _col0, _col1
-                  Reduce Output Operator
-                    key expressions:
-                          expr: _col0
-                          type: string
-                    sort order: +
-                    Map-reduce partition columns:
-                          expr: _col0
-                          type: string
-                    tag: 1
-                    value expressions:
-                          expr: _col0
-                          type: string
-                          expr: _col1
-                          type: string
         src1:src 
           TableScan
             alias: src
@@ -101,6 +69,38 @@ STAGE PLANS:
                             type: string
                             expr: _col1
                             type: string
+        src2:src 
+          TableScan
+            alias: src
+            Filter Operator
+              predicate:
+                  expr: ((key <> '12') and (key <> '4'))
+                  type: boolean
+              Filter Operator
+                predicate:
+                    expr: (key <> '12')
+                    type: boolean
+                Select Operator
+                  expressions:
+                        expr: key
+                        type: string
+                        expr: value
+                        type: string
+                  outputColumnNames: _col0, _col1
+                  Reduce Output Operator
+                    key expressions:
+                          expr: _col0
+                          type: string
+                    sort order: +
+                    Map-reduce partition columns:
+                          expr: _col0
+                          type: string
+                    tag: 1
+                    value expressions:
+                          expr: _col0
+                          type: string
+                          expr: _col1
+                          type: string
         src3:src 
           TableScan
             alias: src
@@ -175,7 +175,7 @@ ON src1.c1 = src3.c5
 WHERE src1.c1 > '0' and (src1.c2 <> 'val_500' or src1.c1 > '1') and (src2.c3 > '10' or src1.c1 <> '10') and (src2.c3 <> '4') and (src3.c5 <> '1')
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/543319193/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-31_804_5890089031375913660/10000
 POSTHOOK: query: SELECT src1.c1, src2.c4 
 FROM
 (SELECT src.key as c1, src.value as c2 from src where src.key <> '11' ) src1
@@ -188,7 +188,7 @@ ON src1.c1 = src3.c5
 WHERE src1.c1 > '0' and (src1.c2 <> 'val_500' or src1.c1 > '1') and (src2.c3 > '10' or src1.c1 <> '10') and (src2.c3 <> '4') and (src3.c5 <> '1')
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/543319193/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-31_804_5890089031375913660/10000
 100	val_100
 100	val_100
 100	val_100
diff --git a/ql/src/test/results/clientpositive/ppd_multi_insert.q.out b/ql/src/test/results/clientpositive/ppd_multi_insert.q.out
index dd9d7de9dd..d00687afde 100644
--- a/ql/src/test/results/clientpositive/ppd_multi_insert.q.out
+++ b/ql/src/test/results/clientpositive/ppd_multi_insert.q.out
@@ -53,9 +53,9 @@ STAGE PLANS:
   Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -64,10 +64,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
-        a 
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+        b 
           TableScan
-            alias: a
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -76,12 +81,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
+              tag: 1
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -246,11 +246,11 @@ POSTHOOK: Output: ../build/ql/test/data/warehouse/mi4.out
 PREHOOK: query: SELECT mi1.* FROM mi1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@mi1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/775375392/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-41_902_6905591894666460215/10000
 POSTHOOK: query: SELECT mi1.* FROM mi1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@mi1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/775375392/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-41_902_6905591894666460215/10000
 0	val_0
 0	val_0
 0	val_0
@@ -402,11 +402,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: SELECT mi2.* FROM mi2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@mi2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/106849464/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-41_936_9202557721170644347/10000
 POSTHOOK: query: SELECT mi2.* FROM mi2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@mi2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/106849464/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-41_936_9202557721170644347/10000
 100	val_100
 100	val_100
 100	val_100
@@ -621,11 +621,11 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/
 PREHOOK: query: SELECT mi3.* FROM mi3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@mi3@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1706731089/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-41_968_153693361750093127/10000
 POSTHOOK: query: SELECT mi3.* FROM mi3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@mi3@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1706731089/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-34-41_968_153693361750093127/10000
 200	2008-04-08	12
 200	2008-04-08	12
 200	2008-04-08	12
diff --git a/ql/src/test/results/clientpositive/ppd_outer_join1.q.out b/ql/src/test/results/clientpositive/ppd_outer_join1.q.out
index 80e0815f0b..060b5709fa 100644
--- a/ql/src/test/results/clientpositive/ppd_outer_join1.q.out
+++ b/ql/src/test/results/clientpositive/ppd_outer_join1.q.out
@@ -27,23 +27,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
-          TableScan
-            alias: b
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 1
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
         a 
           TableScan
             alias: a
@@ -65,6 +48,23 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
+        b 
+          TableScan
+            alias: b
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -110,7 +110,7 @@ PREHOOK: query: FROM
  WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/244410137/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-41_861_2988494112154470083/10000
 POSTHOOK: query: FROM 
   src a
  LEFT OUTER JOIN 
@@ -120,7 +120,7 @@ POSTHOOK: query: FROM
  WHERE a.key > 10 AND a.key < 20 AND b.key > 15 AND b.key < 25
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/244410137/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-41_861_2988494112154470083/10000
 17	val_17	17	val_17
 18	val_18	18	val_18
 18	val_18	18	val_18
diff --git a/ql/src/test/results/clientpositive/ppd_outer_join2.q.out b/ql/src/test/results/clientpositive/ppd_outer_join2.q.out
index 6fb1148925..cb6f72f657 100644
--- a/ql/src/test/results/clientpositive/ppd_outer_join2.q.out
+++ b/ql/src/test/results/clientpositive/ppd_outer_join2.q.out
@@ -27,6 +27,23 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -48,23 +65,6 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -110,7 +110,7 @@ PREHOOK: query: FROM
  WHERE a.key > '10' AND a.key < '20' AND b.key > '15' AND b.key < '25'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/1607355712/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-49_166_7655816003584089890/10000
 POSTHOOK: query: FROM 
   src a
  RIGHT OUTER JOIN 
@@ -120,7 +120,7 @@ POSTHOOK: query: FROM
  WHERE a.key > '10' AND a.key < '20' AND b.key > '15' AND b.key < '25'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/1607355712/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-49_166_7655816003584089890/10000
 150	val_150	150	val_150
 152	val_152	152	val_152
 152	val_152	152	val_152
diff --git a/ql/src/test/results/clientpositive/ppd_outer_join3.q.out b/ql/src/test/results/clientpositive/ppd_outer_join3.q.out
index 32229c0bcb..590c7652c8 100644
--- a/ql/src/test/results/clientpositive/ppd_outer_join3.q.out
+++ b/ql/src/test/results/clientpositive/ppd_outer_join3.q.out
@@ -27,9 +27,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -38,15 +38,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
                     expr: value
                     type: string
-        a 
+        b 
           TableScan
-            alias: a
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -55,7 +55,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
@@ -106,7 +106,7 @@ PREHOOK: query: FROM
  WHERE a.key > '10' AND a.key < '20' AND b.key > '15' AND b.key < '25'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/794158250/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-58_300_1623871517298833290/10000
 POSTHOOK: query: FROM 
   src a
  FULL OUTER JOIN 
@@ -116,7 +116,7 @@ POSTHOOK: query: FROM
  WHERE a.key > '10' AND a.key < '20' AND b.key > '15' AND b.key < '25'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_3/build/ql/tmp/794158250/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_3/build/ql/scratchdir/hive_2010-02-12_22-18-58_300_1623871517298833290/10000
 150	val_150	150	val_150
 152	val_152	152	val_152
 152	val_152	152	val_152
diff --git a/ql/src/test/results/clientpositive/ppd_outer_join4.q.out b/ql/src/test/results/clientpositive/ppd_outer_join4.q.out
index 85a2310133..4f9c1dfe17 100644
--- a/ql/src/test/results/clientpositive/ppd_outer_join4.q.out
+++ b/ql/src/test/results/clientpositive/ppd_outer_join4.q.out
@@ -33,9 +33,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -44,15 +44,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
                     expr: value
                     type: string
-        c 
+        b 
           TableScan
-            alias: c
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -61,13 +61,15 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 2
+              tag: 1
               value expressions:
                     expr: key
                     type: string
-        a 
+                    expr: value
+                    type: string
+        c 
           TableScan
-            alias: a
+            alias: c
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -76,12 +78,10 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 2
               value expressions:
                     expr: key
                     type: string
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -134,7 +134,7 @@ PREHOOK: query: FROM
  WHERE a.key > '10' AND a.key < '20' AND b.key > '15' AND b.key < '25' AND sqrt(c.key) <> 13
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1320647695/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-31-48_596_2953182954930521327/10000
 POSTHOOK: query: FROM 
   src a
  LEFT OUTER JOIN
@@ -147,7 +147,7 @@ POSTHOOK: query: FROM
  WHERE a.key > '10' AND a.key < '20' AND b.key > '15' AND b.key < '25' AND sqrt(c.key) <> 13
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1320647695/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-31-48_596_2953182954930521327/10000
 150	val_150	150	val_150	150
 152	val_152	152	val_152	152
 152	val_152	152	val_152	152
diff --git a/ql/src/test/results/clientpositive/ppd_random.q.out b/ql/src/test/results/clientpositive/ppd_random.q.out
index 1caa379257..4f67ae47f1 100644
--- a/ql/src/test/results/clientpositive/ppd_random.q.out
+++ b/ql/src/test/results/clientpositive/ppd_random.q.out
@@ -27,6 +27,26 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        src1:src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+              outputColumnNames: _col0
+              Reduce Output Operator
+                key expressions:
+                      expr: _col0
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: _col0
+                      type: string
+                tag: 0
+                value expressions:
+                      expr: _col0
+                      type: string
         src2:src 
           TableScan
             alias: src
@@ -57,26 +77,6 @@ STAGE PLANS:
                     value expressions:
                           expr: _col1
                           type: string
-        src1:src 
-          TableScan
-            alias: src
-            Select Operator
-              expressions:
-                    expr: key
-                    type: string
-              outputColumnNames: _col0
-              Reduce Output Operator
-                key expressions:
-                      expr: _col0
-                      type: string
-                sort order: +
-                Map-reduce partition columns:
-                      expr: _col0
-                      type: string
-                tag: 0
-                value expressions:
-                      expr: _col0
-                      type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
diff --git a/ql/src/test/results/clientpositive/ppd_udf_case.q.out b/ql/src/test/results/clientpositive/ppd_udf_case.q.out
index 247b0b32ae..82d9844801 100644
--- a/ql/src/test/results/clientpositive/ppd_udf_case.q.out
+++ b/ql/src/test/results/clientpositive/ppd_udf_case.q.out
@@ -36,12 +36,12 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Filter Operator
               predicate:
-                  expr: (ds = '2008-04-08')
+                  expr: ((ds = '2008-04-08') and CASE (key) WHEN ('27') THEN (true) WHEN ('38') THEN (false) ELSE (null) END)
                   type: boolean
               Reduce Output Operator
                 key expressions:
@@ -51,7 +51,7 @@ STAGE PLANS:
                 Map-reduce partition columns:
                       expr: key
                       type: string
-                tag: 1
+                tag: 0
                 value expressions:
                       expr: key
                       type: string
@@ -61,12 +61,12 @@ STAGE PLANS:
                       type: string
                       expr: hr
                       type: string
-        a 
+        b 
           TableScan
-            alias: a
+            alias: b
             Filter Operator
               predicate:
-                  expr: ((ds = '2008-04-08') and CASE (key) WHEN ('27') THEN (true) WHEN ('38') THEN (false) ELSE (null) END)
+                  expr: (ds = '2008-04-08')
                   type: boolean
               Reduce Output Operator
                 key expressions:
@@ -76,7 +76,7 @@ STAGE PLANS:
                 Map-reduce partition columns:
                       expr: key
                       type: string
-                tag: 0
+                tag: 1
                 value expressions:
                       expr: key
                       type: string
@@ -128,7 +128,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/438623182/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-31-56_689_3254720341447490427/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -194,7 +194,7 @@ ORDER BY a.key, a.value, a.ds, a.hr, b.key, b.value, b.ds, b.hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2137110555/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-31-56_869_4629499201500113908/10000
 POSTHOOK: query: SELECT *
 FROM srcpart a JOIN srcpart b
 ON a.key = b.key
@@ -209,7 +209,7 @@ ORDER BY a.key, a.value, a.ds, a.hr, b.key, b.value, b.ds, b.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2137110555/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-31-56_869_4629499201500113908/10000
 27	val_27	2008-04-08	11	27	val_27	2008-04-08	11
 27	val_27	2008-04-08	11	27	val_27	2008-04-08	12
 27	val_27	2008-04-08	12	27	val_27	2008-04-08	11
diff --git a/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out b/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out
index 311fd43df7..057dcfb3e9 100644
--- a/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out
+++ b/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out
@@ -33,51 +33,51 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1281920331/10001
+                  directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-35-08_059_3516688999660848477/10001
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       properties:
                         columns _col0,_col1
-                        serialization.format 1
                         columns.types string:string
+                        serialization.format 1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1262137321
+              transient_lastDdlTime 1266042907
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1262137321
+                transient_lastDdlTime 1266042907
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -90,11 +90,11 @@ STAGE PLANS:
 PREHOOK: query: select * from src where rand(1) < 0.1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1343937738/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-35-08_099_7501446808782656360/10000
 POSTHOOK: query: select * from src where rand(1) < 0.1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1343937738/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-35-08_099_7501446808782656360/10000
 409	val_409
 429	val_429
 209	val_209
diff --git a/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out b/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out
index 924f90d094..af1ce710a0 100644
--- a/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out
+++ b/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out
@@ -53,30 +53,30 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/297465583/10002
+                  directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-21_884_2937772000010325968/10002
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       properties:
-                        name tmptable
+                        bucket_count -1
+                        columns key,value,hr,ds
                         columns.types string:string:string:string
+                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                        file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                        location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/tmptable
+                        name tmptable
                         serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                         serialization.format 1
-                        columns key,value,hr,ds
-                        bucket_count -1
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/tmptable
-                        transient_lastDdlTime 1263595477
+                        transient_lastDdlTime 1266042741
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -85,39 +85,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595476
+              transient_lastDdlTime 1266042740
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595476
+                transient_lastDdlTime 1266042740
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -126,35 +126,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595476
+              transient_lastDdlTime 1266042740
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595476
+                transient_lastDdlTime 1266042740
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -166,37 +166,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/297465583/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/567762797/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-21_884_2937772000010325968/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-21_884_2937772000010325968/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/567762797/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-21_884_2937772000010325968/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name tmptable
+                bucket_count -1
+                columns key,value,hr,ds
                 columns.types string:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/tmptable
+                name tmptable
                 serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                 serialization.format 1
-                columns key,value,hr,ds
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/tmptable
-                transient_lastDdlTime 1263595477
+                transient_lastDdlTime 1266042741
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: tmptable
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/567762797/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-21_884_2937772000010325968/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/297465583/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-21_884_2937772000010325968/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -214,41 +214,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/297465583/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/297465583/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-21_884_2937772000010325968/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-21_884_2937772000010325968/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/297465583/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-21_884_2937772000010325968/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name tmptable
+              bucket_count -1
+              columns key,value,hr,ds
               columns.types string:string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/tmptable
+              name tmptable
               serialization.ddl struct tmptable { string key, string value, string hr, string ds}
               serialization.format 1
-              columns key,value,hr,ds
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/tmptable
-              transient_lastDdlTime 1263595477
+              transient_lastDdlTime 1266042741
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name tmptable
+                bucket_count -1
+                columns key,value,hr,ds
                 columns.types string:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/tmptable
+                name tmptable
                 serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                 serialization.format 1
-                columns key,value,hr,ds
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/tmptable
-                transient_lastDdlTime 1263595477
+                transient_lastDdlTime 1266042741
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: tmptable
             name: tmptable
@@ -257,22 +257,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/567762797/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-21_884_2937772000010325968/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name tmptable
+                  bucket_count -1
+                  columns key,value,hr,ds
                   columns.types string:string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/tmptable
+                  name tmptable
                   serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                   serialization.format 1
-                  columns key,value,hr,ds
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/tmptable
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595477
+                  transient_lastDdlTime 1266042741
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: tmptable
 
@@ -292,11 +292,11 @@ POSTHOOK: Output: default@tmptable
 PREHOOK: query: select * from tmptable x sort by x.key,x.value,x.ds,x.hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/543578106/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-32_891_7737984582274649304/10000
 POSTHOOK: query: select * from tmptable x sort by x.key,x.value,x.ds,x.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/543578106/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-32_891_7737984582274649304/10000
 103	val_103	2008-04-08	11
 103	val_103	2008-04-08	12
 133	val_133	2008-04-08	11
diff --git a/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out b/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
index 58eef13e2c..3721eef68d 100644
--- a/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
+++ b/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
@@ -39,19 +39,19 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/124088894/10001
+                  directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-37-59_832_3788417974183008166/10001
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       properties:
                         columns _col0,_col1,_col2,_col3
-                        serialization.format 1
                         columns.types string:string:string:string
+                        serialization.format 1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -60,35 +60,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262137336
+              transient_lastDdlTime 1266043078
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262137336
+                transient_lastDdlTime 1266043078
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -101,11 +101,11 @@ STAGE PLANS:
 PREHOOK: query: select a.* from srcpart a where rand(1) < 0.1 and a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1944369228/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-37-59_919_2841312693651221074/10000
 POSTHOOK: query: select a.* from srcpart a where rand(1) < 0.1 and a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1944369228/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-37-59_919_2841312693651221074/10000
 42	val_42	2008-04-08	12
 44	val_44	2008-04-08	12
 26	val_26	2008-04-08	12
@@ -155,19 +155,19 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1956461194/10001
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-03_773_7561053502233744490/10001
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                         properties:
                           columns _col0,_col1,_col2,_col3
-                          serialization.format 1
                           columns.types string:string:string:string
+                          serialization.format 1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -176,35 +176,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262137336
+              transient_lastDdlTime 1266043078
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262137336
+                transient_lastDdlTime 1266043078
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -217,11 +217,11 @@ STAGE PLANS:
 PREHOOK: query: select a.* from srcpart a where a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1681163814/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-03_865_149659006171751209/10000
 POSTHOOK: query: select a.* from srcpart a where a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1681163814/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-03_865_149659006171751209/10000
 27	val_27	2008-04-08	12
 37	val_37	2008-04-08	12
 15	val_15	2008-04-08	12
diff --git a/ql/src/test/results/clientpositive/regex_col.q.out b/ql/src/test/results/clientpositive/regex_col.q.out
index 77f2ab405e..694e1c1340 100644
--- a/ql/src/test/results/clientpositive/regex_col.q.out
+++ b/ql/src/test/results/clientpositive/regex_col.q.out
@@ -113,9 +113,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -128,15 +128,15 @@ STAGE PLANS:
                     type: string
                     expr: value
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: ds
                     type: string
                     expr: hr
                     type: string
-        a 
+        b 
           TableScan
-            alias: a
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -149,7 +149,7 @@ STAGE PLANS:
                     type: string
                     expr: value
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: ds
                     type: string
@@ -209,31 +209,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
-          TableScan
-            alias: b
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-                    expr: hr
-                    type: string
-                    expr: ds
-                    type: string
-              sort order: +++
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-                    expr: hr
-                    type: string
-                    expr: ds
-                    type: string
-              tag: 1
-              value expressions:
-                    expr: ds
-                    type: string
-                    expr: hr
-                    type: string
         a 
           TableScan
             alias: a
@@ -262,6 +237,31 @@ STAGE PLANS:
                         expr: ds
                         type: string
                   tag: 0
+        b 
+          TableScan
+            alias: b
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+                    expr: hr
+                    type: string
+                    expr: ds
+                    type: string
+              sort order: +++
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+                    expr: hr
+                    type: string
+                    expr: ds
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: ds
+                    type: string
+                    expr: hr
+                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -288,7 +288,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/832608785/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-24_399_2804249481999873947/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -324,7 +324,7 @@ PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1495752848/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-24_582_4644469832031285008/10000
 POSTHOOK: query: SELECT b.`..` FROM srcpart a JOIN srcpart b
 ON a.key = b.key AND a.hr = b.hr AND a.ds = b.ds AND a.key = 103
 ORDER BY ds, hr
@@ -333,7 +333,7 @@ POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1495752848/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-24_582_4644469832031285008/10000
 2008-04-08	11
 2008-04-08	11
 2008-04-08	11
@@ -526,14 +526,14 @@ PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/316243993/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-36_271_5109114395556786366/10000
 POSTHOOK: query: SELECT `(ds|hr)?+.+` FROM srcpart ORDER BY key, value LIMIT 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/316243993/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-36_271_5109114395556786366/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/regexp_extract.q.out b/ql/src/test/results/clientpositive/regexp_extract.q.out
index e1435e5750..d6bb112b96 100644
--- a/ql/src/test/results/clientpositive/regexp_extract.q.out
+++ b/ql/src/test/results/clientpositive/regexp_extract.q.out
@@ -47,10 +47,10 @@ STAGE PLANS:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
-                      field.delim 9
                       columns _col0,_col1
-                      serialization.format 9
                       columns.types string,string
+                      field.delim 9
+                      serialization.format 9
                       serialization.last.column.takes.rest true
                 Reduce Output Operator
                   key expressions:
@@ -68,41 +68,41 @@ STAGE PLANS:
                         type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [tmap:src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src [tmap:src]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1262137436
+              transient_lastDdlTime 1266042776
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1262137436
+                transient_lastDdlTime 1266042776
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -123,14 +123,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/237484840/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-57_219_3180291446209228569/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1
-                      serialization.format 1
                       columns.types string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -146,7 +146,7 @@ PREHOOK: query: FROM (
 SELECT tmap.key, regexp_extract(tmap.value, 'val_(\\d+\\t\\d+)',1) WHERE tmap.key < 100
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/687662347/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-57_269_5995859906691510320/10000
 POSTHOOK: query: FROM (
   FROM src
   SELECT TRANSFORM(src.key, src.value, 1+2, 3+4)
@@ -156,7 +156,7 @@ POSTHOOK: query: FROM (
 SELECT tmap.key, regexp_extract(tmap.value, 'val_(\\d+\\t\\d+)',1) WHERE tmap.key < 100
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/687662347/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-32-57_269_5995859906691510320/10000
 0	0	3
 0	0	3
 0	0	3
@@ -290,10 +290,10 @@ STAGE PLANS:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
-                      field.delim 9
                       columns _col0,_col1
-                      serialization.format 9
                       columns.types string,string
+                      field.delim 9
+                      serialization.format 9
                       serialization.last.column.takes.rest true
                 Reduce Output Operator
                   key expressions:
@@ -311,41 +311,41 @@ STAGE PLANS:
                         type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [tmap:src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src [tmap:src]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1262137436
+              transient_lastDdlTime 1266042776
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1262137436
+                transient_lastDdlTime 1266042776
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -366,14 +366,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1239765305/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-03_106_231065528465301889/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1
-                      serialization.format 1
                       columns.types string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -389,7 +389,7 @@ PREHOOK: query: FROM (
 SELECT tmap.key, regexp_extract(tmap.value, 'val_(\\d+\\t\\d+)') WHERE tmap.key < 100
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1514486187/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-03_163_5396716588759691796/10000
 POSTHOOK: query: FROM (
   FROM src
   SELECT TRANSFORM(src.key, src.value, 1+2, 3+4)
@@ -399,7 +399,7 @@ POSTHOOK: query: FROM (
 SELECT tmap.key, regexp_extract(tmap.value, 'val_(\\d+\\t\\d+)') WHERE tmap.key < 100
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1514486187/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-03_163_5396716588759691796/10000
 0	0	3
 0	0	3
 0	0	3
diff --git a/ql/src/test/results/clientpositive/router_join_ppr.q.out b/ql/src/test/results/clientpositive/router_join_ppr.q.out
index 5349e00b45..73473715d4 100644
--- a/ql/src/test/results/clientpositive/router_join_ppr.q.out
+++ b/ql/src/test/results/clientpositive/router_join_ppr.q.out
@@ -27,6 +27,23 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -54,147 +71,130 @@ STAGE PLANS:
                         type: string
                         expr: value
                         type: string
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src 
           Partition
-            base file name: hr=11
+            base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            partition values:
-              ds 2008-04-08
-              hr 11
             properties:
-              name srcpart
-              columns.types string:string
-              serialization.ddl struct srcpart { string key, string value}
-              serialization.format 1
-              columns key,value
-              partition_columns ds/hr
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595522
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+              name src
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042791
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
-                columns.types string:string
-                serialization.ddl struct srcpart { string key, string value}
-                serialization.format 1
-                columns key,value
-                partition_columns ds/hr
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595522
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+                name src
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042791
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: srcpart
-            name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+              name: src
+            name: src
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
-            base file name: hr=12
+            base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             partition values:
               ds 2008-04-08
-              hr 12
+              hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595522
+              transient_lastDdlTime 1266042790
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595522
+                transient_lastDdlTime 1266042790
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
-            base file name: src
+            base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+              hr 12
             properties:
-              name src
-              columns.types string:string
-              serialization.ddl struct src { string key, string value}
-              serialization.format 1
-              columns key,value
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595523
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042790
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
-                columns.types string:string
-                serialization.ddl struct src { string key, string value}
-                serialization.format 1
-                columns key,value
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595523
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042790
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: src
-            name: src
+              name: srcpart
+            name: srcpart
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -223,14 +223,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1695115095/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-11_680_8740735423960494415/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1,_col2,_col3
-                      serialization.format 1
                       columns.types string:string:string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -248,7 +248,7 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2055282463/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-11_855_3626752366637738005/10000
 POSTHOOK: query: FROM 
   src a
  RIGHT OUTER JOIN 
@@ -260,7 +260,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2055282463/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-11_855_3626752366637738005/10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -302,28 +302,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
-          TableScan
-            alias: b
-            Filter Operator
-              isSamplingPred: false
-              predicate:
-                  expr: ((key > 15) and (key < 25))
-                  type: boolean
-              Reduce Output Operator
-                key expressions:
-                      expr: key
-                      type: string
-                sort order: +
-                Map-reduce partition columns:
-                      expr: key
-                      type: string
-                tag: 1
-                value expressions:
-                      expr: key
-                      type: string
-                      expr: value
-                      type: string
         a 
           TableScan
             alias: a
@@ -351,49 +329,71 @@ STAGE PLANS:
                         type: string
                         expr: value
                         type: string
+        b 
+          TableScan
+            alias: b
+            Filter Operator
+              isSamplingPred: false
+              predicate:
+                  expr: ((key > 15) and (key < 25))
+                  type: boolean
+              Reduce Output Operator
+                key expressions:
+                      expr: key
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: key
+                      type: string
+                tag: 1
+                value expressions:
+                      expr: key
+                      type: string
+                      expr: value
+                      type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595523
+              transient_lastDdlTime 1266042791
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595523
+                transient_lastDdlTime 1266042791
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -402,39 +402,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595522
+              transient_lastDdlTime 1266042790
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595522
+                transient_lastDdlTime 1266042790
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -443,35 +443,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595522
+              transient_lastDdlTime 1266042790
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595522
+                transient_lastDdlTime 1266042790
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -503,14 +503,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1738505941/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-18_556_6451069737652786072/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1,_col2,_col3
-                      serialization.format 1
                       columns.types string:string:string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -528,7 +528,7 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1670807983/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-18_768_6055133184497689637/10000
 POSTHOOK: query: FROM 
   srcpart a
  RIGHT OUTER JOIN 
@@ -540,7 +540,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1670807983/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-18_768_6055133184497689637/10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -582,14 +582,31 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
-            Filter Operator
-              isSamplingPred: false
-              predicate:
-                  expr: (((key > 15) and (key < 25)) and (ds = '2008-04-08'))
-                  type: boolean
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+        b 
+          TableScan
+            alias: b
+            Filter Operator
+              isSamplingPred: false
+              predicate:
+                  expr: (((key > 15) and (key < 25)) and (ds = '2008-04-08'))
+                  type: boolean
               Reduce Output Operator
                 key expressions:
                       expr: key
@@ -606,147 +623,130 @@ STAGE PLANS:
                       type: string
                       expr: ds
                       type: string
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src 
           Partition
-            base file name: hr=11
+            base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-            partition values:
-              ds 2008-04-08
-              hr 11
             properties:
-              name srcpart
-              columns.types string:string
-              serialization.ddl struct srcpart { string key, string value}
-              serialization.format 1
-              columns key,value
-              partition_columns ds/hr
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595522
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+              name src
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042791
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
-                columns.types string:string
-                serialization.ddl struct srcpart { string key, string value}
-                serialization.format 1
-                columns key,value
-                partition_columns ds/hr
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595522
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+                name src
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042791
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: srcpart
-            name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+              name: src
+            name: src
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
-            base file name: hr=12
+            base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             partition values:
               ds 2008-04-08
-              hr 12
+              hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595522
+              transient_lastDdlTime 1266042790
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595522
+                transient_lastDdlTime 1266042790
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
-            base file name: src
+            base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+              hr 12
             properties:
-              name src
-              columns.types string:string
-              serialization.ddl struct src { string key, string value}
-              serialization.format 1
-              columns key,value
               bucket_count -1
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns key,value
+              columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595523
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042790
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
-                columns.types string:string
-                serialization.ddl struct src { string key, string value}
-                serialization.format 1
-                columns key,value
                 bucket_count -1
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns key,value
+                columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595523
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042790
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              name: src
-            name: src
+              name: srcpart
+            name: srcpart
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -775,14 +775,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/588273788/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-24_311_1404478145341521043/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1,_col2,_col3
-                      serialization.format 1
                       columns.types string:string:string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -800,7 +800,7 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/266973231/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-24_471_5670962799740565251/10000
 POSTHOOK: query: FROM 
   src a
  RIGHT OUTER JOIN 
@@ -812,7 +812,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/266973231/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-24_471_5670962799740565251/10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -854,6 +854,25 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: string
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+                    expr: ds
+                    type: string
         b 
           TableScan
             alias: b
@@ -876,70 +895,51 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: string
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: string
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
-                    expr: ds
-                    type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src [b]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [a]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src [b]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [a]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1263595523
+              transient_lastDdlTime 1266042791
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1263595523
+                transient_lastDdlTime 1266042791
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -948,39 +948,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595522
+              transient_lastDdlTime 1266042790
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595522
+                transient_lastDdlTime 1266042790
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -989,39 +989,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595522
+              transient_lastDdlTime 1266042790
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595522
+                transient_lastDdlTime 1266042790
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1030,39 +1030,39 @@ STAGE PLANS:
               ds 2008-04-09
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595522
+              transient_lastDdlTime 1266042790
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595522
+                transient_lastDdlTime 1266042790
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1071,35 +1071,35 @@ STAGE PLANS:
               ds 2008-04-09
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595522
+              transient_lastDdlTime 1266042790
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595522
+                transient_lastDdlTime 1266042790
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -1131,14 +1131,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1901851591/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-30_956_7840403612368067707/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1,_col2,_col3
-                      serialization.format 1
                       columns.types string:string:string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -1158,7 +1158,7 @@ PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1873799324/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-31_123_3572579422291761587/10000
 POSTHOOK: query: FROM 
   srcpart a
  RIGHT OUTER JOIN 
@@ -1172,7 +1172,7 @@ POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1873799324/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-31_123_3572579422291761587/10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
diff --git a/ql/src/test/results/clientpositive/sample1.q.out b/ql/src/test/results/clientpositive/sample1.q.out
index e3fcb92185..c444736bb8 100644
--- a/ql/src/test/results/clientpositive/sample1.q.out
+++ b/ql/src/test/results/clientpositive/sample1.q.out
@@ -72,29 +72,29 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1942066969/10002
+                        directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-33_814_7587771414013571098/10002
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                             properties:
-                              name dest1
+                              bucket_count -1
+                              columns key,value,dt,hr
                               columns.types int:string:string:string
+                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                              name dest1
                               serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                               serialization.format 1
-                              columns key,value,dt,hr
-                              bucket_count -1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                              transient_lastDdlTime 1263595473
+                              transient_lastDdlTime 1266043113
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -103,35 +103,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595472
+              transient_lastDdlTime 1266043112
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595472
+                transient_lastDdlTime 1266043112
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -143,37 +143,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1942066969/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/629405183/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-33_814_7587771414013571098/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-33_814_7587771414013571098/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/629405183/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-33_814_7587771414013571098/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value,dt,hr
                 columns.types int:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                 serialization.format 1
-                columns key,value,dt,hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595473
+                transient_lastDdlTime 1266043113
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/629405183/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-33_814_7587771414013571098/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1942066969/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-33_814_7587771414013571098/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -191,41 +191,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1942066969/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1942066969/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-33_814_7587771414013571098/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-33_814_7587771414013571098/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1942066969/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-33_814_7587771414013571098/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest1
+              bucket_count -1
+              columns key,value,dt,hr
               columns.types int:string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+              name dest1
               serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
               serialization.format 1
-              columns key,value,dt,hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-              transient_lastDdlTime 1263595473
+              transient_lastDdlTime 1266043113
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value,dt,hr
                 columns.types int:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                 serialization.format 1
-                columns key,value,dt,hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595473
+                transient_lastDdlTime 1266043113
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -234,22 +234,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/629405183/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-33_814_7587771414013571098/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest1
+                  bucket_count -1
+                  columns key,value,dt,hr
                   columns.types int:string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                  name dest1
                   serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                   serialization.format 1
-                  columns key,value,dt,hr
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595473
+                  transient_lastDdlTime 1266043113
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
@@ -269,11 +269,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1628412982/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-37_918_3282296597502568199/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1628412982/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-37_918_3282296597502568199/10000
 238	val_238	2008-04-08	11
 86	val_86	2008-04-08	11
 311	val_311	2008-04-08	11
@@ -777,9 +777,9 @@ POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/
 PREHOOK: query: select count(1) from srcbucket
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/538379109/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-37_961_4216450504665903294/10000
 POSTHOOK: query: select count(1) from srcbucket
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/538379109/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-37_961_4216450504665903294/10000
 1000
diff --git a/ql/src/test/results/clientpositive/sample2.q.out b/ql/src/test/results/clientpositive/sample2.q.out
index 524045bb1b..651794a7c3 100644
--- a/ql/src/test/results/clientpositive/sample2.q.out
+++ b/ql/src/test/results/clientpositive/sample2.q.out
@@ -52,63 +52,63 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2121073527/10002
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-47_580_6693205893271732507/10002
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                         properties:
-                          name dest1
+                          bucket_count -1
+                          columns key,value
                           columns.types int:string
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                          name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
-                          columns key,value
-                          bucket_count -1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                          transient_lastDdlTime 1263595534
+                          transient_lastDdlTime 1266043007
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket
-              columns.types int:string
+              bucket_count 2
               bucket_field_name key
-              serialization.ddl struct srcbucket { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 2
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcbucket
-              transient_lastDdlTime 1263595533
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcbucket
+              name srcbucket
+              serialization.ddl struct srcbucket { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266043006
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket
-                columns.types int:string
+                bucket_count 2
                 bucket_field_name key
-                serialization.ddl struct srcbucket { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 2
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcbucket
-                transient_lastDdlTime 1263595533
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcbucket
+                name srcbucket
+                serialization.ddl struct srcbucket { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266043006
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -120,37 +120,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2121073527/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1681839978/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-47_580_6693205893271732507/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-47_580_6693205893271732507/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1681839978/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-47_580_6693205893271732507/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value
                 columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595534
+                transient_lastDdlTime 1266043007
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1681839978/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-47_580_6693205893271732507/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2121073527/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-47_580_6693205893271732507/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -164,41 +164,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2121073527/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2121073527/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-47_580_6693205893271732507/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-47_580_6693205893271732507/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2121073527/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-47_580_6693205893271732507/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest1
+              bucket_count -1
+              columns key,value
               columns.types int:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+              name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-              transient_lastDdlTime 1263595534
+              transient_lastDdlTime 1266043007
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value
                 columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595534
+                transient_lastDdlTime 1266043007
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -207,22 +207,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1681839978/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-47_580_6693205893271732507/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest1
+                  bucket_count -1
+                  columns key,value
                   columns.types int:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                  name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
                   serialization.format 1
-                  columns key,value
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595534
+                  transient_lastDdlTime 1266043007
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
@@ -240,11 +240,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/132600222/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-52_555_7114367387788089667/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/132600222/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-52_555_7114367387788089667/10000
 474	val_475
 62	val_63
 468	val_469
diff --git a/ql/src/test/results/clientpositive/sample4.q.out b/ql/src/test/results/clientpositive/sample4.q.out
index d20f7dda34..40e4616521 100644
--- a/ql/src/test/results/clientpositive/sample4.q.out
+++ b/ql/src/test/results/clientpositive/sample4.q.out
@@ -52,63 +52,63 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/999072817/10002
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-43_180_3184692605342050661/10002
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                         properties:
-                          name dest1
+                          bucket_count -1
+                          columns key,value
                           columns.types int:string
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                          name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
-                          columns key,value
-                          bucket_count -1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                          transient_lastDdlTime 1263595485
+                          transient_lastDdlTime 1266043123
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket
-              columns.types int:string
+              bucket_count 2
               bucket_field_name key
-              serialization.ddl struct srcbucket { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 2
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcbucket
-              transient_lastDdlTime 1263595484
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcbucket
+              name srcbucket
+              serialization.ddl struct srcbucket { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266043122
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket
-                columns.types int:string
+                bucket_count 2
                 bucket_field_name key
-                serialization.ddl struct srcbucket { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 2
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcbucket
-                transient_lastDdlTime 1263595484
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcbucket
+                name srcbucket
+                serialization.ddl struct srcbucket { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266043122
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -120,37 +120,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/999072817/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/57591445/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-43_180_3184692605342050661/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-43_180_3184692605342050661/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/57591445/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-43_180_3184692605342050661/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value
                 columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595485
+                transient_lastDdlTime 1266043123
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/57591445/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-43_180_3184692605342050661/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/999072817/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-43_180_3184692605342050661/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -164,41 +164,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/999072817/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/999072817/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-43_180_3184692605342050661/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-43_180_3184692605342050661/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/999072817/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-43_180_3184692605342050661/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest1
+              bucket_count -1
+              columns key,value
               columns.types int:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+              name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-              transient_lastDdlTime 1263595485
+              transient_lastDdlTime 1266043123
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value
                 columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595485
+                transient_lastDdlTime 1266043123
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -207,22 +207,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/57591445/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-43_180_3184692605342050661/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest1
+                  bucket_count -1
+                  columns key,value
                   columns.types int:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                  name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
                   serialization.format 1
-                  columns key,value
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595485
+                  transient_lastDdlTime 1266043123
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
@@ -240,11 +240,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/17072622/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-46_812_227629536846321896/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/17072622/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-46_812_227629536846321896/10000
 474	val_475
 62	val_63
 468	val_469
diff --git a/ql/src/test/results/clientpositive/sample5.q.out b/ql/src/test/results/clientpositive/sample5.q.out
index 5d7ee6a4d9..27f2335ba4 100644
--- a/ql/src/test/results/clientpositive/sample5.q.out
+++ b/ql/src/test/results/clientpositive/sample5.q.out
@@ -50,63 +50,63 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/821942662/10002
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-55_896_179779210255377365/10002
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                         properties:
-                          name dest1
+                          bucket_count -1
+                          columns key,value
                           columns.types int:string
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                          name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
-                          columns key,value
-                          bucket_count -1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                          transient_lastDdlTime 1263595539
+                          transient_lastDdlTime 1266043015
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcbucket [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcbucket [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcbucket 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcbucket 
           Partition
             base file name: srcbucket
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket
-              columns.types int:string
+              bucket_count 2
               bucket_field_name key
-              serialization.ddl struct srcbucket { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 2
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcbucket
-              transient_lastDdlTime 1263595538
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcbucket
+              name srcbucket
+              serialization.ddl struct srcbucket { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266043015
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket
-                columns.types int:string
+                bucket_count 2
                 bucket_field_name key
-                serialization.ddl struct srcbucket { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 2
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcbucket
-                transient_lastDdlTime 1263595538
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcbucket
+                name srcbucket
+                serialization.ddl struct srcbucket { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266043015
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -118,37 +118,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/821942662/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/836975101/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-55_896_179779210255377365/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-55_896_179779210255377365/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/836975101/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-55_896_179779210255377365/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value
                 columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595539
+                transient_lastDdlTime 1266043015
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/836975101/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-55_896_179779210255377365/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/821942662/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-55_896_179779210255377365/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -162,41 +162,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/821942662/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/821942662/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-55_896_179779210255377365/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-55_896_179779210255377365/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/821942662/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-55_896_179779210255377365/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest1
+              bucket_count -1
+              columns key,value
               columns.types int:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+              name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-              transient_lastDdlTime 1263595539
+              transient_lastDdlTime 1266043015
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value
                 columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595539
+                transient_lastDdlTime 1266043015
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -205,22 +205,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/836975101/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-36-55_896_179779210255377365/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest1
+                  bucket_count -1
+                  columns key,value
                   columns.types int:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/dest1
+                  name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
                   serialization.format 1
-                  columns key,value
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/dest1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595539
+                  transient_lastDdlTime 1266043015
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
@@ -238,11 +238,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1 SORT BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2050646271/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-37-05_217_2914373884364264209/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1 SORT BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/2050646271/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-37-05_217_2914373884364264209/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/sample6.q.out b/ql/src/test/results/clientpositive/sample6.q.out
index c69876d6ae..ceb76316e3 100644
--- a/ql/src/test/results/clientpositive/sample6.q.out
+++ b/ql/src/test/results/clientpositive/sample6.q.out
@@ -50,63 +50,63 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/76792880/10002
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-51_119_2219825656679729521/10002
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                         properties:
-                          name dest1
+                          bucket_count -1
+                          columns key,value
                           columns.types int:string
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+                          name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
-                          columns key,value
-                          bucket_count -1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-                          transient_lastDdlTime 1263595552
+                          transient_lastDdlTime 1266042831
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket
-              columns.types int:string
+              bucket_count 2
               bucket_field_name key
-              serialization.ddl struct srcbucket { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 2
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket
-              transient_lastDdlTime 1263595551
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+              name srcbucket
+              serialization.ddl struct srcbucket { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042830
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket
-                columns.types int:string
+                bucket_count 2
                 bucket_field_name key
-                serialization.ddl struct srcbucket { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 2
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket
-                transient_lastDdlTime 1263595551
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+                name srcbucket
+                serialization.ddl struct srcbucket { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042830
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -118,37 +118,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/76792880/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/687711381/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-51_119_2219825656679729521/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-51_119_2219825656679729521/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/687711381/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-51_119_2219825656679729521/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value
                 columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595552
+                transient_lastDdlTime 1266042831
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/687711381/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-51_119_2219825656679729521/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/76792880/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-51_119_2219825656679729521/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -162,41 +162,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/76792880/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/76792880/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-51_119_2219825656679729521/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-51_119_2219825656679729521/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/76792880/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-51_119_2219825656679729521/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest1
+              bucket_count -1
+              columns key,value
               columns.types int:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+              name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-              transient_lastDdlTime 1263595552
+              transient_lastDdlTime 1266042831
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value
                 columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595552
+                transient_lastDdlTime 1266042831
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -205,22 +205,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/687711381/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-51_119_2219825656679729521/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest1
+                  bucket_count -1
+                  columns key,value
                   columns.types int:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/dest1
+                  name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
                   serialization.format 1
-                  columns key,value
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dest1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595552
+                  transient_lastDdlTime 1266042831
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
@@ -238,11 +238,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2070048698/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-56_111_3004481512310530952/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2070048698/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-56_111_3004481512310530952/10000
 468	val_469
 272	val_273
 448	val_449
@@ -544,43 +544,43 @@ STAGE PLANS:
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt 
           Partition
             base file name: srcbucket1.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket
-              columns.types int:string
+              bucket_count 2
               bucket_field_name key
-              serialization.ddl struct srcbucket { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 2
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket
-              transient_lastDdlTime 1263595551
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+              name srcbucket
+              serialization.ddl struct srcbucket { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042830
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket
-                columns.types int:string
+                bucket_count 2
                 bucket_field_name key
-                serialization.ddl struct srcbucket { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 2
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket
-                transient_lastDdlTime 1263595551
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+                name srcbucket
+                serialization.ddl struct srcbucket { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042830
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -589,14 +589,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/82512368/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-56_155_9100961642412278851/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1
-                  serialization.format 1
                   columns.types int:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -607,12 +607,12 @@ PREHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 4 OUT OF 4 on key)
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/618846126/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-56_202_4162487246668955241/10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 4 OUT OF 4 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/618846126/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-33-56_202_4162487246668955241/10000
 3	val_4
 11	val_11
 11	val_12
@@ -904,43 +904,43 @@ STAGE PLANS:
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket
-              columns.types int:string
+              bucket_count 2
               bucket_field_name key
-              serialization.ddl struct srcbucket { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 2
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket
-              transient_lastDdlTime 1263595551
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+              name srcbucket
+              serialization.ddl struct srcbucket { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042830
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket
-                columns.types int:string
+                bucket_count 2
                 bucket_field_name key
-                serialization.ddl struct srcbucket { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 2
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket
-                transient_lastDdlTime 1263595551
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+                name srcbucket
+                serialization.ddl struct srcbucket { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042830
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -949,14 +949,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1069131344/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-01_731_6395441503427700332/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1
-                  serialization.format 1
                   columns.types int:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -967,12 +967,12 @@ PREHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key)
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/476394937/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-01_782_1797145005554910345/10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/476394937/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-01_782_1797145005554910345/10000
 0	val_0
 0	val_0
 0	val_0
@@ -1518,43 +1518,43 @@ STAGE PLANS:
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket 
           Partition
             base file name: srcbucket
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket
-              columns.types int:string
+              bucket_count 2
               bucket_field_name key
-              serialization.ddl struct srcbucket { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 2
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket
-              transient_lastDdlTime 1263595551
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+              name srcbucket
+              serialization.ddl struct srcbucket { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042830
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket
-                columns.types int:string
+                bucket_count 2
                 bucket_field_name key
-                serialization.ddl struct srcbucket { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 2
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket
-                transient_lastDdlTime 1263595551
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+                name srcbucket
+                serialization.ddl struct srcbucket { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042830
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -1563,14 +1563,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1423291663/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-06_458_5690780923487497627/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1
-                  serialization.format 1
                   columns.types int:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -1581,12 +1581,12 @@ PREHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 3 on key)
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1885000441/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-06_510_2608414978582447264/10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 3 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1885000441/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-06_510_2608414978582447264/10000
 0	val_0
 0	val_0
 0	val_0
@@ -1975,43 +1975,43 @@ STAGE PLANS:
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket 
           Partition
             base file name: srcbucket
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket
-              columns.types int:string
+              bucket_count 2
               bucket_field_name key
-              serialization.ddl struct srcbucket { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 2
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket
-              transient_lastDdlTime 1263595551
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+              name srcbucket
+              serialization.ddl struct srcbucket { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042830
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket
-                columns.types int:string
+                bucket_count 2
                 bucket_field_name key
-                serialization.ddl struct srcbucket { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 2
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket
-                transient_lastDdlTime 1263595551
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+                name srcbucket
+                serialization.ddl struct srcbucket { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042830
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -2020,14 +2020,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/905430948/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-12_512_700602305468578454/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1
-                  serialization.format 1
                   columns.types int:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -2038,12 +2038,12 @@ PREHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 2 OUT OF 3 on key)
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/491457993/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-12_563_3247760755754303761/10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 2 OUT OF 3 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/491457993/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-12_563_3247760755754303761/10000
 1	val_2
 4	val_4
 4	val_5
@@ -2418,82 +2418,82 @@ STAGE PLANS:
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt [s]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt 
           Partition
             base file name: srcbucket20.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket2
-              columns.types int:string
+              bucket_count 4
               bucket_field_name key
-              serialization.ddl struct srcbucket2 { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 4
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2
-              transient_lastDdlTime 1263595551
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2
+              name srcbucket2
+              serialization.ddl struct srcbucket2 { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042830
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket2
-                columns.types int:string
+                bucket_count 4
                 bucket_field_name key
-                serialization.ddl struct srcbucket2 { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 4
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2
-                transient_lastDdlTime 1263595551
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2
+                name srcbucket2
+                serialization.ddl struct srcbucket2 { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042830
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket2
             name: srcbucket2
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt 
           Partition
             base file name: srcbucket22.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket2
-              columns.types int:string
+              bucket_count 4
               bucket_field_name key
-              serialization.ddl struct srcbucket2 { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 4
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2
-              transient_lastDdlTime 1263595551
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2
+              name srcbucket2
+              serialization.ddl struct srcbucket2 { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042830
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket2
-                columns.types int:string
+                bucket_count 4
                 bucket_field_name key
-                serialization.ddl struct srcbucket2 { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 4
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2
-                transient_lastDdlTime 1263595551
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2
+                name srcbucket2
+                serialization.ddl struct srcbucket2 { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042830
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket2
             name: srcbucket2
@@ -2502,14 +2502,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1110665362/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-19_152_7679626437931174008/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1
-                  serialization.format 1
                   columns.types int:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -2520,12 +2520,12 @@ PREHOOK: query: SELECT s.* FROM srcbucket2 TABLESAMPLE (BUCKET 1 OUT OF 2 on key
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1183035972/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-19_225_4502411711216640112/10000
 POSTHOOK: query: SELECT s.* FROM srcbucket2 TABLESAMPLE (BUCKET 1 OUT OF 2 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1183035972/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-19_225_4502411711216640112/10000
 0	val_0
 0	val_0
 0	val_0
@@ -2700,43 +2700,43 @@ STAGE PLANS:
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt 
           Partition
             base file name: srcbucket21.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket2
-              columns.types int:string
+              bucket_count 4
               bucket_field_name key
-              serialization.ddl struct srcbucket2 { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 4
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2
-              transient_lastDdlTime 1263595551
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2
+              name srcbucket2
+              serialization.ddl struct srcbucket2 { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042830
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket2
-                columns.types int:string
+                bucket_count 4
                 bucket_field_name key
-                serialization.ddl struct srcbucket2 { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 4
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/srcbucket2
-                transient_lastDdlTime 1263595551
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket2
+                name srcbucket2
+                serialization.ddl struct srcbucket2 { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042830
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket2
             name: srcbucket2
@@ -2745,14 +2745,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1239806329/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-24_674_8736848919113523990/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1
-                  serialization.format 1
                   columns.types int:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -2763,12 +2763,12 @@ PREHOOK: query: SELECT s.* FROM srcbucket2 TABLESAMPLE (BUCKET 2 OUT OF 4 on key
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2076765396/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-24_726_8933628050555327816/10000
 POSTHOOK: query: SELECT s.* FROM srcbucket2 TABLESAMPLE (BUCKET 2 OUT OF 4 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2076765396/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-24_726_8933628050555327816/10000
 5	val_5
 5	val_5
 5	val_5
@@ -2868,14 +2868,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1009963688/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-29_840_8091316488320267247/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1
-                  serialization.format 1
                   columns.types int:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -2886,12 +2886,12 @@ PREHOOK: query: SELECT s.* FROM empty_bucket TABLESAMPLE (BUCKET 1 OUT OF 2 on k
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@empty_bucket
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1185613635/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-29_882_8027872574466731313/10000
 POSTHOOK: query: SELECT s.* FROM empty_bucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@empty_bucket
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1185613635/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-29_882_8027872574466731313/10000
 PREHOOK: query: drop table empty_bucket
 PREHOOK: type: DROPTABLE
 POSTHOOK: query: drop table empty_bucket
diff --git a/ql/src/test/results/clientpositive/sample7.q.out b/ql/src/test/results/clientpositive/sample7.q.out
index 3a661a91ab..f5b5d68959 100644
--- a/ql/src/test/results/clientpositive/sample7.q.out
+++ b/ql/src/test/results/clientpositive/sample7.q.out
@@ -57,63 +57,63 @@ STAGE PLANS:
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1035780131/10002
+                      directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-48_500_8655541435915917144/10002
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                           properties:
-                            name dest1
+                            bucket_count -1
+                            columns key,value
                             columns.types int:string
+                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                            location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                            name dest1
                             serialization.ddl struct dest1 { i32 key, string value}
                             serialization.format 1
-                            columns key,value
-                            bucket_count -1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                            transient_lastDdlTime 1263595490
+                            transient_lastDdlTime 1266043128
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket
-              columns.types int:string
+              bucket_count 2
               bucket_field_name key
-              serialization.ddl struct srcbucket { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 2
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcbucket
-              transient_lastDdlTime 1263595489
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcbucket
+              name srcbucket
+              serialization.ddl struct srcbucket { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266043127
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket
-                columns.types int:string
+                bucket_count 2
                 bucket_field_name key
-                serialization.ddl struct srcbucket { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 2
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/srcbucket
-                transient_lastDdlTime 1263595489
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcbucket
+                name srcbucket
+                serialization.ddl struct srcbucket { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266043127
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -125,37 +125,37 @@ STAGE PLANS:
     Move Operator
       files:
           hdfs directory: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1035780131/10002
-          destination: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/888645524/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-48_500_8655541435915917144/10002
+          destination: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-48_500_8655541435915917144/10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/888645524/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-48_500_8655541435915917144/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value
                 columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595490
+                transient_lastDdlTime 1266043128
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/888645524/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-48_500_8655541435915917144/10001
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1035780131/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-48_500_8655541435915917144/10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -169,41 +169,41 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1035780131/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1035780131/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-48_500_8655541435915917144/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-48_500_8655541435915917144/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1035780131/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-48_500_8655541435915917144/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name dest1
+              bucket_count -1
+              columns key,value
               columns.types int:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+              name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-              transient_lastDdlTime 1263595490
+              transient_lastDdlTime 1266043128
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dest1
+                bucket_count -1
+                columns key,value
                 columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                transient_lastDdlTime 1263595490
+                transient_lastDdlTime 1266043128
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -212,22 +212,22 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/888645524/10000
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-48_500_8655541435915917144/10000
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
-                  name dest1
+                  bucket_count -1
+                  columns key,value
                   columns.types int:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dest1
+                  name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
                   serialization.format 1
-                  columns key,value
-                  bucket_count -1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                  location file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/test/data/warehouse/dest1
-                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  transient_lastDdlTime 1263595490
+                  transient_lastDdlTime 1266043128
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
@@ -247,11 +247,11 @@ POSTHOOK: Output: default@dest1
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1338741395/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-53_265_8088248524292407998/10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/1338741395/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-38-53_265_8088248524292407998/10000
 468	val_469
 272	val_273
 448	val_449
diff --git a/ql/src/test/results/clientpositive/sample8.q.out b/ql/src/test/results/clientpositive/sample8.q.out
index 6fc2bc5662..c0bada0a9c 100644
--- a/ql/src/test/results/clientpositive/sample8.q.out
+++ b/ql/src/test/results/clientpositive/sample8.q.out
@@ -28,60 +28,60 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        t 
+        s 
           TableScan
-            alias: t
+            alias: s
             Filter Operator
               isSamplingPred: false
               predicate:
-                  expr: (((hash(key) & 2147483647) % 10) = 0)
+                  expr: (((((((hash(key) & 2147483647) % 1) = 0) and (ds = '2008-04-08')) and (hr = '11')) and (ds = '2008-04-08')) and (hr = '11'))
                   type: boolean
               Filter Operator
                 isSamplingPred: true
                 predicate:
-                    expr: (((hash(key) & 2147483647) % 10) = 0)
+                    expr: (((hash(key) & 2147483647) % 1) = 0)
                     type: boolean
                 Reduce Output Operator
                   sort order: 
-                  tag: 1
+                  tag: 0
                   value expressions:
                         expr: key
                         type: string
                         expr: value
                         type: string
-        s 
+                        expr: ds
+                        type: string
+                        expr: hr
+                        type: string
+        t 
           TableScan
-            alias: s
+            alias: t
             Filter Operator
               isSamplingPred: false
               predicate:
-                  expr: (((((((hash(key) & 2147483647) % 1) = 0) and (ds = '2008-04-08')) and (hr = '11')) and (ds = '2008-04-08')) and (hr = '11'))
+                  expr: (((hash(key) & 2147483647) % 10) = 0)
                   type: boolean
               Filter Operator
                 isSamplingPred: true
                 predicate:
-                    expr: (((hash(key) & 2147483647) % 1) = 0)
+                    expr: (((hash(key) & 2147483647) % 10) = 0)
                     type: boolean
                 Reduce Output Operator
                   sort order: 
-                  tag: 0
+                  tag: 1
                   value expressions:
                         expr: key
                         type: string
                         expr: value
                         type: string
-                        expr: ds
-                        type: string
-                        expr: hr
-                        type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [t, s]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [t]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [t]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [t]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [t, s]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [t]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [t]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [t]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -90,39 +90,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595550
+              transient_lastDdlTime 1266043030
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595550
+                transient_lastDdlTime 1266043030
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -131,39 +131,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595550
+              transient_lastDdlTime 1266043030
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595550
+                transient_lastDdlTime 1266043030
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -172,39 +172,39 @@ STAGE PLANS:
               ds 2008-04-09
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595550
+              transient_lastDdlTime 1266043030
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595550
+                transient_lastDdlTime 1266043030
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -213,35 +213,35 @@ STAGE PLANS:
               ds 2008-04-09
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1263595550
+              transient_lastDdlTime 1266043030
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1263595550
+                transient_lastDdlTime 1266043030
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -273,7 +273,7 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1204176731/10002
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-37-12_602_8370903476718056476/10002
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -285,7 +285,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1204176731/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-37-12_602_8370903476718056476/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -310,9 +310,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1204176731/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1204176731/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-37-12_602_8370903476718056476/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-37-12_602_8370903476718056476/10002]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1204176731/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-37-12_602_8370903476718056476/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -333,14 +333,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/1204176731/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-37-12_602_8370903476718056476/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1,_col2,_col3
-                  serialization.format 1
                   columns.types string:string:string:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -358,7 +358,7 @@ PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/909331877/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-37-12_818_1555523030124259486/10000
 POSTHOOK: query: SELECT s.key, s.value
 FROM srcpart TABLESAMPLE (BUCKET 1 OUT OF 1 ON key) s
 JOIN srcpart TABLESAMPLE (BUCKET 1 OUT OF 10 ON key) t
@@ -370,7 +370,7 @@ POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_0/build/ql/tmp/909331877/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-37-12_818_1555523030124259486/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/sample9.q.out b/ql/src/test/results/clientpositive/sample9.q.out
index bfa2ab1365..30ec1ea6fd 100644
--- a/ql/src/test/results/clientpositive/sample9.q.out
+++ b/ql/src/test/results/clientpositive/sample9.q.out
@@ -47,53 +47,53 @@ STAGE PLANS:
                     File Output Operator
                       compressed: false
                       GlobalTableId: 0
-                      directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/276265290/10001
+                      directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-36_719_4292341676089982864/10001
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                           properties:
                             columns _col0,_col1
-                            serialization.format 1
                             columns.types int:string
+                            serialization.format 1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s:a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s:a]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name srcbucket
-              columns.types int:string
+              bucket_count 2
               bucket_field_name key
-              serialization.ddl struct srcbucket { i32 key, string value}
               columns key,value
-              serialization.format 1
-              bucket_count 2
-              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket
-              transient_lastDdlTime 1262137551
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+              name srcbucket
+              serialization.ddl struct srcbucket { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1266042876
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcbucket
-                columns.types int:string
+                bucket_count 2
                 bucket_field_name key
-                serialization.ddl struct srcbucket { i32 key, string value}
                 columns key,value
-                serialization.format 1
-                bucket_count 2
-                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket
-                transient_lastDdlTime 1262137551
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcbucket
+                name srcbucket
+                serialization.ddl struct srcbucket { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1266042876
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -107,12 +107,12 @@ PREHOOK: query: SELECT s.*
 FROM (SELECT a.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key) a) s
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1954715033/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-36_768_5670830109541358579/10000
 POSTHOOK: query: SELECT s.*
 FROM (SELECT a.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key) a) s
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1954715033/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-36_768_5670830109541358579/10000
 474	val_475
 62	val_63
 468	val_469
diff --git a/ql/src/test/results/clientpositive/semijoin.q.out b/ql/src/test/results/clientpositive/semijoin.q.out
index 8e83c5343a..d4afa1bf47 100644
--- a/ql/src/test/results/clientpositive/semijoin.q.out
+++ b/ql/src/test/results/clientpositive/semijoin.q.out
@@ -24,11 +24,11 @@ POSTHOOK: Output: default@t1
 PREHOOK: query: select * from t1 sort by key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1822344324/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-55_844_5377426816047644405/10000
 POSTHOOK: query: select * from t1 sort by key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1822344324/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-34-55_844_5377426816047644405/10000
 0	val_0
 0	val_0
 0	val_0
@@ -50,11 +50,11 @@ POSTHOOK: Output: default@t2
 PREHOOK: query: select * from t2 sort by key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1897836188/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-04_090_4392814292183673812/10000
 POSTHOOK: query: select * from t2 sort by key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1897836188/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-04_090_4392814292183673812/10000
 0	val_0
 0	val_0
 0	val_0
@@ -78,11 +78,11 @@ POSTHOOK: Output: default@t3
 PREHOOK: query: select * from t3 sort by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t3
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1295614583/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-18_920_8144945614399368665/10000
 POSTHOOK: query: select * from t3 sort by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t3
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1295614583/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-18_920_8144945614399368665/10000
 0	val_0
 0	val_0
 0	val_0
@@ -113,11 +113,11 @@ POSTHOOK: Output: default@t4
 PREHOOK: query: select * from t4
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t4
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/110828986/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-23_529_199845268930082152/10000
 POSTHOOK: query: select * from t4
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t4
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/110828986/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-23_529_199845268930082152/10000
 PREHOOK: query: explain select * from t1 a left semi join t2 b on a.key=b.key sort by a.key, a.value
 PREHOOK: type: QUERY
 POSTHOOK: query: explain select * from t1 a left semi join t2 b on a.key=b.key sort by a.key, a.value
@@ -134,6 +134,23 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -158,23 +175,6 @@ STAGE PLANS:
                         expr: _col0
                         type: int
                   tag: 1
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -201,7 +201,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/874015996/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-23_552_5758342471643844459/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -233,12 +233,12 @@ PREHOOK: query: select * from t1 a left semi join t2 b on a.key=b.key sort by a.
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/719598717/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-23_609_8429769440251868116/10000
 POSTHOOK: query: select * from t1 a left semi join t2 b on a.key=b.key sort by a.key, a.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/719598717/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-23_609_8429769440251868116/10000
 0	val_0
 0	val_0
 0	val_0
@@ -261,6 +261,23 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -285,23 +302,6 @@ STAGE PLANS:
                         expr: _col0
                         type: int
                   tag: 1
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -328,7 +328,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/443021302/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-33_326_10811326247390379/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -360,12 +360,12 @@ PREHOOK: query: select * from t2 a left semi join t1 b on b.key=a.key sort by a.
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/47199658/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-33_389_3029611191663485159/10000
 POSTHOOK: query: select * from t2 a left semi join t1 b on b.key=a.key sort by a.key, a.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/47199658/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-33_389_3029611191663485159/10000
 0	val_0
 0	val_0
 0	val_0
@@ -390,6 +390,23 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -414,23 +431,6 @@ STAGE PLANS:
                         expr: _col0
                         type: int
                   tag: 1
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -457,7 +457,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1820186808/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-44_263_8841961579095622446/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -489,12 +489,12 @@ PREHOOK: query: select * from t1 a left semi join t4 b on b.key=a.key sort by a.
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t4
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1104896819/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-44_323_4702074512053597213/10000
 POSTHOOK: query: select * from t1 a left semi join t4 b on b.key=a.key sort by a.key, a.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t4
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1104896819/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-44_323_4702074512053597213/10000
 PREHOOK: query: explain select a.value from t1 a left semi join t3 b on (b.key = a.key and b.key < '15') sort by a.value
 PREHOOK: type: QUERY
 POSTHOOK: query: explain select a.value from t1 a left semi join t3 b on (b.key = a.key and b.key < '15') sort by a.value
@@ -511,6 +511,21 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -545,21 +560,6 @@ STAGE PLANS:
                             expr: _col1
                             type: int
                       tag: 1
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -584,7 +584,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/852467505/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-55_150_2508651293444068657/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -612,12 +612,12 @@ PREHOOK: query: select a.value from t1 a left semi join t3 b on (b.key = a.key a
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/429851475/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-55_240_8606996641991993570/10000
 POSTHOOK: query: select a.value from t1 a left semi join t3 b on (b.key = a.key and b.key < '15') sort by a.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/429851475/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-35-55_240_8606996641991993570/10000
 val_0
 val_0
 val_0
@@ -645,6 +645,23 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -681,23 +698,6 @@ STAGE PLANS:
                             expr: _col0
                             type: int
                       tag: 1
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -724,7 +724,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/568618311/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-03_687_6338764462894002347/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -756,12 +756,12 @@ PREHOOK: query: select * from t1 a left semi join t2 b on a.key = b.key and b.va
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/325580841/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-03_797_7630600056988799823/10000
 POSTHOOK: query: select * from t1 a left semi join t2 b on a.key = b.key and b.value < "val_10" sort by a.key, a.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/325580841/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-03_797_7630600056988799823/10000
 0	val_0
 0	val_0
 0	val_0
@@ -857,7 +857,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1835076993/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-13_895_8749833987137479467/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -885,12 +885,12 @@ PREHOOK: query: select a.value from t1 a left semi join (select key from t3 wher
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t3
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/802055445/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-13_967_7732951019053712101/10000
 POSTHOOK: query: select a.value from t1 a left semi join (select key from t3 where key > 5) b on a.key = b.key sort by a.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t3
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/802055445/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-13_967_7732951019053712101/10000
 val_10
 val_8
 val_9
@@ -910,6 +910,21 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: value
+                    type: string
         b:t2 
           TableScan
             alias: t2
@@ -957,21 +972,6 @@ STAGE PLANS:
                                 expr: _col0
                                 type: int
                           tag: 1
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -996,7 +996,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1099438469/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-23_930_6336397226727500924/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1024,12 +1024,12 @@ PREHOOK: query: select a.value from t1 a left semi join (select key , value from
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/847509449/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-24_008_5120080643273177462/10000
 POSTHOOK: query: select a.value from t1 a left semi join (select key , value from t2 where key > 5) b on a.key = b.key and b.value <= 'val_20' sort by a.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/847509449/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-24_008_5120080643273177462/10000
 PREHOOK: query: explain select * from t2 a left semi join (select key , value from t1 where key > 2) b on a.key = b.key sort by a.key, a.value
 PREHOOK: type: QUERY
 POSTHOOK: query: explain select * from t2 a left semi join (select key , value from t1 where key > 2) b on a.key = b.key sort by a.key, a.value
@@ -1046,6 +1046,23 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
+                    expr: value
+                    type: string
         b:t1 
           TableScan
             alias: t1
@@ -1083,23 +1100,6 @@ STAGE PLANS:
                               expr: _col0
                               type: int
                         tag: 1
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -1126,7 +1126,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/752092838/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-36_441_8634130304518118269/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1158,12 +1158,12 @@ PREHOOK: query: select * from t2 a left semi join (select key , value from t1 wh
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1124866757/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-36_508_3551604947895396638/10000
 POSTHOOK: query: select * from t2 a left semi join (select key , value from t1 where key > 2) b on a.key = b.key sort by a.key, a.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1124866757/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-36_508_3551604947895396638/10000
 4	val_2
 8	val_4
 10	val_5
@@ -1250,7 +1250,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1246154974/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-45_883_3501789923939810769/10002 
           Select Operator
             expressions:
                   expr: _col0
@@ -1288,12 +1288,12 @@ PREHOOK: query: select /*+ mapjoin(b) */ a.key from t3 a left semi join t1 b on
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t3
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/528721862/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-45_948_364129600871726553/10000
 POSTHOOK: query: select /*+ mapjoin(b) */ a.key from t3 a left semi join t1 b on a.key = b.key sort by a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t3
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/528721862/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-45_948_364129600871726553/10000
 0
 0
 0
@@ -1329,6 +1329,23 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -1353,23 +1370,6 @@ STAGE PLANS:
                         expr: (2 * _col0)
                         type: int
                   tag: 1
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -1396,7 +1396,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/63039358/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-55_575_4599378053603033966/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1428,12 +1428,12 @@ PREHOOK: query: select * from t1 a left semi join t2 b on a.key = 2*b.key sort b
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/492389910/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-55_643_3871759699151868689/10000
 POSTHOOK: query: select * from t1 a left semi join t2 b on a.key = 2*b.key sort by a.key, a.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/492389910/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-36-55_643_3871759699151868689/10000
 0	val_0
 0	val_0
 0	val_0
@@ -1454,6 +1454,23 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -1495,23 +1512,6 @@ STAGE PLANS:
                         expr: _col0
                         type: int
                   tag: 2
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -1544,7 +1544,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1771820602/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-06_509_1266627034604561120/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1581,13 +1581,13 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/763936868/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-06_996_7821060985422843977/10000
 POSTHOOK: query: select * from t1 a join t2 b on a.key = b.key left semi join t3 c on b.key = c.key sort by a.key, a.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/763936868/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-06_996_7821060985422843977/10000
 0	val_0	0	val_0
 0	val_0	0	val_0
 0	val_0	0	val_0
@@ -1618,6 +1618,27 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+                    expr: value
+                    type: string
+              sort order: ++
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+                    expr: value
+                    type: string
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -1650,27 +1671,6 @@ STAGE PLANS:
                         expr: _col1
                         type: string
                   tag: 1
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-                    expr: value
-                    type: string
-              sort order: ++
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-                    expr: value
-                    type: string
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -1697,7 +1697,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1587364336/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-19_651_1485752586517967264/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1729,12 +1729,12 @@ PREHOOK: query: select * from t3 a left semi join t1 b on a.key = b.key and a.va
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t3
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/825220067/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-19_724_3010359613753099590/10000
 POSTHOOK: query: select * from t3 a left semi join t1 b on a.key = b.key and a.value=b.value sort by a.key, a.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t3
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/825220067/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-19_724_3010359613753099590/10000
 0	val_0
 0	val_0
 0	val_0
@@ -1875,7 +1875,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/580117324/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-31_865_8041672431165280246/10002 
           Select Operator
             expressions:
                   expr: _col0
@@ -1914,13 +1914,13 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1272632986/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-31_958_2097477130102804854/10000
 POSTHOOK: query: select /*+ mapjoin(b, c) */ a.key from t3 a left semi join t1 b on a.key = b.key left semi join t2 c on a.key = c.key sort by a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1272632986/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-31_958_2097477130102804854/10000
 0
 0
 0
@@ -1951,6 +1951,21 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
         b 
           TableScan
             alias: b
@@ -1987,21 +2002,6 @@ STAGE PLANS:
                         expr: _col0
                         type: int
                   tag: 2
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -2028,7 +2028,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/832606254/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-39_609_6038505499338215694/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -2057,13 +2057,13 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1411619492/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-39_689_2219387084268760247/10000
 POSTHOOK: query: select a.key from t3 a left outer join t1 b on a.key = b.key left semi join t2 c on b.key = c.key sort by a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1411619492/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-39_689_2219387084268760247/10000
 0
 0
 0
@@ -2106,6 +2106,21 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
         b 
           TableScan
             alias: b
@@ -2142,21 +2157,6 @@ STAGE PLANS:
                         expr: _col0
                         type: int
                   tag: 2
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -2183,7 +2183,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1566445577/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-48_727_6848151951679507683/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -2212,13 +2212,13 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1441048499/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-48_802_2920426240777860433/10000
 POSTHOOK: query: select a.key from t1 a right outer join t3 b on a.key = b.key left semi join t2 c on b.key = c.key sort by a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1441048499/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-48_802_2920426240777860433/10000
 NULL
 NULL
 NULL
@@ -2264,6 +2264,21 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
         b 
           TableScan
             alias: b
@@ -2300,21 +2315,6 @@ STAGE PLANS:
                         expr: _col0
                         type: int
                   tag: 2
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -2341,7 +2341,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/882719133/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-57_921_1430015658693544867/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -2370,13 +2370,13 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1804734638/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-57_995_3374323430955047812/10000
 POSTHOOK: query: select a.key from t1 a full outer join t3 b on a.key = b.key left semi join t2 c on b.key = c.key sort by a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1804734638/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-37-57_995_3374323430955047812/10000
 NULL
 NULL
 NULL
@@ -2422,6 +2422,21 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
         b 
           TableScan
             alias: b
@@ -2458,21 +2473,6 @@ STAGE PLANS:
                     expr: key
                     type: int
               tag: 2
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -2499,7 +2499,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/72771189/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-06_288_8990291848979148784/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -2528,13 +2528,13 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t3
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1822254251/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-06_381_4851737602793432516/10000
 POSTHOOK: query: select a.key from t3 a left semi join t2 b on a.key = b.key left outer join t1 c on a.key = c.key sort by a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t3
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1822254251/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-06_381_4851737602793432516/10000
 0
 0
 0
@@ -2580,6 +2580,21 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
         b 
           TableScan
             alias: b
@@ -2616,21 +2631,6 @@ STAGE PLANS:
                     expr: key
                     type: int
               tag: 2
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -2657,7 +2657,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1181201254/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-14_800_4127574476527513/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -2686,13 +2686,13 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t3
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/541121985/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-14_885_5696666954446618715/10000
 POSTHOOK: query: select a.key from t3 a left semi join t2 b on a.key = b.key right outer join t1 c on a.key = c.key sort by a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t3
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/541121985/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-14_885_5696666954446618715/10000
 NULL
 NULL
 NULL
@@ -2740,6 +2740,21 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
         b 
           TableScan
             alias: b
@@ -2776,21 +2791,6 @@ STAGE PLANS:
                     expr: key
                     type: int
               tag: 2
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -2817,7 +2817,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/874601771/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-23_064_2361112395389588613/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -2846,13 +2846,13 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/575517554/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-23_146_7021023119933807907/10000
 POSTHOOK: query: select a.key from t3 a left semi join t1 b on a.key = b.key full outer join t2 c on a.key = c.key sort by a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/575517554/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-23_146_7021023119933807907/10000
 NULL
 NULL
 NULL
@@ -2912,6 +2912,23 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Reduce Output Operator
+              key expressions:
+                    expr: key
+                    type: int
+              sort order: +
+              Map-reduce partition columns:
+                    expr: key
+                    type: int
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: int
+                    expr: value
+                    type: string
         b 
           TableScan
             alias: b
@@ -2936,23 +2953,6 @@ STAGE PLANS:
                         expr: _col0
                         type: int
                   tag: 1
-        a 
-          TableScan
-            alias: a
-            Reduce Output Operator
-              key expressions:
-                    expr: key
-                    type: int
-              sort order: +
-              Map-reduce partition columns:
-                    expr: key
-                    type: int
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: int
-                    expr: value
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -3021,7 +3021,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/336616654/10003 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-31_328_3801807852346700415/10003 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -3050,13 +3050,13 @@ PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t3
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/633032319/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-31_406_3452916753684373079/10000
 POSTHOOK: query: select a.key from t3 a left semi join t2 b on a.key = b.key left outer join t1 c on a.value = c.value sort by a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t3
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/633032319/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-38-31_406_3452916753684373079/10000
 0
 0
 0
diff --git a/ql/src/test/results/clientpositive/skewjoin.q.out b/ql/src/test/results/clientpositive/skewjoin.q.out
index e9d41c2865..93353f599b 100644
--- a/ql/src/test/results/clientpositive/skewjoin.q.out
+++ b/ql/src/test/results/clientpositive/skewjoin.q.out
@@ -84,9 +84,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2 
+        src1 
           TableScan
-            alias: src2
+            alias: src1
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -95,13 +95,13 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
-                    expr: value
+                    expr: key
                     type: string
-        src1 
+        src2 
           TableScan
-            alias: src1
+            alias: src2
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -110,9 +110,9 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
-                    expr: key
+                    expr: value
                     type: string
       Reduce Operator Tree:
         Join Operator
@@ -254,11 +254,11 @@ POSTHOOK: Output: default@dest_j1
 PREHOOK: query: SELECT sum(hash(key)), sum(hash(value)) FROM dest_j1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/2065986997/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-39-57_324_3071297753179667524/10000
 POSTHOOK: query: SELECT sum(hash(key)), sum(hash(value)) FROM dest_j1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/2065986997/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-39-57_324_3071297753179667524/10000
 278697	101852390308
 PREHOOK: query: EXPLAIN
 SELECT /*+ STREAMTABLE(a) */ *
@@ -283,9 +283,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        d 
+        a 
           TableScan
-            alias: d
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -294,7 +294,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 3
               value expressions:
                     expr: key
                     type: string
@@ -334,9 +334,9 @@ STAGE PLANS:
                     type: string
                     expr: val
                     type: string
-        a 
+        d 
           TableScan
-            alias: a
+            alias: d
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -345,7 +345,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 3
+              tag: 0
               value expressions:
                     expr: key
                     type: string
@@ -404,7 +404,7 @@ PREHOOK: Input: default@t4
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1684194842/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-40-18_526_8099848720278828714/10000
 POSTHOOK: query: SELECT /*+ STREAMTABLE(a) */ *
 FROM T1 a JOIN T2 b ON a.key = b.key
           JOIN T3 c ON b.key = c.key
@@ -414,7 +414,7 @@ POSTHOOK: Input: default@t4
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1684194842/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-40-18_526_8099848720278828714/10000
 2	12	2	22	2	12	2	12
 PREHOOK: query: EXPLAIN
 SELECT /*+ STREAMTABLE(a,c) */ *
@@ -439,9 +439,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        d 
+        a 
           TableScan
-            alias: d
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -450,7 +450,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
+              tag: 3
               value expressions:
                     expr: key
                     type: string
@@ -490,9 +490,9 @@ STAGE PLANS:
                     type: string
                     expr: val
                     type: string
-        a 
+        d 
           TableScan
-            alias: a
+            alias: d
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -501,7 +501,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 3
+              tag: 0
               value expressions:
                     expr: key
                     type: string
@@ -560,7 +560,7 @@ PREHOOK: Input: default@t4
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1949681608/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-40-23_734_4785359328736541630/10000
 POSTHOOK: query: SELECT /*+ STREAMTABLE(a,c) */ *
 FROM T1 a JOIN T2 b ON a.key = b.key
           JOIN T3 c ON b.key = c.key
@@ -570,7 +570,7 @@ POSTHOOK: Input: default@t4
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1949681608/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-40-23_734_4785359328736541630/10000
 2	12	2	22	2	12	2	12
 PREHOOK: query: EXPLAIN FROM T1 a JOIN src c ON c.key+1=a.key SELECT /*+ STREAMTABLE(a) */ sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 PREHOOK: type: QUERY
@@ -588,38 +588,38 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        c 
+        a 
           TableScan
-            alias: c
+            alias: a
             Reduce Output Operator
               key expressions:
-                    expr: (key + 1)
+                    expr: UDFToDouble(key)
                     type: double
               sort order: +
               Map-reduce partition columns:
-                    expr: (key + 1)
+                    expr: UDFToDouble(key)
                     type: double
-              tag: 0
+              tag: 1
               value expressions:
                     expr: key
                     type: string
-        a 
+                    expr: val
+                    type: string
+        c 
           TableScan
-            alias: a
+            alias: c
             Reduce Output Operator
               key expressions:
-                    expr: UDFToDouble(key)
+                    expr: (key + 1)
                     type: double
               sort order: +
               Map-reduce partition columns:
-                    expr: UDFToDouble(key)
+                    expr: (key + 1)
                     type: double
-              tag: 1
+              tag: 0
               value expressions:
                     expr: key
                     type: string
-                    expr: val
-                    type: string
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -656,7 +656,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1895945248/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-40-29_021_8708656238087823514/10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -701,12 +701,12 @@ PREHOOK: query: FROM T1 a JOIN src c ON c.key+1=a.key SELECT /*+ STREAMTABLE(a)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/893344305/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-40-29_087_1046879883912334112/10000
 POSTHOOK: query: FROM T1 a JOIN src c ON c.key+1=a.key SELECT /*+ STREAMTABLE(a) */ sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/893344305/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-40-29_087_1046879883912334112/10000
 198	6274	194
 PREHOOK: query: EXPLAIN FROM 
 (SELECT src.* FROM src) x
@@ -890,7 +890,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/441875243/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-40-37_328_8353462754003839474/10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -934,7 +934,7 @@ ON (x.key = Y.key)
 SELECT sum(hash(Y.key)), sum(hash(Y.value))
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/586096055/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-40-37_530_5490496591134819475/10000
 POSTHOOK: query: FROM 
 (SELECT src.* FROM src) x
 JOIN 
@@ -943,7 +943,7 @@ ON (x.key = Y.key)
 SELECT sum(hash(Y.key)), sum(hash(Y.value))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/586096055/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-40-37_530_5490496591134819475/10000
 44481300	101852390308
 PREHOOK: query: EXPLAIN FROM 
 (SELECT src.* FROM src) x
@@ -1137,7 +1137,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/964239922/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-42-06_875_657056406676769744/10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -1181,7 +1181,7 @@ ON (x.key = Y.key and substring(x.value, 5)=substring(y.value, 5)+1)
 SELECT sum(hash(Y.key)), sum(hash(Y.value))
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1241392623/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-42-07_486_5787001889489498724/10000
 POSTHOOK: query: FROM 
 (SELECT src.* FROM src) x
 JOIN 
@@ -1190,7 +1190,7 @@ ON (x.key = Y.key and substring(x.value, 5)=substring(y.value, 5)+1)
 SELECT sum(hash(Y.key)), sum(hash(Y.value))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1241392623/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-42-07_486_5787001889489498724/10000
 NULL	NULL
 PREHOOK: query: EXPLAIN
 SELECT sum(hash(src1.c1)), sum(hash(src2.c4)) 
@@ -1229,28 +1229,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        src2:src 
-          TableScan
-            alias: src
-            Select Operator
-              expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
-              outputColumnNames: _col0, _col1
-              Reduce Output Operator
-                key expressions:
-                      expr: _col0
-                      type: string
-                sort order: +
-                Map-reduce partition columns:
-                      expr: _col0
-                      type: string
-                tag: 1
-                value expressions:
-                      expr: _col1
-                      type: string
         src1:src 
           TableScan
             alias: src
@@ -1279,6 +1257,28 @@ STAGE PLANS:
                     value expressions:
                           expr: _col0
                           type: string
+        src2:src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Reduce Output Operator
+                key expressions:
+                      expr: _col0
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: _col0
+                      type: string
+                tag: 1
+                value expressions:
+                      expr: _col1
+                      type: string
         src3:src 
           TableScan
             alias: src
@@ -1464,7 +1464,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1281773/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-42-43_139_341726508136962928/10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -1633,7 +1633,7 @@ JOIN
 ON src1.c1 = src3.c5 AND src3.c5 < 80
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/516996581/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-42-43_572_1869488555235237678/10000
 POSTHOOK: query: SELECT sum(hash(src1.c1)), sum(hash(src2.c4))
 FROM
 (SELECT src.key as c1, src.value as c2 from src) src1
@@ -1645,7 +1645,7 @@ JOIN
 ON src1.c1 = src3.c5 AND src3.c5 < 80
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/516996581/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-42-43_572_1869488555235237678/10000
 293143	-136853010385
 PREHOOK: query: EXPLAIN
 SELECT /*+ mapjoin(v)*/ sum(hash(k.key)), sum(hash(v.val)) FROM T1 k LEFT OUTER JOIN T1 v ON k.key+1=v.key
@@ -1718,7 +1718,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/989529143/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-43-25_195_82127211186947204/10002 
           Select Operator
             expressions:
                   expr: _col0
@@ -1778,111 +1778,111 @@ STAGE PLANS:
 PREHOOK: query: SELECT /*+ mapjoin(v)*/ sum(hash(k.key)), sum(hash(v.val)) FROM T1 k LEFT OUTER JOIN T1 v ON k.key+1=v.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/58672900/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-43-25_264_8428740047419886929/10000
 POSTHOOK: query: SELECT /*+ mapjoin(v)*/ sum(hash(k.key)), sum(hash(v.val)) FROM T1 k LEFT OUTER JOIN T1 v ON k.key+1=v.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/58672900/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-43-25_264_8428740047419886929/10000
 372	6320
 PREHOOK: query: select /*+ mapjoin(k)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.val
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/192419159/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-43-32_938_2032638800596167830/10000
 POSTHOOK: query: select /*+ mapjoin(k)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.val
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/192419159/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-43-32_938_2032638800596167830/10000
 NULL	NULL
 PREHOOK: query: select /*+ mapjoin(k)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1888200353/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-43-40_641_1825449334973878743/10000
 POSTHOOK: query: select /*+ mapjoin(k)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1888200353/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-43-40_641_1825449334973878743/10000
 429	12643
 PREHOOK: query: select sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1407196965/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-43-48_833_5293250651977115318/10000
 POSTHOOK: query: select sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1407196965/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-43-48_833_5293250651977115318/10000
 429	12643
 PREHOOK: query: select count(1) from  T1 a join T1 b on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1011357453/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-01_591_1464928610432503675/10000
 POSTHOOK: query: select count(1) from  T1 a join T1 b on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1011357453/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-01_591_1464928610432503675/10000
 8
 PREHOOK: query: FROM T1 a LEFT OUTER JOIN T2 c ON c.key+1=a.key SELECT sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1527156553/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-13_585_7159832475045196069/10000
 POSTHOOK: query: FROM T1 a LEFT OUTER JOIN T2 c ON c.key+1=a.key SELECT sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1527156553/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-13_585_7159832475045196069/10000
 317	9462	50
 PREHOOK: query: FROM T1 a RIGHT OUTER JOIN T2 c ON c.key+1=a.key SELECT /*+ STREAMTABLE(a) */ sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1123650104/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-22_759_9104803007678785533/10000
 POSTHOOK: query: FROM T1 a RIGHT OUTER JOIN T2 c ON c.key+1=a.key SELECT /*+ STREAMTABLE(a) */ sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1123650104/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-22_759_9104803007678785533/10000
 51	1570	318
 PREHOOK: query: FROM T1 a FULL OUTER JOIN T2 c ON c.key+1=a.key SELECT /*+ STREAMTABLE(a) */ sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1562579732/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-30_661_1739397497215155845/10000
 POSTHOOK: query: FROM T1 a FULL OUTER JOIN T2 c ON c.key+1=a.key SELECT /*+ STREAMTABLE(a) */ sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/1562579732/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-30_661_1739397497215155845/10000
 317	9462	318
 PREHOOK: query: SELECT sum(hash(src1.key)), sum(hash(src1.val)), sum(hash(src2.key)) FROM T1 src1 LEFT OUTER JOIN T2 src2 ON src1.key+1 = src2.key RIGHT OUTER JOIN T2 src3 ON src2.key = src3.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/2068857809/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-38_409_1485725015115349891/10000
 POSTHOOK: query: SELECT sum(hash(src1.key)), sum(hash(src1.val)), sum(hash(src2.key)) FROM T1 src1 LEFT OUTER JOIN T2 src2 ON src1.key+1 = src2.key RIGHT OUTER JOIN T2 src3 ON src2.key = src3.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/2068857809/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-38_409_1485725015115349891/10000
 370	11003	377
 PREHOOK: query: SELECT sum(hash(src1.key)), sum(hash(src1.val)), sum(hash(src2.key)) FROM T1 src1 JOIN T2 src2 ON src1.key+1 = src2.key JOIN T2 src3 ON src2.key = src3.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/976567437/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-47_406_6458878623944968772/10000
 POSTHOOK: query: SELECT sum(hash(src1.key)), sum(hash(src1.val)), sum(hash(src2.key)) FROM T1 src1 JOIN T2 src2 ON src1.key+1 = src2.key JOIN T2 src3 ON src2.key = src3.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/976567437/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-44-47_406_6458878623944968772/10000
 370	11003	377
 PREHOOK: query: select /*+ mapjoin(v)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k left outer join T1 v on k.key+1=v.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/2069296293/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-45-06_018_2671345290627071148/10000
 POSTHOOK: query: select /*+ mapjoin(v)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k left outer join T1 v on k.key+1=v.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/build/ql/tmp/2069296293/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-45-06_018_2671345290627071148/10000
 372	6320
 PREHOOK: query: DROP TABLE dest_j1
 PREHOOK: type: DROPTABLE
diff --git a/ql/src/test/results/clientpositive/transform_ppr1.q.out b/ql/src/test/results/clientpositive/transform_ppr1.q.out
index 57762aca97..90d79c277e 100644
--- a/ql/src/test/results/clientpositive/transform_ppr1.q.out
+++ b/ql/src/test/results/clientpositive/transform_ppr1.q.out
@@ -45,10 +45,10 @@ STAGE PLANS:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
-                      field.delim 9
                       columns _col0,_col1,_col2
-                      serialization.format 9
                       columns.types string,string,string
+                      field.delim 9
+                      serialization.format 9
                 Reduce Output Operator
                   key expressions:
                         expr: _col1
@@ -67,12 +67,12 @@ STAGE PLANS:
                         type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [tmap:src]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [tmap:src]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [tmap:src]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [tmap:src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [tmap:src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [tmap:src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [tmap:src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [tmap:src]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -81,39 +81,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262137788
+              transient_lastDdlTime 1266043519
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262137788
+                transient_lastDdlTime 1266043519
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -122,39 +122,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262137788
+              transient_lastDdlTime 1266043519
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262137788
+                transient_lastDdlTime 1266043519
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -163,39 +163,39 @@ STAGE PLANS:
               ds 2008-04-09
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262137788
+              transient_lastDdlTime 1266043519
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262137788
+                transient_lastDdlTime 1266043519
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -204,35 +204,35 @@ STAGE PLANS:
               ds 2008-04-09
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262137788
+              transient_lastDdlTime 1266043519
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262137788
+                transient_lastDdlTime 1266043519
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -253,14 +253,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1662404369/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-45-20_968_4904768994591945147/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1
-                      serialization.format 1
                       columns.types string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -279,7 +279,7 @@ PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1493893025/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-45-21_092_3109541758242622837/10000
 POSTHOOK: query: FROM (
   FROM srcpart src
   SELECT TRANSFORM(src.ds, src.key, src.value)
@@ -292,7 +292,7 @@ POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/1493893025/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-45-21_092_3109541758242622837/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/transform_ppr2.q.out b/ql/src/test/results/clientpositive/transform_ppr2.q.out
index 3cbdf0532a..5d2a9c973f 100644
--- a/ql/src/test/results/clientpositive/transform_ppr2.q.out
+++ b/ql/src/test/results/clientpositive/transform_ppr2.q.out
@@ -57,10 +57,10 @@ STAGE PLANS:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                         properties:
-                          field.delim 9
                           columns _col0,_col1,_col2
-                          serialization.format 9
                           columns.types string,string,string
+                          field.delim 9
+                          serialization.format 9
                     Reduce Output Operator
                       key expressions:
                             expr: _col1
@@ -79,10 +79,10 @@ STAGE PLANS:
                             type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [tmap:src]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [tmap:src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [tmap:src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [tmap:src]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -91,39 +91,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262137794
+              transient_lastDdlTime 1266043179
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262137794
+                transient_lastDdlTime 1266043179
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -132,35 +132,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262137794
+              transient_lastDdlTime 1266043179
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262137794
+                transient_lastDdlTime 1266043179
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -181,14 +181,14 @@ STAGE PLANS:
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/2007207579/10001
+                directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-39-41_239_4247074791799441588/10001
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     properties:
                       columns _col0,_col1
-                      serialization.format 1
                       columns.types string:string
+                      serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -206,7 +206,7 @@ SELECT tmap.tkey, tmap.tvalue WHERE tmap.tkey < 100
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/656025310/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-39-41_341_8793009202304764521/10000
 POSTHOOK: query: FROM (
   FROM srcpart src
   SELECT TRANSFORM(src.ds, src.key, src.value)
@@ -218,7 +218,7 @@ SELECT tmap.tkey, tmap.tvalue WHERE tmap.tkey < 100
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/656025310/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-39-41_341_8793009202304764521/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/udf_case_column_pruning.q.out b/ql/src/test/results/clientpositive/udf_case_column_pruning.q.out
index bf62d69685..ba881dcd01 100644
--- a/ql/src/test/results/clientpositive/udf_case_column_pruning.q.out
+++ b/ql/src/test/results/clientpositive/udf_case_column_pruning.q.out
@@ -30,9 +30,9 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        b 
+        a 
           TableScan
-            alias: b
+            alias: a
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -41,10 +41,13 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 1
-        a 
+              tag: 0
+              value expressions:
+                    expr: key
+                    type: string
+        b 
           TableScan
-            alias: a
+            alias: b
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -53,10 +56,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: key
                     type: string
-              tag: 0
-              value expressions:
-                    expr: key
-                    type: string
+              tag: 1
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -81,7 +81,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/54439940/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-40-56_328_3918398179294085207/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -116,7 +116,7 @@ ON a.key = b.key
 ORDER BY key LIMIT 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/901846595/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-40-56_386_3460624776357253178/10000
 POSTHOOK: query: SELECT CASE a.key
         WHEN '1' THEN 2
         WHEN '3' THEN 4
@@ -127,7 +127,7 @@ ON a.key = b.key
 ORDER BY key LIMIT 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/901846595/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-40-56_386_3460624776357253178/10000
 5
 5
 5
diff --git a/ql/src/test/results/clientpositive/udf_explode.q.out b/ql/src/test/results/clientpositive/udf_explode.q.out
index 2c1e93d745..9d7bc3d404 100644
--- a/ql/src/test/results/clientpositive/udf_explode.q.out
+++ b/ql/src/test/results/clientpositive/udf_explode.q.out
@@ -37,51 +37,51 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/626057626/10001
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-32_856_5887124237048999090/10001
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                         properties:
                           columns col
-                          serialization.format 1
                           columns.types int
+                          serialization.format 1
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/carl/Projects/hd8/hive-trunk/build/ql/test/data/warehouse/src [src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        file:/Users/carl/Projects/hd8/hive-trunk/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/carl/Projects/hd8/hive-trunk/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1262858387
+              transient_lastDdlTime 1266043292
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/carl/Projects/hd8/hive-trunk/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1262858387
+                transient_lastDdlTime 1266043292
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -126,41 +126,41 @@ STAGE PLANS:
                           type: int
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/carl/Projects/hd8/hive-trunk/build/ql/test/data/warehouse/src [a:src]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src [a:src]
       Path -> Partition:
-        file:/Users/carl/Projects/hd8/hive-trunk/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
             properties:
-              name src
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+              name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
-              columns key,value
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/Users/carl/Projects/hd8/hive-trunk/build/ql/test/data/warehouse/src
-              transient_lastDdlTime 1262858387
+              transient_lastDdlTime 1266043292
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name src
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/src
+                name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
-                columns key,value
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/Users/carl/Projects/hd8/hive-trunk/build/ql/test/data/warehouse/src
-                transient_lastDdlTime 1262858387
+                transient_lastDdlTime 1266043292
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -184,7 +184,7 @@ STAGE PLANS:
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/1329975374/10002
+                  directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-32_906_7264053019388777307/10002
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -196,7 +196,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/1329975374/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-32_906_7264053019388777307/10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -211,9 +211,9 @@ STAGE PLANS:
                     type: bigint
       Needs Tagging: false
       Path -> Alias:
-        file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/1329975374/10002 [file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/1329975374/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-32_906_7264053019388777307/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-32_906_7264053019388777307/10002]
       Path -> Partition:
-        file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/1329975374/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-32_906_7264053019388777307/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -249,14 +249,14 @@ STAGE PLANS:
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/1329975374/10001
+              directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-32_906_7264053019388777307/10001
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                   properties:
                     columns _col0,_col1
-                    serialization.format 1
                     columns.types int:bigint
+                    serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -266,33 +266,33 @@ STAGE PLANS:
 PREHOOK: query: SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/374186866/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-32_965_4841088620097082726/10000
 POSTHOOK: query: SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/374186866/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-32_965_4841088620097082726/10000
 1
 2
 3
 PREHOOK: query: SELECT explode(array(1,2,3)) AS (myCol) FROM src LIMIT 3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/83813908/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-36_506_3661229755671995471/10000
 POSTHOOK: query: SELECT explode(array(1,2,3)) AS (myCol) FROM src LIMIT 3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/83813908/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-36_506_3661229755671995471/10000
 1
 2
 3
 PREHOOK: query: SELECT a.myCol, count(1) FROM (SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3) a GROUP BY a.myCol
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/1571747562/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-39_927_4339771581910567107/10000
 POSTHOOK: query: SELECT a.myCol, count(1) FROM (SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3) a GROUP BY a.myCol
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/Users/carl/Projects/hd8/hive-trunk/build/ql/tmp/1571747562/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-41-39_927_4339771581910567107/10000
 1	1
 2	1
 3	1
diff --git a/ql/src/test/results/clientpositive/union16.q.out b/ql/src/test/results/clientpositive/union16.q.out
index e0a35a0dd5..739b331190 100644
--- a/ql/src/test/results/clientpositive/union16.q.out
+++ b/ql/src/test/results/clientpositive/union16.q.out
@@ -73,7 +73,7 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1:src 
           TableScan
             alias: src
             Select Operator
@@ -97,7 +97,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -121,7 +121,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -145,7 +145,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -169,7 +169,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -193,7 +193,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -217,7 +217,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -241,7 +241,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery2:src-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -265,7 +265,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -289,7 +289,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -313,7 +313,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -337,7 +337,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -361,7 +361,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery2:src-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -385,7 +385,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -409,7 +409,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -433,7 +433,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -457,7 +457,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -481,7 +481,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -505,7 +505,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -529,7 +529,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -553,7 +553,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -577,7 +577,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -601,7 +601,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -625,7 +625,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery2:src-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -649,7 +649,7 @@ STAGE PLANS:
                       value expressions:
                             expr: _col0
                             type: bigint
-        null-subquery1-subquery1-subquery2:src-subquery1-subquery1-subquery2:src 
+        null-subquery2:src-subquery2:src 
           TableScan
             alias: src
             Select Operator
@@ -729,7 +729,7 @@ PREHOOK: query: SELECT count(1) FROM (
   SELECT key, value FROM src) src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk-commit/build/ql/tmp/2070296923/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-45-27_565_1168288157971579592/10000
 POSTHOOK: query: SELECT count(1) FROM (
   SELECT key, value FROM src UNION ALL
   SELECT key, value FROM src UNION ALL
@@ -762,5 +762,5 @@ POSTHOOK: query: SELECT count(1) FROM (
   SELECT key, value FROM src) src
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk-commit/build/ql/tmp/2070296923/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-45-27_565_1168288157971579592/10000
 12500
diff --git a/ql/src/test/results/clientpositive/union20.q.out b/ql/src/test/results/clientpositive/union20.q.out
index 9e59c06d03..91c46a9984 100644
--- a/ql/src/test/results/clientpositive/union20.q.out
+++ b/ql/src/test/results/clientpositive/union20.q.out
@@ -80,8 +80,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/147338598/10002 
-          Union
+        $INTNAME 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -90,13 +89,13 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: _col0
                     type: string
-              tag: 1
+              tag: 0
               value expressions:
                     expr: _col0
                     type: string
                     expr: _col1
                     type: string
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/147338598/10003 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-44-12_799_6947862339516446099/10002 
           Union
             Reduce Output Operator
               key expressions:
@@ -112,7 +111,8 @@ STAGE PLANS:
                     type: string
                     expr: _col1
                     type: string
-        $INTNAME 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-44-12_799_6947862339516446099/10003 
+          Union
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -121,7 +121,7 @@ STAGE PLANS:
               Map-reduce partition columns:
                     expr: _col0
                     type: string
-              tag: 0
+              tag: 1
               value expressions:
                     expr: _col0
                     type: string
@@ -213,7 +213,7 @@ STAGE PLANS:
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/147338598/10004 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-44-12_799_6947862339516446099/10004 
           Union
             File Output Operator
               compressed: false
@@ -221,7 +221,7 @@ STAGE PLANS:
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-        file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/147338598/10006 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-44-12_799_6947862339516446099/10006 
           Union
             File Output Operator
               compressed: false
@@ -286,7 +286,7 @@ JOIN
 ON (unionsrc1.key = unionsrc2.key)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/882907634/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-44-12_925_5957838146435122575/10000
 POSTHOOK: query: SELECT unionsrc1.key, unionsrc1.value, unionsrc2.key, unionsrc2.value
 FROM (select 'tst1' as key, cast(count(1) as string) as value from src s1
                          UNION  ALL  
@@ -298,7 +298,7 @@ JOIN
 ON (unionsrc1.key = unionsrc2.key)
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_2/build/ql/tmp/882907634/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-44-12_925_5957838146435122575/10000
 0	val_0	0	val_0
 0	val_0	0	val_0
 0	val_0	0	val_0
diff --git a/ql/src/test/results/clientpositive/union21.q.out b/ql/src/test/results/clientpositive/union21.q.out
index 82e958f406..60b7724cf6 100644
--- a/ql/src/test/results/clientpositive/union21.q.out
+++ b/ql/src/test/results/clientpositive/union21.q.out
@@ -43,12 +43,12 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        null-subquery1-subquery2:union_output-subquery1-subquery2:src_thrift 
+        null-subquery1-subquery1-subquery1-subquery1:union_output-subquery1-subquery1-subquery1-subquery1:src 
           TableScan
-            alias: src_thrift
+            alias: src
             Select Operator
               expressions:
-                    expr: astring
+                    expr: '1'
                     type: string
               outputColumnNames: _col0
               Union
@@ -78,12 +78,12 @@ STAGE PLANS:
                       value expressions:
                             expr: _col1
                             type: bigint
-        null-subquery1-subquery1-subquery2:union_output-subquery1-subquery1-subquery2:src 
+        null-subquery1-subquery1-subquery1-subquery2:union_output-subquery1-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
               expressions:
-                    expr: key
+                    expr: reverse(key)
                     type: string
               outputColumnNames: _col0
               Union
@@ -113,12 +113,12 @@ STAGE PLANS:
                       value expressions:
                             expr: _col1
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery1:union_output-subquery1-subquery1-subquery1-subquery1:src 
+        null-subquery1-subquery1-subquery2:union_output-subquery1-subquery1-subquery2:src 
           TableScan
             alias: src
             Select Operator
               expressions:
-                    expr: '1'
+                    expr: key
                     type: string
               outputColumnNames: _col0
               Union
@@ -148,12 +148,12 @@ STAGE PLANS:
                       value expressions:
                             expr: _col1
                             type: bigint
-        null-subquery2:union_output-subquery2:src_thrift 
+        null-subquery1-subquery2:union_output-subquery1-subquery2:src_thrift 
           TableScan
             alias: src_thrift
             Select Operator
               expressions:
-                    expr: lstring[0]
+                    expr: astring
                     type: string
               outputColumnNames: _col0
               Union
@@ -183,12 +183,12 @@ STAGE PLANS:
                       value expressions:
                             expr: _col1
                             type: bigint
-        null-subquery1-subquery1-subquery1-subquery2:union_output-subquery1-subquery1-subquery1-subquery2:src 
+        null-subquery2:union_output-subquery2:src_thrift 
           TableScan
-            alias: src
+            alias: src_thrift
             Select Operator
               expressions:
-                    expr: reverse(key)
+                    expr: lstring[0]
                     type: string
               outputColumnNames: _col0
               Union
@@ -263,7 +263,7 @@ GROUP BY key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_thrift
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk-commit/build/ql/tmp/507855090/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-50-40_879_1035612367995200636/10000
 POSTHOOK: query: SELECT key, count(1)
 FROM (
   SELECT '1' as key from src
@@ -280,7 +280,7 @@ GROUP BY key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_thrift
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk-commit/build/ql/tmp/507855090/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_2/build/ql/scratchdir/hive_2010-02-12_22-50-40_879_1035612367995200636/10000
 NULL	2
 0	7
 001	2
diff --git a/ql/src/test/results/clientpositive/union22.q.out b/ql/src/test/results/clientpositive/union22.q.out
index d4af05389a..2817079788 100644
--- a/ql/src/test/results/clientpositive/union22.q.out
+++ b/ql/src/test/results/clientpositive/union22.q.out
@@ -102,7 +102,7 @@ STAGE PLANS:
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2007294374/10002
+                    directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-05_533_3831098180551834446/10002
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -154,7 +154,7 @@ STAGE PLANS:
                         File Output Operator
                           compressed: false
                           GlobalTableId: 0
-                          directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2007294374/10002
+                          directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-05_533_3831098180551834446/10002
                           table:
                               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -164,9 +164,9 @@ STAGE PLANS:
                                 escape.delim \
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dst_union22/ds=1 [null-subquery2:subq-subquery2:a]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dst_union22/ds=1 [null-subquery2:subq-subquery2:a]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dst_union22/ds=1 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dst_union22/ds=1 
           Partition
             base file name: ds=1
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -174,35 +174,35 @@ STAGE PLANS:
             partition values:
               ds 1
             properties:
-              name dst_union22
+              bucket_count -1
+              columns k1,k2,k3,k4
               columns.types string:string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dst_union22
+              name dst_union22
+              partition_columns ds
               serialization.ddl struct dst_union22 { string k1, string k2, string k3, string k4}
               serialization.format 1
-              columns k1,k2,k3,k4
-              partition_columns ds
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dst_union22
-              transient_lastDdlTime 1263596343
+              transient_lastDdlTime 1266043558
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dst_union22
+                bucket_count -1
+                columns k1,k2,k3,k4
                 columns.types string:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dst_union22
+                name dst_union22
+                partition_columns ds
                 serialization.ddl struct dst_union22 { string k1, string k2, string k3, string k4}
                 serialization.format 1
-                columns k1,k2,k3,k4
-                partition_columns ds
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dst_union22
-                transient_lastDdlTime 1263596343
+                transient_lastDdlTime 1266043558
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dst_union22
             name: dst_union22
@@ -210,7 +210,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2007294374/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-05_533_3831098180551834446/10002 
           Select Operator
             expressions:
                   expr: _col0
@@ -253,23 +253,23 @@ STAGE PLANS:
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/844330966/10000
+                      directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-05_533_3831098180551834446/10000
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                           properties:
-                            name dst_union22
+                            bucket_count -1
+                            columns k1,k2,k3,k4
                             columns.types string:string:string:string
+                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                            location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dst_union22
+                            name dst_union22
+                            partition_columns ds
                             serialization.ddl struct dst_union22 { string k1, string k2, string k3, string k4}
                             serialization.format 1
-                            columns k1,k2,k3,k4
-                            partition_columns ds
-                            bucket_count -1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dst_union22
-                            transient_lastDdlTime 1263596343
+                            transient_lastDdlTime 1266043558
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dst_union22
         null-subquery1:subq-subquery1:dst_union22_delta 
@@ -311,31 +311,31 @@ STAGE PLANS:
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/844330966/10000
+                        directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-05_533_3831098180551834446/10000
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                             properties:
-                              name dst_union22
+                              bucket_count -1
+                              columns k1,k2,k3,k4
                               columns.types string:string:string:string
+                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dst_union22
+                              name dst_union22
+                              partition_columns ds
                               serialization.ddl struct dst_union22 { string k1, string k2, string k3, string k4}
                               serialization.format 1
-                              columns k1,k2,k3,k4
-                              partition_columns ds
-                              bucket_count -1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dst_union22
-                              transient_lastDdlTime 1263596343
+                              transient_lastDdlTime 1266043558
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dst_union22
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2007294374/10002 [file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2007294374/10002]
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dst_union22_delta/ds=1 [null-subquery1:subq-subquery1:dst_union22_delta]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-05_533_3831098180551834446/10002 [file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-05_533_3831098180551834446/10002]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dst_union22_delta/ds=1 [null-subquery1:subq-subquery1:dst_union22_delta]
       Path -> Partition:
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/2007294374/10002 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-05_533_3831098180551834446/10002 
           Partition
             base file name: 10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -351,7 +351,7 @@ STAGE PLANS:
                 columns _col0,_col1,_col8,_col9
                 columns.types string,string,string,string
                 escape.delim \
-        file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dst_union22_delta/ds=1 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dst_union22_delta/ds=1 
           Partition
             base file name: ds=1
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -359,35 +359,35 @@ STAGE PLANS:
             partition values:
               ds 1
             properties:
-              name dst_union22_delta
+              bucket_count -1
+              columns k0,k1,k2,k3,k4,k5
               columns.types string:string:string:string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dst_union22_delta
+              name dst_union22_delta
+              partition_columns ds
               serialization.ddl struct dst_union22_delta { string k0, string k1, string k2, string k3, string k4, string k5}
               serialization.format 1
-              columns k0,k1,k2,k3,k4,k5
-              partition_columns ds
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dst_union22_delta
-              transient_lastDdlTime 1263596343
+              transient_lastDdlTime 1266043558
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dst_union22_delta
+                bucket_count -1
+                columns k0,k1,k2,k3,k4,k5
                 columns.types string:string:string:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dst_union22_delta
+                name dst_union22_delta
+                partition_columns ds
                 serialization.ddl struct dst_union22_delta { string k0, string k1, string k2, string k3, string k4, string k5}
                 serialization.format 1
-                columns k0,k1,k2,k3,k4,k5
-                partition_columns ds
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dst_union22_delta
-                transient_lastDdlTime 1263596343
+                transient_lastDdlTime 1266043558
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dst_union22_delta
             name: dst_union22_delta
@@ -398,26 +398,26 @@ STAGE PLANS:
           partition:
             ds 2
           replace: true
-          source: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/844330966/10000
+          source: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-05_533_3831098180551834446/10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name dst_union22
+                bucket_count -1
+                columns k1,k2,k3,k4
                 columns.types string:string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/test/data/warehouse/dst_union22
+                name dst_union22
+                partition_columns ds
                 serialization.ddl struct dst_union22 { string k1, string k2, string k3, string k4}
                 serialization.format 1
-                columns k1,k2,k3,k4
-                partition_columns ds
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/test/data/warehouse/dst_union22
-                transient_lastDdlTime 1263596343
+                transient_lastDdlTime 1266043558
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dst_union22
-          tmp directory: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/844330966/10001
+          tmp directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-05_533_3831098180551834446/10001
 
 
 PREHOOK: query: insert overwrite table dst_union22 partition (ds='2')
@@ -453,11 +453,11 @@ POSTHOOK: Output: default@dst_union22@ds=2
 PREHOOK: query: select * from dst_union22 where ds = '2' order by k1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dst_union22@ds=2
-PREHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1808125050/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-14_241_8587033370594928612/10000
 POSTHOOK: query: select * from dst_union22 where ds = '2' order by k1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dst_union22@ds=2
-POSTHOOK: Output: file:/data/users/heyongqiang/hive-trunk/.ptest_1/build/ql/tmp/1808125050/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_0/build/ql/scratchdir/hive_2010-02-12_22-46-14_241_8587033370594928612/10000
 0	val_0	0	val_0	2
 0	val_0	0	val_0	2
 0	val_0	0	val_0	2
diff --git a/ql/src/test/results/clientpositive/union23.q.out b/ql/src/test/results/clientpositive/union23.q.out
index c30b79ee6b..dcc968a908 100644
--- a/ql/src/test/results/clientpositive/union23.q.out
+++ b/ql/src/test/results/clientpositive/union23.q.out
@@ -27,37 +27,6 @@ STAGE PLANS:
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        null-subquery2:s-subquery2:src 
-          TableScan
-            alias: src
-            Select Operator
-              expressions:
-                    expr: key
-                    type: string
-                    expr: value
-                    type: string
-              outputColumnNames: _col0, _col1
-              Union
-                Select Operator
-                  expressions:
-                        expr: _col0
-                        type: string
-                        expr: _col1
-                        type: string
-                  outputColumnNames: _col0, _col1
-                  Reduce Output Operator
-                    key expressions:
-                          expr: _col0
-                          type: string
-                          expr: _col1
-                          type: string
-                    sort order: ++
-                    tag: -1
-                    value expressions:
-                          expr: _col0
-                          type: string
-                          expr: _col1
-                          type: string
         null-subquery1:s-subquery1:src 
           TableScan
             alias: src
@@ -94,6 +63,37 @@ STAGE PLANS:
                             type: string
                             expr: _col1
                             type: string
+        null-subquery2:s-subquery2:src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Union
+                Select Operator
+                  expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+                  outputColumnNames: _col0, _col1
+                  Reduce Output Operator
+                    key expressions:
+                          expr: _col0
+                          type: string
+                          expr: _col1
+                          type: string
+                    sort order: ++
+                    tag: -1
+                    value expressions:
+                          expr: _col0
+                          type: string
+                          expr: _col1
+                          type: string
       Reduce Operator Tree:
         Extract
           File Output Operator
@@ -117,7 +117,7 @@ from (
 order by s.key2, s.value2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/nzhang/work/876/apache-hive/build/ql/tmp/1377718694/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-44-40_928_3838457318369252981/10000
 POSTHOOK: query: select s.key2, s.value2
 from (
   select transform(key, value) using 'cat' as (key2, value2)
@@ -127,7 +127,7 @@ from (
 order by s.key2, s.value2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/nzhang/work/876/apache-hive/build/ql/tmp/1377718694/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-44-40_928_3838457318369252981/10000
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/union_ppr.q.out b/ql/src/test/results/clientpositive/union_ppr.q.out
index 9ea63d4e04..3f2546cf79 100644
--- a/ql/src/test/results/clientpositive/union_ppr.q.out
+++ b/ql/src/test/results/clientpositive/union_ppr.q.out
@@ -141,10 +141,10 @@ STAGE PLANS:
                                 type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
       Path -> Partition:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -153,39 +153,39 @@ STAGE PLANS:
               ds 2008-04-08
               hr 11
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262138674
+              transient_lastDdlTime 1266043520
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262138674
+                transient_lastDdlTime 1266043520
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -194,35 +194,35 @@ STAGE PLANS:
               ds 2008-04-08
               hr 12
             properties:
-              name srcpart
+              bucket_count -1
+              columns key,value
               columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
-              columns key,value
-              partition_columns ds/hr
-              bucket_count -1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              file.inputformat org.apache.hadoop.mapred.TextInputFormat
-              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-              transient_lastDdlTime 1262138674
+              transient_lastDdlTime 1266043520
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
               properties:
-                name srcpart
+                bucket_count -1
+                columns key,value
                 columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
-                columns key,value
-                partition_columns ds/hr
-                bucket_count -1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
-                transient_lastDdlTime 1262138674
+                transient_lastDdlTime 1266043520
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -231,14 +231,14 @@ STAGE PLANS:
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/930717093/10001
+            directory: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-45-21_846_1524738879962733240/10001
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                 properties:
                   columns _col0,_col1,_col2,_col3
-                  serialization.format 1
                   columns.types string:string:string:string
+                  serialization.format 1
 
   Stage: Stage-0
     Fetch Operator
@@ -255,7 +255,7 @@ SORT BY A.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/718706902/10000
+PREHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-45-21_964_3202410711818578967/10000
 POSTHOOK: query: SELECT * FROM (
   SELECT X.* FROM SRCPART X WHERE X.key < 100
   UNION ALL
@@ -266,7 +266,7 @@ SORT BY A.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/tmp/718706902/10000
+POSTHOOK: Output: file:/data/users/zshao/hadoop_hive_trunk2/.ptest_1/build/ql/scratchdir/hive_2010-02-12_22-45-21_964_3202410711818578967/10000
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
