diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffColCol.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffColCol.java
index 9f926fe851..2a6d719cb7 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffColCol.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffColCol.java
@@ -30,10 +30,9 @@
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;
 import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hive.common.util.DateParser;
 
 import java.sql.Date;
-import java.text.ParseException;
-import java.text.SimpleDateFormat;
 import java.util.Arrays;
 
 public class VectorUDFDateDiffColCol extends VectorExpression {
@@ -41,7 +40,6 @@ public class VectorUDFDateDiffColCol extends VectorExpression {
 
   private final int colNum2;
 
-  private transient final SimpleDateFormat formatter = new SimpleDateFormat("yyyy-MM-dd");
   private transient final Date date = new Date(0);
 
   // Transient members initialized by transientInit method.
@@ -212,11 +210,11 @@ public void copySelected(
     if (input.isRepeating) {
       if (input.noNulls || !input.isNull[0]) {
         String string = new String(input.vector[0], input.start[0], input.length[0]);
-        try {
-          date.setTime(formatter.parse(string).getTime());
-          output.vector[0] = DateWritableV2.dateToDays(date);
+        org.apache.hadoop.hive.common.type.Date hiveDate = DateParser.parseDate(string);
+        if (hiveDate != null) {
+          output.vector[0] = hiveDate.toEpochDay();
           output.isNull[0] = false;
-        } catch (ParseException e) {
+        } else {
           output.isNull[0] = true;
           output.noNulls = false;
         }
@@ -291,10 +289,10 @@ public void copySelected(
 
   private void setDays(BytesColumnVector input, LongColumnVector output, int i) {
     String string = new String(input.vector[i], input.start[i], input.length[i]);
-    try {
-      date.setTime(formatter.parse(string).getTime());
-      output.vector[i] = DateWritableV2.dateToDays(date);
-    } catch (ParseException e) {
+    org.apache.hadoop.hive.common.type.Date hiveDate = DateParser.parseDate(string);
+    if (hiveDate != null) {
+      output.vector[i] = hiveDate.toEpochDay();
+    } else {
       output.isNull[i] = true;
       output.noNulls = false;
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffColScalar.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffColScalar.java
index 799ee1a56f..ec82ef299f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffColScalar.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffColScalar.java
@@ -30,10 +30,9 @@
 import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
 import org.apache.hadoop.io.Text;
 
+import java.nio.charset.StandardCharsets;
 import java.sql.Date;
 import java.sql.Timestamp;
-import java.text.ParseException;
-import java.text.SimpleDateFormat;
 import java.util.Arrays;
 
 public class VectorUDFDateDiffColScalar extends VectorExpression {
@@ -43,7 +42,6 @@ public class VectorUDFDateDiffColScalar extends VectorExpression {
   private Timestamp timestampValue;
   private byte[] bytesValue;
 
-  private transient final SimpleDateFormat formatter = new SimpleDateFormat("yyyy-MM-dd");
   private transient final Text text = new Text();
   private transient final Date date = new Date(0);
 
@@ -105,8 +103,9 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
       case CHAR:
       case VARCHAR:
         try {
-          date.setTime(formatter.parse(new String(bytesValue, "UTF-8")).getTime());
-          baseDate = DateWritableV2.dateToDays(date);
+          org.apache.hadoop.hive.common.type.Date hiveDate
+              = org.apache.hadoop.hive.common.type.Date.valueOf(new String(bytesValue, StandardCharsets.UTF_8));
+          baseDate = hiveDate.toEpochDay();
           break;
         } catch (Exception e) {
           outputColVector.noNulls = false;
@@ -350,9 +349,10 @@ protected void evaluateString(ColumnVector columnVector, LongColumnVector output
     BytesColumnVector bcv = (BytesColumnVector) columnVector;
     text.set(bcv.vector[i], bcv.start[i], bcv.length[i]);
     try {
-      date.setTime(formatter.parse(text.toString()).getTime());
-      output.vector[i] = DateWritableV2.dateToDays(date) - baseDate;
-    } catch (ParseException e) {
+      org.apache.hadoop.hive.common.type.Date hiveDate
+          = org.apache.hadoop.hive.common.type.Date.valueOf(text.toString());
+      output.vector[i] = hiveDate.toEpochDay() - baseDate;
+    } catch (IllegalArgumentException e) {
       output.vector[i] = 1;
       output.isNull[i] = true;
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffScalarCol.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffScalarCol.java
index 3eeba83a3b..0e9e346f1a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffScalarCol.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/VectorUDFDateDiffScalarCol.java
@@ -30,10 +30,9 @@
 import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
 import org.apache.hadoop.io.Text;
 
+import java.nio.charset.StandardCharsets;
 import java.sql.Date;
 import java.sql.Timestamp;
-import java.text.ParseException;
-import java.text.SimpleDateFormat;
 import java.util.Arrays;
 
 public class VectorUDFDateDiffScalarCol extends VectorExpression {
@@ -43,7 +42,6 @@ public class VectorUDFDateDiffScalarCol extends VectorExpression {
   private Timestamp timestampValue = null;
   private byte[] stringValue;
 
-  private transient final SimpleDateFormat formatter = new SimpleDateFormat("yyyy-MM-dd");
   private transient final Text text = new Text();
   private transient final Date date = new Date(0);
 
@@ -106,8 +104,9 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
       case CHAR:
       case VARCHAR:
         try {
-          date.setTime(formatter.parse(new String(stringValue, "UTF-8")).getTime());
-          baseDate = DateWritableV2.dateToDays(date);
+          org.apache.hadoop.hive.common.type.Date hiveDate
+              = org.apache.hadoop.hive.common.type.Date.valueOf(new String(stringValue, StandardCharsets.UTF_8));
+          baseDate = hiveDate.toEpochDay();
           break;
         } catch (Exception e) {
           outputColVector.noNulls = false;
@@ -352,9 +351,10 @@ protected void evaluateString(ColumnVector columnVector, LongColumnVector output
     BytesColumnVector bcv = (BytesColumnVector) columnVector;
     text.set(bcv.vector[i], bcv.start[i], bcv.length[i]);
     try {
-      date.setTime(formatter.parse(text.toString()).getTime());
-      output.vector[i] = baseDate - DateWritableV2.dateToDays(date);
-    } catch (ParseException e) {
+      org.apache.hadoop.hive.common.type.Date hiveDate
+          = org.apache.hadoop.hive.common.type.Date.valueOf(text.toString());
+      output.vector[i] = baseDate - hiveDate.toEpochDay();
+    } catch (IllegalArgumentException e) {
       output.vector[i] = 1;
       output.isNull[i] = true;
     }
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorGenericDateExpressions.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorGenericDateExpressions.java
index f42282c40f..62f0c51ceb 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorGenericDateExpressions.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorGenericDateExpressions.java
@@ -21,6 +21,7 @@
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;
 import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;
+import org.apache.hadoop.hive.ql.exec.vector.DateColumnVector;
 import org.apache.hadoop.hive.ql.exec.vector.LongColumnVector;
 import org.apache.hadoop.hive.ql.exec.vector.TestVectorizedRowBatch;
 import org.apache.hadoop.hive.ql.exec.vector.TimestampColumnVector;
@@ -38,6 +39,7 @@
 import java.sql.Date;
 import java.sql.Timestamp;
 import java.text.SimpleDateFormat;
+import java.time.LocalDate;
 import java.util.Arrays;
 import java.util.List;
 import java.util.Random;
@@ -580,6 +582,78 @@ public void testDateDiffColScalar() throws HiveException {
     Assert.assertEquals(batch.cols[1].isNull[0], true);
   }
 
+  @Test
+  public void testDateDiffColScalarWithTz() throws HiveException {
+    final TimeZone originalTz = TimeZone.getDefault();
+    try {
+      TimeZone.setDefault(TimeZone.getTimeZone("GMT+8"));
+
+      // input column vector - 1st arg to datediff()
+      DateColumnVector dateColumnVector = new DateColumnVector(1);
+      dateColumnVector.fill(LocalDate.parse("2021-07-06").toEpochDay());
+
+      // scalar date string - 2nd arg to datediff()
+      byte[] scalarDateBytes = "2021-07-01".getBytes(utf8);
+
+
+      VectorExpression udf = new VectorUDFDateDiffColScalar(0, scalarDateBytes, 1);
+      udf.setInputTypeInfos(TypeInfoFactory.dateTypeInfo, TypeInfoFactory.stringTypeInfo);
+      udf.transientInit(hiveConf);
+
+      VectorizedRowBatch batch = new VectorizedRowBatch(2, 1);
+      batch.cols[0] = dateColumnVector;
+      // output container
+      LongColumnVector outputVector = new LongColumnVector(1);
+      batch.cols[1] = outputVector;
+      udf.evaluate(batch);
+      // ("2021-07-06" - "2021-07-01")
+      Assert.assertEquals(5, outputVector.vector[0]);
+    } finally {
+      TimeZone.setDefault(originalTz);
+    }
+  }
+
+  @Test
+  public void testDateDiffScalarColWithTz() throws HiveException {
+    final TimeZone originalTz = TimeZone.getDefault();
+    try {
+      TimeZone.setDefault(TimeZone.getTimeZone("GMT+8"));
+
+      // scalar date string - 1st arg to datediff()
+      byte[] scalarDateBytes = "2021-07-01".getBytes(utf8);
+
+      // input column vector - 2nd arg to datediff()
+      DateColumnVector dateColumnVector = new DateColumnVector(1);
+      dateColumnVector.fill(LocalDate.parse("2021-07-06").toEpochDay());
+
+      VectorExpression udf = new VectorUDFDateDiffScalarCol(scalarDateBytes, 0, 1);
+      udf.setInputTypeInfos(TypeInfoFactory.stringTypeInfo, TypeInfoFactory.dateTypeInfo);
+      udf.transientInit(hiveConf);
+
+      VectorizedRowBatch batch = new VectorizedRowBatch(2, 1);
+      batch.cols[0] = dateColumnVector;
+      // output container
+      LongColumnVector outputVector = new LongColumnVector(1);
+      batch.cols[1] = outputVector;
+      udf.evaluate(batch);
+      // ("2021-07-01" - "2021-07-06")
+      Assert.assertEquals(-5, outputVector.vector[0]);
+    } finally {
+      TimeZone.setDefault(originalTz);
+    }
+  }
+
+  @Test
+  public void testDateDiffColColWithTz() throws HiveException {
+    final TimeZone originalTz = TimeZone.getDefault();
+    try {
+      TimeZone.setDefault(TimeZone.getTimeZone("GMT+8"));
+      testDateDiffColCol();
+    } finally {
+      TimeZone.setDefault(originalTz);
+    }
+  }
+
   private void validateDateDiff(VectorizedRowBatch batch,
                                 LongColumnVector date1, LongColumnVector date2,
                                 PrimitiveCategory colType1, PrimitiveCategory colType2)
diff --git a/ql/src/test/queries/clientpositive/udf_datediff_with_tz.q b/ql/src/test/queries/clientpositive/udf_datediff_with_tz.q
new file mode 100644
index 0000000000..27a9ab2d2f
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/udf_datediff_with_tz.q
@@ -0,0 +1,15 @@
+--! qt:timezone:GMT+8
+
+--create test data
+create external table test_dt(id string, dt date);
+insert into test_dt values('11', '2021-07-06'), ('22', '2021-07-07');
+
+--test all the three variants of datediff() - (col,scalar), (scalar, col), (col, col)
+select datediff(dt1.dt, '2021-07-01') from test_dt dt1;
+select datediff(dt1.dt, '2021-07-01') from test_dt dt1 left join test_dt dt on dt1.id = dt.id;
+
+select datediff('2021-07-01', dt1.dt) from test_dt dt1;
+select datediff('2021-07-01', dt1.dt) from test_dt dt1 left join test_dt dt on dt1.id = dt.id;
+
+select datediff(dt1.dt, dt1.dt) from test_dt dt1;
+select datediff(dt1.dt, dt1.dt) from test_dt dt1 left join test_dt dt on dt1.id = dt.id;
\ No newline at end of file
diff --git a/ql/src/test/results/clientpositive/llap/udf_datediff_with_tz.q.out b/ql/src/test/results/clientpositive/llap/udf_datediff_with_tz.q.out
new file mode 100644
index 0000000000..cee09b62b6
--- /dev/null
+++ b/ql/src/test/results/clientpositive/llap/udf_datediff_with_tz.q.out
@@ -0,0 +1,78 @@
+PREHOOK: query: create external table test_dt(id string, dt date)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@test_dt
+POSTHOOK: query: create external table test_dt(id string, dt date)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@test_dt
+PREHOOK: query: insert into test_dt values('11', '2021-07-06'), ('22', '2021-07-07')
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@test_dt
+POSTHOOK: query: insert into test_dt values('11', '2021-07-06'), ('22', '2021-07-07')
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@test_dt
+POSTHOOK: Lineage: test_dt.dt SCRIPT []
+POSTHOOK: Lineage: test_dt.id SCRIPT []
+PREHOOK: query: select datediff(dt1.dt, '2021-07-01') from test_dt dt1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+POSTHOOK: query: select datediff(dt1.dt, '2021-07-01') from test_dt dt1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+5
+6
+PREHOOK: query: select datediff(dt1.dt, '2021-07-01') from test_dt dt1 left join test_dt dt on dt1.id = dt.id
+PREHOOK: type: QUERY
+PREHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+POSTHOOK: query: select datediff(dt1.dt, '2021-07-01') from test_dt dt1 left join test_dt dt on dt1.id = dt.id
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+5
+6
+PREHOOK: query: select datediff('2021-07-01', dt1.dt) from test_dt dt1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+POSTHOOK: query: select datediff('2021-07-01', dt1.dt) from test_dt dt1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+-5
+-6
+PREHOOK: query: select datediff('2021-07-01', dt1.dt) from test_dt dt1 left join test_dt dt on dt1.id = dt.id
+PREHOOK: type: QUERY
+PREHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+POSTHOOK: query: select datediff('2021-07-01', dt1.dt) from test_dt dt1 left join test_dt dt on dt1.id = dt.id
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+-5
+-6
+PREHOOK: query: select datediff(dt1.dt, dt1.dt) from test_dt dt1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+POSTHOOK: query: select datediff(dt1.dt, dt1.dt) from test_dt dt1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+0
+0
+PREHOOK: query: select datediff(dt1.dt, dt1.dt) from test_dt dt1 left join test_dt dt on dt1.id = dt.id
+PREHOOK: type: QUERY
+PREHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+POSTHOOK: query: select datediff(dt1.dt, dt1.dt) from test_dt dt1 left join test_dt dt on dt1.id = dt.id
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@test_dt
+#### A masked pattern was here ####
+0
+0
