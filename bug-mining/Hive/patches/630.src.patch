diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
index d212fb7176..7570ea45ee 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
@@ -1363,7 +1363,7 @@ private int unarchive(Hive db, AlterTableSimpleDesc simpleDesc)
       try {
 
         // Copy the files out of the archive into the temporary directory
-        String copySource = (new Path(sourceDir, "*")).toString();
+        String copySource = sourceDir.toString();
         String copyDest = tmpDir.toString();
         List<String> args = new ArrayList<String>();
         args.add("-cp");
diff --git a/ql/src/test/queries/clientpositive/archive.q b/ql/src/test/queries/clientpositive/archive.q
index ef04882aa0..3ed195be75 100644
--- a/ql/src/test/queries/clientpositive/archive.q
+++ b/ql/src/test/queries/clientpositive/archive.q
@@ -7,7 +7,7 @@ drop table tstsrcpart;
 create table tstsrc like src;
 insert overwrite table tstsrc select key, value from src;
 
-create table tstsrcpart like srcpart;
+create table tstsrcpart (key string, value string) partitioned by (ds string, hr string) clustered by (key) into 10 buckets;
 
 insert overwrite table tstsrcpart partition (ds='2008-04-08', hr='11')
 select key, value from srcpart where ds='2008-04-08' and hr='11';
diff --git a/ql/src/test/results/clientpositive/archive.q.out b/ql/src/test/results/clientpositive/archive.q.out
index 0dee7276ff..32fd1bc423 100644
--- a/ql/src/test/results/clientpositive/archive.q.out
+++ b/ql/src/test/results/clientpositive/archive.q.out
@@ -21,9 +21,9 @@ POSTHOOK: Input: default@src
 POSTHOOK: Output: default@tstsrc
 POSTHOOK: Lineage: tstsrc.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: tstsrc.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
-PREHOOK: query: create table tstsrcpart like srcpart
+PREHOOK: query: create table tstsrcpart (key string, value string) partitioned by (ds string, hr string) clustered by (key) into 10 buckets
 PREHOOK: type: CREATETABLE
-POSTHOOK: query: create table tstsrcpart like srcpart
+POSTHOOK: query: create table tstsrcpart (key string, value string) partitioned by (ds string, hr string) clustered by (key) into 10 buckets
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: default@tstsrcpart
 POSTHOOK: Lineage: tstsrc.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
