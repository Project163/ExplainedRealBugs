diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index 514257f3df..9df9cca278 100644
--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -1843,7 +1843,6 @@ public static enum ConfVars {
     TESTMODE_BUCKET_CODEC_VERSION("hive.test.bucketcodec.version", 1,
       "For testing only.  Will make ACID subsystem write RecordIdentifier.bucketId in specified\n" +
         "format", false),
-    HIVE_QUERY_TIMESTAMP("hive.query.timestamp", System.currentTimeMillis(), "query execute time."),
 
     HIVEMERGEMAPFILES("hive.merge.mapfiles", true,
         "Merge small files at the end of a map-only job"),
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java b/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
index 9f65a771f9..6bb756cc08 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
@@ -1924,7 +1924,6 @@ public String getNextValuesTempTableSuffix() {
    */
   public void setupQueryCurrentTimestamp() {
     queryCurrentTimestamp = new Timestamp(System.currentTimeMillis());
-    sessionConf.setLongVar(ConfVars.HIVE_QUERY_TIMESTAMP, queryCurrentTimestamp.getTime());
 
     // Provide a facility to set current timestamp during tests
     if (sessionConf.getBoolVar(ConfVars.HIVE_IN_TEST)) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java
index 91fd08f13e..7d3c3f46aa 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java
@@ -18,12 +18,8 @@
 package org.apache.hadoop.hive.ql.udf.generic;
 
 import java.sql.Date;
-import java.sql.Timestamp;
 
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.exec.Description;
-import org.apache.hadoop.hive.ql.exec.MapredContext;
 import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
 import org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
@@ -43,13 +39,6 @@
 public class GenericUDFCurrentDate extends GenericUDF {
 
   protected DateWritable currentDate;
-  private Configuration conf;
-
-  @Override
-  public void configure(MapredContext context) {
-    super.configure(context);
-    conf = context.getJobConf();
-  }
 
   @Override
   public ObjectInspector initialize(ObjectInspector[] arguments)
@@ -61,21 +50,8 @@ public ObjectInspector initialize(ObjectInspector[] arguments)
     }
 
     if (currentDate == null) {
-      SessionState ss = SessionState.get();
-      Timestamp queryTimestamp;
-      if (ss == null) {
-        if (conf == null) {
-          queryTimestamp = new Timestamp(System.currentTimeMillis());
-        } else {
-          queryTimestamp = new Timestamp(
-                  HiveConf.getLongVar(conf, HiveConf.ConfVars.HIVE_QUERY_TIMESTAMP));
-        }
-      } else {
-        queryTimestamp = ss.getQueryCurrentTimestamp();
-      }
-
       Date dateVal =
-              Date.valueOf(queryTimestamp.toString().substring(0, 10));
+          Date.valueOf(SessionState.get().getQueryCurrentTimestamp().toString().substring(0, 10));
       currentDate = new DateWritable(dateVal);
     }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java
index ca43840e37..9da51c84f5 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java
@@ -17,12 +17,7 @@
  */
 package org.apache.hadoop.hive.ql.udf.generic;
 
-import java.sql.Timestamp;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.exec.Description;
-import org.apache.hadoop.hive.ql.exec.MapredContext;
 import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
 import org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
@@ -42,13 +37,6 @@
 public class GenericUDFCurrentTimestamp extends GenericUDF {
 
   protected TimestampWritable currentTimestamp;
-  private Configuration conf;
-
-  @Override
-  public void configure(MapredContext context) {
-    super.configure(context);
-    conf = context.getJobConf();
-  }
 
   @Override
   public ObjectInspector initialize(ObjectInspector[] arguments)
@@ -60,19 +48,7 @@ public ObjectInspector initialize(ObjectInspector[] arguments)
     }
 
     if (currentTimestamp == null) {
-      SessionState ss = SessionState.get();
-      Timestamp queryTimestamp;
-      if (ss == null) {
-        if (conf == null) {
-          queryTimestamp = new Timestamp(System.currentTimeMillis());
-        } else {
-          queryTimestamp = new Timestamp(
-                  HiveConf.getLongVar(conf, HiveConf.ConfVars.HIVE_QUERY_TIMESTAMP));
-        }
-      } else {
-        queryTimestamp = ss.getQueryCurrentTimestamp();
-      }
-      currentTimestamp = new TimestampWritable(queryTimestamp);
+      currentTimestamp = new TimestampWritable(SessionState.get().getQueryCurrentTimestamp());
     }
 
     return PrimitiveObjectInspectorFactory.writableTimestampObjectInspector;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java
index 6ce72f7703..832983105f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java
@@ -18,11 +18,6 @@
 
 package org.apache.hadoop.hive.ql.udf.generic;
 
-import java.sql.Timestamp;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.hive.conf.HiveConf;
-import org.apache.hadoop.hive.ql.exec.MapredContext;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.apache.hadoop.hive.ql.exec.Description;
@@ -42,14 +37,6 @@
 public class GenericUDFUnixTimeStamp extends GenericUDFToUnixTimeStamp {
   private static final Logger LOG = LoggerFactory.getLogger(GenericUDFUnixTimeStamp.class);
   private LongWritable currentTimestamp; // retValue is transient so store this separately.
-  private Configuration conf;
-
-  @Override
-  public void configure(MapredContext context) {
-    super.configure(context);
-    conf = context.getJobConf();
-  }
-
   @Override
   protected void initializeInput(ObjectInspector[] arguments) throws UDFArgumentException {
     if (arguments.length > 0) {
@@ -57,19 +44,7 @@ protected void initializeInput(ObjectInspector[] arguments) throws UDFArgumentEx
     } else {
       if (currentTimestamp == null) {
         currentTimestamp = new LongWritable(0);
-        SessionState ss = SessionState.get();
-        Timestamp queryTimestamp;
-        if (ss == null) {
-          if (conf == null) {
-            queryTimestamp = new Timestamp(System.currentTimeMillis());
-          } else {
-            queryTimestamp = new Timestamp(
-                    HiveConf.getLongVar(conf, HiveConf.ConfVars.HIVE_QUERY_TIMESTAMP));
-          }
-        } else {
-          queryTimestamp = ss.getQueryCurrentTimestamp();
-        }
-        setValueFromTs(currentTimestamp, queryTimestamp);
+        setValueFromTs(currentTimestamp, SessionState.get().getQueryCurrentTimestamp());
         String msg = "unix_timestamp(void) is deprecated. Use current_timestamp instead.";
         SessionState.getConsole().printInfo(msg, false);
       }
