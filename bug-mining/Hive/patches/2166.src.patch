diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java
index 59b120e3e7..5c711cf73b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java
@@ -42,13 +42,13 @@
 import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;
 import org.apache.hadoop.hive.ql.exec.RowSchema;
 import org.apache.hadoop.hive.ql.exec.Utilities;
+import org.apache.hadoop.hive.ql.lib.DefaultGraphWalker;
 import org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher;
 import org.apache.hadoop.hive.ql.lib.Dispatcher;
 import org.apache.hadoop.hive.ql.lib.GraphWalker;
 import org.apache.hadoop.hive.ql.lib.Node;
 import org.apache.hadoop.hive.ql.lib.NodeProcessor;
 import org.apache.hadoop.hive.ql.lib.NodeProcessorCtx;
-import org.apache.hadoop.hive.ql.lib.PreOrderWalker;
 import org.apache.hadoop.hive.ql.lib.Rule;
 import org.apache.hadoop.hive.ql.lib.RuleRegExp;
 import org.apache.hadoop.hive.ql.metadata.Table;
@@ -95,7 +95,7 @@ public ParseContext transform(ParseContext pCtx) throws SemanticException {
     opRules.put(new RuleRegExp("Sorted Dynamic Partition", FS), getSortDynPartProc(pCtx));
 
     Dispatcher disp = new DefaultRuleDispatcher(null, opRules, null);
-    GraphWalker ogw = new PreOrderWalker(disp);
+    GraphWalker ogw = new DefaultGraphWalker(disp);
 
     ArrayList<Node> topNodes = new ArrayList<Node>();
     topNodes.addAll(pCtx.getTopOps().values());
diff --git a/ql/src/test/results/clientpositive/load_dyn_part14.q.out b/ql/src/test/results/clientpositive/load_dyn_part14.q.out
index 603f2f84ab..48270bc1a2 100644
--- a/ql/src/test/results/clientpositive/load_dyn_part14.q.out
+++ b/ql/src/test/results/clientpositive/load_dyn_part14.q.out
@@ -132,18 +132,14 @@ STAGE PLANS:
       Reduce Operator Tree:
         Extract
           Statistics: Num rows: 0 Data size: 17436 Basic stats: PARTIAL Column stats: COMPLETE
-          Select Operator
-            expressions: _col0 (type: string), _col1 (type: string)
-            outputColumnNames: _col0, _col1
+          File Output Operator
+            compressed: false
             Statistics: Num rows: 0 Data size: 17436 Basic stats: PARTIAL Column stats: COMPLETE
-            File Output Operator
-              compressed: false
-              Statistics: Num rows: 0 Data size: 17436 Basic stats: PARTIAL Column stats: COMPLETE
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: default.nzhang_part14
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                name: default.nzhang_part14
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/merge4.q.out b/ql/src/test/results/clientpositive/merge4.q.out
index 8c06473d14..b32ac91732 100644
--- a/ql/src/test/results/clientpositive/merge4.q.out
+++ b/ql/src/test/results/clientpositive/merge4.q.out
@@ -2869,18 +2869,14 @@ STAGE PLANS:
       Reduce Operator Tree:
         Extract
           Statistics: Num rows: 58 Data size: 17436 Basic stats: COMPLETE Column stats: COMPLETE
-          Select Operator
-            expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)
-            outputColumnNames: _col0, _col1, _col2
-            Statistics: Num rows: 58 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
-            File Output Operator
-              compressed: false
-              Statistics: Num rows: 58 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: default.nzhang_part
+          File Output Operator
+            compressed: false
+            Statistics: Num rows: 58 Data size: 17436 Basic stats: COMPLETE Column stats: COMPLETE
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                name: default.nzhang_part
 
   Stage: Stage-8
     Conditional Operator
diff --git a/ql/src/test/results/clientpositive/union_remove_17.q.out b/ql/src/test/results/clientpositive/union_remove_17.q.out
index d277ce0517..3ca10c10b7 100644
--- a/ql/src/test/results/clientpositive/union_remove_17.q.out
+++ b/ql/src/test/results/clientpositive/union_remove_17.q.out
@@ -107,18 +107,14 @@ STAGE PLANS:
       Reduce Operator Tree:
         Extract
           Statistics: Num rows: 0 Data size: 60 Basic stats: PARTIAL Column stats: NONE
-          Select Operator
-            expressions: _col0 (type: string), _col1 (type: bigint), _col2 (type: string)
-            outputColumnNames: _col0, _col1, _col2
+          File Output Operator
+            compressed: false
             Statistics: Num rows: 0 Data size: 60 Basic stats: PARTIAL Column stats: NONE
-            File Output Operator
-              compressed: false
-              Statistics: Num rows: 0 Data size: 60 Basic stats: PARTIAL Column stats: NONE
-              table:
-                  input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
-                  name: default.outputtbl1
+            table:
+                input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
+                output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
+                serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
+                name: default.outputtbl1
 
   Stage: Stage-0
     Move Operator
