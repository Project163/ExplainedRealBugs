diff --git a/parser/src/java/org/apache/hadoop/hive/ql/parse/Quotation.java b/parser/src/java/org/apache/hadoop/hive/ql/parse/Quotation.java
index da94ed9132..effba13b7f 100644
--- a/parser/src/java/org/apache/hadoop/hive/ql/parse/Quotation.java
+++ b/parser/src/java/org/apache/hadoop/hive/ql/parse/Quotation.java
@@ -29,28 +29,34 @@ public enum Quotation {
    * Quotation of identifiers and special characters in identifiers are not allowed.
    * But regular expressions in backticks are supported for column names.
    */
-  NONE("none"),
+  NONE("none", ""),
   /**
    * Use the backtick character to quote identifiers having special characters.
    * Use single quotes to quote string literals. Double quotes are also accepted but not recommended.
    */
-  BACKTICKS("column"),
+  BACKTICKS("column", "`"),
   /**
    * SQL standard way to quote identifiers.
    * Use double quotes to quote identifiers having special characters and single quotes for string literals.
    */
-  STANDARD("standard");
+  STANDARD("standard", "\"");
 
-  Quotation(String stringValue) {
+  Quotation(String stringValue, String quotationChar) {
     this.stringValue = stringValue;
+    this.quotationChar = quotationChar;
   }
 
   private final String stringValue;
+  private final String quotationChar;
 
   public String stringValue() {
     return stringValue;
   }
 
+  public String getQuotationChar() {
+    return quotationChar;
+  }
+
   public static Quotation from(Configuration configuration) {
     String supportedQIds;
     if (configuration == null) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/ddl/table/constraint/ConstraintsUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/ddl/table/constraint/ConstraintsUtils.java
index 07350e26b7..3291e3daef 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/ddl/table/constraint/ConstraintsUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/ddl/table/constraint/ConstraintsUtils.java
@@ -19,9 +19,13 @@
 package org.apache.hadoop.hive.ql.ddl.table.constraint;
 
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.List;
 import java.util.Map;
+import java.util.Stack;
 
+import com.google.common.collect.HashMultimap;
+import com.google.common.collect.SetMultimap;
 import org.antlr.runtime.TokenRewriteStream;
 import org.antlr.runtime.tree.Tree;
 import org.apache.hadoop.conf.Configuration;
@@ -36,10 +40,17 @@
 import org.apache.hadoop.hive.ql.ErrorMsg;
 import org.apache.hadoop.hive.ql.exec.ColumnInfo;
 import org.apache.hadoop.hive.ql.exec.FunctionRegistry;
+import org.apache.hadoop.hive.ql.lib.CostLessRuleDispatcher;
+import org.apache.hadoop.hive.ql.lib.ExpressionWalker;
+import org.apache.hadoop.hive.ql.lib.Node;
+import org.apache.hadoop.hive.ql.lib.NodeProcessorCtx;
+import org.apache.hadoop.hive.ql.lib.SemanticGraphWalker;
+import org.apache.hadoop.hive.ql.lib.SemanticNodeProcessor;
 import org.apache.hadoop.hive.ql.parse.ASTNode;
 import org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer;
 import org.apache.hadoop.hive.ql.parse.HiveParser;
 import org.apache.hadoop.hive.ql.parse.ParseDriver;
+import org.apache.hadoop.hive.ql.parse.Quotation;
 import org.apache.hadoop.hive.ql.parse.RowResolver;
 import org.apache.hadoop.hive.ql.parse.SemanticException;
 import org.apache.hadoop.hive.ql.parse.type.ExprNodeTypeCheck;
@@ -58,6 +69,9 @@
  * Utilities for constraints.
  */
 public final class ConstraintsUtils {
+
+  public static final String CHECK_CONSTRAINT_PROGRAM = "CHECK_CONSTRAINT_PROGRAM";
+
   private ConstraintsUtils() {
     throw new UnsupportedOperationException("ConstraintsUtils should not be instantiated!");
   }
@@ -241,7 +255,9 @@ private static List<ConstraintInfo> generateConstraintInfos(ASTNode child, List<
         // try to get default value only if this is DEFAULT constraint
         checkOrDefaultValue = getDefaultValue(grandChild, typeChildForDefault, tokenRewriteStream);
       } else if (childType == HiveParser.TOK_CHECK_CONSTRAINT) {
-        checkOrDefaultValue = tokenRewriteStream.toOriginalString(grandChild.getTokenStartIndex(),
+        UnparseTranslator unparseTranslator = collectUnescapeIdentifierTranslations(grandChild);
+        unparseTranslator.applyTranslations(tokenRewriteStream, CHECK_CONSTRAINT_PROGRAM);
+        checkOrDefaultValue = tokenRewriteStream.toString(CHECK_CONSTRAINT_PROGRAM, grandChild.getTokenStartIndex(),
             grandChild.getTokenStopIndex());
       }
     }
@@ -282,6 +298,52 @@ private static List<ConstraintInfo> generateConstraintInfos(ASTNode child, List<
     return constraintInfos;
   }
 
+  static class ConstraintExpressionContext implements NodeProcessorCtx {
+    private UnparseTranslator unparseTranslator;
+
+    public ConstraintExpressionContext(UnparseTranslator unparseTranslator) {
+      this.unparseTranslator = unparseTranslator;
+    }
+
+    public UnparseTranslator getUnparseTranslator() {
+      return unparseTranslator;
+    }
+  }
+
+  private static UnparseTranslator collectUnescapeIdentifierTranslations(ASTNode node)
+      throws SemanticException {
+    UnparseTranslator unparseTranslator = new UnparseTranslator(Quotation.BACKTICKS);
+    unparseTranslator.enable();
+
+    SetMultimap<Integer, SemanticNodeProcessor> astNodeToProcessor = HashMultimap.create();
+    astNodeToProcessor.put(HiveParser.TOK_TABLE_OR_COL, new ColumnExprProcessor());
+    astNodeToProcessor.put(HiveParser.DOT, new ColumnExprProcessor());
+    NodeProcessorCtx nodeProcessorCtx = new ConstraintExpressionContext(unparseTranslator);
+
+    CostLessRuleDispatcher costLessRuleDispatcher = new CostLessRuleDispatcher(
+        (nd, stack, procCtx, nodeOutputs) -> null, astNodeToProcessor, nodeProcessorCtx);
+    SemanticGraphWalker walker = new ExpressionWalker(costLessRuleDispatcher);
+    walker.startWalking(Collections.singletonList(node), null);
+    return unparseTranslator;
+  }
+
+  static class ColumnExprProcessor implements SemanticNodeProcessor {
+
+    @Override
+    public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx, Object... nodeOutputs)
+        throws SemanticException {
+      UnparseTranslator unparseTranslator = ((ConstraintExpressionContext)procCtx).getUnparseTranslator();
+      ASTNode tokTableOrColNode = (ASTNode) nd;
+      for (int i = 0; i < tokTableOrColNode.getChildCount(); ++i) {
+        ASTNode child = (ASTNode) tokTableOrColNode.getChild(i);
+        if (child.getType() == HiveParser.Identifier) {
+          unparseTranslator.addIdentifierTranslation(child);
+        }
+      }
+      return null;
+    }
+  }
+
   private static final int DEFAULT_MAX_LEN = 255;
 
   /**
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveUtils.java
index 8009edca22..199c564bd7 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveUtils.java
@@ -285,11 +285,19 @@ public static String unparseIdentifier(String identifier, Configuration conf) {
     // in identifier by doubling them up.
     Quotation quotation = Quotation.from(conf);
     if (quotation != Quotation.NONE) {
-      identifier = identifier.replaceAll("`", "``");
+      return unparseIdentifier(identifier, Quotation.BACKTICKS);
     }
     return "`" + identifier + "`";
   }
 
+  public static String unparseIdentifier(String identifier, Quotation quotation) {
+    return String.format("%s%s%s",
+        quotation.getQuotationChar(),
+        identifier.replaceAll(
+            quotation.getQuotationChar(), quotation.getQuotationChar() + quotation.getQuotationChar()),
+        quotation.getQuotationChar());
+  }
+
   public static HiveStorageHandler getStorageHandler(
     Configuration conf, String className) throws HiveException {
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/UnparseTranslator.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/UnparseTranslator.java
index eadafff4ce..e78bb0177f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/UnparseTranslator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/UnparseTranslator.java
@@ -43,10 +43,14 @@ public class UnparseTranslator {
   private final NavigableMap<Integer, Translation> translations;
   private final List<CopyTranslation> copyTranslations;
   private boolean enabled;
-  private Configuration conf;
+  private Quotation quotation;
 
-  public UnparseTranslator(Configuration conf) {
-    this.conf = conf;
+  public UnparseTranslator(Configuration configuration) {
+    this(Quotation.from(configuration));
+  }
+
+  public UnparseTranslator(Quotation quotation) {
+    this.quotation = quotation;
     translations = new TreeMap<Integer, Translation>();
     copyTranslations = new ArrayList<CopyTranslation>();
   }
@@ -54,7 +58,7 @@ public UnparseTranslator(Configuration conf) {
   /**
    * Enable this translator.
    */
-  void enable() {
+  public void enable() {
     enabled = true;
   }
 
@@ -161,12 +165,12 @@ public void addTableNameTranslation(ASTNode tableName, String currentDatabaseNam
     else {
       // transform the table reference to an absolute reference (i.e., "db.table")
       StringBuilder replacementText = new StringBuilder();
-      replacementText.append(HiveUtils.unparseIdentifier(currentDatabaseName, conf));
+      replacementText.append(HiveUtils.unparseIdentifier(currentDatabaseName, quotation));
       replacementText.append('.');
 
       ASTNode identifier = (ASTNode)tableName.getChild(0);
       String identifierText = BaseSemanticAnalyzer.unescapeIdentifier(identifier.getText());
-      replacementText.append(HiveUtils.unparseIdentifier(identifierText, conf));
+      replacementText.append(HiveUtils.unparseIdentifier(identifierText, quotation));
 
       addTranslation(identifier, replacementText.toString());
     }
@@ -185,7 +189,7 @@ public void addIdentifierTranslation(ASTNode identifier) {
     assert (identifier.getToken().getType() == HiveParser.Identifier);
     String replacementText = identifier.getText();
     replacementText = BaseSemanticAnalyzer.unescapeIdentifier(replacementText);
-    replacementText = HiveUtils.unparseIdentifier(replacementText, conf);
+    replacementText = HiveUtils.unparseIdentifier(replacementText, quotation);
     addTranslation(identifier, replacementText);
   }
 
@@ -239,7 +243,7 @@ void applyTranslations(TokenRewriteStream tokenRewriteStream) {
     applyTranslations(tokenRewriteStream, TokenRewriteStream.DEFAULT_PROGRAM_NAME);
   }
 
-  void applyTranslations(TokenRewriteStream tokenRewriteStream, String programName) {
+  public void applyTranslations(TokenRewriteStream tokenRewriteStream, String programName) {
     for (Map.Entry<Integer, Translation> entry : translations.entrySet()) {
       if (entry.getKey() > 0) { // negative means the key didn't exist in the original
                                 // stream (i.e.: we changed the tree)
diff --git a/ql/src/test/queries/clientpositive/quotedid_basic.q b/ql/src/test/queries/clientpositive/quotedid_basic.q
index ebaff82846..c0b10e1b08 100644
--- a/ql/src/test/queries/clientpositive/quotedid_basic.q
+++ b/ql/src/test/queries/clientpositive/quotedid_basic.q
@@ -39,3 +39,11 @@ select `x+1```, `y&y`, rank() over(partition by `x+1``` order by  `y&y`)
 from v1
 group by `x+1```, `y&y`
 ;
+
+create table test (
+    col1 int,
+    ` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` int check (` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` > 10) enable novalidate rely,
+    constraint check_constraint check (col1 + ` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` > 15) enable novalidate rely
+);
+
+describe formatted test;
diff --git a/ql/src/test/queries/clientpositive/quotedid_basic_standard.q b/ql/src/test/queries/clientpositive/quotedid_basic_standard.q
index 07ae79853a..0cf47b5a82 100644
--- a/ql/src/test/queries/clientpositive/quotedid_basic_standard.q
+++ b/ql/src/test/queries/clientpositive/quotedid_basic_standard.q
@@ -54,4 +54,13 @@ create table lv_table(c1 string) partitioned by(c2 string);
 create view "lv~!@#$%^&*()_q<>" partitioned on (c2) as select c1, c2 from lv_table;
 alter view "lv~!@#$%^&*()_q<>" add partition (c2='a');
 
+-- quoted identifier in check constraint
+create table test (
+    col1 int,
+    " ""%&'()*+,-/;<=>?[]_|{}$^!~#@`" int check (" ""%&'()*+,-/;<=>?[]_|{}$^!~#@`" > 10) enable novalidate rely,
+    constraint check_constraint check (col1 + " ""%&'()*+,-/;<=>?[]_|{}$^!~#@`" > 15) enable novalidate rely
+);
+
+describe formatted test;
+
 set hive.support.quoted.identifiers=column;
diff --git a/ql/src/test/results/clientnegative/check_constraint_aggregate.q.out b/ql/src/test/results/clientnegative/check_constraint_aggregate.q.out
index e641c81326..d529c135a4 100644
--- a/ql/src/test/results/clientnegative/check_constraint_aggregate.q.out
+++ b/ql/src/test/results/clientnegative/check_constraint_aggregate.q.out
@@ -1 +1 @@
-FAILED: SemanticException [Error 10128]: Invalid Constraint syntax Invalid CHECK constraint expression: sum(i) > 5. Line 1:0 Not yet supported place for UDAF 'sum'
+FAILED: SemanticException [Error 10128]: Invalid Constraint syntax Invalid CHECK constraint expression: sum(`i`) > 5. Line 1:0 Not yet supported place for UDAF 'sum'
diff --git a/ql/src/test/results/clientnegative/check_constraint_max_length.q.out b/ql/src/test/results/clientnegative/check_constraint_max_length.q.out
index a3eb23fcc1..ff26101df1 100644
--- a/ql/src/test/results/clientnegative/check_constraint_max_length.q.out
+++ b/ql/src/test/results/clientnegative/check_constraint_max_length.q.out
@@ -1 +1 @@
-FAILED: SemanticException [Error 10326]: Invalid Constraint syntax Constraint value: j > '345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234' exceeded maximum allowed length: 255
+FAILED: SemanticException [Error 10326]: Invalid Constraint syntax Constraint value: `j` > '345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234' exceeded maximum allowed length: 255
diff --git a/ql/src/test/results/clientnegative/check_constraint_nonboolean_expr.q.out b/ql/src/test/results/clientnegative/check_constraint_nonboolean_expr.q.out
index fe64d2c24c..17fe75cab2 100644
--- a/ql/src/test/results/clientnegative/check_constraint_nonboolean_expr.q.out
+++ b/ql/src/test/results/clientnegative/check_constraint_nonboolean_expr.q.out
@@ -1 +1 @@
-FAILED: SemanticException [Error 10326]: Invalid Constraint syntax Invalid CHECK constraint expression: i+j. Invalid Constraint syntax Only boolean type is supported for CHECK constraint: i+j. Found: int
+FAILED: SemanticException [Error 10326]: Invalid Constraint syntax Invalid CHECK constraint expression: `i`+`j`. Invalid Constraint syntax Only boolean type is supported for CHECK constraint: `i`+`j`. Found: int
diff --git a/ql/src/test/results/clientnegative/check_constraint_qual_name.q.out b/ql/src/test/results/clientnegative/check_constraint_qual_name.q.out
index bbda7f5947..d006d96a0e 100644
--- a/ql/src/test/results/clientnegative/check_constraint_qual_name.q.out
+++ b/ql/src/test/results/clientnegative/check_constraint_qual_name.q.out
@@ -1 +1 @@
-FAILED: SemanticException [Error 10326]: Invalid Constraint syntax Invalid CHECK constraint expression: tconstr.i>j. Invalid Constraint syntax Invalid type for CHECK constraint: tconstr.i>j
+FAILED: SemanticException [Error 10326]: Invalid Constraint syntax Invalid CHECK constraint expression: `tconstr`.`i`>`j`. Invalid Constraint syntax Invalid type for CHECK constraint: `tconstr`.`i`>`j`
diff --git a/ql/src/test/results/clientnegative/check_constraint_temporary_udf.q.out b/ql/src/test/results/clientnegative/check_constraint_temporary_udf.q.out
index 4eb4526bbc..3810428874 100644
--- a/ql/src/test/results/clientnegative/check_constraint_temporary_udf.q.out
+++ b/ql/src/test/results/clientnegative/check_constraint_temporary_udf.q.out
@@ -4,4 +4,4 @@ PREHOOK: Output: test_udf2
 POSTHOOK: query: CREATE TEMPORARY FUNCTION test_udf2 AS 'org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestGetJavaString'
 POSTHOOK: type: CREATEFUNCTION
 POSTHOOK: Output: test_udf2
-FAILED: SemanticException [Error 10326]: Invalid Constraint syntax Invalid CHECK constraint expression: test_udf2(v) <> 'vin'. Invalid Constraint syntax Temporary UDFs are not allowed in Check Constraints
+FAILED: SemanticException [Error 10326]: Invalid Constraint syntax Invalid CHECK constraint expression: test_udf2(`v`) <> 'vin'. Invalid Constraint syntax Temporary UDFs are not allowed in Check Constraints
diff --git a/ql/src/test/results/clientnegative/check_constraint_window_fun.q.out b/ql/src/test/results/clientnegative/check_constraint_window_fun.q.out
index 8582ea94cc..d9fa0f2eda 100644
--- a/ql/src/test/results/clientnegative/check_constraint_window_fun.q.out
+++ b/ql/src/test/results/clientnegative/check_constraint_window_fun.q.out
@@ -1 +1 @@
-FAILED: SemanticException [Error 10326]: Invalid Constraint syntax Invalid CHECK constraint expression: lead(i, 1) > 3. Invalid Constraint syntax Window functions are not allowed in Check Constraints
+FAILED: SemanticException [Error 10326]: Invalid Constraint syntax Invalid CHECK constraint expression: lead(`i`, 1) > 3. Invalid Constraint syntax Window functions are not allowed in Check Constraints
diff --git a/ql/src/test/results/clientpositive/llap/check_constraint.q.out b/ql/src/test/results/clientpositive/llap/check_constraint.q.out
index f332d035f7..143331420f 100644
--- a/ql/src/test/results/clientpositive/llap/check_constraint.q.out
+++ b/ql/src/test/results/clientpositive/llap/check_constraint.q.out
@@ -58,22 +58,22 @@ Sort Columns:       	[]
 # Check Constraints	 	 
 Table:              	default.table1_n0   	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:a       	Check Value:a BETWEEN i AND j	 
+Column Name:a       	Check Value:`a` BETWEEN `i` AND `j`	 
 	 	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:d       	Check Value:d > round(567.6) AND d < round(1000.4)	 
+Column Name:d       	Check Value:`d` > round(567.6) AND `d` < round(1000.4)	 
 	 	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:i       	Check Value:-i > -10	 
+Column Name:i       	Check Value:-`i` > -10	 
 	 	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:j       	Check Value:+j > 10 	 
+Column Name:j       	Check Value:+`j` > 10	 
 	 	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:ij      	Check Value:ij IS NOT NULL	 
+Column Name:ij      	Check Value:`ij` IS NOT NULL	 
 	 	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:bb      	Check Value:bb IN (23.4,56,4)	 
+Column Name:bb      	Check Value:`bb` IN (23.4,56,4)	 
 	 	 
 PREHOOK: query: EXPLAIN INSERT INTO table1_n0 values(1,100,true, 5, 23.4, 700.5)
 PREHOOK: type: QUERY
@@ -236,7 +236,7 @@ Storage Desc Params:
 # Check Constraints	 	 
 Table:              	default.table2_n0   	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:i       	Check Value:i + NULL > 0	 
+Column Name:i       	Check Value:`i` + NULL > 0	 
 	 	 
 PREHOOK: query: EXPLAIN INSERT INTO table2_n0 values(8)
 PREHOOK: type: QUERY
@@ -499,7 +499,7 @@ Column Name:        	url
 # Check Constraints	 	 
 Table:              	default.tmulti      	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:numclicks	Check Value:numClicks > 0	 
+Column Name:numclicks	Check Value:`numClicks` > 0	 
 	 	 
 PREHOOK: query: EXPLAIN INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '2018-01-12')
 PREHOOK: type: QUERY
@@ -664,13 +664,13 @@ Column Name:        	url
 # Check Constraints	 	 
 Table:              	default.tmulti      	 
 Constraint Name:    	chk1                	 
-Column Name:null    	Check Value:userName != NULL	 
+Column Name:null    	Check Value:`userName` != NULL	 
 	 	 
 Constraint Name:    	chk2                	 
-Column Name:null    	Check Value:numClicks <= 10000 AND userName != ''	 
+Column Name:null    	Check Value:`numClicks` <= 10000 AND `userName` != ''	 
 	 	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:numclicks	Check Value:numClicks > 0	 
+Column Name:numclicks	Check Value:`numClicks` > 0	 
 	 	 
 PREHOOK: query: EXPLAIN INSERT INTO tmulti values('hive.apache.com', 'user1', 48, '2018-01-12')
 PREHOOK: type: QUERY
@@ -821,7 +821,7 @@ Column Name:        	url
 # Check Constraints	 	 
 Table:              	default.tcase       	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:numclicks	Check Value:numclicks > 0	 
+Column Name:numclicks	Check Value:`numclicks` > 0	 
 	 	 
 PREHOOK: query: EXPLAIN INSERT INTO tcase values('hive.apache.com', 'user1', '2018-01-12', 48)
 PREHOOK: type: QUERY
@@ -973,7 +973,7 @@ Column Name:        	url
 # Check Constraints	 	 
 Table:              	default.tcast       	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:price   	Check Value:cast(numClicks as FLOAT)*price > 10.00	 
+Column Name:price   	Check Value:cast(`numClicks` as FLOAT)*`price` > 10.00	 
 	 	 
 PREHOOK: query: EXPLAIN INSERT INTO tcast values('www.google.com', 100, cast(0.5 as float))
 PREHOOK: type: QUERY
@@ -1214,7 +1214,7 @@ Column Name:i       	Default Value:89
 # Check Constraints	 	 
 Table:              	default.texpr       	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:b       	Check Value:((cast(d as float) + f) < cast(i as float) + (i*i))	 
+Column Name:b       	Check Value:((cast(`d` as float) + `f`) < cast(`i` as float) + (`i`*`i`))	 
 	 	 
 PREHOOK: query: explain insert into texpr values(3,3.4,5.6,true)
 PREHOOK: type: QUERY
@@ -1370,7 +1370,7 @@ Column Name:        	de
 # Check Constraints	 	 
 Table:              	default.acid_uami_n0	 
 Constraint Name:    	ch2                 	 
-Column Name:vc      	Check Value:de >= cast(i as decimal(5,2))	 
+Column Name:vc      	Check Value:`de` >= cast(`i` as decimal(5,2))	 
 	 	 
 PREHOOK: query: explain insert into table acid_uami_n0 select cast(key as int), cast (key as decimal(5,2)), value from src
 PREHOOK: type: QUERY
@@ -2468,7 +2468,7 @@ Column Name:        	a1
 # Check Constraints	 	 
 Table:              	default.tmerge      	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:key     	Check Value:key > 0 AND (key < 100 OR key = 5)	 
+Column Name:key     	Check Value:`key` > 0 AND (`key` < 100 OR `key` = 5)	 
 	 	 
 PREHOOK: query: create table nonacid (key int, a1 string, value string) stored as orc
 PREHOOK: type: CREATETABLE
@@ -3375,7 +3375,7 @@ Column Name:a       	Default Value:127Y
 # Check Constraints	 	 
 Table:              	default.numericdatatype	 
 Constraint Name:    	check1              	 
-Column Name:b       	Check Value:b in(4,5)	 
+Column Name:b       	Check Value:`b` in(4,5)	 
 	 	 
 PREHOOK: query: ALTER TABLE numericDataType DROP CONSTRAINT check1
 PREHOOK: type: ALTERTABLE_DROPCONSTRAINT
@@ -3576,7 +3576,7 @@ Sort Columns:       	[]
 # Check Constraints	 	 
 Table:              	default.tcheck      	 
 Constraint Name:    	check1              	 
-Column Name:b       	Check Value:b in(4,5)	 
+Column Name:b       	Check Value:`b` in(4,5)	 
 	 	 
 PREHOOK: query: EXPLAIN INSERT INTO tcheck(a) values(1)
 PREHOOK: type: QUERY
@@ -3972,7 +3972,7 @@ Storage Desc Params:
 # Check Constraints	 	 
 Table:              	default.trely       	 
 Constraint Name:    	#### A masked pattern was here ####	 
-Column Name:i       	Check Value:i>0     	 
+Column Name:i       	Check Value:`i`>0   	 
 	 	 
 PREHOOK: query: DROP TABLE trely
 PREHOOK: type: DROPTABLE
@@ -4030,7 +4030,7 @@ Storage Desc Params:
 # Check Constraints	 	 
 Table:              	default.tbl1_n1     	 
 Constraint Name:    	check1              	 
-Column Name:null    	Check Value:a != '' AND b > 4	 
+Column Name:null    	Check Value:`a` != '' AND `b` > 4	 
 	 	 
 PREHOOK: query: explain insert into tbl1_n1 values('a', 69)
 PREHOOK: type: QUERY
@@ -4164,10 +4164,10 @@ Storage Desc Params:
 # Check Constraints	 	 
 Table:              	default.tbl1_n1     	 
 Constraint Name:    	check1              	 
-Column Name:null    	Check Value:a != '' AND b > 4	 
+Column Name:null    	Check Value:`a` != '' AND `b` > 4	 
 	 	 
 Constraint Name:    	chk2                	 
-Column Name:null    	Check Value:b < 100 	 
+Column Name:null    	Check Value:`b` < 100	 
 	 	 
 PREHOOK: query: explain insert into tbl1_n1 values('a', 69)
 PREHOOK: type: QUERY
diff --git a/ql/src/test/results/clientpositive/llap/quotedid_basic.q.out b/ql/src/test/results/clientpositive/llap/quotedid_basic.q.out
index 622ceb4ddb..e21ee969d1 100644
--- a/ql/src/test/results/clientpositive/llap/quotedid_basic.q.out
+++ b/ql/src/test/results/clientpositive/llap/quotedid_basic.q.out
@@ -550,3 +550,65 @@ POSTHOOK: Input: default@v1
 199	val_199	1
 2	val_2	1
 20	val_20	1
+PREHOOK: query: create table test (
+    col1 int,
+    ` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` int check (` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` > 10) enable novalidate rely,
+    constraint check_constraint check (col1 + ` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` > 15) enable novalidate rely
+)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@test
+POSTHOOK: query: create table test (
+    col1 int,
+    ` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` int check (` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` > 10) enable novalidate rely,
+    constraint check_constraint check (col1 + ` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` > 15) enable novalidate rely
+)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@test
+PREHOOK: query: describe formatted test
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: default@test
+POSTHOOK: query: describe formatted test
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: default@test
+# col_name            	data_type           	comment             
+col1                	int                 	                    
+ "%&'()*+,-/;<=>?[]_|{}$^!~#@`	int                 	                    
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\" \\\"%&'()*+,-/;<=>?[]_|{}$^!~#@`\":\"true\",\"col1\":\"true\"}}
+	bucketing_version   	2                   
+	numFiles            	0                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	0                   
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+# Constraints	 	 
+	 	 
+# Check Constraints	 	 
+Table:              	default.test        	 
+Constraint Name:    	check_constraint    	 
+Column Name:null    	Check Value:`col1` + ` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` > 15	 
+	 	 
+Constraint Name:    	#### A masked pattern was here ####	 
+Column Name:null    	Check Value:` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` > 10	 
+	 	 
diff --git a/ql/src/test/results/clientpositive/llap/quotedid_basic_standard.q.out b/ql/src/test/results/clientpositive/llap/quotedid_basic_standard.q.out
index fbbda59103..b43ecbbb16 100644
--- a/ql/src/test/results/clientpositive/llap/quotedid_basic_standard.q.out
+++ b/ql/src/test/results/clientpositive/llap/quotedid_basic_standard.q.out
@@ -649,3 +649,65 @@ POSTHOOK: Input: default@lv_table
 POSTHOOK: Input: default@lv~!@#$%^&*()_q<>
 POSTHOOK: Output: default@lv~!@#$%^&*()_q<>
 POSTHOOK: Output: default@lv~!@#$%^&*()_q<>@c2=a
+PREHOOK: query: create table test (
+    col1 int,
+    " ""%&'()*+,-/;<=>?[]_|{}$^!~#@`" int check (" ""%&'()*+,-/;<=>?[]_|{}$^!~#@`" > 10) enable novalidate rely,
+    constraint check_constraint check (col1 + " ""%&'()*+,-/;<=>?[]_|{}$^!~#@`" > 15) enable novalidate rely
+)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@test
+POSTHOOK: query: create table test (
+    col1 int,
+    " ""%&'()*+,-/;<=>?[]_|{}$^!~#@`" int check (" ""%&'()*+,-/;<=>?[]_|{}$^!~#@`" > 10) enable novalidate rely,
+    constraint check_constraint check (col1 + " ""%&'()*+,-/;<=>?[]_|{}$^!~#@`" > 15) enable novalidate rely
+)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@test
+PREHOOK: query: describe formatted test
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: default@test
+POSTHOOK: query: describe formatted test
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: default@test
+# col_name            	data_type           	comment             
+col1                	int                 	                    
+ "%&'()*+,-/;<=>?[]_|{}$^!~#@`	int                 	                    
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\" \\\"%&'()*+,-/;<=>?[]_|{}$^!~#@`\":\"true\",\"col1\":\"true\"}}
+	bucketing_version   	2                   
+	numFiles            	0                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	0                   
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+# Constraints	 	 
+	 	 
+# Check Constraints	 	 
+Table:              	default.test        	 
+Constraint Name:    	check_constraint    	 
+Column Name:null    	Check Value:`col1` + ` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` > 15	 
+	 	 
+Constraint Name:    	#### A masked pattern was here ####	 
+Column Name:null    	Check Value:` "%&'()*+,-/;<=>?[]_|{}$^!~#@``` > 10	 
+	 	 
diff --git a/ql/src/test/results/clientpositive/llap/show_create_table.q.out b/ql/src/test/results/clientpositive/llap/show_create_table.q.out
index 8bc76f8e26..304e5ad7ff 100644
--- a/ql/src/test/results/clientpositive/llap/show_create_table.q.out
+++ b/ql/src/test/results/clientpositive/llap/show_create_table.q.out
@@ -114,8 +114,8 @@ TBLPROPERTIES (
 ALTER TABLE default.test ADD CONSTRAINT #### A masked pattern was here #### PRIMARY KEY (col1,col2) DISABLE NOVALIDATE RELY;
 ALTER TABLE default.test ADD CONSTRAINT c4_unique UNIQUE (col4) DISABLE NOVALIDATE RELY;
 ALTER TABLE test.test CHANGE COLUMN col2 col2 timestamp CONSTRAINT  DEFAULT CURRENT_TIMESTAMP() ENABLE NOVALIDATE RELY;
-ALTER TABLE default.test ADD CONSTRAINT c3_c4_check CHECK ((col3 + col4)/(col3 - col4) > 3) ENABLE NOVALIDATE NORELY;
-ALTER TABLE default.test ADD CONSTRAINT #### A masked pattern was here #### CHECK (col3 + col4 > 1) ENABLE NOVALIDATE RELY;
+ALTER TABLE default.test ADD CONSTRAINT c3_c4_check CHECK ((`col3` + `col4`)/(`col3` - `col4`) > 3) ENABLE NOVALIDATE NORELY;
+ALTER TABLE default.test ADD CONSTRAINT #### A masked pattern was here #### CHECK (`col3` + `col4` > 1) ENABLE NOVALIDATE RELY;
 ALTER TABLE default.test CHANGE COLUMN col1 col1 varchar(100) CONSTRAINT #### A masked pattern was here #### NOT NULL ENABLE NOVALIDATE RELY;
 ALTER TABLE default.test CHANGE COLUMN col4 col4 decimal(10,0) CONSTRAINT #### A masked pattern was here #### NOT NULL ENABLE NOVALIDATE RELY;
 PREHOOK: query: SHOW CREATE TABLE TEST2
