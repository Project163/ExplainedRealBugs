diff --git a/hbase-handler/src/test/queries/positive/hbase_disable_limitopt.q b/hbase-handler/src/test/queries/positive/hbase_disable_limitopt.q
new file mode 100644
index 0000000000..5918519a9b
--- /dev/null
+++ b/hbase-handler/src/test/queries/positive/hbase_disable_limitopt.q
@@ -0,0 +1,17 @@
+set hive.limit.optimize.enable=true;
+set hive.fetch.task.conversion=none;
+
+drop table if exists hht;
+
+CREATE EXTERNAL TABLE hht (key string, value int)
+STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
+WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf1:val")
+TBLPROPERTIES ("hbase.table.name" = "hht", "hbase.mapred.output.outputtable" = "hht", "external.table.purge" = "true");
+
+insert into hht values ('a', 1);
+insert into hht values ('b', 1);
+insert into hht values ('c', 1);
+
+select * from hht limit 10;
+
+drop table hht;
\ No newline at end of file
diff --git a/hbase-handler/src/test/results/positive/hbase_disable_limitopt.q.out b/hbase-handler/src/test/results/positive/hbase_disable_limitopt.q.out
new file mode 100644
index 0000000000..6a760d5992
--- /dev/null
+++ b/hbase-handler/src/test/results/positive/hbase_disable_limitopt.q.out
@@ -0,0 +1,61 @@
+PREHOOK: query: drop table if exists hht
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table if exists hht
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: CREATE EXTERNAL TABLE hht (key string, value int)
+STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
+WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf1:val")
+TBLPROPERTIES ("hbase.table.name" = "hht", "hbase.mapred.output.outputtable" = "hht", "external.table.purge" = "true")
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@hht
+POSTHOOK: query: CREATE EXTERNAL TABLE hht (key string, value int)
+STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
+WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf1:val")
+TBLPROPERTIES ("hbase.table.name" = "hht", "hbase.mapred.output.outputtable" = "hht", "external.table.purge" = "true")
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@hht
+PREHOOK: query: insert into hht values ('a', 1)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@hht
+POSTHOOK: query: insert into hht values ('a', 1)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@hht
+PREHOOK: query: insert into hht values ('b', 1)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@hht
+POSTHOOK: query: insert into hht values ('b', 1)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@hht
+PREHOOK: query: insert into hht values ('c', 1)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@hht
+POSTHOOK: query: insert into hht values ('c', 1)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@hht
+PREHOOK: query: select * from hht limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@hht
+#### A masked pattern was here ####
+POSTHOOK: query: select * from hht limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@hht
+#### A masked pattern was here ####
+a	1
+b	1
+c	1
+PREHOOK: query: drop table hht
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@hht
+PREHOOK: Output: default@hht
+POSTHOOK: query: drop table hht
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@hht
+POSTHOOK: Output: default@hht
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GlobalLimitOptimizer.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GlobalLimitOptimizer.java
index 4e47aea562..d7daeac7c8 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GlobalLimitOptimizer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GlobalLimitOptimizer.java
@@ -93,6 +93,10 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {
       //
       TableScanOperator ts = topOps.values().iterator().next();
       Table tab = ts.getConf().getTableMetadata();
+      if (tab.isNonNative()) {
+        LOG.info("Not enabling limit optimization on non native table: " + tab.getTableName());
+        return pctx;
+      }
       // StorageHandlers will always have empty tablePath.
       // GenMapRedUtils.setMapWork removes empty tablePath from input dir with select-Limit
       // InputFormat.getSplits wont be called if no input path & TS Vertex will have 0 task parallelism
