diff --git a/CHANGES.txt b/CHANGES.txt
index 718c58893c..e84eb4f957 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -31,6 +31,9 @@ Trunk -  Unreleased
     HIVE-1440. Bug in RCFiles with local work (map-join or sort-merge join)
     (He Yongqiang via namit)
 
+    HIVE-1454. insert overwrite and CTAS fail in hive local mode
+    (Joydeep Sen Sarma via He Yongqiang )
+
 Release 0.6.0 -  Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/RCFileOutputFormat.java b/ql/src/java/org/apache/hadoop/hive/ql/io/RCFileOutputFormat.java
index de0ff3b986..6c0c17048a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/RCFileOutputFormat.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/RCFileOutputFormat.java
@@ -134,8 +134,9 @@ public org.apache.hadoop.hive.ql.exec.FileSinkOperator.RecordWriter getHiveRecor
     }
 
     RCFileOutputFormat.setColumnNumber(jc, cols.length);
-    final RCFile.Writer outWriter = Utilities.createRCFileWriter(jc, FileSystem
-        .get(jc), finalOutPath, isCompressed);
+    final RCFile.Writer outWriter = Utilities.createRCFileWriter
+      (jc, finalOutPath.getFileSystem(jc),
+       finalOutPath, isCompressed);
 
     return new org.apache.hadoop.hive.ql.exec.FileSinkOperator.RecordWriter() {
       public void write(Writable r) throws IOException {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java
index 275a416cd9..90fa37b671 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java
@@ -24,6 +24,7 @@
 import java.util.List;
 import java.util.Stack;
 
+import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.Context;
 import org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator;
@@ -283,9 +284,10 @@ private String processFS(Node nd, Stack<Node> stack,
       dest = fsOp.getConf().getDirName();
 
       // generate the temporary file
+      // it must be on the same file system as the current destination
       ParseContext parseCtx = ctx.getParseCtx();
       Context baseCtx = parseCtx.getContext();
-      String tmpDir = baseCtx.getMRTmpFileURI();
+      String tmpDir = baseCtx.getExternalTmpFileURI((new Path(dest)).toUri());
 
       fsOp.getConf().setDirName(tmpDir);
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 252b89d4c1..6a0ae025e4 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -803,14 +803,26 @@ public void getMetaData(QB qb) throws SemanticException {
           String fname = stripQuotes(ast.getChild(0).getText());
           if ((!qb.getParseInfo().getIsSubQ())
               && (((ASTNode) ast.getChild(0)).getToken().getType() == HiveParser.TOK_TMP_FILE)) {
-            fname = ctx.getMRTmpFileURI();
-            ctx.setResDir(new Path(fname));
 
             if (qb.isCTAS()) {
               qb.setIsQuery(false);
+
+              // allocate a temporary output dir on the location of the table
+              String location = conf.getVar(HiveConf.ConfVars.METASTOREWAREHOUSE);
+              try {
+                fname = ctx.getExternalTmpFileURI
+                  (FileUtils.makeQualified(new Path(location), conf).toUri());
+
+              } catch (Exception e) {
+                throw new SemanticException("Error creating temporary folder on: "
+                                            + location, e);
+              }
+
             } else {
               qb.setIsQuery(true);
+              fname = ctx.getMRTmpFileURI();
             }
+            ctx.setResDir(new Path(fname));
           }
           qb.getMetaData().setDestForAlias(name, fname,
               (ast.getToken().getType() == HiveParser.TOK_DIR));
