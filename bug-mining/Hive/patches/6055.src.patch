diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
index 45839ad572..6119fc4cb7 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java
@@ -29,6 +29,7 @@
 import java.util.Set;
 import java.util.Stack;
 
+import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator;
@@ -804,8 +805,10 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx ctx,
         for (FieldNode col : cols) {
           int index = originalOutputColumnNames.indexOf(col.getFieldName());
           Table tab = cppCtx.getParseContext().getViewProjectToTableSchema().get(op);
+          List<FieldSchema> fullFieldList = new ArrayList<FieldSchema>(tab.getCols());
+          fullFieldList.addAll(tab.getPartCols());
           cppCtx.getParseContext().getColumnAccessInfo()
-              .add(tab.getCompleteName(), tab.getCols().get(index).getName());
+              .add(tab.getCompleteName(), fullFieldList.get(index).getName());
         }
       }
       if (cols.size() < originalOutputColumnNames.size()) {
diff --git a/ql/src/test/queries/clientpositive/column_pruning_partitioned_view.q b/ql/src/test/queries/clientpositive/column_pruning_partitioned_view.q
new file mode 100644
index 0000000000..0a1a6d7a58
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/column_pruning_partitioned_view.q
@@ -0,0 +1,3 @@
+CREATE TABLE lv_table(c1 STRING) PARTITIONED BY(c2 STRING);
+CREATE VIEW lv_view PARTITIONED ON (c2) AS SELECT c1, c2 FROM lv_table;
+EXPLAIN SELECT * FROM lv_view;
\ No newline at end of file
diff --git a/ql/src/test/results/clientpositive/column_pruning_partitioned_view.q.out b/ql/src/test/results/clientpositive/column_pruning_partitioned_view.q.out
new file mode 100644
index 0000000000..3b9fe540a6
--- /dev/null
+++ b/ql/src/test/results/clientpositive/column_pruning_partitioned_view.q.out
@@ -0,0 +1,42 @@
+PREHOOK: query: CREATE TABLE lv_table(c1 STRING) PARTITIONED BY(c2 STRING)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@lv_table
+POSTHOOK: query: CREATE TABLE lv_table(c1 STRING) PARTITIONED BY(c2 STRING)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@lv_table
+PREHOOK: query: CREATE VIEW lv_view PARTITIONED ON (c2) AS SELECT c1, c2 FROM lv_table
+PREHOOK: type: CREATEVIEW
+PREHOOK: Input: default@lv_table
+PREHOOK: Output: database:default
+PREHOOK: Output: default@lv_view
+POSTHOOK: query: CREATE VIEW lv_view PARTITIONED ON (c2) AS SELECT c1, c2 FROM lv_table
+POSTHOOK: type: CREATEVIEW
+POSTHOOK: Input: default@lv_table
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@lv_view
+POSTHOOK: Lineage: lv_view.c1 SIMPLE [(lv_table)lv_table.FieldSchema(name:c1, type:string, comment:null), ]
+PREHOOK: query: EXPLAIN SELECT * FROM lv_view
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT * FROM lv_view
+POSTHOOK: type: QUERY
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        TableScan
+          alias: lv_table
+          properties:
+            insideView TRUE
+          Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
+          Select Operator
+            expressions: c1 (type: string), c2 (type: string)
+            outputColumnNames: _col0, _col1
+            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
+            ListSink
+
