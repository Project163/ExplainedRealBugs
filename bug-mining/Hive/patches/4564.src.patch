diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
index 636f079471..00552a88ec 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
@@ -406,7 +406,11 @@ private void completeInitialization(Collection<Future<?>> fs) throws HiveExcepti
       }
     }
     if (asyncEx != null) {
-      throw new HiveException("Async initialization failed", asyncEx);
+      if (asyncEx instanceof Exception) {
+        throw new HiveException("Async initialization failed", asyncEx);
+      } else {
+        throw (Error) asyncEx;
+      }
     }
     completeInitializationOp(os);
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
index 449bef8e5c..2ab9ed2aa9 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
@@ -21,6 +21,7 @@
 import java.util.ArrayList;
 import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
+
 import java.beans.DefaultPersistenceDelegate;
 import java.beans.Encoder;
 import java.beans.Expression;
@@ -96,6 +97,7 @@
 import org.apache.hadoop.hive.common.StatsSetupConst;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
+import org.apache.hadoop.hive.llap.io.api.LlapProxy;
 import org.apache.hadoop.hive.metastore.MetaStoreUtils;
 import org.apache.hadoop.hive.metastore.Warehouse;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
@@ -194,6 +196,7 @@
 import org.slf4j.LoggerFactory;
 
 import com.esotericsoftware.kryo.Kryo;
+import com.esotericsoftware.kryo.KryoException;
 import com.google.common.base.Preconditions;
 
 /**
@@ -436,6 +439,7 @@ private static BaseWork getBaseWork(Configuration conf, String name) {
             throw new RuntimeException("Unknown work type: " + name);
           }
         }
+
         gWorkMap.get(conf).put(path, gWork);
       } else if (LOG.isDebugEnabled()) {
         LOG.debug("Found plan in cache for name: " + name);
@@ -446,6 +450,16 @@ private static BaseWork getBaseWork(Configuration conf, String name) {
       LOG.debug("File not found: " + fnf.getMessage());
       LOG.info("No plan file found: "+path);
       return null;
+    } catch (KryoException ke) {
+      Throwable cnfThrowable = findClassNotFoundException(ke);
+      if (LlapProxy.isDaemon() && (cnfThrowable != null)) {
+        LOG.error("Missing class \"" + cnfThrowable.getMessage() + "\". If this is a UDF and you " +
+            "are running LLAP, you may need to regenerate the llap startup script and restart " +
+            "llap with jars for your udf.", cnfThrowable);
+        throw new RuntimeException("Cannot find \"" + cnfThrowable.getMessage() + "\" You may" +
+           " need to regenerate the LLAP startup script and restart llap daemons.", cnfThrowable);
+      }
+      throw new RuntimeException(ke);
     } catch (Exception e) {
       String msg = "Failed to load plan: " + path + ": " + e;
       LOG.error(msg, e);
@@ -460,6 +474,16 @@ private static BaseWork getBaseWork(Configuration conf, String name) {
     }
   }
 
+  private static Throwable findClassNotFoundException(Throwable ke) {
+    while (ke != null) {
+      if (ke instanceof ClassNotFoundException) {
+        return ke;
+      }
+      ke = ke.getCause();
+    }
+    return null;
+  }
+
   public static void setWorkflowAdjacencies(Configuration conf, QueryPlan plan) {
     try {
       Graph stageGraph = plan.getQueryPlan().getStageGraph();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezProcessor.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezProcessor.java
index c560f37d0b..a33b6e215a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezProcessor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezProcessor.java
@@ -39,6 +39,7 @@
 import org.apache.tez.runtime.api.LogicalInput;
 import org.apache.tez.runtime.api.LogicalOutput;
 import org.apache.tez.runtime.api.ProcessorContext;
+import org.apache.tez.runtime.api.TaskFailureType;
 import org.apache.tez.runtime.library.api.KeyValueWriter;
 
 /**
@@ -178,6 +179,8 @@ protected void initializeAndRunProcessor(Map<String, LogicalInput> inputs,
     } finally {
       if (originalThrowable != null && originalThrowable instanceof Error) {
         LOG.error(StringUtils.stringifyException(originalThrowable));
+        getContext().reportFailure(TaskFailureType.FATAL, originalThrowable,
+            "Cannot recover from this error");
         throw new RuntimeException(originalThrowable);
       }
 
