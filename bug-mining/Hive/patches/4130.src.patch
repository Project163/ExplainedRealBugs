diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java b/metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
index 4c5043bb5c..8ff219558f 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
@@ -17,6 +17,7 @@
  */
 package org.apache.hadoop.hive.metastore.txn;
 
+import com.google.common.annotations.VisibleForTesting;
 import com.jolbox.bonecp.BoneCPConfig;
 import com.jolbox.bonecp.BoneCPDataSource;
 import org.apache.commons.dbcp.ConnectionFactory;
@@ -528,6 +529,7 @@ public LockResponse checkLock(CheckLockRequest rqst)
         else {
           heartbeatLock(dbConn, extLockId);
         }
+        closeDbConn(dbConn);
         dbConn = getDbConn(Connection.TRANSACTION_SERIALIZABLE);
         return checkLock(dbConn, extLockId);
       } catch (SQLException e) {
@@ -936,22 +938,24 @@ public void addDynamicPartitions(AddDynamicPartitions rqst)
   /**
    * For testing only, do not use.
    */
+  @VisibleForTesting
   int numLocksInLockTable() throws SQLException, MetaException {
-    Connection dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);
+    Connection dbConn = null;
     Statement stmt = null;
+    ResultSet rs = null;
     try {
+      dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);
       stmt = dbConn.createStatement();
       String s = "select count(*) from HIVE_LOCKS";
       LOG.debug("Going to execute query <" + s + ">");
-      ResultSet rs = stmt.executeQuery(s);
+      rs = stmt.executeQuery(s);
       rs.next();
       int rc = rs.getInt(1);
       // Necessary to clean up the transaction in the db.
       dbConn.rollback();
       return rc;
     } finally {
-      closeDbConn(dbConn);
-      closeStmt(stmt);
+      close(rs, stmt, dbConn);
     }
   }
 
@@ -978,7 +982,8 @@ protected Connection getDbConn(int isolationLevel) throws SQLException {
         return dbConn;
       } catch (SQLException e){
         if ((--rc) <= 0) throw e;
-        LOG.error("There is a problem with a connection from the pool, retrying", e);
+        LOG.error("There is a problem with a connection from the pool, retrying(rc=" + rc + "): " +
+          getMessage(e), e);
       }
     }
   }
@@ -1953,7 +1958,7 @@ private List<LockInfo> getLockInfoFromLockId(Connection dbConn, long extLockId)
       }
       if (!sawAtLeastOne) {
         throw new MetaException("This should never happen!  We already " +
-          "checked the lock existed but now we can't find it!");
+          "checked the lock(" + JavaUtils.lockIdToString(extLockId) + ") existed but now we can't find it!");
       }
       return ourLockInfo;
     } finally {
@@ -2118,6 +2123,9 @@ private static synchronized void setupJdbcConnectionPool(HiveConf conf) throws S
     if ("bonecp".equals(connectionPooler)) {
       BoneCPConfig config = new BoneCPConfig();
       config.setJdbcUrl(driverUrl);
+      //if we are waiting for connection for 60s, something is really wrong
+      //better raise an error than hang forever
+      config.setConnectionTimeoutInMs(60000);
       config.setMaxConnectionsPerPartition(10);
       config.setPartitionCount(1);
       config.setUser(user);
@@ -2276,9 +2284,14 @@ private static String getMessage(SQLException ex) {
    */
   private int getRequiredIsolationLevel() throws MetaException, SQLException {
     if(dbProduct == null) {
-      Connection tmp = getDbConn(Connection.TRANSACTION_READ_COMMITTED);
-      determineDatabaseProduct(tmp);
-      closeDbConn(tmp);
+      Connection tmp = null;
+      try {
+        tmp = getDbConn(Connection.TRANSACTION_READ_COMMITTED);
+        determineDatabaseProduct(tmp);
+      }
+      finally {
+        closeDbConn(tmp);
+      }
     }
     switch (dbProduct) {
       case DERBY:
