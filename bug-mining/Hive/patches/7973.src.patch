diff --git a/itests/qtest/pom.xml b/itests/qtest/pom.xml
index a17c974ec0..93b8e055f6 100644
--- a/itests/qtest/pom.xml
+++ b/itests/qtest/pom.xml
@@ -525,6 +525,7 @@
                 <property name="test.classpath" refid="maven.test.classpath"/>
                 <taskdef resource="net/sf/antcontrib/antcontrib.properties"
                   classpathref="maven.plugin.classpath" />
+                <delete dir="${project.build.directory}/localfs/"/>
                 <mkdir dir="${project.build.directory}/qfile-results/clientpositive/" />
                 <mkdir dir="${project.build.directory}/qfile-results/clientpositive/perf" />
                 <mkdir dir="${project.build.directory}/qfile-results/clientnegative/" />
diff --git a/ql/src/test/queries/clientnegative/translated_external_rename.q b/ql/src/test/queries/clientnegative/translated_external_rename.q
new file mode 100644
index 0000000000..dec2feacac
--- /dev/null
+++ b/ql/src/test/queries/clientnegative/translated_external_rename.q
@@ -0,0 +1,11 @@
+set metastore.metadata.transformer.class=org.apache.hadoop.hive.metastore.MetastoreDefaultTransformer;
+set metastore.metadata.transformer.location.mode=prohibit;
+
+set hive.fetch.task.conversion=none;
+set hive.compute.query.using.stats=false;
+
+create external table t (a integer);
+insert into t values(1);
+alter table t rename to t2;
+create table t (a integer);
+
diff --git a/ql/src/test/queries/clientpositive/translated_external_rename.q b/ql/src/test/queries/clientpositive/translated_external_rename.q
new file mode 100644
index 0000000000..dfbe40d796
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/translated_external_rename.q
@@ -0,0 +1,20 @@
+set metastore.metadata.transformer.class=org.apache.hadoop.hive.metastore.MetastoreDefaultTransformer;
+set metastore.metadata.transformer.location.mode=seqsuffix;
+
+set hive.fetch.task.conversion=none;
+set hive.compute.query.using.stats=false;
+
+create table t (a integer);
+insert into t values(1);
+alter table t rename to t2;
+create table t (a integer);
+insert into t values(2);
+
+select assert_true(count(1) = 1) from t;
+select assert_true(count(1) = 1) from t2;
+
+desc formatted t;
+desc formatted t2;
+
+drop table t2;
+select assert_true(count(1) = 1) from t;
diff --git a/ql/src/test/queries/clientpositive/translated_external_rename2.q b/ql/src/test/queries/clientpositive/translated_external_rename2.q
new file mode 100644
index 0000000000..834dbc3769
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/translated_external_rename2.q
@@ -0,0 +1,20 @@
+set metastore.metadata.transformer.class=org.apache.hadoop.hive.metastore.MetastoreDefaultTransformer;
+set metastore.metadata.transformer.location.mode=seqprefix;
+
+set hive.fetch.task.conversion=none;
+set hive.compute.query.using.stats=false;
+
+create table t (a integer);
+insert into t values(1);
+alter table t rename to t2;
+create table t (a integer);
+insert into t values(2);
+
+select assert_true(count(1) = 1) from t;
+select assert_true(count(1) = 1) from t2;
+
+desc formatted t;
+desc formatted t2;
+
+drop table t2;
+select assert_true(count(1) = 1) from t;
diff --git a/ql/src/test/results/clientnegative/translated_external_rename.q.out b/ql/src/test/results/clientnegative/translated_external_rename.q.out
new file mode 100644
index 0000000000..149ea71f3f
--- /dev/null
+++ b/ql/src/test/results/clientnegative/translated_external_rename.q.out
@@ -0,0 +1,31 @@
+PREHOOK: query: create external table t (a integer)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t
+POSTHOOK: query: create external table t (a integer)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t
+PREHOOK: query: insert into t values(1)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@t
+POSTHOOK: query: insert into t values(1)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@t
+POSTHOOK: Lineage: t.a SCRIPT []
+PREHOOK: query: alter table t rename to t2
+PREHOOK: type: ALTERTABLE_RENAME
+PREHOOK: Input: default@t
+PREHOOK: Output: default@t
+POSTHOOK: query: alter table t rename to t2
+POSTHOOK: type: ALTERTABLE_RENAME
+POSTHOOK: Input: default@t
+POSTHOOK: Output: default@t
+POSTHOOK: Output: default@t2
+PREHOOK: query: create table t (a integer)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t
+#### A masked pattern was here ####
diff --git a/ql/src/test/results/clientpositive/llap/translated_external_rename.q.out b/ql/src/test/results/clientpositive/llap/translated_external_rename.q.out
new file mode 100644
index 0000000000..110ce9bf51
--- /dev/null
+++ b/ql/src/test/results/clientpositive/llap/translated_external_rename.q.out
@@ -0,0 +1,153 @@
+PREHOOK: query: create table t (a integer)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t
+POSTHOOK: query: create table t (a integer)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t
+PREHOOK: query: insert into t values(1)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@t
+POSTHOOK: query: insert into t values(1)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@t
+POSTHOOK: Lineage: t.a SCRIPT []
+PREHOOK: query: alter table t rename to t2
+PREHOOK: type: ALTERTABLE_RENAME
+PREHOOK: Input: default@t
+PREHOOK: Output: default@t
+POSTHOOK: query: alter table t rename to t2
+POSTHOOK: type: ALTERTABLE_RENAME
+POSTHOOK: Input: default@t
+POSTHOOK: Output: default@t
+POSTHOOK: Output: default@t2
+PREHOOK: query: create table t (a integer)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t
+POSTHOOK: query: create table t (a integer)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t
+PREHOOK: query: insert into t values(2)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@t
+POSTHOOK: query: insert into t values(2)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@t
+POSTHOOK: Lineage: t.a SCRIPT []
+PREHOOK: query: select assert_true(count(1) = 1) from t
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t
+#### A masked pattern was here ####
+POSTHOOK: query: select assert_true(count(1) = 1) from t
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t
+#### A masked pattern was here ####
+NULL
+PREHOOK: query: select assert_true(count(1) = 1) from t2
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t2
+#### A masked pattern was here ####
+POSTHOOK: query: select assert_true(count(1) = 1) from t2
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t2
+#### A masked pattern was here ####
+NULL
+PREHOOK: query: desc formatted t
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: default@t
+POSTHOOK: query: desc formatted t
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: default@t
+# col_name            	data_type           	comment             
+a                   	int                 	                    
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	EXTERNAL_TABLE      	 
+Table Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"a\":\"true\"}}
+	EXTERNAL            	TRUE                
+	TRANSLATED_TO_EXTERNAL	TRUE                
+	bucketing_version   	2                   
+	external.table.purge	TRUE                
+	numFiles            	1                   
+	numRows             	1                   
+	rawDataSize         	1                   
+	totalSize           	2                   
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: desc formatted t2
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: default@t2
+POSTHOOK: query: desc formatted t2
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: default@t2
+# col_name            	data_type           	comment             
+a                   	int                 	                    
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	EXTERNAL_TABLE      	 
+Table Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"a\":\"true\"}}
+	EXTERNAL            	TRUE                
+	TRANSLATED_TO_EXTERNAL	TRUE                
+	bucketing_version   	2                   
+	external.table.purge	TRUE                
+#### A masked pattern was here ####
+	numFiles            	1                   
+	numRows             	1                   
+	rawDataSize         	1                   
+	totalSize           	2                   
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: drop table t2
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@t2
+PREHOOK: Output: default@t2
+POSTHOOK: query: drop table t2
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@t2
+POSTHOOK: Output: default@t2
+PREHOOK: query: select assert_true(count(1) = 1) from t
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t
+#### A masked pattern was here ####
+POSTHOOK: query: select assert_true(count(1) = 1) from t
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t
+#### A masked pattern was here ####
+NULL
diff --git a/ql/src/test/results/clientpositive/llap/translated_external_rename2.q.out b/ql/src/test/results/clientpositive/llap/translated_external_rename2.q.out
new file mode 100644
index 0000000000..110ce9bf51
--- /dev/null
+++ b/ql/src/test/results/clientpositive/llap/translated_external_rename2.q.out
@@ -0,0 +1,153 @@
+PREHOOK: query: create table t (a integer)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t
+POSTHOOK: query: create table t (a integer)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t
+PREHOOK: query: insert into t values(1)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@t
+POSTHOOK: query: insert into t values(1)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@t
+POSTHOOK: Lineage: t.a SCRIPT []
+PREHOOK: query: alter table t rename to t2
+PREHOOK: type: ALTERTABLE_RENAME
+PREHOOK: Input: default@t
+PREHOOK: Output: default@t
+POSTHOOK: query: alter table t rename to t2
+POSTHOOK: type: ALTERTABLE_RENAME
+POSTHOOK: Input: default@t
+POSTHOOK: Output: default@t
+POSTHOOK: Output: default@t2
+PREHOOK: query: create table t (a integer)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t
+POSTHOOK: query: create table t (a integer)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t
+PREHOOK: query: insert into t values(2)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@t
+POSTHOOK: query: insert into t values(2)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@t
+POSTHOOK: Lineage: t.a SCRIPT []
+PREHOOK: query: select assert_true(count(1) = 1) from t
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t
+#### A masked pattern was here ####
+POSTHOOK: query: select assert_true(count(1) = 1) from t
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t
+#### A masked pattern was here ####
+NULL
+PREHOOK: query: select assert_true(count(1) = 1) from t2
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t2
+#### A masked pattern was here ####
+POSTHOOK: query: select assert_true(count(1) = 1) from t2
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t2
+#### A masked pattern was here ####
+NULL
+PREHOOK: query: desc formatted t
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: default@t
+POSTHOOK: query: desc formatted t
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: default@t
+# col_name            	data_type           	comment             
+a                   	int                 	                    
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	EXTERNAL_TABLE      	 
+Table Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"a\":\"true\"}}
+	EXTERNAL            	TRUE                
+	TRANSLATED_TO_EXTERNAL	TRUE                
+	bucketing_version   	2                   
+	external.table.purge	TRUE                
+	numFiles            	1                   
+	numRows             	1                   
+	rawDataSize         	1                   
+	totalSize           	2                   
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: desc formatted t2
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: default@t2
+POSTHOOK: query: desc formatted t2
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: default@t2
+# col_name            	data_type           	comment             
+a                   	int                 	                    
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	EXTERNAL_TABLE      	 
+Table Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"a\":\"true\"}}
+	EXTERNAL            	TRUE                
+	TRANSLATED_TO_EXTERNAL	TRUE                
+	bucketing_version   	2                   
+	external.table.purge	TRUE                
+#### A masked pattern was here ####
+	numFiles            	1                   
+	numRows             	1                   
+	rawDataSize         	1                   
+	totalSize           	2                   
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+PREHOOK: query: drop table t2
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@t2
+PREHOOK: Output: default@t2
+POSTHOOK: query: drop table t2
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@t2
+POSTHOOK: Output: default@t2
+PREHOOK: query: select assert_true(count(1) = 1) from t
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t
+#### A masked pattern was here ####
+POSTHOOK: query: select assert_true(count(1) = 1) from t
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t
+#### A masked pattern was here ####
+NULL
diff --git a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java
index 70d41489ee..63f05b6179 100644
--- a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java
+++ b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/conf/MetastoreConf.java
@@ -955,6 +955,19 @@ public enum ConfVars {
             + "which is used by HMS Server to fetch the extended tables/partitions information \n"
             + "based on the data processor capabilities \n"
             + " This class should implement the IMetaStoreMetadataTransformer interface"),
+    METASTORE_METADATA_TRANSFORMER_TRANSLATED_TO_EXTERNAL_FOLLOWS_RENAMES(
+        "metastore.metadata.transformer.translated.to.external.follows.renames",
+        "metastore.metadata.transformer.translated.to.external.follows.renames", true,
+        "Wether TRANSLATED_TO_EXTERNAL tables should follow renames. In case the default directory exists "
+            + "the strategy of metastore.metadata.transformer.location.mode is used"),
+    METASTORE_METADATA_TRANSFORMER_LOCATION_MODE("metastore.metadata.transformer.location.mode",
+        "metastore.metadata.transformer.location.mode", "prohibit",
+        new StringSetValidator("seqsuffix", "seqprefix", "prohibit"),
+        "Defines the strategy to use in case the default location for a translated table already exists.\n"
+            + "  seqsuffix: add a '_N' suffix to the table name to get a unique location (table,table_1,table_2,...)\n"
+            + "  seqprefix: adds a 'N_' prefix to the table name to get a unique location (table,1_table,2_table,...)\n"
+            + "  prohibit: do not allow alternate locations; throw error if the default is not available\n"),
+
     MULTITHREADED("javax.jdo.option.Multithreaded", "javax.jdo.option.Multithreaded", true,
         "Set this to true if multiple threads access metastore through JDO concurrently."),
     MAX_OPEN_TXNS("metastore.max.open.txns", "hive.max.open.txns", 100000,
diff --git a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreUtils.java b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreUtils.java
index 787df35d0e..7349061b4a 100644
--- a/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreUtils.java
+++ b/standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreUtils.java
@@ -47,6 +47,7 @@
 import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.common.StatsSetupConst;
+import org.apache.hadoop.hive.common.TableName;
 import org.apache.hadoop.hive.metastore.ColumnType;
 import org.apache.hadoop.hive.metastore.TableType;
 import org.apache.hadoop.hive.metastore.Warehouse;
@@ -1019,6 +1020,10 @@ public static boolean hasUnknownPartitions(PartitionsSpecByExprResult r) {
     return !r.isSetHasUnknownPartitions() || r.isHasUnknownPartitions();
   }
 
+  public static TableName getTableNameFor(Table table) {
+    return TableName.fromString(table.getTableName(), table.getCatName(), table.getDbName());
+  }
+
   /**
    * Because TABLE_NO_AUTO_COMPACT was originally assumed to be NO_AUTO_COMPACT and then was moved
    * to no_auto_compact, we need to check it in both cases.
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
index feecc56b55..a8e979aad7 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
@@ -4564,8 +4564,9 @@ private int add_partitions_pspec_core(RawStore ms, String catName, String dbName
         throw new InvalidObjectException("Unable to add partitions because "
             + "database or table " + dbName + "." + tblName + " does not exist");
       }
-      if (db.getType() == DatabaseType.REMOTE)
+      if (db.getType() == DatabaseType.REMOTE) {
         throw new MetaException("Operation add_partitions_pspec not supported on tables in REMOTE database");
+      }
       tbl = ms.getTable(catName, dbName, tblName, null);
       if (tbl == null) {
         throw new InvalidObjectException("Unable to add partitions because "
@@ -6031,7 +6032,7 @@ private void alter_table_core(String catName, String dbname, String name, Table
       request.setCatName(catName);
       Table oldt = get_table_core(request);
       if (transformer != null) {
-        newTable = transformer.transformAlterTable(newTable, processorCapabilities, processorId);
+        newTable = transformer.transformAlterTable(oldt, newTable, processorCapabilities, processorId);
       }
       firePreEvent(new PreAlterTableEvent(oldt, newTable, this));
       alterHandler.alterTable(getMS(), wh, catName, dbname, name, newTable,
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/IMetaStoreMetadataTransformer.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/IMetaStoreMetadataTransformer.java
index b60e94cbde..6f0bf91df2 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/IMetaStoreMetadataTransformer.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/IMetaStoreMetadataTransformer.java
@@ -79,13 +79,13 @@ public Table transformCreateTable(Table table, List<String> processorCapabilitie
  public Database transformDatabase(Database db, List<String> processorCapabilities,
      String processorId) throws MetaException;
 
- /**
+  /**
   * @param table A table object to be transformed prior to the alteration of a table
   * @param processorCapabilities A array of String capabilities received from the data processor
   * @param processorId String ID used for logging purpose.
   * @return Table An altered Table based on the processor capabilities
   * @throws HiveMetaException
   */
- public Table transformAlterTable(Table table, List<String> processorCapabilities,
+  public Table transformAlterTable(Table oldTable, Table newTable, List<String> processorCapabilities,
      String processorId) throws MetaException;
 }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDefaultTransformer.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDefaultTransformer.java
index 3227bde334..3e59e4bd18 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDefaultTransformer.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MetastoreDefaultTransformer.java
@@ -40,6 +40,7 @@
 import org.apache.hadoop.hive.metastore.api.StorageDescriptor;
 import org.apache.hadoop.hive.metastore.api.Table;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
+import org.apache.hadoop.hive.metastore.conf.MetastoreConf.ConfVars;
 import org.apache.hadoop.hive.metastore.utils.FileUtils;
 import org.apache.hadoop.hive.metastore.utils.MetaStoreUtils;
 import org.slf4j.Logger;
@@ -466,8 +467,9 @@ public List<Partition> transformPartitions(List<Partition> objects, Table table,
       String dbName = partition.getDbName();
 
       Map<String, String> params = table.getParameters();
-      if (params == null)
+      if (params == null) {
         params = new HashMap<>();
+      }
       String tableType = table.getTableType();
       String tCapabilities = params.get(OBJCAPABILITIES);
       if (partition.getSd() != null) {
@@ -485,8 +487,9 @@ public List<Partition> transformPartitions(List<Partition> objects, Table table,
           if (partBuckets > 0 && !processorCapabilities.contains(HIVEBUCKET2)) {
             Partition newPartition = new Partition(partition);
             StorageDescriptor newSd = new StorageDescriptor(partition.getSd());
-            if (!processorCapabilities.contains(ACCEPTSUNMODIFIEDMETADATA))
+            if (!processorCapabilities.contains(ACCEPTSUNMODIFIEDMETADATA)) {
               newSd.setNumBuckets(-1); // remove bucketing info
+            }
             newPartition.setSd(newSd);
             ret.add(newPartition);
           } else {
@@ -499,8 +502,9 @@ public List<Partition> transformPartitions(List<Partition> objects, Table table,
             if (partBuckets > 0 && !processorCapabilities.contains(HIVEBUCKET2)) {
               Partition newPartition = new Partition(partition);
               StorageDescriptor newSd = new StorageDescriptor(partition.getSd());
-              if (!processorCapabilities.contains(ACCEPTSUNMODIFIEDMETADATA))
+              if (!processorCapabilities.contains(ACCEPTSUNMODIFIEDMETADATA)) {
                 newSd.setNumBuckets(-1); // remove bucketing info
+              }
               newPartition.setSd(newSd);
               ret.add(newPartition);
               break;
@@ -526,8 +530,9 @@ public List<Partition> transformPartitions(List<Partition> objects, Table table,
             if (requiredCapabilities.contains(HIVEBUCKET2) && !processorCapabilities.contains(HIVEBUCKET2)) {
               Partition newPartition = new Partition(partition);
               StorageDescriptor newSd = new StorageDescriptor(partition.getSd());
-              if (!processorCapabilities.contains(ACCEPTSUNMODIFIEDMETADATA))
+              if (!processorCapabilities.contains(ACCEPTSUNMODIFIEDMETADATA)) {
                 newSd.setNumBuckets(-1); // removing bucketing if HIVEBUCKET2 isnt specified
+              }
               newPartition.setSd(newSd);
               LOG.info("Removed bucketing information from partition");
               ret.add(newPartition);
@@ -539,8 +544,9 @@ public List<Partition> transformPartitions(List<Partition> objects, Table table,
               if (!processorCapabilities.contains(HIVEBUCKET2)) {
                 Partition newPartition = new Partition(partition);
                 StorageDescriptor newSd = new StorageDescriptor(partition.getSd());
-                if (!processorCapabilities.contains(ACCEPTSUNMODIFIEDMETADATA))
+                if (!processorCapabilities.contains(ACCEPTSUNMODIFIEDMETADATA)) {
                   newSd.setNumBuckets(-1); // remove bucketing info
+                }
                 newPartition.setSd(newSd);
                 ret.add(newPartition);
                 break;
@@ -558,6 +564,47 @@ public List<Partition> transformPartitions(List<Partition> objects, Table table,
     return ret;
   }
 
+  static enum TableLocationStrategy {
+    seqprefix {
+      @Override
+      Path getLocation(IHMSHandler hmsHandler, Database db, Table table, int idx) throws MetaException {
+        if (idx == 0) {
+          return getDefaultPath(hmsHandler, db, table.getTableName());
+        }
+        return getDefaultPath(hmsHandler, db, idx + "_" + table.getTableName());
+      }
+    },
+    seqsuffix {
+      @Override
+      Path getLocation(IHMSHandler hmsHandler, Database db, Table table, int idx) throws MetaException {
+        if (idx == 0) {
+          return getDefaultPath(hmsHandler, db, table.getTableName());
+        }
+        return getDefaultPath(hmsHandler, db, table.getTableName() + "_" + idx);
+      }
+    },
+    prohibit {
+      @Override
+      Path getLocation(IHMSHandler hmsHandler, Database db, Table table, int idx) throws MetaException {
+        Path p = getDefaultPath(hmsHandler, db, table.getTableName());
+
+        if (idx == 0) {
+          return p;
+        }
+        throw new MetaException("Default location is not available for table: " + p);
+      }
+
+    };
+
+    private static final Path getDefaultPath(IHMSHandler hmsHandler, Database db, String tableName)
+        throws MetaException {
+      return hmsHandler.getWh().getDefaultTablePath(db, tableName, true);
+    }
+
+    abstract Path getLocation(IHMSHandler hmsHandler, Database db, Table table, int idx) throws MetaException;
+
+  }
+
   @Override
   public Table transformCreateTable(Table table, List<String> processorCapabilities, String processorId) throws MetaException {
     if (!defaultCatalog.equalsIgnoreCase(table.getCatName())) {
@@ -569,8 +616,9 @@ public Table transformCreateTable(Table table, List<String> processorCapabilitie
     LOG.info("Starting translation for CreateTable for processor " + processorId + " with " + processorCapabilities
         + " on table " + newTable.getTableName());
     Map<String, String> params = table.getParameters();
-    if (params == null)
+    if (params == null) {
       params = new HashMap<>();
+    }
     String tableType = newTable.getTableType();
     String txnal = null;
     String txn_properties = null;
@@ -604,14 +652,17 @@ public Table transformCreateTable(Table table, List<String> processorCapabilitie
           newTable.setParameters(params);
           LOG.info("Modified table params are:" + params.toString());
 
-          if (!table.isSetSd() || table.getSd().getLocation() == null) {
+          if (getLocation(table) == null) {
             try {
-              Path newPath = hmsHandler.getWh().getDefaultTablePath(db, table.getTableName(), true);
-              newTable.getSd().setLocation(newPath.toString());
-              LOG.info("Modified location from null to " + newPath);
+              Path location = getTranslatedToExternalTableDefaultLocation(db, newTable);
+              newTable.getSd().setLocation(location.toString());
             } catch (Exception e) {
-              LOG.warn("Exception determining external table location:" + e.getMessage());
+              throw new MetaException("Exception determining external table location:" + e.getMessage());
             }
+          } else {
+            // table with explicitly set location
+            // has "translated" properties and will be removed on drop
+            // should we check tbl directory existence?
           }
         }
       } else { // ACID table
@@ -646,36 +697,95 @@ public Table transformCreateTable(Table table, List<String> processorCapabilitie
     return newTable;
   }
 
+  private Path getTranslatedToExternalTableDefaultLocation(Database db, Table table) throws MetaException {
+    String strategyVar =
+        MetastoreConf.getVar(hmsHandler.getConf(), ConfVars.METASTORE_METADATA_TRANSFORMER_LOCATION_MODE);
+    TableLocationStrategy strategy = TableLocationStrategy.valueOf(strategyVar);
+    int idx = 0;
+    Path location = null;
+    while (true) {
+      location = strategy.getLocation(hmsHandler, db, table, idx++);
+      if (!hmsHandler.getWh().isDir(location)) {
+        break;
+      }
+    }
+    LOG.info("Using location {} for table {}", location, table.getTableName());
+    return location;
+  }
+
+  private Path getLocation(Table table) {
+    if (table.isSetSd() && table.getSd().getLocation() != null) {
+      return new Path(table.getSd().getLocation());
+    }
+    return null;
+  }
+
   @Override
-  public Table transformAlterTable(Table table, List<String> processorCapabilities, String processorId) throws MetaException {
-    if (!defaultCatalog.equalsIgnoreCase(table.getCatName())) {
+  public Table transformAlterTable(Table oldTable, Table newTable, List<String> processorCapabilities,
+      String processorId) throws MetaException {
+    if (!defaultCatalog.equalsIgnoreCase(newTable.getCatName())) {
       LOG.debug("Table belongs to non-default catalog, skipping translation");
-      return table;
+      return newTable;
     }
 
     LOG.info("Starting translation for Alter table for processor " + processorId + " with " + processorCapabilities
-        + " on table " + table.getTableName());
+        + " on table " + newTable.getTableName());
 
-    if (tableLocationChanged(table))
-      validateTablePaths(table);
 
-    LOG.debug("Transformer returning table:" + table.toString());
-    return table;
-  }
+    if (tableLocationChanged(oldTable, newTable)) {
+      validateTablePaths(newTable);
+    }
 
-  private boolean tableLocationChanged(Table alteredTable) throws MetaException {
-    if (!alteredTable.isSetSd() || alteredTable.getSd().getLocation() == null) {
-      return false;
+    Database oldDb = getDbForTable(oldTable);
+    boolean isTranslatedToExternalFollowsRenames = MetastoreConf.getBoolVar(hmsHandler.getConf(),
+        ConfVars.METASTORE_METADATA_TRANSFORMER_TRANSLATED_TO_EXTERNAL_FOLLOWS_RENAMES);
+
+    if (isTranslatedToExternalFollowsRenames && isTableRename(oldTable, newTable)
+        && isTranslatedToExternalTable(oldTable)
+        && isTranslatedToExternalTable(newTable)) {
+      Database newDb = getDbForTable(newTable);
+      Path oldPath = TableLocationStrategy.getDefaultPath(hmsHandler, oldDb, oldTable.getTableName());
+      if (oldTable.getSd().getLocation().equals(oldPath.toString())) {
+        Path newPath = getTranslatedToExternalTableDefaultLocation(newDb, newTable);
+        newTable.getSd().setLocation(newPath.toString());
+        hmsHandler.getWh().renameDir(oldPath, newPath, ReplChangeManager.shouldEnableCm(oldDb, oldTable));
+      }
     }
+
+    LOG.debug("Transformer returning table:" + newTable.toString());
+    return newTable;
+  }
+
+  private Database getDbForTable(Table oldTable) throws MetaException {
     try {
-      Table currentTable = hmsHandler.get_table_core(alteredTable.getCatName(), alteredTable.getDbName(), alteredTable.getTableName());
-      if (!currentTable.isSetSd() || currentTable.getSd().getLocation() == null) {
-        return false;
-      }
-      return !currentTable.getSd().getLocation().equals(alteredTable.getSd().getLocation());
+      return hmsHandler.get_database_core(oldTable.getCatName(), oldTable.getDbName());
     } catch (NoSuchObjectException e) {
+      throw new MetaException(
+          "Database " + oldTable.getTableName() + " for table " + oldTable.getTableName() + " could not be found");
+    }
+  }
+
+  private boolean isTableRename(Table oldTable, Table newTable) {
+    return !MetaStoreUtils.getTableNameFor(oldTable).equals(MetaStoreUtils.getTableNameFor(newTable));
+  }
+
+  private boolean isTranslatedToExternalTable(Table table) {
+    Map<String, String> p = table.getParameters();
+    ;
+    return p != null && MetaStoreUtils.isPropertyTrue(p, "EXTERNAL")
+        && MetaStoreUtils.isPropertyTrue(p, "TRANSLATED_TO_EXTERNAL") && table.getSd() != null
+        && table.getSd().isSetLocation();
+
+  }
+
+  private boolean tableLocationChanged(Table oldTable, Table newTable) throws MetaException {
+    if (!newTable.isSetSd() || newTable.getSd().getLocation() == null) {
       return false;
     }
+    if (!oldTable.isSetSd() || oldTable.getSd().getLocation() == null) {
+      return false;
+    }
+    return !oldTable.getSd().getLocation().equals(newTable.getSd().getLocation());
   }
 
   /**
@@ -693,7 +803,7 @@ public Database transformDatabase(Database db, List<String> processorCapabilitie
         + " on database {} locationUri={} managedLocationUri={}", db.getName(), db.getLocationUri(), db.getManagedLocationUri());
 
     if (!isTenantBasedStorage) {
-      // for legacy DBs, location could have been managed or external. So if it is pointing to managed location, set it as 
+      // for legacy DBs, location could have been managed or external. So if it is pointing to managed location, set it as
       // managed location and return a new default external path for location
       Path locationPath = Path.getPathWithoutSchemeAndAuthority(new Path(db.getLocationUri()));
       Path whRootPath = Path.getPathWithoutSchemeAndAuthority(hmsHandler.getWh().getWhRoot());
@@ -717,14 +827,17 @@ public Database transformDatabase(Database db, List<String> processorCapabilitie
   private List<String> diff(final List<String> list1, final List<String> list2) {
     List<String> diffList = new ArrayList<>();
 
-    if (list2 == null || list2.size() == 0)
+    if (list2 == null || list2.size() == 0) {
       return list1;
+    }
 
-    if (list1 == null || list1.size() == 0)
+    if (list1 == null || list1.size() == 0) {
       return Collections.emptyList();
+    }
 
-    if (list2.containsAll(list1))
+    if (list2.containsAll(list1)) {
       return Collections.emptyList();
+    }
 
     diffList.addAll(list2);
     LOG.debug("diffList=" + Arrays.toString(diffList.toArray()) + ",master list=" + Arrays.toString(list1.toArray()));
@@ -822,7 +935,7 @@ private Table validateTablePaths(Table table) throws MetaException {
                     + table.getTableName() + ",location:" + tablePath + ",Database's managed warehouse:" + dbLocation);
           }
         } else {
-          if (FileUtils.isSubdirectory(whRootPath.toString(), tablePath.toString())) {
+          if (isExternalWarehouseSet() && FileUtils.isSubdirectory(whRootPath.toString(), tablePath.toString())) {
             throw new MetaException(
                 "An external table's location should not be located within managed warehouse root directory, table:"
                     + table.getTableName() + ",location:" + tablePath + ",managed warehouse:" + whRootPath);
@@ -842,4 +955,8 @@ private Table validateTablePaths(Table table) throws MetaException {
     }
     return table;
   }
+
+  private boolean isExternalWarehouseSet() {
+    return !"".equals(hmsHandler.getConf().get(MetastoreConf.ConfVars.WAREHOUSE_EXTERNAL.getVarname()));
+  }
 }
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetPartitions.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetPartitions.java
index f76ec44060..f4fafcdcb3 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetPartitions.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetPartitions.java
@@ -76,19 +76,17 @@ public void setUp() throws Exception {
     client = metaStore.getClient();
 
     // Clean up the database
-    client.dropDatabase(DB_NAME, true, true, true);
     createDB(DB_NAME);
   }
 
   @After
   public void tearDown() throws Exception {
     try {
-      if (client != null) {
-        try {
-          client.close();
-        } catch (Exception e) {
-          // HIVE-19729: Shallow the exceptions based on the discussion in the Jira
-        }
+      client.dropDatabase(DB_NAME, true, true, true);
+      try {
+        client.close();
+      } catch (Exception e) {
+        // HIVE-19729: Shallow the exceptions based on the discussion in the Jira
       }
     } finally {
       client = null;
@@ -594,7 +592,9 @@ public void otherCatalog() throws TException {
         Arrays.asList("partcol=a0", "partcol=a1"));
     Assert.assertEquals(2, fetchedParts.size());
     Set<String> vals = new HashSet<>(fetchedParts.size());
-    for (Partition part : fetchedParts) vals.add(part.getValues().get(0));
+    for (Partition part : fetchedParts) {
+      vals.add(part.getValues().get(0));
+    }
     Assert.assertTrue(vals.contains("a0"));
     Assert.assertTrue(vals.contains("a1"));
 
