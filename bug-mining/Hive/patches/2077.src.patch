diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/pcr/PcrExprProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/pcr/PcrExprProcFactory.java
index bd0e8c360f..e46e144f9f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/pcr/PcrExprProcFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/pcr/PcrExprProcFactory.java
@@ -62,7 +62,6 @@ static Object evalExprWithPart(ExprNodeDesc expr, Partition p, List<VirtualColum
       throws SemanticException {
     StructObjectInspector rowObjectInspector;
     Table tbl = p.getTable();
-    LinkedHashMap<String, String> partSpec = p.getSpec();
 
     try {
       rowObjectInspector = (StructObjectInspector) tbl
@@ -72,7 +71,7 @@ static Object evalExprWithPart(ExprNodeDesc expr, Partition p, List<VirtualColum
     }
 
     try {
-      return PartExprEvalUtils.evalExprWithPart(expr, partSpec, vcs, rowObjectInspector);
+      return PartExprEvalUtils.evalExprWithPart(expr, p, vcs, rowObjectInspector);
     } catch (HiveException e) {
       throw new SemanticException(e);
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartExprEvalUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartExprEvalUtils.java
index 641c5a3e43..6159c7d49c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartExprEvalUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartExprEvalUtils.java
@@ -22,19 +22,24 @@
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.Properties;
 
 import org.apache.hadoop.hive.common.ObjectPair;
+import org.apache.hadoop.hive.metastore.api.hive_metastoreConstants;
 import org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator;
 import org.apache.hadoop.hive.ql.exec.ExprNodeEvaluatorFactory;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.metadata.Partition;
 import org.apache.hadoop.hive.ql.metadata.VirtualColumn;
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 
 public class PartExprEvalUtils {
   /**
@@ -47,19 +52,32 @@ public class PartExprEvalUtils {
    * @throws HiveException
    */
   static synchronized public Object evalExprWithPart(ExprNodeDesc expr,
-      LinkedHashMap<String, String> partSpec, List<VirtualColumn> vcs,
+      Partition p, List<VirtualColumn> vcs,
       StructObjectInspector rowObjectInspector) throws HiveException {
+    LinkedHashMap<String, String> partSpec = p.getSpec();
+    Properties partProps = p.getSchema();
+    String pcolTypes = partProps.getProperty(hive_metastoreConstants.META_TABLE_PARTITION_COLUMN_TYPES);
+    String[] partKeyTypes = pcolTypes.trim().split(":");
+
+    if (partSpec.size() != partKeyTypes.length) {
+        throw new HiveException("Internal error : Partition Spec size, " + partProps.size() +
+                " doesn't match partition key definition size, " + partKeyTypes.length);
+    }
     boolean hasVC = vcs != null && !vcs.isEmpty();
     Object[] rowWithPart = new Object[hasVC ? 3 : 2];
     // Create the row object
     ArrayList<String> partNames = new ArrayList<String>();
-    ArrayList<String> partValues = new ArrayList<String>();
+    ArrayList<Object> partValues = new ArrayList<Object>();
     ArrayList<ObjectInspector> partObjectInspectors = new ArrayList<ObjectInspector>();
+    int i=0;
     for (Map.Entry<String, String> entry : partSpec.entrySet()) {
       partNames.add(entry.getKey());
-      partValues.add(entry.getValue());
-      partObjectInspectors
-          .add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);
+      ObjectInspector oi = PrimitiveObjectInspectorFactory.getPrimitiveWritableObjectInspector
+          (TypeInfoFactory.getPrimitiveTypeInfo(partKeyTypes[i++]));
+      partValues.add(ObjectInspectorConverters.getConverter(
+          PrimitiveObjectInspectorFactory.javaStringObjectInspector, oi)
+          .convert(entry.getValue()));
+      partObjectInspectors.add(oi);
     }
     StructObjectInspector partObjectInspector = ObjectInspectorFactory
         .getStandardStructObjectInspector(partNames, partObjectInspectors);
diff --git a/ql/src/test/queries/clientpositive/pcr.q b/ql/src/test/queries/clientpositive/pcr.q
index a7199b387c..3be0ff23b8 100644
--- a/ql/src/test/queries/clientpositive/pcr.q
+++ b/ql/src/test/queries/clientpositive/pcr.q
@@ -112,7 +112,7 @@ insert overwrite table pcr_foo partition (ds=5) select * from src where key < 10
 insert overwrite table pcr_foo partition (ds=7) select * from src where key < 10 order by key;
 
 -- the condition is 'true' for all the 3 partitions (ds=3,5,7):
-select key, value, ds from pcr_foo where (ds % 2.0 == 1);
+select key, value, ds from pcr_foo where (ds % 2 == 1);
 
 -- the condition is 'true' for partitions (ds=3,5) but 'false' of partition ds=7:
 select key, value, ds from pcr_foo where (ds / 3 < 2);
diff --git a/ql/src/test/results/clientpositive/pcr.q.out b/ql/src/test/results/clientpositive/pcr.q.out
index bf5bcce618..44c8856b23 100644
--- a/ql/src/test/results/clientpositive/pcr.q.out
+++ b/ql/src/test/results/clientpositive/pcr.q.out
@@ -6267,7 +6267,7 @@ POSTHOOK: Lineage: pcr_t3.key SIMPLE [(pcr_t1)pcr_t1.FieldSchema(name:key, type:
 POSTHOOK: Lineage: pcr_t3.value SIMPLE [(pcr_t1)pcr_t1.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: pcr_t3.value SIMPLE [(pcr_t1)pcr_t1.FieldSchema(name:value, type:string, comment:null), ]
 PREHOOK: query: -- the condition is 'true' for all the 3 partitions (ds=3,5,7):
-select key, value, ds from pcr_foo where (ds % 2.0 == 1)
+select key, value, ds from pcr_foo where (ds % 2 == 1)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@pcr_foo
 PREHOOK: Input: default@pcr_foo@ds=3
@@ -6275,7 +6275,7 @@ PREHOOK: Input: default@pcr_foo@ds=5
 PREHOOK: Input: default@pcr_foo@ds=7
 #### A masked pattern was here ####
 POSTHOOK: query: -- the condition is 'true' for all the 3 partitions (ds=3,5,7):
-select key, value, ds from pcr_foo where (ds % 2.0 == 1)
+select key, value, ds from pcr_foo where (ds % 2 == 1)
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@pcr_foo
 POSTHOOK: Input: default@pcr_foo@ds=3
