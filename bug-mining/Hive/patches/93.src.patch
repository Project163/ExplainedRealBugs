diff --git a/CHANGES.txt b/CHANGES.txt
index eeb3a9ae64..6b129049de 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -6,6 +6,9 @@ Trunk (unreleased changes)
 
   NEW FEATURES
 
+    HIVE-337. LazySimpleSerDe to support multi-level nested array, map, struct
+    types. (zshao)
+
     HIVE-313. Add UDF date_add, date_sub, datediff. (zshao)
 
     HIVE-79. Print number of rows inserted to table(s).
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java b/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
index 9781a60739..e184178014 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
@@ -52,6 +52,8 @@
 import org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
 import org.apache.hadoop.util.StringUtils;
 
 public class MetaStoreUtils {
@@ -486,6 +488,32 @@ public static Properties getSchema(org.apache.hadoop.hive.metastore.api.Table tb
     return schema;
   }
   
+  /** Convert FieldSchemas to columnNames.
+   */
+  public static String getColumnNamesFromFieldSchema(List<FieldSchema> fieldSchemas) {
+    StringBuilder sb = new StringBuilder();
+    for (int i=0; i<fieldSchemas.size(); i++) {
+      if (i>0) {
+        sb.append(",");
+      }
+      sb.append(fieldSchemas.get(i).getName());
+    }
+    return sb.toString();
+  }
+
+  /** Convert FieldSchemas to columnTypes.
+   */
+  public static String getColumnTypesFromFieldSchema(List<FieldSchema> fieldSchemas) {
+    StringBuilder sb = new StringBuilder();
+    for (int i=0; i<fieldSchemas.size(); i++) {
+      if (i>0) {
+        sb.append(",");
+      }
+      sb.append(fieldSchemas.get(i).getType());
+    }
+    return sb.toString();
+  }
+  
   public static void makeDir(Path path, HiveConf hiveConf) throws MetaException {
     FileSystem fs;
     try {
@@ -564,4 +592,13 @@ else if (oi instanceof MapObjectInspector && names[i].equalsIgnoreCase("$value$"
     return str_fields;
   }
 
+  /**
+   * Convert TypeInfo to FieldSchema. 
+   */
+  public static FieldSchema getFieldSchemaFromTypeInfo(String fieldName, TypeInfo typeInfo) {
+    return new FieldSchema(
+        fieldName, TypeInfoUtils.getTypeStringFromTypeInfo(typeInfo), "generated by TypeInfoUtils.getFieldSchemaFromTypeInfo"
+    );
+  }
+  
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java
index 5a370d5ddd..de3831f841 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java
@@ -21,8 +21,8 @@
 import java.lang.Class;
 import java.io.*;
 
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 
 /**
  * Implementation for ColumnInfo which contains the internal name for the 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
index a26267c04c..2d6a5fb0a8 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
@@ -514,7 +514,7 @@ else if (alterTbl.getOp() == alterTableDesc.alterTableTypes.ADDCOLS) {
         tbl.getTTable().getSd().setCols(oldCols);
       }
     } else if (alterTbl.getOp() == alterTableDesc.alterTableTypes.REPLACECOLS) {
-      // change SerDe to MetadataTypedColumnsetSerDe if it is columnsetSerDe
+      // change SerDe to LazySimpleSerDe if it is columnsetSerDe
       if (tbl.getSerializationLib().equals("org.apache.hadoop.hive.serde.thrift.columnsetSerDe")) {
         console
             .printInfo("Replacing columns for columnsetSerDe and changing to LazySimpleSerDe");
@@ -669,22 +669,8 @@ private int createTable(Hive db, createTableDesc crtTbl) throws HiveException {
      * we will have to use DynamicSerDe instead.
      */
     if (crtTbl.getSerName() == null) {
-      boolean useDynamicSerDe = false;
-      if (crtTbl.getCols() != null) {
-        for (FieldSchema field: crtTbl.getCols()) {
-          if (field.getType().indexOf('<') >= 0 || field.getType().indexOf('>') >= 0) {
-            useDynamicSerDe = true;
-          }
-        }
-      }
-      if (useDynamicSerDe) {
-        LOG.info("Default to DynamicSerDe for table " + crtTbl.getTableName() );
-        tbl.setSerializationLib(org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe.class.getName());
-        tbl.setSerdeParam(org.apache.hadoop.hive.serde.Constants.SERIALIZATION_FORMAT, org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol.class.getName());
-      } else {
-        LOG.info("Default to LazySimpleSerDe for table " + crtTbl.getTableName() );
-        tbl.setSerializationLib(org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.class.getName());
-      }
+      LOG.info("Default to LazySimpleSerDe for table " + crtTbl.getTableName() );
+      tbl.setSerializationLib(org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.class.getName());
     }
 
     if (crtTbl.getComment() != null)
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
index dd046f55a0..bb658b74b1 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
@@ -337,7 +337,9 @@ public int execute() {
     job.setMapperClass(ExecMapper.class);
 
     job.setMapOutputKeyClass(HiveKey.class);
-    job.setMapOutputValueClass(BytesWritable.class);
+    // LazySimpleSerDe writes to Text
+    // Revert to DynamicSerDe: job.setMapOutputValueClass(BytesWritable.class); 
+    job.setMapOutputValueClass(Text.class);
 
     job.setNumReduceTasks(work.getNumReduceTasks().intValue());
     job.setReducerClass(ExecReducer.class);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeFuncEvaluator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeFuncEvaluator.java
index 8d276c49cb..aa974085a6 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeFuncEvaluator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeFuncEvaluator.java
@@ -26,8 +26,11 @@
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.plan.exprNodeFuncDesc;
 import org.apache.hadoop.hive.serde2.objectinspector.InspectableObject;
+import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
 import org.apache.hadoop.util.ReflectionUtils;
 
 public class ExprNodeFuncEvaluator extends ExprNodeEvaluator {
@@ -70,7 +73,21 @@ public void evaluate(Object row, ObjectInspector rowInspector,
     // Evaluate all children first
     for(int i=0; i<paramEvaluators.length; i++) {
       paramEvaluators[i].evaluate(row, rowInspector, paramInspectableObjects[i]);
-      paramValues[i] = paramInspectableObjects[i].o;
+      Category c = paramInspectableObjects[i].oi.getCategory();
+      // TODO: Both getList and getMap are not very efficient.
+      // We should convert them to UDFTemplate - UDFs that accepts Object with 
+      // ObjectInspectors when needed.
+      if (c.equals(Category.LIST)) {
+        // Need to pass a Java List for List type
+        paramValues[i] = ((ListObjectInspector)paramInspectableObjects[i].oi)
+        .getList(paramInspectableObjects[i].o);
+      } else if (c.equals(Category.MAP)) {
+        // Need to pass a Java Map for Map type
+        paramValues[i] = ((MapObjectInspector)paramInspectableObjects[i].oi)
+        .getMap(paramInspectableObjects[i].o);
+      } else {
+        paramValues[i] = paramInspectableObjects[i].o;
+      }
     }
     result.o = FunctionRegistry.invoke(udfMethod, udf, paramValues);
     result.oi = outputObjectInspector;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java
index c34fa3bd9b..780ad7bcf7 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java
@@ -37,8 +37,8 @@
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hive.ql.parse.OpParseContext;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
-import org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.mapred.Reporter;
 import org.apache.commons.logging.Log;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/InputSignature.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/InputSignature.java
index f345c14f68..36a0ef4e27 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/InputSignature.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/InputSignature.java
@@ -23,8 +23,8 @@
 import java.lang.Object;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 
 /**
  * The input signature of a function or operator. The signature basically consists
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/PartitionPruner.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/PartitionPruner.java
index c8b7a2fd83..8c2cae5822 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/PartitionPruner.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/PartitionPruner.java
@@ -30,11 +30,11 @@
 import org.apache.hadoop.hive.ql.plan.exprNodeFuncDesc;
 import org.apache.hadoop.hive.ql.plan.exprNodeIndexDesc;
 import org.apache.hadoop.hive.ql.plan.exprNodeNullDesc;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoUtils;
 import org.apache.hadoop.hive.ql.udf.UDFOPAnd;
 import org.apache.hadoop.hive.ql.udf.UDFOPNot;
 import org.apache.hadoop.hive.ql.udf.UDFOPOr;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
 import org.apache.hadoop.hive.ql.udf.UDFType;
 import org.apache.hadoop.hive.serde2.SerDeException;
 import org.apache.hadoop.hive.serde2.objectinspector.InspectableObject;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 0e80506db3..6b53acc773 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -23,6 +23,9 @@
 import java.io.Serializable;
 import java.lang.reflect.Method;
 
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
 import org.apache.hadoop.hive.serde2.Deserializer;
 import org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe;
 import org.apache.hadoop.hive.serde2.SerDeException;
@@ -52,9 +55,6 @@
 import org.apache.hadoop.hive.ql.optimizer.GenMRRedSink1;
 import org.apache.hadoop.hive.ql.optimizer.GenMRRedSink2;
 import org.apache.hadoop.hive.ql.plan.*;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoFactory;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoUtils;
 import org.apache.hadoop.hive.ql.udf.UDFOPPositive;
 import org.apache.hadoop.hive.ql.exec.*;
 import org.apache.hadoop.hive.conf.HiveConf;
@@ -2208,16 +2208,20 @@ Operator genConversionSelectOperator(String dest, QB qb,
     boolean converted = false;
     int columnNumber = tableFields.size();
     ArrayList<exprNodeDesc> expressions = new ArrayList<exprNodeDesc>(columnNumber);
-    // MetadataTypedColumnsetSerDe/LazySimpleSerDe does not need type conversions because it does
+    // MetadataTypedColumnsetSerDe does not need type conversions because it does
     // the conversion to String by itself.
-    if (! table_desc.getDeserializerClass().equals(MetadataTypedColumnsetSerDe.class)
-        && ! table_desc.getDeserializerClass().equals(LazySimpleSerDe.class)) {
+    boolean isMetaDataSerDe = table_desc.getDeserializerClass().equals(MetadataTypedColumnsetSerDe.class);
+    boolean isLazySimpleSerDe = table_desc.getDeserializerClass().equals(LazySimpleSerDe.class);
+    if (!isMetaDataSerDe) {
       for (int i=0; i<columnNumber; i++) {
         ObjectInspector tableFieldOI = tableFields.get(i).getFieldObjectInspector();
         TypeInfo tableFieldTypeInfo = TypeInfoUtils.getTypeInfoFromObjectInspector(tableFieldOI);
         TypeInfo rowFieldTypeInfo = rowFields.get(i).getType();
         exprNodeDesc column = new exprNodeColumnDesc(rowFieldTypeInfo, Integer.valueOf(i).toString());
-        if (! tableFieldTypeInfo.equals(rowFieldTypeInfo)) {
+        // LazySimpleSerDe can convert any types to String type using JSON-format.
+        if (!tableFieldTypeInfo.equals(rowFieldTypeInfo)
+            && !(isLazySimpleSerDe && tableFieldTypeInfo.getCategory().equals(Category.PRIMITIVE)
+              && tableFieldTypeInfo.getPrimitiveClass().equals(String.class))) { 
           // need to do some conversions here
           converted = true;
           if (tableFieldTypeInfo.getCategory() != Category.PRIMITIVE) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java
index 3f6f2eb1a1..5b8d52263f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java
@@ -38,8 +38,8 @@
 import org.apache.hadoop.hive.ql.plan.exprNodeFuncDesc;
 import org.apache.hadoop.hive.ql.plan.exprNodeIndexDesc;
 import org.apache.hadoop.hive.ql.plan.exprNodeNullDesc;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 import org.apache.hadoop.hive.ql.udf.UDFOPPositive;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java
index a435f6adb8..7fd7bcd80c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java
@@ -29,12 +29,10 @@
 import org.apache.hadoop.hive.ql.exec.Utilities;
 import org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat;
 import org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoUtils;
 import org.apache.hadoop.hive.serde.Constants;
 import org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe;
 import org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe;
 import org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe;
-import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
 import org.apache.hadoop.hive.serde2.thrift.TBinarySortableProtocol;
 import org.apache.hadoop.mapred.SequenceFileInputFormat;
 import org.apache.hadoop.mapred.SequenceFileOutputFormat;
@@ -138,7 +136,21 @@ public static tableDesc getBinaryTableDesc(List<FieldSchema> fieldSchemas) {
               MetaStoreUtils.getDDLFromFieldSchema(structName, fieldSchemas)
         ));    
   }
-  
+
+  /** 
+   * Generate the table descriptor of LazySimpleSerDe.
+   */
+  public static tableDesc getLazySimpleSerDeTableDesc(List<FieldSchema> fieldSchemas) {
+    return new tableDesc(
+        LazySimpleSerDe.class,
+        SequenceFileInputFormat.class,
+        SequenceFileOutputFormat.class,
+        Utilities.makeProperties(
+            "columns", MetaStoreUtils.getColumnNamesFromFieldSchema(fieldSchemas),
+            "columns.types", MetaStoreUtils.getColumnTypesFromFieldSchema(fieldSchemas)
+        ));
+  }
+
   
   /** 
    * Convert the ColumnList to FieldSchema list.
@@ -147,7 +159,7 @@ public static List<FieldSchema> getFieldSchemasFromColumnList(ArrayList<exprNode
       String fieldPrefix) {
     List<FieldSchema> schemas = new ArrayList<FieldSchema>(cols.size());
     for (int i=0; i<cols.size(); i++) {
-      schemas.add(TypeInfoUtils.getFieldSchemaFromTypeInfo(fieldPrefix + i, cols.get(i).getTypeInfo()));
+      schemas.add(MetaStoreUtils.getFieldSchemaFromTypeInfo(fieldPrefix + i, cols.get(i).getTypeInfo()));
     }
     return schemas;
   }
@@ -170,7 +182,7 @@ public static List<FieldSchema> getFieldSchemasFromColumnInfo(Vector<ColumnInfo>
       if (name.equals(Integer.valueOf(i).toString())) {
         name = fieldPrefix + name; 
       }
-      schemas.add(TypeInfoUtils.getFieldSchemaFromTypeInfo(name, cols.get(i).getType()));
+      schemas.add(MetaStoreUtils.getFieldSchemaFromTypeInfo(name, cols.get(i).getType()));
     }
     return schemas;
   }
@@ -194,7 +206,8 @@ public static reduceSinkDesc getReduceSinkDesc(ArrayList<exprNodeDesc> keyCols,
     
     return new reduceSinkDesc(keyCols, valueCols, tag, partitionCols, numReducers, 
         getBinarySortableTableDesc(getFieldSchemasFromColumnList(keyCols, "reducesinkkey"), order),
-        getBinaryTableDesc(getFieldSchemasFromColumnList(valueCols, "reducesinkvalue")));
+        // Revert to DynamicSerDe: getBinaryTableDesc(getFieldSchemasFromColumnList(valueCols, "reducesinkvalue")));
+        getLazySimpleSerDeTableDesc(getFieldSchemasFromColumnList(valueCols, "reducesinkvalue")));
   }
 
   /**
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeColumnDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeColumnDesc.java
index 69b0525f1b..bb341d1f4d 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeColumnDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeColumnDesc.java
@@ -22,8 +22,8 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 
 public class exprNodeColumnDesc extends exprNodeDesc implements Serializable {
   private static final long serialVersionUID = 1L;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeConstantDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeConstantDesc.java
index c1fcb686b7..3087acdcfd 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeConstantDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeConstantDesc.java
@@ -20,8 +20,8 @@
 
 import java.io.Serializable;
 
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 
 
 public class exprNodeConstantDesc extends exprNodeDesc implements Serializable {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeDesc.java
index de37d96722..0168e10bec 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeDesc.java
@@ -21,7 +21,7 @@
 import java.io.Serializable;
 import java.util.List;
 
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 
 public class exprNodeDesc implements Serializable {  
   private static final long serialVersionUID = 1L;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeFieldDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeFieldDesc.java
index add99667d0..d6f7d776d9 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeFieldDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeFieldDesc.java
@@ -22,7 +22,7 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 import org.apache.hadoop.hive.ql.exec.Utilities;
 import org.apache.hadoop.hive.ql.parse.RowResolver;
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeFuncDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeFuncDesc.java
index 7ebab8190b..b84a4a5c9d 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeFuncDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeFuncDesc.java
@@ -23,7 +23,7 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 import org.apache.hadoop.hive.ql.exec.FunctionInfo;
 import org.apache.hadoop.hive.ql.exec.FunctionRegistry;
 import org.apache.hadoop.hive.ql.exec.UDF;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeIndexDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeIndexDesc.java
index 73509984e6..7876f9a6ee 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeIndexDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeIndexDesc.java
@@ -22,7 +22,7 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 import org.apache.hadoop.hive.ql.exec.Utilities;
 import org.apache.hadoop.hive.ql.parse.RowResolver;
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeNullDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeNullDesc.java
index e38685a792..64092932e0 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeNullDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/exprNodeNullDesc.java
@@ -20,7 +20,7 @@
 
 import java.io.Serializable;
 
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 
 public class exprNodeNullDesc extends exprNodeDesc implements Serializable {
   
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/TypeInfoUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/TypeInfoUtils.java
deleted file mode 100644
index b26ecf9d33..0000000000
--- a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/TypeInfoUtils.java
+++ /dev/null
@@ -1,162 +0,0 @@
-package org.apache.hadoop.hive.ql.typeinfo;
-
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import org.apache.hadoop.hive.metastore.api.FieldSchema;
-import org.apache.hadoop.hive.ql.parse.HiveParser;
-import org.apache.hadoop.hive.serde.Constants;
-import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
-import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
-import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.StructField;
-import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
-
-public class TypeInfoUtils {
-  
-  static HashMap<TypeInfo, ObjectInspector> cachedStandardObjectInspector = new HashMap<TypeInfo, ObjectInspector>();
-  /**
-   * Returns the standard object inspector that can be used to translate an object of that typeInfo
-   * to a standard object type.  
-   */
-  public static ObjectInspector getStandardObjectInspectorFromTypeInfo(TypeInfo typeInfo) {
-    ObjectInspector result = cachedStandardObjectInspector.get(typeInfo);
-    if (result == null) {
-      switch(typeInfo.getCategory()) {
-        case PRIMITIVE: {
-          result = ObjectInspectorFactory.getStandardPrimitiveObjectInspector(typeInfo.getPrimitiveClass());
-          break;
-        }
-        case LIST: {
-          ObjectInspector elementObjectInspector = getStandardObjectInspectorFromTypeInfo(typeInfo.getListElementTypeInfo());
-          result = ObjectInspectorFactory.getStandardListObjectInspector(elementObjectInspector);
-          break;
-        }
-        case MAP: {
-          ObjectInspector keyObjectInspector = getStandardObjectInspectorFromTypeInfo(typeInfo.getMapKeyTypeInfo());
-          ObjectInspector valueObjectInspector = getStandardObjectInspectorFromTypeInfo(typeInfo.getMapValueTypeInfo());
-          result = ObjectInspectorFactory.getStandardMapObjectInspector(keyObjectInspector, valueObjectInspector);
-          break;
-        }
-        case STRUCT: {
-          List<String> fieldNames = typeInfo.getAllStructFieldNames();
-          List<TypeInfo> fieldTypeInfos = typeInfo.getAllStructFieldTypeInfos();
-          List<ObjectInspector> fieldObjectInspectors = new ArrayList<ObjectInspector>(fieldTypeInfos.size());
-          for(int i=0; i<fieldTypeInfos.size(); i++) {
-            fieldObjectInspectors.add(getStandardObjectInspectorFromTypeInfo(fieldTypeInfos.get(i)));
-          }
-          result = ObjectInspectorFactory.getStandardStructObjectInspector(fieldNames, fieldObjectInspectors);
-          break;
-        }
-        default: {
-          result = null;
-        }
-      }
-      cachedStandardObjectInspector.put(typeInfo, result);
-    }
-    return result;
-  }
-
-  
-  /**
-   * Get the TypeInfo object from the ObjectInspector object by recursively going into the
-   * ObjectInspector structure.
-   */
-  public static TypeInfo getTypeInfoFromObjectInspector(ObjectInspector oi) {
-//    OPTIMIZATION for later.
-//    if (oi instanceof TypeInfoBasedObjectInspector) {
-//      TypeInfoBasedObjectInspector typeInfoBasedObjectInspector = (ObjectInspector)oi;
-//      return typeInfoBasedObjectInspector.getTypeInfo();
-//    }
-    
-    // Recursively going into ObjectInspector structure
-    TypeInfo result = null;
-    switch (oi.getCategory()) {
-      case PRIMITIVE: {
-        PrimitiveObjectInspector poi =(PrimitiveObjectInspector)oi;
-        result = TypeInfoFactory.getPrimitiveTypeInfo(poi.getPrimitiveClass());
-        break;
-      }
-      case LIST: {
-        ListObjectInspector loi = (ListObjectInspector)oi;
-        result = TypeInfoFactory.getListTypeInfo(
-            getTypeInfoFromObjectInspector(loi.getListElementObjectInspector()));
-        break;
-      }
-      case MAP: {
-        MapObjectInspector moi = (MapObjectInspector)oi;
-        result = TypeInfoFactory.getMapTypeInfo(
-            getTypeInfoFromObjectInspector(moi.getMapKeyObjectInspector()),
-            getTypeInfoFromObjectInspector(moi.getMapValueObjectInspector()));
-        break;
-      }
-      case STRUCT: {
-        StructObjectInspector soi = (StructObjectInspector)oi;
-        List<? extends StructField> fields = soi.getAllStructFieldRefs();
-        List<String> fieldNames = new ArrayList<String>(fields.size());
-        List<TypeInfo> fieldTypeInfos = new ArrayList<TypeInfo>(fields.size());
-        for(StructField f : fields) {
-          fieldNames.add(f.getFieldName());
-          fieldTypeInfos.add(getTypeInfoFromObjectInspector(f.getFieldObjectInspector()));
-        }
-        result = TypeInfoFactory.getStructTypeInfo(fieldNames, fieldTypeInfos);
-        break;
-      }
-      default: {
-        throw new RuntimeException("Unknown ObjectInspector category!");
-      }
-    }
-    return result;
-  }
-    
-  public static String getFieldSchemaTypeFromTypeInfo(TypeInfo typeInfo) {
-    switch(typeInfo.getCategory()) {
-      case PRIMITIVE: {
-        return ObjectInspectorUtils.getClassShortName(typeInfo.getPrimitiveClass());
-      }
-      case LIST: {
-        String elementType = getFieldSchemaTypeFromTypeInfo(typeInfo.getListElementTypeInfo());
-        return org.apache.hadoop.hive.serde.Constants.LIST_TYPE_NAME + "<" + elementType + ">";
-      }
-      case MAP: {
-        String keyType = getFieldSchemaTypeFromTypeInfo(typeInfo.getMapKeyTypeInfo());
-        String valueType = getFieldSchemaTypeFromTypeInfo(typeInfo.getMapValueTypeInfo());
-        return org.apache.hadoop.hive.serde.Constants.MAP_TYPE_NAME + "<" +
-          keyType + "," + valueType + ">";
-      }
-      case STRUCT: {
-        throw new RuntimeException("Complex struct type not supported!");
-      }
-      default: {
-        throw new RuntimeException("Unknown type!");
-      }
-    }
-  }
-  
-  /**
-   * Convert TypeInfo to FieldSchema. 
-   */
-  public static FieldSchema getFieldSchemaFromTypeInfo(String fieldName, TypeInfo typeInfo) {
-    return new FieldSchema(
-        fieldName, getFieldSchemaTypeFromTypeInfo(typeInfo), "generated by TypeInfoUtils.getFieldSchemaFromTypeInfo"
-    );
-  }
-
-  
-  /**
-   * Return the primitive type corresponding to the field schema
-   * @param field The field schema
-   * @return The TypeInfo object, or null if the field is not a primitive type.
-   */
-  public static TypeInfo getPrimitiveTypeInfoFromFieldSchema(FieldSchema field) {
-    String type = field.getType();
-    
-    Class<?> c = ObjectInspectorUtils.typeNameToClass.get(type);
-    return c == null ? null : TypeInfoFactory.getPrimitiveTypeInfo(c);
-  }
-}
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
index 79b449e2a5..6d6576cb70 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
@@ -38,8 +38,8 @@
 import org.apache.hadoop.hive.ql.exec.Utilities;
 import org.apache.hadoop.hive.ql.plan.PlanUtils.ExpressionTypes;
 import org.apache.hadoop.hive.ql.plan.*;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 
 import org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExpressionEvaluator.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExpressionEvaluator.java
index 1ac16f869b..bfdcb483d5 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExpressionEvaluator.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestExpressionEvaluator.java
@@ -31,9 +31,9 @@
 import org.apache.hadoop.hive.ql.plan.exprNodeDesc;
 import org.apache.hadoop.hive.ql.plan.exprNodeIndexDesc;
 import org.apache.hadoop.hive.ql.plan.PlanUtils.ExpressionTypes;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfo;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoFactory;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoUtils;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
 
 public class TestExpressionEvaluator extends TestCase {
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
index ea0c88aa58..f734090e00 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
@@ -31,7 +31,7 @@
 import org.apache.hadoop.hive.ql.parse.SemanticAnalyzer;
 import org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory;
 import org.apache.hadoop.hive.ql.plan.*;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.serde2.objectinspector.InspectableObject;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestPlan.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestPlan.java
index 36427675b6..1760e5b48c 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/TestPlan.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/TestPlan.java
@@ -28,7 +28,7 @@
 import org.apache.hadoop.hive.ql.parse.SemanticAnalyzer;
 import org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory;
 import org.apache.hadoop.hive.ql.plan.*;
-import org.apache.hadoop.hive.ql.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 import org.apache.hadoop.hive.ql.exec.Utilities;
 import org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat;
 import org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe;
diff --git a/ql/src/test/queries/clientpositive/input_lazyserde.q b/ql/src/test/queries/clientpositive/input_lazyserde.q
new file mode 100644
index 0000000000..4c1672697c
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/input_lazyserde.q
@@ -0,0 +1,18 @@
+CREATE TABLE dest1(a array<int>, b array<string>, c map<string,string>, d int, e string)
+ROW FORMAT DELIMITED
+FIELDS TERMINATED BY '1'
+COLLECTION ITEMS TERMINATED BY '2'
+MAP KEYS TERMINATED BY '3'
+LINES TERMINATED BY '10'
+STORED AS TEXTFILE;
+
+EXPLAIN
+FROM src_thrift
+INSERT OVERWRITE TABLE dest1 SELECT src_thrift.lint, src_thrift.lstring, src_thrift.mstringstring, src_thrift.aint, src_thrift.astring DISTRIBUTE BY 1;
+
+FROM src_thrift
+INSERT OVERWRITE TABLE dest1 SELECT src_thrift.lint, src_thrift.lstring, src_thrift.mstringstring, src_thrift.aint, src_thrift.astring DISTRIBUTE BY 1;
+
+SELECT dest1.* FROM dest1 DISTRIBUTE BY 1;
+
+SELECT dest1.a[0], dest1.b[0], dest1.c['key2'], dest1.d, dest1.e FROM dest1 DISTRIBUTE BY 1;
diff --git a/ql/src/test/results/clientpositive/case_sensitivity.q.out b/ql/src/test/results/clientpositive/case_sensitivity.q.out
index 51f8630c74..e35001b2e2 100644
--- a/ql/src/test/results/clientpositive/case_sensitivity.q.out
+++ b/ql/src/test/results/clientpositive/case_sensitivity.q.out
@@ -15,7 +15,7 @@ STAGE PLANS:
                     expr: lint
                     type: array<int>
                     expr: lintstring
-                    type: array<struct{myint:int,mystring:string}>
+                    type: array<struct<myint:int,mystring:string>>
               Filter Operator
                 predicate:
                     expr: (0[0] > 0)
diff --git a/ql/src/test/results/clientpositive/groupby1.q.out b/ql/src/test/results/clientpositive/groupby1.q.out
index ee82e1b531..bebccac120 100644
--- a/ql/src/test/results/clientpositive/groupby1.q.out
+++ b/ql/src/test/results/clientpositive/groupby1.q.out
@@ -42,7 +42,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/suresh/hive_external/build/ql/tmp/173094765/312984077.10001 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/383864989/212664797.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -69,14 +69,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest_g1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest_g1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby1_limit.q.out b/ql/src/test/results/clientpositive/groupby1_limit.q.out
index 15b1de76c2..473a35dcf1 100644
--- a/ql/src/test/results/clientpositive/groupby1_limit.q.out
+++ b/ql/src/test/results/clientpositive/groupby1_limit.q.out
@@ -56,7 +56,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/746802126/1233171241.10001 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/1330446638/19184728.10001 
           Reduce Output Operator
             sort order: 
             tag: -1
@@ -68,14 +68,20 @@ STAGE PLANS:
       Reduce Operator Tree:
         Extract
           Limit
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby1_map.q.out b/ql/src/test/results/clientpositive/groupby1_map.q.out
index b4661724c3..81ba479a3d 100644
--- a/ql/src/test/results/clientpositive/groupby1_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby1_map.q.out
@@ -43,14 +43,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby1_map_nomap.q.out b/ql/src/test/results/clientpositive/groupby1_map_nomap.q.out
index b4661724c3..81ba479a3d 100644
--- a/ql/src/test/results/clientpositive/groupby1_map_nomap.q.out
+++ b/ql/src/test/results/clientpositive/groupby1_map_nomap.q.out
@@ -43,14 +43,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby1_map_skew.q.out b/ql/src/test/results/clientpositive/groupby1_map_skew.q.out
index 3c9a5ea7e7..7e70b1b324 100644
--- a/ql/src/test/results/clientpositive/groupby1_map_skew.q.out
+++ b/ql/src/test/results/clientpositive/groupby1_map_skew.q.out
@@ -49,7 +49,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/98848080/907077792.10001 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/133273148/247233082.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -76,14 +76,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby1_noskew.q.out b/ql/src/test/results/clientpositive/groupby1_noskew.q.out
index a118362f6d..fff79723ed 100644
--- a/ql/src/test/results/clientpositive/groupby1_noskew.q.out
+++ b/ql/src/test/results/clientpositive/groupby1_noskew.q.out
@@ -36,14 +36,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest_g1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest_g1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby2.q.out b/ql/src/test/results/clientpositive/groupby2.q.out
index 1f281527f4..27e88b4e13 100644
--- a/ql/src/test/results/clientpositive/groupby2.q.out
+++ b/ql/src/test/results/clientpositive/groupby2.q.out
@@ -44,7 +44,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive2/hive/build/ql/tmp/458651873/137748425.10001 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/118170734/653990469.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -76,14 +76,22 @@ STAGE PLANS:
                   type: bigint
                   expr: concat(0, UDFToString(2))
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest_g2
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: string
+                    expr: UDFToInteger(1)
+                    type: int
+                    expr: 2
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest_g2
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby2_map.q.out b/ql/src/test/results/clientpositive/groupby2_map.q.out
index 52e63d9380..2ca9fd04a4 100644
--- a/ql/src/test/results/clientpositive/groupby2_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby2_map.q.out
@@ -53,14 +53,22 @@ STAGE PLANS:
                   type: bigint
                   expr: concat(0, UDFToString(2))
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: string
+                    expr: UDFToInteger(1)
+                    type: int
+                    expr: 2
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby2_map_skew.q.out b/ql/src/test/results/clientpositive/groupby2_map_skew.q.out
index 40a8df3503..d744a69815 100644
--- a/ql/src/test/results/clientpositive/groupby2_map_skew.q.out
+++ b/ql/src/test/results/clientpositive/groupby2_map_skew.q.out
@@ -59,7 +59,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive2/hive/build/ql/tmp/76959905/5017405.10001 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/1067456520/103403345.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -91,14 +91,22 @@ STAGE PLANS:
                   type: bigint
                   expr: concat(0, UDFToString(2))
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: string
+                    expr: UDFToInteger(1)
+                    type: int
+                    expr: 2
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby2_noskew.q.out b/ql/src/test/results/clientpositive/groupby2_noskew.q.out
index c91e1b5af3..059fad86a2 100644
--- a/ql/src/test/results/clientpositive/groupby2_noskew.q.out
+++ b/ql/src/test/results/clientpositive/groupby2_noskew.q.out
@@ -38,14 +38,22 @@ STAGE PLANS:
                   type: bigint
                   expr: concat(0, UDFToString(2))
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest_g2
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: string
+                    expr: UDFToInteger(1)
+                    type: int
+                    expr: 2
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest_g2
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby3.q.out b/ql/src/test/results/clientpositive/groupby3.q.out
index d497b9ab7c..8290b1f1ed 100644
--- a/ql/src/test/results/clientpositive/groupby3.q.out
+++ b/ql/src/test/results/clientpositive/groupby3.q.out
@@ -44,7 +44,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive2/hive/build/ql/tmp/513475036/98479737.10001 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/412878724/247817393.10001 
           Reduce Output Operator
             sort order: 
             tag: -1
@@ -80,14 +80,26 @@ STAGE PLANS:
                   type: string
                   expr: 4
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: double
+                    expr: 1
+                    type: double
+                    expr: 2
+                    type: double
+                    expr: UDFToDouble(3)
+                    type: double
+                    expr: UDFToDouble(4)
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby3_map.q.out b/ql/src/test/results/clientpositive/groupby3_map.q.out
index 619a4365f5..6fdfc97281 100644
--- a/ql/src/test/results/clientpositive/groupby3_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby3_map.q.out
@@ -63,14 +63,26 @@ STAGE PLANS:
                   type: string
                   expr: 4
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: double
+                    expr: 1
+                    type: double
+                    expr: 2
+                    type: double
+                    expr: UDFToDouble(3)
+                    type: double
+                    expr: UDFToDouble(4)
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby3_map_skew.q.out b/ql/src/test/results/clientpositive/groupby3_map_skew.q.out
index aee4f31bbc..adb5e4a38d 100644
--- a/ql/src/test/results/clientpositive/groupby3_map_skew.q.out
+++ b/ql/src/test/results/clientpositive/groupby3_map_skew.q.out
@@ -66,7 +66,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive2/hive/build/ql/tmp/189942724/9179609.10001 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/62935826/32361129.10001 
           Reduce Output Operator
             sort order: 
             tag: -1
@@ -102,14 +102,26 @@ STAGE PLANS:
                   type: string
                   expr: 4
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: double
+                    expr: 1
+                    type: double
+                    expr: 2
+                    type: double
+                    expr: UDFToDouble(3)
+                    type: double
+                    expr: UDFToDouble(4)
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby3_noskew.q.out b/ql/src/test/results/clientpositive/groupby3_noskew.q.out
index 9b2f21447f..df1b392006 100644
--- a/ql/src/test/results/clientpositive/groupby3_noskew.q.out
+++ b/ql/src/test/results/clientpositive/groupby3_noskew.q.out
@@ -41,14 +41,26 @@ STAGE PLANS:
                   type: string
                   expr: 4
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: double
+                    expr: 1
+                    type: double
+                    expr: 2
+                    type: double
+                    expr: UDFToDouble(3)
+                    type: double
+                    expr: UDFToDouble(4)
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby4_map.q.out b/ql/src/test/results/clientpositive/groupby4_map.q.out
index 7b010ffabf..6bf3192888 100644
--- a/ql/src/test/results/clientpositive/groupby4_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby4_map.q.out
@@ -30,14 +30,18 @@ STAGE PLANS:
             expressions:
                   expr: 0
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby4_map_skew.q.out b/ql/src/test/results/clientpositive/groupby4_map_skew.q.out
index a50f650fb7..4969391e1e 100644
--- a/ql/src/test/results/clientpositive/groupby4_map_skew.q.out
+++ b/ql/src/test/results/clientpositive/groupby4_map_skew.q.out
@@ -30,14 +30,18 @@ STAGE PLANS:
             expressions:
                   expr: 0
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby5.q.out b/ql/src/test/results/clientpositive/groupby5.q.out
index 057f7c4211..0234882f2d 100644
--- a/ql/src/test/results/clientpositive/groupby5.q.out
+++ b/ql/src/test/results/clientpositive/groupby5.q.out
@@ -42,7 +42,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/suresh/hive_external/build/ql/tmp/1860802028/54191199.10001 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/808701189/631585736.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -69,14 +69,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby5_map.q.out b/ql/src/test/results/clientpositive/groupby5_map.q.out
index e8114315eb..5dac723bc2 100644
--- a/ql/src/test/results/clientpositive/groupby5_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby5_map.q.out
@@ -33,14 +33,18 @@ STAGE PLANS:
             expressions:
                   expr: 0
                   type: double
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -53,4 +57,4 @@ STAGE PLANS:
                 name: dest1
 
 
-NULL
+130091
diff --git a/ql/src/test/results/clientpositive/groupby5_map_skew.q.out b/ql/src/test/results/clientpositive/groupby5_map_skew.q.out
index f2002dd560..76fa0c3f59 100644
--- a/ql/src/test/results/clientpositive/groupby5_map_skew.q.out
+++ b/ql/src/test/results/clientpositive/groupby5_map_skew.q.out
@@ -33,14 +33,18 @@ STAGE PLANS:
             expressions:
                   expr: 0
                   type: double
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -53,4 +57,4 @@ STAGE PLANS:
                 name: dest1
 
 
-NULL
+130091
diff --git a/ql/src/test/results/clientpositive/groupby5_noskew.q.out b/ql/src/test/results/clientpositive/groupby5_noskew.q.out
index 825e08d0ce..371d3f57c1 100644
--- a/ql/src/test/results/clientpositive/groupby5_noskew.q.out
+++ b/ql/src/test/results/clientpositive/groupby5_noskew.q.out
@@ -36,14 +36,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/groupby7_map.q.out b/ql/src/test/results/clientpositive/groupby7_map.q.out
index 20d8c386f2..d3160f5190 100644
--- a/ql/src/test/results/clientpositive/groupby7_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby7_map.q.out
@@ -59,14 +59,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: true
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: true
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -87,7 +93,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/272279570/1527190226.10002 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/804020905/86268938.10002 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -114,14 +120,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: true
-              GlobalTableId: 2
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest2
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: true
+                GlobalTableId: 2
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest2
 
 
 0	0.0
diff --git a/ql/src/test/results/clientpositive/groupby7_map_skew.q.out b/ql/src/test/results/clientpositive/groupby7_map_skew.q.out
index 2cc0ef0cff..a332282689 100644
--- a/ql/src/test/results/clientpositive/groupby7_map_skew.q.out
+++ b/ql/src/test/results/clientpositive/groupby7_map_skew.q.out
@@ -66,7 +66,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/394039040/604571971.10002 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/588492101/148869634.10002 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -93,14 +93,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: true
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: true
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -121,7 +127,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/394039040/604571971.10003 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/588492101/148869634.10003 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -153,7 +159,7 @@ STAGE PLANS:
   Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/394039040/604571971.10004 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/588492101/148869634.10004 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -180,14 +186,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: true
-              GlobalTableId: 2
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest2
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: true
+                GlobalTableId: 2
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest2
 
 
 0	0.0
diff --git a/ql/src/test/results/clientpositive/groupby7_noskew.q.out b/ql/src/test/results/clientpositive/groupby7_noskew.q.out
index 2e50e3f8e2..23e8b746c7 100644
--- a/ql/src/test/results/clientpositive/groupby7_noskew.q.out
+++ b/ql/src/test/results/clientpositive/groupby7_noskew.q.out
@@ -45,14 +45,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: true
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: true
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -73,7 +79,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/82243566/219229434.10002 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/62157086/551485196.10002 
           Reduce Output Operator
             key expressions:
                   expr: key
@@ -100,14 +106,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: true
-              GlobalTableId: 2
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest2
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: true
+                GlobalTableId: 2
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest2
 
 
 0	0.0
diff --git a/ql/src/test/results/clientpositive/groupby8.q.out b/ql/src/test/results/clientpositive/groupby8.q.out
index b5bfb03be8..4b590723bd 100644
--- a/ql/src/test/results/clientpositive/groupby8.q.out
+++ b/ql/src/test/results/clientpositive/groupby8.q.out
@@ -53,7 +53,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/556477511/22889498.10002 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/56858921/8846383.10002 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -80,14 +80,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: bigint
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -108,7 +114,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/556477511/22889498.10003 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/56858921/8846383.10003 
           Reduce Output Operator
             key expressions:
                   expr: key
@@ -141,7 +147,7 @@ STAGE PLANS:
   Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/556477511/22889498.10004 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/56858921/8846383.10004 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -168,14 +174,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 2
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest2
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: bigint
+              File Output Operator
+                compressed: false
+                GlobalTableId: 2
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest2
 
 
 0	1
diff --git a/ql/src/test/results/clientpositive/groupby8_map.q.out b/ql/src/test/results/clientpositive/groupby8_map.q.out
index c9eb3d1da3..b3cdd934be 100644
--- a/ql/src/test/results/clientpositive/groupby8_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby8_map.q.out
@@ -65,14 +65,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: bigint
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -93,7 +99,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/1165802094/307152394.10002 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/429738952/71540049.10002 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -122,14 +128,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 2
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest2
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: bigint
+              File Output Operator
+                compressed: false
+                GlobalTableId: 2
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest2
 
 
 0	1
diff --git a/ql/src/test/results/clientpositive/groupby8_map_skew.q.out b/ql/src/test/results/clientpositive/groupby8_map_skew.q.out
index d9f9c2d5bc..d2ffa5e3de 100644
--- a/ql/src/test/results/clientpositive/groupby8_map_skew.q.out
+++ b/ql/src/test/results/clientpositive/groupby8_map_skew.q.out
@@ -74,7 +74,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/38395175/705859885.10002 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/169036351/65570237.10002 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -101,14 +101,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: bigint
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -129,7 +135,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/38395175/705859885.10003 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/169036351/65570237.10003 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -165,7 +171,7 @@ STAGE PLANS:
   Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/38395175/705859885.10004 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/169036351/65570237.10004 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -192,14 +198,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 2
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest2
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: bigint
+              File Output Operator
+                compressed: false
+                GlobalTableId: 2
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest2
 
 
 0	1
diff --git a/ql/src/test/results/clientpositive/groupby8_noskew.q.out b/ql/src/test/results/clientpositive/groupby8_noskew.q.out
index bde36a3398..827f094638 100644
--- a/ql/src/test/results/clientpositive/groupby8_noskew.q.out
+++ b/ql/src/test/results/clientpositive/groupby8_noskew.q.out
@@ -44,14 +44,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: bigint
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -72,7 +78,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/njain/hive1/hive/build/ql/tmp/2049900183/867913462.10002 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/359055670/660236244.10002 
           Reduce Output Operator
             key expressions:
                   expr: key
@@ -98,14 +104,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 2
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest2
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: bigint
+              File Output Operator
+                compressed: false
+                GlobalTableId: 2
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest2
 
 
 0	1
diff --git a/ql/src/test/results/clientpositive/input11.q.out b/ql/src/test/results/clientpositive/input11.q.out
index 0e0bde4195..696ae6b03d 100644
--- a/ql/src/test/results/clientpositive/input11.q.out
+++ b/ql/src/test/results/clientpositive/input11.q.out
@@ -20,14 +20,20 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input11_limit.q.out b/ql/src/test/results/clientpositive/input11_limit.q.out
index 4ed194aa4e..0695f6aeee 100644
--- a/ql/src/test/results/clientpositive/input11_limit.q.out
+++ b/ql/src/test/results/clientpositive/input11_limit.q.out
@@ -32,14 +32,20 @@ STAGE PLANS:
       Reduce Operator Tree:
         Extract
           Limit
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input12.q.out b/ql/src/test/results/clientpositive/input12.q.out
index 18b9da8d06..0a9863aff8 100644
--- a/ql/src/test/results/clientpositive/input12.q.out
+++ b/ql/src/test/results/clientpositive/input12.q.out
@@ -20,14 +20,20 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
             Filter Operator
               predicate:
                   expr: ((UDFToDouble(key) >= UDFToDouble(100)) and (UDFToDouble(key) < UDFToDouble(200)))
@@ -38,14 +44,20 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 2
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest2
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 2
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest2
             Filter Operator
               predicate:
                   expr: (UDFToDouble(key) >= UDFToDouble(200))
@@ -54,14 +66,18 @@ STAGE PLANS:
                 expressions:
                       expr: key
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 3
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest3
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 3
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest3
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input13.q.out b/ql/src/test/results/clientpositive/input13.q.out
index 5a6124867e..71ea641aa5 100644
--- a/ql/src/test/results/clientpositive/input13.q.out
+++ b/ql/src/test/results/clientpositive/input13.q.out
@@ -20,14 +20,20 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
             Filter Operator
               predicate:
                   expr: ((UDFToDouble(key) >= UDFToDouble(100)) and (UDFToDouble(key) < UDFToDouble(200)))
@@ -38,14 +44,20 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 2
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest2
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 2
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest2
             Filter Operator
               predicate:
                   expr: ((UDFToDouble(key) >= UDFToDouble(200)) and (UDFToDouble(key) < UDFToDouble(300)))
@@ -54,14 +66,18 @@ STAGE PLANS:
                 expressions:
                       expr: key
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 3
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest3
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 3
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest3
             Filter Operator
               predicate:
                   expr: (UDFToDouble(key) >= UDFToDouble(300))
diff --git a/ql/src/test/results/clientpositive/input14.q.out b/ql/src/test/results/clientpositive/input14.q.out
index 320d8e0590..75f4abd2ea 100644
--- a/ql/src/test/results/clientpositive/input14.q.out
+++ b/ql/src/test/results/clientpositive/input14.q.out
@@ -47,14 +47,20 @@ STAGE PLANS:
                     type: string
                     expr: 1
                     type: string
-              File Output Operator
-                compressed: false
-                GlobalTableId: 1
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input14_limit.q.out b/ql/src/test/results/clientpositive/input14_limit.q.out
index 13229325b9..9f20aff752 100644
--- a/ql/src/test/results/clientpositive/input14_limit.q.out
+++ b/ql/src/test/results/clientpositive/input14_limit.q.out
@@ -50,7 +50,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/suresh/hive_external/build/ql/tmp/80651290/173357897.10001 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/116387172/286027190.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -78,14 +78,20 @@ STAGE PLANS:
                       type: string
                       expr: 1
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input17.q.out b/ql/src/test/results/clientpositive/input17.q.out
index 775f4fa37b..752a94894e 100644
--- a/ql/src/test/results/clientpositive/input17.q.out
+++ b/ql/src/test/results/clientpositive/input17.q.out
@@ -17,13 +17,13 @@ STAGE PLANS:
                     expr: lint
                     type: array<int>
                     expr: lintstring
-                    type: array<struct{myint:int,mystring:string}>
+                    type: array<struct<myint:int,mystring:string>>
               Select Operator
                 expressions:
                       expr: (0 + 1[0])
                       type: int
                       expr: 2[0]
-                      type: struct{myint:int,mystring:string}
+                      type: struct<myint:int,mystring:string>
                 Transform Operator
                   command: /bin/cat
                   output info:
@@ -51,14 +51,20 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input18.q.out b/ql/src/test/results/clientpositive/input18.q.out
index 32bc5c026f..19f1801f5c 100644
--- a/ql/src/test/results/clientpositive/input18.q.out
+++ b/ql/src/test/results/clientpositive/input18.q.out
@@ -51,14 +51,20 @@ STAGE PLANS:
                     type: string
                     expr: regexp_replace(1, '	', '+')
                     type: string
-              File Output Operator
-                compressed: false
-                GlobalTableId: 1
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input1_limit.q.out b/ql/src/test/results/clientpositive/input1_limit.q.out
index 22f35a2f0e..c5e836b631 100644
--- a/ql/src/test/results/clientpositive/input1_limit.q.out
+++ b/ql/src/test/results/clientpositive/input1_limit.q.out
@@ -52,14 +52,20 @@ STAGE PLANS:
       Reduce Operator Tree:
         Extract
           Limit
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -80,7 +86,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /data/users/suresh/hive_external/build/ql/tmp/613371753/59892183.10002 
+        /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/87031805/46374236.10002 
           Reduce Output Operator
             sort order: 
             tag: -1
@@ -92,14 +98,20 @@ STAGE PLANS:
       Reduce Operator Tree:
         Extract
           Limit
-            File Output Operator
-              compressed: false
-              GlobalTableId: 2
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest2
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 2
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest2
 
 
 86	val_86
diff --git a/ql/src/test/results/clientpositive/input20.q.out b/ql/src/test/results/clientpositive/input20.q.out
index 1b2ecd4ace..14500dc289 100644
--- a/ql/src/test/results/clientpositive/input20.q.out
+++ b/ql/src/test/results/clientpositive/input20.q.out
@@ -54,14 +54,20 @@ STAGE PLANS:
               output info:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-              File Output Operator
-                compressed: false
-                GlobalTableId: 1
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input5.q.out b/ql/src/test/results/clientpositive/input5.q.out
index 94ac8771b4..6e05ea2039 100644
--- a/ql/src/test/results/clientpositive/input5.q.out
+++ b/ql/src/test/results/clientpositive/input5.q.out
@@ -15,13 +15,13 @@ STAGE PLANS:
                     expr: lint
                     type: array<int>
                     expr: lintstring
-                    type: array<struct{myint:int,mystring:string}>
+                    type: array<struct<myint:int,mystring:string>>
               Select Operator
                 expressions:
                       expr: 0
                       type: array<int>
                       expr: 1
-                      type: array<struct{myint:int,mystring:string}>
+                      type: array<struct<myint:int,mystring:string>>
                 Transform Operator
                   command: /bin/cat
                   output info:
diff --git a/ql/src/test/results/clientpositive/input7.q.out b/ql/src/test/results/clientpositive/input7.q.out
index e10b786134..661f8473c1 100644
--- a/ql/src/test/results/clientpositive/input7.q.out
+++ b/ql/src/test/results/clientpositive/input7.q.out
@@ -20,14 +20,20 @@ STAGE PLANS:
                       type: string
                       expr: 0
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToDouble(0)
+                        type: double
+                        expr: UDFToInteger(1)
+                        type: int
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input8.q.out b/ql/src/test/results/clientpositive/input8.q.out
index ce849ff528..aceeed03a1 100644
--- a/ql/src/test/results/clientpositive/input8.q.out
+++ b/ql/src/test/results/clientpositive/input8.q.out
@@ -22,14 +22,22 @@ STAGE PLANS:
                       type: double
                       expr: (null + null)
                       type: double
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: 0
+                        type: double
+                        expr: UDFToInteger(1)
+                        type: int
+                        expr: 2
+                        type: double
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input9.q.out b/ql/src/test/results/clientpositive/input9.q.out
index 833df06d95..f86c86ce30 100644
--- a/ql/src/test/results/clientpositive/input9.q.out
+++ b/ql/src/test/results/clientpositive/input9.q.out
@@ -24,14 +24,20 @@ STAGE PLANS:
                         type: string
                         expr: 0
                         type: string
-                  File Output Operator
-                    compressed: false
-                    GlobalTableId: 1
-                    table:
-                        input format: org.apache.hadoop.mapred.TextInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        name: dest1
+                  Select Operator
+                    expressions:
+                          expr: 0
+                          type: Void
+                          expr: UDFToInteger(1)
+                          type: int
+                    File Output Operator
+                      compressed: false
+                      GlobalTableId: 1
+                      table:
+                          input format: org.apache.hadoop.mapred.TextInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input_dynamicserde.q.out b/ql/src/test/results/clientpositive/input_dynamicserde.q.out
index 9178dabd87..332247ebb3 100644
--- a/ql/src/test/results/clientpositive/input_dynamicserde.q.out
+++ b/ql/src/test/results/clientpositive/input_dynamicserde.q.out
@@ -40,7 +40,7 @@ STAGE PLANS:
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
 
   Stage: Stage-0
@@ -50,7 +50,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input_lazyserde.q.out b/ql/src/test/results/clientpositive/input_lazyserde.q.out
new file mode 100644
index 0000000000..819a95007d
--- /dev/null
+++ b/ql/src/test/results/clientpositive/input_lazyserde.q.out
@@ -0,0 +1,97 @@
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF src_thrift)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB dest1)) (TOK_SELECT (TOK_SELEXPR (TOK_COLREF src_thrift lint)) (TOK_SELEXPR (TOK_COLREF src_thrift lstring)) (TOK_SELEXPR (TOK_COLREF src_thrift mstringstring)) (TOK_SELEXPR (TOK_COLREF src_thrift aint)) (TOK_SELEXPR (TOK_COLREF src_thrift astring))) (TOK_DISTRIBUTEBY 1)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        src_thrift 
+            Select Operator
+              expressions:
+                    expr: lint
+                    type: array<int>
+                    expr: lstring
+                    type: array<string>
+                    expr: mstringstring
+                    type: map<string,string>
+                    expr: aint
+                    type: int
+                    expr: astring
+                    type: string
+              Select Operator
+                expressions:
+                      expr: 0
+                      type: array<int>
+                      expr: 1
+                      type: array<string>
+                      expr: 2
+                      type: map<string,string>
+                      expr: 3
+                      type: int
+                      expr: 4
+                      type: string
+                Reduce Output Operator
+                  sort order: 
+                  Map-reduce partition columns:
+                        expr: 1
+                        type: int
+                  tag: -1
+                  value expressions:
+                        expr: 0
+                        type: array<int>
+                        expr: 1
+                        type: array<string>
+                        expr: 2
+                        type: map<string,string>
+                        expr: 3
+                        type: int
+                        expr: 4
+                        type: string
+      Reduce Operator Tree:
+        Extract
+          File Output Operator
+            compressed: false
+            GlobalTableId: 1
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                name: dest1
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+            replace: true
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                name: dest1
+
+
+[0,0,0]	["0","0","0"]	{"key_0":"value_0"}	1712634731	record_0
+[1,2,3]	["10","100","1000"]	{"key_1":"value_1"}	465985200	record_1
+[2,4,6]	["20","200","2000"]	{"key_2":"value_2"}	-751827638	record_2
+[3,6,9]	["30","300","3000"]	{"key_3":"value_3"}	477111222	record_3
+[4,8,12]	["40","400","4000"]	{"key_4":"value_4"}	-734328909	record_4
+[5,10,15]	["50","500","5000"]	{"key_5":"value_5"}	-1952710710	record_5
+[6,12,18]	["60","600","6000"]	{"key_6":"value_6"}	1244525190	record_6
+[7,14,21]	["70","700","7000"]	{"key_7":"value_7"}	-1461153973	record_7
+[8,16,24]	["80","800","8000"]	{"key_8":"value_8"}	1638581578	record_8
+[9,18,27]	["90","900","9000"]	{"key_9":"value_9"}	336964413	record_9
+null	null	null	0	NULL
+0	0	NULL	1712634731	record_0
+1	10	NULL	465985200	record_1
+2	20	NULL	-751827638	record_2
+3	30	NULL	477111222	record_3
+4	40	NULL	-734328909	record_4
+5	50	NULL	-1952710710	record_5
+6	60	NULL	1244525190	record_6
+7	70	NULL	-1461153973	record_7
+8	80	NULL	1638581578	record_8
+9	90	NULL	336964413	record_9
+NULL	NULL	NULL	0	NULL
diff --git a/ql/src/test/results/clientpositive/input_part1.q.out b/ql/src/test/results/clientpositive/input_part1.q.out
index 9fdf484910..025aee2d3b 100644
--- a/ql/src/test/results/clientpositive/input_part1.q.out
+++ b/ql/src/test/results/clientpositive/input_part1.q.out
@@ -24,31 +24,41 @@ STAGE PLANS:
                       type: string
                       expr: ds
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  directory: /data/users/suresh/hive_external/ql/../build/ql/tmp/86176150/198528042.10000.insclause-0
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      properties:
-                        name dest1
-                        columns.types int:string:string:string
-                        serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
-                        serialization.format 1
-                        columns key,value,hr,ds
-                        bucket_count -1
-                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                        expr: 2
+                        type: string
+                        expr: 3
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    directory: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/877523544/755373214.10000.insclause-0
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        properties:
+                          name dest1
+                          columns.types int:string:string:string
+                          serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
+                          serialization.format 1
+                          columns key,value,hr,ds
+                          bucket_count -1
+                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
       Path -> Partition:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
           Partition
             partition values:
               ds 2008-04-08
@@ -67,7 +77,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
 
@@ -75,7 +85,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/suresh/hive_external/ql/../build/ql/tmp/86176150/198528042.10000.insclause-0
+            source: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/877523544/755373214.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
@@ -89,7 +99,7 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
diff --git a/ql/src/test/results/clientpositive/input_part2.q.out b/ql/src/test/results/clientpositive/input_part2.q.out
index 866df6c765..6ea9fde3e7 100644
--- a/ql/src/test/results/clientpositive/input_part2.q.out
+++ b/ql/src/test/results/clientpositive/input_part2.q.out
@@ -24,26 +24,36 @@ STAGE PLANS:
                       type: string
                       expr: ds
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  directory: /data/users/suresh/hive_external/ql/../build/ql/tmp/592672360/455172239.10000.insclause-0
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      properties:
-                        name dest1
-                        columns.types int:string:string:string
-                        serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
-                        serialization.format 1
-                        columns key,value,hr,ds
-                        bucket_count -1
-                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                        expr: 2
+                        type: string
+                        expr: 3
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    directory: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/1430035997/363011936.10000.insclause-0
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        properties:
+                          name dest1
+                          columns.types int:string:string:string
+                          serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
+                          serialization.format 1
+                          columns key,value,hr,ds
+                          bucket_count -1
+                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
             Filter Operator
               predicate:
                   expr: (((UDFToDouble(key) < UDFToDouble(100)) and (ds = '2008-04-09')) and (hr = '12'))
@@ -58,32 +68,42 @@ STAGE PLANS:
                       type: string
                       expr: ds
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 2
-                  directory: /data/users/suresh/hive_external/ql/../build/ql/tmp/592672360/455172239.10001.insclause-1
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      properties:
-                        name dest2
-                        columns.types int:string:string:string
-                        serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
-                        serialization.format 1
-                        columns key,value,hr,ds
-                        bucket_count -1
-                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest2
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest2
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                        expr: 2
+                        type: string
+                        expr: 3
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 2
+                    directory: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/1430035997/363011936.10001.insclause-1
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        properties:
+                          name dest2
+                          columns.types int:string:string:string
+                          serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
+                          serialization.format 1
+                          columns key,value,hr,ds
+                          bucket_count -1
+                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest2
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest2
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-09 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-09 
       Path -> Partition:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
           Partition
             partition values:
               ds 2008-04-08
@@ -102,10 +122,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-09 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-09 
           Partition
             partition values:
               ds 2008-04-09
@@ -124,7 +144,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
 
@@ -132,7 +152,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/suresh/hive_external/ql/../build/ql/tmp/592672360/455172239.10000.insclause-0
+            source: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/1430035997/363011936.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
@@ -146,11 +166,11 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
             replace: true
-            source: /data/users/suresh/hive_external/ql/../build/ql/tmp/592672360/455172239.10001.insclause-1
+            source: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/1430035997/363011936.10001.insclause-1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
@@ -164,7 +184,7 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest2
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest2
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest2
 
diff --git a/ql/src/test/results/clientpositive/input_testsequencefile.q.out b/ql/src/test/results/clientpositive/input_testsequencefile.q.out
index 01702366c1..752844fe21 100644
--- a/ql/src/test/results/clientpositive/input_testsequencefile.q.out
+++ b/ql/src/test/results/clientpositive/input_testsequencefile.q.out
@@ -16,14 +16,20 @@ STAGE PLANS:
                     type: string
                     expr: value
                     type: string
-              File Output Operator
-                compressed: false
-                GlobalTableId: 1
-                table:
-                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                    output format: org.apache.hadoop.mapred.SequenceFileOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    name: dest4_sequencefile
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.mapred.SequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: dest4_sequencefile
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/input_testxpath.q.out b/ql/src/test/results/clientpositive/input_testxpath.q.out
index d0c1570088..1bf1d6f9bc 100644
--- a/ql/src/test/results/clientpositive/input_testxpath.q.out
+++ b/ql/src/test/results/clientpositive/input_testxpath.q.out
@@ -15,7 +15,7 @@ STAGE PLANS:
                     expr: lint
                     type: array<int>
                     expr: lintstring
-                    type: array<struct{myint:int,mystring:string}>
+                    type: array<struct<myint:int,mystring:string>>
                     expr: mstringstring
                     type: map<string,string>
               Select Operator
diff --git a/ql/src/test/results/clientpositive/input_testxpath2.q.out b/ql/src/test/results/clientpositive/input_testxpath2.q.out
index d2f2c7352b..4b2750ed6f 100644
--- a/ql/src/test/results/clientpositive/input_testxpath2.q.out
+++ b/ql/src/test/results/clientpositive/input_testxpath2.q.out
@@ -15,7 +15,7 @@ STAGE PLANS:
                     expr: lint
                     type: array<int>
                     expr: lintstring
-                    type: array<struct{myint:int,mystring:string}>
+                    type: array<struct<myint:int,mystring:string>>
                     expr: mstringstring
                     type: map<string,string>
               Filter Operator
diff --git a/ql/src/test/results/clientpositive/input_testxpath3.q.out b/ql/src/test/results/clientpositive/input_testxpath3.q.out
index 7fdd96b634..83f3197943 100644
--- a/ql/src/test/results/clientpositive/input_testxpath3.q.out
+++ b/ql/src/test/results/clientpositive/input_testxpath3.q.out
@@ -15,7 +15,7 @@ STAGE PLANS:
                     expr: mstringstring
                     type: map<string,string>
                     expr: lintstring
-                    type: array<struct{myint:int,mystring:string}>
+                    type: array<struct<myint:int,mystring:string>>
               Select Operator
                 expressions:
                       expr: 0['key_9']
diff --git a/ql/src/test/results/clientpositive/join1.q.out b/ql/src/test/results/clientpositive/join1.q.out
index 9629af8c83..5d903d0537 100644
--- a/ql/src/test/results/clientpositive/join1.q.out
+++ b/ql/src/test/results/clientpositive/join1.q.out
@@ -54,14 +54,20 @@ STAGE PLANS:
                   type: string
                   expr: 2
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest_j1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest_j1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/join14.q.out b/ql/src/test/results/clientpositive/join14.q.out
index 8b7ba627f4..0c3fa9acc5 100644
--- a/ql/src/test/results/clientpositive/join14.q.out
+++ b/ql/src/test/results/clientpositive/join14.q.out
@@ -72,14 +72,20 @@ STAGE PLANS:
                   type: string
                   expr: 2
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/join17.q.out b/ql/src/test/results/clientpositive/join17.q.out
index 7021e1c950..1cc46d8c7f 100644
--- a/ql/src/test/results/clientpositive/join17.q.out
+++ b/ql/src/test/results/clientpositive/join17.q.out
@@ -41,9 +41,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src 
       Path -> Partition:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -58,7 +58,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/src
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
       Reduce Operator Tree:
@@ -78,32 +78,42 @@ STAGE PLANS:
                   type: string
                   expr: 3
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              directory: /data/users/suresh/hive_external/ql/../build/ql/tmp/1798908065/135704638.10000.insclause-0
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  properties:
-                    name dest1
-                    columns.types int:string:int:string
-                    serialization.ddl struct dest1 { i32 key1, string value1, i32 key2, string value2}
-                    serialization.format 1
-                    columns key1,value1,key2,value2
-                    bucket_count -1
-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                    file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+                    expr: UDFToInteger(2)
+                    type: int
+                    expr: 3
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                directory: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/178622185/60647075.10000.insclause-0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    properties:
+                      name dest1
+                      columns.types int:string:int:string
+                      serialization.ddl struct dest1 { i32 key1, string value1, i32 key2, string value2}
+                      serialization.format 1
+                      columns key1,value1,key2,value2
+                      bucket_count -1
+                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                      file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
       tables:
             replace: true
-            source: /data/users/suresh/hive_external/ql/../build/ql/tmp/1798908065/135704638.10000.insclause-0
+            source: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/178622185/60647075.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
@@ -117,7 +127,7 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
diff --git a/ql/src/test/results/clientpositive/join2.q.out b/ql/src/test/results/clientpositive/join2.q.out
index 5a5f6fdcf9..c3a1344700 100644
--- a/ql/src/test/results/clientpositive/join2.q.out
+++ b/ql/src/test/results/clientpositive/join2.q.out
@@ -105,14 +105,20 @@ STAGE PLANS:
                   type: string
                   expr: 3
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest_j2
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest_j2
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/join3.q.out b/ql/src/test/results/clientpositive/join3.q.out
index 2cdfab36b5..6f81c30c56 100644
--- a/ql/src/test/results/clientpositive/join3.q.out
+++ b/ql/src/test/results/clientpositive/join3.q.out
@@ -73,14 +73,20 @@ STAGE PLANS:
                   type: string
                   expr: 3
                   type: string
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -92,7 +98,6 @@ STAGE PLANS:
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
-
 0	val_0
 0	val_0
 0	val_0
diff --git a/ql/src/test/results/clientpositive/join4.q.out b/ql/src/test/results/clientpositive/join4.q.out
index aa3da48cca..ae4cf28b8d 100644
--- a/ql/src/test/results/clientpositive/join4.q.out
+++ b/ql/src/test/results/clientpositive/join4.q.out
@@ -86,14 +86,24 @@ STAGE PLANS:
                     type: string
                     expr: 3
                     type: string
-              File Output Operator
-                compressed: false
-                GlobalTableId: 1
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                      expr: UDFToInteger(2)
+                      type: int
+                      expr: 3
+                      type: string
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/join5.q.out b/ql/src/test/results/clientpositive/join5.q.out
index ccfad7f7fa..f22646c662 100644
--- a/ql/src/test/results/clientpositive/join5.q.out
+++ b/ql/src/test/results/clientpositive/join5.q.out
@@ -86,14 +86,24 @@ STAGE PLANS:
                     type: string
                     expr: 3
                     type: string
-              File Output Operator
-                compressed: false
-                GlobalTableId: 1
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                      expr: UDFToInteger(2)
+                      type: int
+                      expr: 3
+                      type: string
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/join6.q.out b/ql/src/test/results/clientpositive/join6.q.out
index 4701e68355..56a2007723 100644
--- a/ql/src/test/results/clientpositive/join6.q.out
+++ b/ql/src/test/results/clientpositive/join6.q.out
@@ -86,14 +86,24 @@ STAGE PLANS:
                     type: string
                     expr: 3
                     type: string
-              File Output Operator
-                compressed: false
-                GlobalTableId: 1
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                      expr: UDFToInteger(2)
+                      type: int
+                      expr: 3
+                      type: string
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/join7.q.out b/ql/src/test/results/clientpositive/join7.q.out
index 8ef7ddc0e3..9b53a0a0c1 100644
--- a/ql/src/test/results/clientpositive/join7.q.out
+++ b/ql/src/test/results/clientpositive/join7.q.out
@@ -121,14 +121,28 @@ STAGE PLANS:
                     type: string
                     expr: 5
                     type: string
-              File Output Operator
-                compressed: false
-                GlobalTableId: 1
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                      expr: UDFToInteger(2)
+                      type: int
+                      expr: 3
+                      type: string
+                      expr: UDFToInteger(4)
+                      type: int
+                      expr: 5
+                      type: string
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/join8.q.out b/ql/src/test/results/clientpositive/join8.q.out
index dd68bd32db..9113fb14c4 100644
--- a/ql/src/test/results/clientpositive/join8.q.out
+++ b/ql/src/test/results/clientpositive/join8.q.out
@@ -90,14 +90,24 @@ STAGE PLANS:
                       type: string
                       expr: 3
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                        expr: UDFToInteger(2)
+                        type: int
+                        expr: 3
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/join9.q.out b/ql/src/test/results/clientpositive/join9.q.out
index 669e248332..eeaf221c4c 100644
--- a/ql/src/test/results/clientpositive/join9.q.out
+++ b/ql/src/test/results/clientpositive/join9.q.out
@@ -51,10 +51,10 @@ STAGE PLANS:
                       type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/src 
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
       Path -> Partition:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -69,10 +69,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/src
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08 
           Partition
             partition values:
               ds 2008-04-08
@@ -91,7 +91,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
       Reduce Operator Tree:
@@ -111,32 +111,38 @@ STAGE PLANS:
                     type: string
                     expr: 4
                     type: string
-              File Output Operator
-                compressed: false
-                GlobalTableId: 1
-                directory: /data/users/suresh/hive_external/ql/../build/ql/tmp/1684503332.10000.insclause-0
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    properties:
-                      name dest1
-                      columns.types int:string
-                      serialization.ddl struct dest1 { i32 key, string value}
-                      serialization.format 1
-                      columns key,value
-                      bucket_count -1
-                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                      file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  directory: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/692832157.10000.insclause-0
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      properties:
+                        name dest1
+                        columns.types int:string
+                        serialization.ddl struct dest1 { i32 key, string value}
+                        serialization.format 1
+                        columns key,value
+                        bucket_count -1
+                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
       tables:
             replace: true
-            source: /data/users/suresh/hive_external/ql/../build/ql/tmp/1684503332.10000.insclause-0
+            source: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/692832157.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
@@ -150,7 +156,7 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
diff --git a/ql/src/test/results/clientpositive/mapreduce1.q.out b/ql/src/test/results/clientpositive/mapreduce1.q.out
index ef3c59b51d..3134a1e39b 100644
--- a/ql/src/test/results/clientpositive/mapreduce1.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce1.q.out
@@ -49,14 +49,24 @@ STAGE PLANS:
                         type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: UDFToInteger(1)
+                  type: int
+                  expr: UDFToInteger(2)
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/mapreduce2.q.out b/ql/src/test/results/clientpositive/mapreduce2.q.out
index 8e983fe05c..0e76b1e96a 100644
--- a/ql/src/test/results/clientpositive/mapreduce2.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce2.q.out
@@ -44,14 +44,24 @@ STAGE PLANS:
                         type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: UDFToInteger(1)
+                  type: int
+                  expr: UDFToInteger(2)
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/mapreduce3.q.out b/ql/src/test/results/clientpositive/mapreduce3.q.out
index de41d382c0..4b29d12e94 100644
--- a/ql/src/test/results/clientpositive/mapreduce3.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce3.q.out
@@ -44,14 +44,24 @@ STAGE PLANS:
                         type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: UDFToInteger(1)
+                  type: int
+                  expr: UDFToInteger(2)
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/mapreduce4.q.out b/ql/src/test/results/clientpositive/mapreduce4.q.out
index d5c32d1e81..e7ca98046e 100644
--- a/ql/src/test/results/clientpositive/mapreduce4.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce4.q.out
@@ -49,14 +49,24 @@ STAGE PLANS:
                         type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: UDFToInteger(1)
+                  type: int
+                  expr: UDFToInteger(2)
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/mapreduce5.q.out b/ql/src/test/results/clientpositive/mapreduce5.q.out
index 917543cbee..a473abb5a1 100644
--- a/ql/src/test/results/clientpositive/mapreduce5.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce5.q.out
@@ -44,14 +44,24 @@ STAGE PLANS:
                       type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: 1
+                  type: int
+                  expr: 2
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/mapreduce6.q.out b/ql/src/test/results/clientpositive/mapreduce6.q.out
index 3f0c948ced..a3ef6e7554 100644
--- a/ql/src/test/results/clientpositive/mapreduce6.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce6.q.out
@@ -44,14 +44,24 @@ STAGE PLANS:
                       type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: 1
+                  type: int
+                  expr: 2
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/mapreduce7.q.out b/ql/src/test/results/clientpositive/mapreduce7.q.out
index be04b7a0c2..f5d35e28cd 100644
--- a/ql/src/test/results/clientpositive/mapreduce7.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce7.q.out
@@ -52,14 +52,28 @@ STAGE PLANS:
                         type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: 0
+                  type: string
+                  expr: 1
+                  type: string
+                  expr: UDFToInteger(2)
+                  type: int
+                  expr: UDFToInteger(3)
+                  type: int
+                  expr: UDFToInteger(4)
+                  type: int
+                  expr: 5
+                  type: string
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/mapreduce8.q.out b/ql/src/test/results/clientpositive/mapreduce8.q.out
index 50764d43d9..8941fc6ddd 100644
--- a/ql/src/test/results/clientpositive/mapreduce8.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce8.q.out
@@ -55,14 +55,28 @@ STAGE PLANS:
                         type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: 0
+                  type: string
+                  expr: 1
+                  type: string
+                  expr: UDFToInteger(2)
+                  type: int
+                  expr: UDFToInteger(3)
+                  type: int
+                  expr: UDFToInteger(4)
+                  type: int
+                  expr: 5
+                  type: string
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/notable_alias1.q.out b/ql/src/test/results/clientpositive/notable_alias1.q.out
index 2235bcf070..0b6022eac6 100644
--- a/ql/src/test/results/clientpositive/notable_alias1.q.out
+++ b/ql/src/test/results/clientpositive/notable_alias1.q.out
@@ -53,14 +53,22 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: string
+                    expr: UDFToInteger(1)
+                    type: int
+                    expr: UDFToDouble(2)
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/notable_alias2.q.out b/ql/src/test/results/clientpositive/notable_alias2.q.out
index 0d8906e94a..eef960c449 100644
--- a/ql/src/test/results/clientpositive/notable_alias2.q.out
+++ b/ql/src/test/results/clientpositive/notable_alias2.q.out
@@ -53,14 +53,22 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              GlobalTableId: 1
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: string
+                    expr: UDFToInteger(1)
+                    type: int
+                    expr: UDFToDouble(2)
+                    type: double
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/quote1.q.out b/ql/src/test/results/clientpositive/quote1.q.out
index 80e668e3af..9378c6dd22 100644
--- a/ql/src/test/results/clientpositive/quote1.q.out
+++ b/ql/src/test/results/clientpositive/quote1.q.out
@@ -20,14 +20,20 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/sample1.q.out b/ql/src/test/results/clientpositive/sample1.q.out
index a41ade68bf..8f47e8f4b8 100644
--- a/ql/src/test/results/clientpositive/sample1.q.out
+++ b/ql/src/test/results/clientpositive/sample1.q.out
@@ -28,31 +28,41 @@ STAGE PLANS:
                         type: string
                         expr: hr
                         type: string
-                  File Output Operator
-                    compressed: false
-                    GlobalTableId: 1
-                    directory: /data/users/suresh/hive_external/ql/../build/ql/tmp/96438088/738268075.10000.insclause-0
-                    table:
-                        input format: org.apache.hadoop.mapred.TextInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        properties:
-                          name dest1
-                          columns.types int:string:string:string
-                          serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
-                          serialization.format 1
-                          columns key,value,dt,hr
-                          bucket_count -1
-                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                          location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
-                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        name: dest1
+                  Select Operator
+                    expressions:
+                          expr: UDFToInteger(0)
+                          type: int
+                          expr: 1
+                          type: string
+                          expr: 2
+                          type: string
+                          expr: 3
+                          type: string
+                    File Output Operator
+                      compressed: false
+                      GlobalTableId: 1
+                      directory: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/319540068/256141092.10000.insclause-0
+                      table:
+                          input format: org.apache.hadoop.mapred.TextInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          properties:
+                            name dest1
+                            columns.types int:string:string:string
+                            serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
+                            serialization.format 1
+                            columns key,value,dt,hr
+                            bucket_count -1
+                            serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                            file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                            location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
+                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart/hr=11/ds=2008-04-08 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=11/ds=2008-04-08 
       Path -> Partition:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart/hr=11/ds=2008-04-08 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=11/ds=2008-04-08 
           Partition
             partition values:
               ds 2008-04-08
@@ -71,7 +81,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
 
@@ -79,7 +89,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/suresh/hive_external/ql/../build/ql/tmp/96438088/738268075.10000.insclause-0
+            source: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/319540068/256141092.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
@@ -93,7 +103,7 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
diff --git a/ql/src/test/results/clientpositive/sample2.q.out b/ql/src/test/results/clientpositive/sample2.q.out
index cc753f6406..a5542b8072 100644
--- a/ql/src/test/results/clientpositive/sample2.q.out
+++ b/ql/src/test/results/clientpositive/sample2.q.out
@@ -16,31 +16,37 @@ STAGE PLANS:
                     type: string
                     expr: value
                     type: string
-              File Output Operator
-                compressed: false
-                GlobalTableId: 1
-                directory: /data/users/suresh/hive_external/ql/../build/ql/tmp/285296283/100507889.10000.insclause-0
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    properties:
-                      name dest1
-                      columns.types int:string
-                      serialization.ddl struct dest1 { i32 key, string value}
-                      serialization.format 1
-                      columns key,value
-                      bucket_count -1
-                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                      file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  directory: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/477645695/400755064.10000.insclause-0
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      properties:
+                        name dest1
+                        columns.types int:string
+                        serialization.ddl struct dest1 { i32 key, string value}
+                        serialization.format 1
+                        columns key,value
+                        bucket_count -1
+                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -56,7 +62,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
 
@@ -64,7 +70,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/suresh/hive_external/ql/../build/ql/tmp/285296283/100507889.10000.insclause-0
+            source: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/477645695/400755064.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
@@ -78,7 +84,7 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
diff --git a/ql/src/test/results/clientpositive/sample4.q.out b/ql/src/test/results/clientpositive/sample4.q.out
index d3d6d85a5f..b8da51fb87 100644
--- a/ql/src/test/results/clientpositive/sample4.q.out
+++ b/ql/src/test/results/clientpositive/sample4.q.out
@@ -16,31 +16,37 @@ STAGE PLANS:
                     type: string
                     expr: value
                     type: string
-              File Output Operator
-                compressed: false
-                GlobalTableId: 1
-                directory: /data/users/suresh/hive_external/ql/../build/ql/tmp/352752249/345097786.10000.insclause-0
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    properties:
-                      name dest1
-                      columns.types int:string
-                      serialization.ddl struct dest1 { i32 key, string value}
-                      serialization.format 1
-                      columns key,value
-                      bucket_count -1
-                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                      file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  directory: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/267461892/432952658.10000.insclause-0
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      properties:
+                        name dest1
+                        columns.types int:string
+                        serialization.ddl struct dest1 { i32 key, string value}
+                        serialization.format 1
+                        columns key,value
+                        bucket_count -1
+                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -56,7 +62,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
 
@@ -64,7 +70,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/suresh/hive_external/ql/../build/ql/tmp/352752249/345097786.10000.insclause-0
+            source: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/267461892/432952658.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
@@ -78,7 +84,7 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
diff --git a/ql/src/test/results/clientpositive/sample5.q.out b/ql/src/test/results/clientpositive/sample5.q.out
index 5a1e194576..55c3aeb714 100644
--- a/ql/src/test/results/clientpositive/sample5.q.out
+++ b/ql/src/test/results/clientpositive/sample5.q.out
@@ -20,31 +20,37 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  directory: /data/users/suresh/hive_external/ql/../build/ql/tmp/39418037/95228957.10000.insclause-0
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      properties:
-                        name dest1
-                        columns.types int:string
-                        serialization.ddl struct dest1 { i32 key, string value}
-                        serialization.format 1
-                        columns key,value
-                        bucket_count -1
-                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    directory: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/358722082/194096633.10000.insclause-0
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        properties:
+                          name dest1
+                          columns.types int:string
+                          serialization.ddl struct dest1 { i32 key, string value}
+                          serialization.format 1
+                          columns key,value
+                          bucket_count -1
+                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket 
       Path -> Partition:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -60,7 +66,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
 
@@ -68,7 +74,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/suresh/hive_external/ql/../build/ql/tmp/39418037/95228957.10000.insclause-0
+            source: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/358722082/194096633.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
@@ -82,7 +88,7 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
diff --git a/ql/src/test/results/clientpositive/sample6.q.out b/ql/src/test/results/clientpositive/sample6.q.out
index bb88cb3d22..75eaf15fe3 100644
--- a/ql/src/test/results/clientpositive/sample6.q.out
+++ b/ql/src/test/results/clientpositive/sample6.q.out
@@ -20,31 +20,37 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  GlobalTableId: 1
-                  directory: /data/users/suresh/hive_external/ql/../build/ql/tmp/9261073/201358769.10000.insclause-0
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      properties:
-                        name dest1
-                        columns.types int:string
-                        serialization.ddl struct dest1 { i32 key, string value}
-                        serialization.format 1
-                        columns key,value
-                        bucket_count -1
-                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    directory: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/150676077/22724205.10000.insclause-0
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        properties:
+                          name dest1
+                          columns.types int:string
+                          serialization.ddl struct dest1 { i32 key, string value}
+                          serialization.format 1
+                          columns key,value
+                          bucket_count -1
+                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -60,7 +66,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
 
@@ -68,7 +74,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/suresh/hive_external/ql/../build/ql/tmp/9261073/201358769.10000.insclause-0
+            source: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/150676077/22724205.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
@@ -82,7 +88,7 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
diff --git a/ql/src/test/results/clientpositive/sample7.q.out b/ql/src/test/results/clientpositive/sample7.q.out
index b337413ee3..5d6099834a 100644
--- a/ql/src/test/results/clientpositive/sample7.q.out
+++ b/ql/src/test/results/clientpositive/sample7.q.out
@@ -24,31 +24,37 @@ STAGE PLANS:
                         type: string
                         expr: value
                         type: string
-                  File Output Operator
-                    compressed: false
-                    GlobalTableId: 1
-                    directory: /data/users/suresh/hive_external/ql/../build/ql/tmp/1494119520/1981029424.10000.insclause-0
-                    table:
-                        input format: org.apache.hadoop.mapred.TextInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        properties:
-                          name dest1
-                          columns.types int:string
-                          serialization.ddl struct dest1 { i32 key, string value}
-                          serialization.format 1
-                          columns key,value
-                          bucket_count -1
-                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                          location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
-                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        name: dest1
+                  Select Operator
+                    expressions:
+                          expr: UDFToInteger(0)
+                          type: int
+                          expr: 1
+                          type: string
+                    File Output Operator
+                      compressed: false
+                      GlobalTableId: 1
+                      directory: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/747880952/732471250.10000.insclause-0
+                      table:
+                          input format: org.apache.hadoop.mapred.TextInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          properties:
+                            name dest1
+                            columns.types int:string
+                            serialization.ddl struct dest1 { i32 key, string value}
+                            serialization.format 1
+                            columns key,value
+                            bucket_count -1
+                            serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                            file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                            location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
+                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -64,7 +70,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
 
@@ -72,7 +78,7 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /data/users/suresh/hive_external/ql/../build/ql/tmp/1494119520/1981029424.10000.insclause-0
+            source: /data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/747880952/732471250.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
@@ -86,7 +92,7 @@ STAGE PLANS:
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/data/users/suresh/hive_external/build/ql/test/data/warehouse/dest1
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
diff --git a/ql/src/test/results/compiler/plan/case_sensitivity.q.xml b/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
index 940bf76416..e000863e55 100644
--- a/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
+++ b/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/22214176.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/128516067.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -135,7 +135,7 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/22214176.10000.insclause-0</string> 
+                           <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/128516067.10000.insclause-0</string> 
                           </void> 
                           <void property="tableInfo"> 
                            <object idref="tableDesc0"/> 
@@ -162,7 +162,7 @@
                                <string>0</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.Integer</class> 
                                 </void> 
@@ -176,7 +176,7 @@
                                <string>1</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.String</class> 
                                 </void> 
@@ -204,7 +204,7 @@
                              <string>0</string> 
                             </void> 
                             <void property="typeInfo"> 
-                             <object id="ListTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+                             <object id="ListTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                               <void property="listElementTypeInfo"> 
                                <object idref="PrimitiveTypeInfo0"/> 
                               </void> 
@@ -237,9 +237,9 @@
                                <string>1</string> 
                               </void> 
                               <void property="typeInfo"> 
-                               <object id="ListTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+                               <object id="ListTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                                 <void property="listElementTypeInfo"> 
-                                 <object id="StructTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.StructTypeInfo"/> 
+                                 <object id="StructTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo"/> 
                                 </void> 
                                </object> 
                               </void> 
@@ -358,7 +358,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Boolean</class> 
                       </void> 
@@ -502,7 +502,7 @@
                <string>lstring</string> 
               </void> 
               <void property="type"> 
-               <object class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+               <object class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                 <void property="listElementTypeInfo"> 
                  <object idref="PrimitiveTypeInfo1"/> 
                 </void> 
@@ -526,7 +526,7 @@
                <string>mstringstring</string> 
               </void> 
               <void property="type"> 
-               <object class="org.apache.hadoop.hive.ql.typeinfo.MapTypeInfo"> 
+               <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
                 <void property="mapKeyTypeInfo"> 
                  <object idref="PrimitiveTypeInfo1"/> 
                 </void> 
@@ -548,7 +548,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src_thrift</string> 
@@ -560,7 +560,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -620,7 +620,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/cast1.q.xml b/ql/src/test/results/compiler/plan/cast1.q.xml
index ce5662a68e..c6890d9aa1 100644
--- a/ql/src/test/results/compiler/plan/cast1.q.xml
+++ b/ql/src/test/results/compiler/plan/cast1.q.xml
@@ -30,7 +30,7 @@
                         <void property="conf"> 
                          <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                           <void property="dirName"> 
-                           <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/86110692.10001.insclause-0</string> 
+                           <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/799830677.10001.insclause-0</string> 
                           </void> 
                           <void property="tableInfo"> 
                            <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -79,7 +79,7 @@
                                <string>0</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.Integer</class> 
                                 </void> 
@@ -93,7 +93,7 @@
                                <string>1</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.Double</class> 
                                 </void> 
@@ -137,7 +137,7 @@
                                <string>5</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.Boolean</class> 
                                 </void> 
@@ -612,7 +612,7 @@
                              <string>0</string> 
                             </void> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.String</class> 
                               </void> 
@@ -779,7 +779,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -791,7 +791,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -847,7 +847,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/groupby1.q.xml b/ql/src/test/results/compiler/plan/groupby1.q.xml
index 5b87534c2d..15182493b8 100755
--- a/ql/src/test/results/compiler/plan/groupby1.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby1.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/434688883/186307528.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/2037119/495156427.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -131,7 +131,7 @@
                        <string>0</string> 
                       </void> 
                       <void property="typeInfo"> 
-                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.String</class> 
                         </void> 
@@ -191,7 +191,7 @@
                        <string>1</string> 
                       </void> 
                       <void property="typeInfo"> 
-                       <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.Double</class> 
                         </void> 
@@ -204,7 +204,7 @@
                   <void property="valueSerializeInfo"> 
                    <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                     <void property="deserializerClass"> 
-                     <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                     <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                     </void> 
                     <void property="inputFileFormatClass"> 
                      <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -215,16 +215,12 @@
                     <void property="properties"> 
                      <object class="java.util.Properties"> 
                       <void method="put"> 
-                       <string>name</string> 
-                       <string>binary_table</string> 
-                      </void> 
-                      <void method="put"> 
-                       <string>serialization.ddl</string> 
-                       <string>struct binary_table { double reducesinkvalue0}</string> 
+                       <string>columns</string> 
+                       <string>reducesinkvalue0</string> 
                       </void> 
                       <void method="put"> 
-                       <string>serialization.format</string> 
-                       <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                       <string>columns.types</string> 
+                       <string>double</string> 
                       </void> 
                      </object> 
                     </void> 
@@ -342,7 +338,7 @@
                             <void method="add"> 
                              <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                               <void property="typeInfo"> 
-                               <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.Integer</class> 
                                 </void> 
@@ -487,7 +483,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -499,7 +495,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -555,7 +551,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -584,7 +580,7 @@
                  <int>1</int> 
                 </void> 
                 <void property="dirName"> 
-                 <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/434688883/186307528.10000.insclause-0</string> 
+                 <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/2037119/495156427.10000.insclause-0</string> 
                 </void> 
                 <void property="tableInfo"> 
                  <object idref="tableDesc0"/> 
diff --git a/ql/src/test/results/compiler/plan/groupby2.q.xml b/ql/src/test/results/compiler/plan/groupby2.q.xml
index 23d754fb13..a0e9b48129 100755
--- a/ql/src/test/results/compiler/plan/groupby2.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby2.q.xml
@@ -29,7 +29,7 @@
                        <string>0</string> 
                       </void> 
                       <void property="typeInfo"> 
-                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.String</class> 
                         </void> 
@@ -103,7 +103,7 @@
                        <string>2</string> 
                       </void> 
                       <void property="typeInfo"> 
-                       <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.Long</class> 
                         </void> 
@@ -117,7 +117,7 @@
                        <string>3</string> 
                       </void> 
                       <void property="typeInfo"> 
-                       <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.Double</class> 
                         </void> 
@@ -130,7 +130,7 @@
                   <void property="valueSerializeInfo"> 
                    <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                     <void property="deserializerClass"> 
-                     <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                     <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                     </void> 
                     <void property="inputFileFormatClass"> 
                      <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -141,16 +141,12 @@
                     <void property="properties"> 
                      <object class="java.util.Properties"> 
                       <void method="put"> 
-                       <string>name</string> 
-                       <string>binary_table</string> 
-                      </void> 
-                      <void method="put"> 
-                       <string>serialization.ddl</string> 
-                       <string>struct binary_table { i64 reducesinkvalue0, double reducesinkvalue1}</string> 
+                       <string>columns</string> 
+                       <string>reducesinkvalue0,reducesinkvalue1</string> 
                       </void> 
                       <void method="put"> 
-                       <string>serialization.format</string> 
-                       <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                       <string>columns.types</string> 
+                       <string>bigint,double</string> 
                       </void> 
                      </object> 
                     </void> 
@@ -277,7 +273,7 @@
                         <void method="add"> 
                          <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Integer</class> 
                             </void> 
@@ -617,7 +613,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive2/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -629,7 +625,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive2/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -685,7 +681,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive2/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -711,7 +707,7 @@
               <void property="conf"> 
                <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                 <void property="dirName"> 
-                 <string>/data/users/njain/hive2/hive/ql/../build/ql/tmp/86661890/270948052.10001.insclause-0</string> 
+                 <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/136189421/655540892.10001.insclause-0</string> 
                 </void> 
                 <void property="tableInfo"> 
                  <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
diff --git a/ql/src/test/results/compiler/plan/groupby3.q.xml b/ql/src/test/results/compiler/plan/groupby3.q.xml
index 21d49527f7..adccd9d949 100644
--- a/ql/src/test/results/compiler/plan/groupby3.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby3.q.xml
@@ -33,7 +33,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -93,7 +93,7 @@
                            <string>1</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Double</class> 
                             </void> 
@@ -146,7 +146,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -157,16 +157,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { double reducesinkvalue0, string reducesinkvalue1, string reducesinkvalue2, string reducesinkvalue3, string reducesinkvalue4}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1,reducesinkvalue2,reducesinkvalue3,reducesinkvalue4</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>double,string,string,string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -336,7 +332,7 @@
                                 <void method="add"> 
                                  <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                                   <void property="typeInfo"> 
-                                   <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                                   <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                     <void property="primitiveClass"> 
                                      <class>java.lang.Integer</class> 
                                     </void> 
@@ -903,7 +899,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive2/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -915,7 +911,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive2/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -971,7 +967,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive2/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -997,7 +993,7 @@
               <void property="conf"> 
                <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                 <void property="dirName"> 
-                 <string>/data/users/njain/hive2/hive/ql/../build/ql/tmp/96733497.10001.insclause-0</string> 
+                 <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/474335337.10001.insclause-0</string> 
                 </void> 
                 <void property="tableInfo"> 
                  <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
diff --git a/ql/src/test/results/compiler/plan/groupby4.q.xml b/ql/src/test/results/compiler/plan/groupby4.q.xml
index 2f1596c01f..9d97eda01b 100644
--- a/ql/src/test/results/compiler/plan/groupby4.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby4.q.xml
@@ -33,7 +33,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -91,7 +91,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -102,16 +102,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { }</string> 
+                           <string>columns</string> 
+                           <string></string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string></string> 
                           </void> 
                          </object> 
                         </void> 
@@ -200,7 +196,7 @@
                         <void method="add"> 
                          <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Integer</class> 
                             </void> 
@@ -363,7 +359,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -375,7 +371,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -431,7 +427,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -457,7 +453,7 @@
               <void property="conf"> 
                <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                 <void property="dirName"> 
-                 <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/57949151.10001.insclause-0</string> 
+                 <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/263052953.10001.insclause-0</string> 
                 </void> 
                 <void property="tableInfo"> 
                  <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
diff --git a/ql/src/test/results/compiler/plan/groupby5.q.xml b/ql/src/test/results/compiler/plan/groupby5.q.xml
index 86b97941bc..89d3a56fee 100644
--- a/ql/src/test/results/compiler/plan/groupby5.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby5.q.xml
@@ -29,7 +29,7 @@
                        <string>0</string> 
                       </void> 
                       <void property="typeInfo"> 
-                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.String</class> 
                         </void> 
@@ -89,7 +89,7 @@
                        <string>1</string> 
                       </void> 
                       <void property="typeInfo"> 
-                       <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.Double</class> 
                         </void> 
@@ -102,7 +102,7 @@
                   <void property="valueSerializeInfo"> 
                    <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                     <void property="deserializerClass"> 
-                     <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                     <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                     </void> 
                     <void property="inputFileFormatClass"> 
                      <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -113,16 +113,12 @@
                     <void property="properties"> 
                      <object class="java.util.Properties"> 
                       <void method="put"> 
-                       <string>name</string> 
-                       <string>binary_table</string> 
-                      </void> 
-                      <void method="put"> 
-                       <string>serialization.ddl</string> 
-                       <string>struct binary_table { double reducesinkvalue0}</string> 
+                       <string>columns</string> 
+                       <string>reducesinkvalue0</string> 
                       </void> 
                       <void method="put"> 
-                       <string>serialization.format</string> 
-                       <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                       <string>columns.types</string> 
+                       <string>double</string> 
                       </void> 
                      </object> 
                     </void> 
@@ -240,7 +236,7 @@
                             <void method="add"> 
                              <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                               <void property="typeInfo"> 
-                               <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.Integer</class> 
                                 </void> 
@@ -385,7 +381,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -397,7 +393,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -453,7 +449,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -479,7 +475,7 @@
               <void property="conf"> 
                <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                 <void property="dirName"> 
-                 <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/979288592/53411655.10001.insclause-0</string> 
+                 <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/300356380/322347891.10001.insclause-0</string> 
                 </void> 
                 <void property="tableInfo"> 
                  <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
diff --git a/ql/src/test/results/compiler/plan/groupby6.q.xml b/ql/src/test/results/compiler/plan/groupby6.q.xml
index 9f7fd30fb5..c5de6092f4 100644
--- a/ql/src/test/results/compiler/plan/groupby6.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby6.q.xml
@@ -33,7 +33,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -91,7 +91,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -102,16 +102,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { }</string> 
+                           <string>columns</string> 
+                           <string></string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string></string> 
                           </void> 
                          </object> 
                         </void> 
@@ -200,7 +196,7 @@
                         <void method="add"> 
                          <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Integer</class> 
                             </void> 
@@ -363,7 +359,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -375,7 +371,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -431,7 +427,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -457,7 +453,7 @@
               <void property="conf"> 
                <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                 <void property="dirName"> 
-                 <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/272705795.10001.insclause-0</string> 
+                 <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/19708182.10001.insclause-0</string> 
                 </void> 
                 <void property="tableInfo"> 
                  <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
diff --git a/ql/src/test/results/compiler/plan/input1.q.xml b/ql/src/test/results/compiler/plan/input1.q.xml
index cb3658d631..f3e45552f3 100755
--- a/ql/src/test/results/compiler/plan/input1.q.xml
+++ b/ql/src/test/results/compiler/plan/input1.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/381187180/535792190.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/685032521/170074575.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -131,7 +131,7 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/381187180/535792190.10000.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/685032521/170074575.10000.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc0"/> 
@@ -158,7 +158,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -285,7 +285,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Double</class> 
                       </void> 
@@ -313,7 +313,7 @@
                       <void method="add"> 
                        <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                         <void property="typeInfo"> 
-                         <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Integer</class> 
                           </void> 
@@ -334,7 +334,7 @@
                  </object> 
                 </void> 
                 <void property="typeInfo"> 
-                 <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                 <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                   <void property="primitiveClass"> 
                    <class>java.lang.Boolean</class> 
                   </void> 
@@ -403,7 +403,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -415,7 +415,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -471,7 +471,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/input2.q.xml b/ql/src/test/results/compiler/plan/input2.q.xml
index 4214fb0744..009fd1b0d0 100755
--- a/ql/src/test/results/compiler/plan/input2.q.xml
+++ b/ql/src/test/results/compiler/plan/input2.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/681854335/165687308.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/293273344/128845477.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -104,7 +104,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/681854335/165687308.10001.insclause-1</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/293273344/128845477.10001.insclause-1</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -157,7 +157,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest2</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest2</string> 
                 </void> 
                </object> 
               </void> 
@@ -186,7 +186,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/681854335/165687308.10002.insclause-2</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/293273344/128845477.10002.insclause-2</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -243,7 +243,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest3</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest3</string> 
                 </void> 
                </object> 
               </void> 
@@ -290,7 +290,7 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/681854335/165687308.10000.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/293273344/128845477.10000.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc0"/> 
@@ -317,7 +317,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -447,7 +447,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Double</class> 
                       </void> 
@@ -475,7 +475,7 @@
                       <void method="add"> 
                        <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Integer</class> 
                           </void> 
@@ -496,7 +496,7 @@
                  </object> 
                 </void> 
                 <void property="typeInfo"> 
-                 <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                 <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                   <void property="primitiveClass"> 
                    <class>java.lang.Boolean</class> 
                   </void> 
@@ -562,7 +562,7 @@
                        <int>2</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/681854335/165687308.10001.insclause-1</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/293273344/128845477.10001.insclause-1</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc1"/> 
@@ -916,7 +916,7 @@
                        <int>3</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/681854335/165687308.10002.insclause-2</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/293273344/128845477.10002.insclause-2</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc2"/> 
@@ -1151,7 +1151,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -1163,7 +1163,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -1219,7 +1219,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/input20.q.xml b/ql/src/test/results/compiler/plan/input20.q.xml
index 199ac096f0..997fb05c23 100644
--- a/ql/src/test/results/compiler/plan/input20.q.xml
+++ b/ql/src/test/results/compiler/plan/input20.q.xml
@@ -37,7 +37,7 @@
                                <string>key</string> 
                               </void> 
                               <void property="typeInfo"> 
-                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.String</class> 
                                 </void> 
@@ -127,7 +127,7 @@
                           <void property="valueSerializeInfo"> 
                            <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                             <void property="deserializerClass"> 
-                             <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                             <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                             </void> 
                             <void property="inputFileFormatClass"> 
                              <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -138,16 +138,12 @@
                             <void property="properties"> 
                              <object class="java.util.Properties"> 
                               <void method="put"> 
-                               <string>name</string> 
-                               <string>binary_table</string> 
-                              </void> 
-                              <void method="put"> 
-                               <string>serialization.ddl</string> 
-                               <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                               <string>columns</string> 
+                               <string>reducesinkvalue0,reducesinkvalue1</string> 
                               </void> 
                               <void method="put"> 
-                               <string>serialization.format</string> 
-                               <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                               <string>columns.types</string> 
+                               <string>string,string</string> 
                               </void> 
                              </object> 
                             </void> 
@@ -333,7 +329,7 @@
                            </object> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Double</class> 
                             </void> 
@@ -361,7 +357,7 @@
                             <void method="add"> 
                              <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                               <void property="typeInfo"> 
-                               <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.Integer</class> 
                                 </void> 
@@ -621,7 +617,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>tmap:src</string> 
@@ -633,7 +629,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -689,7 +685,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -719,7 +715,7 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/1576892419.10001.insclause-0</string> 
+                     <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/47727235.10001.insclause-0</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
diff --git a/ql/src/test/results/compiler/plan/input3.q.xml b/ql/src/test/results/compiler/plan/input3.q.xml
index 41de0cc5ef..2a44d54490 100755
--- a/ql/src/test/results/compiler/plan/input3.q.xml
+++ b/ql/src/test/results/compiler/plan/input3.q.xml
@@ -28,7 +28,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/398532315/183057132.10003.insclause-3</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/653439832/118684271.10003.insclause-3</string> 
             </void> 
             <void property="targetDir"> 
              <string>../../../../build/contrib/hive/ql/test/data/warehouse/dest4.out</string> 
@@ -48,7 +48,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/398532315/183057132.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/653439832/118684271.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -101,7 +101,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -121,7 +121,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/398532315/183057132.10001.insclause-1</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/653439832/118684271.10001.insclause-1</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -174,7 +174,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest2</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest2</string> 
                 </void> 
                </object> 
               </void> 
@@ -203,7 +203,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/398532315/183057132.10002.insclause-2</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/653439832/118684271.10002.insclause-2</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -260,7 +260,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest3</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest3</string> 
                 </void> 
                </object> 
               </void> 
@@ -307,7 +307,7 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/398532315/183057132.10000.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/653439832/118684271.10000.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc0"/> 
@@ -334,7 +334,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -464,7 +464,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Double</class> 
                       </void> 
@@ -492,7 +492,7 @@
                       <void method="add"> 
                        <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Integer</class> 
                           </void> 
@@ -513,7 +513,7 @@
                  </object> 
                 </void> 
                 <void property="typeInfo"> 
-                 <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                 <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                   <void property="primitiveClass"> 
                    <class>java.lang.Boolean</class> 
                   </void> 
@@ -579,7 +579,7 @@
                        <int>2</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/398532315/183057132.10001.insclause-1</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/653439832/118684271.10001.insclause-1</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc1"/> 
@@ -933,7 +933,7 @@
                        <int>3</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/398532315/183057132.10002.insclause-2</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/653439832/118684271.10002.insclause-2</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc2"/> 
@@ -1287,7 +1287,7 @@
                        <int>4</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/398532315/183057132.10003.insclause-3</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/653439832/118684271.10003.insclause-3</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -1524,7 +1524,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -1536,7 +1536,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -1592,7 +1592,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/input4.q.xml b/ql/src/test/results/compiler/plan/input4.q.xml
index 5aad7b5187..a28735e446 100755
--- a/ql/src/test/results/compiler/plan/input4.q.xml
+++ b/ql/src/test/results/compiler/plan/input4.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/75486369/68136209.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/1132769434/128028494.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -135,7 +135,7 @@
                            <string>tkey</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -225,7 +225,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -236,16 +236,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -487,7 +483,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>tmap:src</string> 
@@ -499,7 +495,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -555,7 +551,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -588,7 +584,7 @@
                      <int>1</int> 
                     </void> 
                     <void property="dirName"> 
-                     <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/75486369/68136209.10000.insclause-0</string> 
+                     <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/1132769434/128028494.10000.insclause-0</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object idref="tableDesc0"/> 
@@ -738,7 +734,7 @@
                    </object> 
                   </void> 
                   <void property="typeInfo"> 
-                   <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                   <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                     <void property="primitiveClass"> 
                      <class>java.lang.Double</class> 
                     </void> 
@@ -766,7 +762,7 @@
                     <void method="add"> 
                      <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                       <void property="typeInfo"> 
-                       <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.Integer</class> 
                         </void> 
@@ -787,7 +783,7 @@
                </object> 
               </void> 
               <void property="typeInfo"> 
-               <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+               <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                 <void property="primitiveClass"> 
                  <class>java.lang.Boolean</class> 
                 </void> 
diff --git a/ql/src/test/results/compiler/plan/input5.q.xml b/ql/src/test/results/compiler/plan/input5.q.xml
index 7671de4e48..004ac28d77 100644
--- a/ql/src/test/results/compiler/plan/input5.q.xml
+++ b/ql/src/test/results/compiler/plan/input5.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/674332792.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/464639314.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -139,7 +139,7 @@
                                <string>tkey</string> 
                               </void> 
                               <void property="typeInfo"> 
-                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.String</class> 
                                 </void> 
@@ -229,7 +229,7 @@
                           <void property="valueSerializeInfo"> 
                            <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                             <void property="deserializerClass"> 
-                             <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                             <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                             </void> 
                             <void property="inputFileFormatClass"> 
                              <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -240,16 +240,12 @@
                             <void property="properties"> 
                              <object class="java.util.Properties"> 
                               <void method="put"> 
-                               <string>name</string> 
-                               <string>binary_table</string> 
-                              </void> 
-                              <void method="put"> 
-                               <string>serialization.ddl</string> 
-                               <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                               <string>columns</string> 
+                               <string>reducesinkvalue0,reducesinkvalue1</string> 
                               </void> 
                               <void method="put"> 
-                               <string>serialization.format</string> 
-                               <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                               <string>columns.types</string> 
+                               <string>string,string</string> 
                               </void> 
                              </object> 
                             </void> 
@@ -387,9 +383,9 @@
                        <string>0</string> 
                       </void> 
                       <void property="typeInfo"> 
-                       <object id="ListTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+                       <object id="ListTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                         <void property="listElementTypeInfo"> 
-                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Integer</class> 
                           </void> 
@@ -405,9 +401,9 @@
                        <string>1</string> 
                       </void> 
                       <void property="typeInfo"> 
-                       <object id="ListTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+                       <object id="ListTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                         <void property="listElementTypeInfo"> 
-                         <object class="org.apache.hadoop.hive.ql.typeinfo.StructTypeInfo"/> 
+                         <object class="org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo"/> 
                         </void> 
                        </object> 
                       </void> 
@@ -572,7 +568,7 @@
                <string>lstring</string> 
               </void> 
               <void property="type"> 
-               <object class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+               <object class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                 <void property="listElementTypeInfo"> 
                  <object idref="PrimitiveTypeInfo0"/> 
                 </void> 
@@ -596,7 +592,7 @@
                <string>mstringstring</string> 
               </void> 
               <void property="type"> 
-               <object class="org.apache.hadoop.hive.ql.typeinfo.MapTypeInfo"> 
+               <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
                 <void property="mapKeyTypeInfo"> 
                  <object idref="PrimitiveTypeInfo0"/> 
                 </void> 
@@ -624,7 +620,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>tmap:src_thrift</string> 
@@ -636,7 +632,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -696,7 +692,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
             </void> 
            </object> 
           </void> 
@@ -725,7 +721,7 @@
                  <int>1</int> 
                 </void> 
                 <void property="dirName"> 
-                 <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/674332792.10000.insclause-0</string> 
+                 <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/464639314.10000.insclause-0</string> 
                 </void> 
                 <void property="tableInfo"> 
                  <object idref="tableDesc0"/> 
diff --git a/ql/src/test/results/compiler/plan/input6.q.xml b/ql/src/test/results/compiler/plan/input6.q.xml
index 689f5bd058..4d5f49c138 100644
--- a/ql/src/test/results/compiler/plan/input6.q.xml
+++ b/ql/src/test/results/compiler/plan/input6.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/12967886/673104914.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/914303434/523506981.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -131,7 +131,7 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/12967886/673104914.10000.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/914303434/523506981.10000.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc0"/> 
@@ -158,7 +158,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -265,7 +265,7 @@
                  </object> 
                 </void> 
                 <void property="typeInfo"> 
-                 <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                 <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                   <void property="primitiveClass"> 
                    <class>java.lang.Boolean</class> 
                   </void> 
@@ -334,7 +334,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src1</string> 
@@ -346,7 +346,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -402,7 +402,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/input7.q.xml b/ql/src/test/results/compiler/plan/input7.q.xml
index 466e79ac83..002724b608 100644
--- a/ql/src/test/results/compiler/plan/input7.q.xml
+++ b/ql/src/test/results/compiler/plan/input7.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/368968382.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/497726600.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -131,7 +131,7 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/368968382.10000.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/497726600.10000.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc0"/> 
@@ -158,7 +158,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Void</class> 
                             </void> 
@@ -172,7 +172,7 @@
                            <string>1</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -322,7 +322,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src1</string> 
@@ -334,7 +334,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -390,7 +390,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/input8.q.xml b/ql/src/test/results/compiler/plan/input8.q.xml
index c191e08cde..7c08d92b2e 100644
--- a/ql/src/test/results/compiler/plan/input8.q.xml
+++ b/ql/src/test/results/compiler/plan/input8.q.xml
@@ -26,7 +26,7 @@
                     <void property="conf"> 
                      <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/158610613.10001.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/146597259.10001.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -75,7 +75,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Double</class> 
                             </void> 
@@ -155,7 +155,7 @@
                             <void method="add"> 
                              <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                               <void property="typeInfo"> 
-                               <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.Integer</class> 
                                 </void> 
@@ -230,7 +230,7 @@
                                <string>0</string> 
                               </void> 
                               <void property="typeInfo"> 
-                               <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.String</class> 
                                 </void> 
@@ -413,7 +413,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src1</string> 
@@ -425,7 +425,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -481,7 +481,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/input9.q.xml b/ql/src/test/results/compiler/plan/input9.q.xml
index b0617b087b..4db31a44f5 100644
--- a/ql/src/test/results/compiler/plan/input9.q.xml
+++ b/ql/src/test/results/compiler/plan/input9.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/379753258.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/598599562.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -135,7 +135,7 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/379753258.10000.insclause-0</string> 
+                           <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/598599562.10000.insclause-0</string> 
                           </void> 
                           <void property="tableInfo"> 
                            <object idref="tableDesc0"/> 
@@ -162,7 +162,7 @@
                                <string>0</string> 
                               </void> 
                               <void property="type"> 
-                               <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.Void</class> 
                                 </void> 
@@ -176,7 +176,7 @@
                                <string>1</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.String</class> 
                                 </void> 
@@ -263,7 +263,7 @@
                       <void method="add"> 
                        <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Double</class> 
                           </void> 
@@ -281,7 +281,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Boolean</class> 
                       </void> 
@@ -400,7 +400,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src1</string> 
@@ -412,7 +412,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -468,7 +468,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src1</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src1</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/input_part1.q.xml b/ql/src/test/results/compiler/plan/input_part1.q.xml
index 98c92f9da5..c1e25f80f2 100644
--- a/ql/src/test/results/compiler/plan/input_part1.q.xml
+++ b/ql/src/test/results/compiler/plan/input_part1.q.xml
@@ -26,7 +26,7 @@
                     <void property="conf"> 
                      <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/1260276323/87357426.10001.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/111994731/468397088.10001.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -75,7 +75,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -282,7 +282,7 @@
                              </object> 
                             </void> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Double</class> 
                               </void> 
@@ -310,7 +310,7 @@
                               <void method="add"> 
                                <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                                 <void property="typeInfo"> 
-                                 <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                                 <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                   <void property="primitiveClass"> 
                                    <class>java.lang.Integer</class> 
                                   </void> 
@@ -331,7 +331,7 @@
                          </object> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Boolean</class> 
                           </void> 
@@ -528,7 +528,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>srcpart</string> 
@@ -540,7 +540,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=12/ds=2008-04-08</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"> 
@@ -609,7 +609,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcpart</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml b/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
index cd55e0cec8..3f20725a5f 100644
--- a/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
+++ b/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/88106625/3398743.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/1357142888/674272481.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest4_sequencefile</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest4_sequencefile</string> 
                 </void> 
                </object> 
               </void> 
@@ -127,7 +127,7 @@
                    <int>1</int> 
                   </void> 
                   <void property="dirName"> 
-                   <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/88106625/3398743.10000.insclause-0</string> 
+                   <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/1357142888/674272481.10000.insclause-0</string> 
                   </void> 
                   <void property="tableInfo"> 
                    <object idref="tableDesc0"/> 
@@ -154,7 +154,7 @@
                        <string>0</string> 
                       </void> 
                       <void property="type"> 
-                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.String</class> 
                         </void> 
@@ -267,7 +267,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -279,7 +279,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -335,7 +335,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/input_testxpath.q.xml b/ql/src/test/results/compiler/plan/input_testxpath.q.xml
index 37345ea022..ca5e013193 100644
--- a/ql/src/test/results/compiler/plan/input_testxpath.q.xml
+++ b/ql/src/test/results/compiler/plan/input_testxpath.q.xml
@@ -26,7 +26,7 @@
                     <void property="conf"> 
                      <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/226690002.10001.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/882645160.10001.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -75,7 +75,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Integer</class> 
                             </void> 
@@ -89,7 +89,7 @@
                            <string>1</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -127,7 +127,7 @@
                          <string>0</string> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="ListTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+                         <object id="ListTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                           <void property="listElementTypeInfo"> 
                            <object idref="PrimitiveTypeInfo0"/> 
                           </void> 
@@ -160,9 +160,9 @@
                            <string>1</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="ListTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+                           <object id="ListTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                             <void property="listElementTypeInfo"> 
-                             <object id="StructTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.StructTypeInfo"/> 
+                             <object id="StructTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo"/> 
                             </void> 
                            </object> 
                           </void> 
@@ -202,7 +202,7 @@
                          <string>2</string> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="MapTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.MapTypeInfo"> 
+                         <object id="MapTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
                           <void property="mapKeyTypeInfo"> 
                            <object idref="PrimitiveTypeInfo1"/> 
                           </void> 
@@ -386,7 +386,7 @@
                <string>lstring</string> 
               </void> 
               <void property="type"> 
-               <object class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+               <object class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                 <void property="listElementTypeInfo"> 
                  <object idref="PrimitiveTypeInfo1"/> 
                 </void> 
@@ -425,7 +425,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src_thrift</string> 
@@ -437,7 +437,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -497,7 +497,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/input_testxpath2.q.xml b/ql/src/test/results/compiler/plan/input_testxpath2.q.xml
index 995a850c05..1c0be4d08e 100644
--- a/ql/src/test/results/compiler/plan/input_testxpath2.q.xml
+++ b/ql/src/test/results/compiler/plan/input_testxpath2.q.xml
@@ -30,7 +30,7 @@
                         <void property="conf"> 
                          <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                           <void property="dirName"> 
-                           <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/586486000.10001.insclause-0</string> 
+                           <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/336000718.10001.insclause-0</string> 
                           </void> 
                           <void property="tableInfo"> 
                            <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -79,7 +79,7 @@
                                <string>0</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.Integer</class> 
                                 </void> 
@@ -142,7 +142,7 @@
                                <string>0</string> 
                               </void> 
                               <void property="typeInfo"> 
-                               <object id="ListTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+                               <object id="ListTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                                 <void property="listElementTypeInfo"> 
                                  <object idref="PrimitiveTypeInfo0"/> 
                                 </void> 
@@ -180,9 +180,9 @@
                                <string>1</string> 
                               </void> 
                               <void property="typeInfo"> 
-                               <object id="ListTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+                               <object id="ListTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                                 <void property="listElementTypeInfo"> 
-                                 <object class="org.apache.hadoop.hive.ql.typeinfo.StructTypeInfo"/> 
+                                 <object class="org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo"/> 
                                 </void> 
                                </object> 
                               </void> 
@@ -218,9 +218,9 @@
                                <string>2</string> 
                               </void> 
                               <void property="typeInfo"> 
-                               <object id="MapTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.MapTypeInfo"> 
+                               <object id="MapTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
                                 <void property="mapKeyTypeInfo"> 
-                                 <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                                 <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                   <void property="primitiveClass"> 
                                    <class>java.lang.String</class> 
                                   </void> 
@@ -317,7 +317,7 @@
                          </object> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Boolean</class> 
                           </void> 
@@ -546,7 +546,7 @@
                <string>lstring</string> 
               </void> 
               <void property="type"> 
-               <object class="org.apache.hadoop.hive.ql.typeinfo.ListTypeInfo"> 
+               <object class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                 <void property="listElementTypeInfo"> 
                  <object idref="PrimitiveTypeInfo1"/> 
                 </void> 
@@ -585,7 +585,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src_thrift</string> 
@@ -597,7 +597,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -657,7 +657,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src_thrift</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src_thrift</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/join1.q.xml b/ql/src/test/results/compiler/plan/join1.q.xml
index ea84bf2954..84e3b0fe04 100644
--- a/ql/src/test/results/compiler/plan/join1.q.xml
+++ b/ql/src/test/results/compiler/plan/join1.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/272699686.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/328753767.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -127,7 +127,7 @@
                    <string>key</string> 
                   </void> 
                   <void property="typeInfo"> 
-                   <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                   <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                     <void property="primitiveClass"> 
                      <class>java.lang.String</class> 
                     </void> 
@@ -206,7 +206,7 @@
               <void property="valueSerializeInfo"> 
                <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                 <void property="deserializerClass"> 
-                 <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                 <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                 </void> 
                 <void property="inputFileFormatClass"> 
                  <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -217,16 +217,12 @@
                 <void property="properties"> 
                  <object class="java.util.Properties"> 
                   <void method="put"> 
-                   <string>name</string> 
-                   <string>binary_table</string> 
-                  </void> 
-                  <void method="put"> 
-                   <string>serialization.ddl</string> 
-                   <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                   <string>columns</string> 
+                   <string>reducesinkvalue0,reducesinkvalue1</string> 
                   </void> 
                   <void method="put"> 
-                   <string>serialization.format</string> 
-                   <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                   <string>columns.types</string> 
+                   <string>string,string</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -392,7 +388,7 @@
                   <void property="valueSerializeInfo"> 
                    <object id="tableDesc3" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                     <void property="deserializerClass"> 
-                     <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                     <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                     </void> 
                     <void property="inputFileFormatClass"> 
                      <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -403,16 +399,12 @@
                     <void property="properties"> 
                      <object class="java.util.Properties"> 
                       <void method="put"> 
-                       <string>name</string> 
-                       <string>binary_table</string> 
-                      </void> 
-                      <void method="put"> 
-                       <string>serialization.ddl</string> 
-                       <string>struct binary_table { string reducesinkvalue0}</string> 
+                       <string>columns</string> 
+                       <string>reducesinkvalue0</string> 
                       </void> 
                       <void method="put"> 
-                       <string>serialization.format</string> 
-                       <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                       <string>columns.types</string> 
+                       <string>string</string> 
                       </void> 
                      </object> 
                     </void> 
@@ -549,7 +541,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src2</string> 
@@ -564,7 +556,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -620,7 +612,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -649,7 +641,7 @@
                  <int>1</int> 
                 </void> 
                 <void property="dirName"> 
-                 <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/272699686.10000.insclause-0</string> 
+                 <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/328753767.10000.insclause-0</string> 
                 </void> 
                 <void property="tableInfo"> 
                  <object idref="tableDesc0"/> 
diff --git a/ql/src/test/results/compiler/plan/join2.q.xml b/ql/src/test/results/compiler/plan/join2.q.xml
index b92924704b..fdfc98db66 100644
--- a/ql/src/test/results/compiler/plan/join2.q.xml
+++ b/ql/src/test/results/compiler/plan/join2.q.xml
@@ -35,7 +35,7 @@
                  <boolean>true</boolean> 
                 </void> 
                 <void property="sourceDir"> 
-                 <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/941692599.10000.insclause-0</string> 
+                 <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/94793090.10000.insclause-0</string> 
                 </void> 
                 <void property="table"> 
                  <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -88,7 +88,7 @@
                     </void> 
                     <void method="put"> 
                      <string>location</string> 
-                     <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                     <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                     </void> 
                    </object> 
                   </void> 
@@ -155,7 +155,7 @@
                            <string>key</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -166,7 +166,7 @@
                        </object> 
                       </void> 
                       <void property="typeInfo"> 
-                       <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.Double</class> 
                         </void> 
@@ -245,7 +245,7 @@
                   <void property="valueSerializeInfo"> 
                    <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                     <void property="deserializerClass"> 
-                     <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                     <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                     </void> 
                     <void property="inputFileFormatClass"> 
                      <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -256,16 +256,12 @@
                     <void property="properties"> 
                      <object class="java.util.Properties"> 
                       <void method="put"> 
-                       <string>name</string> 
-                       <string>binary_table</string> 
+                       <string>columns</string> 
+                       <string>reducesinkvalue0,reducesinkvalue1</string> 
                       </void> 
                       <void method="put"> 
-                       <string>serialization.ddl</string> 
-                       <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
-                      </void> 
-                      <void method="put"> 
-                       <string>serialization.format</string> 
-                       <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                       <string>columns.types</string> 
+                       <string>string,string</string> 
                       </void> 
                      </object> 
                     </void> 
@@ -518,7 +514,7 @@
               <void property="valueSerializeInfo"> 
                <object id="tableDesc3" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                 <void property="deserializerClass"> 
-                 <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                 <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                 </void> 
                 <void property="inputFileFormatClass"> 
                  <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -529,16 +525,12 @@
                 <void property="properties"> 
                  <object class="java.util.Properties"> 
                   <void method="put"> 
-                   <string>name</string> 
-                   <string>binary_table</string> 
+                   <string>columns</string> 
+                   <string>reducesinkvalue0,reducesinkvalue1</string> 
                   </void> 
                   <void method="put"> 
-                   <string>serialization.ddl</string> 
-                   <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
-                  </void> 
-                  <void method="put"> 
-                   <string>serialization.format</string> 
-                   <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                   <string>columns.types</string> 
+                   <string>string,string</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -560,7 +552,7 @@
                     <void property="conf"> 
                      <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/build/ql/tmp/184397894/401816724.10001</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/94806813/1222150108.10001</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object id="tableDesc4" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -763,7 +755,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc6" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -774,16 +766,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -991,7 +979,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc7" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -1002,16 +990,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0}</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1195,7 +1179,7 @@
         <void property="pathToAliases"> 
          <object class="java.util.LinkedHashMap"> 
           <void method="put"> 
-           <string>/data/users/njain/hive1/hive/build/ql/tmp/184397894/401816724.10001</string> 
+           <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/94806813/1222150108.10001</string> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <string>$INTNAME</string> 
@@ -1203,7 +1187,7 @@
            </object> 
           </void> 
           <void method="put"> 
-           <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+           <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <string>src3</string> 
@@ -1215,7 +1199,7 @@
         <void property="pathToPartitionInfo"> 
          <object class="java.util.LinkedHashMap"> 
           <void method="put"> 
-           <string>/data/users/njain/hive1/hive/build/ql/tmp/184397894/401816724.10001</string> 
+           <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/tmp/94806813/1222150108.10001</string> 
            <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
             <void property="tableDesc"> 
              <object idref="tableDesc4"/> 
@@ -1223,7 +1207,7 @@
            </object> 
           </void> 
           <void method="put"> 
-           <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+           <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
            <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
             <void property="partSpec"> 
              <object class="java.util.LinkedHashMap"/> 
@@ -1279,7 +1263,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
                 </void> 
                </object> 
               </void> 
@@ -1308,7 +1292,7 @@
                      <int>1</int> 
                     </void> 
                     <void property="dirName"> 
-                     <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/941692599.10000.insclause-0</string> 
+                     <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/94793090.10000.insclause-0</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object idref="tableDesc0"/> 
@@ -1583,7 +1567,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src2</string> 
@@ -1598,7 +1582,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -1654,7 +1638,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/join3.q.xml b/ql/src/test/results/compiler/plan/join3.q.xml
index 5ce71b4d3a..7f90e78010 100644
--- a/ql/src/test/results/compiler/plan/join3.q.xml
+++ b/ql/src/test/results/compiler/plan/join3.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/1517829764.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/446143495.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -131,7 +131,7 @@
                        <string>0</string> 
                       </void> 
                       <void property="typeInfo"> 
-                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.String</class> 
                         </void> 
@@ -200,7 +200,7 @@
                   <void property="valueSerializeInfo"> 
                    <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                     <void property="deserializerClass"> 
-                     <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                     <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                     </void> 
                     <void property="inputFileFormatClass"> 
                      <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -211,16 +211,12 @@
                     <void property="properties"> 
                      <object class="java.util.Properties"> 
                       <void method="put"> 
-                       <string>name</string> 
-                       <string>binary_table</string> 
+                       <string>columns</string> 
+                       <string>reducesinkvalue0</string> 
                       </void> 
                       <void method="put"> 
-                       <string>serialization.ddl</string> 
-                       <string>struct binary_table { string reducesinkvalue0}</string> 
-                      </void> 
-                      <void method="put"> 
-                       <string>serialization.format</string> 
-                       <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                       <string>columns.types</string> 
+                       <string>string</string> 
                       </void> 
                      </object> 
                     </void> 
@@ -435,7 +431,7 @@
               <void property="valueSerializeInfo"> 
                <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                 <void property="deserializerClass"> 
-                 <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                 <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                 </void> 
                 <void property="inputFileFormatClass"> 
                  <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -446,16 +442,12 @@
                 <void property="properties"> 
                  <object class="java.util.Properties"> 
                   <void method="put"> 
-                   <string>name</string> 
-                   <string>binary_table</string> 
-                  </void> 
-                  <void method="put"> 
-                   <string>serialization.ddl</string> 
-                   <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                   <string>columns</string> 
+                   <string>reducesinkvalue0,reducesinkvalue1</string> 
                   </void> 
                   <void method="put"> 
-                   <string>serialization.format</string> 
-                   <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                   <string>columns.types</string> 
+                   <string>string,string</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -621,7 +613,7 @@
                   <void property="valueSerializeInfo"> 
                    <object id="tableDesc4" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                     <void property="deserializerClass"> 
-                     <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                     <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                     </void> 
                     <void property="inputFileFormatClass"> 
                      <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -632,16 +624,12 @@
                     <void property="properties"> 
                      <object class="java.util.Properties"> 
                       <void method="put"> 
-                       <string>name</string> 
-                       <string>binary_table</string> 
+                       <string>columns</string> 
+                       <string>reducesinkvalue0</string> 
                       </void> 
                       <void method="put"> 
-                       <string>serialization.ddl</string> 
-                       <string>struct binary_table { string reducesinkvalue0}</string> 
-                      </void> 
-                      <void method="put"> 
-                       <string>serialization.format</string> 
-                       <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                       <string>columns.types</string> 
+                       <string>string</string> 
                       </void> 
                      </object> 
                     </void> 
@@ -778,7 +766,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src2</string> 
@@ -796,7 +784,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -852,7 +840,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -881,7 +869,7 @@
                  <int>1</int> 
                 </void> 
                 <void property="dirName"> 
-                 <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/1517829764.10000.insclause-0</string> 
+                 <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/446143495.10000.insclause-0</string> 
                 </void> 
                 <void property="tableInfo"> 
                  <object idref="tableDesc0"/> 
diff --git a/ql/src/test/results/compiler/plan/join4.q.xml b/ql/src/test/results/compiler/plan/join4.q.xml
index 495520dde7..75f1e205d5 100644
--- a/ql/src/test/results/compiler/plan/join4.q.xml
+++ b/ql/src/test/results/compiler/plan/join4.q.xml
@@ -33,7 +33,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -112,7 +112,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -123,16 +123,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -324,7 +320,7 @@
                          </object> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Double</class> 
                           </void> 
@@ -352,7 +348,7 @@
                           <void method="add"> 
                            <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Integer</class> 
                               </void> 
@@ -373,7 +369,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Boolean</class> 
                       </void> 
@@ -636,7 +632,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -647,16 +643,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1065,7 +1057,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1080,7 +1072,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -1136,7 +1128,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -1166,7 +1158,7 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/58057286/297438101.10001.insclause-0</string> 
+                     <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/613794445/340050966.10001.insclause-0</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
diff --git a/ql/src/test/results/compiler/plan/join5.q.xml b/ql/src/test/results/compiler/plan/join5.q.xml
index 530fe2b67e..e147306c03 100644
--- a/ql/src/test/results/compiler/plan/join5.q.xml
+++ b/ql/src/test/results/compiler/plan/join5.q.xml
@@ -33,7 +33,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -112,7 +112,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -123,16 +123,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -324,7 +320,7 @@
                          </object> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Double</class> 
                           </void> 
@@ -352,7 +348,7 @@
                           <void method="add"> 
                            <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Integer</class> 
                               </void> 
@@ -373,7 +369,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Boolean</class> 
                       </void> 
@@ -636,7 +632,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -647,16 +643,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1065,7 +1057,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1080,7 +1072,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -1136,7 +1128,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -1166,7 +1158,7 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/155967095/309101621.10001.insclause-0</string> 
+                     <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/8270598/757172805.10001.insclause-0</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
diff --git a/ql/src/test/results/compiler/plan/join6.q.xml b/ql/src/test/results/compiler/plan/join6.q.xml
index 91df3b3f6c..2fbd078143 100644
--- a/ql/src/test/results/compiler/plan/join6.q.xml
+++ b/ql/src/test/results/compiler/plan/join6.q.xml
@@ -33,7 +33,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -112,7 +112,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -123,16 +123,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -324,7 +320,7 @@
                          </object> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Double</class> 
                           </void> 
@@ -352,7 +348,7 @@
                           <void method="add"> 
                            <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Integer</class> 
                               </void> 
@@ -373,7 +369,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Boolean</class> 
                       </void> 
@@ -636,7 +632,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -647,16 +643,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1065,7 +1057,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1080,7 +1072,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -1136,7 +1128,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -1166,7 +1158,7 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/510290766/36796370.10001.insclause-0</string> 
+                     <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/264525044/485431796.10001.insclause-0</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
diff --git a/ql/src/test/results/compiler/plan/join7.q.xml b/ql/src/test/results/compiler/plan/join7.q.xml
index 9b582f0e5e..7375c272ab 100644
--- a/ql/src/test/results/compiler/plan/join7.q.xml
+++ b/ql/src/test/results/compiler/plan/join7.q.xml
@@ -33,7 +33,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -112,7 +112,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -123,16 +123,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -324,7 +320,7 @@
                          </object> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Double</class> 
                           </void> 
@@ -352,7 +348,7 @@
                           <void method="add"> 
                            <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Integer</class> 
                               </void> 
@@ -373,7 +369,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Boolean</class> 
                       </void> 
@@ -636,7 +632,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -647,16 +643,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1151,7 +1143,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc3" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -1162,16 +1154,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1580,7 +1568,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1598,7 +1586,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -1654,7 +1642,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -1684,7 +1672,7 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/1828040/2977146.10001.insclause-0</string> 
+                     <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/38218356/606851787.10001.insclause-0</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
diff --git a/ql/src/test/results/compiler/plan/join8.q.xml b/ql/src/test/results/compiler/plan/join8.q.xml
index f129c045a4..52390e7bd6 100644
--- a/ql/src/test/results/compiler/plan/join8.q.xml
+++ b/ql/src/test/results/compiler/plan/join8.q.xml
@@ -33,7 +33,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="typeInfo"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -112,7 +112,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc1" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -123,16 +123,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -324,7 +320,7 @@
                          </object> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Double</class> 
                           </void> 
@@ -352,7 +348,7 @@
                           <void method="add"> 
                            <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Integer</class> 
                               </void> 
@@ -373,7 +369,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Boolean</class> 
                       </void> 
@@ -636,7 +632,7 @@
                       <void property="valueSerializeInfo"> 
                        <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
                         <void property="deserializerClass"> 
-                         <class>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</class> 
+                         <class>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</class> 
                         </void> 
                         <void property="inputFileFormatClass"> 
                          <class>org.apache.hadoop.mapred.SequenceFileInputFormat</class> 
@@ -647,16 +643,12 @@
                         <void property="properties"> 
                          <object class="java.util.Properties"> 
                           <void method="put"> 
-                           <string>name</string> 
-                           <string>binary_table</string> 
-                          </void> 
-                          <void method="put"> 
-                           <string>serialization.ddl</string> 
-                           <string>struct binary_table { string reducesinkvalue0, string reducesinkvalue1}</string> 
+                           <string>columns</string> 
+                           <string>reducesinkvalue0,reducesinkvalue1</string> 
                           </void> 
                           <void method="put"> 
-                           <string>serialization.format</string> 
-                           <string>com.facebook.thrift.protocol.TBinaryProtocol</string> 
+                           <string>columns.types</string> 
+                           <string>string,string</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1065,7 +1057,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1080,7 +1072,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -1136,7 +1128,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
@@ -1170,7 +1162,7 @@
                       <void property="conf"> 
                        <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                         <void property="dirName"> 
-                         <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/283039679/214129911.10001.insclause-0</string> 
+                         <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/499436361/141218703.10001.insclause-0</string> 
                         </void> 
                         <void property="tableInfo"> 
                          <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
diff --git a/ql/src/test/results/compiler/plan/sample1.q.xml b/ql/src/test/results/compiler/plan/sample1.q.xml
index c886f84d23..114300f6a9 100644
--- a/ql/src/test/results/compiler/plan/sample1.q.xml
+++ b/ql/src/test/results/compiler/plan/sample1.q.xml
@@ -30,7 +30,7 @@
                         <void property="conf"> 
                          <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                           <void property="dirName"> 
-                           <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/128865599/7453289.10001.insclause-0</string> 
+                           <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/8910670/580142077.10001.insclause-0</string> 
                           </void> 
                           <void property="tableInfo"> 
                            <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -79,7 +79,7 @@
                                <string>0</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.String</class> 
                                 </void> 
@@ -262,7 +262,7 @@
                          </object> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Boolean</class> 
                           </void> 
@@ -482,7 +482,7 @@
                                  <object class="java.util.ArrayList"/> 
                                 </void> 
                                 <void property="typeInfo"> 
-                                 <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                                 <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                   <void property="primitiveClass"> 
                                    <class>java.lang.Double</class> 
                                   </void> 
@@ -493,7 +493,7 @@
                              </object> 
                             </void> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Integer</class> 
                               </void> 
@@ -585,7 +585,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcpart/hr=11/ds=2008-04-08</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=11/ds=2008-04-08</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -597,7 +597,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcpart/hr=11/ds=2008-04-08</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart/hr=11/ds=2008-04-08</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"> 
@@ -666,7 +666,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcpart</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcpart</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/sample2.q.xml b/ql/src/test/results/compiler/plan/sample2.q.xml
index ddd08bf0fa..e6c0817219 100644
--- a/ql/src/test/results/compiler/plan/sample2.q.xml
+++ b/ql/src/test/results/compiler/plan/sample2.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/603724760/97704502.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/132818864/1251270971.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -127,7 +127,7 @@
                    <int>1</int> 
                   </void> 
                   <void property="dirName"> 
-                   <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/603724760/97704502.10000.insclause-0</string> 
+                   <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/132818864/1251270971.10000.insclause-0</string> 
                   </void> 
                   <void property="tableInfo"> 
                    <object idref="tableDesc0"/> 
@@ -154,7 +154,7 @@
                        <string>0</string> 
                       </void> 
                       <void property="type"> 
-                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.String</class> 
                         </void> 
@@ -270,7 +270,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -282,7 +282,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -342,7 +342,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/sample3.q.xml b/ql/src/test/results/compiler/plan/sample3.q.xml
index 5bb65e578b..27e1592811 100644
--- a/ql/src/test/results/compiler/plan/sample3.q.xml
+++ b/ql/src/test/results/compiler/plan/sample3.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/407132582/519780727.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/120614374/185173877.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -131,7 +131,7 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/407132582/519780727.10000.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/120614374/185173877.10000.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc0"/> 
@@ -158,7 +158,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -341,7 +341,7 @@
                              </object> 
                             </void> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Integer</class> 
                               </void> 
@@ -396,7 +396,7 @@
                  </object> 
                 </void> 
                 <void property="typeInfo"> 
-                 <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                 <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                   <void property="primitiveClass"> 
                    <class>java.lang.Boolean</class> 
                   </void> 
@@ -458,7 +458,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -470,7 +470,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -530,7 +530,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/sample4.q.xml b/ql/src/test/results/compiler/plan/sample4.q.xml
index 7d3ad062d4..bccea01393 100644
--- a/ql/src/test/results/compiler/plan/sample4.q.xml
+++ b/ql/src/test/results/compiler/plan/sample4.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/25711766/4550052.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/520241420/1334023792.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -127,7 +127,7 @@
                    <int>1</int> 
                   </void> 
                   <void property="dirName"> 
-                   <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/25711766/4550052.10000.insclause-0</string> 
+                   <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/520241420/1334023792.10000.insclause-0</string> 
                   </void> 
                   <void property="tableInfo"> 
                    <object idref="tableDesc0"/> 
@@ -154,7 +154,7 @@
                        <string>0</string> 
                       </void> 
                       <void property="type"> 
-                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                       <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                         <void property="primitiveClass"> 
                          <class>java.lang.String</class> 
                         </void> 
@@ -270,7 +270,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -282,7 +282,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -342,7 +342,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/sample5.q.xml b/ql/src/test/results/compiler/plan/sample5.q.xml
index ac4ee5850b..7529105a3b 100644
--- a/ql/src/test/results/compiler/plan/sample5.q.xml
+++ b/ql/src/test/results/compiler/plan/sample5.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/456641136/546384642.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/139915444/315702445.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -131,7 +131,7 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/456641136/546384642.10000.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/139915444/315702445.10000.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc0"/> 
@@ -158,7 +158,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -328,7 +328,7 @@
                              </object> 
                             </void> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Integer</class> 
                               </void> 
@@ -383,7 +383,7 @@
                  </object> 
                 </void> 
                 <void property="typeInfo"> 
-                 <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                 <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                   <void property="primitiveClass"> 
                    <class>java.lang.Boolean</class> 
                   </void> 
@@ -445,7 +445,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -457,7 +457,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -517,7 +517,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/sample6.q.xml b/ql/src/test/results/compiler/plan/sample6.q.xml
index 11c82a8e3f..a3405dcf59 100644
--- a/ql/src/test/results/compiler/plan/sample6.q.xml
+++ b/ql/src/test/results/compiler/plan/sample6.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/113572139/488354152.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/489210097/1142608438.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -131,7 +131,7 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/113572139/488354152.10000.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/489210097/1142608438.10000.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object idref="tableDesc0"/> 
@@ -158,7 +158,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -328,7 +328,7 @@
                              </object> 
                             </void> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Integer</class> 
                               </void> 
@@ -383,7 +383,7 @@
                  </object> 
                 </void> 
                 <void property="typeInfo"> 
-                 <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                 <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                   <void property="primitiveClass"> 
                    <class>java.lang.Boolean</class> 
                   </void> 
@@ -445,7 +445,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -457,7 +457,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -517,7 +517,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/sample7.q.xml b/ql/src/test/results/compiler/plan/sample7.q.xml
index 8636fc2277..cd3a74feed 100644
--- a/ql/src/test/results/compiler/plan/sample7.q.xml
+++ b/ql/src/test/results/compiler/plan/sample7.q.xml
@@ -31,7 +31,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/26112435/364425107.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/526449165/1680628781.10000.insclause-0</string> 
             </void> 
             <void property="table"> 
              <object id="tableDesc0" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -84,7 +84,7 @@
                 </void> 
                 <void method="put"> 
                  <string>location</string> 
-                 <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+                 <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
                 </void> 
                </object> 
               </void> 
@@ -135,7 +135,7 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/26112435/364425107.10000.insclause-0</string> 
+                           <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/526449165/1680628781.10000.insclause-0</string> 
                           </void> 
                           <void property="tableInfo"> 
                            <object idref="tableDesc0"/> 
@@ -162,7 +162,7 @@
                                <string>0</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.String</class> 
                                 </void> 
@@ -292,7 +292,7 @@
                          </object> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Double</class> 
                           </void> 
@@ -320,7 +320,7 @@
                           <void method="add"> 
                            <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                             <void property="typeInfo"> 
-                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Integer</class> 
                               </void> 
@@ -341,7 +341,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Boolean</class> 
                       </void> 
@@ -573,7 +573,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -585,7 +585,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket/kv1.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -645,7 +645,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/srcbucket</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/srcbucket</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/subq.q.xml b/ql/src/test/results/compiler/plan/subq.q.xml
index 5e9512491d..0749607406 100644
--- a/ql/src/test/results/compiler/plan/subq.q.xml
+++ b/ql/src/test/results/compiler/plan/subq.q.xml
@@ -28,7 +28,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/250562852/763290833.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/237129909/163870306.10000.insclause-0</string> 
             </void> 
             <void property="targetDir"> 
              <string>../build/ql/test/data/warehouse/union.out</string> 
@@ -78,7 +78,7 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/250562852/763290833.10000.insclause-0</string> 
+                           <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/237129909/163870306.10000.insclause-0</string> 
                           </void> 
                           <void property="tableInfo"> 
                            <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -127,7 +127,7 @@
                                <string>0</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.String</class> 
                                 </void> 
@@ -330,7 +330,7 @@
                      </object> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                     <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                       <void property="primitiveClass"> 
                        <class>java.lang.Double</class> 
                       </void> 
@@ -358,7 +358,7 @@
                       <void method="add"> 
                        <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                         <void property="typeInfo"> 
-                         <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Integer</class> 
                           </void> 
@@ -379,7 +379,7 @@
                  </object> 
                 </void> 
                 <void property="typeInfo"> 
-                 <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                 <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                   <void property="primitiveClass"> 
                    <class>java.lang.Boolean</class> 
                   </void> 
@@ -448,7 +448,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>unioninput:src</string> 
@@ -460,7 +460,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -516,7 +516,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/udf1.q.xml b/ql/src/test/results/compiler/plan/udf1.q.xml
index 57c03da776..6121ed9b2a 100644
--- a/ql/src/test/results/compiler/plan/udf1.q.xml
+++ b/ql/src/test/results/compiler/plan/udf1.q.xml
@@ -30,7 +30,7 @@
                         <void property="conf"> 
                          <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                           <void property="dirName"> 
-                           <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/600185748.10001.insclause-0</string> 
+                           <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/291760856.10001.insclause-0</string> 
                           </void> 
                           <void property="tableInfo"> 
                            <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -79,7 +79,7 @@
                                <string>0</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.Boolean</class> 
                                 </void> 
@@ -213,7 +213,7 @@
                                <string>13</string> 
                               </void> 
                               <void property="type"> 
-                               <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                               <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                 <void property="primitiveClass"> 
                                  <class>java.lang.String</class> 
                                 </void> 
@@ -1191,7 +1191,7 @@
                          </object> 
                         </void> 
                         <void property="typeInfo"> 
-                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                           <void property="primitiveClass"> 
                            <class>java.lang.Double</class> 
                           </void> 
@@ -1219,7 +1219,7 @@
                           <void method="add"> 
                            <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                             <void property="typeInfo"> 
-                             <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                             <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                               <void property="primitiveClass"> 
                                <class>java.lang.Integer</class> 
                               </void> 
@@ -1355,7 +1355,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -1367,7 +1367,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -1423,7 +1423,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/udf4.q.xml b/ql/src/test/results/compiler/plan/udf4.q.xml
index 2e93a78d7a..ec82bd7caa 100644
--- a/ql/src/test/results/compiler/plan/udf4.q.xml
+++ b/ql/src/test/results/compiler/plan/udf4.q.xml
@@ -26,7 +26,7 @@
                     <void property="conf"> 
                      <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/990628631.10001.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/468540921.10001.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -75,7 +75,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Long</class> 
                             </void> 
@@ -139,7 +139,7 @@
                            <string>6</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Double</class> 
                             </void> 
@@ -223,7 +223,7 @@
                            <string>14</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Integer</class> 
                             </void> 
@@ -1137,7 +1137,7 @@
                <string>key</string> 
               </void> 
               <void property="type"> 
-               <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+               <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                 <void property="primitiveClass"> 
                  <class>java.lang.String</class> 
                 </void> 
@@ -1166,7 +1166,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>dest1</string> 
@@ -1178,7 +1178,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -1234,7 +1234,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/dest1</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/dest1</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/udf6.q.xml b/ql/src/test/results/compiler/plan/udf6.q.xml
index 370d9f32e6..0f35814fdb 100644
--- a/ql/src/test/results/compiler/plan/udf6.q.xml
+++ b/ql/src/test/results/compiler/plan/udf6.q.xml
@@ -26,7 +26,7 @@
                     <void property="conf"> 
                      <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                       <void property="dirName"> 
-                       <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/1328628098.10001.insclause-0</string> 
+                       <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/642208387.10001.insclause-0</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -75,7 +75,7 @@
                            <string>0</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.String</class> 
                             </void> 
@@ -89,7 +89,7 @@
                            <string>1</string> 
                           </void> 
                           <void property="type"> 
-                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Integer</class> 
                             </void> 
@@ -182,7 +182,7 @@
                         <void method="add"> 
                          <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                           <void property="typeInfo"> 
-                           <object class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                           <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                             <void property="primitiveClass"> 
                              <class>java.lang.Boolean</class> 
                             </void> 
@@ -307,7 +307,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -319,7 +319,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -375,7 +375,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
diff --git a/ql/src/test/results/compiler/plan/union.q.xml b/ql/src/test/results/compiler/plan/union.q.xml
index 941fce9e68..eaf3d8699f 100644
--- a/ql/src/test/results/compiler/plan/union.q.xml
+++ b/ql/src/test/results/compiler/plan/union.q.xml
@@ -28,7 +28,7 @@
              <boolean>true</boolean> 
             </void> 
             <void property="sourceDir"> 
-             <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/672033374/77772175.10000.insclause-0</string> 
+             <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/597756301/937793043.10000.insclause-0</string> 
             </void> 
             <void property="targetDir"> 
              <string>../build/ql/test/data/warehouse/union.out</string> 
@@ -82,7 +82,7 @@
                                <int>1</int> 
                               </void> 
                               <void property="dirName"> 
-                               <string>/data/users/njain/hive1/hive/ql/../build/ql/tmp/672033374/77772175.10000.insclause-0</string> 
+                               <string>/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/ql/../build/ql/tmp/597756301/937793043.10000.insclause-0</string> 
                               </void> 
                               <void property="tableInfo"> 
                                <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -131,7 +131,7 @@
                                    <string>0</string> 
                                   </void> 
                                   <void property="type"> 
-                                   <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                                   <object id="PrimitiveTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                     <void property="primitiveClass"> 
                                      <class>java.lang.String</class> 
                                     </void> 
@@ -319,7 +319,7 @@
                                      </object> 
                                     </void> 
                                     <void property="typeInfo"> 
-                                     <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                                     <object id="PrimitiveTypeInfo1" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                       <void property="primitiveClass"> 
                                        <class>java.lang.Double</class> 
                                       </void> 
@@ -347,7 +347,7 @@
                                       <void method="add"> 
                                        <object class="org.apache.hadoop.hive.ql.plan.exprNodeConstantDesc"> 
                                         <void property="typeInfo"> 
-                                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                                         <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                           <void property="primitiveClass"> 
                                            <class>java.lang.Integer</class> 
                                           </void> 
@@ -368,7 +368,7 @@
                                  </object> 
                                 </void> 
                                 <void property="typeInfo"> 
-                                 <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.ql.typeinfo.PrimitiveTypeInfo"> 
+                                 <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                                   <void property="primitiveClass"> 
                                    <class>java.lang.Boolean</class> 
                                   </void> 
@@ -720,7 +720,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>null-subquery1:unioninput-subquery1:src</string> 
@@ -735,7 +735,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -791,7 +791,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/data/users/njain/hive1/hive/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-337-trunk/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/ByteArrayRef.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/ByteArrayRef.java
new file mode 100644
index 0000000000..2b82e45d40
--- /dev/null
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/ByteArrayRef.java
@@ -0,0 +1,44 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.serde2.lazy;
+
+/**
+ * ByteArrayRef stores a reference to a byte array.
+ * 
+ * The LazyObject hierarchy uses a reference to a single ByteArrayRef,
+ * so that it's much faster to switch to the next row and release the 
+ * reference to the old row (so that the system can do garbage collection
+ * if needed).
+ */
+public class ByteArrayRef {
+
+  
+  /**
+   * Stores the actual data.
+   */
+  byte[] data;
+
+  public byte[] getData() {
+    return data;
+  }
+
+  public void setData(byte[] data) {
+    this.data = data;
+  }
+  
+}
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyArray.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyArray.java
new file mode 100644
index 0000000000..8aa8f502a1
--- /dev/null
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyArray.java
@@ -0,0 +1,219 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.serde2.lazy;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.io.Text;
+
+/**
+ * LazyArray stores an array of Lazy Objects.
+ * 
+ * LazyArray does not deal with the case of a NULL array. That is handled
+ * by LazyArrayObjectInspector.
+ */
+public class LazyArray extends LazyNonPrimitive {
+
+  /**
+   * Whether the data is already parsed or not.
+   */
+  boolean parsed = false;
+  /**
+   * The length of the array.
+   * Only valid when the data is parsed.
+   * -1 when the array is NULL.
+   */
+  int arrayLength = 0;
+  
+  /**
+   * The start positions of array elements.
+   * Only valid when the data is parsed.
+   * Note that startPosition[arrayLength] = begin + length + 1;
+   * that makes sure we can use the same formula to compute the
+   * length of each element of the array.
+   */
+  int[] startPosition;
+  
+  /**
+   * Whether init() has been called on the element or not.
+   */
+  boolean[] elementInited;
+  
+  /**
+   * The elements of the array. Note that we do arrayElements[i].
+   * init(bytes, begin, length) only when that element is accessed.
+   */
+  LazyObject[] arrayElements;
+
+  /**
+   * Construct a LazyArray object with the TypeInfo.
+   * @param typeInfo  the TypeInfo representing the type of this LazyArray.
+   */
+  protected LazyArray(TypeInfo typeInfo) {
+    super(typeInfo);
+  }
+
+  /**
+   * Set the row data for this LazyArray.
+   * @see LazyObject#init(ByteArrayRef, int, int)
+   */
+  @Override
+  public void init(ByteArrayRef bytes, int start, int length) {
+    super.init(bytes, start, length);
+    parsed = false;
+  }
+  
+  /**
+   * Enlarge the size of arrays storing information for the elements inside 
+   * the array.
+   */
+  protected void enlargeArrays() {
+    if (startPosition == null) {
+      int initialSize = 2;
+      startPosition = new int[initialSize]; 
+      arrayElements = new LazyObject[initialSize];
+      elementInited = new boolean[initialSize];
+    } else {
+      startPosition = Arrays.copyOf(startPosition, startPosition.length*2);
+      arrayElements = Arrays.copyOf(arrayElements, arrayElements.length*2);
+      elementInited = Arrays.copyOf(elementInited, elementInited.length*2);
+    }
+  }
+  
+  /**
+   * Parse the bytes and fill arrayLength and startPosition.
+   */
+  private void parse(byte separator, Text nullSequence) {
+    parsed = true;
+    
+    // empty array?
+    if (length == 0) {
+      arrayLength = 0;
+      return;
+    }
+    
+    byte[] bytes = this.bytes.getData();
+    
+    arrayLength = 0;
+    int arrayByteEnd = start + length;
+    int elementByteBegin = start;
+    int elementByteEnd = start;
+    
+    // Go through all bytes in the byte[]
+    while (elementByteEnd <= arrayByteEnd) {
+      // Reached the end of a field?
+      if (elementByteEnd == arrayByteEnd 
+          || bytes[elementByteEnd] == separator) {
+        // Array size not big enough?
+        if (startPosition == null || arrayLength+1 == startPosition.length) {
+          enlargeArrays();
+        }
+        startPosition[arrayLength] = elementByteBegin;
+        arrayLength++;
+        elementByteBegin = elementByteEnd + 1;
+      }
+      elementByteEnd++;
+    }
+    // Store arrayByteEnd+1 in startPosition[arrayLength]
+    // so that we can use the same formula to compute the length of
+    // each element in the array: startPosition[i+1] - startPosition[i] - 1
+    startPosition[arrayLength] = elementByteEnd;
+    
+    if (arrayLength > 0) {
+      Arrays.fill(elementInited, 0, arrayLength, false);
+    }
+    
+  }
+  
+  /**
+   * Returns the actual primitive object at the index position
+   * inside the array represented by this LazyObject.
+   */
+  public Object getListElementObject(int index, byte separator, 
+      Text nullSequence) {
+    if (!parsed) {
+      parse(separator, nullSequence);
+    }
+    if (index < 0 || index >= arrayLength) {
+      return null;
+    }
+    return uncheckedGetElement(index, nullSequence);
+  }
+  
+  /**
+   * Get the element without checking parsed or out-of-bound index.
+   */
+  private Object uncheckedGetElement(int index, Text nullSequence) {
+    int elementLength = startPosition[index+1] - startPosition[index] - 1;
+    if (elementLength == nullSequence.getLength() 
+        && 0 == LazyUtils.compare(bytes.getData(), startPosition[index], 
+            elementLength, nullSequence.getBytes(), 0, 
+            nullSequence.getLength())) {
+      return null;
+    } else {
+      if (!elementInited[index]) {
+        elementInited[index] = true;
+        if (arrayElements[index] == null) {
+          arrayElements[index] = LazyFactory.createLazyObject(
+            typeInfo.getListElementTypeInfo());
+        }
+        arrayElements[index].init(bytes, startPosition[index], 
+            elementLength);
+      }
+    }
+    return arrayElements[index].getObject();
+  }
+  
+  /** Returns -1 for null array.
+   */
+  public int getListLength(byte separator, Text nullSequence) {
+    if (!parsed) {
+      parse(separator, nullSequence);
+    }
+    return arrayLength;
+  }
+  
+  /** 
+   * cachedList is reused every time getList is called.
+   * Different LazyArray instances cannot share the same cachedList. 
+   */
+  ArrayList<Object> cachedList;
+  /** Returns the List of actual primitive objects.
+   *  Returns null for null array.
+   */
+  public List<Object> getList(byte separator, Text nullSequence) {
+    if (!parsed) {
+      parse(separator, nullSequence);
+    }
+    if (arrayLength == -1) {
+      return null;
+    }
+    if (cachedList == null) {
+      cachedList = new ArrayList<Object>(arrayLength);
+    } else {
+      cachedList.clear();
+    }
+    for (int index=0; index<arrayLength; index++) {
+      cachedList.add(uncheckedGetElement(index, nullSequence));
+    }
+    return cachedList;
+  }
+}
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyByte.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyByte.java
index 550e4957cd..6c57c4338a 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyByte.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyByte.java
@@ -33,21 +33,18 @@
 public class LazyByte extends LazyPrimitive<Byte> {
 
   public LazyByte() {
-    super(Byte.class);
   }
-  
+
   @Override
-  public Byte getPrimitiveObject() {
-    if (bytes == null) return null;
+  public void init(ByteArrayRef bytes, int start, int length) {
     try {
       // Slower method: convert to String and then convert to Integer
       // return Byte.valueOf(LazyUtils.convertToString(bytes, start, length));
-      return Byte.valueOf(parseByte(bytes, start, length));
+      data = Byte.valueOf(parseByte(bytes.getData(), start, length));
     } catch (NumberFormatException e) {
-      return null;
+      data = null;
     }
   }
-
   
   /**
    * Parses the string argument as if it was a byte value and returns the
@@ -91,5 +88,6 @@ public static byte parseByte(byte[] bytes, int start, int length, int radix)
       }
       throw new NumberFormatException();
   }
-  
+
+
 }
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyDouble.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyDouble.java
index d691549a6a..6cd6b3881e 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyDouble.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyDouble.java
@@ -27,22 +27,14 @@
  */
 public class LazyDouble extends LazyPrimitive<Double> {
 
-  public LazyDouble() {
-    super(Double.class);
-  }
-  
-  Text text = new Text();
-  
   @Override
-  public Double getPrimitiveObject() {
-    // TODO: replace this by directly parsing the bytes buffer for better performance.
-    if (bytes == null) return null;
+  public void init(ByteArrayRef bytes, int start, int length) {
     try {
-      return Double.valueOf(Text.decode(bytes, start, length));
+      data = Double.valueOf(Text.decode(bytes.getData(), start, length));
     } catch (NumberFormatException e) {
-      return null;
+      data = null;
     } catch (CharacterCodingException e) {
-      return null;
+      data = null;
     }
   }
 
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java
new file mode 100644
index 0000000000..7bd9984114
--- /dev/null
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java
@@ -0,0 +1,141 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.serde2.lazy;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.io.Text;
+
+public class LazyFactory {
+
+  /**
+   * Create a lazy primitive class given the java class. 
+   */
+  public static LazyPrimitive<?> createLazyPrimitiveClass(Class<?> c) {
+    if (String.class.equals(c)) {
+      return new LazyString();
+    } else if (Integer.class.equals(c)) {
+      return new LazyInteger();
+    } else if (Double.class.equals(c)) {
+      return new LazyDouble();
+    } else if (Byte.class.equals(c)) {
+      return new LazyByte();
+    } else if (Short.class.equals(c)) {
+      return new LazyShort();
+    } else if (Long.class.equals(c)) {
+      return new LazyLong();
+    } else {
+      return null;
+    }
+  }
+
+  /**
+   * Create a hierarchical LazyObject based on the given typeInfo.
+   */
+  public static LazyObject createLazyObject(TypeInfo typeInfo) {
+    ObjectInspector.Category c = typeInfo.getCategory();
+    switch(c) {
+    case PRIMITIVE:
+      return createLazyPrimitiveClass(typeInfo.getPrimitiveClass());
+    case MAP:
+      return new LazyMap(typeInfo);      
+    case LIST: 
+      return new LazyArray(typeInfo);      
+    case STRUCT:
+      return new LazyStruct(typeInfo);      
+    }
+
+    throw new RuntimeException("Hive LazySerDe Internal error.");
+  }
+  
+  /**
+   * Create a hierarchical ObjectInspector for LazyObject with the given
+   * typeInfo.
+   * @param typeInfo  The type information for the LazyObject
+   * @param separator The array of separators for delimiting each level
+   * @param separatorIndex  The current level (for separators). List(array), 
+   *                        struct uses 1 level of separator, and map uses 2
+   *                        levels: the first one for delimiting entries, the
+   *                        second one for delimiting key and values. 
+   * @param nullSequence    The sequence of bytes representing NULL.
+   * @return  The ObjectInspector
+   */
+  public static ObjectInspector createLazyObjectInspector(TypeInfo typeInfo, byte[] separator, 
+      int separatorIndex, Text nullSequence) {
+    ObjectInspector.Category c = typeInfo.getCategory();
+    switch(c) {
+    case PRIMITIVE:
+      return ObjectInspectorFactory.getStandardPrimitiveObjectInspector(typeInfo.getPrimitiveClass());
+    case MAP:
+      return ObjectInspectorFactory.getLazySimpleMapObjectInspector(
+          createLazyObjectInspector(typeInfo.getMapKeyTypeInfo(), separator, separatorIndex+2, nullSequence), 
+          createLazyObjectInspector(typeInfo.getMapValueTypeInfo(), separator, separatorIndex+2, nullSequence), 
+          separator[separatorIndex], 
+          separator[separatorIndex+1], 
+          nullSequence);
+    case LIST: 
+      return ObjectInspectorFactory.getLazySimpleListObjectInspector(
+          createLazyObjectInspector(typeInfo.getListElementTypeInfo(), separator, separatorIndex+1, nullSequence),
+          separator[separatorIndex], 
+          nullSequence);
+    case STRUCT:
+      List<String> fieldNames = typeInfo.getAllStructFieldNames();
+      List<TypeInfo> fieldTypeInfos = typeInfo.getAllStructFieldTypeInfos();
+      List<ObjectInspector> fieldObjectInspectors = new ArrayList<ObjectInspector>(fieldTypeInfos.size());
+      for(int i=0; i<fieldTypeInfos.size(); i++) {
+        fieldObjectInspectors.add(
+            createLazyObjectInspector(fieldTypeInfos.get(i), separator, separatorIndex+1, nullSequence));
+      }
+      return ObjectInspectorFactory.getLazySimpleStructObjectInspector(
+          fieldNames, 
+          fieldObjectInspectors, 
+          separator[separatorIndex], 
+          nullSequence,
+          false);  
+    }
+
+    throw new RuntimeException("Hive LazySerDe Internal error.");
+  }
+
+  /**
+   * Create a hierarchical ObjectInspector for LazyStruct with the given
+   * columnNames and columnTypeInfos.
+   * 
+   * @param lastColumnTakesRest whether the last column of the struct should take
+   *                            the rest of the row if there are extra fields. 
+   * @see LazyFactory#createLazyObjectInspector(TypeInfo, byte[], int, Text)
+   */  
+  public static ObjectInspector createLazyStructInspector(List<String> columnNames, 
+      List<TypeInfo> typeInfos, byte[] separators, 
+      Text nullSequence, boolean lastColumnTakesRest) {
+    ArrayList<ObjectInspector> columnObjectInspectors =
+        new ArrayList<ObjectInspector>(typeInfos.size());  
+    for (int i=0; i<typeInfos.size(); i++) {
+      columnObjectInspectors.add(
+          LazyFactory.createLazyObjectInspector(typeInfos.get(i), separators, 1, nullSequence));
+    }
+    return 
+        ObjectInspectorFactory.getLazySimpleStructObjectInspector(columnNames,
+            columnObjectInspectors, separators[0], nullSequence, lastColumnTakesRest);
+  }
+  
+}
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyInteger.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyInteger.java
index 00151437d6..23c3c42763 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyInteger.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyInteger.java
@@ -33,20 +33,19 @@
 public class LazyInteger extends LazyPrimitive<Integer> {
 
   public LazyInteger() {
-    super(Integer.class);
   }
-  
+
   @Override
-  public Integer getPrimitiveObject() {
+  public void init(ByteArrayRef bytes, int start, int length) {
     try {
       // Slower method: convert to String and then convert to Integer
       // return Integer.valueOf(LazyUtils.convertToString(bytes, start, length));
-      return Integer.valueOf(parseInt(bytes, start, length));
+      data = Integer.valueOf(parseInt(bytes.getData(), start, length));
     } catch (NumberFormatException e) {
-      return null;
+      data = null;
     }
   }
-
+  
   /**
    * Parses the string argument as if it was an int value and returns the
    * result. Throws NumberFormatException if the string does not represent an
@@ -76,7 +75,7 @@ public static int parseInt(byte[] bytes, int start, int length) throws NumberFor
    *            a UTF-8 encoded string representation of an int quantity.
    * @param radix
    *            the base to use for conversion.
-   * @return int the value represented by the argument
+   * @return    the value represented by the argument
    * @exception NumberFormatException
    *                if the argument could not be parsed as an int quantity.
    */
@@ -104,6 +103,24 @@ public static int parseInt(byte[] bytes, int start, int length, int radix)
     return parse(bytes, start, length, offset, radix, negative);
   }
 
+  /**
+   * 
+   * @param bytes
+   * @param start
+   * @param length
+   *            a UTF-8 encoded string representation of an int quantity.
+   * @param radix
+   *            the base to use for conversion.
+   * @param offset
+   *            the starting position after the sign (if exists)
+   * @param radix
+   *            the base to use for conversion.
+   * @param negative
+   *            whether the number is negative.
+   * @return the value represented by the argument
+   * @exception NumberFormatException
+   *                if the argument could not be parsed as an int quantity.
+   */
   private static int parse(byte[] bytes, int start, int length, int offset, int radix,
           boolean negative) throws NumberFormatException {
       int max = Integer.MIN_VALUE / radix;
@@ -130,5 +147,5 @@ private static int parse(byte[] bytes, int start, int length, int offset, int ra
       }
       return result;
   }
-  
+
 }
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyLong.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyLong.java
index 5b5f966582..c4a483fad9 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyLong.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyLong.java
@@ -33,17 +33,16 @@
 public class LazyLong extends LazyPrimitive<Long> {
 
   public LazyLong() {
-    super(Long.class);
   }
 
   @Override
-  public Long getPrimitiveObject() {
+  public void init(ByteArrayRef bytes, int start, int length) {
     try {
       // Slower method: convert to String and then convert to Long
       // return Long.valueOf(LazyUtils.convertToString(bytes, start, length));
-      return Long.valueOf(parseLong(bytes, start, length));
+      data = Long.valueOf(parseLong(bytes.getData(), start, length));
     } catch (NumberFormatException e) {
-      return null;
+      data = null;
     }
   }
 
@@ -76,7 +75,7 @@ public static long parseLong(byte[] bytes, int start, int length) throws NumberF
    *            a UTF-8 encoded string representation of a long quantity.
    * @param radix
    *            the base to use for conversion.
-   * @return long the value represented by the argument
+   * @return the value represented by the argument
    * @exception NumberFormatException
    *                if the argument could not be parsed as an long quantity.
    */
@@ -104,6 +103,27 @@ public static long parseLong(byte[] bytes, int start, int length, int radix)
     return parse(bytes, start, length, offset, radix, negative);
   }
 
+  /**
+  /**
+   * Parses the string argument as if it was an long value and returns the
+   * result. Throws NumberFormatException if the string does not represent an
+   * long quantity. The second argument specifies the radix to use when
+   * parsing the value.
+   * 
+   * @param bytes
+   * @param start
+   * @param length
+   *            a UTF-8 encoded string representation of a long quantity.
+   * @param offset
+   *            the starting position after the sign (if exists)
+   * @param radix
+   *            the base to use for conversion.
+   * @param negative
+   *            whether the number is negative.
+   * @return the value represented by the argument
+   * @exception NumberFormatException
+   *                if the argument could not be parsed as an long quantity.
+   */
   private static long parse(byte[] bytes, int start, int length, int offset, int radix,
       boolean negative) {
     long max = Long.MIN_VALUE / radix;
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyMap.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyMap.java
new file mode 100644
index 0000000000..62e603e397
--- /dev/null
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyMap.java
@@ -0,0 +1,328 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.serde2.lazy;
+
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.io.Text;
+
+/**
+ * LazyMap stores a map of Primitive LazyObjects to LazyObjects.
+ * Note that the keys of the map cannot contain null.
+ * 
+ * LazyMap does not deal with the case of a NULL map. That is handled
+ * by LazyMapObjectInspector.
+ */
+public class LazyMap extends LazyNonPrimitive {
+  
+  /**
+   * Whether the data is already parsed or not.
+   */
+  boolean parsed = false;
+  
+  /**
+   * The size of the map.
+   * Only valid when the data is parsed.
+   * -1 when the map is NULL.
+   */
+  int mapSize = 0;
+  
+  /**
+   * The beginning position of key[i].
+   * Only valid when the data is parsed.
+   * Note that keyStart[mapSize] = begin + length + 1;
+   * that makes sure we can use the same formula to compute the
+   * length of each value in the map.
+   */
+  int[] keyStart;
+  
+  /**
+   * The end position of key[i] (the position of the key-value separator).
+   * Only valid when the data is parsed.
+   */  
+  int[] keyEnd;
+  /**
+   * The keys are stored in an array of LazyPrimitives.
+   */
+  LazyPrimitive<?>[] keyObjects;
+  /**
+   * Whether init() is called on keyObjects[i]. 
+   */
+  boolean[] keyInited;
+  /**
+   * The values are stored in an array of LazyObjects.
+   * value[index] will start from KeyEnd[index] + 1,
+   * and ends before KeyStart[index+1] - 1.
+   */
+  LazyObject[] valueObjects;
+  /**
+   * Whether init() is called on valueObjects[i]
+   */
+  boolean[] valueInited;
+  
+  /**
+   * Construct a LazyMap object with the TypeInfo.
+   * @param typeInfo  the TypeInfo representing the type of this LazyMap.
+   */
+  protected LazyMap(TypeInfo typeInfo) {
+    super(typeInfo);
+  }
+
+  /**
+   * Set the row data for this LazyArray.
+   * @see LazyObject#init(ByteArrayRef, int, int)
+   */
+  @Override
+  public void init(ByteArrayRef bytes, int start, int length) {
+    super.init(bytes, start, length);
+    parsed = false;
+  }
+  
+  /**
+   * Enlarge the size of arrays storing information for the elements inside 
+   * the array.
+   */
+  protected void enlargeArrays() {
+    if (keyStart == null) {
+      int initialSize = 2;
+      keyStart = new int[initialSize];
+      keyEnd = new int[initialSize];
+      keyObjects = new LazyPrimitive<?>[initialSize];
+      valueObjects = new LazyObject[initialSize];
+      keyInited = new boolean[initialSize];
+      valueInited = new boolean[initialSize];
+    } else {
+      keyStart = Arrays.copyOf(keyStart, keyStart.length*2);
+      keyEnd = Arrays.copyOf(keyEnd, keyEnd.length*2);
+      keyObjects = Arrays.copyOf(keyObjects, keyObjects.length*2);
+      valueObjects = Arrays.copyOf(valueObjects, valueObjects.length*2);
+      keyInited = Arrays.copyOf(keyInited, keyInited.length*2);
+      valueInited = Arrays.copyOf(valueInited, valueInited.length*2);
+    }
+  }
+
+  /**
+   * Parse the byte[] and fill keyStart, keyEnd.
+   * @param itemSeparator     The separator between different entries.
+   * @param keyValueSeparator The separator between key and value.
+   * @param nullSequence      The byte sequence representing NULL.
+   */
+  private void parse(byte itemSeparator, byte keyValueSeparator, 
+      Text nullSequence) {
+    parsed = true;
+    
+    // empty array?
+    if (length == 0) {
+      mapSize = 0;
+      return;
+    }
+    
+    mapSize = 0;
+    int arrayByteEnd = start + length;
+    int elementByteBegin = start;
+    int keyValueSeparatorPosition = -1;
+    int elementByteEnd = start;
+    byte[] bytes = this.bytes.getData();
+    
+    // Go through all bytes in the byte[]
+    while (elementByteEnd <= arrayByteEnd) {
+      // End of entry reached?
+      if (elementByteEnd == arrayByteEnd 
+          || bytes[elementByteEnd] == itemSeparator) {
+        // Array full?
+        if (keyStart == null || mapSize + 1 == keyStart.length) {
+          enlargeArrays();
+        }
+        keyStart[mapSize] = elementByteBegin;
+        // If no keyValueSeparator is seen, all bytes belong to key, and 
+        // value will be NULL.
+        keyEnd[mapSize] = (keyValueSeparatorPosition == -1 
+            ? elementByteEnd: keyValueSeparatorPosition);
+        // reset keyValueSeparatorPosition
+        keyValueSeparatorPosition = -1;
+        mapSize++;
+        elementByteBegin = elementByteEnd + 1;
+      }
+      // Is this the first keyValueSeparator in this entry?
+      if (keyValueSeparatorPosition == -1 && elementByteEnd != arrayByteEnd
+          && bytes[elementByteEnd] == keyValueSeparator) {
+        keyValueSeparatorPosition = elementByteEnd;
+      }
+      elementByteEnd++;
+    }
+    
+    // This makes sure we can use the same formula to compute the
+    // length of each value in the map.
+    keyStart[mapSize] = arrayByteEnd + 1;
+
+    if (mapSize > 0) {
+      Arrays.fill(keyInited, 0, mapSize, false);
+      Arrays.fill(valueInited, 0, mapSize, false);
+    }
+  }
+  
+  /**
+   * Get the value in the map for the key.
+   * 
+   * If there are multiple matches (which is possible in the serialized 
+   * format), only the first one is returned.
+   * 
+   * The most efficient way to get the value for the key is to serialize the 
+   * key and then try to find it in the array.  We do linear search because in 
+   * most cases, user only wants to get one or two values out of the map, and 
+   * the cost of building up a HashMap is substantially higher.
+   * 
+   * @param itemSeparator     The separator between different entries.
+   * @param keyValueSeparator The separator between key and value.
+   * @param nullSequence      The byte sequence representing NULL.
+   * @param key               The key object that we are looking for.
+   * @return The corresponding value object, or NULL if not found
+   */
+  public Object getMapValueElement(byte itemSeparator, byte keyValueSeparator, 
+      Text nullSequence, Object key) {
+    if (!parsed) {
+      parse(itemSeparator, keyValueSeparator, nullSequence);
+    }
+    
+    // search for the key
+    for (int i=0; i<mapSize; i++) {
+      LazyPrimitive<?> lazyKeyI = uncheckedGetKey(i, nullSequence);
+      if (lazyKeyI == null) continue;
+      // getObject() will convert LazyPrimitive to actual primitive objects.
+      Object keyI = lazyKeyI.getObject();
+      if (keyI == null) continue;
+      if (keyI.equals(key)) {
+        // Got a match, return the value
+        LazyObject v = uncheckedGetValue(i, nullSequence);
+        return v == null ? v : v.getObject();
+      }
+    }
+    
+    return null;
+  }
+
+  /**
+   * Get the value object with the index without checking parsed.
+   * @param index  The index into the array starting from 0
+   * @param nullSequence  The byte sequence representing the NULL value
+   */
+  private LazyObject uncheckedGetValue(int index, Text nullSequence) {
+    int valueIBegin = keyEnd[index] + 1;
+    int valueILength = keyStart[index+1] - 1 - valueIBegin;
+    if (valueILength < 0 || 
+         ((valueILength == nullSequence.getLength())
+          && 0 == LazyUtils.compare(bytes.getData(), valueIBegin, valueILength, 
+              nullSequence.getBytes(), 0, nullSequence.getLength()))) {
+      return null; 
+    }
+    if (!valueInited[index]) {
+      valueInited[index] = true;
+      if (valueObjects[index] == null) {
+        valueObjects[index] = LazyFactory.createLazyObject(
+            typeInfo.getMapValueTypeInfo());
+      }
+      valueObjects[index].init(bytes, valueIBegin, valueILength);
+    }
+    return valueObjects[index];
+  }
+  
+  /**
+   * Get the key object with the index without checking parsed.
+   * @param index  The index into the array starting from 0
+   * @param nullSequence  The byte sequence representing the NULL value
+   */
+  private LazyPrimitive<?> uncheckedGetKey(int index, Text nullSequence) {
+    int keyIBegin = keyStart[index];
+    int keyILength = keyEnd[index] - keyStart[index];
+    if (keyILength < 0 || 
+         ((keyILength == nullSequence.getLength())
+          && 0 == LazyUtils.compare(bytes.getData(), keyIBegin, keyILength, 
+              nullSequence.getBytes(), 0, nullSequence.getLength()))) {
+      return null;
+    }
+    if (!keyInited[index]) {
+      keyInited[index] = true;
+      if (keyObjects[index] == null) {
+        // Keys are always primitive
+        keyObjects[index] = LazyFactory.createLazyPrimitiveClass(
+            typeInfo.getMapKeyTypeInfo().getPrimitiveClass());
+      }
+      keyObjects[index].init(bytes, keyIBegin, keyILength);
+    }
+    return keyObjects[index];
+  }
+  
+  /**
+   * cachedMap is reused for different calls to getMap().
+   * But each LazyMap has a separate cachedMap so we won't overwrite the
+   * data by accident.
+   */
+  HashMap<Object, Object> cachedMap;
+  
+  /**
+   * Return the map object representing this LazyMap.
+   * Note that the keyObjects will be Java primitive objects.
+   * @param itemSeparator     The separator between different entries.
+   * @param keyValueSeparator The separator between key and value.
+   * @param nullSequence      The byte sequence representing NULL.
+   * @return
+   */
+  public Map<Object, Object> getMap(byte itemSeparator, byte keyValueSeparator,
+      Text nullSequence) {
+    if (!parsed) {
+      parse(itemSeparator, keyValueSeparator, nullSequence);
+    }
+    if (cachedMap == null) {
+      cachedMap = new HashMap<Object, Object>();
+    }
+    cachedMap.clear();
+    
+    // go through each element of the map
+    for (int i = 0; i < mapSize; i++) {
+      LazyPrimitive<?> lazyKey = uncheckedGetKey(i, nullSequence);
+      if (lazyKey == null) continue;
+      Object key = lazyKey.getObject();
+      // do not overwrite if there are duplicate keys
+      if (key != null && !cachedMap.containsKey(key)) {
+        LazyObject lazyValue = uncheckedGetValue(i, nullSequence);
+        Object value = (lazyValue == null ? null : lazyValue.getObject());
+        cachedMap.put(key, value);
+      }
+    }
+    return cachedMap;
+  }
+
+  /**
+   * Get the size of the map represented by this LazyMap.
+   * @param itemSeparator     The separator between different entries.
+   * @param keyValueSeparator The separator between key and value.
+   * @param nullSequence      The byte sequence representing NULL.
+   * @return                  The size of the map, -1 for NULL map.
+   */
+  public int getMapSize(byte itemSeparator, byte keyValueSeparator,
+      Text nullSequence) {
+    if (!parsed) {
+      parse(itemSeparator, keyValueSeparator, nullSequence);
+    }
+    return mapSize;
+  }
+
+}
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyNonPrimitive.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyNonPrimitive.java
new file mode 100644
index 0000000000..fd352e9079
--- /dev/null
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyNonPrimitive.java
@@ -0,0 +1,58 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.serde2.lazy;
+
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+
+
+/**
+ * LazyPrimitive stores a primitive Object in a LazyObject.
+ */
+public abstract class LazyNonPrimitive implements LazyObject {
+
+  protected ByteArrayRef bytes;
+  protected int start;
+  protected int length;
+  
+  /**
+   * The TypeInfo for this LazyNonPrimitive. 
+   */
+  TypeInfo typeInfo;
+  
+  protected LazyNonPrimitive(TypeInfo typeInfo) {
+    this.typeInfo = typeInfo;
+    bytes = null;
+    start = 0;
+    length = 0;
+  }
+  
+  @Override
+  public void init(ByteArrayRef bytes, int start, int length) {
+    if (bytes == null) {
+      throw new RuntimeException("bytes cannot be null!");
+    }
+    this.bytes = bytes;
+    this.start = start;
+    this.length = length;
+  }
+
+  @Override
+  public Object getObject() {
+    return this; 
+  }
+}
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyObject.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyObject.java
index f2df162a3c..092c215d8b 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyObject.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyObject.java
@@ -17,34 +17,30 @@
  */
 package org.apache.hadoop.hive.serde2.lazy;
 
-import org.apache.hadoop.io.Text;
-
 /**
  * LazyObject stores an object in a range of bytes in a byte[].
  * 
- * A LazyObject can represent anything.
- *
+ * A LazyObject can represent any primitive object or hierarchical object
+ * like array, map or struct.
  */
-public class LazyObject {
+public interface LazyObject {
 
-  protected byte[] bytes;
-  protected int start;
-  protected int length;
-  
-  protected LazyObject() {
-    bytes = null;
-    start = 0;
-    length = 0;
-  }
-  
-  protected LazyObject(byte[] bytes, int start, int length) {
-    setAll(bytes, start, length);
-  }
+  /**
+   * Set the data for this LazyObject.
+   * We take ByteArrayRef instead of byte[] so that we will be able to drop
+   * the reference to byte[] by a single assignment.
+   * The ByteArrayRef object can be reused across multiple rows.
+   * @param bytes  The wrapper of the byte[].
+   * @param start  The start position inside the bytes.
+   * @param length The length of the data, starting from "start"
+   * @see ByteArrayRef
+   */
+  void init(ByteArrayRef bytes, int start, int length);
 
-  protected void setAll(byte[] bytes, int start, int length) {
-    this.bytes = bytes;
-    this.start = start;
-    this.length = length;
-  }
-  
+  /**
+   * If the LazyObject is a primitive Object, then deserialize it and return
+   * the actual primitive Object.
+   * Otherwise (array, map, struct), return this. 
+   */
+  public Object getObject();
 }
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyPrimitive.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyPrimitive.java
index 80675f30ba..50d3f71f80 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyPrimitive.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyPrimitive.java
@@ -21,17 +21,15 @@
 /**
  * LazyPrimitive stores a primitive Object in a LazyObject.
  */
-public abstract class LazyPrimitive<T> extends LazyObject {
+public abstract class LazyPrimitive<T> implements LazyObject {
+
+  T data;
 
-  Class<T> primitiveClass;
-  
-  protected LazyPrimitive(Class<T> primitiveClass) {
-    this.primitiveClass = primitiveClass;
-  }
-  
   /**
    * Returns the actual primitive object represented by this LazyObject.
    */
-  public abstract T getPrimitiveObject();
-  
+  public T getObject() {
+    return data;
+  }
+
 }
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyShort.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyShort.java
index 9e7f276cbf..3d7cdcbc87 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyShort.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyShort.java
@@ -33,17 +33,16 @@
 public class LazyShort extends LazyPrimitive<Short> {
 
   public LazyShort() {
-    super(Short.class);
   }
   
   @Override
-  public Short getPrimitiveObject() {
+  public void init(ByteArrayRef bytes, int start, int length) {
     try {
       // Slower method: convert to String and then convert to Integer
       // return Short.valueOf(LazyUtils.convertToString(bytes, start, length));
-      return Short.valueOf(parseShort(bytes, start, length));
+      data = Short.valueOf(parseShort(bytes.getData(), start, length));
     } catch (NumberFormatException e) {
-      return null;
+      data = null;
     }
   }
 
@@ -90,5 +89,5 @@ public static short parseShort(byte[] bytes, int start, int length, int radix)
     }
     throw new NumberFormatException();
   }
-  
+
 }
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazySimpleSerDe.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazySimpleSerDe.java
index c49991566e..f21ad3c830 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazySimpleSerDe.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazySimpleSerDe.java
@@ -21,22 +21,25 @@
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
+import java.util.Map;
 import java.util.Properties;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hive.serde.Constants;
-import org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe;
 import org.apache.hadoop.hive.serde2.SerDe;
 import org.apache.hadoop.hive.serde2.SerDeException;
 import org.apache.hadoop.hive.serde2.SerDeUtils;
+import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
-import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
-import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
 import org.apache.hadoop.hive.serde2.objectinspector.StructField;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
 import org.apache.hadoop.io.BytesWritable;
 import org.apache.hadoop.io.Text;
 import org.apache.hadoop.io.Writable;
@@ -53,28 +56,35 @@
  */
 public class LazySimpleSerDe implements SerDe {
 
-  public static final Log LOG = LogFactory.getLog(LazySimpleSerDe.class.getName());
+  public static final Log LOG = LogFactory.getLog(
+      LazySimpleSerDe.class.getName());
 
-  final public static byte DefaultSeparator = 1;
-  private byte separator;
-
-
-  private List<String> columnNames;
-  private List<String> columnTypes;
-  private ObjectInspector cachedObjectInspector;
+  final public static byte[] DefaultSeparators = {(byte)1, (byte)2, (byte)3};
+  // We need some initial values in case user don't call initialize()
+  private byte[] separators = DefaultSeparators;
 
   private String nullString;
+  private Text nullSequence;
   private boolean lastColumnTakesRest;
   
+  private TypeInfo rowTypeInfo;
+  private ObjectInspector cachedObjectInspector;
+
   public String toString() {
-    return getClass().toString() + "[" + separator + ":" 
-        + columnNames + ":" + columnTypes + "]";
+    return getClass().toString() + "[" + Arrays.asList(separators) + ":" 
+        + rowTypeInfo.getAllStructFieldNames()
+        + ":" + rowTypeInfo.getAllStructFieldTypeInfos() + "]";
   }
 
   public LazySimpleSerDe() throws SerDeException {
-    separator = DefaultSeparator;
   }
 
+  /**
+   * Return the byte value of the number string.
+   * @param altValue   The string containing a number.
+   * @param defaultVal If the altValue does not represent a number, 
+   *                   return the defaultVal.
+   */
   private byte getByte(String altValue, byte defaultVal) {
     if (altValue != null && altValue.length() > 0) {
       try {
@@ -88,91 +98,111 @@ private byte getByte(String altValue, byte defaultVal) {
 
   /**
    * Initialize the SerDe given the parameters.
-   * serialization.format: separator char or byte code (only supports byte-value up to 127)
-   * columns:  ,-separated column naems 
-   * columns.types:  :-separated column types 
+   * serialization.format: separator char or byte code (only supports 
+   * byte-value up to 127)
+   * columns:  ","-separated column names 
+   * columns.types:  ",", ":", or ";"-separated column types
+   * @see SerDe#initialize(Configuration, Properties) 
    */
-  public void initialize(Configuration job, Properties tbl) throws SerDeException {
-    // Read the separator
-    String alt_sep = tbl.getProperty(Constants.SERIALIZATION_FORMAT);
-    separator = getByte(alt_sep, DefaultSeparator);
+  public void initialize(Configuration job, Properties tbl) 
+  throws SerDeException {
+
+    // Read the separators: We use 10 levels of separators by default, but we 
+    // should change this when we allow users to specify more than 10 levels 
+    // of separators through DDL.
+    separators = new byte[10];
+    separators[0] = getByte(tbl.getProperty(Constants.FIELD_DELIM, 
+                              tbl.getProperty(Constants.SERIALIZATION_FORMAT)),
+                              DefaultSeparators[0]);
+    separators[1] = getByte(tbl.getProperty(Constants.COLLECTION_DELIM),
+        DefaultSeparators[1]);
+    separators[2] = getByte(tbl.getProperty(Constants.MAPKEY_DELIM),
+        DefaultSeparators[2]);
+    for (int i=3; i<separators.length; i++) {
+      separators[i] = (byte)(i+1);
+    }
+    
+    nullString = tbl.getProperty(Constants.SERIALIZATION_NULL_FORMAT, "\\N");
+    nullSequence = new Text(nullString);
+    
+    String lastColumnTakesRestString = tbl.getProperty(
+        Constants.SERIALIZATION_LAST_COLUMN_TAKES_REST);
+    lastColumnTakesRest = (lastColumnTakesRestString != null 
+        && lastColumnTakesRestString.equalsIgnoreCase("true"));
+
 
     // Read the configuration parameters
     String columnNameProperty = tbl.getProperty("columns");
     // NOTE: if "columns.types" is missing, all columns will be of String type
     String columnTypeProperty = tbl.getProperty("columns.types");
     
-    nullString = tbl.getProperty(Constants.SERIALIZATION_NULL_FORMAT);
-    if (nullString == null) {
-      nullString = "\\N";
-    }
-    
-    String lastColumnTakesRestString = tbl.getProperty(Constants.SERIALIZATION_LAST_COLUMN_TAKES_REST);
-    lastColumnTakesRest = (lastColumnTakesRestString != null && lastColumnTakesRestString.equalsIgnoreCase("true"));
-    
     // Parse the configuration parameters
-    if (columnNameProperty != null) {
+    List<String> columnNames;
+    if (columnNameProperty != null && columnNameProperty.length()>0) {
       columnNames = Arrays.asList(columnNameProperty.split(","));
     } else {
       columnNames = new ArrayList<String>();
     }
-    if (columnTypeProperty != null) {
-      columnTypes = Arrays.asList(columnTypeProperty.split(":"));
-    } else {
+    if (columnTypeProperty == null) {
       // Default type: all string
-      columnTypes = new ArrayList<String>();
+      StringBuilder sb = new StringBuilder();
       for (int i = 0; i < columnNames.size(); i++) {
-        columnTypes.add(Constants.STRING_TYPE_NAME);
+        if (i>0) sb.append(":");
+        sb.append(Constants.STRING_TYPE_NAME);
       }
+      columnTypeProperty = sb.toString();
     }
+    
+    List<TypeInfo> columnTypes = 
+      TypeInfoUtils.getTypeInfosFromTypeString(columnTypeProperty);
+    
     if (columnNames.size() != columnTypes.size()) {
       throw new SerDeException(getClass().toString() 
           + ": columns has " + columnNames.size() 
-          + " elements while columns.types has " + columnTypes.size() + " elements!");
+          + " elements while columns.types has " + columnTypes.size()
+          + " elements!");
     }
     
     // Create the LazyObject for storing the rows
-    LazyObject[] lazyPrimitives = new LazyObject[columnNames.size()];
+    rowTypeInfo = TypeInfoFactory.getStructTypeInfo(columnNames, columnTypes);
+    cachedLazyStruct = (LazyStruct)LazyFactory.createLazyObject(rowTypeInfo);
+
     // Create the ObjectInspectors for the fields
-    ArrayList<ObjectInspector> columnObjectInspectors
-        = new ArrayList<ObjectInspector>(columnNames.size());  
-    for (int i=0; i<columnTypes.size(); i++) {
-      Class<?> primitiveClass = ObjectInspectorUtils.typeNameToClass.get( columnTypes.get(i) );
-      if (primitiveClass == null) {
-        throw new SerDeException(getClass().toString() 
-            + ": type " + columnTypes.get(i) + " not supported!");
-      }
-      columnObjectInspectors.add(ObjectInspectorFactory.
-          getStandardPrimitiveObjectInspector(primitiveClass));
-      lazyPrimitives[i] = LazyUtils.createLazyPrimitiveClass(primitiveClass);
-    }
-    
-    cachedObjectInspector = 
-        ObjectInspectorFactory.getLazySimpleStructObjectInspector(columnNames,
-            columnObjectInspectors);
+    cachedObjectInspector = LazyFactory.createLazyStructInspector(columnNames,
+            columnTypes, separators, nullSequence, lastColumnTakesRest);
     
-    cachedLazyStruct = new LazyStruct(lazyPrimitives, separator, 
-        new Text(nullString), lastColumnTakesRest);
     
-    LOG.debug("LazySimpleSerDe initialized with: columnNames=" + columnNames + " columnTypes=" 
-        + columnTypes + " separator=" + separator + " nullstring=" + nullString 
+    LOG.debug("LazySimpleSerDe initialized with: columnNames=" + columnNames
+        + " columnTypes=" + columnTypes + " separator=" 
+        + Arrays.asList(separators) + " nullstring=" + nullString 
         + " lastColumnTakesRest=" + lastColumnTakesRest);
   }
   
   // The object for storing row data
   LazyStruct cachedLazyStruct;
   
+  // The wrapper for byte array
+  ByteArrayRef byteArrayRef;
+  
   /**
    * Deserialize a row from the Writable to a LazyObject.
+   * @param field the Writable that contains the data
+   * @return  The deserialized row Object.
+   * @see SerDe#deserialize(Writable)
    */
   public Object deserialize(Writable field) throws SerDeException {
+    if (byteArrayRef == null) {
+      byteArrayRef = new ByteArrayRef();
+    }
     if (field instanceof BytesWritable) {
       BytesWritable b = (BytesWritable)field;
       // For backward-compatibility with hadoop 0.17
-      cachedLazyStruct.setAll(b.get(), 0, b.getSize());
+      byteArrayRef.setData(b.get());
+      cachedLazyStruct.init(byteArrayRef, 0, b.getSize());
     } else if (field instanceof Text) {
       Text t = (Text)field;
-      cachedLazyStruct.setAll(t.getBytes(), 0, t.getLength());
+      byteArrayRef.setData(t.getBytes());
+      cachedLazyStruct.init(byteArrayRef, 0, t.getLength());
     } else {
       throw new SerDeException(getClass().toString()  
           + ": expects either BytesWritable or Text object!");
@@ -190,6 +220,7 @@ public ObjectInspector getObjectInspector() throws SerDeException {
 
   /**
    * Returns the Writable Class after serialization.
+   * @see SerDe#getSerializedClass()
    */
   public Class<? extends Writable> getSerializedClass() {
     return Text.class;
@@ -198,34 +229,159 @@ public Class<? extends Writable> getSerializedClass() {
   Text serializeCache = new Text();
   /**
    * Serialize a row of data.
+   * @param obj          The row object
+   * @param objInspector The ObjectInspector for the row object
+   * @return             The serialized Writable object
+   * @see SerDe#serialize(Object, ObjectInspector)  
    */
-  public Writable serialize(Object obj, ObjectInspector objInspector) throws SerDeException {
+  public Writable serialize(Object obj, ObjectInspector objInspector) 
+      throws SerDeException {
 
-    // TODO: We can switch the serialization to be directly based on 
     if (objInspector.getCategory() != Category.STRUCT) {
       throw new SerDeException(getClass().toString() 
-          + " can only serialize struct types, but we got: " + objInspector.getTypeName());
+          + " can only serialize struct types, but we got: " 
+          + objInspector.getTypeName());
     }
-    StructObjectInspector soi = (StructObjectInspector) objInspector;
-    List<? extends StructField> fields = soi.getAllStructFieldRefs();
-    
+
     StringBuilder sb = new StringBuilder();
-    for(int i=0; i<fields.size(); i++) {
+
+    StructObjectInspector soi = (StructObjectInspector)objInspector;
+    List<? extends StructField> fields = soi.getAllStructFieldRefs();
+    List<Object> list = soi.getStructFieldsDataAsList(obj);
+    List<? extends StructField> declaredFields = 
+        (rowTypeInfo != null && rowTypeInfo.getAllStructFieldNames().size()>0)
+        ? ((StructObjectInspector)getObjectInspector()).getAllStructFieldRefs()
+        : null;
+        
+    for (int i=0; i<fields.size(); i++) {
+      // Append the separator if needed.
       if (i>0) {
-        sb.append((char)separator);
+        sb.append((char)separators[0]);
+      }
+      // Get the field objectInspector and the field object.
+      ObjectInspector foi = fields.get(i).getFieldObjectInspector();
+      Object f = (list == null ? null : list.get(i));
+
+      if (declaredFields != null && i >= declaredFields.size()) {
+        throw new SerDeException(
+            "Error: expecting " + declaredFields.size() 
+            + " but asking for field " + i + "\n" + "data=" + obj + "\n"
+            + "tableType=" + rowTypeInfo.toString() + "\n"
+            + "dataType=" 
+            + TypeInfoUtils.getTypeInfoFromObjectInspector(objInspector));
       }
-      StructField field = fields.get(i);
-      Object fieldData = soi.getStructFieldData(obj, field);
-      if (field.getFieldObjectInspector().getCategory() == Category.PRIMITIVE) {
-        // For primitive object, serialize to plain string
-        sb.append(fieldData == null ? nullString : fieldData.toString());
+      
+      // If the field that is passed in is a primitive, then we serialize the
+      // primitive object.
+      if (foi.getCategory().equals(Category.PRIMITIVE)) {
+        sb.append(f == null ? nullString : f.toString());
       } else {
-        // For complex object, serialize to JSON format
-        sb.append(SerDeUtils.getJSONString(fieldData, field.getFieldObjectInspector()));
+        // If the field is not declared (no schema was given at 
+        // initialization), or the field is declared as a primitive in 
+        // initialization, serialize the data to JSON string.
+        // Otherwise serialize the data in the delimited way.
+        if (declaredFields == null || 
+            declaredFields.get(i).getFieldObjectInspector().getCategory()
+            .equals(Category.PRIMITIVE)) {
+          sb.append(SerDeUtils.getJSONString(f, foi));
+        } else {
+          serialize(sb, f, foi, separators, 1, nullString);
+        }
       }
     }
     serializeCache.set(sb.toString());
     return serializeCache;
   }
 
+  
+  /**
+   * Serialize the row into the StringBuilder.
+   * @param sb  The StringBuilder to store the serialized data.
+   * @param obj The object for the current field.
+   * @param objInspector  The ObjectInspector for the current Object.
+   * @param separators    The separators array.
+   * @param level         The current level of separator.
+   * @param nullString    The byte sequence representing the NULL value.
+   */
+  private void serialize(StringBuilder sb, Object obj, 
+      ObjectInspector objInspector, byte[] separators, int level,
+      String nullString) {
+    
+    if (obj == null) {
+      sb.append(nullString);
+      return;
+    }
+    
+    switch (objInspector.getCategory()) {
+      case PRIMITIVE: {
+        sb.append(obj.toString());
+        return;
+      }
+      case LIST: {
+        char separator = (char)separators[level];
+        ListObjectInspector loi = (ListObjectInspector)objInspector;
+        List<?> list = loi.getList(obj);
+        ObjectInspector eoi = loi.getListElementObjectInspector();
+        if (list == null) {
+          sb.append(nullString);
+        } else {
+          for (int i=0; i<list.size(); i++) {
+            if (i>0) {
+              sb.append((char)separator);
+            }
+            serialize(sb, list.get(i), eoi, separators, level+1, nullString);
+          }
+        }
+        return;
+      }
+      case MAP: {
+        char separator = (char)separators[level];
+        char keyValueSeparator = (char)separators[level+1];
+        MapObjectInspector moi = (MapObjectInspector)objInspector;
+        ObjectInspector koi = moi.getMapKeyObjectInspector();
+        ObjectInspector voi = moi.getMapValueObjectInspector();
+        
+        Map<?, ?> map = moi.getMap(obj);
+        if (map == null) {
+          sb.append(nullString);
+        } else {
+          boolean first = true;
+          for (Map.Entry<?, ?> entry: map.entrySet()) {
+            if (first) {
+              first = false;
+            } else {
+              sb.append((char)separator);
+            }
+            serialize(sb, entry.getKey(), koi, separators, level+2, 
+                nullString);
+            sb.append((char)keyValueSeparator);
+            serialize(sb, entry.getValue(), voi, separators, level+2, 
+                nullString);
+          }
+        }
+        return;
+      }
+      case STRUCT: {
+        char separator = (char)separators[level];
+        StructObjectInspector soi = (StructObjectInspector)objInspector;
+        List<? extends StructField> fields = soi.getAllStructFieldRefs();
+        List<Object> list = soi.getStructFieldsDataAsList(obj);
+        if (list == null) {
+          sb.append(nullString);
+        } else {
+          for (int i=0; i<list.size(); i++) {
+            if (i>0) {
+              sb.append((char)separator);
+            }
+            serialize(sb, list.get(i), fields.get(i).getFieldObjectInspector(),
+                separators, level+1, nullString);
+          }
+        }
+        return;
+      }
+    }
+    
+    throw new RuntimeException("Unknown category type: "
+        + objInspector.getCategory());
+  }
 }
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyString.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyString.java
index 67ae33fd0f..1650dd4de6 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyString.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyString.java
@@ -27,18 +27,16 @@
 public class LazyString extends LazyPrimitive<String> {
 
   public LazyString() {
-    super(String.class);
   }
 
   @Override
-  public String getPrimitiveObject() {
+  public void init(ByteArrayRef bytes, int start, int length) {
     // In the future, we should allow returning a Text Object to save the UTF-8
     // decoding/encoding, and the creation of new String object.
-    if (bytes == null) return null;
     try {
-      return Text.decode(bytes, start, length);
+      data = Text.decode(bytes.getData(), start, length);
     } catch (CharacterCodingException e) {
-      return null;
+      data = null;
     }
   }
 
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyStruct.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyStruct.java
index cb2fa43f00..08178fdd88 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyStruct.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyStruct.java
@@ -17,95 +17,117 @@
  */
 package org.apache.hadoop.hive.serde2.lazy;
 
-import java.nio.charset.CharacterCodingException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 import org.apache.hadoop.io.Text;
 
 
 /**
  * LazyObject for storing a struct.
  * The field of a struct can be primitive or non-primitive.
- * 
+ *
+ * LazyStruct does not deal with the case of a NULL struct. That is handled
+ * by LazySimpleStructObjectInspector.
  */
-public class LazyStruct extends LazyObject {
+public class LazyStruct extends LazyNonPrimitive {
 
-  
   private static Log LOG = LogFactory.getLog(LazyStruct.class.getName());
+
+  /**
+   * Whether the data is already parsed or not.
+   */
+  boolean parsed;
+
+  /**
+   * The start positions of struct fields.
+   * Only valid when the data is parsed.
+   * Note that startPosition[arrayLength] = begin + length + 1;
+   * that makes sure we can use the same formula to compute the
+   * length of each element of the array.
+   */
+  int[] startPosition;
   
+  /**
+   * The fields of the struct.
+   */
   LazyObject[] fields;
-  boolean[] fieldIsPrimitive;
-  
-  byte separator;
-  Text nullSequence;
-  boolean lastColumnTakesAll;
-  
-  boolean parsed;
+  /**
+   * Whether init() has been called on the field or not.
+   */
+  boolean[] fieldInited;
   
   /**
-   * Create a new LazyStruct Object.
-   * @param fields     The field LazyObjects
-   * @param separator  The separator for delimiting the fields in the byte[]
-   * @param nullSequence  The sequence for null value
-   * @param lastColumnTakesAll  whether the additional fields should be all put into the last column
-   *                            in case the data contains more columns than the schema.  
+   * Construct a LazyStruct object with the TypeInfo.
+   * @param typeInfo  the TypeInfo representing the type of this LazyStruct.
    */
-  public LazyStruct(LazyObject[] fields, byte separator,
-      Text nullSequence, boolean lastColumnTakesAll) {
-    this.fields = fields;
-    this.separator = separator;
-    this.nullSequence = nullSequence;
-    this.lastColumnTakesAll = lastColumnTakesAll; 
-      
-    parsed = false;
-    fieldIsPrimitive = new boolean[fields.length];
-    for(int i=0; i<fields.length; i++) {
-      fieldIsPrimitive[i] = (fields[i] instanceof LazyPrimitive);
-    }
+  public LazyStruct(TypeInfo typeInfo) {
+    super(typeInfo);
   }
   
   /**
    * Set the row data for this LazyStruct.
+   * @see LazyObject#init(ByteArrayRef, int, int)
    */
-  protected void setAll(byte[] bytes, int start, int length) {
-    super.setAll(bytes, start, length);
+  public void init(ByteArrayRef bytes, int start, int length) {
+    super.init(bytes, start, length);
     parsed = false;
   }
-  
-  
+
   boolean missingFieldWarned = false;
   boolean extraFieldWarned = false;
   /**
    * Parse the byte[] and fill each field.
+   * @param separator  The separator for delimiting the fields in the byte[]
+   * @param nullSequence  The sequence for the NULL value
+   * @param lastColumnTakesRest  Whether the additional fields should be all 
+   *                             put into the last column in case the data 
+   *                             contains more columns than the schema.  
    */
-  private void parse() {
+  private void parse(byte separator, Text nullSequence, 
+      boolean lastColumnTakesRest) {
+    
+    if (fields == null) {
+      List<TypeInfo> fieldTypeInfos = typeInfo.getAllStructFieldTypeInfos();
+      fields = new LazyObject[fieldTypeInfos.size()];
+      for (int i = 0 ; i < fields.length; i++) {
+        fields[i] = LazyFactory.createLazyObject(fieldTypeInfos.get(i));
+      }
+      fieldInited = new boolean[fields.length];      
+      // Extra element to make sure we have the same formula to compute the 
+      // length of each element of the array. 
+      startPosition = new int[fields.length+1];
+    }
     
     int structByteEnd = start + length;
     int fieldId = 0;
     int fieldByteBegin = start;
     int fieldByteEnd = start;
+    byte[] bytes = this.bytes.getData();
     
     // Go through all bytes in the byte[]
     while (fieldByteEnd <= structByteEnd) {
       if (fieldByteEnd == structByteEnd || bytes[fieldByteEnd] == separator) {
-        // end of field reached
-        if (lastColumnTakesAll && fieldId == fields.length - 1) {
+        // Reached the end of a field?
+        if (lastColumnTakesRest && fieldId == fields.length - 1) {
           fieldByteEnd = structByteEnd;
         }
-        // Test the length first so in most cases we avoid doing a byte[] comparison.
-        int fieldLength = fieldByteEnd - fieldByteBegin;
-        if (fieldLength == nullSequence.getLength()
-            && LazyUtils.compare(bytes, fieldByteBegin, fieldLength,
-            nullSequence.getBytes(), 0, nullSequence.getLength()) == 0) {
-          fields[fieldId].setAll(null, 0, 0);
-        } else {
-          fields[fieldId].setAll(bytes, fieldByteBegin,
-              fieldByteEnd - fieldByteBegin);
-        }
+        startPosition[fieldId] = fieldByteBegin;
         fieldId ++;
         if (fieldId == fields.length || fieldByteEnd == structByteEnd) {
-          // all fields have been parsed, or all bytes have been parsed 
+          // All fields have been parsed, or bytes have been parsed.
+          // We need to set the startPosition of fields.length to ensure we
+          // can use the same formula to calculate the length of each field.
+          // For missing fields, their starting positions will all be the same,
+          // which will make their lengths to be -1 and uncheckedGetField will
+          // return these fields as NULLs.
+          for (int i = fieldId; i <= fields.length; i++) {
+            startPosition[i] = fieldByteEnd + 1;
+          }          
           break;
         }
         fieldByteBegin = fieldByteEnd + 1;
@@ -116,21 +138,18 @@ private void parse() {
     // Extra bytes at the end?
     if (!extraFieldWarned && fieldByteEnd < structByteEnd) {
       extraFieldWarned = true;
-      LOG.warn("Extra bytes detected at the end of the row! Ignoring similar problems.");
+      LOG.warn("Extra bytes detected at the end of the row! Ignoring similar "
+          + "problems.");
     }
     
     // Missing fields?
     if (!missingFieldWarned && fieldId < fields.length) {
       missingFieldWarned = true;
-      LOG.warn("Missing fields! Expected " + fields.length + " fields but only got "
-          + fieldId + "! Ignoring similar problems.");
-    }
-    
-    // Fill all missing fields with nulls.
-    for(; fieldId < fields.length; fieldId ++) {
-      fields[fieldId].setAll(null, 0, 0);
+      LOG.warn("Missing fields! Expected " + fields.length + " fields but "
+          + "only got " + fieldId + "! Ignoring similar problems.");
     }
     
+    Arrays.fill(fieldInited, false);
     parsed = true;
   }
   
@@ -143,17 +162,80 @@ private void parse() {
    * directly use the Object instead of going through 
    * Object PrimitiveObjectInspector.get(Object).  
    * 
-   * @param i  the field ID
-   * @return   the field as a LazyObject
+   * NOTE: separator and nullSequence has to be the same each time 
+   * this method is called.  These two parameters are used only once to parse
+   * each record.
+   * 
+   * @param fieldID  The field ID
+   * @param separator  The separator for delimiting the fields in the byte[]
+   * @param nullSequence  The sequence for null value
+   * @param lastColumnTakesRest  Whether the additional fields should be all 
+   *                             put into the last column in case the data 
+   *                             contains more columns than the schema.  
+   * @return         The field as a LazyObject
    */
-  public Object getField(int i) {
+  public Object getField(int fieldID, byte separator, Text nullSequence, 
+      boolean lastColumnTakesRest) {
     if (!parsed) {
-      parse();
+      parse(separator, nullSequence, lastColumnTakesRest);
+    }
+    return uncheckedGetField(fieldID, nullSequence);
+  }
+
+  /**
+   * Get the field out of the row without checking parsed.
+   * This is called by both getField and getFieldsAsList.
+   * @param fieldID  The id of the field starting from 0.
+   * @param nullSequence  The sequence representing NULL value.
+   * @return  The value of the field 
+   */
+  private Object uncheckedGetField(int fieldID, Text nullSequence) {
+    // Test the length first so in most cases we avoid doing a byte[] 
+    // comparison.
+    int fieldByteBegin = startPosition[fieldID];
+    int fieldLength = startPosition[fieldID+1] - startPosition[fieldID] - 1;
+    if ((fieldLength < 0)
+        || (fieldLength == nullSequence.getLength()
+           && LazyUtils.compare(bytes.getData(), fieldByteBegin, fieldLength,
+          nullSequence.getBytes(), 0, nullSequence.getLength()) == 0)) {
+      return null;
     }
-    if (!fieldIsPrimitive[i]) {
-      return fields[i];
+    if (!fieldInited[fieldID]) {
+      fieldInited[fieldID] = true;
+      fields[fieldID].init(bytes, fieldByteBegin, fieldLength);
+    }
+    return fields[fieldID].getObject();
+  }
+
+  ArrayList<Object> cachedList;
+  /**
+   * Get the values of the fields as an ArrayList.
+   * @param separator  The separator for delimiting the fields in the byte[]
+   * @param nullSequence         The sequence for the NULL value
+   * @param lastColumnTakesRest  Whether the additional fields should be all 
+   *                             put into the last column in case the data 
+   *                             contains more columns than the schema.  
+   * @return The values of the fields as an ArrayList.
+   */
+  public ArrayList<Object> getFieldsAsList(byte separator, Text nullSequence, 
+      boolean lastColumnTakesRest) {
+    if (!parsed) {
+      parse(separator, nullSequence, lastColumnTakesRest);
+    }
+    if (cachedList == null) {
+      cachedList = new ArrayList<Object>();
     } else {
-      return ((LazyPrimitive)fields[i]).getPrimitiveObject();
+      cachedList.clear();
+    }
+    for (int i=0; i<fields.length; i++) {
+      cachedList.add(uncheckedGetField(i, nullSequence));
     }
+    return cachedList;
   }
+  
+  @Override
+  public Object getObject() {
+    return this;
+  }
+
 }
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java
index 1b5b31ccd4..374154a496 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java
@@ -18,32 +18,10 @@
 package org.apache.hadoop.hive.serde2.lazy;
 
 import java.nio.charset.CharacterCodingException;
-
 import org.apache.hadoop.io.Text;
 
 public class LazyUtils {
 
-  /**
-   * Create a lazy primitive class given the java class. 
-   */
-  public static LazyPrimitive<?> createLazyPrimitiveClass(Class<?> c) {
-    if (String.class.equals(c)) {
-      return new LazyString();
-    } else if (Integer.class.equals(c)) {
-      return new LazyInteger();
-    } else if (Double.class.equals(c)) {
-      return new LazyDouble();
-    } else if (Byte.class.equals(c)) {
-      return new LazyByte();
-    } else if (Short.class.equals(c)) {
-      return new LazyShort();
-    } else if (Long.class.equals(c)) {
-      return new LazyLong();
-    } else {
-      return null;
-    }
-  }
-
   /**
    * Returns the digit represented by character b.
    * @param b  The ascii code of the character
@@ -90,6 +68,10 @@ public static int compare(byte[] b1, int start1, int length1, byte[] b2, int sta
   
   /**
    * Convert a UTF-8 byte array to String.
+   * @param bytes  The byte[] containing the UTF-8 String.
+   * @param start  The start position inside the bytes.
+   * @param length The length of the data, starting from "start"
+   * @return The unicode String
    */
   public static String convertToString(byte[] bytes, int start, int length) {
     try {
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/LazyListObjectInspector.java b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/LazyListObjectInspector.java
new file mode 100644
index 0000000000..e1346f8e81
--- /dev/null
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/LazyListObjectInspector.java
@@ -0,0 +1,97 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.serde2.objectinspector;
+
+import java.util.List;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hive.serde2.lazy.LazyArray;
+import org.apache.hadoop.io.Text;
+
+/**
+ * LazyListObjectInspector works on array data that is stored in LazyArray.
+ * 
+ * Always use the ObjectInspectorFactory to create new ObjectInspector objects, instead
+ * of directly creating an instance of this class.
+ */
+public class LazyListObjectInspector implements ListObjectInspector {
+
+  public static final Log LOG = LogFactory.getLog(LazyListObjectInspector.class.getName());
+  
+  ObjectInspector listElementObjectInspector;
+  
+  byte separator;
+  Text nullSequence;
+  
+  /** Call ObjectInspectorFactory.getLazySimpleListObjectInspector instead.
+   */
+  protected LazyListObjectInspector(ObjectInspector listElementObjectInspector, 
+      byte separator, Text nullSequence) {
+    this.listElementObjectInspector = listElementObjectInspector;
+    this.separator = separator;
+    this.nullSequence = nullSequence;
+  }
+
+  @Override
+  public final Category getCategory() {
+    return Category.LIST;
+  }
+
+  // without data
+  @Override
+  public ObjectInspector getListElementObjectInspector() {
+    return listElementObjectInspector;
+  }
+  
+  // with data
+  @Override
+  public Object getListElement(Object data, int index) {
+    if (data == null) {
+      return null;
+    }
+    LazyArray array = (LazyArray) data;
+    return array.getListElementObject(index, separator, nullSequence);
+  }
+  
+  @Override
+  public int getListLength(Object data) {
+    if (data == null) {
+      return -1;
+    }
+    LazyArray array = (LazyArray) data;
+    return array.getListLength(separator, nullSequence);
+  }
+  
+  @Override
+  public List<?> getList(Object data) {
+    if (data == null) {
+      return null;
+    }
+    LazyArray array = (LazyArray) data;
+    return array.getList(separator, nullSequence);
+  }
+
+  @Override
+  public String getTypeName() {
+    return org.apache.hadoop.hive.serde.Constants.LIST_TYPE_NAME 
+        + "<" + listElementObjectInspector.getTypeName() + ">";
+  }
+
+}
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/LazyMapObjectInspector.java b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/LazyMapObjectInspector.java
new file mode 100644
index 0000000000..e3688f3405
--- /dev/null
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/LazyMapObjectInspector.java
@@ -0,0 +1,104 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.serde2.objectinspector;
+
+import java.util.Map;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hive.serde2.lazy.LazyMap;
+import org.apache.hadoop.io.Text;
+
+/**
+ * LazyMapObjectInspector works on struct data that is stored in LazyStruct.
+ * 
+ * Always use the ObjectInspectorFactory to create new ObjectInspector objects, instead
+ * of directly creating an instance of this class.
+ */
+public class LazyMapObjectInspector implements MapObjectInspector {
+
+  public static final Log LOG = LogFactory.getLog(LazyMapObjectInspector.class.getName());
+  
+  ObjectInspector mapKeyObjectInspector;
+  ObjectInspector mapValueObjectInspector;
+  
+  byte itemSeparator;
+  byte keyValueSeparator;  
+  Text nullSequence;
+  
+  /** Call ObjectInspectorFactory.getStandardListObjectInspector instead.
+   */
+  protected LazyMapObjectInspector(ObjectInspector mapKeyObjectInspector,
+      ObjectInspector mapValueObjectInspector,
+      byte itemSeparator, byte keyValueSeparator, Text nullSequence) {
+    this.mapKeyObjectInspector = mapKeyObjectInspector;
+    this.mapValueObjectInspector = mapValueObjectInspector;
+
+    this.itemSeparator = itemSeparator;
+    this.keyValueSeparator = keyValueSeparator;
+    this.nullSequence = nullSequence;
+  }
+
+  @Override
+  public final Category getCategory() {
+    return Category.MAP;
+  }
+
+  @Override
+  public String getTypeName() {
+    return org.apache.hadoop.hive.serde.Constants.MAP_TYPE_NAME 
+        + "<" + mapKeyObjectInspector.getTypeName() + "," 
+        + mapValueObjectInspector.getTypeName() + ">";
+  }
+
+  @Override
+  public ObjectInspector getMapKeyObjectInspector() {
+    return mapKeyObjectInspector;
+  }
+
+  @Override
+  public ObjectInspector getMapValueObjectInspector() {
+    return mapValueObjectInspector;
+  }
+
+  @Override
+  public Object getMapValueElement(Object data, Object key) {
+    if (data == null) {
+      return null;
+    }
+    return ((LazyMap)data).getMapValueElement(itemSeparator, keyValueSeparator, nullSequence, key);
+  }
+
+  @Override
+  public Map<?, ?> getMap(Object data) {
+    if (data == null) {
+      return null;
+    }
+    return ((LazyMap)data).getMap(itemSeparator, keyValueSeparator, nullSequence);
+  }
+
+  @Override
+  public int getMapSize(Object data) {
+    if (data == null) {
+      return -1;
+    }
+    return ((LazyMap)data).getMapSize(itemSeparator, keyValueSeparator, nullSequence);
+  }
+  
+}
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/LazySimpleStructObjectInspector.java b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/LazySimpleStructObjectInspector.java
index cc301006ab..7cfac48a49 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/LazySimpleStructObjectInspector.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/LazySimpleStructObjectInspector.java
@@ -24,10 +24,10 @@
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hive.serde2.lazy.LazyStruct;
+import org.apache.hadoop.io.Text;
 
 /**
  * LazySimpleStructObjectInspector works on struct data that is stored in LazyStruct.
- * It only supports primitive types as its fields for simplicity and efficiency. 
  * 
  * The names of the struct fields and the internal structure of the struct fields
  * are specified in the ctor of the LazySimpleStructObjectInspector.
@@ -67,28 +67,43 @@ public String toString() {
   
   protected List<MyField> fields;
   
+  @Override
   public String getTypeName() {
     return ObjectInspectorUtils.getStandardStructTypeName(this);
   }
   
+  
+  byte separator;
+  Text nullSequence;  
+  boolean lastColumnTakesRest;
+  
   /** Call ObjectInspectorFactory.getLazySimpleStructObjectInspector instead.
    */
-  protected LazySimpleStructObjectInspector(List<String> structFieldNames, List<ObjectInspector> structFieldObjectInspectors) {
-    init(structFieldNames, structFieldObjectInspectors);
+  protected LazySimpleStructObjectInspector(List<String> structFieldNames, List<ObjectInspector> structFieldObjectInspectors,
+      byte separator, Text nullSequence, boolean lastColumnTakesRest) {
+    init(structFieldNames, structFieldObjectInspectors, separator, nullSequence, lastColumnTakesRest);
   }
-  protected void init(List<String> structFieldNames, List<ObjectInspector> structFieldObjectInspectors) {
+  protected void init(List<String> structFieldNames, List<ObjectInspector> structFieldObjectInspectors,
+      byte separator, Text nullSequence, boolean lastColumnTakesRest) {
     assert(structFieldNames.size() == structFieldObjectInspectors.size());
     
+    this.separator = separator;
+    this.nullSequence = nullSequence;
+    this.lastColumnTakesRest = lastColumnTakesRest;
+    
     fields = new ArrayList<MyField>(structFieldNames.size()); 
     for(int i=0; i<structFieldNames.size(); i++) {
       fields.add(new MyField(i, structFieldNames.get(i), structFieldObjectInspectors.get(i)));
     }
   }
   
-  protected LazySimpleStructObjectInspector(List<StructField> fields) {
-    init(fields);
+  protected LazySimpleStructObjectInspector(List<StructField> fields, byte separator, Text nullSequence) {
+    init(fields, separator, nullSequence);
   }
-  protected void init(List<StructField> fields) {
+  protected void init(List<StructField> fields, byte separator, Text nullSequence) {
+    this.separator = separator;
+    this.nullSequence = nullSequence;
+    
     this.fields = new ArrayList<MyField>(fields.size()); 
     for(int i=0; i<fields.size(); i++) {
       this.fields.add(new MyField(i, fields.get(i).getFieldName(), fields.get(i).getFieldObjectInspector()));
@@ -96,20 +111,23 @@ protected void init(List<StructField> fields) {
   }
 
   
+  @Override
   public final Category getCategory() {
     return Category.STRUCT;
   }
 
   // Without Data
+  @Override
   public StructField getStructFieldRef(String fieldName) {
     return ObjectInspectorUtils.getStandardStructFieldRef(fieldName, fields);
   }
+  @Override
   public List<? extends StructField> getAllStructFieldRefs() {
     return fields;
   }
 
   // With Data
-  @SuppressWarnings("unchecked")
+  @Override
   public Object getStructFieldData(Object data, StructField fieldRef) {
     if (data == null) {
       return null;
@@ -120,7 +138,7 @@ public Object getStructFieldData(Object data, StructField fieldRef) {
     int fieldID = f.getFieldID();
     assert(fieldID >= 0 && fieldID < fields.size());
     
-    return struct.getField(fieldID);
+    return struct.getField(fieldID, separator, nullSequence, lastColumnTakesRest);
   }
 
   @Override
@@ -128,12 +146,8 @@ public List<Object> getStructFieldsDataAsList(Object data) {
     if (data == null) {
       return null;
     }
-    List<Object> fieldsData = new ArrayList<Object>(fields.size());
     LazyStruct struct = (LazyStruct)data;
-    for (int i=0; i<fields.size(); i++) {
-      fieldsData.add(struct.getField(i));
-    }
-    return fieldsData;
+    return struct.getFieldsAsList(separator, nullSequence, lastColumnTakesRest);
   }
 
 }
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/MapObjectInspector.java b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/MapObjectInspector.java
index c7fe9593e7..8a82138f67 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/MapObjectInspector.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/MapObjectInspector.java
@@ -39,4 +39,8 @@ public interface MapObjectInspector extends ObjectInspector {
    */
   public Map<?,?> getMap(Object data);
 
+  /**
+   * returns -1 for NULL map.
+   */
+  public int getMapSize(Object data);
 }
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorFactory.java b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorFactory.java
index 01695a9239..c88d6b7cc4 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorFactory.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorFactory.java
@@ -27,12 +27,18 @@
 import java.util.List;
 import java.util.Map;
 
+import org.apache.hadoop.io.Text;
+
 
 /**
  * ObjectInspectorFactory is the primary way to create new ObjectInspector instances.
  * 
  * SerDe classes should call the static functions in this library to create an ObjectInspector
- * to return to the caller of SerDe2.getObjectInspector(). 
+ * to return to the caller of SerDe2.getObjectInspector().
+ * 
+ * The reason of having caches here is that ObjectInspector is because ObjectInspectors do
+ * not have an internal state - so ObjectInspectors with the same construction parameters should
+ * result in exactly the same ObjectInspector.
  */
 public class ObjectInspectorFactory {
 
@@ -181,19 +187,60 @@ public static StandardStructObjectInspector getStandardStructObjectInspector(Lis
     return result;
   }
 
-  static HashMap<ArrayList<List<?>>, LazySimpleStructObjectInspector> cachedLazySimpleStructObjectInspector =
-    new HashMap<ArrayList<List<?>>, LazySimpleStructObjectInspector>(); 
-  public static LazySimpleStructObjectInspector getLazySimpleStructObjectInspector(List<String> structFieldNames, List<ObjectInspector> structFieldObjectInspectors) {
-    ArrayList<List<?>> signature = new ArrayList<List<?>>();
+  static HashMap<ArrayList<Object>, LazySimpleStructObjectInspector> cachedLazySimpleStructObjectInspector =
+    new HashMap<ArrayList<Object>, LazySimpleStructObjectInspector>(); 
+  public static LazySimpleStructObjectInspector getLazySimpleStructObjectInspector(List<String> structFieldNames, 
+      List<ObjectInspector> structFieldObjectInspectors, byte separator, Text nullSequence,
+      boolean lastColumnTakesRest) {
+    ArrayList<Object> signature = new ArrayList<Object>();
     signature.add(structFieldNames);
     signature.add(structFieldObjectInspectors);
+    signature.add(Byte.valueOf(separator));
+    signature.add(nullSequence.toString());
+    signature.add(Boolean.valueOf(lastColumnTakesRest));
     LazySimpleStructObjectInspector result = cachedLazySimpleStructObjectInspector.get(signature);
     if (result == null) {
-      result = new LazySimpleStructObjectInspector(structFieldNames, structFieldObjectInspectors);
+      result = new LazySimpleStructObjectInspector(structFieldNames, structFieldObjectInspectors, 
+          separator, nullSequence, lastColumnTakesRest);
       cachedLazySimpleStructObjectInspector.put(signature, result);
     }
     return result;
   }
+
+  static HashMap<ArrayList<Object>, LazyListObjectInspector> cachedLazySimpleListObjectInspector =
+    new HashMap<ArrayList<Object>, LazyListObjectInspector>(); 
+  public static LazyListObjectInspector getLazySimpleListObjectInspector( 
+      ObjectInspector listElementObjectInspector, byte separator, Text nullSequence) {
+    ArrayList<Object> signature = new ArrayList<Object>();
+    signature.add(listElementObjectInspector);
+    signature.add(Byte.valueOf(separator));
+    signature.add(nullSequence.toString());
+    LazyListObjectInspector result = cachedLazySimpleListObjectInspector.get(signature);
+    if (result == null) {
+      result = new LazyListObjectInspector(listElementObjectInspector, 
+          separator, nullSequence);
+      cachedLazySimpleListObjectInspector.put(signature, result);
+    }
+    return result;
+  }
+  
+  static HashMap<ArrayList<Object>, LazyMapObjectInspector> cachedLazySimpleMapObjectInspector =
+    new HashMap<ArrayList<Object>, LazyMapObjectInspector>(); 
+  public static LazyMapObjectInspector getLazySimpleMapObjectInspector( 
+      ObjectInspector mapKeyObjectInspector, ObjectInspector mapValueObjectInspector, 
+      byte itemSeparator, byte keyValueSeparator, Text nullSequence) {
+    ArrayList<Object> signature = new ArrayList<Object>();
+    signature.add(mapKeyObjectInspector);
+    signature.add(mapValueObjectInspector);
+    signature.add(nullSequence.toString());
+    LazyMapObjectInspector result = cachedLazySimpleMapObjectInspector.get(signature);
+    if (result == null) {
+      result = new LazyMapObjectInspector(mapKeyObjectInspector,
+          mapValueObjectInspector, itemSeparator, keyValueSeparator, nullSequence);
+      cachedLazySimpleMapObjectInspector.put(signature, result);
+    }
+    return result;
+  }
   
   static HashMap<List<StructObjectInspector>, UnionStructObjectInspector> cachedUnionStructObjectInspector =
     new HashMap<List<StructObjectInspector>, UnionStructObjectInspector>(); 
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/StandardMapObjectInspector.java b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/StandardMapObjectInspector.java
index 75c5a3aaab..42d22f4ef2 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/StandardMapObjectInspector.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/StandardMapObjectInspector.java
@@ -59,7 +59,8 @@ public Object getMapValueElement(Object data, Object key) {
     Map<?,?> map = (Map<?,?>)data;
     return map.get(key);
   }
-  int getMapSize(Object data) {
+  
+  public int getMapSize(Object data) {
     if (data == null) return -1;
     Map<?,?> map = (Map<?,?>)data;
     return map.size();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/ListTypeInfo.java b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ListTypeInfo.java
similarity index 94%
rename from ql/src/java/org/apache/hadoop/hive/ql/typeinfo/ListTypeInfo.java
rename to serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ListTypeInfo.java
index 2d3f742a46..389600e541 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/ListTypeInfo.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ListTypeInfo.java
@@ -16,10 +16,9 @@
  * limitations under the License.
  */
 
-package org.apache.hadoop.hive.ql.typeinfo;
+package org.apache.hadoop.hive.serde2.typeinfo;
 
 import java.io.Serializable;
-import java.util.List;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
 
 /** A List Type has homogeneous elements.  All elements of the List has
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/MapTypeInfo.java b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/MapTypeInfo.java
similarity index 94%
rename from ql/src/java/org/apache/hadoop/hive/ql/typeinfo/MapTypeInfo.java
rename to serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/MapTypeInfo.java
index 804e691679..d73c2eec5f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/MapTypeInfo.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/MapTypeInfo.java
@@ -16,10 +16,9 @@
  * limitations under the License.
  */
 
-package org.apache.hadoop.hive.ql.typeinfo;
+package org.apache.hadoop.hive.serde2.typeinfo;
 
 import java.io.Serializable;
-import java.util.List;
 
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/PrimitiveTypeInfo.java b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/PrimitiveTypeInfo.java
similarity index 84%
rename from ql/src/java/org/apache/hadoop/hive/ql/typeinfo/PrimitiveTypeInfo.java
rename to serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/PrimitiveTypeInfo.java
index 2a9eb73bbe..cc490374fd 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/PrimitiveTypeInfo.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/PrimitiveTypeInfo.java
@@ -16,12 +16,9 @@
  * limitations under the License.
  */
 
-package org.apache.hadoop.hive.ql.typeinfo;
+package org.apache.hadoop.hive.serde2.typeinfo;
 
 import java.io.Serializable;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-import org.apache.commons.lang.StringUtils;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
 
@@ -36,7 +33,7 @@ public class PrimitiveTypeInfo extends TypeInfo implements Serializable {
 
   private static final long serialVersionUID = 1L;
   
-  Class primitiveClass;
+  Class<?> primitiveClass;
   
   /** For java serialization use only.
    */
@@ -49,13 +46,13 @@ public String getTypeName() {
   
   /** For java serialization use only.
    */
-  public void setPrimitiveClass(Class primitiveClass) {
+  public void setPrimitiveClass(Class<?> primitiveClass) {
     this.primitiveClass = primitiveClass;
   }
   
   /** For TypeInfoFactory use only.
    */
-  PrimitiveTypeInfo(Class primitiveClass) {
+  PrimitiveTypeInfo(Class<?> primitiveClass) {
     this.primitiveClass = primitiveClass;
   }
   
@@ -63,7 +60,7 @@ public Category getCategory() {
     return Category.PRIMITIVE;
   }
 
-  public Class getPrimitiveClass() {
+  public Class<?> getPrimitiveClass() {
     return primitiveClass;
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/StructTypeInfo.java b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/StructTypeInfo.java
similarity index 90%
rename from ql/src/java/org/apache/hadoop/hive/ql/typeinfo/StructTypeInfo.java
rename to serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/StructTypeInfo.java
index 245297aeb6..ac772d993b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/StructTypeInfo.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/StructTypeInfo.java
@@ -16,15 +16,12 @@
  * limitations under the License.
  */
 
-package org.apache.hadoop.hive.ql.typeinfo;
+package org.apache.hadoop.hive.serde2.typeinfo;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.List;
 
-import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
-import org.apache.hadoop.hive.serde2.objectinspector.StructField;
-import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
 
 /** StructTypeInfo represents the TypeInfo of a struct.
@@ -48,14 +45,14 @@ public StructTypeInfo() {}
 
   public String getTypeName() {
     StringBuilder sb = new StringBuilder();
-    sb.append("struct{");
+    sb.append("struct<");
     for(int i=0; i<allStructFieldNames.size(); i++) {
       if (i>0) sb.append(",");
       sb.append(allStructFieldNames.get(i));
       sb.append(":");
       sb.append(allStructFieldTypeInfos.get(i).getTypeName());
     }
-    sb.append("}");
+    sb.append(">");
     return sb.toString();
   }
   
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/TypeInfo.java b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java
similarity index 93%
rename from ql/src/java/org/apache/hadoop/hive/ql/typeinfo/TypeInfo.java
rename to serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java
index 1ab0719707..d1b8f7b042 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/TypeInfo.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java
@@ -16,9 +16,10 @@
  * limitations under the License.
  */
 
-package org.apache.hadoop.hive.ql.typeinfo;
+package org.apache.hadoop.hive.serde2.typeinfo;
 
-import java.io.Serializable;import java.util.List;
+import java.io.Serializable;
+import java.util.List;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
 
 /**
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/TypeInfoFactory.java b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java
similarity index 94%
rename from ql/src/java/org/apache/hadoop/hive/ql/typeinfo/TypeInfoFactory.java
rename to serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java
index 81e983e05e..73550237c6 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/typeinfo/TypeInfoFactory.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java
@@ -16,13 +16,17 @@
  * limitations under the License.
  */
 
-package org.apache.hadoop.hive.ql.typeinfo;
+package org.apache.hadoop.hive.serde2.typeinfo;
 
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
+import java.util.Stack;
 
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
+import org.apache.hadoop.io.IntWritable;
+
+
 
 /**
  * TypeInfoFactory can be used to create the TypeInfo object for any types.
@@ -79,7 +83,6 @@ public static TypeInfo getMapTypeInfo(TypeInfo keyTypeInfo, TypeInfo valueTypeIn
       cachedMapTypeInfo.put(signature, result);
     }
     return result;
-  }
-  
-  
+  };
+
 }
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java
new file mode 100644
index 0000000000..db007612fa
--- /dev/null
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java
@@ -0,0 +1,330 @@
+package org.apache.hadoop.hive.serde2.typeinfo;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+
+import org.apache.hadoop.hive.serde.Constants;
+import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.StructField;
+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
+
+public class TypeInfoUtils {
+  
+  /**
+   * Parse a recursive TypeInfo list String.
+   * For example, the following inputs are valid inputs: 
+   *  "int,string,map<string,int>,list<map<int,list<string>>>,list<struct<a:int,b:string>>"
+   * The separators between TypeInfos can be ",", ":", or ";".
+   * 
+   * In order to use this class:
+   * TypeInfoParser parser = new TypeInfoParser("int,string");
+   * ArrayList<TypeInfo> typeInfos = parser.parseTypeInfos();
+   */
+  private static class TypeInfoParser {
+    
+    static final String STRUCT_TYPE_NAME = "struct";
+    
+    private static class Token {
+      public int position;
+      public String text;
+      public boolean isAlphaDigit;
+    };
+    
+    /**
+     * Tokenize the typeInfoString.
+     * The rule is simple: all consecutive alphadigits are in one token, and all 
+     * other characters are one character per token.
+     * 
+     * tokenize("map<int,string>") should return ["map","<","int",",","string",">"]
+     */
+    private static ArrayList<Token> tokenize(String typeInfoString) {
+      ArrayList<Token> tokens = new ArrayList<Token>(0);
+      int begin = 0;
+      int end = 1;
+      while (end <= typeInfoString.length()) {
+        // last character ends a token? 
+        if (end == typeInfoString.length() 
+            || !Character.isLetterOrDigit(typeInfoString.charAt(end-1))
+            || !Character.isLetterOrDigit(typeInfoString.charAt(end))) {
+          Token t = new Token();
+          t.position = begin;
+          t.text = typeInfoString.substring(begin, end);
+          t.isAlphaDigit = Character.isLetterOrDigit(typeInfoString.charAt(begin));
+          tokens.add(t);
+          begin = end;
+        }          
+        end ++;
+      }
+      return tokens;
+    }
+  
+    public TypeInfoParser(String typeInfoString) {
+      this.typeInfoString = typeInfoString;
+      this.typeInfoTokens = tokenize(typeInfoString);
+    }
+  
+    private String typeInfoString;
+    private ArrayList<Token> typeInfoTokens;
+    private ArrayList<TypeInfo> typeInfos;
+    private int iToken;
+    
+    public ArrayList<TypeInfo> parseTypeInfos() throws IllegalArgumentException {
+      typeInfos = new ArrayList<TypeInfo>();
+      iToken = 0;
+      while (iToken < typeInfoTokens.size()) {
+        typeInfos.add(parseType());
+        if (iToken < typeInfoTokens.size()) {
+          Token separator = typeInfoTokens.get(iToken);
+          if (",".equals(separator.text) || ";".equals(separator.text) || ":".equals(separator.text)) {
+            iToken ++;
+          } else {
+            throw new IllegalArgumentException("Error: ',', ':', or ';' expected at position " 
+                + separator.position + " from '" + typeInfoString + "'" );
+          }
+        }
+      }
+      return typeInfos;
+    }
+  
+    private Token expect(String item) {
+      return expect(item, null);
+    }
+    
+    private Token expect(String item, String alternative) {
+      if (iToken >= typeInfoTokens.size()) {
+        throw new IllegalArgumentException("Error: " + item + " expected at the end of '"  
+            + typeInfoString + "'" );
+      }
+      Token t = typeInfoTokens.get(iToken);
+      if (item.equals("type")) {
+        if (!Constants.LIST_TYPE_NAME.equals(t.text)
+            && !Constants.MAP_TYPE_NAME.equals(t.text)
+            && !STRUCT_TYPE_NAME.equals(t.text)
+            && null == ObjectInspectorUtils.typeNameToClass.get(t.text)
+            && !t.text.equals(alternative)) {
+          throw new IllegalArgumentException("Error: " + item + " expected at the position "
+              + t.position + " of '" + typeInfoString + "'" );
+        }
+      } else if (item.equals("name")) {
+        if (!t.isAlphaDigit && !t.text.equals(alternative)) {
+          throw new IllegalArgumentException("Error: " + item + " expected at the position "
+              + t.position + " of '" + typeInfoString + "'" );
+        }
+      } else {
+        if (!item.equals(t.text) && !t.text.equals(alternative)) {
+          throw new IllegalArgumentException("Error: " + item + " expected at the position "
+              + t.position + " of '" + typeInfoString + "'" );
+        }
+      }
+      iToken ++;
+      return t;
+    }
+    
+    private TypeInfo parseType() {
+      
+      Token t = expect("type");
+  
+      // Is this a primitive type?
+      Class<?> clazz = ObjectInspectorUtils.typeNameToClass.get(t.text);
+      if (clazz != null) {
+        return TypeInfoFactory.getPrimitiveTypeInfo(clazz);
+      }
+      
+      // Is this a list type?
+      if (Constants.LIST_TYPE_NAME.equals(t.text)) {
+        expect("<");
+        TypeInfo listElementType = parseType();
+        expect(">");
+        return TypeInfoFactory.getListTypeInfo(listElementType);
+      }
+  
+      // Is this a map type?
+      if (Constants.MAP_TYPE_NAME.equals(t.text)) {
+        expect("<");
+        TypeInfo mapKeyType = parseType();
+        expect(",");
+        TypeInfo mapValueType = parseType();
+        expect(">");
+        return TypeInfoFactory.getMapTypeInfo(mapKeyType, mapValueType);
+      }
+  
+      // Is this a struct type?
+      if (STRUCT_TYPE_NAME.equals(t.text)) {
+        ArrayList<String> fieldNames = new ArrayList<String>();
+        ArrayList<TypeInfo> fieldTypeInfos = new ArrayList<TypeInfo>();
+        boolean first = true;
+        do {
+          if (first) {
+            expect("<");
+            first = false;
+          } else {
+            Token separator = expect(">", ",");
+            if (separator.text.equals(">")) {
+              // end of struct
+              break;
+            }
+          }
+          Token name = expect("name");
+          fieldNames.add(name.text);
+          expect(":");
+          fieldTypeInfos.add(parseType());
+        } while (true);
+        
+        return TypeInfoFactory.getStructTypeInfo(fieldNames, fieldTypeInfos);
+      }
+  
+      throw new RuntimeException("Internal error parsing position " + t.position + " of '"
+          + typeInfoString + "'");
+    }
+    
+  }
+
+  static HashMap<TypeInfo, ObjectInspector> cachedStandardObjectInspector = new HashMap<TypeInfo, ObjectInspector>();
+  /**
+   * Returns the standard object inspector that can be used to translate an object of that typeInfo
+   * to a standard object type.  
+   */
+  public static ObjectInspector getStandardObjectInspectorFromTypeInfo(TypeInfo typeInfo) {
+    ObjectInspector result = cachedStandardObjectInspector.get(typeInfo);
+    if (result == null) {
+      switch(typeInfo.getCategory()) {
+        case PRIMITIVE: {
+          result = ObjectInspectorFactory.getStandardPrimitiveObjectInspector(typeInfo.getPrimitiveClass());
+          break;
+        }
+        case LIST: {
+          ObjectInspector elementObjectInspector = getStandardObjectInspectorFromTypeInfo(typeInfo.getListElementTypeInfo());
+          result = ObjectInspectorFactory.getStandardListObjectInspector(elementObjectInspector);
+          break;
+        }
+        case MAP: {
+          ObjectInspector keyObjectInspector = getStandardObjectInspectorFromTypeInfo(typeInfo.getMapKeyTypeInfo());
+          ObjectInspector valueObjectInspector = getStandardObjectInspectorFromTypeInfo(typeInfo.getMapValueTypeInfo());
+          result = ObjectInspectorFactory.getStandardMapObjectInspector(keyObjectInspector, valueObjectInspector);
+          break;
+        }
+        case STRUCT: {
+          List<String> fieldNames = typeInfo.getAllStructFieldNames();
+          List<TypeInfo> fieldTypeInfos = typeInfo.getAllStructFieldTypeInfos();
+          List<ObjectInspector> fieldObjectInspectors = new ArrayList<ObjectInspector>(fieldTypeInfos.size());
+          for(int i=0; i<fieldTypeInfos.size(); i++) {
+            fieldObjectInspectors.add(getStandardObjectInspectorFromTypeInfo(fieldTypeInfos.get(i)));
+          }
+          result = ObjectInspectorFactory.getStandardStructObjectInspector(fieldNames, fieldObjectInspectors);
+          break;
+        }
+        default: {
+          result = null;
+        }
+      }
+      cachedStandardObjectInspector.put(typeInfo, result);
+    }
+    return result;
+  }
+
+  
+  /**
+   * Get the TypeInfo object from the ObjectInspector object by recursively going into the
+   * ObjectInspector structure.
+   */
+  public static TypeInfo getTypeInfoFromObjectInspector(ObjectInspector oi) {
+//    OPTIMIZATION for later.
+//    if (oi instanceof TypeInfoBasedObjectInspector) {
+//      TypeInfoBasedObjectInspector typeInfoBasedObjectInspector = (ObjectInspector)oi;
+//      return typeInfoBasedObjectInspector.getTypeInfo();
+//    }
+    
+    // Recursively going into ObjectInspector structure
+    TypeInfo result = null;
+    switch (oi.getCategory()) {
+      case PRIMITIVE: {
+        PrimitiveObjectInspector poi =(PrimitiveObjectInspector)oi;
+        result = TypeInfoFactory.getPrimitiveTypeInfo(poi.getPrimitiveClass());
+        break;
+      }
+      case LIST: {
+        ListObjectInspector loi = (ListObjectInspector)oi;
+        result = TypeInfoFactory.getListTypeInfo(
+            getTypeInfoFromObjectInspector(loi.getListElementObjectInspector()));
+        break;
+      }
+      case MAP: {
+        MapObjectInspector moi = (MapObjectInspector)oi;
+        result = TypeInfoFactory.getMapTypeInfo(
+            getTypeInfoFromObjectInspector(moi.getMapKeyObjectInspector()),
+            getTypeInfoFromObjectInspector(moi.getMapValueObjectInspector()));
+        break;
+      }
+      case STRUCT: {
+        StructObjectInspector soi = (StructObjectInspector)oi;
+        List<? extends StructField> fields = soi.getAllStructFieldRefs();
+        List<String> fieldNames = new ArrayList<String>(fields.size());
+        List<TypeInfo> fieldTypeInfos = new ArrayList<TypeInfo>(fields.size());
+        for(StructField f : fields) {
+          fieldNames.add(f.getFieldName());
+          fieldTypeInfos.add(getTypeInfoFromObjectInspector(f.getFieldObjectInspector()));
+        }
+        result = TypeInfoFactory.getStructTypeInfo(fieldNames, fieldTypeInfos);
+        break;
+      }
+      default: {
+        throw new RuntimeException("Unknown ObjectInspector category!");
+      }
+    }
+    return result;
+  }
+    
+  /**
+   * Return the 
+   */
+  public static String getTypeStringFromTypeInfo(TypeInfo typeInfo) {
+    switch(typeInfo.getCategory()) {
+      case PRIMITIVE: {
+        return ObjectInspectorUtils.getClassShortName(typeInfo.getPrimitiveClass());
+      }
+      case LIST: {
+        String elementType = getTypeStringFromTypeInfo(typeInfo.getListElementTypeInfo());
+        return org.apache.hadoop.hive.serde.Constants.LIST_TYPE_NAME + "<" + elementType + ">";
+      }
+      case MAP: {
+        String keyType = getTypeStringFromTypeInfo(typeInfo.getMapKeyTypeInfo());
+        String valueType = getTypeStringFromTypeInfo(typeInfo.getMapValueTypeInfo());
+        return org.apache.hadoop.hive.serde.Constants.MAP_TYPE_NAME + "<" +
+          keyType + "," + valueType + ">";
+      }
+      case STRUCT: {
+        StringBuilder sb = new StringBuilder();
+        sb.append("struct<");
+        List<String> fieldNames = typeInfo.getAllStructFieldNames();
+        List<TypeInfo> fieldTypeInfos = typeInfo.getAllStructFieldTypeInfos();
+        for (int i = 0; i < fieldNames.size(); i++) {
+          if (i>0) sb.append(",");
+          sb.append(fieldNames.get(i));
+          sb.append(":");
+          sb.append(getTypeStringFromTypeInfo(fieldTypeInfos.get(i)));
+        }        
+        sb.append(">");
+        return sb.toString();
+      }
+      default: {
+        throw new RuntimeException("Unknown type!");
+      }
+    }
+  }
+  
+  public static ArrayList<TypeInfo> getTypeInfosFromTypeString(String typeString) {
+    TypeInfoParser parser = new TypeInfoParser(typeString);
+    return parser.parseTypeInfos();
+  }
+
+  public static TypeInfo getTypeInfoFromTypeString(String typeString) {
+    TypeInfoParser parser = new TypeInfoParser(typeString);
+    return parser.parseTypeInfos().get(0);
+  }
+}
diff --git a/serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazyArrayMapStruct.java b/serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazyArrayMapStruct.java
new file mode 100644
index 0000000000..8fc9890d5b
--- /dev/null
+++ b/serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazyArrayMapStruct.java
@@ -0,0 +1,196 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.serde2.lazy;
+
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+import org.apache.hadoop.hive.serde2.SerDeUtils;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
+import org.apache.hadoop.io.Text;
+import java.util.HashMap;
+
+import junit.framework.TestCase;
+
+public class TestLazyArrayMapStruct extends TestCase {
+
+  /**
+   * Test the LazyArray class.
+   */
+  public void testLazyArray() throws Throwable {
+    try {
+      // Array of Byte
+      Text nullSequence = new Text("\\N");
+      LazyArray b = (LazyArray)LazyFactory.createLazyObject(TypeInfoUtils.getTypeInfoFromTypeString("array<tinyint>"));
+      byte[] data = new byte[]{'-', '1', 1, '\\', 'N', 1, '8'};
+      TestLazyPrimitive.initLazyObject(b, data, 0, data.length);
+      
+      assertNull(b.getListElementObject(-1, (byte)1, nullSequence));
+      assertEquals(Byte.valueOf((byte)-1), b.getListElementObject(0, (byte)1, nullSequence));
+      assertNull(b.getListElementObject(1, (byte)1, nullSequence));
+      assertEquals(Byte.valueOf((byte)8), b.getListElementObject(2, (byte)1, nullSequence));
+      assertNull(b.getListElementObject(3, (byte)1, nullSequence));
+      assertEquals(Arrays.asList(new Byte[]{-1,null,8}), b.getList((byte)1, nullSequence));
+      
+      // Array of String
+      b = (LazyArray)LazyFactory.createLazyObject(TypeInfoUtils.getTypeInfoFromTypeString("array<string>"));
+      data = new byte[]{'a', 'b', '\t', 'c', '\t', '\\', 'N', '\t', '\t', 'd'};
+      // Note: the first and last element of the byte[] are NOT used
+      TestLazyPrimitive.initLazyObject(b, data, 1, data.length - 2);
+      assertNull(b.getListElementObject(-1, (byte)'\t', nullSequence));
+      assertEquals("b", b.getListElementObject(0, (byte)'\t', nullSequence));
+      assertEquals("c", b.getListElementObject(1, (byte)'\t', nullSequence));
+      assertNull(b.getListElementObject(2, (byte)'\t', nullSequence));
+      assertEquals("", b.getListElementObject(3, (byte)'\t', nullSequence));
+      assertEquals("", b.getListElementObject(4, (byte)'\t', nullSequence));
+      assertNull(b.getListElementObject(5, (byte)'\t', nullSequence));
+      assertEquals(Arrays.asList(new String[]{"b", "c", null, "", ""}), b.getList((byte)'\t', nullSequence));
+      
+    } catch (Throwable e) {
+      e.printStackTrace();
+      throw e;
+    }
+  }
+    
+  /**
+   * Test the LazyMap class.
+   */
+  public void testLazyMap() throws Throwable {
+    try {
+      {
+        // Map of Integer to String
+        Text nullSequence = new Text("\\N");
+        LazyMap b = (LazyMap)LazyFactory.createLazyObject(TypeInfoUtils.getTypeInfoFromTypeString("map<int,string>"));
+        byte[] data = new byte[]{'2', 2, 'd', 'e', 'f', 1, '-', '1', 2, '\\', 'N', 1, '0', 2, '0', 1, '8', 2, 'a', 'b', 'c'};
+        TestLazyPrimitive.initLazyObject(b, data, 0, data.length);
+        
+        assertEquals("def", b.getMapValueElement((byte)1, (byte)2, nullSequence, Integer.valueOf(2)));
+        assertNull(b.getMapValueElement((byte)1, (byte)2, nullSequence, Integer.valueOf(-1)));
+        assertEquals("0", b.getMapValueElement((byte)1, (byte)2, nullSequence, Integer.valueOf(0)));
+        assertEquals("abc", b.getMapValueElement((byte)1, (byte)2, nullSequence, Integer.valueOf(8)));
+        assertNull(b.getMapValueElement((byte)1, (byte)2, nullSequence, Integer.valueOf(12345)));
+        
+        HashMap<Integer, String> r = new HashMap<Integer, String>();
+        r.put(2, "def");
+        r.put(-1, null);
+        r.put(0, "0");
+        r.put(8, "abc");
+        assertEquals(r, b.getMap((byte)1, (byte)2, nullSequence));
+      }
+      
+      {
+        // Map of String to String
+        Text nullSequence = new Text("\\N");
+        LazyMap b = (LazyMap)LazyFactory.createLazyObject(TypeInfoUtils.getTypeInfoFromTypeString("map<string,string>"));
+        byte[] data = new byte[]{'2', '\t', 'd', '\t', 'f', '#', '2', '\t', 'd', '#', '-', '1', '#', '0', '\t', '0', '#', '8', '\t', 'a', 'b', 'c'};
+        TestLazyPrimitive.initLazyObject(b, data, 0, data.length);
+        
+        assertEquals("d\tf", b.getMapValueElement((byte)'#', (byte)'\t', nullSequence, "2"));
+        assertNull(b.getMapValueElement((byte)'#', (byte)'\t', nullSequence, Integer.valueOf(-1)));
+        assertEquals("0", b.getMapValueElement((byte)'#', (byte)'\t', nullSequence, "0"));
+        assertEquals("abc", b.getMapValueElement((byte)'#', (byte)'\t', nullSequence, "8"));
+        assertNull(b.getMapValueElement((byte)'#', (byte)'\t', nullSequence, "-"));
+        
+        HashMap<String,String> r = new HashMap<String, String>();
+        r.put("2", "d\tf");
+        r.put("-1", null);
+        r.put("0", "0");
+        r.put("8", "abc");
+        assertEquals(r, b.getMap((byte)1, (byte)2, nullSequence));
+      }
+      
+    } catch (Throwable e) {
+      e.printStackTrace();
+      throw e;
+    }
+  }
+  
+  /**
+   * Test the LazyStruct class.
+   */
+  public void testLazyStruct() throws Throwable {
+    try {
+      {
+        ArrayList<TypeInfo> fieldTypeInfos = 
+          TypeInfoUtils.getTypeInfosFromTypeString("int,array<string>,map<string,string>,string");
+        List<String> fieldNames = Arrays.asList(new String[]{"a", "b", "c", "d"});
+        TypeInfo rowTypeInfo = TypeInfoFactory.getStructTypeInfo(fieldNames, fieldTypeInfos);
+        
+        Text nullSequence = new Text("\\N");
+        
+        LazyStruct o = (LazyStruct)LazyFactory.createLazyObject(rowTypeInfo);
+        ObjectInspector oi = LazyFactory.createLazyStructInspector(Arrays.asList(new String[]{"a","b","c","d"}),
+            fieldTypeInfos, new byte[] {' ', ':', '='}, nullSequence, false);
+        
+        Text data;
+        
+        data = new Text("123 a:b:c d=e:f=g hi");
+        TestLazyPrimitive.initLazyObject(o, data.getBytes(), 0, data.getLength());
+        assertEquals("{'a':123,'b':['a','b','c'],'c':{'f':'g','d':'e'},'d':'hi'}".replace("'", "\""),
+            SerDeUtils.getJSONString(o, oi));
+
+        data = new Text("123 \\N d=e:f=g \\N");
+        TestLazyPrimitive.initLazyObject(o, data.getBytes(), 0, data.getLength());
+        assertEquals("{'a':123,'b':null,'c':{'f':'g','d':'e'},'d':null}".replace("'", "\""),
+            SerDeUtils.getJSONString(o, oi));
+
+        data = new Text("\\N a d=\\N:f=g:h no tail");
+        TestLazyPrimitive.initLazyObject(o, data.getBytes(), 0, data.getLength());
+        assertEquals("{'a':null,'b':['a'],'c':{'f':'g','d':null,'h':null},'d':'no'}".replace("'", "\""),
+            SerDeUtils.getJSONString(o, oi));
+
+        data = new Text("\\N :a:: \\N no tail");
+        TestLazyPrimitive.initLazyObject(o, data.getBytes(), 0, data.getLength());
+        assertEquals("{'a':null,'b':['','a','',''],'c':null,'d':'no'}".replace("'", "\""),
+            SerDeUtils.getJSONString(o, oi));
+
+        data = new Text("123   ");
+        TestLazyPrimitive.initLazyObject(o, data.getBytes(), 0, data.getLength());
+        assertEquals("{'a':123,'b':[],'c':{},'d':''}".replace("'", "\""),
+            SerDeUtils.getJSONString(o, oi));
+
+        data = new Text(": : : :");
+        TestLazyPrimitive.initLazyObject(o, data.getBytes(), 0, data.getLength());
+        assertEquals("{'a':null,'b':['',''],'c':{'':null},'d':':'}".replace("'", "\""),
+            SerDeUtils.getJSONString(o, oi));
+
+        data = new Text("= = = =");
+        TestLazyPrimitive.initLazyObject(o, data.getBytes(), 0, data.getLength());
+        assertEquals("{'a':null,'b':['='],'c':{'':''},'d':'='}".replace("'", "\""),
+            SerDeUtils.getJSONString(o, oi));
+        
+        // test LastColumnTakesRest
+        oi = LazyFactory.createLazyStructInspector(Arrays.asList(new String[]{"a","b","c","d"}),
+            fieldTypeInfos, new byte[] {' ', ':', '='}, nullSequence, true);
+        data = new Text("\\N a d=\\N:f=g:h has tail");
+        TestLazyPrimitive.initLazyObject(o, data.getBytes(), 0, data.getLength());
+        assertEquals("{'a':null,'b':['a'],'c':{'f':'g','d':null,'h':null},'d':'has tail'}".replace("'", "\""),
+            SerDeUtils.getJSONString(o, oi));
+      }
+    } catch (Throwable e) {
+      e.printStackTrace();
+      throw e;
+    }
+  }
+  
+}
diff --git a/serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazyPrimitive.java b/serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazyPrimitive.java
index e47bae4d74..e7f4f405fc 100644
--- a/serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazyPrimitive.java
+++ b/serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazyPrimitive.java
@@ -22,39 +22,49 @@
 
 public class TestLazyPrimitive extends TestCase {
 
+  /**
+   * Initialize the LazyObject with the parameters, wrapping the byte[] automatically.
+   */
+  public static void initLazyObject(LazyObject lo, byte[] data, int start, int length) {
+    ByteArrayRef b = new ByteArrayRef();
+    b.setData(data);
+    lo.init(b, start, length);    
+  }
   /**
    * Test the LazyByte class.
    */
   public void testLazyByte() throws Throwable {
     try {
       LazyByte b = new LazyByte();
-      b.setAll(new byte[]{'0'}, 0, 1);
-      assertEquals(Byte.valueOf((byte)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '0'}, 0, 2);
-      assertEquals(Byte.valueOf((byte)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '0'}, 0, 2);
-      assertEquals(Byte.valueOf((byte)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '1', 'b'}, 1, 1);
-      assertEquals(Byte.valueOf((byte)1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '-', '1'}, 1, 2);
-      assertEquals(Byte.valueOf((byte)-1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '+', '1'}, 1, 2);
-      assertEquals(Byte.valueOf((byte)1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', '2', '8'}, 0, 4);
-      assertEquals(Byte.valueOf((byte)-128), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', '2', '7'}, 0, 4);
-      assertEquals(Byte.valueOf((byte)127), b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'0'}, 0, 0);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'0'}, 0, 1);
+      assertEquals(Byte.valueOf((byte)0), b.getObject());
+      initLazyObject(b,new byte[]{'+', '0'}, 0, 2);
+      assertEquals(Byte.valueOf((byte)0), b.getObject());
+      initLazyObject(b,new byte[]{'-', '0'}, 0, 2);
+      assertEquals(Byte.valueOf((byte)0), b.getObject());
+      initLazyObject(b,new byte[]{'a', '1', 'b'}, 1, 1);
+      assertEquals(Byte.valueOf((byte)1), b.getObject());
+      initLazyObject(b,new byte[]{'a', '-', '1'}, 1, 2);
+      assertEquals(Byte.valueOf((byte)-1), b.getObject());
+      initLazyObject(b,new byte[]{'a', '+', '1'}, 1, 2);
+      assertEquals(Byte.valueOf((byte)1), b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', '2', '8'}, 0, 4);
+      assertEquals(Byte.valueOf((byte)-128), b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', '2', '7'}, 0, 4);
+      assertEquals(Byte.valueOf((byte)127), b.getObject());
       
-      b.setAll(new byte[]{'a', '1', 'b'}, 1, 2);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', '2', '8'}, 0, 4);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', '2', '9'}, 0, 4);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', '2', '3'}, 0, 1);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', '2', '3'}, 0, 1);
-      assertNull(b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'a', '1', 'b'}, 1, 2);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', '2', '8'}, 0, 4);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', '2', '9'}, 0, 4);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', '2', '3'}, 0, 1);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', '2', '3'}, 0, 1);
+      assertNull(b.getObject());
      
     } catch (Throwable e) {
       e.printStackTrace();
@@ -68,37 +78,39 @@ public void testLazyByte() throws Throwable {
   public void testLazyShort() throws Throwable {
     try {
       LazyShort b = new LazyShort();
-      b.setAll(new byte[]{'0'}, 0, 1);
-      assertEquals(Short.valueOf((short)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '0'}, 0, 2);
-      assertEquals(Short.valueOf((short)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '0'}, 0, 2);
-      assertEquals(Short.valueOf((short)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '1', 'b'}, 1, 1);
-      assertEquals(Short.valueOf((short)1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '-', '1'}, 1, 2);
-      assertEquals(Short.valueOf((short)-1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '+', '1'}, 1, 2);
-      assertEquals(Short.valueOf((short)1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', '2', '8'}, 0, 4);
-      assertEquals(Short.valueOf((short)-128), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', '2', '7'}, 0, 4);
-      assertEquals(Short.valueOf((short)127), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '3', '2', '7', '6', '8'}, 0, 6);
-      assertEquals(Short.valueOf((short)-32768), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '3', '2', '7', '6', '7'}, 0, 6);
-      assertEquals(Short.valueOf((short)32767), b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'0'}, 0, 0);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'0'}, 0, 1);
+      assertEquals(Short.valueOf((short)0), b.getObject());
+      initLazyObject(b,new byte[]{'+', '0'}, 0, 2);
+      assertEquals(Short.valueOf((short)0), b.getObject());
+      initLazyObject(b,new byte[]{'-', '0'}, 0, 2);
+      assertEquals(Short.valueOf((short)0), b.getObject());
+      initLazyObject(b,new byte[]{'a', '1', 'b'}, 1, 1);
+      assertEquals(Short.valueOf((short)1), b.getObject());
+      initLazyObject(b,new byte[]{'a', '-', '1'}, 1, 2);
+      assertEquals(Short.valueOf((short)-1), b.getObject());
+      initLazyObject(b,new byte[]{'a', '+', '1'}, 1, 2);
+      assertEquals(Short.valueOf((short)1), b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', '2', '8'}, 0, 4);
+      assertEquals(Short.valueOf((short)-128), b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', '2', '7'}, 0, 4);
+      assertEquals(Short.valueOf((short)127), b.getObject());
+      initLazyObject(b,new byte[]{'-', '3', '2', '7', '6', '8'}, 0, 6);
+      assertEquals(Short.valueOf((short)-32768), b.getObject());
+      initLazyObject(b,new byte[]{'+', '3', '2', '7', '6', '7'}, 0, 6);
+      assertEquals(Short.valueOf((short)32767), b.getObject());
 
-      b.setAll(new byte[]{'a', '1', 'b'}, 1, 2);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '3', '2', '7', '6', '9'}, 0, 6);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '3', '2', '7', '6', '8'}, 0, 6);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', '2', '3'}, 0, 1);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', '2', '3'}, 0, 1);
-      assertNull(b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'a', '1', 'b'}, 1, 2);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'-', '3', '2', '7', '6', '9'}, 0, 6);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'+', '3', '2', '7', '6', '8'}, 0, 6);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', '2', '3'}, 0, 1);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', '2', '3'}, 0, 1);
+      assertNull(b.getObject());
 
     } catch (Throwable e) {
       e.printStackTrace();
@@ -113,41 +125,43 @@ public void testLazyShort() throws Throwable {
   public void testLazyInteger() throws Throwable {
     try {
       LazyInteger b = new LazyInteger();
-      b.setAll(new byte[]{'0'}, 0, 1);
-      assertEquals(Integer.valueOf((int)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '0'}, 0, 2);
-      assertEquals(Integer.valueOf((int)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '0'}, 0, 2);
-      assertEquals(Integer.valueOf((int)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '1', 'b'}, 1, 1);
-      assertEquals(Integer.valueOf((int)1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '-', '1'}, 1, 2);
-      assertEquals(Integer.valueOf((int)-1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '+', '1'}, 1, 2);
-      assertEquals(Integer.valueOf((int)1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', '2', '8'}, 0, 4);
-      assertEquals(Integer.valueOf((int)-128), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', '2', '7'}, 0, 4);
-      assertEquals(Integer.valueOf((int)127), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '3', '2', '7', '6', '8'}, 0, 6);
-      assertEquals(Integer.valueOf((int)-32768), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '3', '2', '7', '6', '7'}, 0, 6);
-      assertEquals(Integer.valueOf((int)32767), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '2', '1', '4', '7', '4', '8', '3', '6', '4', '8'}, 0, 11);
-      assertEquals(Integer.valueOf((int)-2147483648), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '2', '1', '4', '7', '4', '8', '3', '6', '4', '7'}, 0, 11);
-      assertEquals(Integer.valueOf((int)2147483647), b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'0'}, 0, 0);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'0'}, 0, 1);
+      assertEquals(Integer.valueOf((int)0), b.getObject());
+      initLazyObject(b,new byte[]{'+', '0'}, 0, 2);
+      assertEquals(Integer.valueOf((int)0), b.getObject());
+      initLazyObject(b,new byte[]{'-', '0'}, 0, 2);
+      assertEquals(Integer.valueOf((int)0), b.getObject());
+      initLazyObject(b,new byte[]{'a', '1', 'b'}, 1, 1);
+      assertEquals(Integer.valueOf((int)1), b.getObject());
+      initLazyObject(b,new byte[]{'a', '-', '1'}, 1, 2);
+      assertEquals(Integer.valueOf((int)-1), b.getObject());
+      initLazyObject(b,new byte[]{'a', '+', '1'}, 1, 2);
+      assertEquals(Integer.valueOf((int)1), b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', '2', '8'}, 0, 4);
+      assertEquals(Integer.valueOf((int)-128), b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', '2', '7'}, 0, 4);
+      assertEquals(Integer.valueOf((int)127), b.getObject());
+      initLazyObject(b,new byte[]{'-', '3', '2', '7', '6', '8'}, 0, 6);
+      assertEquals(Integer.valueOf((int)-32768), b.getObject());
+      initLazyObject(b,new byte[]{'+', '3', '2', '7', '6', '7'}, 0, 6);
+      assertEquals(Integer.valueOf((int)32767), b.getObject());
+      initLazyObject(b,new byte[]{'-', '2', '1', '4', '7', '4', '8', '3', '6', '4', '8'}, 0, 11);
+      assertEquals(Integer.valueOf((int)-2147483648), b.getObject());
+      initLazyObject(b,new byte[]{'+', '2', '1', '4', '7', '4', '8', '3', '6', '4', '7'}, 0, 11);
+      assertEquals(Integer.valueOf((int)2147483647), b.getObject());
 
-      b.setAll(new byte[]{'a', '1', 'b'}, 1, 2);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '2', '1', '4', '7', '4', '8', '3', '6', '4', '9'}, 0, 11);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '2', '1', '4', '7', '4', '8', '3', '6', '4', '8'}, 0, 11);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', '2', '3'}, 0, 1);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', '2', '3'}, 0, 1);
-      assertNull(b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'a', '1', 'b'}, 1, 2);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'-', '2', '1', '4', '7', '4', '8', '3', '6', '4', '9'}, 0, 11);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'+', '2', '1', '4', '7', '4', '8', '3', '6', '4', '8'}, 0, 11);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', '2', '3'}, 0, 1);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', '2', '3'}, 0, 1);
+      assertNull(b.getObject());
 
     } catch (Throwable e) {
       e.printStackTrace();
@@ -162,49 +176,51 @@ public void testLazyInteger() throws Throwable {
   public void testLazyLong() throws Throwable {
     try {
       LazyLong b = new LazyLong();
-      b.setAll(new byte[]{'0'}, 0, 1);
-      assertEquals(Long.valueOf((long)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '0'}, 0, 2);
-      assertEquals(Long.valueOf((long)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '0'}, 0, 2);
-      assertEquals(Long.valueOf((long)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '1', 'b'}, 1, 1);
-      assertEquals(Long.valueOf((long)1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '-', '1'}, 1, 2);
-      assertEquals(Long.valueOf((long)-1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '+', '1'}, 1, 2);
-      assertEquals(Long.valueOf((long)1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', '2', '8'}, 0, 4);
-      assertEquals(Long.valueOf((long)-128), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', '2', '7'}, 0, 4);
-      assertEquals(Long.valueOf((long)127), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '3', '2', '7', '6', '8'}, 0, 6);
-      assertEquals(Long.valueOf((long)-32768), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '3', '2', '7', '6', '7'}, 0, 6);
-      assertEquals(Long.valueOf((long)32767), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '2', '1', '4', '7', '4', '8', '3', '6', '4', '8'}, 0, 11);
-      assertEquals(Long.valueOf((long)-2147483648), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '2', '1', '4', '7', '4', '8', '3', '6', '4', '7'}, 0, 11);
-      assertEquals(Long.valueOf((long)2147483647), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
+      initLazyObject(b,new byte[]{'0'}, 0, 0);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'0'}, 0, 1);
+      assertEquals(Long.valueOf((long)0), b.getObject());
+      initLazyObject(b,new byte[]{'+', '0'}, 0, 2);
+      assertEquals(Long.valueOf((long)0), b.getObject());
+      initLazyObject(b,new byte[]{'-', '0'}, 0, 2);
+      assertEquals(Long.valueOf((long)0), b.getObject());
+      initLazyObject(b,new byte[]{'a', '1', 'b'}, 1, 1);
+      assertEquals(Long.valueOf((long)1), b.getObject());
+      initLazyObject(b,new byte[]{'a', '-', '1'}, 1, 2);
+      assertEquals(Long.valueOf((long)-1), b.getObject());
+      initLazyObject(b,new byte[]{'a', '+', '1'}, 1, 2);
+      assertEquals(Long.valueOf((long)1), b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', '2', '8'}, 0, 4);
+      assertEquals(Long.valueOf((long)-128), b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', '2', '7'}, 0, 4);
+      assertEquals(Long.valueOf((long)127), b.getObject());
+      initLazyObject(b,new byte[]{'-', '3', '2', '7', '6', '8'}, 0, 6);
+      assertEquals(Long.valueOf((long)-32768), b.getObject());
+      initLazyObject(b,new byte[]{'+', '3', '2', '7', '6', '7'}, 0, 6);
+      assertEquals(Long.valueOf((long)32767), b.getObject());
+      initLazyObject(b,new byte[]{'-', '2', '1', '4', '7', '4', '8', '3', '6', '4', '8'}, 0, 11);
+      assertEquals(Long.valueOf((long)-2147483648), b.getObject());
+      initLazyObject(b,new byte[]{'+', '2', '1', '4', '7', '4', '8', '3', '6', '4', '7'}, 0, 11);
+      assertEquals(Long.valueOf((long)2147483647), b.getObject());
+      initLazyObject(b,new byte[]{'-', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
           '4', '7', '7', '5', '8', '0', '8'}, 0, 20);
-      assertEquals(Long.valueOf((long)-9223372036854775808L), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
+      assertEquals(Long.valueOf((long)-9223372036854775808L), b.getObject());
+      initLazyObject(b,new byte[]{'+', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
           '4', '7', '7', '5', '8', '0', '7'}, 0, 20);
-      assertEquals(Long.valueOf((long)9223372036854775807L), b.getPrimitiveObject());
+      assertEquals(Long.valueOf((long)9223372036854775807L), b.getObject());
 
-      b.setAll(new byte[]{'a', '1', 'b'}, 1, 2);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
+      initLazyObject(b,new byte[]{'a', '1', 'b'}, 1, 2);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'-', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
           '4', '7', '7', '5', '8', '0', '9'}, 0, 20);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'+', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
           '4', '7', '7', '5', '8', '0', '8'}, 0, 20);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', '2', '3'}, 0, 1);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', '2', '3'}, 0, 1);
-      assertNull(b.getPrimitiveObject());
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', '2', '3'}, 0, 1);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', '2', '3'}, 0, 1);
+      assertNull(b.getObject());
 
     } catch (Throwable e) {
       e.printStackTrace();
@@ -218,78 +234,80 @@ public void testLazyLong() throws Throwable {
   public void testLazyDouble() throws Throwable {
     try {
       LazyDouble b = new LazyDouble();
-      b.setAll(new byte[]{'0'}, 0, 1);
-      assertEquals(Double.valueOf((double)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '0'}, 0, 2);
-      assertEquals(Double.valueOf((double)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '0'}, 0, 2);
-      assertEquals(Double.valueOf((double)-0.0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '1', 'b'}, 1, 1);
-      assertEquals(Double.valueOf((double)1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '-', '1'}, 1, 2);
-      assertEquals(Double.valueOf((double)-1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'a', '+', '1'}, 1, 2);
-      assertEquals(Double.valueOf((double)1), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', '2', '8'}, 0, 4);
-      assertEquals(Double.valueOf((double)-128), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', '2', '7'}, 0, 4);
-      assertEquals(Double.valueOf((double)127), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '3', '2', '7', '6', '8'}, 0, 6);
-      assertEquals(Double.valueOf((double)-32768), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '3', '2', '7', '6', '7'}, 0, 6);
-      assertEquals(Double.valueOf((double)32767), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '2', '1', '4', '7', '4', '8', '3', '6', '4', '8'}, 0, 11);
-      assertEquals(Double.valueOf((double)-2147483648), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '2', '1', '4', '7', '4', '8', '3', '6', '4', '7'}, 0, 11);
-      assertEquals(Double.valueOf((double)2147483647), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
+      initLazyObject(b,new byte[]{'0'}, 0, 0);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'0'}, 0, 1);
+      assertEquals(Double.valueOf((double)0), b.getObject());
+      initLazyObject(b,new byte[]{'+', '0'}, 0, 2);
+      assertEquals(Double.valueOf((double)0), b.getObject());
+      initLazyObject(b,new byte[]{'-', '0'}, 0, 2);
+      assertEquals(Double.valueOf((double)-0.0), b.getObject());
+      initLazyObject(b,new byte[]{'a', '1', 'b'}, 1, 1);
+      assertEquals(Double.valueOf((double)1), b.getObject());
+      initLazyObject(b,new byte[]{'a', '-', '1'}, 1, 2);
+      assertEquals(Double.valueOf((double)-1), b.getObject());
+      initLazyObject(b,new byte[]{'a', '+', '1'}, 1, 2);
+      assertEquals(Double.valueOf((double)1), b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', '2', '8'}, 0, 4);
+      assertEquals(Double.valueOf((double)-128), b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', '2', '7'}, 0, 4);
+      assertEquals(Double.valueOf((double)127), b.getObject());
+      initLazyObject(b,new byte[]{'-', '3', '2', '7', '6', '8'}, 0, 6);
+      assertEquals(Double.valueOf((double)-32768), b.getObject());
+      initLazyObject(b,new byte[]{'+', '3', '2', '7', '6', '7'}, 0, 6);
+      assertEquals(Double.valueOf((double)32767), b.getObject());
+      initLazyObject(b,new byte[]{'-', '2', '1', '4', '7', '4', '8', '3', '6', '4', '8'}, 0, 11);
+      assertEquals(Double.valueOf((double)-2147483648), b.getObject());
+      initLazyObject(b,new byte[]{'+', '2', '1', '4', '7', '4', '8', '3', '6', '4', '7'}, 0, 11);
+      assertEquals(Double.valueOf((double)2147483647), b.getObject());
+      initLazyObject(b,new byte[]{'-', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
           '4', '7', '7', '5', '8', '0', '8'}, 0, 20);
-      assertEquals(Double.valueOf((double)-9223372036854775808L), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
+      assertEquals(Double.valueOf((double)-9223372036854775808L), b.getObject());
+      initLazyObject(b,new byte[]{'+', '9', '2', '2', '3', '3', '7', '2', '0', '3', '6', '8', '5',
           '4', '7', '7', '5', '8', '0', '7'}, 0, 20);
-      assertEquals(Double.valueOf((long)9223372036854775807L), b.getPrimitiveObject());
+      assertEquals(Double.valueOf((long)9223372036854775807L), b.getObject());
 
-      b.setAll(new byte[]{'-', '3', '.', '7', '6', '8'}, 0, 6);
-      assertEquals(Double.valueOf((double)-3.768), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '3', '.', '7', '6', '7'}, 0, 6);
-      assertEquals(Double.valueOf((double)3.767), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '2', '.', '4', '7', '4', '8', '3', '6', 'e', '8'}, 0, 11);
-      assertEquals(Double.valueOf((double)-2.474836e8), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '2', '.', '4', '7', '4', '8', '3', 'E', '-', '7'}, 0, 11);
-      assertEquals(Double.valueOf((double)2.47483E-7), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '.', '4', '7', '4', '8', '3', '6', 'e', '8'}, 0, 10);
-      assertEquals(Double.valueOf((double)-.474836e8), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '.', '4', '7', '4', '8', '3', 'E', '-', '7'}, 0, 10);
-      assertEquals(Double.valueOf((double).47483E-7), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '2', '1', '4', '7', '4', '8', '3', '6', '4', '.'}, 0, 11);
-      assertEquals(Double.valueOf((double)-214748364.), b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '2', '1', '4', '7', '4', '8', '3', '6', '4', '.'}, 0, 11);
-      assertEquals(Double.valueOf((double)+214748364.), b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'-', '3', '.', '7', '6', '8'}, 0, 6);
+      assertEquals(Double.valueOf((double)-3.768), b.getObject());
+      initLazyObject(b,new byte[]{'+', '3', '.', '7', '6', '7'}, 0, 6);
+      assertEquals(Double.valueOf((double)3.767), b.getObject());
+      initLazyObject(b,new byte[]{'-', '2', '.', '4', '7', '4', '8', '3', '6', 'e', '8'}, 0, 11);
+      assertEquals(Double.valueOf((double)-2.474836e8), b.getObject());
+      initLazyObject(b,new byte[]{'+', '2', '.', '4', '7', '4', '8', '3', 'E', '-', '7'}, 0, 11);
+      assertEquals(Double.valueOf((double)2.47483E-7), b.getObject());
+      initLazyObject(b,new byte[]{'-', '.', '4', '7', '4', '8', '3', '6', 'e', '8'}, 0, 10);
+      assertEquals(Double.valueOf((double)-.474836e8), b.getObject());
+      initLazyObject(b,new byte[]{'+', '.', '4', '7', '4', '8', '3', 'E', '-', '7'}, 0, 10);
+      assertEquals(Double.valueOf((double).47483E-7), b.getObject());
+      initLazyObject(b,new byte[]{'-', '2', '1', '4', '7', '4', '8', '3', '6', '4', '.'}, 0, 11);
+      assertEquals(Double.valueOf((double)-214748364.), b.getObject());
+      initLazyObject(b,new byte[]{'+', '2', '1', '4', '7', '4', '8', '3', '6', '4', '.'}, 0, 11);
+      assertEquals(Double.valueOf((double)+214748364.), b.getObject());
 
-      b.setAll(new byte[]{'.', '0'}, 0, 2);
-      assertEquals(Double.valueOf((double).0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'0', '.'}, 0, 2);
-      assertEquals(Double.valueOf((double)0.), b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'.', '0'}, 0, 2);
+      assertEquals(Double.valueOf((double).0), b.getObject());
+      initLazyObject(b,new byte[]{'0', '.'}, 0, 2);
+      assertEquals(Double.valueOf((double)0.), b.getObject());
       
-      b.setAll(new byte[]{'a', '1', 'b'}, 1, 2);
-      assertNull(b.getPrimitiveObject());
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'.', '1', '2', '3'}, 0, 1);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', '2', '3'}, 0, 1);
-      assertNull(b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', '2', '3'}, 0, 1);
-      assertNull(b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'a', '1', 'b'}, 1, 2);
+      assertNull(b.getObject());
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'.', '1', '2', '3'}, 0, 1);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', '2', '3'}, 0, 1);
+      assertNull(b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', '2', '3'}, 0, 1);
+      assertNull(b.getObject());
       
-      b.setAll(new byte[]{'-', '1', 'e', '3', '3', '3', '3', '3', '3'}, 0, 9);
-      assertEquals(Double.NEGATIVE_INFINITY, b.getPrimitiveObject());
-      b.setAll(new byte[]{'+', '1', 'e', '3', '3', '3', '3', '3', '3'}, 0, 9);
-      assertEquals(Double.POSITIVE_INFINITY, b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'-', '1', 'e', '3', '3', '3', '3', '3', '3'}, 0, 9);
+      assertEquals(Double.NEGATIVE_INFINITY, b.getObject());
+      initLazyObject(b,new byte[]{'+', '1', 'e', '3', '3', '3', '3', '3', '3'}, 0, 9);
+      assertEquals(Double.POSITIVE_INFINITY, b.getObject());
 
-      b.setAll(new byte[]{'+', '1', 'e', '-', '3', '3', '3', '3', '3'}, 0, 8);
-      assertEquals(Double.valueOf((double)0), b.getPrimitiveObject());
-      b.setAll(new byte[]{'-', '1', 'e', '-', '3', '3', '3', '3', '3'}, 0, 8);
-      assertEquals(Double.valueOf((double)-0.0), b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'+', '1', 'e', '-', '3', '3', '3', '3', '3'}, 0, 8);
+      assertEquals(Double.valueOf((double)0), b.getObject());
+      initLazyObject(b,new byte[]{'-', '1', 'e', '-', '3', '3', '3', '3', '3'}, 0, 8);
+      assertEquals(Double.valueOf((double)-0.0), b.getObject());
       
     } catch (Throwable e) {
       e.printStackTrace();
@@ -303,10 +321,12 @@ public void testLazyDouble() throws Throwable {
   public void testLazyString() throws Throwable {
     try {
       LazyString b = new LazyString();
-      b.setAll(new byte[]{'0'}, 0, 1);
-      assertEquals("0", b.getPrimitiveObject());
-      b.setAll(new byte[]{'0', '1', '2'}, 1, 1);
-      assertEquals("1", b.getPrimitiveObject());
+      initLazyObject(b,new byte[]{'0'}, 0, 0);
+      assertEquals("", b.getObject());
+      initLazyObject(b,new byte[]{'0'}, 0, 1);
+      assertEquals("0", b.getObject());
+      initLazyObject(b,new byte[]{'0', '1', '2'}, 1, 1);
+      assertEquals("1", b.getObject());
       
     } catch (Throwable e) {
       e.printStackTrace();
diff --git a/serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazySimpleSerDe.java b/serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazySimpleSerDe.java
index 90743d74ef..f5dc35137e 100644
--- a/serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazySimpleSerDe.java
+++ b/serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazySimpleSerDe.java
@@ -183,5 +183,4 @@ public void testLazySimpleSerDeMissingColumns() throws Throwable {
     }
   }
   
-  
 }
