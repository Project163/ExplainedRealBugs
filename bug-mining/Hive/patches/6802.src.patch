diff --git a/itests/src/test/resources/testconfiguration.properties b/itests/src/test/resources/testconfiguration.properties
index 3a5aec7d6b..146f6305d1 100644
--- a/itests/src/test/resources/testconfiguration.properties
+++ b/itests/src/test/resources/testconfiguration.properties
@@ -469,6 +469,7 @@ minillaplocal.query.files=\
   runtime_stats_hs2.q,\
   bucketsortoptimize_insert_2.q,\
   change_allowincompatible_vectorization_false_date.q,\
+  char_trailing_space.q,\
   check_constraint.q,\
   cbo_gby.q,\
   cbo_join.q,\
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/OctetLength.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/OctetLength.java
index ebea38d375..59583c52c9 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/OctetLength.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/OctetLength.java
@@ -25,6 +25,10 @@
 import org.apache.hadoop.hive.ql.exec.vector.VectorExpressionDescriptor;
 import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;
+import org.apache.hadoop.hive.serde2.typeinfo.CharTypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
 
 public class OctetLength extends VectorExpression {
   private static final long serialVersionUID = 1L;
@@ -65,6 +69,10 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
       return;
     }
 
+    boolean isFixedLength = inputTypeInfos[0].getCategory() == Category.PRIMITIVE &&
+        ((PrimitiveTypeInfo) inputTypeInfos[0]).getPrimitiveCategory() == PrimitiveCategory.CHAR;
+    int fixedLength = isFixedLength ? ((CharTypeInfo) inputTypeInfos[0]).getLength() : -1;
+
     // We do not need to do a column reset since we are carefully changing the output.
     outputColVector.isRepeating = false;
 
@@ -72,7 +80,7 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
       if (inputColVector.noNulls || !inputIsNull[0]) {
         // Set isNull before call in case it changes it mind.
         outputIsNull[0] = false;
-        resultLen[0] = length[0];
+        resultLen[0] = isFixedLength ? fixedLength : length[0];
       } else {
         outputIsNull[0] = true;
         outputColVector.noNulls = false;
@@ -95,12 +103,12 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
            final int i = sel[j];
            // Set isNull before call in case it changes it mind.
            outputIsNull[i] = false;
-           resultLen[i] = length[i];
+           resultLen[i] = isFixedLength ? fixedLength : length[i];
          }
         } else {
           for(int j = 0; j != n; j++) {
             final int i = sel[j];
-            resultLen[i] = length[i];
+            resultLen[i] = isFixedLength ? fixedLength : length[i];
           }
         }
       } else {
@@ -112,7 +120,7 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
           outputColVector.noNulls = true;
         }
         for(int i = 0; i != n; i++) {
-          resultLen[i] = length[i];
+          resultLen[i] = isFixedLength ? fixedLength : length[i];
         }
       }
     } else {
@@ -128,14 +136,14 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
           int i = sel[j];
           outputIsNull[i] = inputIsNull[i];
           if (!inputIsNull[i]) {
-            resultLen[i] = length[i];
+            resultLen[i] = isFixedLength ? fixedLength : length[i];
           }
         }
       } else {
         System.arraycopy(inputIsNull, 0, outputIsNull, 0, n);
         for(int i = 0; i != n; i++) {
           if (!inputIsNull[i]) {
-            resultLen[i] = length[i];
+            resultLen[i] = isFixedLength ? fixedLength : length[i];
           }
         }
       }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/StringLength.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/StringLength.java
index 956fd7b7b5..ea33843704 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/StringLength.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/StringLength.java
@@ -25,6 +25,11 @@
 import org.apache.hadoop.hive.ql.exec.vector.VectorExpressionDescriptor;
 import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;
+import org.apache.hadoop.hive.serde2.typeinfo.CharTypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 
 /**
  * Calculate the length of the strings in the input column vector, and store
@@ -71,6 +76,10 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
       return;
     }
 
+    boolean isFixedLength = inputTypeInfos[0].getCategory() == Category.PRIMITIVE &&
+        ((PrimitiveTypeInfo) inputTypeInfos[0]).getPrimitiveCategory() == PrimitiveCategory.CHAR;
+    int fixedLength = isFixedLength ? ((CharTypeInfo) inputTypeInfos[0]).getLength() : -1;
+
     // We do not need to do a column reset since we are carefully changing the output.
     outputColVector.isRepeating = false;
 
@@ -78,7 +87,7 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
       if (inputColVector.noNulls || !inputIsNull[0]) {
         // Set isNull before call in case it changes it mind.
         outputIsNull[0] = false;
-        resultLen[0] = utf8StringLength(vector[0], start[0], length[0]);
+        resultLen[0] = isFixedLength ? fixedLength : utf8StringLength(vector[0], start[0], length[0]);
       } else {
         outputIsNull[0] = true;
         outputColVector.noNulls = false;
@@ -97,12 +106,12 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
            final int i = sel[j];
            // Set isNull before call in case it changes it mind.
            outputIsNull[i] = false;
-           resultLen[i] = utf8StringLength(vector[i], start[i], length[i]);
+           resultLen[i] = isFixedLength ? fixedLength : utf8StringLength(vector[i], start[i], length[i]);
          }
         } else {
           for(int j = 0; j != n; j++) {
             final int i = sel[j];
-            resultLen[i] = utf8StringLength(vector[i], start[i], length[i]);
+            resultLen[i] = isFixedLength ? fixedLength : utf8StringLength(vector[i], start[i], length[i]);
           }
         }
       } else {
@@ -114,7 +123,7 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
           outputColVector.noNulls = true;
         }
         for(int i = 0; i != n; i++) {
-          resultLen[i] = utf8StringLength(vector[i], start[i], length[i]);
+          resultLen[i] = isFixedLength ? fixedLength : utf8StringLength(vector[i], start[i], length[i]);
         }
       }
     } else /* there are nulls in the inputColVector */ {
@@ -127,7 +136,7 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
           int i = sel[j];
           outputColVector.isNull[i] = inputColVector.isNull[i];
           if (!inputColVector.isNull[i]) {
-            resultLen[i] = utf8StringLength(vector[i], start[i], length[i]);
+            resultLen[i] = isFixedLength ? fixedLength : utf8StringLength(vector[i], start[i], length[i]);
           }
         }
         outputColVector.isRepeating = false;
@@ -135,7 +144,7 @@ public void evaluate(VectorizedRowBatch batch) throws HiveException {
         for(int i = 0; i != n; i++) {
           outputColVector.isNull[i] = inputColVector.isNull[i];
           if (!inputColVector.isNull[i]) {
-            resultLen[i] = utf8StringLength(vector[i], start[i], length[i]);
+            resultLen[i] = isFixedLength ? fixedLength : utf8StringLength(vector[i], start[i], length[i]);
           }
         }
       }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCharacterLength.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCharacterLength.java
index ce6cd301d7..30c40d39da 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCharacterLength.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCharacterLength.java
@@ -27,6 +27,7 @@
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.CharTypeInfo;
 import org.apache.hadoop.io.BytesWritable;
 import org.apache.hadoop.io.IntWritable;
 
@@ -40,6 +41,7 @@ public class GenericUDFCharacterLength extends GenericUDF {
   private transient PrimitiveObjectInspector argumentOI;
   private transient PrimitiveObjectInspectorConverter.StringConverter stringConverter;
   private transient boolean isInputString;
+  private transient boolean isInputFixedLength;
 
   @Override
   public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumentException {
@@ -59,6 +61,8 @@ public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumen
     ObjectInspector outputOI = null;
     switch (inputType) {
       case CHAR:
+        isInputFixedLength = true;
+        result.set(((CharTypeInfo) argumentOI.getTypeInfo()).getLength());
       case VARCHAR:
       case STRING:
         isInputString = true;
@@ -90,6 +94,11 @@ public Object evaluate(DeferredObject[] arguments) throws HiveException {
         return null;
       }
 
+      // For char, we do not need to explore the data
+      if (isInputFixedLength) {
+        return result;
+      }
+
       data = val.getBytes();
     } else {
       BytesWritable val = null;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLength.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLength.java
index f4ac350b71..f9ca15d5bd 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLength.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLength.java
@@ -28,6 +28,7 @@
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.CharTypeInfo;
 import org.apache.hadoop.io.BytesWritable;
 import org.apache.hadoop.io.IntWritable;
 
@@ -46,6 +47,7 @@ public class GenericUDFLength extends GenericUDF {
   private transient PrimitiveObjectInspectorConverter.StringConverter stringConverter;
   private transient PrimitiveObjectInspectorConverter.BinaryConverter binaryConverter;
   private transient boolean isInputString;
+  private transient boolean isInputFixedLength;
 
   @Override
   public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumentException {
@@ -64,6 +66,8 @@ public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumen
     ObjectInspector outputOI = null;
     switch (inputType) {
       case CHAR:
+        isInputFixedLength = true;
+        result.set(((CharTypeInfo) argumentOI.getTypeInfo()).getLength());
       case VARCHAR:
       case STRING:
         isInputString = true;
@@ -98,6 +102,11 @@ public Object evaluate(DeferredObject[] arguments) throws HiveException {
         return null;
       }
 
+      // For char, we do not need to explore the data
+      if (isInputFixedLength) {
+        return result;
+      }
+
       data = val.getBytes();
 
       int len = 0;
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOctetLength.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOctetLength.java
index 825066fc02..2a39ebb63b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOctetLength.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOctetLength.java
@@ -27,6 +27,7 @@
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.CharTypeInfo;
 import org.apache.hadoop.io.BytesWritable;
 import org.apache.hadoop.io.IntWritable;
 
@@ -40,6 +41,7 @@ public class GenericUDFOctetLength extends GenericUDF {
   private transient PrimitiveObjectInspector argumentOI;
   private transient PrimitiveObjectInspectorConverter.StringConverter stringConverter;
   private transient boolean isInputString;
+  private transient boolean isInputFixedLength;
 
   @Override
   public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumentException {
@@ -59,6 +61,8 @@ public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumen
     ObjectInspector outputOI = null;
     switch (inputType) {
       case CHAR:
+        isInputFixedLength = true;
+        result.set(((CharTypeInfo) argumentOI.getTypeInfo()).getLength());
       case VARCHAR:
       case STRING:
         isInputString = true;
@@ -90,6 +94,11 @@ public Object evaluate(GenericUDF.DeferredObject[] arguments) throws HiveExcepti
         return null;
       }
 
+      // For char, we do not need to explore the data
+      if (isInputFixedLength) {
+        return result;
+      }
+
       data = val.getBytes();
     } else {
       BytesWritable val = null;
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorStringExpressions.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorStringExpressions.java
index 902f29ee9f..8a521f9877 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorStringExpressions.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorStringExpressions.java
@@ -63,6 +63,9 @@
 import org.apache.hadoop.hive.ql.exec.vector.util.VectorizedRowGroupGenUtil;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.udf.UDFLike;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
 import org.apache.hadoop.io.BooleanWritable;
 import org.apache.hadoop.io.Text;
 import org.junit.Test;
@@ -4138,9 +4141,12 @@ public void testColUpper() throws HiveException {
   @Test
   public void testStringLength() throws HiveException {
 
+    StringLength expr = new StringLength(0, 1);
+    expr.inputTypeInfos = new TypeInfo[1];
+    expr.inputTypeInfos[0] = TypeInfoFactory.stringTypeInfo;
+
     // has nulls, not repeating
     VectorizedRowBatch batch = makeStringBatchMixedCharSize();
-    StringLength expr = new StringLength(0, 1);
     expr.evaluate(batch);
     LongColumnVector outCol = (LongColumnVector) batch.cols[1];
     Assert.assertEquals(5, outCol.vector[1]); // length of green is 5
diff --git a/ql/src/test/queries/clientpositive/char_trailing_space.q b/ql/src/test/queries/clientpositive/char_trailing_space.q
new file mode 100644
index 0000000000..a8fb6d06cb
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/char_trailing_space.q
@@ -0,0 +1,8 @@
+create table char_trailing_space(a char(2), b varchar(2));
+insert into char_trailing_space values('L ', 'L ');
+
+select length(a),length(b) from char_trailing_space;
+select character_length(a),character_length(b) from char_trailing_space;
+select octet_length(a),octet_length(b) from char_trailing_space;
+
+drop table char_trailing_space;
diff --git a/ql/src/test/results/clientpositive/alter_char2.q.out b/ql/src/test/results/clientpositive/alter_char2.q.out
index 2084477c50..76d72341a5 100644
--- a/ql/src/test/results/clientpositive/alter_char2.q.out
+++ b/ql/src/test/results/clientpositive/alter_char2.q.out
@@ -35,7 +35,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alter_char2
 POSTHOOK: Input: default@alter_char2@hr=1
 #### A masked pattern was here ####
-val_238                                                                                                                                                                                                                                                        	7
+val_238                                                                                                                                                                                                                                                        	255
 PREHOOK: query: alter table alter_char2 change column c1 c1 char(10)
 PREHOOK: type: ALTERTABLE_RENAMECOL
 PREHOOK: Input: default@alter_char2
@@ -54,7 +54,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alter_char2
 POSTHOOK: Input: default@alter_char2@hr=1
 #### A masked pattern was here ####
-1	val_238   	7
+1	val_238   	10
 PREHOOK: query: insert overwrite table alter_char2 partition (hr=2)
   select key from src limit 1
 PREHOOK: type: QUERY
@@ -76,7 +76,7 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alter_char2
 POSTHOOK: Input: default@alter_char2@hr=1
 #### A masked pattern was here ####
-1	val_238   	7
+1	val_238   	10
 PREHOOK: query: select hr, c1, length(c1) from alter_char2 where hr = 2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@alter_char2
@@ -87,4 +87,4 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alter_char2
 POSTHOOK: Input: default@alter_char2@hr=2
 #### A masked pattern was here ####
-2	238       	3
+2	238       	10
diff --git a/ql/src/test/results/clientpositive/char_udf1.q.out b/ql/src/test/results/clientpositive/char_udf1.q.out
index 09fb69782f..f5d1acf818 100644
--- a/ql/src/test/results/clientpositive/char_udf1.q.out
+++ b/ql/src/test/results/clientpositive/char_udf1.q.out
@@ -159,7 +159,7 @@ from char_udf_1 limit 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@char_udf_1
 #### A masked pattern was here ####
-7	7	true
+7	20	false
 PREHOOK: query: select
   locate('a', 'abcdabcd', 3),
   locate(cast('a' as char(1)), cast('abcdabcd' as char(10)), 3),
diff --git a/ql/src/test/results/clientpositive/llap/char_trailing_space.q.out b/ql/src/test/results/clientpositive/llap/char_trailing_space.q.out
new file mode 100644
index 0000000000..cea90f7889
--- /dev/null
+++ b/ql/src/test/results/clientpositive/llap/char_trailing_space.q.out
@@ -0,0 +1,53 @@
+PREHOOK: query: create table char_trailing_space(a char(2), b varchar(2))
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@char_trailing_space
+POSTHOOK: query: create table char_trailing_space(a char(2), b varchar(2))
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@char_trailing_space
+PREHOOK: query: insert into char_trailing_space values('L ', 'L ')
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@char_trailing_space
+POSTHOOK: query: insert into char_trailing_space values('L ', 'L ')
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@char_trailing_space
+POSTHOOK: Lineage: char_trailing_space.a SCRIPT []
+POSTHOOK: Lineage: char_trailing_space.b SCRIPT []
+PREHOOK: query: select length(a),length(b) from char_trailing_space
+PREHOOK: type: QUERY
+PREHOOK: Input: default@char_trailing_space
+#### A masked pattern was here ####
+POSTHOOK: query: select length(a),length(b) from char_trailing_space
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@char_trailing_space
+#### A masked pattern was here ####
+2	2
+PREHOOK: query: select character_length(a),character_length(b) from char_trailing_space
+PREHOOK: type: QUERY
+PREHOOK: Input: default@char_trailing_space
+#### A masked pattern was here ####
+POSTHOOK: query: select character_length(a),character_length(b) from char_trailing_space
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@char_trailing_space
+#### A masked pattern was here ####
+2	2
+PREHOOK: query: select octet_length(a),octet_length(b) from char_trailing_space
+PREHOOK: type: QUERY
+PREHOOK: Input: default@char_trailing_space
+#### A masked pattern was here ####
+POSTHOOK: query: select octet_length(a),octet_length(b) from char_trailing_space
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@char_trailing_space
+#### A masked pattern was here ####
+2	2
+PREHOOK: query: drop table char_trailing_space
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@char_trailing_space
+PREHOOK: Output: default@char_trailing_space
+POSTHOOK: query: drop table char_trailing_space
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@char_trailing_space
+POSTHOOK: Output: default@char_trailing_space
diff --git a/ql/src/test/results/clientpositive/llap/parquet_types.q.out b/ql/src/test/results/clientpositive/llap/parquet_types.q.out
index 508ac16878..9678bb4cb0 100644
--- a/ql/src/test/results/clientpositive/llap/parquet_types.q.out
+++ b/ql/src/test/results/clientpositive/llap/parquet_types.q.out
@@ -192,10 +192,10 @@ POSTHOOK: query: SELECT cchar, LENGTH(cchar), cvarchar, LENGTH(cvarchar) FROM pa
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@parquet_types
 #### A masked pattern was here ####
-a    	1	a  	3
-ab   	2	ab 	3
-abc  	3	abc	3
-abcd 	4	abcd	4
+a    	5	a  	3
+ab   	5	ab 	3
+abc  	5	abc	3
+abcd 	5	abcd	4
 abcde	5	abcde	5
 abcde	5	abcdef	6
 abcde	5	abcdefg	7
diff --git a/ql/src/test/results/clientpositive/llap/vector_char_varchar_1.q.out b/ql/src/test/results/clientpositive/llap/vector_char_varchar_1.q.out
index 5a23539cc9..0ba2755dec 100644
--- a/ql/src/test/results/clientpositive/llap/vector_char_varchar_1.q.out
+++ b/ql/src/test/results/clientpositive/llap/vector_char_varchar_1.q.out
@@ -291,4 +291,4 @@ char_ctas_1._c0	char_ctas_1._c1
 10	m thgilnus
 10	sdrow emos
 10	t eht sgeb
-8	wolley  
+10	wolley  
diff --git a/ql/src/test/results/clientpositive/llap/vectorized_parquet_types.q.out b/ql/src/test/results/clientpositive/llap/vectorized_parquet_types.q.out
index d0d13ba40a..cf45c90047 100644
--- a/ql/src/test/results/clientpositive/llap/vectorized_parquet_types.q.out
+++ b/ql/src/test/results/clientpositive/llap/vectorized_parquet_types.q.out
@@ -211,10 +211,10 @@ POSTHOOK: query: SELECT cchar, LENGTH(cchar), cvarchar, LENGTH(cvarchar), cdecim
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@parquet_types_n2
 #### A masked pattern was here ####
-a    	1	a  	3	48.88	1
-ab   	2	ab 	3	8.72	1
-abc  	3	abc	3	90.21	1
-abcd 	4	abcd	4	3.89	1
+a    	5	a  	3	48.88	1
+ab   	5	ab 	3	8.72	1
+abc  	5	abc	3	90.21	1
+abcd 	5	abcd	4	3.89	1
 abcde	5	abcde	5	56.23	1
 abcde	5	abcdef	6	90.21	1
 abcde	5	abcdefg	7	6.09	1
@@ -552,10 +552,10 @@ POSTHOOK: query: SELECT cchar, LENGTH(cchar), cvarchar, LENGTH(cvarchar), cdecim
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@parquet_type_nodict
 #### A masked pattern was here ####
-a    	1	a  	3	48.88	1
-ab   	2	ab 	3	8.72	1
-abc  	3	abc	3	90.21	1
-abcd 	4	abcd	4	3.89	1
+a    	5	a  	3	48.88	1
+ab   	5	ab 	3	8.72	1
+abc  	5	abc	3	90.21	1
+abcd 	5	abcd	4	3.89	1
 abcde	5	abcde	5	56.23	1
 abcde	5	abcdef	6	90.21	1
 abcde	5	abcdefg	7	6.09	1
diff --git a/ql/src/test/results/clientpositive/vectorized_parquet_types.q.out b/ql/src/test/results/clientpositive/vectorized_parquet_types.q.out
index c1f2d54057..772e5b05a1 100644
--- a/ql/src/test/results/clientpositive/vectorized_parquet_types.q.out
+++ b/ql/src/test/results/clientpositive/vectorized_parquet_types.q.out
@@ -279,10 +279,10 @@ POSTHOOK: query: SELECT cchar, LENGTH(cchar), cvarchar, LENGTH(cvarchar), cdecim
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@parquet_types_n2
 #### A masked pattern was here ####
-a    	1	a  	3	48.88	1
-ab   	2	ab 	3	8.72	1
-abc  	3	abc	3	90.21	1
-abcd 	4	abcd	4	3.89	1
+a    	5	a  	3	48.88	1
+ab   	5	ab 	3	8.72	1
+abc  	5	abc	3	90.21	1
+abcd 	5	abcd	4	3.89	1
 abcde	5	abcde	5	56.23	1
 abcde	5	abcdef	6	90.21	1
 abcde	5	abcdefg	7	6.09	1
@@ -678,10 +678,10 @@ POSTHOOK: query: SELECT cchar, LENGTH(cchar), cvarchar, LENGTH(cvarchar), cdecim
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@parquet_type_nodict
 #### A masked pattern was here ####
-a    	1	a  	3	48.88	1
-ab   	2	ab 	3	8.72	1
-abc  	3	abc	3	90.21	1
-abcd 	4	abcd	4	3.89	1
+a    	5	a  	3	48.88	1
+ab   	5	ab 	3	8.72	1
+abc  	5	abc	3	90.21	1
+abcd 	5	abcd	4	3.89	1
 abcde	5	abcde	5	56.23	1
 abcde	5	abcdef	6	90.21	1
 abcde	5	abcdefg	7	6.09	1
