diff --git a/contrib/src/test/results/clientpositive/udf_example_arraymapstruct.q.out b/contrib/src/test/results/clientpositive/udf_example_arraymapstruct.q.out
index e876cdd4ac..44aa263bf4 100644
--- a/contrib/src/test/results/clientpositive/udf_example_arraymapstruct.q.out
+++ b/contrib/src/test/results/clientpositive/udf_example_arraymapstruct.q.out
@@ -34,14 +34,14 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: example_arraysum(lint) (type: double), example_mapconcat(mstringstring) (type: string), example_structprint(lintstring[0]) (type: string)
               outputColumnNames: _col0, _col1, _col2
-              Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
               File Output Operator
                 compressed: false
-                Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/queries/clientpositive/input_lazyserde.q b/ql/src/test/queries/clientpositive/input_lazyserde.q
index 69c0d04074..74d7a2ae61 100644
--- a/ql/src/test/queries/clientpositive/input_lazyserde.q
+++ b/ql/src/test/queries/clientpositive/input_lazyserde.q
@@ -1,5 +1,6 @@
 -- SORT_QUERY_RESULTS
 
+DROP TABLE dest1;
 CREATE TABLE dest1(a array<int>, b array<string>, c map<string,string>, d int, e string)
 ROW FORMAT DELIMITED
 FIELDS TERMINATED BY '1'
@@ -32,5 +33,21 @@ SELECT * from dest1;
 
 CREATE TABLE destBin(a UNIONTYPE<int, double, array<string>, struct<col1:int,col2:string>>) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe' STORED AS SEQUENCEFILE;
 INSERT OVERWRITE TABLE destBin SELECT create_union( CASE WHEN key < 100 THEN 0 WHEN key < 200 THEN 1 WHEN key < 300 THEN 2 WHEN key < 400 THEN 3 ELSE 0 END, key, 2.0, array("one","two"), struct(5,"five")) FROM srcbucket2;
-SELECT * from destBin ORDER BY a;
+SELECT * from destBin;
 DROP TABLE destBin;
+
+DROP TABLE dest2;
+DROP TABLE dest3;
+
+CREATE TABLE dest2 (a map<string,map<string,map<string,uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>>>>)
+  ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe' STORED AS SEQUENCEFILE;
+INSERT OVERWRITE TABLE dest2 SELECT src_thrift.attributes FROM src_thrift;
+SELECT a from dest2 limit 10;
+
+CREATE TABLE dest3 (
+unionfield1 uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>,
+unionfield2 uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>,
+unionfield3 uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>
+) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe' STORED AS SEQUENCEFILE;
+INSERT OVERWRITE TABLE dest3 SELECT src_thrift.unionField1,src_thrift.unionField2,src_thrift.unionField3 from src_thrift;
+SELECT unionfield1, unionField2, unionfield3 from dest3 limit 10;
diff --git a/ql/src/test/results/clientnegative/describe_xpath1.q.out b/ql/src/test/results/clientnegative/describe_xpath1.q.out
index d81c96ebdd..e83e9d6909 100644
--- a/ql/src/test/results/clientnegative/describe_xpath1.q.out
+++ b/ql/src/test/results/clientnegative/describe_xpath1.q.out
@@ -1,4 +1,4 @@
 PREHOOK: query: describe src_thrift.$elem$
 PREHOOK: type: DESCTABLE
 PREHOOK: Input: default@src_thrift
-FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. cannot find field $elem$ from [private int org.apache.hadoop.hive.serde2.thrift.test.Complex.aint, private java.lang.String org.apache.hadoop.hive.serde2.thrift.test.Complex.aString, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lint, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lString, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lintString, private java.util.Map org.apache.hadoop.hive.serde2.thrift.test.Complex.mStringString]
+FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. cannot find field $elem$ from [private int org.apache.hadoop.hive.serde2.thrift.test.Complex.aint, private java.lang.String org.apache.hadoop.hive.serde2.thrift.test.Complex.aString, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lint, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lString, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lintString, private java.util.Map org.apache.hadoop.hive.serde2.thrift.test.Complex.mStringString, private java.util.Map org.apache.hadoop.hive.serde2.thrift.test.Complex.attributes, private org.apache.hadoop.hive.serde2.thrift.test.PropValueUnion org.apache.hadoop.hive.serde2.thrift.test.Complex.unionField1, private org.apache.hadoop.hive.serde2.thrift.test.PropValueUnion org.apache.hadoop.hive.serde2.thrift.test.Complex.unionField2, private org.apache.hadoop.hive.serde2.thrift.test.PropValueUnion org.apache.hadoop.hive.serde2.thrift.test.Complex.unionField3]
diff --git a/ql/src/test/results/clientnegative/describe_xpath2.q.out b/ql/src/test/results/clientnegative/describe_xpath2.q.out
index 2bd0f06131..3c3f263495 100644
--- a/ql/src/test/results/clientnegative/describe_xpath2.q.out
+++ b/ql/src/test/results/clientnegative/describe_xpath2.q.out
@@ -1,4 +1,4 @@
 PREHOOK: query: describe src_thrift.$key$
 PREHOOK: type: DESCTABLE
 PREHOOK: Input: default@src_thrift
-FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. cannot find field $key$ from [private int org.apache.hadoop.hive.serde2.thrift.test.Complex.aint, private java.lang.String org.apache.hadoop.hive.serde2.thrift.test.Complex.aString, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lint, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lString, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lintString, private java.util.Map org.apache.hadoop.hive.serde2.thrift.test.Complex.mStringString]
+FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. cannot find field $key$ from [private int org.apache.hadoop.hive.serde2.thrift.test.Complex.aint, private java.lang.String org.apache.hadoop.hive.serde2.thrift.test.Complex.aString, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lint, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lString, private java.util.List org.apache.hadoop.hive.serde2.thrift.test.Complex.lintString, private java.util.Map org.apache.hadoop.hive.serde2.thrift.test.Complex.mStringString, private java.util.Map org.apache.hadoop.hive.serde2.thrift.test.Complex.attributes, private org.apache.hadoop.hive.serde2.thrift.test.PropValueUnion org.apache.hadoop.hive.serde2.thrift.test.Complex.unionField1, private org.apache.hadoop.hive.serde2.thrift.test.PropValueUnion org.apache.hadoop.hive.serde2.thrift.test.Complex.unionField2, private org.apache.hadoop.hive.serde2.thrift.test.PropValueUnion org.apache.hadoop.hive.serde2.thrift.test.Complex.unionField3]
diff --git a/ql/src/test/results/clientpositive/case_sensitivity.q.out b/ql/src/test/results/clientpositive/case_sensitivity.q.out
index 8684557675..a5b14e8a72 100644
--- a/ql/src/test/results/clientpositive/case_sensitivity.q.out
+++ b/ql/src/test/results/clientpositive/case_sensitivity.q.out
@@ -30,17 +30,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
               predicate: (lint[0] > 0) (type: boolean)
-              Statistics: Num rows: 3 Data size: 437 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
               Select Operator
                 expressions: lint[1] (type: int), lintstring[0].MYSTRING (type: string)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 3 Data size: 437 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 3 Data size: 437 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/columnarserde_create_shortcut.q.out b/ql/src/test/results/clientpositive/columnarserde_create_shortcut.q.out
index 4805836c51..4a34cabb4f 100644
--- a/ql/src/test/results/clientpositive/columnarserde_create_shortcut.q.out
+++ b/ql/src/test/results/clientpositive/columnarserde_create_shortcut.q.out
@@ -29,24 +29,24 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: lint (type: array<int>), lstring (type: array<string>), mstringstring (type: map<string,string>), aint (type: int), astring (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4
-              Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
               Reduce Output Operator
                 sort order: 
                 Map-reduce partition columns: 1 (type: int)
-                Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
                 value expressions: _col0 (type: array<int>), _col1 (type: array<string>), _col2 (type: map<string,string>), _col3 (type: int), _col4 (type: string)
       Reduce Operator Tree:
         Select Operator
           expressions: VALUE._col0 (type: array<int>), VALUE._col1 (type: array<string>), VALUE._col2 (type: map<string,string>), VALUE._col3 (type: int), VALUE._col4 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3, _col4
-          Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
           File Output Operator
             compressed: false
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             table:
                 input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/input17.q.out b/ql/src/test/results/clientpositive/input17.q.out
index 8fff21bb56..8a74ba3dfc 100644
--- a/ql/src/test/results/clientpositive/input17.q.out
+++ b/ql/src/test/results/clientpositive/input17.q.out
@@ -35,32 +35,32 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: (aint + lint[0]) (type: int), lintstring[0] (type: struct<myint:int,mystring:string,underscore_int:int>)
               outputColumnNames: _col0, _col1
-              Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
               Transform Operator
                 command: cat
                 output info:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
                   key expressions: _col0 (type: string)
                   sort order: +
                   Map-reduce partition columns: _col0 (type: string)
-                  Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
                   value expressions: _col0 (type: string), _col1 (type: string)
       Reduce Operator Tree:
         Select Operator
           expressions: UDFToInteger(VALUE._col0) (type: int), VALUE._col1 (type: string)
           outputColumnNames: _col0, _col1
-          Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
           File Output Operator
             compressed: false
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/input5.q.out b/ql/src/test/results/clientpositive/input5.q.out
index 7524ca735d..a39952878d 100644
--- a/ql/src/test/results/clientpositive/input5.q.out
+++ b/ql/src/test/results/clientpositive/input5.q.out
@@ -35,32 +35,32 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: lint (type: array<int>), lintstring (type: array<struct<myint:int,mystring:string,underscore_int:int>>)
               outputColumnNames: _col0, _col1
-              Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
               Transform Operator
                 command: cat
                 output info:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
                   key expressions: _col0 (type: string)
                   sort order: +
                   Map-reduce partition columns: _col0 (type: string)
-                  Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
                   value expressions: _col0 (type: string), _col1 (type: string)
       Reduce Operator Tree:
         Select Operator
           expressions: VALUE._col0 (type: string), VALUE._col1 (type: string)
           outputColumnNames: _col0, _col1
-          Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
           File Output Operator
             compressed: false
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/input_columnarserde.q.out b/ql/src/test/results/clientpositive/input_columnarserde.q.out
index 13cfb7f60b..afa0e28d17 100644
--- a/ql/src/test/results/clientpositive/input_columnarserde.q.out
+++ b/ql/src/test/results/clientpositive/input_columnarserde.q.out
@@ -35,24 +35,24 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: lint (type: array<int>), lstring (type: array<string>), mstringstring (type: map<string,string>), aint (type: int), astring (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4
-              Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
               Reduce Output Operator
                 sort order: 
                 Map-reduce partition columns: 1 (type: int)
-                Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
                 value expressions: _col0 (type: array<int>), _col1 (type: array<string>), _col2 (type: map<string,string>), _col3 (type: int), _col4 (type: string)
       Reduce Operator Tree:
         Select Operator
           expressions: VALUE._col0 (type: array<int>), VALUE._col1 (type: array<string>), VALUE._col2 (type: map<string,string>), VALUE._col3 (type: int), VALUE._col4 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3, _col4
-          Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
           File Output Operator
             compressed: false
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             table:
                 input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
diff --git a/ql/src/test/results/clientpositive/input_dynamicserde.q.out b/ql/src/test/results/clientpositive/input_dynamicserde.q.out
index ebcf1d83ac..30493be357 100644
--- a/ql/src/test/results/clientpositive/input_dynamicserde.q.out
+++ b/ql/src/test/results/clientpositive/input_dynamicserde.q.out
@@ -42,14 +42,14 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: lint (type: array<int>), lstring (type: array<string>), mstringstring (type: map<string,string>), aint (type: int), astring (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4
-              Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
               File Output Operator
                 compressed: false
-                Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/input_lazyserde.q.out b/ql/src/test/results/clientpositive/input_lazyserde.q.out
index 0f685f2765..3cf3bd26bf 100644
--- a/ql/src/test/results/clientpositive/input_lazyserde.q.out
+++ b/ql/src/test/results/clientpositive/input_lazyserde.q.out
@@ -1,6 +1,12 @@
 PREHOOK: query: -- SORT_QUERY_RESULTS
 
-CREATE TABLE dest1(a array<int>, b array<string>, c map<string,string>, d int, e string)
+DROP TABLE dest1
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: -- SORT_QUERY_RESULTS
+
+DROP TABLE dest1
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: CREATE TABLE dest1(a array<int>, b array<string>, c map<string,string>, d int, e string)
 ROW FORMAT DELIMITED
 FIELDS TERMINATED BY '1'
 COLLECTION ITEMS TERMINATED BY '2'
@@ -10,9 +16,7 @@ STORED AS TEXTFILE
 PREHOOK: type: CREATETABLE
 PREHOOK: Output: database:default
 PREHOOK: Output: default@dest1
-POSTHOOK: query: -- SORT_QUERY_RESULTS
-
-CREATE TABLE dest1(a array<int>, b array<string>, c map<string,string>, d int, e string)
+POSTHOOK: query: CREATE TABLE dest1(a array<int>, b array<string>, c map<string,string>, d int, e string)
 ROW FORMAT DELIMITED
 FIELDS TERMINATED BY '1'
 COLLECTION ITEMS TERMINATED BY '2'
@@ -41,24 +45,24 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: lint (type: array<int>), lstring (type: array<string>), mstringstring (type: map<string,string>), aint (type: int), astring (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4
-              Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
               Reduce Output Operator
                 sort order: 
                 Map-reduce partition columns: 1 (type: int)
-                Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
                 value expressions: _col0 (type: array<int>), _col1 (type: array<string>), _col2 (type: map<string,string>), _col3 (type: int), _col4 (type: string)
       Reduce Operator Tree:
         Select Operator
           expressions: VALUE._col0 (type: array<int>), VALUE._col1 (type: array<string>), VALUE._col2 (type: map<string,string>), VALUE._col3 (type: int), VALUE._col4 (type: string)
           outputColumnNames: _col0, _col1, _col2, _col3, _col4
-          Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
           File Output Operator
             compressed: false
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -236,11 +240,11 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket2
 POSTHOOK: Output: default@destbin
 POSTHOOK: Lineage: destbin.a EXPRESSION [(srcbucket2)srcbucket2.FieldSchema(name:key, type:int, comment:null), ]
-PREHOOK: query: SELECT * from destBin ORDER BY a
+PREHOOK: query: SELECT * from destBin
 PREHOOK: type: QUERY
 PREHOOK: Input: default@destbin
 #### A masked pattern was here ####
-POSTHOOK: query: SELECT * from destBin ORDER BY a
+POSTHOOK: query: SELECT * from destBin
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@destbin
 #### A masked pattern was here ####
@@ -752,3 +756,93 @@ POSTHOOK: query: DROP TABLE destBin
 POSTHOOK: type: DROPTABLE
 POSTHOOK: Input: default@destbin
 POSTHOOK: Output: default@destbin
+PREHOOK: query: DROP TABLE dest2
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: DROP TABLE dest2
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: DROP TABLE dest3
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: DROP TABLE dest3
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: CREATE TABLE dest2 (a map<string,map<string,map<string,uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>>>>)
+  ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe' STORED AS SEQUENCEFILE
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@dest2
+POSTHOOK: query: CREATE TABLE dest2 (a map<string,map<string,map<string,uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>>>>)
+  ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe' STORED AS SEQUENCEFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@dest2
+PREHOOK: query: INSERT OVERWRITE TABLE dest2 SELECT src_thrift.attributes FROM src_thrift
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src_thrift
+PREHOOK: Output: default@dest2
+POSTHOOK: query: INSERT OVERWRITE TABLE dest2 SELECT src_thrift.attributes FROM src_thrift
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src_thrift
+POSTHOOK: Output: default@dest2
+POSTHOOK: Lineage: dest2.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:attributes, type:map<string,map<string,map<string,uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>>>>, comment:from deserializer), ]
+PREHOOK: query: SELECT a from dest2 limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@dest2
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT a from dest2 limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@dest2
+#### A masked pattern was here ####
+{"key_0":{"erVal0":{"value_0":{3:1.0}}}}
+{"key_1":{"erVal1":{"value_1":{3:1.0}}}}
+{"key_2":{"erVal2":{"value_2":{3:1.0}}}}
+{"key_3":{"erVal3":{"value_3":{3:1.0}}}}
+{"key_4":{"erVal4":{"value_4":{3:1.0}}}}
+{"key_5":{"erVal5":{"value_5":{3:1.0}}}}
+{"key_6":{"erVal6":{"value_6":{3:1.0}}}}
+{"key_7":{"erVal7":{"value_7":{3:1.0}}}}
+{"key_8":{"erVal8":{"value_8":{3:1.0}}}}
+{"key_9":{"erVal9":{"value_9":{3:1.0}}}}
+PREHOOK: query: CREATE TABLE dest3 (
+unionfield1 uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>,
+unionfield2 uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>,
+unionfield3 uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>
+) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe' STORED AS SEQUENCEFILE
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@dest3
+POSTHOOK: query: CREATE TABLE dest3 (
+unionfield1 uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>,
+unionfield2 uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>,
+unionfield3 uniontype<int, bigint, string, double, boolean, array<string>, map<string,string>>
+) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe' STORED AS SEQUENCEFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@dest3
+PREHOOK: query: INSERT OVERWRITE TABLE dest3 SELECT src_thrift.unionField1,src_thrift.unionField2,src_thrift.unionField3 from src_thrift
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src_thrift
+PREHOOK: Output: default@dest3
+POSTHOOK: query: INSERT OVERWRITE TABLE dest3 SELECT src_thrift.unionField1,src_thrift.unionField2,src_thrift.unionField3 from src_thrift
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src_thrift
+POSTHOOK: Output: default@dest3
+POSTHOOK: Lineage: dest3.unionfield1 SIMPLE [(src_thrift)src_thrift.FieldSchema(name:unionfield1, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer), ]
+POSTHOOK: Lineage: dest3.unionfield2 SIMPLE [(src_thrift)src_thrift.FieldSchema(name:unionfield2, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer), ]
+POSTHOOK: Lineage: dest3.unionfield3 SIMPLE [(src_thrift)src_thrift.FieldSchema(name:unionfield3, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer), ]
+PREHOOK: query: SELECT unionfield1, unionField2, unionfield3 from dest3 limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@dest3
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT unionfield1, unionField2, unionfield3 from dest3 limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@dest3
+#### A masked pattern was here ####
+{2:"test0"}	{6:{"key_0":"value_0"}}	{5:["0","0","0"]}
+{2:"test1"}	{6:{"key_1":"value_1"}}	{5:["10","100","1000"]}
+{2:"test2"}	{6:{"key_2":"value_2"}}	{5:["20","200","2000"]}
+{2:"test3"}	{6:{"key_3":"value_3"}}	{5:["30","300","3000"]}
+{2:"test4"}	{6:{"key_4":"value_4"}}	{5:["40","400","4000"]}
+{2:"test5"}	{6:{"key_5":"value_5"}}	{5:["50","500","5000"]}
+{2:"test6"}	{6:{"key_6":"value_6"}}	{5:["60","600","6000"]}
+{2:"test7"}	{6:{"key_7":"value_7"}}	{5:["70","700","7000"]}
+{2:"test8"}	{6:{"key_8":"value_8"}}	{5:["80","800","8000"]}
+{2:"test9"}	{6:{"key_9":"value_9"}}	{5:["90","900","9000"]}
diff --git a/ql/src/test/results/clientpositive/input_testxpath.q.out b/ql/src/test/results/clientpositive/input_testxpath.q.out
index 3f4b96e409..e07628aaea 100644
--- a/ql/src/test/results/clientpositive/input_testxpath.q.out
+++ b/ql/src/test/results/clientpositive/input_testxpath.q.out
@@ -30,14 +30,14 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: lint[1] (type: int), lintstring[0].mystring (type: string), mstringstring['key_2'] (type: string)
               outputColumnNames: _col0, _col1, _col2
-              Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
               File Output Operator
                 compressed: false
-                Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/input_testxpath2.q.out b/ql/src/test/results/clientpositive/input_testxpath2.q.out
index af1e99991f..d3a6f29a4a 100644
--- a/ql/src/test/results/clientpositive/input_testxpath2.q.out
+++ b/ql/src/test/results/clientpositive/input_testxpath2.q.out
@@ -30,17 +30,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
               predicate: (lint is not null and (not mstringstring is null)) (type: boolean)
-              Statistics: Num rows: 3 Data size: 437 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
               Select Operator
                 expressions: size(lint) (type: int), size(lintstring) (type: int), size(mstringstring) (type: int)
                 outputColumnNames: _col0, _col1, _col2
-                Statistics: Num rows: 3 Data size: 437 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 3 Data size: 437 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/input_testxpath3.q.out b/ql/src/test/results/clientpositive/input_testxpath3.q.out
index b31b2f3838..f7a61abea9 100644
--- a/ql/src/test/results/clientpositive/input_testxpath3.q.out
+++ b/ql/src/test/results/clientpositive/input_testxpath3.q.out
@@ -16,14 +16,14 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: mstringstring['key_9'] (type: string), lintstring.myint (type: array<int>)
               outputColumnNames: _col0, _col1
-              Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
               File Output Operator
                 compressed: false
-                Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/input_testxpath4.q.out b/ql/src/test/results/clientpositive/input_testxpath4.q.out
index 3dca8bfa2b..b522b8ac06 100644
--- a/ql/src/test/results/clientpositive/input_testxpath4.q.out
+++ b/ql/src/test/results/clientpositive/input_testxpath4.q.out
@@ -22,17 +22,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
               predicate: ((mstringstring['key_9'] is not null and lintstring.myint is not null) and lintstring is not null) (type: boolean)
-              Statistics: Num rows: 2 Data size: 292 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 2 Data size: 558 Basic stats: COMPLETE Column stats: NONE
               Select Operator
                 expressions: mstringstring['key_9'] (type: string), lintstring.myint (type: array<int>)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 2 Data size: 292 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 2 Data size: 558 Basic stats: COMPLETE Column stats: NONE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 2 Data size: 292 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 2 Data size: 558 Basic stats: COMPLETE Column stats: NONE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -94,17 +94,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
               predicate: ((mstringstring['key_9'] is not null and lintstring.myint is not null) and lintstring is not null) (type: boolean)
-              Statistics: Num rows: 2 Data size: 292 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 2 Data size: 558 Basic stats: COMPLETE Column stats: NONE
               Select Operator
                 expressions: mstringstring['key_9'] (type: string), lintstring.myint (type: array<int>)
                 outputColumnNames: _col0, _col1
-                Statistics: Num rows: 2 Data size: 292 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 2 Data size: 558 Basic stats: COMPLETE Column stats: NONE
                 File Output Operator
                   compressed: false
-                  Statistics: Num rows: 2 Data size: 292 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 2 Data size: 558 Basic stats: COMPLETE Column stats: NONE
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/inputddl8.q.out b/ql/src/test/results/clientpositive/inputddl8.q.out
index fc13356930..8361110194 100644
--- a/ql/src/test/results/clientpositive/inputddl8.q.out
+++ b/ql/src/test/results/clientpositive/inputddl8.q.out
@@ -30,6 +30,10 @@ lint                	array<int>          	from deserializer
 lstring             	array<string>       	from deserializer   
 lintstring          	array<struct<myint:int,mystring:string,underscore_int:int>>	from deserializer   
 mstringstring       	map<string,string>  	from deserializer   
+attributes          	map<string,map<string,map<string,uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>>>>	from deserializer   
+unionfield1         	uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>	from deserializer   
+unionfield2         	uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>	from deserializer   
+unionfield3         	uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>	from deserializer   
 ds                  	string              	                    
 country             	string              	                    
 	 	 
diff --git a/ql/src/test/results/clientpositive/join_thrift.q.out b/ql/src/test/results/clientpositive/join_thrift.q.out
index e1588c5553..3bbc0b9cec 100644
--- a/ql/src/test/results/clientpositive/join_thrift.q.out
+++ b/ql/src/test/results/clientpositive/join_thrift.q.out
@@ -10,6 +10,10 @@ lint                	array<int>          	from deserializer
 lstring             	array<string>       	from deserializer   
 lintstring          	array<struct<myint:int,mystring:string,underscore_int:int>>	from deserializer   
 mstringstring       	map<string,string>  	from deserializer   
+attributes          	map<string,map<string,map<string,uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>>>>	from deserializer   
+unionfield1         	uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>	from deserializer   
+unionfield2         	uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>	from deserializer   
+unionfield3         	uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>	from deserializer   
 PREHOOK: query: EXPLAIN
 SELECT s1.aint, s2.lintstring
 FROM src_thrift s1
@@ -32,27 +36,27 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: s2
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
               predicate: aint is not null (type: boolean)
-              Statistics: Num rows: 6 Data size: 875 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 6 Data size: 1674 Basic stats: COMPLETE Column stats: NONE
               Reduce Output Operator
                 key expressions: aint (type: int)
                 sort order: +
                 Map-reduce partition columns: aint (type: int)
-                Statistics: Num rows: 6 Data size: 875 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 6 Data size: 1674 Basic stats: COMPLETE Column stats: NONE
                 value expressions: lintstring (type: array<struct<myint:int,mystring:string,underscore_int:int>>)
           TableScan
             alias: s1
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
               predicate: aint is not null (type: boolean)
-              Statistics: Num rows: 6 Data size: 875 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 6 Data size: 1674 Basic stats: COMPLETE Column stats: NONE
               Reduce Output Operator
                 key expressions: aint (type: int)
                 sort order: +
                 Map-reduce partition columns: aint (type: int)
-                Statistics: Num rows: 6 Data size: 875 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 6 Data size: 1674 Basic stats: COMPLETE Column stats: NONE
       Reduce Operator Tree:
         Join Operator
           condition map:
@@ -60,15 +64,15 @@ STAGE PLANS:
           condition expressions:
             0 {KEY.reducesinkkey0}
             1 {VALUE._col3}
-          outputColumnNames: _col0, _col13
-          Statistics: Num rows: 6 Data size: 962 Basic stats: COMPLETE Column stats: NONE
+          outputColumnNames: _col0, _col17
+          Statistics: Num rows: 6 Data size: 1841 Basic stats: COMPLETE Column stats: NONE
           Select Operator
-            expressions: _col0 (type: int), _col13 (type: array<struct<myint:int,mystring:string,underscore_int:int>>)
+            expressions: _col0 (type: int), _col17 (type: array<struct<myint:int,mystring:string,underscore_int:int>>)
             outputColumnNames: _col0, _col1
-            Statistics: Num rows: 6 Data size: 962 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 6 Data size: 1841 Basic stats: COMPLETE Column stats: NONE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 6 Data size: 962 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 6 Data size: 1841 Basic stats: COMPLETE Column stats: NONE
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/udf_case_thrift.q.out b/ql/src/test/results/clientpositive/udf_case_thrift.q.out
index 0fc8e84229..2048a35c9e 100644
--- a/ql/src/test/results/clientpositive/udf_case_thrift.q.out
+++ b/ql/src/test/results/clientpositive/udf_case_thrift.q.out
@@ -45,11 +45,11 @@ STAGE PLANS:
         TableScan
           alias: src_thrift
           Row Limit Per Split: 3
-          Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
           Select Operator
             expressions: CASE (lint[0]) WHEN (0) THEN ((lint[0] + 1)) WHEN (1) THEN ((lint[0] + 2)) WHEN (2) THEN (100) ELSE (5) END (type: int), CASE (lstring[0]) WHEN ('0') THEN ('zero') WHEN ('10') THEN (concat(lstring[0], ' is ten')) ELSE ('default') END (type: string), CASE (lstring[0]) WHEN ('0') THEN (lstring) ELSE (null) END[0] (type: string)
             outputColumnNames: _col0, _col1, _col2
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             ListSink
 
 PREHOOK: query: SELECT CASE src_thrift.lint[0]
diff --git a/ql/src/test/results/clientpositive/udf_coalesce.q.out b/ql/src/test/results/clientpositive/udf_coalesce.q.out
index 0d32476757..322dc4e8a9 100644
--- a/ql/src/test/results/clientpositive/udf_coalesce.q.out
+++ b/ql/src/test/results/clientpositive/udf_coalesce.q.out
@@ -138,11 +138,11 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: src_thrift
-          Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
           Select Operator
             expressions: COALESCE(lint[1],999) (type: int), COALESCE(lintstring[0].mystring,'999') (type: string), COALESCE(mstringstring['key_2'],'999') (type: string)
             outputColumnNames: _col0, _col1, _col2
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             ListSink
 
 PREHOOK: query: SELECT COALESCE(src_thrift.lint[1], 999),
diff --git a/ql/src/test/results/clientpositive/udf_isnull_isnotnull.q.out b/ql/src/test/results/clientpositive/udf_isnull_isnotnull.q.out
index 1f600b4c7c..a7d45ea510 100644
--- a/ql/src/test/results/clientpositive/udf_isnull_isnotnull.q.out
+++ b/ql/src/test/results/clientpositive/udf_isnull_isnotnull.q.out
@@ -95,17 +95,17 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: src_thrift
-          Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
           Filter Operator
             predicate: (lint is not null and (not mstringstring is null)) (type: boolean)
-            Statistics: Num rows: 3 Data size: 437 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: lint is not null (type: boolean), lintstring is not null (type: boolean), mstringstring is not null (type: boolean)
               outputColumnNames: _col0, _col1, _col2
-              Statistics: Num rows: 3 Data size: 437 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
               Limit
                 Number of rows: 1
-                Statistics: Num rows: 1 Data size: 145 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 1 Data size: 279 Basic stats: COMPLETE Column stats: NONE
                 ListSink
 
 PREHOOK: query: FROM src_thrift
diff --git a/ql/src/test/results/clientpositive/udf_size.q.out b/ql/src/test/results/clientpositive/udf_size.q.out
index d7a4fa2328..95b8e61862 100644
--- a/ql/src/test/results/clientpositive/udf_size.q.out
+++ b/ql/src/test/results/clientpositive/udf_size.q.out
@@ -36,17 +36,17 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: src_thrift
-          Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
           Filter Operator
             predicate: (lint is not null and (not mstringstring is null)) (type: boolean)
-            Statistics: Num rows: 3 Data size: 437 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: size(lint) (type: int), size(lintstring) (type: int), size(mstringstring) (type: int), size(null) (type: int)
               outputColumnNames: _col0, _col1, _col2, _col3
-              Statistics: Num rows: 3 Data size: 437 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 3 Data size: 837 Basic stats: COMPLETE Column stats: NONE
               Limit
                 Number of rows: 1
-                Statistics: Num rows: 1 Data size: 145 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 1 Data size: 279 Basic stats: COMPLETE Column stats: NONE
                 ListSink
 
 PREHOOK: query: FROM src_thrift
diff --git a/ql/src/test/results/clientpositive/union21.q.out b/ql/src/test/results/clientpositive/union21.q.out
index 0e47ff490d..eaaffb0fd3 100644
--- a/ql/src/test/results/clientpositive/union21.q.out
+++ b/ql/src/test/results/clientpositive/union21.q.out
@@ -44,17 +44,17 @@ STAGE PLANS:
       Map Operator Tree:
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: astring (type: string)
               outputColumnNames: _col0
-              Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
               Union
-                Statistics: Num rows: 1522 Data size: 56336 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1522 Data size: 59264 Basic stats: COMPLETE Column stats: PARTIAL
                 Select Operator
                   expressions: _col0 (type: string)
                   outputColumnNames: _col0
-                  Statistics: Num rows: 1522 Data size: 56336 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1522 Data size: 59264 Basic stats: COMPLETE Column stats: PARTIAL
                   Group By Operator
                     aggregations: count(1)
                     keys: _col0 (type: string)
@@ -69,17 +69,17 @@ STAGE PLANS:
                       value expressions: _col1 (type: bigint)
           TableScan
             alias: src_thrift
-            Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
             Select Operator
               expressions: lstring[0] (type: string)
               outputColumnNames: _col0
-              Statistics: Num rows: 11 Data size: 1606 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 11 Data size: 3070 Basic stats: COMPLETE Column stats: NONE
               Union
-                Statistics: Num rows: 1522 Data size: 56336 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1522 Data size: 59264 Basic stats: COMPLETE Column stats: PARTIAL
                 Select Operator
                   expressions: _col0 (type: string)
                   outputColumnNames: _col0
-                  Statistics: Num rows: 1522 Data size: 56336 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1522 Data size: 59264 Basic stats: COMPLETE Column stats: PARTIAL
                   Group By Operator
                     aggregations: count(1)
                     keys: _col0 (type: string)
@@ -100,11 +100,11 @@ STAGE PLANS:
               outputColumnNames: _col0
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
               Union
-                Statistics: Num rows: 1522 Data size: 56336 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1522 Data size: 59264 Basic stats: COMPLETE Column stats: PARTIAL
                 Select Operator
                   expressions: _col0 (type: string)
                   outputColumnNames: _col0
-                  Statistics: Num rows: 1522 Data size: 56336 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1522 Data size: 59264 Basic stats: COMPLETE Column stats: PARTIAL
                   Group By Operator
                     aggregations: count(1)
                     keys: _col0 (type: string)
@@ -125,11 +125,11 @@ STAGE PLANS:
               outputColumnNames: _col0
               Statistics: Num rows: 500 Data size: 42500 Basic stats: COMPLETE Column stats: COMPLETE
               Union
-                Statistics: Num rows: 1522 Data size: 56336 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1522 Data size: 59264 Basic stats: COMPLETE Column stats: PARTIAL
                 Select Operator
                   expressions: _col0 (type: string)
                   outputColumnNames: _col0
-                  Statistics: Num rows: 1522 Data size: 56336 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1522 Data size: 59264 Basic stats: COMPLETE Column stats: PARTIAL
                   Group By Operator
                     aggregations: count(1)
                     keys: _col0 (type: string)
@@ -150,11 +150,11 @@ STAGE PLANS:
               outputColumnNames: _col0
               Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
               Union
-                Statistics: Num rows: 1522 Data size: 56336 Basic stats: COMPLETE Column stats: PARTIAL
+                Statistics: Num rows: 1522 Data size: 59264 Basic stats: COMPLETE Column stats: PARTIAL
                 Select Operator
                   expressions: _col0 (type: string)
                   outputColumnNames: _col0
-                  Statistics: Num rows: 1522 Data size: 56336 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1522 Data size: 59264 Basic stats: COMPLETE Column stats: PARTIAL
                   Group By Operator
                     aggregations: count(1)
                     keys: _col0 (type: string)
diff --git a/ql/src/test/results/compiler/plan/case_sensitivity.q.xml b/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
index c62441842f..53aea3c3a2 100644
--- a/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
+++ b/ql/src/test/results/compiler/plan/case_sensitivity.q.xml
@@ -629,7 +629,7 @@
             </void> 
             <void method="put"> 
              <string>totalSize</string> 
-             <string>1606</string> 
+             <string>3070</string> 
             </void> 
             <void method="put"> 
              <string>bucket_count</string> 
@@ -983,7 +983,7 @@
                 <object class="org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPGreaterThan"/> 
                </void> 
                <void property="typeInfo"> 
-                <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
                  <void property="typeName"> 
                   <string>boolean</string> 
                  </void> 
@@ -1132,7 +1132,7 @@
               <string>src_thrift</string> 
              </void> 
              <void property="type"> 
-              <object class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
+              <object id="ListTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                <void property="listElementTypeInfo"> 
                 <object idref="PrimitiveTypeInfo0"/> 
                </void> 
@@ -1155,7 +1155,7 @@
               <string>src_thrift</string> 
              </void> 
              <void property="type"> 
-              <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+              <object id="MapTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
                <void property="mapKeyTypeInfo"> 
                 <object idref="PrimitiveTypeInfo0"/> 
                </void> 
@@ -1169,6 +1169,125 @@
              </void> 
             </object> 
            </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>attributes</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+               <void property="mapKeyTypeInfo"> 
+                <object idref="PrimitiveTypeInfo0"/> 
+               </void> 
+               <void property="mapValueTypeInfo"> 
+                <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+                 <void property="mapKeyTypeInfo"> 
+                  <object idref="PrimitiveTypeInfo0"/> 
+                 </void> 
+                 <void property="mapValueTypeInfo"> 
+                  <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+                   <void property="mapKeyTypeInfo"> 
+                    <object idref="PrimitiveTypeInfo0"/> 
+                   </void> 
+                   <void property="mapValueTypeInfo"> 
+                    <object id="UnionTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.UnionTypeInfo"> 
+                     <void property="allUnionObjectTypeInfos"> 
+                      <object class="java.util.ArrayList"> 
+                       <void method="add"> 
+                        <object idref="PrimitiveTypeInfo1"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                         <void property="typeName"> 
+                          <string>bigint</string> 
+                         </void> 
+                        </object> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="PrimitiveTypeInfo0"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                         <void property="typeName"> 
+                          <string>double</string> 
+                         </void> 
+                        </object> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="PrimitiveTypeInfo2"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="ListTypeInfo2"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="MapTypeInfo0"/> 
+                       </void> 
+                      </object> 
+                     </void> 
+                    </object> 
+                   </void> 
+                  </object> 
+                 </void> 
+                </object> 
+               </void> 
+              </object> 
+             </void> 
+             <void property="typeName"> 
+              <string>map&lt;string,map&lt;string,map&lt;string,uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;&gt;&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield1</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield2</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield3</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
            <void method="add"> 
             <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
              <void property="hiddenVirtualCol"> 
@@ -1181,11 +1300,7 @@
               <string>src_thrift</string> 
              </void> 
              <void property="type"> 
-              <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
-               <void property="typeName"> 
-                <string>bigint</string> 
-               </void> 
-              </object> 
+              <object idref="PrimitiveTypeInfo3"/> 
              </void> 
              <void property="typeName"> 
               <string>bigint</string> 
@@ -1240,13 +1355,13 @@
                <void property="allStructFieldTypeInfos"> 
                 <object class="java.util.ArrayList"> 
                  <void method="add"> 
-                  <object idref="PrimitiveTypeInfo2"/> 
+                  <object idref="PrimitiveTypeInfo3"/> 
                  </void> 
                  <void method="add"> 
                   <object idref="PrimitiveTypeInfo1"/> 
                  </void> 
                  <void method="add"> 
-                  <object idref="PrimitiveTypeInfo2"/> 
+                  <object idref="PrimitiveTypeInfo3"/> 
                  </void> 
                 </object> 
                </void> 
@@ -1340,7 +1455,7 @@
           </void> 
           <void method="put"> 
            <string>totalSize</string> 
-           <string>1606</string> 
+           <string>3070</string> 
           </void> 
           <void method="put"> 
            <string>bucket_count</string> 
diff --git a/ql/src/test/results/compiler/plan/input5.q.xml b/ql/src/test/results/compiler/plan/input5.q.xml
index a881da392b..22afeb1235 100644
--- a/ql/src/test/results/compiler/plan/input5.q.xml
+++ b/ql/src/test/results/compiler/plan/input5.q.xml
@@ -279,7 +279,7 @@
             </void> 
             <void method="put"> 
              <string>totalSize</string> 
-             <string>1606</string> 
+             <string>3070</string> 
             </void> 
             <void method="put"> 
              <string>bucket_count</string> 
@@ -955,7 +955,7 @@
               <string>src_thrift</string> 
              </void> 
              <void property="type"> 
-              <object class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
+              <object id="ListTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                <void property="listElementTypeInfo"> 
                 <object idref="PrimitiveTypeInfo0"/> 
                </void> 
@@ -991,7 +991,7 @@
               <string>src_thrift</string> 
              </void> 
              <void property="type"> 
-              <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+              <object id="MapTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
                <void property="mapKeyTypeInfo"> 
                 <object idref="PrimitiveTypeInfo0"/> 
                </void> 
@@ -1005,6 +1005,129 @@
              </void> 
             </object> 
            </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>attributes</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+               <void property="mapKeyTypeInfo"> 
+                <object idref="PrimitiveTypeInfo0"/> 
+               </void> 
+               <void property="mapValueTypeInfo"> 
+                <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+                 <void property="mapKeyTypeInfo"> 
+                  <object idref="PrimitiveTypeInfo0"/> 
+                 </void> 
+                 <void property="mapValueTypeInfo"> 
+                  <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+                   <void property="mapKeyTypeInfo"> 
+                    <object idref="PrimitiveTypeInfo0"/> 
+                   </void> 
+                   <void property="mapValueTypeInfo"> 
+                    <object id="UnionTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.UnionTypeInfo"> 
+                     <void property="allUnionObjectTypeInfos"> 
+                      <object class="java.util.ArrayList"> 
+                       <void method="add"> 
+                        <object idref="PrimitiveTypeInfo1"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                         <void property="typeName"> 
+                          <string>bigint</string> 
+                         </void> 
+                        </object> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="PrimitiveTypeInfo0"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                         <void property="typeName"> 
+                          <string>double</string> 
+                         </void> 
+                        </object> 
+                       </void> 
+                       <void method="add"> 
+                        <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                         <void property="typeName"> 
+                          <string>boolean</string> 
+                         </void> 
+                        </object> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="ListTypeInfo2"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="MapTypeInfo0"/> 
+                       </void> 
+                      </object> 
+                     </void> 
+                    </object> 
+                   </void> 
+                  </object> 
+                 </void> 
+                </object> 
+               </void> 
+              </object> 
+             </void> 
+             <void property="typeName"> 
+              <string>map&lt;string,map&lt;string,map&lt;string,uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;&gt;&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield1</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield2</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield3</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
            <void method="add"> 
             <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
              <void property="hiddenVirtualCol"> 
@@ -1017,11 +1140,7 @@
               <string>src_thrift</string> 
              </void> 
              <void property="type"> 
-              <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
-               <void property="typeName"> 
-                <string>bigint</string> 
-               </void> 
-              </object> 
+              <object idref="PrimitiveTypeInfo2"/> 
              </void> 
              <void property="typeName"> 
               <string>bigint</string> 
@@ -1176,7 +1295,7 @@
           </void> 
           <void method="put"> 
            <string>totalSize</string> 
-           <string>1606</string> 
+           <string>3070</string> 
           </void> 
           <void method="put"> 
            <string>bucket_count</string> 
diff --git a/ql/src/test/results/compiler/plan/input_testxpath.q.xml b/ql/src/test/results/compiler/plan/input_testxpath.q.xml
index a3dacdfbce..1848f95db6 100644
--- a/ql/src/test/results/compiler/plan/input_testxpath.q.xml
+++ b/ql/src/test/results/compiler/plan/input_testxpath.q.xml
@@ -131,7 +131,7 @@
             </void> 
             <void method="put"> 
              <string>totalSize</string> 
-             <string>1606</string> 
+             <string>3070</string> 
             </void> 
             <void method="put"> 
              <string>bucket_count</string> 
@@ -691,7 +691,7 @@
               <string>src_thrift</string> 
              </void> 
              <void property="type"> 
-              <object class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
+              <object id="ListTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                <void property="listElementTypeInfo"> 
                 <object idref="PrimitiveTypeInfo1"/> 
                </void> 
@@ -734,6 +734,129 @@
              </void> 
             </object> 
            </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>attributes</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+               <void property="mapKeyTypeInfo"> 
+                <object idref="PrimitiveTypeInfo1"/> 
+               </void> 
+               <void property="mapValueTypeInfo"> 
+                <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+                 <void property="mapKeyTypeInfo"> 
+                  <object idref="PrimitiveTypeInfo1"/> 
+                 </void> 
+                 <void property="mapValueTypeInfo"> 
+                  <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+                   <void property="mapKeyTypeInfo"> 
+                    <object idref="PrimitiveTypeInfo1"/> 
+                   </void> 
+                   <void property="mapValueTypeInfo"> 
+                    <object id="UnionTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.UnionTypeInfo"> 
+                     <void property="allUnionObjectTypeInfos"> 
+                      <object class="java.util.ArrayList"> 
+                       <void method="add"> 
+                        <object idref="PrimitiveTypeInfo0"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                         <void property="typeName"> 
+                          <string>bigint</string> 
+                         </void> 
+                        </object> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="PrimitiveTypeInfo1"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                         <void property="typeName"> 
+                          <string>double</string> 
+                         </void> 
+                        </object> 
+                       </void> 
+                       <void method="add"> 
+                        <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                         <void property="typeName"> 
+                          <string>boolean</string> 
+                         </void> 
+                        </object> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="ListTypeInfo2"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="MapTypeInfo0"/> 
+                       </void> 
+                      </object> 
+                     </void> 
+                    </object> 
+                   </void> 
+                  </object> 
+                 </void> 
+                </object> 
+               </void> 
+              </object> 
+             </void> 
+             <void property="typeName"> 
+              <string>map&lt;string,map&lt;string,map&lt;string,uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;&gt;&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield1</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield2</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield3</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
            <void method="add"> 
             <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
              <void property="hiddenVirtualCol"> 
@@ -746,11 +869,7 @@
               <string>src_thrift</string> 
              </void> 
              <void property="type"> 
-              <object id="PrimitiveTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
-               <void property="typeName"> 
-                <string>bigint</string> 
-               </void> 
-              </object> 
+              <object idref="PrimitiveTypeInfo2"/> 
              </void> 
              <void property="typeName"> 
               <string>bigint</string> 
@@ -902,7 +1021,7 @@
           </void> 
           <void method="put"> 
            <string>totalSize</string> 
-           <string>1606</string> 
+           <string>3070</string> 
           </void> 
           <void method="put"> 
            <string>bucket_count</string> 
diff --git a/ql/src/test/results/compiler/plan/input_testxpath2.q.xml b/ql/src/test/results/compiler/plan/input_testxpath2.q.xml
index 7fc3a49724..d2fa662132 100644
--- a/ql/src/test/results/compiler/plan/input_testxpath2.q.xml
+++ b/ql/src/test/results/compiler/plan/input_testxpath2.q.xml
@@ -131,7 +131,7 @@
             </void> 
             <void method="put"> 
              <string>totalSize</string> 
-             <string>1606</string> 
+             <string>3070</string> 
             </void> 
             <void method="put"> 
              <string>bucket_count</string> 
@@ -793,7 +793,7 @@
               <string>src_thrift</string> 
              </void> 
              <void property="type"> 
-              <object class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
+              <object id="ListTypeInfo2" class="org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo"> 
                <void property="listElementTypeInfo"> 
                 <object idref="PrimitiveTypeInfo1"/> 
                </void> 
@@ -810,6 +810,125 @@
            <void method="add"> 
             <object idref="ColumnInfo2"/> 
            </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>attributes</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+               <void property="mapKeyTypeInfo"> 
+                <object idref="PrimitiveTypeInfo1"/> 
+               </void> 
+               <void property="mapValueTypeInfo"> 
+                <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+                 <void property="mapKeyTypeInfo"> 
+                  <object idref="PrimitiveTypeInfo1"/> 
+                 </void> 
+                 <void property="mapValueTypeInfo"> 
+                  <object class="org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo"> 
+                   <void property="mapKeyTypeInfo"> 
+                    <object idref="PrimitiveTypeInfo1"/> 
+                   </void> 
+                   <void property="mapValueTypeInfo"> 
+                    <object id="UnionTypeInfo0" class="org.apache.hadoop.hive.serde2.typeinfo.UnionTypeInfo"> 
+                     <void property="allUnionObjectTypeInfos"> 
+                      <object class="java.util.ArrayList"> 
+                       <void method="add"> 
+                        <object idref="PrimitiveTypeInfo0"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                         <void property="typeName"> 
+                          <string>bigint</string> 
+                         </void> 
+                        </object> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="PrimitiveTypeInfo1"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
+                         <void property="typeName"> 
+                          <string>double</string> 
+                         </void> 
+                        </object> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="PrimitiveTypeInfo2"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="ListTypeInfo2"/> 
+                       </void> 
+                       <void method="add"> 
+                        <object idref="MapTypeInfo0"/> 
+                       </void> 
+                      </object> 
+                     </void> 
+                    </object> 
+                   </void> 
+                  </object> 
+                 </void> 
+                </object> 
+               </void> 
+              </object> 
+             </void> 
+             <void property="typeName"> 
+              <string>map&lt;string,map&lt;string,map&lt;string,uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;&gt;&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield1</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield2</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
+           <void method="add"> 
+            <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
+             <void property="internalName"> 
+              <string>unionfield3</string> 
+             </void> 
+             <void property="tabAlias"> 
+              <string>src_thrift</string> 
+             </void> 
+             <void property="type"> 
+              <object idref="UnionTypeInfo0"/> 
+             </void> 
+             <void property="typeName"> 
+              <string>uniontype&lt;int,bigint,string,double,boolean,array&lt;string&gt;,map&lt;string,string&gt;&gt;</string> 
+             </void> 
+            </object> 
+           </void> 
            <void method="add"> 
             <object class="org.apache.hadoop.hive.ql.exec.ColumnInfo"> 
              <void property="hiddenVirtualCol"> 
@@ -822,11 +941,7 @@
               <string>src_thrift</string> 
              </void> 
              <void property="type"> 
-              <object id="PrimitiveTypeInfo3" class="org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo"> 
-               <void property="typeName"> 
-                <string>bigint</string> 
-               </void> 
-              </object> 
+              <object idref="PrimitiveTypeInfo3"/> 
              </void> 
              <void property="typeName"> 
               <string>bigint</string> 
@@ -978,7 +1093,7 @@
           </void> 
           <void method="put"> 
            <string>totalSize</string> 
-           <string>1606</string> 
+           <string>3070</string> 
           </void> 
           <void method="put"> 
            <string>bucket_count</string> 
diff --git a/serde/if/test/complex.thrift b/serde/if/test/complex.thrift
index 8a042ee9be..2aa9bc07d2 100644
--- a/serde/if/test/complex.thrift
+++ b/serde/if/test/complex.thrift
@@ -18,6 +18,16 @@
 
 namespace java org.apache.hadoop.hive.serde2.thrift.test
 
+union PropValueUnion {
+	1: optional i32 intValue;
+	2: optional i64 longValue;
+	3: optional string stringValue;
+	4: optional double doubleValue;
+	5: optional bool flag;
+	6: list<string> lString;
+	7: map<string, string> unionMStringString;
+}
+
 struct IntString {
   1: i32  myint;
   2: string myString;
@@ -31,6 +41,10 @@ struct Complex {
   4: list<string> lString;
   5: list<IntString> lintString;
   6: map<string, string> mStringString;
+  7: map<string,map<string,map<string,PropValueUnion>>> attributes;
+  8: PropValueUnion unionField1;
+  9: PropValueUnion unionField2;
+  10: PropValueUnion unionField3;
 }
 
 struct SetIntString {
diff --git a/serde/src/gen/thrift/gen-cpp/complex_types.cpp b/serde/src/gen/thrift/gen-cpp/complex_types.cpp
index 9526d3df39..f0ede2cbcb 100644
--- a/serde/src/gen/thrift/gen-cpp/complex_types.cpp
+++ b/serde/src/gen/thrift/gen-cpp/complex_types.cpp
@@ -10,6 +10,195 @@
 
 
 
+const char* PropValueUnion::ascii_fingerprint = "123CD9D82D5B5054B5054EFD63FC8590";
+const uint8_t PropValueUnion::binary_fingerprint[16] = {0x12,0x3C,0xD9,0xD8,0x2D,0x5B,0x50,0x54,0xB5,0x05,0x4E,0xFD,0x63,0xFC,0x85,0x90};
+
+uint32_t PropValueUnion::read(::apache::thrift::protocol::TProtocol* iprot) {
+
+  uint32_t xfer = 0;
+  std::string fname;
+  ::apache::thrift::protocol::TType ftype;
+  int16_t fid;
+
+  xfer += iprot->readStructBegin(fname);
+
+  using ::apache::thrift::protocol::TProtocolException;
+
+
+  while (true)
+  {
+    xfer += iprot->readFieldBegin(fname, ftype, fid);
+    if (ftype == ::apache::thrift::protocol::T_STOP) {
+      break;
+    }
+    switch (fid)
+    {
+      case 1:
+        if (ftype == ::apache::thrift::protocol::T_I32) {
+          xfer += iprot->readI32(this->intValue);
+          this->__isset.intValue = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 2:
+        if (ftype == ::apache::thrift::protocol::T_I64) {
+          xfer += iprot->readI64(this->longValue);
+          this->__isset.longValue = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 3:
+        if (ftype == ::apache::thrift::protocol::T_STRING) {
+          xfer += iprot->readString(this->stringValue);
+          this->__isset.stringValue = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 4:
+        if (ftype == ::apache::thrift::protocol::T_DOUBLE) {
+          xfer += iprot->readDouble(this->doubleValue);
+          this->__isset.doubleValue = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 5:
+        if (ftype == ::apache::thrift::protocol::T_BOOL) {
+          xfer += iprot->readBool(this->flag);
+          this->__isset.flag = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 6:
+        if (ftype == ::apache::thrift::protocol::T_LIST) {
+          {
+            this->lString.clear();
+            uint32_t _size0;
+            ::apache::thrift::protocol::TType _etype3;
+            xfer += iprot->readListBegin(_etype3, _size0);
+            this->lString.resize(_size0);
+            uint32_t _i4;
+            for (_i4 = 0; _i4 < _size0; ++_i4)
+            {
+              xfer += iprot->readString(this->lString[_i4]);
+            }
+            xfer += iprot->readListEnd();
+          }
+          this->__isset.lString = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 7:
+        if (ftype == ::apache::thrift::protocol::T_MAP) {
+          {
+            this->unionMStringString.clear();
+            uint32_t _size5;
+            ::apache::thrift::protocol::TType _ktype6;
+            ::apache::thrift::protocol::TType _vtype7;
+            xfer += iprot->readMapBegin(_ktype6, _vtype7, _size5);
+            uint32_t _i9;
+            for (_i9 = 0; _i9 < _size5; ++_i9)
+            {
+              std::string _key10;
+              xfer += iprot->readString(_key10);
+              std::string& _val11 = this->unionMStringString[_key10];
+              xfer += iprot->readString(_val11);
+            }
+            xfer += iprot->readMapEnd();
+          }
+          this->__isset.unionMStringString = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      default:
+        xfer += iprot->skip(ftype);
+        break;
+    }
+    xfer += iprot->readFieldEnd();
+  }
+
+  xfer += iprot->readStructEnd();
+
+  return xfer;
+}
+
+uint32_t PropValueUnion::write(::apache::thrift::protocol::TProtocol* oprot) const {
+  uint32_t xfer = 0;
+  xfer += oprot->writeStructBegin("PropValueUnion");
+
+  if (this->__isset.intValue) {
+    xfer += oprot->writeFieldBegin("intValue", ::apache::thrift::protocol::T_I32, 1);
+    xfer += oprot->writeI32(this->intValue);
+    xfer += oprot->writeFieldEnd();
+  }
+  if (this->__isset.longValue) {
+    xfer += oprot->writeFieldBegin("longValue", ::apache::thrift::protocol::T_I64, 2);
+    xfer += oprot->writeI64(this->longValue);
+    xfer += oprot->writeFieldEnd();
+  }
+  if (this->__isset.stringValue) {
+    xfer += oprot->writeFieldBegin("stringValue", ::apache::thrift::protocol::T_STRING, 3);
+    xfer += oprot->writeString(this->stringValue);
+    xfer += oprot->writeFieldEnd();
+  }
+  if (this->__isset.doubleValue) {
+    xfer += oprot->writeFieldBegin("doubleValue", ::apache::thrift::protocol::T_DOUBLE, 4);
+    xfer += oprot->writeDouble(this->doubleValue);
+    xfer += oprot->writeFieldEnd();
+  }
+  if (this->__isset.flag) {
+    xfer += oprot->writeFieldBegin("flag", ::apache::thrift::protocol::T_BOOL, 5);
+    xfer += oprot->writeBool(this->flag);
+    xfer += oprot->writeFieldEnd();
+  }
+  xfer += oprot->writeFieldBegin("lString", ::apache::thrift::protocol::T_LIST, 6);
+  {
+    xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->lString.size()));
+    std::vector<std::string> ::const_iterator _iter12;
+    for (_iter12 = this->lString.begin(); _iter12 != this->lString.end(); ++_iter12)
+    {
+      xfer += oprot->writeString((*_iter12));
+    }
+    xfer += oprot->writeListEnd();
+  }
+  xfer += oprot->writeFieldEnd();
+
+  xfer += oprot->writeFieldBegin("unionMStringString", ::apache::thrift::protocol::T_MAP, 7);
+  {
+    xfer += oprot->writeMapBegin(::apache::thrift::protocol::T_STRING, ::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->unionMStringString.size()));
+    std::map<std::string, std::string> ::const_iterator _iter13;
+    for (_iter13 = this->unionMStringString.begin(); _iter13 != this->unionMStringString.end(); ++_iter13)
+    {
+      xfer += oprot->writeString(_iter13->first);
+      xfer += oprot->writeString(_iter13->second);
+    }
+    xfer += oprot->writeMapEnd();
+  }
+  xfer += oprot->writeFieldEnd();
+
+  xfer += oprot->writeFieldStop();
+  xfer += oprot->writeStructEnd();
+  return xfer;
+}
+
+void swap(PropValueUnion &a, PropValueUnion &b) {
+  using ::std::swap;
+  swap(a.intValue, b.intValue);
+  swap(a.longValue, b.longValue);
+  swap(a.stringValue, b.stringValue);
+  swap(a.doubleValue, b.doubleValue);
+  swap(a.flag, b.flag);
+  swap(a.lString, b.lString);
+  swap(a.unionMStringString, b.unionMStringString);
+  swap(a.__isset, b.__isset);
+}
+
 const char* IntString::ascii_fingerprint = "52C6DAB6CF51AF617111F6D3964C6503";
 const uint8_t IntString::binary_fingerprint[16] = {0x52,0xC6,0xDA,0xB6,0xCF,0x51,0xAF,0x61,0x71,0x11,0xF6,0xD3,0x96,0x4C,0x65,0x03};
 
@@ -98,8 +287,8 @@ void swap(IntString &a, IntString &b) {
   swap(a.__isset, b.__isset);
 }
 
-const char* Complex::ascii_fingerprint = "B6556501F2F746F0BF83D55B0A9824DE";
-const uint8_t Complex::binary_fingerprint[16] = {0xB6,0x55,0x65,0x01,0xF2,0xF7,0x46,0xF0,0xBF,0x83,0xD5,0x5B,0x0A,0x98,0x24,0xDE};
+const char* Complex::ascii_fingerprint = "FFA84FEA7037F5858F2BFEDA73AD679A";
+const uint8_t Complex::binary_fingerprint[16] = {0xFF,0xA8,0x4F,0xEA,0x70,0x37,0xF5,0x85,0x8F,0x2B,0xFE,0xDA,0x73,0xAD,0x67,0x9A};
 
 uint32_t Complex::read(::apache::thrift::protocol::TProtocol* iprot) {
 
@@ -141,14 +330,14 @@ uint32_t Complex::read(::apache::thrift::protocol::TProtocol* iprot) {
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->lint.clear();
-            uint32_t _size0;
-            ::apache::thrift::protocol::TType _etype3;
-            xfer += iprot->readListBegin(_etype3, _size0);
-            this->lint.resize(_size0);
-            uint32_t _i4;
-            for (_i4 = 0; _i4 < _size0; ++_i4)
+            uint32_t _size14;
+            ::apache::thrift::protocol::TType _etype17;
+            xfer += iprot->readListBegin(_etype17, _size14);
+            this->lint.resize(_size14);
+            uint32_t _i18;
+            for (_i18 = 0; _i18 < _size14; ++_i18)
             {
-              xfer += iprot->readI32(this->lint[_i4]);
+              xfer += iprot->readI32(this->lint[_i18]);
             }
             xfer += iprot->readListEnd();
           }
@@ -161,14 +350,14 @@ uint32_t Complex::read(::apache::thrift::protocol::TProtocol* iprot) {
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->lString.clear();
-            uint32_t _size5;
-            ::apache::thrift::protocol::TType _etype8;
-            xfer += iprot->readListBegin(_etype8, _size5);
-            this->lString.resize(_size5);
-            uint32_t _i9;
-            for (_i9 = 0; _i9 < _size5; ++_i9)
+            uint32_t _size19;
+            ::apache::thrift::protocol::TType _etype22;
+            xfer += iprot->readListBegin(_etype22, _size19);
+            this->lString.resize(_size19);
+            uint32_t _i23;
+            for (_i23 = 0; _i23 < _size19; ++_i23)
             {
-              xfer += iprot->readString(this->lString[_i9]);
+              xfer += iprot->readString(this->lString[_i23]);
             }
             xfer += iprot->readListEnd();
           }
@@ -181,14 +370,14 @@ uint32_t Complex::read(::apache::thrift::protocol::TProtocol* iprot) {
         if (ftype == ::apache::thrift::protocol::T_LIST) {
           {
             this->lintString.clear();
-            uint32_t _size10;
-            ::apache::thrift::protocol::TType _etype13;
-            xfer += iprot->readListBegin(_etype13, _size10);
-            this->lintString.resize(_size10);
-            uint32_t _i14;
-            for (_i14 = 0; _i14 < _size10; ++_i14)
+            uint32_t _size24;
+            ::apache::thrift::protocol::TType _etype27;
+            xfer += iprot->readListBegin(_etype27, _size24);
+            this->lintString.resize(_size24);
+            uint32_t _i28;
+            for (_i28 = 0; _i28 < _size24; ++_i28)
             {
-              xfer += this->lintString[_i14].read(iprot);
+              xfer += this->lintString[_i28].read(iprot);
             }
             xfer += iprot->readListEnd();
           }
@@ -201,17 +390,17 @@ uint32_t Complex::read(::apache::thrift::protocol::TProtocol* iprot) {
         if (ftype == ::apache::thrift::protocol::T_MAP) {
           {
             this->mStringString.clear();
-            uint32_t _size15;
-            ::apache::thrift::protocol::TType _ktype16;
-            ::apache::thrift::protocol::TType _vtype17;
-            xfer += iprot->readMapBegin(_ktype16, _vtype17, _size15);
-            uint32_t _i19;
-            for (_i19 = 0; _i19 < _size15; ++_i19)
+            uint32_t _size29;
+            ::apache::thrift::protocol::TType _ktype30;
+            ::apache::thrift::protocol::TType _vtype31;
+            xfer += iprot->readMapBegin(_ktype30, _vtype31, _size29);
+            uint32_t _i33;
+            for (_i33 = 0; _i33 < _size29; ++_i33)
             {
-              std::string _key20;
-              xfer += iprot->readString(_key20);
-              std::string& _val21 = this->mStringString[_key20];
-              xfer += iprot->readString(_val21);
+              std::string _key34;
+              xfer += iprot->readString(_key34);
+              std::string& _val35 = this->mStringString[_key34];
+              xfer += iprot->readString(_val35);
             }
             xfer += iprot->readMapEnd();
           }
@@ -220,6 +409,83 @@ uint32_t Complex::read(::apache::thrift::protocol::TProtocol* iprot) {
           xfer += iprot->skip(ftype);
         }
         break;
+      case 7:
+        if (ftype == ::apache::thrift::protocol::T_MAP) {
+          {
+            this->attributes.clear();
+            uint32_t _size36;
+            ::apache::thrift::protocol::TType _ktype37;
+            ::apache::thrift::protocol::TType _vtype38;
+            xfer += iprot->readMapBegin(_ktype37, _vtype38, _size36);
+            uint32_t _i40;
+            for (_i40 = 0; _i40 < _size36; ++_i40)
+            {
+              std::string _key41;
+              xfer += iprot->readString(_key41);
+              std::map<std::string, std::map<std::string, PropValueUnion> > & _val42 = this->attributes[_key41];
+              {
+                _val42.clear();
+                uint32_t _size43;
+                ::apache::thrift::protocol::TType _ktype44;
+                ::apache::thrift::protocol::TType _vtype45;
+                xfer += iprot->readMapBegin(_ktype44, _vtype45, _size43);
+                uint32_t _i47;
+                for (_i47 = 0; _i47 < _size43; ++_i47)
+                {
+                  std::string _key48;
+                  xfer += iprot->readString(_key48);
+                  std::map<std::string, PropValueUnion> & _val49 = _val42[_key48];
+                  {
+                    _val49.clear();
+                    uint32_t _size50;
+                    ::apache::thrift::protocol::TType _ktype51;
+                    ::apache::thrift::protocol::TType _vtype52;
+                    xfer += iprot->readMapBegin(_ktype51, _vtype52, _size50);
+                    uint32_t _i54;
+                    for (_i54 = 0; _i54 < _size50; ++_i54)
+                    {
+                      std::string _key55;
+                      xfer += iprot->readString(_key55);
+                      PropValueUnion& _val56 = _val49[_key55];
+                      xfer += _val56.read(iprot);
+                    }
+                    xfer += iprot->readMapEnd();
+                  }
+                }
+                xfer += iprot->readMapEnd();
+              }
+            }
+            xfer += iprot->readMapEnd();
+          }
+          this->__isset.attributes = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 8:
+        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
+          xfer += this->unionField1.read(iprot);
+          this->__isset.unionField1 = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 9:
+        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
+          xfer += this->unionField2.read(iprot);
+          this->__isset.unionField2 = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
+      case 10:
+        if (ftype == ::apache::thrift::protocol::T_STRUCT) {
+          xfer += this->unionField3.read(iprot);
+          this->__isset.unionField3 = true;
+        } else {
+          xfer += iprot->skip(ftype);
+        }
+        break;
       default:
         xfer += iprot->skip(ftype);
         break;
@@ -247,10 +513,10 @@ uint32_t Complex::write(::apache::thrift::protocol::TProtocol* oprot) const {
   xfer += oprot->writeFieldBegin("lint", ::apache::thrift::protocol::T_LIST, 3);
   {
     xfer += oprot->writeListBegin(::apache::thrift::protocol::T_I32, static_cast<uint32_t>(this->lint.size()));
-    std::vector<int32_t> ::const_iterator _iter22;
-    for (_iter22 = this->lint.begin(); _iter22 != this->lint.end(); ++_iter22)
+    std::vector<int32_t> ::const_iterator _iter57;
+    for (_iter57 = this->lint.begin(); _iter57 != this->lint.end(); ++_iter57)
     {
-      xfer += oprot->writeI32((*_iter22));
+      xfer += oprot->writeI32((*_iter57));
     }
     xfer += oprot->writeListEnd();
   }
@@ -259,10 +525,10 @@ uint32_t Complex::write(::apache::thrift::protocol::TProtocol* oprot) const {
   xfer += oprot->writeFieldBegin("lString", ::apache::thrift::protocol::T_LIST, 4);
   {
     xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->lString.size()));
-    std::vector<std::string> ::const_iterator _iter23;
-    for (_iter23 = this->lString.begin(); _iter23 != this->lString.end(); ++_iter23)
+    std::vector<std::string> ::const_iterator _iter58;
+    for (_iter58 = this->lString.begin(); _iter58 != this->lString.end(); ++_iter58)
     {
-      xfer += oprot->writeString((*_iter23));
+      xfer += oprot->writeString((*_iter58));
     }
     xfer += oprot->writeListEnd();
   }
@@ -271,10 +537,10 @@ uint32_t Complex::write(::apache::thrift::protocol::TProtocol* oprot) const {
   xfer += oprot->writeFieldBegin("lintString", ::apache::thrift::protocol::T_LIST, 5);
   {
     xfer += oprot->writeListBegin(::apache::thrift::protocol::T_STRUCT, static_cast<uint32_t>(this->lintString.size()));
-    std::vector<IntString> ::const_iterator _iter24;
-    for (_iter24 = this->lintString.begin(); _iter24 != this->lintString.end(); ++_iter24)
+    std::vector<IntString> ::const_iterator _iter59;
+    for (_iter59 = this->lintString.begin(); _iter59 != this->lintString.end(); ++_iter59)
     {
-      xfer += (*_iter24).write(oprot);
+      xfer += (*_iter59).write(oprot);
     }
     xfer += oprot->writeListEnd();
   }
@@ -283,16 +549,59 @@ uint32_t Complex::write(::apache::thrift::protocol::TProtocol* oprot) const {
   xfer += oprot->writeFieldBegin("mStringString", ::apache::thrift::protocol::T_MAP, 6);
   {
     xfer += oprot->writeMapBegin(::apache::thrift::protocol::T_STRING, ::apache::thrift::protocol::T_STRING, static_cast<uint32_t>(this->mStringString.size()));
-    std::map<std::string, std::string> ::const_iterator _iter25;
-    for (_iter25 = this->mStringString.begin(); _iter25 != this->mStringString.end(); ++_iter25)
+    std::map<std::string, std::string> ::const_iterator _iter60;
+    for (_iter60 = this->mStringString.begin(); _iter60 != this->mStringString.end(); ++_iter60)
     {
-      xfer += oprot->writeString(_iter25->first);
-      xfer += oprot->writeString(_iter25->second);
+      xfer += oprot->writeString(_iter60->first);
+      xfer += oprot->writeString(_iter60->second);
     }
     xfer += oprot->writeMapEnd();
   }
   xfer += oprot->writeFieldEnd();
 
+  xfer += oprot->writeFieldBegin("attributes", ::apache::thrift::protocol::T_MAP, 7);
+  {
+    xfer += oprot->writeMapBegin(::apache::thrift::protocol::T_STRING, ::apache::thrift::protocol::T_MAP, static_cast<uint32_t>(this->attributes.size()));
+    std::map<std::string, std::map<std::string, std::map<std::string, PropValueUnion> > > ::const_iterator _iter61;
+    for (_iter61 = this->attributes.begin(); _iter61 != this->attributes.end(); ++_iter61)
+    {
+      xfer += oprot->writeString(_iter61->first);
+      {
+        xfer += oprot->writeMapBegin(::apache::thrift::protocol::T_STRING, ::apache::thrift::protocol::T_MAP, static_cast<uint32_t>(_iter61->second.size()));
+        std::map<std::string, std::map<std::string, PropValueUnion> > ::const_iterator _iter62;
+        for (_iter62 = _iter61->second.begin(); _iter62 != _iter61->second.end(); ++_iter62)
+        {
+          xfer += oprot->writeString(_iter62->first);
+          {
+            xfer += oprot->writeMapBegin(::apache::thrift::protocol::T_STRING, ::apache::thrift::protocol::T_STRUCT, static_cast<uint32_t>(_iter62->second.size()));
+            std::map<std::string, PropValueUnion> ::const_iterator _iter63;
+            for (_iter63 = _iter62->second.begin(); _iter63 != _iter62->second.end(); ++_iter63)
+            {
+              xfer += oprot->writeString(_iter63->first);
+              xfer += _iter63->second.write(oprot);
+            }
+            xfer += oprot->writeMapEnd();
+          }
+        }
+        xfer += oprot->writeMapEnd();
+      }
+    }
+    xfer += oprot->writeMapEnd();
+  }
+  xfer += oprot->writeFieldEnd();
+
+  xfer += oprot->writeFieldBegin("unionField1", ::apache::thrift::protocol::T_STRUCT, 8);
+  xfer += this->unionField1.write(oprot);
+  xfer += oprot->writeFieldEnd();
+
+  xfer += oprot->writeFieldBegin("unionField2", ::apache::thrift::protocol::T_STRUCT, 9);
+  xfer += this->unionField2.write(oprot);
+  xfer += oprot->writeFieldEnd();
+
+  xfer += oprot->writeFieldBegin("unionField3", ::apache::thrift::protocol::T_STRUCT, 10);
+  xfer += this->unionField3.write(oprot);
+  xfer += oprot->writeFieldEnd();
+
   xfer += oprot->writeFieldStop();
   xfer += oprot->writeStructEnd();
   return xfer;
@@ -306,6 +615,10 @@ void swap(Complex &a, Complex &b) {
   swap(a.lString, b.lString);
   swap(a.lintString, b.lintString);
   swap(a.mStringString, b.mStringString);
+  swap(a.attributes, b.attributes);
+  swap(a.unionField1, b.unionField1);
+  swap(a.unionField2, b.unionField2);
+  swap(a.unionField3, b.unionField3);
   swap(a.__isset, b.__isset);
 }
 
diff --git a/serde/src/gen/thrift/gen-cpp/complex_types.h b/serde/src/gen/thrift/gen-cpp/complex_types.h
index 17991d44b6..de9f5f99f5 100644
--- a/serde/src/gen/thrift/gen-cpp/complex_types.h
+++ b/serde/src/gen/thrift/gen-cpp/complex_types.h
@@ -16,6 +16,112 @@
 
 
 
+typedef struct _PropValueUnion__isset {
+  _PropValueUnion__isset() : intValue(false), longValue(false), stringValue(false), doubleValue(false), flag(false), lString(false), unionMStringString(false) {}
+  bool intValue;
+  bool longValue;
+  bool stringValue;
+  bool doubleValue;
+  bool flag;
+  bool lString;
+  bool unionMStringString;
+} _PropValueUnion__isset;
+
+class PropValueUnion {
+ public:
+
+  static const char* ascii_fingerprint; // = "123CD9D82D5B5054B5054EFD63FC8590";
+  static const uint8_t binary_fingerprint[16]; // = {0x12,0x3C,0xD9,0xD8,0x2D,0x5B,0x50,0x54,0xB5,0x05,0x4E,0xFD,0x63,0xFC,0x85,0x90};
+
+  PropValueUnion() : intValue(0), longValue(0), stringValue(), doubleValue(0), flag(0) {
+  }
+
+  virtual ~PropValueUnion() throw() {}
+
+  int32_t intValue;
+  int64_t longValue;
+  std::string stringValue;
+  double doubleValue;
+  bool flag;
+  std::vector<std::string>  lString;
+  std::map<std::string, std::string>  unionMStringString;
+
+  _PropValueUnion__isset __isset;
+
+  void __set_intValue(const int32_t val) {
+    intValue = val;
+    __isset.intValue = true;
+  }
+
+  void __set_longValue(const int64_t val) {
+    longValue = val;
+    __isset.longValue = true;
+  }
+
+  void __set_stringValue(const std::string& val) {
+    stringValue = val;
+    __isset.stringValue = true;
+  }
+
+  void __set_doubleValue(const double val) {
+    doubleValue = val;
+    __isset.doubleValue = true;
+  }
+
+  void __set_flag(const bool val) {
+    flag = val;
+    __isset.flag = true;
+  }
+
+  void __set_lString(const std::vector<std::string> & val) {
+    lString = val;
+  }
+
+  void __set_unionMStringString(const std::map<std::string, std::string> & val) {
+    unionMStringString = val;
+  }
+
+  bool operator == (const PropValueUnion & rhs) const
+  {
+    if (__isset.intValue != rhs.__isset.intValue)
+      return false;
+    else if (__isset.intValue && !(intValue == rhs.intValue))
+      return false;
+    if (__isset.longValue != rhs.__isset.longValue)
+      return false;
+    else if (__isset.longValue && !(longValue == rhs.longValue))
+      return false;
+    if (__isset.stringValue != rhs.__isset.stringValue)
+      return false;
+    else if (__isset.stringValue && !(stringValue == rhs.stringValue))
+      return false;
+    if (__isset.doubleValue != rhs.__isset.doubleValue)
+      return false;
+    else if (__isset.doubleValue && !(doubleValue == rhs.doubleValue))
+      return false;
+    if (__isset.flag != rhs.__isset.flag)
+      return false;
+    else if (__isset.flag && !(flag == rhs.flag))
+      return false;
+    if (!(lString == rhs.lString))
+      return false;
+    if (!(unionMStringString == rhs.unionMStringString))
+      return false;
+    return true;
+  }
+  bool operator != (const PropValueUnion &rhs) const {
+    return !(*this == rhs);
+  }
+
+  bool operator < (const PropValueUnion & ) const;
+
+  uint32_t read(::apache::thrift::protocol::TProtocol* iprot);
+  uint32_t write(::apache::thrift::protocol::TProtocol* oprot) const;
+
+};
+
+void swap(PropValueUnion &a, PropValueUnion &b);
+
 typedef struct _IntString__isset {
   _IntString__isset() : myint(false), myString(false), underscore_int(false) {}
   bool myint;
@@ -76,20 +182,24 @@ class IntString {
 void swap(IntString &a, IntString &b);
 
 typedef struct _Complex__isset {
-  _Complex__isset() : aint(false), aString(false), lint(false), lString(false), lintString(false), mStringString(false) {}
+  _Complex__isset() : aint(false), aString(false), lint(false), lString(false), lintString(false), mStringString(false), attributes(false), unionField1(false), unionField2(false), unionField3(false) {}
   bool aint;
   bool aString;
   bool lint;
   bool lString;
   bool lintString;
   bool mStringString;
+  bool attributes;
+  bool unionField1;
+  bool unionField2;
+  bool unionField3;
 } _Complex__isset;
 
 class Complex {
  public:
 
-  static const char* ascii_fingerprint; // = "B6556501F2F746F0BF83D55B0A9824DE";
-  static const uint8_t binary_fingerprint[16]; // = {0xB6,0x55,0x65,0x01,0xF2,0xF7,0x46,0xF0,0xBF,0x83,0xD5,0x5B,0x0A,0x98,0x24,0xDE};
+  static const char* ascii_fingerprint; // = "FFA84FEA7037F5858F2BFEDA73AD679A";
+  static const uint8_t binary_fingerprint[16]; // = {0xFF,0xA8,0x4F,0xEA,0x70,0x37,0xF5,0x85,0x8F,0x2B,0xFE,0xDA,0x73,0xAD,0x67,0x9A};
 
   Complex() : aint(0), aString() {
   }
@@ -102,6 +212,10 @@ class Complex {
   std::vector<std::string>  lString;
   std::vector<IntString>  lintString;
   std::map<std::string, std::string>  mStringString;
+  std::map<std::string, std::map<std::string, std::map<std::string, PropValueUnion> > >  attributes;
+  PropValueUnion unionField1;
+  PropValueUnion unionField2;
+  PropValueUnion unionField3;
 
   _Complex__isset __isset;
 
@@ -129,6 +243,22 @@ class Complex {
     mStringString = val;
   }
 
+  void __set_attributes(const std::map<std::string, std::map<std::string, std::map<std::string, PropValueUnion> > > & val) {
+    attributes = val;
+  }
+
+  void __set_unionField1(const PropValueUnion& val) {
+    unionField1 = val;
+  }
+
+  void __set_unionField2(const PropValueUnion& val) {
+    unionField2 = val;
+  }
+
+  void __set_unionField3(const PropValueUnion& val) {
+    unionField3 = val;
+  }
+
   bool operator == (const Complex & rhs) const
   {
     if (!(aint == rhs.aint))
@@ -143,6 +273,14 @@ class Complex {
       return false;
     if (!(mStringString == rhs.mStringString))
       return false;
+    if (!(attributes == rhs.attributes))
+      return false;
+    if (!(unionField1 == rhs.unionField1))
+      return false;
+    if (!(unionField2 == rhs.unionField2))
+      return false;
+    if (!(unionField3 == rhs.unionField3))
+      return false;
     return true;
   }
   bool operator != (const Complex &rhs) const {
diff --git a/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java b/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java
index e36a792e46..41df559da1 100644
--- a/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java
+++ b/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java
@@ -40,6 +40,10 @@ public class Complex implements org.apache.thrift.TBase<Complex, Complex._Fields
   private static final org.apache.thrift.protocol.TField L_STRING_FIELD_DESC = new org.apache.thrift.protocol.TField("lString", org.apache.thrift.protocol.TType.LIST, (short)4);
   private static final org.apache.thrift.protocol.TField LINT_STRING_FIELD_DESC = new org.apache.thrift.protocol.TField("lintString", org.apache.thrift.protocol.TType.LIST, (short)5);
   private static final org.apache.thrift.protocol.TField M_STRING_STRING_FIELD_DESC = new org.apache.thrift.protocol.TField("mStringString", org.apache.thrift.protocol.TType.MAP, (short)6);
+  private static final org.apache.thrift.protocol.TField ATTRIBUTES_FIELD_DESC = new org.apache.thrift.protocol.TField("attributes", org.apache.thrift.protocol.TType.MAP, (short)7);
+  private static final org.apache.thrift.protocol.TField UNION_FIELD1_FIELD_DESC = new org.apache.thrift.protocol.TField("unionField1", org.apache.thrift.protocol.TType.STRUCT, (short)8);
+  private static final org.apache.thrift.protocol.TField UNION_FIELD2_FIELD_DESC = new org.apache.thrift.protocol.TField("unionField2", org.apache.thrift.protocol.TType.STRUCT, (short)9);
+  private static final org.apache.thrift.protocol.TField UNION_FIELD3_FIELD_DESC = new org.apache.thrift.protocol.TField("unionField3", org.apache.thrift.protocol.TType.STRUCT, (short)10);
 
   private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
   static {
@@ -53,6 +57,10 @@ public class Complex implements org.apache.thrift.TBase<Complex, Complex._Fields
   private List<String> lString; // required
   private List<IntString> lintString; // required
   private Map<String,String> mStringString; // required
+  private Map<String,Map<String,Map<String,PropValueUnion>>> attributes; // required
+  private PropValueUnion unionField1; // required
+  private PropValueUnion unionField2; // required
+  private PropValueUnion unionField3; // required
 
   /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
   public enum _Fields implements org.apache.thrift.TFieldIdEnum {
@@ -61,7 +69,11 @@ public enum _Fields implements org.apache.thrift.TFieldIdEnum {
     LINT((short)3, "lint"),
     L_STRING((short)4, "lString"),
     LINT_STRING((short)5, "lintString"),
-    M_STRING_STRING((short)6, "mStringString");
+    M_STRING_STRING((short)6, "mStringString"),
+    ATTRIBUTES((short)7, "attributes"),
+    UNION_FIELD1((short)8, "unionField1"),
+    UNION_FIELD2((short)9, "unionField2"),
+    UNION_FIELD3((short)10, "unionField3");
 
     private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
 
@@ -88,6 +100,14 @@ public static _Fields findByThriftId(int fieldId) {
           return LINT_STRING;
         case 6: // M_STRING_STRING
           return M_STRING_STRING;
+        case 7: // ATTRIBUTES
+          return ATTRIBUTES;
+        case 8: // UNION_FIELD1
+          return UNION_FIELD1;
+        case 9: // UNION_FIELD2
+          return UNION_FIELD2;
+        case 10: // UNION_FIELD3
+          return UNION_FIELD3;
         default:
           return null;
       }
@@ -150,6 +170,20 @@ public String getFieldName() {
         new org.apache.thrift.meta_data.MapMetaData(org.apache.thrift.protocol.TType.MAP, 
             new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING), 
             new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING))));
+    tmpMap.put(_Fields.ATTRIBUTES, new org.apache.thrift.meta_data.FieldMetaData("attributes", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+        new org.apache.thrift.meta_data.MapMetaData(org.apache.thrift.protocol.TType.MAP, 
+            new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING), 
+            new org.apache.thrift.meta_data.MapMetaData(org.apache.thrift.protocol.TType.MAP, 
+                new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING), 
+                new org.apache.thrift.meta_data.MapMetaData(org.apache.thrift.protocol.TType.MAP, 
+                    new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING), 
+                    new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, PropValueUnion.class))))));
+    tmpMap.put(_Fields.UNION_FIELD1, new org.apache.thrift.meta_data.FieldMetaData("unionField1", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+        new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, PropValueUnion.class)));
+    tmpMap.put(_Fields.UNION_FIELD2, new org.apache.thrift.meta_data.FieldMetaData("unionField2", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+        new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, PropValueUnion.class)));
+    tmpMap.put(_Fields.UNION_FIELD3, new org.apache.thrift.meta_data.FieldMetaData("unionField3", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+        new org.apache.thrift.meta_data.StructMetaData(org.apache.thrift.protocol.TType.STRUCT, PropValueUnion.class)));
     metaDataMap = Collections.unmodifiableMap(tmpMap);
     org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(Complex.class, metaDataMap);
   }
@@ -163,7 +197,11 @@ public Complex(
     List<Integer> lint,
     List<String> lString,
     List<IntString> lintString,
-    Map<String,String> mStringString)
+    Map<String,String> mStringString,
+    Map<String,Map<String,Map<String,PropValueUnion>>> attributes,
+    PropValueUnion unionField1,
+    PropValueUnion unionField2,
+    PropValueUnion unionField3)
   {
     this();
     this.aint = aint;
@@ -173,6 +211,10 @@ public Complex(
     this.lString = lString;
     this.lintString = lintString;
     this.mStringString = mStringString;
+    this.attributes = attributes;
+    this.unionField1 = unionField1;
+    this.unionField2 = unionField2;
+    this.unionField3 = unionField3;
   }
 
   /**
@@ -220,6 +262,52 @@ public Complex(Complex other) {
       }
       this.mStringString = __this__mStringString;
     }
+    if (other.isSetAttributes()) {
+      Map<String,Map<String,Map<String,PropValueUnion>>> __this__attributes = new HashMap<String,Map<String,Map<String,PropValueUnion>>>();
+      for (Map.Entry<String, Map<String,Map<String,PropValueUnion>>> other_element : other.attributes.entrySet()) {
+
+        String other_element_key = other_element.getKey();
+        Map<String,Map<String,PropValueUnion>> other_element_value = other_element.getValue();
+
+        String __this__attributes_copy_key = other_element_key;
+
+        Map<String,Map<String,PropValueUnion>> __this__attributes_copy_value = new HashMap<String,Map<String,PropValueUnion>>();
+        for (Map.Entry<String, Map<String,PropValueUnion>> other_element_value_element : other_element_value.entrySet()) {
+
+          String other_element_value_element_key = other_element_value_element.getKey();
+          Map<String,PropValueUnion> other_element_value_element_value = other_element_value_element.getValue();
+
+          String __this__attributes_copy_value_copy_key = other_element_value_element_key;
+
+          Map<String,PropValueUnion> __this__attributes_copy_value_copy_value = new HashMap<String,PropValueUnion>();
+          for (Map.Entry<String, PropValueUnion> other_element_value_element_value_element : other_element_value_element_value.entrySet()) {
+
+            String other_element_value_element_value_element_key = other_element_value_element_value_element.getKey();
+            PropValueUnion other_element_value_element_value_element_value = other_element_value_element_value_element.getValue();
+
+            String __this__attributes_copy_value_copy_value_copy_key = other_element_value_element_value_element_key;
+
+            PropValueUnion __this__attributes_copy_value_copy_value_copy_value = new PropValueUnion(other_element_value_element_value_element_value);
+
+            __this__attributes_copy_value_copy_value.put(__this__attributes_copy_value_copy_value_copy_key, __this__attributes_copy_value_copy_value_copy_value);
+          }
+
+          __this__attributes_copy_value.put(__this__attributes_copy_value_copy_key, __this__attributes_copy_value_copy_value);
+        }
+
+        __this__attributes.put(__this__attributes_copy_key, __this__attributes_copy_value);
+      }
+      this.attributes = __this__attributes;
+    }
+    if (other.isSetUnionField1()) {
+      this.unionField1 = new PropValueUnion(other.unionField1);
+    }
+    if (other.isSetUnionField2()) {
+      this.unionField2 = new PropValueUnion(other.unionField2);
+    }
+    if (other.isSetUnionField3()) {
+      this.unionField3 = new PropValueUnion(other.unionField3);
+    }
   }
 
   public Complex deepCopy() {
@@ -235,6 +323,10 @@ public void clear() {
     this.lString = null;
     this.lintString = null;
     this.mStringString = null;
+    this.attributes = null;
+    this.unionField1 = null;
+    this.unionField2 = null;
+    this.unionField3 = null;
   }
 
   public int getAint() {
@@ -430,6 +522,109 @@ public void setMStringStringIsSet(boolean value) {
     }
   }
 
+  public int getAttributesSize() {
+    return (this.attributes == null) ? 0 : this.attributes.size();
+  }
+
+  public void putToAttributes(String key, Map<String,Map<String,PropValueUnion>> val) {
+    if (this.attributes == null) {
+      this.attributes = new HashMap<String,Map<String,Map<String,PropValueUnion>>>();
+    }
+    this.attributes.put(key, val);
+  }
+
+  public Map<String,Map<String,Map<String,PropValueUnion>>> getAttributes() {
+    return this.attributes;
+  }
+
+  public void setAttributes(Map<String,Map<String,Map<String,PropValueUnion>>> attributes) {
+    this.attributes = attributes;
+  }
+
+  public void unsetAttributes() {
+    this.attributes = null;
+  }
+
+  /** Returns true if field attributes is set (has been assigned a value) and false otherwise */
+  public boolean isSetAttributes() {
+    return this.attributes != null;
+  }
+
+  public void setAttributesIsSet(boolean value) {
+    if (!value) {
+      this.attributes = null;
+    }
+  }
+
+  public PropValueUnion getUnionField1() {
+    return this.unionField1;
+  }
+
+  public void setUnionField1(PropValueUnion unionField1) {
+    this.unionField1 = unionField1;
+  }
+
+  public void unsetUnionField1() {
+    this.unionField1 = null;
+  }
+
+  /** Returns true if field unionField1 is set (has been assigned a value) and false otherwise */
+  public boolean isSetUnionField1() {
+    return this.unionField1 != null;
+  }
+
+  public void setUnionField1IsSet(boolean value) {
+    if (!value) {
+      this.unionField1 = null;
+    }
+  }
+
+  public PropValueUnion getUnionField2() {
+    return this.unionField2;
+  }
+
+  public void setUnionField2(PropValueUnion unionField2) {
+    this.unionField2 = unionField2;
+  }
+
+  public void unsetUnionField2() {
+    this.unionField2 = null;
+  }
+
+  /** Returns true if field unionField2 is set (has been assigned a value) and false otherwise */
+  public boolean isSetUnionField2() {
+    return this.unionField2 != null;
+  }
+
+  public void setUnionField2IsSet(boolean value) {
+    if (!value) {
+      this.unionField2 = null;
+    }
+  }
+
+  public PropValueUnion getUnionField3() {
+    return this.unionField3;
+  }
+
+  public void setUnionField3(PropValueUnion unionField3) {
+    this.unionField3 = unionField3;
+  }
+
+  public void unsetUnionField3() {
+    this.unionField3 = null;
+  }
+
+  /** Returns true if field unionField3 is set (has been assigned a value) and false otherwise */
+  public boolean isSetUnionField3() {
+    return this.unionField3 != null;
+  }
+
+  public void setUnionField3IsSet(boolean value) {
+    if (!value) {
+      this.unionField3 = null;
+    }
+  }
+
   public void setFieldValue(_Fields field, Object value) {
     switch (field) {
     case AINT:
@@ -480,6 +675,38 @@ public void setFieldValue(_Fields field, Object value) {
       }
       break;
 
+    case ATTRIBUTES:
+      if (value == null) {
+        unsetAttributes();
+      } else {
+        setAttributes((Map<String,Map<String,Map<String,PropValueUnion>>>)value);
+      }
+      break;
+
+    case UNION_FIELD1:
+      if (value == null) {
+        unsetUnionField1();
+      } else {
+        setUnionField1((PropValueUnion)value);
+      }
+      break;
+
+    case UNION_FIELD2:
+      if (value == null) {
+        unsetUnionField2();
+      } else {
+        setUnionField2((PropValueUnion)value);
+      }
+      break;
+
+    case UNION_FIELD3:
+      if (value == null) {
+        unsetUnionField3();
+      } else {
+        setUnionField3((PropValueUnion)value);
+      }
+      break;
+
     }
   }
 
@@ -503,6 +730,18 @@ public Object getFieldValue(_Fields field) {
     case M_STRING_STRING:
       return getMStringString();
 
+    case ATTRIBUTES:
+      return getAttributes();
+
+    case UNION_FIELD1:
+      return getUnionField1();
+
+    case UNION_FIELD2:
+      return getUnionField2();
+
+    case UNION_FIELD3:
+      return getUnionField3();
+
     }
     throw new IllegalStateException();
   }
@@ -526,6 +765,14 @@ public boolean isSet(_Fields field) {
       return isSetLintString();
     case M_STRING_STRING:
       return isSetMStringString();
+    case ATTRIBUTES:
+      return isSetAttributes();
+    case UNION_FIELD1:
+      return isSetUnionField1();
+    case UNION_FIELD2:
+      return isSetUnionField2();
+    case UNION_FIELD3:
+      return isSetUnionField3();
     }
     throw new IllegalStateException();
   }
@@ -597,6 +844,42 @@ public boolean equals(Complex that) {
         return false;
     }
 
+    boolean this_present_attributes = true && this.isSetAttributes();
+    boolean that_present_attributes = true && that.isSetAttributes();
+    if (this_present_attributes || that_present_attributes) {
+      if (!(this_present_attributes && that_present_attributes))
+        return false;
+      if (!this.attributes.equals(that.attributes))
+        return false;
+    }
+
+    boolean this_present_unionField1 = true && this.isSetUnionField1();
+    boolean that_present_unionField1 = true && that.isSetUnionField1();
+    if (this_present_unionField1 || that_present_unionField1) {
+      if (!(this_present_unionField1 && that_present_unionField1))
+        return false;
+      if (!this.unionField1.equals(that.unionField1))
+        return false;
+    }
+
+    boolean this_present_unionField2 = true && this.isSetUnionField2();
+    boolean that_present_unionField2 = true && that.isSetUnionField2();
+    if (this_present_unionField2 || that_present_unionField2) {
+      if (!(this_present_unionField2 && that_present_unionField2))
+        return false;
+      if (!this.unionField2.equals(that.unionField2))
+        return false;
+    }
+
+    boolean this_present_unionField3 = true && this.isSetUnionField3();
+    boolean that_present_unionField3 = true && that.isSetUnionField3();
+    if (this_present_unionField3 || that_present_unionField3) {
+      if (!(this_present_unionField3 && that_present_unionField3))
+        return false;
+      if (!this.unionField3.equals(that.unionField3))
+        return false;
+    }
+
     return true;
   }
 
@@ -634,6 +917,26 @@ public int hashCode() {
     if (present_mStringString)
       builder.append(mStringString);
 
+    boolean present_attributes = true && (isSetAttributes());
+    builder.append(present_attributes);
+    if (present_attributes)
+      builder.append(attributes);
+
+    boolean present_unionField1 = true && (isSetUnionField1());
+    builder.append(present_unionField1);
+    if (present_unionField1)
+      builder.append(unionField1);
+
+    boolean present_unionField2 = true && (isSetUnionField2());
+    builder.append(present_unionField2);
+    if (present_unionField2)
+      builder.append(unionField2);
+
+    boolean present_unionField3 = true && (isSetUnionField3());
+    builder.append(present_unionField3);
+    if (present_unionField3)
+      builder.append(unionField3);
+
     return builder.toHashCode();
   }
 
@@ -705,6 +1008,46 @@ public int compareTo(Complex other) {
         return lastComparison;
       }
     }
+    lastComparison = Boolean.valueOf(isSetAttributes()).compareTo(typedOther.isSetAttributes());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetAttributes()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.attributes, typedOther.attributes);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    lastComparison = Boolean.valueOf(isSetUnionField1()).compareTo(typedOther.isSetUnionField1());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetUnionField1()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.unionField1, typedOther.unionField1);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    lastComparison = Boolean.valueOf(isSetUnionField2()).compareTo(typedOther.isSetUnionField2());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetUnionField2()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.unionField2, typedOther.unionField2);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    lastComparison = Boolean.valueOf(isSetUnionField3()).compareTo(typedOther.isSetUnionField3());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetUnionField3()) {
+      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.unionField3, typedOther.unionField3);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
     return 0;
   }
 
@@ -768,6 +1111,38 @@ public String toString() {
       sb.append(this.mStringString);
     }
     first = false;
+    if (!first) sb.append(", ");
+    sb.append("attributes:");
+    if (this.attributes == null) {
+      sb.append("null");
+    } else {
+      sb.append(this.attributes);
+    }
+    first = false;
+    if (!first) sb.append(", ");
+    sb.append("unionField1:");
+    if (this.unionField1 == null) {
+      sb.append("null");
+    } else {
+      sb.append(this.unionField1);
+    }
+    first = false;
+    if (!first) sb.append(", ");
+    sb.append("unionField2:");
+    if (this.unionField2 == null) {
+      sb.append("null");
+    } else {
+      sb.append(this.unionField2);
+    }
+    first = false;
+    if (!first) sb.append(", ");
+    sb.append("unionField3:");
+    if (this.unionField3 == null) {
+      sb.append("null");
+    } else {
+      sb.append(this.unionField3);
+    }
+    first = false;
     sb.append(")");
     return sb.toString();
   }
@@ -832,13 +1207,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, Complex struct) thr
           case 3: // LINT
             if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
               {
-                org.apache.thrift.protocol.TList _list0 = iprot.readListBegin();
-                struct.lint = new ArrayList<Integer>(_list0.size);
-                for (int _i1 = 0; _i1 < _list0.size; ++_i1)
+                org.apache.thrift.protocol.TList _list18 = iprot.readListBegin();
+                struct.lint = new ArrayList<Integer>(_list18.size);
+                for (int _i19 = 0; _i19 < _list18.size; ++_i19)
                 {
-                  int _elem2; // required
-                  _elem2 = iprot.readI32();
-                  struct.lint.add(_elem2);
+                  int _elem20; // required
+                  _elem20 = iprot.readI32();
+                  struct.lint.add(_elem20);
                 }
                 iprot.readListEnd();
               }
@@ -850,13 +1225,13 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, Complex struct) thr
           case 4: // L_STRING
             if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
               {
-                org.apache.thrift.protocol.TList _list3 = iprot.readListBegin();
-                struct.lString = new ArrayList<String>(_list3.size);
-                for (int _i4 = 0; _i4 < _list3.size; ++_i4)
+                org.apache.thrift.protocol.TList _list21 = iprot.readListBegin();
+                struct.lString = new ArrayList<String>(_list21.size);
+                for (int _i22 = 0; _i22 < _list21.size; ++_i22)
                 {
-                  String _elem5; // required
-                  _elem5 = iprot.readString();
-                  struct.lString.add(_elem5);
+                  String _elem23; // required
+                  _elem23 = iprot.readString();
+                  struct.lString.add(_elem23);
                 }
                 iprot.readListEnd();
               }
@@ -868,14 +1243,14 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, Complex struct) thr
           case 5: // LINT_STRING
             if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
               {
-                org.apache.thrift.protocol.TList _list6 = iprot.readListBegin();
-                struct.lintString = new ArrayList<IntString>(_list6.size);
-                for (int _i7 = 0; _i7 < _list6.size; ++_i7)
+                org.apache.thrift.protocol.TList _list24 = iprot.readListBegin();
+                struct.lintString = new ArrayList<IntString>(_list24.size);
+                for (int _i25 = 0; _i25 < _list24.size; ++_i25)
                 {
-                  IntString _elem8; // required
-                  _elem8 = new IntString();
-                  _elem8.read(iprot);
-                  struct.lintString.add(_elem8);
+                  IntString _elem26; // required
+                  _elem26 = new IntString();
+                  _elem26.read(iprot);
+                  struct.lintString.add(_elem26);
                 }
                 iprot.readListEnd();
               }
@@ -887,15 +1262,15 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, Complex struct) thr
           case 6: // M_STRING_STRING
             if (schemeField.type == org.apache.thrift.protocol.TType.MAP) {
               {
-                org.apache.thrift.protocol.TMap _map9 = iprot.readMapBegin();
-                struct.mStringString = new HashMap<String,String>(2*_map9.size);
-                for (int _i10 = 0; _i10 < _map9.size; ++_i10)
+                org.apache.thrift.protocol.TMap _map27 = iprot.readMapBegin();
+                struct.mStringString = new HashMap<String,String>(2*_map27.size);
+                for (int _i28 = 0; _i28 < _map27.size; ++_i28)
                 {
-                  String _key11; // required
-                  String _val12; // required
-                  _key11 = iprot.readString();
-                  _val12 = iprot.readString();
-                  struct.mStringString.put(_key11, _val12);
+                  String _key29; // required
+                  String _val30; // optional
+                  _key29 = iprot.readString();
+                  _val30 = iprot.readString();
+                  struct.mStringString.put(_key29, _val30);
                 }
                 iprot.readMapEnd();
               }
@@ -904,6 +1279,78 @@ public void read(org.apache.thrift.protocol.TProtocol iprot, Complex struct) thr
               org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
             }
             break;
+          case 7: // ATTRIBUTES
+            if (schemeField.type == org.apache.thrift.protocol.TType.MAP) {
+              {
+                org.apache.thrift.protocol.TMap _map31 = iprot.readMapBegin();
+                struct.attributes = new HashMap<String,Map<String,Map<String,PropValueUnion>>>(2*_map31.size);
+                for (int _i32 = 0; _i32 < _map31.size; ++_i32)
+                {
+                  String _key33; // required
+                  Map<String,Map<String,PropValueUnion>> _val34; // optional
+                  _key33 = iprot.readString();
+                  {
+                    org.apache.thrift.protocol.TMap _map35 = iprot.readMapBegin();
+                    _val34 = new HashMap<String,Map<String,PropValueUnion>>(2*_map35.size);
+                    for (int _i36 = 0; _i36 < _map35.size; ++_i36)
+                    {
+                      String _key37; // required
+                      Map<String,PropValueUnion> _val38; // optional
+                      _key37 = iprot.readString();
+                      {
+                        org.apache.thrift.protocol.TMap _map39 = iprot.readMapBegin();
+                        _val38 = new HashMap<String,PropValueUnion>(2*_map39.size);
+                        for (int _i40 = 0; _i40 < _map39.size; ++_i40)
+                        {
+                          String _key41; // required
+                          PropValueUnion _val42; // optional
+                          _key41 = iprot.readString();
+                          _val42 = new PropValueUnion();
+                          _val42.read(iprot);
+                          _val38.put(_key41, _val42);
+                        }
+                        iprot.readMapEnd();
+                      }
+                      _val34.put(_key37, _val38);
+                    }
+                    iprot.readMapEnd();
+                  }
+                  struct.attributes.put(_key33, _val34);
+                }
+                iprot.readMapEnd();
+              }
+              struct.setAttributesIsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
+          case 8: // UNION_FIELD1
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
+              struct.unionField1 = new PropValueUnion();
+              struct.unionField1.read(iprot);
+              struct.setUnionField1IsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
+          case 9: // UNION_FIELD2
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
+              struct.unionField2 = new PropValueUnion();
+              struct.unionField2.read(iprot);
+              struct.setUnionField2IsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
+          case 10: // UNION_FIELD3
+            if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
+              struct.unionField3 = new PropValueUnion();
+              struct.unionField3.read(iprot);
+              struct.setUnionField3IsSet(true);
+            } else { 
+              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
+            }
+            break;
           default:
             org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
         }
@@ -929,9 +1376,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, Complex struct) th
         oprot.writeFieldBegin(LINT_FIELD_DESC);
         {
           oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.I32, struct.lint.size()));
-          for (int _iter13 : struct.lint)
+          for (int _iter43 : struct.lint)
           {
-            oprot.writeI32(_iter13);
+            oprot.writeI32(_iter43);
           }
           oprot.writeListEnd();
         }
@@ -941,9 +1388,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, Complex struct) th
         oprot.writeFieldBegin(L_STRING_FIELD_DESC);
         {
           oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.lString.size()));
-          for (String _iter14 : struct.lString)
+          for (String _iter44 : struct.lString)
           {
-            oprot.writeString(_iter14);
+            oprot.writeString(_iter44);
           }
           oprot.writeListEnd();
         }
@@ -953,9 +1400,9 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, Complex struct) th
         oprot.writeFieldBegin(LINT_STRING_FIELD_DESC);
         {
           oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, struct.lintString.size()));
-          for (IntString _iter15 : struct.lintString)
+          for (IntString _iter45 : struct.lintString)
           {
-            _iter15.write(oprot);
+            _iter45.write(oprot);
           }
           oprot.writeListEnd();
         }
@@ -965,15 +1412,59 @@ public void write(org.apache.thrift.protocol.TProtocol oprot, Complex struct) th
         oprot.writeFieldBegin(M_STRING_STRING_FIELD_DESC);
         {
           oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, struct.mStringString.size()));
-          for (Map.Entry<String, String> _iter16 : struct.mStringString.entrySet())
+          for (Map.Entry<String, String> _iter46 : struct.mStringString.entrySet())
+          {
+            oprot.writeString(_iter46.getKey());
+            oprot.writeString(_iter46.getValue());
+          }
+          oprot.writeMapEnd();
+        }
+        oprot.writeFieldEnd();
+      }
+      if (struct.attributes != null) {
+        oprot.writeFieldBegin(ATTRIBUTES_FIELD_DESC);
+        {
+          oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.MAP, struct.attributes.size()));
+          for (Map.Entry<String, Map<String,Map<String,PropValueUnion>>> _iter47 : struct.attributes.entrySet())
           {
-            oprot.writeString(_iter16.getKey());
-            oprot.writeString(_iter16.getValue());
+            oprot.writeString(_iter47.getKey());
+            {
+              oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.MAP, _iter47.getValue().size()));
+              for (Map.Entry<String, Map<String,PropValueUnion>> _iter48 : _iter47.getValue().entrySet())
+              {
+                oprot.writeString(_iter48.getKey());
+                {
+                  oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRUCT, _iter48.getValue().size()));
+                  for (Map.Entry<String, PropValueUnion> _iter49 : _iter48.getValue().entrySet())
+                  {
+                    oprot.writeString(_iter49.getKey());
+                    _iter49.getValue().write(oprot);
+                  }
+                  oprot.writeMapEnd();
+                }
+              }
+              oprot.writeMapEnd();
+            }
           }
           oprot.writeMapEnd();
         }
         oprot.writeFieldEnd();
       }
+      if (struct.unionField1 != null) {
+        oprot.writeFieldBegin(UNION_FIELD1_FIELD_DESC);
+        struct.unionField1.write(oprot);
+        oprot.writeFieldEnd();
+      }
+      if (struct.unionField2 != null) {
+        oprot.writeFieldBegin(UNION_FIELD2_FIELD_DESC);
+        struct.unionField2.write(oprot);
+        oprot.writeFieldEnd();
+      }
+      if (struct.unionField3 != null) {
+        oprot.writeFieldBegin(UNION_FIELD3_FIELD_DESC);
+        struct.unionField3.write(oprot);
+        oprot.writeFieldEnd();
+      }
       oprot.writeFieldStop();
       oprot.writeStructEnd();
     }
@@ -1010,7 +1501,19 @@ public void write(org.apache.thrift.protocol.TProtocol prot, Complex struct) thr
       if (struct.isSetMStringString()) {
         optionals.set(5);
       }
-      oprot.writeBitSet(optionals, 6);
+      if (struct.isSetAttributes()) {
+        optionals.set(6);
+      }
+      if (struct.isSetUnionField1()) {
+        optionals.set(7);
+      }
+      if (struct.isSetUnionField2()) {
+        optionals.set(8);
+      }
+      if (struct.isSetUnionField3()) {
+        optionals.set(9);
+      }
+      oprot.writeBitSet(optionals, 10);
       if (struct.isSetAint()) {
         oprot.writeI32(struct.aint);
       }
@@ -1020,46 +1523,79 @@ public void write(org.apache.thrift.protocol.TProtocol prot, Complex struct) thr
       if (struct.isSetLint()) {
         {
           oprot.writeI32(struct.lint.size());
-          for (int _iter17 : struct.lint)
+          for (int _iter50 : struct.lint)
           {
-            oprot.writeI32(_iter17);
+            oprot.writeI32(_iter50);
           }
         }
       }
       if (struct.isSetLString()) {
         {
           oprot.writeI32(struct.lString.size());
-          for (String _iter18 : struct.lString)
+          for (String _iter51 : struct.lString)
           {
-            oprot.writeString(_iter18);
+            oprot.writeString(_iter51);
           }
         }
       }
       if (struct.isSetLintString()) {
         {
           oprot.writeI32(struct.lintString.size());
-          for (IntString _iter19 : struct.lintString)
+          for (IntString _iter52 : struct.lintString)
           {
-            _iter19.write(oprot);
+            _iter52.write(oprot);
           }
         }
       }
       if (struct.isSetMStringString()) {
         {
           oprot.writeI32(struct.mStringString.size());
-          for (Map.Entry<String, String> _iter20 : struct.mStringString.entrySet())
+          for (Map.Entry<String, String> _iter53 : struct.mStringString.entrySet())
           {
-            oprot.writeString(_iter20.getKey());
-            oprot.writeString(_iter20.getValue());
+            oprot.writeString(_iter53.getKey());
+            oprot.writeString(_iter53.getValue());
           }
         }
       }
+      if (struct.isSetAttributes()) {
+        {
+          oprot.writeI32(struct.attributes.size());
+          for (Map.Entry<String, Map<String,Map<String,PropValueUnion>>> _iter54 : struct.attributes.entrySet())
+          {
+            oprot.writeString(_iter54.getKey());
+            {
+              oprot.writeI32(_iter54.getValue().size());
+              for (Map.Entry<String, Map<String,PropValueUnion>> _iter55 : _iter54.getValue().entrySet())
+              {
+                oprot.writeString(_iter55.getKey());
+                {
+                  oprot.writeI32(_iter55.getValue().size());
+                  for (Map.Entry<String, PropValueUnion> _iter56 : _iter55.getValue().entrySet())
+                  {
+                    oprot.writeString(_iter56.getKey());
+                    _iter56.getValue().write(oprot);
+                  }
+                }
+              }
+            }
+          }
+        }
+      }
+      if (struct.isSetUnionField1()) {
+        struct.unionField1.write(oprot);
+      }
+      if (struct.isSetUnionField2()) {
+        struct.unionField2.write(oprot);
+      }
+      if (struct.isSetUnionField3()) {
+        struct.unionField3.write(oprot);
+      }
     }
 
     @Override
     public void read(org.apache.thrift.protocol.TProtocol prot, Complex struct) throws org.apache.thrift.TException {
       TTupleProtocol iprot = (TTupleProtocol) prot;
-      BitSet incoming = iprot.readBitSet(6);
+      BitSet incoming = iprot.readBitSet(10);
       if (incoming.get(0)) {
         struct.aint = iprot.readI32();
         struct.setAintIsSet(true);
@@ -1070,59 +1606,112 @@ public void read(org.apache.thrift.protocol.TProtocol prot, Complex struct) thro
       }
       if (incoming.get(2)) {
         {
-          org.apache.thrift.protocol.TList _list21 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.I32, iprot.readI32());
-          struct.lint = new ArrayList<Integer>(_list21.size);
-          for (int _i22 = 0; _i22 < _list21.size; ++_i22)
+          org.apache.thrift.protocol.TList _list57 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.I32, iprot.readI32());
+          struct.lint = new ArrayList<Integer>(_list57.size);
+          for (int _i58 = 0; _i58 < _list57.size; ++_i58)
           {
-            int _elem23; // required
-            _elem23 = iprot.readI32();
-            struct.lint.add(_elem23);
+            int _elem59; // required
+            _elem59 = iprot.readI32();
+            struct.lint.add(_elem59);
           }
         }
         struct.setLintIsSet(true);
       }
       if (incoming.get(3)) {
         {
-          org.apache.thrift.protocol.TList _list24 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-          struct.lString = new ArrayList<String>(_list24.size);
-          for (int _i25 = 0; _i25 < _list24.size; ++_i25)
+          org.apache.thrift.protocol.TList _list60 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+          struct.lString = new ArrayList<String>(_list60.size);
+          for (int _i61 = 0; _i61 < _list60.size; ++_i61)
           {
-            String _elem26; // required
-            _elem26 = iprot.readString();
-            struct.lString.add(_elem26);
+            String _elem62; // required
+            _elem62 = iprot.readString();
+            struct.lString.add(_elem62);
           }
         }
         struct.setLStringIsSet(true);
       }
       if (incoming.get(4)) {
         {
-          org.apache.thrift.protocol.TList _list27 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
-          struct.lintString = new ArrayList<IntString>(_list27.size);
-          for (int _i28 = 0; _i28 < _list27.size; ++_i28)
+          org.apache.thrift.protocol.TList _list63 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
+          struct.lintString = new ArrayList<IntString>(_list63.size);
+          for (int _i64 = 0; _i64 < _list63.size; ++_i64)
           {
-            IntString _elem29; // required
-            _elem29 = new IntString();
-            _elem29.read(iprot);
-            struct.lintString.add(_elem29);
+            IntString _elem65; // required
+            _elem65 = new IntString();
+            _elem65.read(iprot);
+            struct.lintString.add(_elem65);
           }
         }
         struct.setLintStringIsSet(true);
       }
       if (incoming.get(5)) {
         {
-          org.apache.thrift.protocol.TMap _map30 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
-          struct.mStringString = new HashMap<String,String>(2*_map30.size);
-          for (int _i31 = 0; _i31 < _map30.size; ++_i31)
+          org.apache.thrift.protocol.TMap _map66 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
+          struct.mStringString = new HashMap<String,String>(2*_map66.size);
+          for (int _i67 = 0; _i67 < _map66.size; ++_i67)
           {
-            String _key32; // required
-            String _val33; // required
-            _key32 = iprot.readString();
-            _val33 = iprot.readString();
-            struct.mStringString.put(_key32, _val33);
+            String _key68; // required
+            String _val69; // optional
+            _key68 = iprot.readString();
+            _val69 = iprot.readString();
+            struct.mStringString.put(_key68, _val69);
           }
         }
         struct.setMStringStringIsSet(true);
       }
+      if (incoming.get(6)) {
+        {
+          org.apache.thrift.protocol.TMap _map70 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.MAP, iprot.readI32());
+          struct.attributes = new HashMap<String,Map<String,Map<String,PropValueUnion>>>(2*_map70.size);
+          for (int _i71 = 0; _i71 < _map70.size; ++_i71)
+          {
+            String _key72; // required
+            Map<String,Map<String,PropValueUnion>> _val73; // optional
+            _key72 = iprot.readString();
+            {
+              org.apache.thrift.protocol.TMap _map74 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.MAP, iprot.readI32());
+              _val73 = new HashMap<String,Map<String,PropValueUnion>>(2*_map74.size);
+              for (int _i75 = 0; _i75 < _map74.size; ++_i75)
+              {
+                String _key76; // required
+                Map<String,PropValueUnion> _val77; // optional
+                _key76 = iprot.readString();
+                {
+                  org.apache.thrift.protocol.TMap _map78 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
+                  _val77 = new HashMap<String,PropValueUnion>(2*_map78.size);
+                  for (int _i79 = 0; _i79 < _map78.size; ++_i79)
+                  {
+                    String _key80; // required
+                    PropValueUnion _val81; // optional
+                    _key80 = iprot.readString();
+                    _val81 = new PropValueUnion();
+                    _val81.read(iprot);
+                    _val77.put(_key80, _val81);
+                  }
+                }
+                _val73.put(_key76, _val77);
+              }
+            }
+            struct.attributes.put(_key72, _val73);
+          }
+        }
+        struct.setAttributesIsSet(true);
+      }
+      if (incoming.get(7)) {
+        struct.unionField1 = new PropValueUnion();
+        struct.unionField1.read(iprot);
+        struct.setUnionField1IsSet(true);
+      }
+      if (incoming.get(8)) {
+        struct.unionField2 = new PropValueUnion();
+        struct.unionField2.read(iprot);
+        struct.setUnionField2IsSet(true);
+      }
+      if (incoming.get(9)) {
+        struct.unionField3 = new PropValueUnion();
+        struct.unionField3.read(iprot);
+        struct.setUnionField3IsSet(true);
+      }
     }
   }
 
diff --git a/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/PropValueUnion.java b/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/PropValueUnion.java
new file mode 100644
index 0000000000..0a5757e5b5
--- /dev/null
+++ b/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/PropValueUnion.java
@@ -0,0 +1,730 @@
+/**
+ * Autogenerated by Thrift Compiler (0.9.0)
+ *
+ * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
+ *  @generated
+ */
+package org.apache.hadoop.hive.serde2.thrift.test;
+
+import org.apache.commons.lang.builder.HashCodeBuilder;
+import org.apache.thrift.scheme.IScheme;
+import org.apache.thrift.scheme.SchemeFactory;
+import org.apache.thrift.scheme.StandardScheme;
+
+import org.apache.thrift.scheme.TupleScheme;
+import org.apache.thrift.protocol.TTupleProtocol;
+import org.apache.thrift.protocol.TProtocolException;
+import org.apache.thrift.EncodingUtils;
+import org.apache.thrift.TException;
+import java.util.List;
+import java.util.ArrayList;
+import java.util.Map;
+import java.util.HashMap;
+import java.util.EnumMap;
+import java.util.Set;
+import java.util.HashSet;
+import java.util.EnumSet;
+import java.util.Collections;
+import java.util.BitSet;
+import java.nio.ByteBuffer;
+import java.util.Arrays;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class PropValueUnion extends org.apache.thrift.TUnion<PropValueUnion, PropValueUnion._Fields> {
+  private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("PropValueUnion");
+  private static final org.apache.thrift.protocol.TField INT_VALUE_FIELD_DESC = new org.apache.thrift.protocol.TField("intValue", org.apache.thrift.protocol.TType.I32, (short)1);
+  private static final org.apache.thrift.protocol.TField LONG_VALUE_FIELD_DESC = new org.apache.thrift.protocol.TField("longValue", org.apache.thrift.protocol.TType.I64, (short)2);
+  private static final org.apache.thrift.protocol.TField STRING_VALUE_FIELD_DESC = new org.apache.thrift.protocol.TField("stringValue", org.apache.thrift.protocol.TType.STRING, (short)3);
+  private static final org.apache.thrift.protocol.TField DOUBLE_VALUE_FIELD_DESC = new org.apache.thrift.protocol.TField("doubleValue", org.apache.thrift.protocol.TType.DOUBLE, (short)4);
+  private static final org.apache.thrift.protocol.TField FLAG_FIELD_DESC = new org.apache.thrift.protocol.TField("flag", org.apache.thrift.protocol.TType.BOOL, (short)5);
+  private static final org.apache.thrift.protocol.TField L_STRING_FIELD_DESC = new org.apache.thrift.protocol.TField("lString", org.apache.thrift.protocol.TType.LIST, (short)6);
+  private static final org.apache.thrift.protocol.TField UNION_MSTRING_STRING_FIELD_DESC = new org.apache.thrift.protocol.TField("unionMStringString", org.apache.thrift.protocol.TType.MAP, (short)7);
+
+  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
+  public enum _Fields implements org.apache.thrift.TFieldIdEnum {
+    INT_VALUE((short)1, "intValue"),
+    LONG_VALUE((short)2, "longValue"),
+    STRING_VALUE((short)3, "stringValue"),
+    DOUBLE_VALUE((short)4, "doubleValue"),
+    FLAG((short)5, "flag"),
+    L_STRING((short)6, "lString"),
+    UNION_MSTRING_STRING((short)7, "unionMStringString");
+
+    private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
+
+    static {
+      for (_Fields field : EnumSet.allOf(_Fields.class)) {
+        byName.put(field.getFieldName(), field);
+      }
+    }
+
+    /**
+     * Find the _Fields constant that matches fieldId, or null if its not found.
+     */
+    public static _Fields findByThriftId(int fieldId) {
+      switch(fieldId) {
+        case 1: // INT_VALUE
+          return INT_VALUE;
+        case 2: // LONG_VALUE
+          return LONG_VALUE;
+        case 3: // STRING_VALUE
+          return STRING_VALUE;
+        case 4: // DOUBLE_VALUE
+          return DOUBLE_VALUE;
+        case 5: // FLAG
+          return FLAG;
+        case 6: // L_STRING
+          return L_STRING;
+        case 7: // UNION_MSTRING_STRING
+          return UNION_MSTRING_STRING;
+        default:
+          return null;
+      }
+    }
+
+    /**
+     * Find the _Fields constant that matches fieldId, throwing an exception
+     * if it is not found.
+     */
+    public static _Fields findByThriftIdOrThrow(int fieldId) {
+      _Fields fields = findByThriftId(fieldId);
+      if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
+      return fields;
+    }
+
+    /**
+     * Find the _Fields constant that matches name, or null if its not found.
+     */
+    public static _Fields findByName(String name) {
+      return byName.get(name);
+    }
+
+    private final short _thriftId;
+    private final String _fieldName;
+
+    _Fields(short thriftId, String fieldName) {
+      _thriftId = thriftId;
+      _fieldName = fieldName;
+    }
+
+    public short getThriftFieldId() {
+      return _thriftId;
+    }
+
+    public String getFieldName() {
+      return _fieldName;
+    }
+  }
+
+  public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
+  static {
+    Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
+    tmpMap.put(_Fields.INT_VALUE, new org.apache.thrift.meta_data.FieldMetaData("intValue", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I32)));
+    tmpMap.put(_Fields.LONG_VALUE, new org.apache.thrift.meta_data.FieldMetaData("longValue", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I64)));
+    tmpMap.put(_Fields.STRING_VALUE, new org.apache.thrift.meta_data.FieldMetaData("stringValue", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
+    tmpMap.put(_Fields.DOUBLE_VALUE, new org.apache.thrift.meta_data.FieldMetaData("doubleValue", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.DOUBLE)));
+    tmpMap.put(_Fields.FLAG, new org.apache.thrift.meta_data.FieldMetaData("flag", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
+        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.BOOL)));
+    tmpMap.put(_Fields.L_STRING, new org.apache.thrift.meta_data.FieldMetaData("lString", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+        new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
+            new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING))));
+    tmpMap.put(_Fields.UNION_MSTRING_STRING, new org.apache.thrift.meta_data.FieldMetaData("unionMStringString", org.apache.thrift.TFieldRequirementType.DEFAULT, 
+        new org.apache.thrift.meta_data.MapMetaData(org.apache.thrift.protocol.TType.MAP, 
+            new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING), 
+            new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING))));
+    metaDataMap = Collections.unmodifiableMap(tmpMap);
+    org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(PropValueUnion.class, metaDataMap);
+  }
+
+  public PropValueUnion() {
+    super();
+  }
+
+  public PropValueUnion(_Fields setField, Object value) {
+    super(setField, value);
+  }
+
+  public PropValueUnion(PropValueUnion other) {
+    super(other);
+  }
+  public PropValueUnion deepCopy() {
+    return new PropValueUnion(this);
+  }
+
+  public static PropValueUnion intValue(int value) {
+    PropValueUnion x = new PropValueUnion();
+    x.setIntValue(value);
+    return x;
+  }
+
+  public static PropValueUnion longValue(long value) {
+    PropValueUnion x = new PropValueUnion();
+    x.setLongValue(value);
+    return x;
+  }
+
+  public static PropValueUnion stringValue(String value) {
+    PropValueUnion x = new PropValueUnion();
+    x.setStringValue(value);
+    return x;
+  }
+
+  public static PropValueUnion doubleValue(double value) {
+    PropValueUnion x = new PropValueUnion();
+    x.setDoubleValue(value);
+    return x;
+  }
+
+  public static PropValueUnion flag(boolean value) {
+    PropValueUnion x = new PropValueUnion();
+    x.setFlag(value);
+    return x;
+  }
+
+  public static PropValueUnion lString(List<String> value) {
+    PropValueUnion x = new PropValueUnion();
+    x.setLString(value);
+    return x;
+  }
+
+  public static PropValueUnion unionMStringString(Map<String,String> value) {
+    PropValueUnion x = new PropValueUnion();
+    x.setUnionMStringString(value);
+    return x;
+  }
+
+
+  @Override
+  protected void checkType(_Fields setField, Object value) throws ClassCastException {
+    switch (setField) {
+      case INT_VALUE:
+        if (value instanceof Integer) {
+          break;
+        }
+        throw new ClassCastException("Was expecting value of type Integer for field 'intValue', but got " + value.getClass().getSimpleName());
+      case LONG_VALUE:
+        if (value instanceof Long) {
+          break;
+        }
+        throw new ClassCastException("Was expecting value of type Long for field 'longValue', but got " + value.getClass().getSimpleName());
+      case STRING_VALUE:
+        if (value instanceof String) {
+          break;
+        }
+        throw new ClassCastException("Was expecting value of type String for field 'stringValue', but got " + value.getClass().getSimpleName());
+      case DOUBLE_VALUE:
+        if (value instanceof Double) {
+          break;
+        }
+        throw new ClassCastException("Was expecting value of type Double for field 'doubleValue', but got " + value.getClass().getSimpleName());
+      case FLAG:
+        if (value instanceof Boolean) {
+          break;
+        }
+        throw new ClassCastException("Was expecting value of type Boolean for field 'flag', but got " + value.getClass().getSimpleName());
+      case L_STRING:
+        if (value instanceof List) {
+          break;
+        }
+        throw new ClassCastException("Was expecting value of type List<String> for field 'lString', but got " + value.getClass().getSimpleName());
+      case UNION_MSTRING_STRING:
+        if (value instanceof Map) {
+          break;
+        }
+        throw new ClassCastException("Was expecting value of type Map<String,String> for field 'unionMStringString', but got " + value.getClass().getSimpleName());
+      default:
+        throw new IllegalArgumentException("Unknown field id " + setField);
+    }
+  }
+
+  @Override
+  protected Object standardSchemeReadValue(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TField field) throws org.apache.thrift.TException {
+    _Fields setField = _Fields.findByThriftId(field.id);
+    if (setField != null) {
+      switch (setField) {
+        case INT_VALUE:
+          if (field.type == INT_VALUE_FIELD_DESC.type) {
+            Integer intValue;
+            intValue = iprot.readI32();
+            return intValue;
+          } else {
+            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
+            return null;
+          }
+        case LONG_VALUE:
+          if (field.type == LONG_VALUE_FIELD_DESC.type) {
+            Long longValue;
+            longValue = iprot.readI64();
+            return longValue;
+          } else {
+            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
+            return null;
+          }
+        case STRING_VALUE:
+          if (field.type == STRING_VALUE_FIELD_DESC.type) {
+            String stringValue;
+            stringValue = iprot.readString();
+            return stringValue;
+          } else {
+            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
+            return null;
+          }
+        case DOUBLE_VALUE:
+          if (field.type == DOUBLE_VALUE_FIELD_DESC.type) {
+            Double doubleValue;
+            doubleValue = iprot.readDouble();
+            return doubleValue;
+          } else {
+            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
+            return null;
+          }
+        case FLAG:
+          if (field.type == FLAG_FIELD_DESC.type) {
+            Boolean flag;
+            flag = iprot.readBool();
+            return flag;
+          } else {
+            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
+            return null;
+          }
+        case L_STRING:
+          if (field.type == L_STRING_FIELD_DESC.type) {
+            List<String> lString;
+            {
+              org.apache.thrift.protocol.TList _list0 = iprot.readListBegin();
+              lString = new ArrayList<String>(_list0.size);
+              for (int _i1 = 0; _i1 < _list0.size; ++_i1)
+              {
+                String _elem2; // required
+                _elem2 = iprot.readString();
+                lString.add(_elem2);
+              }
+              iprot.readListEnd();
+            }
+            return lString;
+          } else {
+            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
+            return null;
+          }
+        case UNION_MSTRING_STRING:
+          if (field.type == UNION_MSTRING_STRING_FIELD_DESC.type) {
+            Map<String,String> unionMStringString;
+            {
+              org.apache.thrift.protocol.TMap _map3 = iprot.readMapBegin();
+              unionMStringString = new HashMap<String,String>(2*_map3.size);
+              for (int _i4 = 0; _i4 < _map3.size; ++_i4)
+              {
+                String _key5; // required
+                String _val6; // optional
+                _key5 = iprot.readString();
+                _val6 = iprot.readString();
+                unionMStringString.put(_key5, _val6);
+              }
+              iprot.readMapEnd();
+            }
+            return unionMStringString;
+          } else {
+            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, field.type);
+            return null;
+          }
+        default:
+          throw new IllegalStateException("setField wasn't null, but didn't match any of the case statements!");
+      }
+    } else {
+      return null;
+    }
+  }
+
+  @Override
+  protected void standardSchemeWriteValue(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
+    switch (setField_) {
+      case INT_VALUE:
+        Integer intValue = (Integer)value_;
+        oprot.writeI32(intValue);
+        return;
+      case LONG_VALUE:
+        Long longValue = (Long)value_;
+        oprot.writeI64(longValue);
+        return;
+      case STRING_VALUE:
+        String stringValue = (String)value_;
+        oprot.writeString(stringValue);
+        return;
+      case DOUBLE_VALUE:
+        Double doubleValue = (Double)value_;
+        oprot.writeDouble(doubleValue);
+        return;
+      case FLAG:
+        Boolean flag = (Boolean)value_;
+        oprot.writeBool(flag);
+        return;
+      case L_STRING:
+        List<String> lString = (List<String>)value_;
+        {
+          oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, lString.size()));
+          for (String _iter7 : lString)
+          {
+            oprot.writeString(_iter7);
+          }
+          oprot.writeListEnd();
+        }
+        return;
+      case UNION_MSTRING_STRING:
+        Map<String,String> unionMStringString = (Map<String,String>)value_;
+        {
+          oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, unionMStringString.size()));
+          for (Map.Entry<String, String> _iter8 : unionMStringString.entrySet())
+          {
+            oprot.writeString(_iter8.getKey());
+            oprot.writeString(_iter8.getValue());
+          }
+          oprot.writeMapEnd();
+        }
+        return;
+      default:
+        throw new IllegalStateException("Cannot write union with unknown field " + setField_);
+    }
+  }
+
+  @Override
+  protected Object tupleSchemeReadValue(org.apache.thrift.protocol.TProtocol iprot, short fieldID) throws org.apache.thrift.TException {
+    _Fields setField = _Fields.findByThriftId(fieldID);
+    if (setField != null) {
+      switch (setField) {
+        case INT_VALUE:
+          Integer intValue;
+          intValue = iprot.readI32();
+          return intValue;
+        case LONG_VALUE:
+          Long longValue;
+          longValue = iprot.readI64();
+          return longValue;
+        case STRING_VALUE:
+          String stringValue;
+          stringValue = iprot.readString();
+          return stringValue;
+        case DOUBLE_VALUE:
+          Double doubleValue;
+          doubleValue = iprot.readDouble();
+          return doubleValue;
+        case FLAG:
+          Boolean flag;
+          flag = iprot.readBool();
+          return flag;
+        case L_STRING:
+          List<String> lString;
+          {
+            org.apache.thrift.protocol.TList _list9 = iprot.readListBegin();
+            lString = new ArrayList<String>(_list9.size);
+            for (int _i10 = 0; _i10 < _list9.size; ++_i10)
+            {
+              String _elem11; // required
+              _elem11 = iprot.readString();
+              lString.add(_elem11);
+            }
+            iprot.readListEnd();
+          }
+          return lString;
+        case UNION_MSTRING_STRING:
+          Map<String,String> unionMStringString;
+          {
+            org.apache.thrift.protocol.TMap _map12 = iprot.readMapBegin();
+            unionMStringString = new HashMap<String,String>(2*_map12.size);
+            for (int _i13 = 0; _i13 < _map12.size; ++_i13)
+            {
+              String _key14; // required
+              String _val15; // optional
+              _key14 = iprot.readString();
+              _val15 = iprot.readString();
+              unionMStringString.put(_key14, _val15);
+            }
+            iprot.readMapEnd();
+          }
+          return unionMStringString;
+        default:
+          throw new IllegalStateException("setField wasn't null, but didn't match any of the case statements!");
+      }
+    } else {
+      throw new TProtocolException("Couldn't find a field with field id " + fieldID);
+    }
+  }
+
+  @Override
+  protected void tupleSchemeWriteValue(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
+    switch (setField_) {
+      case INT_VALUE:
+        Integer intValue = (Integer)value_;
+        oprot.writeI32(intValue);
+        return;
+      case LONG_VALUE:
+        Long longValue = (Long)value_;
+        oprot.writeI64(longValue);
+        return;
+      case STRING_VALUE:
+        String stringValue = (String)value_;
+        oprot.writeString(stringValue);
+        return;
+      case DOUBLE_VALUE:
+        Double doubleValue = (Double)value_;
+        oprot.writeDouble(doubleValue);
+        return;
+      case FLAG:
+        Boolean flag = (Boolean)value_;
+        oprot.writeBool(flag);
+        return;
+      case L_STRING:
+        List<String> lString = (List<String>)value_;
+        {
+          oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, lString.size()));
+          for (String _iter16 : lString)
+          {
+            oprot.writeString(_iter16);
+          }
+          oprot.writeListEnd();
+        }
+        return;
+      case UNION_MSTRING_STRING:
+        Map<String,String> unionMStringString = (Map<String,String>)value_;
+        {
+          oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, unionMStringString.size()));
+          for (Map.Entry<String, String> _iter17 : unionMStringString.entrySet())
+          {
+            oprot.writeString(_iter17.getKey());
+            oprot.writeString(_iter17.getValue());
+          }
+          oprot.writeMapEnd();
+        }
+        return;
+      default:
+        throw new IllegalStateException("Cannot write union with unknown field " + setField_);
+    }
+  }
+
+  @Override
+  protected org.apache.thrift.protocol.TField getFieldDesc(_Fields setField) {
+    switch (setField) {
+      case INT_VALUE:
+        return INT_VALUE_FIELD_DESC;
+      case LONG_VALUE:
+        return LONG_VALUE_FIELD_DESC;
+      case STRING_VALUE:
+        return STRING_VALUE_FIELD_DESC;
+      case DOUBLE_VALUE:
+        return DOUBLE_VALUE_FIELD_DESC;
+      case FLAG:
+        return FLAG_FIELD_DESC;
+      case L_STRING:
+        return L_STRING_FIELD_DESC;
+      case UNION_MSTRING_STRING:
+        return UNION_MSTRING_STRING_FIELD_DESC;
+      default:
+        throw new IllegalArgumentException("Unknown field id " + setField);
+    }
+  }
+
+  @Override
+  protected org.apache.thrift.protocol.TStruct getStructDesc() {
+    return STRUCT_DESC;
+  }
+
+  @Override
+  protected _Fields enumForId(short id) {
+    return _Fields.findByThriftIdOrThrow(id);
+  }
+
+  public _Fields fieldForId(int fieldId) {
+    return _Fields.findByThriftId(fieldId);
+  }
+
+
+  public int getIntValue() {
+    if (getSetField() == _Fields.INT_VALUE) {
+      return (Integer)getFieldValue();
+    } else {
+      throw new RuntimeException("Cannot get field 'intValue' because union is currently set to " + getFieldDesc(getSetField()).name);
+    }
+  }
+
+  public void setIntValue(int value) {
+    setField_ = _Fields.INT_VALUE;
+    value_ = value;
+  }
+
+  public long getLongValue() {
+    if (getSetField() == _Fields.LONG_VALUE) {
+      return (Long)getFieldValue();
+    } else {
+      throw new RuntimeException("Cannot get field 'longValue' because union is currently set to " + getFieldDesc(getSetField()).name);
+    }
+  }
+
+  public void setLongValue(long value) {
+    setField_ = _Fields.LONG_VALUE;
+    value_ = value;
+  }
+
+  public String getStringValue() {
+    if (getSetField() == _Fields.STRING_VALUE) {
+      return (String)getFieldValue();
+    } else {
+      throw new RuntimeException("Cannot get field 'stringValue' because union is currently set to " + getFieldDesc(getSetField()).name);
+    }
+  }
+
+  public void setStringValue(String value) {
+    if (value == null) throw new NullPointerException();
+    setField_ = _Fields.STRING_VALUE;
+    value_ = value;
+  }
+
+  public double getDoubleValue() {
+    if (getSetField() == _Fields.DOUBLE_VALUE) {
+      return (Double)getFieldValue();
+    } else {
+      throw new RuntimeException("Cannot get field 'doubleValue' because union is currently set to " + getFieldDesc(getSetField()).name);
+    }
+  }
+
+  public void setDoubleValue(double value) {
+    setField_ = _Fields.DOUBLE_VALUE;
+    value_ = value;
+  }
+
+  public boolean getFlag() {
+    if (getSetField() == _Fields.FLAG) {
+      return (Boolean)getFieldValue();
+    } else {
+      throw new RuntimeException("Cannot get field 'flag' because union is currently set to " + getFieldDesc(getSetField()).name);
+    }
+  }
+
+  public void setFlag(boolean value) {
+    setField_ = _Fields.FLAG;
+    value_ = value;
+  }
+
+  public List<String> getLString() {
+    if (getSetField() == _Fields.L_STRING) {
+      return (List<String>)getFieldValue();
+    } else {
+      throw new RuntimeException("Cannot get field 'lString' because union is currently set to " + getFieldDesc(getSetField()).name);
+    }
+  }
+
+  public void setLString(List<String> value) {
+    if (value == null) throw new NullPointerException();
+    setField_ = _Fields.L_STRING;
+    value_ = value;
+  }
+
+  public Map<String,String> getUnionMStringString() {
+    if (getSetField() == _Fields.UNION_MSTRING_STRING) {
+      return (Map<String,String>)getFieldValue();
+    } else {
+      throw new RuntimeException("Cannot get field 'unionMStringString' because union is currently set to " + getFieldDesc(getSetField()).name);
+    }
+  }
+
+  public void setUnionMStringString(Map<String,String> value) {
+    if (value == null) throw new NullPointerException();
+    setField_ = _Fields.UNION_MSTRING_STRING;
+    value_ = value;
+  }
+
+  public boolean isSetIntValue() {
+    return setField_ == _Fields.INT_VALUE;
+  }
+
+
+  public boolean isSetLongValue() {
+    return setField_ == _Fields.LONG_VALUE;
+  }
+
+
+  public boolean isSetStringValue() {
+    return setField_ == _Fields.STRING_VALUE;
+  }
+
+
+  public boolean isSetDoubleValue() {
+    return setField_ == _Fields.DOUBLE_VALUE;
+  }
+
+
+  public boolean isSetFlag() {
+    return setField_ == _Fields.FLAG;
+  }
+
+
+  public boolean isSetLString() {
+    return setField_ == _Fields.L_STRING;
+  }
+
+
+  public boolean isSetUnionMStringString() {
+    return setField_ == _Fields.UNION_MSTRING_STRING;
+  }
+
+
+  public boolean equals(Object other) {
+    if (other instanceof PropValueUnion) {
+      return equals((PropValueUnion)other);
+    } else {
+      return false;
+    }
+  }
+
+  public boolean equals(PropValueUnion other) {
+    return other != null && getSetField() == other.getSetField() && getFieldValue().equals(other.getFieldValue());
+  }
+
+  @Override
+  public int compareTo(PropValueUnion other) {
+    int lastComparison = org.apache.thrift.TBaseHelper.compareTo(getSetField(), other.getSetField());
+    if (lastComparison == 0) {
+      return org.apache.thrift.TBaseHelper.compareTo(getFieldValue(), other.getFieldValue());
+    }
+    return lastComparison;
+  }
+
+
+  @Override
+  public int hashCode() {
+    HashCodeBuilder hcb = new HashCodeBuilder();
+    hcb.append(this.getClass().getName());
+    org.apache.thrift.TFieldIdEnum setField = getSetField();
+    if (setField != null) {
+      hcb.append(setField.getThriftFieldId());
+      Object value = getFieldValue();
+      if (value instanceof org.apache.thrift.TEnum) {
+        hcb.append(((org.apache.thrift.TEnum)getFieldValue()).getValue());
+      } else {
+        hcb.append(value);
+      }
+    }
+    return hcb.toHashCode();
+  }
+  private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
+    try {
+      write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
+    } catch (org.apache.thrift.TException te) {
+      throw new java.io.IOException(te);
+    }
+  }
+
+
+  private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
+    try {
+      read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
+    } catch (org.apache.thrift.TException te) {
+      throw new java.io.IOException(te);
+    }
+  }
+
+
+}
diff --git a/serde/src/gen/thrift/gen-py/complex/ttypes.py b/serde/src/gen/thrift/gen-py/complex/ttypes.py
index 7283e4c53b..3bc7a6ffd0 100644
--- a/serde/src/gen/thrift/gen-py/complex/ttypes.py
+++ b/serde/src/gen/thrift/gen-py/complex/ttypes.py
@@ -17,6 +17,156 @@
 
 
 
+class PropValueUnion:
+  """
+  Attributes:
+   - intValue
+   - longValue
+   - stringValue
+   - doubleValue
+   - flag
+   - lString
+   - unionMStringString
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.I32, 'intValue', None, None, ), # 1
+    (2, TType.I64, 'longValue', None, None, ), # 2
+    (3, TType.STRING, 'stringValue', None, None, ), # 3
+    (4, TType.DOUBLE, 'doubleValue', None, None, ), # 4
+    (5, TType.BOOL, 'flag', None, None, ), # 5
+    (6, TType.LIST, 'lString', (TType.STRING,None), None, ), # 6
+    (7, TType.MAP, 'unionMStringString', (TType.STRING,None,TType.STRING,None), None, ), # 7
+  )
+
+  def __init__(self, intValue=None, longValue=None, stringValue=None, doubleValue=None, flag=None, lString=None, unionMStringString=None,):
+    self.intValue = intValue
+    self.longValue = longValue
+    self.stringValue = stringValue
+    self.doubleValue = doubleValue
+    self.flag = flag
+    self.lString = lString
+    self.unionMStringString = unionMStringString
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.I32:
+          self.intValue = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.I64:
+          self.longValue = iprot.readI64();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRING:
+          self.stringValue = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.DOUBLE:
+          self.doubleValue = iprot.readDouble();
+        else:
+          iprot.skip(ftype)
+      elif fid == 5:
+        if ftype == TType.BOOL:
+          self.flag = iprot.readBool();
+        else:
+          iprot.skip(ftype)
+      elif fid == 6:
+        if ftype == TType.LIST:
+          self.lString = []
+          (_etype3, _size0) = iprot.readListBegin()
+          for _i4 in xrange(_size0):
+            _elem5 = iprot.readString();
+            self.lString.append(_elem5)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 7:
+        if ftype == TType.MAP:
+          self.unionMStringString = {}
+          (_ktype7, _vtype8, _size6 ) = iprot.readMapBegin() 
+          for _i10 in xrange(_size6):
+            _key11 = iprot.readString();
+            _val12 = iprot.readString();
+            self.unionMStringString[_key11] = _val12
+          iprot.readMapEnd()
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('PropValueUnion')
+    if self.intValue is not None:
+      oprot.writeFieldBegin('intValue', TType.I32, 1)
+      oprot.writeI32(self.intValue)
+      oprot.writeFieldEnd()
+    if self.longValue is not None:
+      oprot.writeFieldBegin('longValue', TType.I64, 2)
+      oprot.writeI64(self.longValue)
+      oprot.writeFieldEnd()
+    if self.stringValue is not None:
+      oprot.writeFieldBegin('stringValue', TType.STRING, 3)
+      oprot.writeString(self.stringValue)
+      oprot.writeFieldEnd()
+    if self.doubleValue is not None:
+      oprot.writeFieldBegin('doubleValue', TType.DOUBLE, 4)
+      oprot.writeDouble(self.doubleValue)
+      oprot.writeFieldEnd()
+    if self.flag is not None:
+      oprot.writeFieldBegin('flag', TType.BOOL, 5)
+      oprot.writeBool(self.flag)
+      oprot.writeFieldEnd()
+    if self.lString is not None:
+      oprot.writeFieldBegin('lString', TType.LIST, 6)
+      oprot.writeListBegin(TType.STRING, len(self.lString))
+      for iter13 in self.lString:
+        oprot.writeString(iter13)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.unionMStringString is not None:
+      oprot.writeFieldBegin('unionMStringString', TType.MAP, 7)
+      oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.unionMStringString))
+      for kiter14,viter15 in self.unionMStringString.items():
+        oprot.writeString(kiter14)
+        oprot.writeString(viter15)
+      oprot.writeMapEnd()
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+
+  def validate(self):
+    return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
 class IntString:
   """
   Attributes:
@@ -110,6 +260,10 @@ class Complex:
    - lString
    - lintString
    - mStringString
+   - attributes
+   - unionField1
+   - unionField2
+   - unionField3
   """
 
   thrift_spec = (
@@ -120,15 +274,23 @@ class Complex:
     (4, TType.LIST, 'lString', (TType.STRING,None), None, ), # 4
     (5, TType.LIST, 'lintString', (TType.STRUCT,(IntString, IntString.thrift_spec)), None, ), # 5
     (6, TType.MAP, 'mStringString', (TType.STRING,None,TType.STRING,None), None, ), # 6
+    (7, TType.MAP, 'attributes', (TType.STRING,None,TType.MAP,(TType.STRING,None,TType.MAP,(TType.STRING,None,TType.STRUCT,(PropValueUnion, PropValueUnion.thrift_spec)))), None, ), # 7
+    (8, TType.STRUCT, 'unionField1', (PropValueUnion, PropValueUnion.thrift_spec), None, ), # 8
+    (9, TType.STRUCT, 'unionField2', (PropValueUnion, PropValueUnion.thrift_spec), None, ), # 9
+    (10, TType.STRUCT, 'unionField3', (PropValueUnion, PropValueUnion.thrift_spec), None, ), # 10
   )
 
-  def __init__(self, aint=None, aString=None, lint=None, lString=None, lintString=None, mStringString=None,):
+  def __init__(self, aint=None, aString=None, lint=None, lString=None, lintString=None, mStringString=None, attributes=None, unionField1=None, unionField2=None, unionField3=None,):
     self.aint = aint
     self.aString = aString
     self.lint = lint
     self.lString = lString
     self.lintString = lintString
     self.mStringString = mStringString
+    self.attributes = attributes
+    self.unionField1 = unionField1
+    self.unionField2 = unionField2
+    self.unionField3 = unionField3
 
   def read(self, iprot):
     if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
@@ -152,45 +314,87 @@ def read(self, iprot):
       elif fid == 3:
         if ftype == TType.LIST:
           self.lint = []
-          (_etype3, _size0) = iprot.readListBegin()
-          for _i4 in xrange(_size0):
-            _elem5 = iprot.readI32();
-            self.lint.append(_elem5)
+          (_etype19, _size16) = iprot.readListBegin()
+          for _i20 in xrange(_size16):
+            _elem21 = iprot.readI32();
+            self.lint.append(_elem21)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
       elif fid == 4:
         if ftype == TType.LIST:
           self.lString = []
-          (_etype9, _size6) = iprot.readListBegin()
-          for _i10 in xrange(_size6):
-            _elem11 = iprot.readString();
-            self.lString.append(_elem11)
+          (_etype25, _size22) = iprot.readListBegin()
+          for _i26 in xrange(_size22):
+            _elem27 = iprot.readString();
+            self.lString.append(_elem27)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
       elif fid == 5:
         if ftype == TType.LIST:
           self.lintString = []
-          (_etype15, _size12) = iprot.readListBegin()
-          for _i16 in xrange(_size12):
-            _elem17 = IntString()
-            _elem17.read(iprot)
-            self.lintString.append(_elem17)
+          (_etype31, _size28) = iprot.readListBegin()
+          for _i32 in xrange(_size28):
+            _elem33 = IntString()
+            _elem33.read(iprot)
+            self.lintString.append(_elem33)
           iprot.readListEnd()
         else:
           iprot.skip(ftype)
       elif fid == 6:
         if ftype == TType.MAP:
           self.mStringString = {}
-          (_ktype19, _vtype20, _size18 ) = iprot.readMapBegin() 
-          for _i22 in xrange(_size18):
-            _key23 = iprot.readString();
-            _val24 = iprot.readString();
-            self.mStringString[_key23] = _val24
+          (_ktype35, _vtype36, _size34 ) = iprot.readMapBegin() 
+          for _i38 in xrange(_size34):
+            _key39 = iprot.readString();
+            _val40 = iprot.readString();
+            self.mStringString[_key39] = _val40
+          iprot.readMapEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 7:
+        if ftype == TType.MAP:
+          self.attributes = {}
+          (_ktype42, _vtype43, _size41 ) = iprot.readMapBegin() 
+          for _i45 in xrange(_size41):
+            _key46 = iprot.readString();
+            _val47 = {}
+            (_ktype49, _vtype50, _size48 ) = iprot.readMapBegin() 
+            for _i52 in xrange(_size48):
+              _key53 = iprot.readString();
+              _val54 = {}
+              (_ktype56, _vtype57, _size55 ) = iprot.readMapBegin() 
+              for _i59 in xrange(_size55):
+                _key60 = iprot.readString();
+                _val61 = PropValueUnion()
+                _val61.read(iprot)
+                _val54[_key60] = _val61
+              iprot.readMapEnd()
+              _val47[_key53] = _val54
+            iprot.readMapEnd()
+            self.attributes[_key46] = _val47
           iprot.readMapEnd()
         else:
           iprot.skip(ftype)
+      elif fid == 8:
+        if ftype == TType.STRUCT:
+          self.unionField1 = PropValueUnion()
+          self.unionField1.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 9:
+        if ftype == TType.STRUCT:
+          self.unionField2 = PropValueUnion()
+          self.unionField2.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 10:
+        if ftype == TType.STRUCT:
+          self.unionField3 = PropValueUnion()
+          self.unionField3.read(iprot)
+        else:
+          iprot.skip(ftype)
       else:
         iprot.skip(ftype)
       iprot.readFieldEnd()
@@ -212,32 +416,60 @@ def write(self, oprot):
     if self.lint is not None:
       oprot.writeFieldBegin('lint', TType.LIST, 3)
       oprot.writeListBegin(TType.I32, len(self.lint))
-      for iter25 in self.lint:
-        oprot.writeI32(iter25)
+      for iter62 in self.lint:
+        oprot.writeI32(iter62)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.lString is not None:
       oprot.writeFieldBegin('lString', TType.LIST, 4)
       oprot.writeListBegin(TType.STRING, len(self.lString))
-      for iter26 in self.lString:
-        oprot.writeString(iter26)
+      for iter63 in self.lString:
+        oprot.writeString(iter63)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.lintString is not None:
       oprot.writeFieldBegin('lintString', TType.LIST, 5)
       oprot.writeListBegin(TType.STRUCT, len(self.lintString))
-      for iter27 in self.lintString:
-        iter27.write(oprot)
+      for iter64 in self.lintString:
+        iter64.write(oprot)
       oprot.writeListEnd()
       oprot.writeFieldEnd()
     if self.mStringString is not None:
       oprot.writeFieldBegin('mStringString', TType.MAP, 6)
       oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.mStringString))
-      for kiter28,viter29 in self.mStringString.items():
-        oprot.writeString(kiter28)
-        oprot.writeString(viter29)
+      for kiter65,viter66 in self.mStringString.items():
+        oprot.writeString(kiter65)
+        oprot.writeString(viter66)
+      oprot.writeMapEnd()
+      oprot.writeFieldEnd()
+    if self.attributes is not None:
+      oprot.writeFieldBegin('attributes', TType.MAP, 7)
+      oprot.writeMapBegin(TType.STRING, TType.MAP, len(self.attributes))
+      for kiter67,viter68 in self.attributes.items():
+        oprot.writeString(kiter67)
+        oprot.writeMapBegin(TType.STRING, TType.MAP, len(viter68))
+        for kiter69,viter70 in viter68.items():
+          oprot.writeString(kiter69)
+          oprot.writeMapBegin(TType.STRING, TType.STRUCT, len(viter70))
+          for kiter71,viter72 in viter70.items():
+            oprot.writeString(kiter71)
+            viter72.write(oprot)
+          oprot.writeMapEnd()
+        oprot.writeMapEnd()
       oprot.writeMapEnd()
       oprot.writeFieldEnd()
+    if self.unionField1 is not None:
+      oprot.writeFieldBegin('unionField1', TType.STRUCT, 8)
+      self.unionField1.write(oprot)
+      oprot.writeFieldEnd()
+    if self.unionField2 is not None:
+      oprot.writeFieldBegin('unionField2', TType.STRUCT, 9)
+      self.unionField2.write(oprot)
+      oprot.writeFieldEnd()
+    if self.unionField3 is not None:
+      oprot.writeFieldBegin('unionField3', TType.STRUCT, 10)
+      self.unionField3.write(oprot)
+      oprot.writeFieldEnd()
     oprot.writeFieldStop()
     oprot.writeStructEnd()
 
diff --git a/serde/src/gen/thrift/gen-rb/complex_types.rb b/serde/src/gen/thrift/gen-rb/complex_types.rb
index 5527096383..2c91cbc5fa 100644
--- a/serde/src/gen/thrift/gen-rb/complex_types.rb
+++ b/serde/src/gen/thrift/gen-rb/complex_types.rb
@@ -6,6 +6,65 @@
 
 require 'thrift'
 
+class PropValueUnion < ::Thrift::Union
+  include ::Thrift::Struct_Union
+  class << self
+    def intValue(val)
+      PropValueUnion.new(:intValue, val)
+    end
+
+    def longValue(val)
+      PropValueUnion.new(:longValue, val)
+    end
+
+    def stringValue(val)
+      PropValueUnion.new(:stringValue, val)
+    end
+
+    def doubleValue(val)
+      PropValueUnion.new(:doubleValue, val)
+    end
+
+    def flag(val)
+      PropValueUnion.new(:flag, val)
+    end
+
+    def lString(val)
+      PropValueUnion.new(:lString, val)
+    end
+
+    def unionMStringString(val)
+      PropValueUnion.new(:unionMStringString, val)
+    end
+  end
+
+  INTVALUE = 1
+  LONGVALUE = 2
+  STRINGVALUE = 3
+  DOUBLEVALUE = 4
+  FLAG = 5
+  LSTRING = 6
+  UNIONMSTRINGSTRING = 7
+
+  FIELDS = {
+    INTVALUE => {:type => ::Thrift::Types::I32, :name => 'intValue', :optional => true},
+    LONGVALUE => {:type => ::Thrift::Types::I64, :name => 'longValue', :optional => true},
+    STRINGVALUE => {:type => ::Thrift::Types::STRING, :name => 'stringValue', :optional => true},
+    DOUBLEVALUE => {:type => ::Thrift::Types::DOUBLE, :name => 'doubleValue', :optional => true},
+    FLAG => {:type => ::Thrift::Types::BOOL, :name => 'flag', :optional => true},
+    LSTRING => {:type => ::Thrift::Types::LIST, :name => 'lString', :element => {:type => ::Thrift::Types::STRING}},
+    UNIONMSTRINGSTRING => {:type => ::Thrift::Types::MAP, :name => 'unionMStringString', :key => {:type => ::Thrift::Types::STRING}, :value => {:type => ::Thrift::Types::STRING}}
+  }
+
+  def struct_fields; FIELDS; end
+
+  def validate
+    raise(StandardError, 'Union fields are not set.') if get_set_field.nil? || get_value.nil?
+  end
+
+  ::Thrift::Union.generate_accessors self
+end
+
 class IntString
   include ::Thrift::Struct, ::Thrift::Struct_Union
   MYINT = 1
@@ -34,6 +93,10 @@ class Complex
   LSTRING = 4
   LINTSTRING = 5
   MSTRINGSTRING = 6
+  ATTRIBUTES = 7
+  UNIONFIELD1 = 8
+  UNIONFIELD2 = 9
+  UNIONFIELD3 = 10
 
   FIELDS = {
     AINT => {:type => ::Thrift::Types::I32, :name => 'aint'},
@@ -41,7 +104,11 @@ class Complex
     LINT => {:type => ::Thrift::Types::LIST, :name => 'lint', :element => {:type => ::Thrift::Types::I32}},
     LSTRING => {:type => ::Thrift::Types::LIST, :name => 'lString', :element => {:type => ::Thrift::Types::STRING}},
     LINTSTRING => {:type => ::Thrift::Types::LIST, :name => 'lintString', :element => {:type => ::Thrift::Types::STRUCT, :class => ::IntString}},
-    MSTRINGSTRING => {:type => ::Thrift::Types::MAP, :name => 'mStringString', :key => {:type => ::Thrift::Types::STRING}, :value => {:type => ::Thrift::Types::STRING}}
+    MSTRINGSTRING => {:type => ::Thrift::Types::MAP, :name => 'mStringString', :key => {:type => ::Thrift::Types::STRING}, :value => {:type => ::Thrift::Types::STRING}},
+    ATTRIBUTES => {:type => ::Thrift::Types::MAP, :name => 'attributes', :key => {:type => ::Thrift::Types::STRING}, :value => {:type => ::Thrift::Types::MAP, :key => {:type => ::Thrift::Types::STRING}, :value => {:type => ::Thrift::Types::MAP, :key => {:type => ::Thrift::Types::STRING}, :value => {:type => ::Thrift::Types::STRUCT, :class => ::PropValueUnion}}}},
+    UNIONFIELD1 => {:type => ::Thrift::Types::STRUCT, :name => 'unionField1', :class => ::PropValueUnion},
+    UNIONFIELD2 => {:type => ::Thrift::Types::STRUCT, :name => 'unionField2', :class => ::PropValueUnion},
+    UNIONFIELD3 => {:type => ::Thrift::Types::STRUCT, :name => 'unionField3', :class => ::PropValueUnion}
   }
 
   def struct_fields; FIELDS; end
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorFactory.java b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorFactory.java
index d8f0dfb0d0..d7affae1c7 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorFactory.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorFactory.java
@@ -31,6 +31,7 @@
 
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
 import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils;
+import org.apache.thrift.TUnion;
 
 /**
  * ObjectInspectorFactory is the primary way to create new ObjectInspector
@@ -174,7 +175,7 @@ private static ObjectInspector getReflectionObjectInspectorNoCache(Type t,
       oi = new ReflectionStructObjectInspector();
       break;
     case THRIFT:
-      oi = new ThriftStructObjectInspector();
+      oi = TUnion.class.isAssignableFrom(c) ? new ThriftUnionObjectInspector() : new ThriftStructObjectInspector();
       break;
     case PROTOCOL_BUFFERS:
       oi = new ProtocolBuffersStructObjectInspector();
@@ -183,20 +184,13 @@ private static ObjectInspector getReflectionObjectInspectorNoCache(Type t,
       throw new RuntimeException(ObjectInspectorFactory.class.getName()
           + ": internal error.");
     }
+
     // put it into the cache BEFORE it is initialized to make sure we can catch
     // recursive types.
     objectInspectorCache.put(t, oi);
-    Field[] fields = ObjectInspectorUtils.getDeclaredNonStaticFields(c);
-    ArrayList<ObjectInspector> structFieldObjectInspectors = new ArrayList<ObjectInspector>(
-        fields.length);
-    for (int i = 0; i < fields.length; i++) {
-      if (!oi.shouldIgnoreField(fields[i].getName())) {
-        structFieldObjectInspectors.add(getReflectionObjectInspector(fields[i]
-            .getGenericType(), options));
-      }
-    }
-    oi.init(c, structFieldObjectInspectors);
+    oi.init(c, options);
     return oi;
+
   }
 
   static ConcurrentHashMap<ObjectInspector, StandardListObjectInspector> cachedStandardListObjectInspector =
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ReflectionStructObjectInspector.java b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ReflectionStructObjectInspector.java
index ee5b0d0a15..78e60668d6 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ReflectionStructObjectInspector.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ReflectionStructObjectInspector.java
@@ -44,6 +44,7 @@ public class ReflectionStructObjectInspector extends
   public static class MyField implements StructField {
     protected int fieldID;
     protected Field field;
+
     protected ObjectInspector fieldObjectInspector;
 
     protected MyField() {
@@ -116,12 +117,13 @@ public String getTypeName() {
    * The reason that this method is not recursive by itself is because we want
    * to allow recursive types.
    */
-  void init(Class<?> objectClass,
-      List<ObjectInspector> structFieldObjectInspectors) {
-    assert (!List.class.isAssignableFrom(objectClass));
-    assert (!Map.class.isAssignableFrom(objectClass));
+  protected void init(Class<?> objectClass,
+      ObjectInspectorFactory.ObjectInspectorOptions options) {
 
+    verifyObjectClassType(objectClass);
     this.objectClass = objectClass;
+    final List<? extends ObjectInspector> structFieldObjectInspectors = extractFieldObjectInspectors(objectClass, options);
+
     Field[] reflectionFields = ObjectInspectorUtils
         .getDeclaredNonStaticFields(objectClass);
     fields = new ArrayList<MyField>(structFieldObjectInspectors.size());
@@ -205,4 +207,23 @@ public Object setStructFieldData(Object struct, StructField field,
     return struct;
   }
 
+  protected List<? extends ObjectInspector> extractFieldObjectInspectors(Class<?> clazz,
+    ObjectInspectorFactory.ObjectInspectorOptions options) {
+    Field[] fields = ObjectInspectorUtils.getDeclaredNonStaticFields(clazz);
+    ArrayList<ObjectInspector> structFieldObjectInspectors = new ArrayList<ObjectInspector>(
+      fields.length);
+    for (int i = 0; i < fields.length; i++) {
+      if (!shouldIgnoreField(fields[i].getName())) {
+        structFieldObjectInspectors.add(ObjectInspectorFactory.getReflectionObjectInspector(fields[i]
+          .getGenericType(), options));
+      }
+    }
+    return structFieldObjectInspectors;
+  }
+
+
+  protected void verifyObjectClassType(Class<?> objectClass) {
+    assert (!List.class.isAssignableFrom(objectClass));
+    assert (!Map.class.isAssignableFrom(objectClass));
+  }
 }
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ThriftObjectInspectorUtils.java b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ThriftObjectInspectorUtils.java
new file mode 100644
index 0000000000..86ad7a529a
--- /dev/null
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ThriftObjectInspectorUtils.java
@@ -0,0 +1,64 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hive.serde2.objectinspector;
+
+
+import java.lang.reflect.Method;
+import java.lang.reflect.Type;
+
+public class ThriftObjectInspectorUtils {
+
+  /**
+   * Returns generic type for a field in a Thrift class. The type is the return
+   * type for the accessor method for the field (e.g. <code>isFieldName()</code>
+   * for a boolean type or <code>getFieldName</code> for other types). The return
+   * type works for both structs and unions. Reflecting directly based on
+   * fields does not work for unions.
+   *
+   * @return generic {@link Type} of the thrift field.
+   */
+  public static Type getFieldType(Class<?> containingClass, String fieldName) {
+
+    String suffix = // uppercase first letter
+      fieldName.substring(0, 1).toUpperCase() + fieldName.substring(1);
+
+    // look for getFieldName() or isFieldName()
+
+    for(String prefix : new String[]{"get", "is"}) {
+      try {
+        Method method = containingClass.getDeclaredMethod(prefix + suffix);
+        return method.getGenericReturnType();
+      } catch (NoSuchMethodException e) {
+      }
+    }
+
+    // look for bean style accessors get_fieldName and is_fieldName
+
+    for(String prefix : new String[]{"get_", "is_"}) {
+      try {
+        Method method = containingClass.getDeclaredMethod(prefix + fieldName);
+        return method.getGenericReturnType();
+      } catch (NoSuchMethodException e) {
+      }
+    }
+
+    throw new RuntimeException("Could not find type for " + fieldName +
+                                       " in " + containingClass);
+  }
+
+}
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ThriftUnionObjectInspector.java b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ThriftUnionObjectInspector.java
new file mode 100644
index 0000000000..17add28133
--- /dev/null
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ThriftUnionObjectInspector.java
@@ -0,0 +1,121 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.serde2.objectinspector;
+
+import com.google.common.primitives.UnsignedBytes;
+import org.apache.hadoop.util.ReflectionUtils;
+import org.apache.thrift.TFieldIdEnum;
+import org.apache.thrift.TUnion;
+import org.apache.thrift.meta_data.FieldMetaData;
+
+import java.lang.reflect.Field;
+import java.lang.reflect.Type;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * Always use the ObjectInspectorFactory to create new ObjectInspector objects,
+ * instead of directly creating an instance of this class.
+ */
+public class ThriftUnionObjectInspector extends ReflectionStructObjectInspector implements UnionObjectInspector {
+
+  private static final String FIELD_METADATA_MAP = "metaDataMap";
+  private  List<ObjectInspector> ois;
+
+  @Override
+  public boolean shouldIgnoreField(String name) {
+    return name.startsWith("__isset");
+  }
+
+  @Override
+  public List<ObjectInspector> getObjectInspectors() {
+    return ois;
+  }
+
+  @Override
+  public byte getTag(final Object o) {
+    if (o == null) {
+      return -1;
+    }
+    final TFieldIdEnum setField = ((TUnion<? extends TUnion<?, ?>, ? extends TFieldIdEnum>) o).getSetField();
+    return UnsignedBytes.checkedCast((setField.getThriftFieldId() - 1));
+  }
+
+  @Override
+  public Object getField(final Object o) {
+    if (o == null) {
+      return null;
+    }
+    return ((TUnion<? extends TUnion<?, ?>, ? extends TFieldIdEnum>) o).getFieldValue();
+  }
+
+  /**
+   * This method is only intended to be used by Utilities class in this package.
+   * The reason that this method is not recursive by itself is because we want
+   * to allow recursive types.
+   */
+  @Override
+  protected void init(Class<?> objectClass,
+                      ObjectInspectorFactory.ObjectInspectorOptions options) {
+    verifyObjectClassType(objectClass);
+    this.objectClass = objectClass;
+    final Field fieldMetaData;
+
+    try {
+      fieldMetaData = objectClass.getDeclaredField(FIELD_METADATA_MAP);
+      assert(Map.class.isAssignableFrom(fieldMetaData.getType()));
+      fieldMetaData.setAccessible(true);
+    } catch (NoSuchFieldException e) {
+      throw new RuntimeException("Unable to find field metadata for thrift union field " , e);
+    }
+
+    try {
+      final Map<? extends TFieldIdEnum, FieldMetaData> fieldMap = (Map<? extends TFieldIdEnum, FieldMetaData>) fieldMetaData.get(null);
+      this.ois = new ArrayList<ObjectInspector>();
+      for(Map.Entry<? extends TFieldIdEnum, FieldMetaData> metadata : fieldMap.entrySet()) {
+        final Type fieldType = ThriftObjectInspectorUtils.getFieldType(objectClass, metadata.getValue().fieldName);
+        final ObjectInspector reflectionObjectInspector = ObjectInspectorFactory.getReflectionObjectInspector(fieldType, options);
+        this.ois.add(reflectionObjectInspector);
+      }
+    } catch (IllegalAccessException e) {
+      throw new RuntimeException("Unable to find field metadata for thrift union field ", e);
+    }
+  }
+
+  @Override
+  public Category getCategory() {
+    return Category.UNION;
+  }
+
+  @Override
+  public List<? extends StructField> getAllStructFieldRefs() {
+    return fields;
+  }
+
+  public String getTypeName() {
+    return ObjectInspectorUtils.getStandardUnionTypeName(this);
+  }
+
+  @Override
+  public Object create() {
+    return ReflectionUtils.newInstance(objectClass, null);
+  }
+}
+
diff --git a/serde/src/test/org/apache/hadoop/hive/serde2/objectinspector/TestObjectInspectorUtils.java b/serde/src/test/org/apache/hadoop/hive/serde2/objectinspector/TestObjectInspectorUtils.java
index a18f4a753b..f3fd6fa50f 100644
--- a/serde/src/test/org/apache/hadoop/hive/serde2/objectinspector/TestObjectInspectorUtils.java
+++ b/serde/src/test/org/apache/hadoop/hive/serde2/objectinspector/TestObjectInspectorUtils.java
@@ -46,7 +46,7 @@ public void testObjectInspectorUtils() throws Throwable {
       StructObjectInspector soi = (StructObjectInspector) ObjectInspectorUtils
           .getStandardObjectInspector(oi1);
       List<? extends StructField> fields = soi.getAllStructFieldRefs();
-      assertEquals(6, fields.size());
+      assertEquals(10, fields.size());
       assertEquals(fields.get(0), soi.getStructFieldRef("aint"));
 
       // null
@@ -75,7 +75,7 @@ public void testObjectInspectorUtils() throws Throwable {
       assertEquals(c4, soi.getStructFieldData(c, fields.get(4)));
       assertNull(soi.getStructFieldData(c, fields.get(5)));
       ArrayList<Object> cfields = new ArrayList<Object>();
-      for (int i = 0; i < 6; i++) {
+      for (int i = 0; i < 10; i++) {
         cfields.add(soi.getStructFieldData(c, fields.get(i)));
       }
       assertEquals(cfields, soi.getStructFieldsDataAsList(c));
diff --git a/serde/src/test/org/apache/hadoop/hive/serde2/objectinspector/TestThriftObjectInspectors.java b/serde/src/test/org/apache/hadoop/hive/serde2/objectinspector/TestThriftObjectInspectors.java
index e3b306dc6f..968cd2287e 100644
--- a/serde/src/test/org/apache/hadoop/hive/serde2/objectinspector/TestThriftObjectInspectors.java
+++ b/serde/src/test/org/apache/hadoop/hive/serde2/objectinspector/TestThriftObjectInspectors.java
@@ -52,7 +52,7 @@ public void testThriftObjectInspectors() throws Throwable {
       assertEquals(Category.STRUCT, oi1.getCategory());
       StructObjectInspector soi = (StructObjectInspector) oi1;
       List<? extends StructField> fields = soi.getAllStructFieldRefs();
-      assertEquals(6, fields.size());
+      assertEquals(10, fields.size());
       assertEquals(fields.get(0), soi.getStructFieldRef("aint"));
 
       // null
@@ -71,6 +71,10 @@ public void testThriftObjectInspectors() throws Throwable {
       List<IntString> c4 = new ArrayList<IntString>();
       c.setLintString(c4);
       c.setMStringString(null);
+      c.setAttributes(null);
+      c.setUnionField1(null);
+      c.setUnionField2(null);
+      c.setUnionField3(null);
 
       assertEquals(1, soi.getStructFieldData(c, fields.get(0)));
       assertEquals("test", soi.getStructFieldData(c, fields.get(1)));
@@ -78,8 +82,13 @@ public void testThriftObjectInspectors() throws Throwable {
       assertEquals(c3, soi.getStructFieldData(c, fields.get(3)));
       assertEquals(c4, soi.getStructFieldData(c, fields.get(4)));
       assertNull(soi.getStructFieldData(c, fields.get(5)));
+      assertNull(soi.getStructFieldData(c, fields.get(6)));
+      assertNull(soi.getStructFieldData(c, fields.get(7)));
+      assertNull(soi.getStructFieldData(c, fields.get(8)));
+      assertNull(soi.getStructFieldData(c, fields.get(9)));
+
       ArrayList<Object> cfields = new ArrayList<Object>();
-      for (int i = 0; i < 6; i++) {
+      for (int i = 0; i < 10; i++) {
         cfields.add(soi.getStructFieldData(c, fields.get(i)));
       }
       assertEquals(cfields, soi.getStructFieldsDataAsList(c));
diff --git a/serde/src/test/org/apache/hadoop/hive/serde2/thrift_test/CreateSequenceFile.java b/serde/src/test/org/apache/hadoop/hive/serde2/thrift_test/CreateSequenceFile.java
index 7269cd0638..53c98226f9 100644
--- a/serde/src/test/org/apache/hadoop/hive/serde2/thrift_test/CreateSequenceFile.java
+++ b/serde/src/test/org/apache/hadoop/hive/serde2/thrift_test/CreateSequenceFile.java
@@ -19,6 +19,7 @@
 package org.apache.hadoop.hive.serde2.thrift_test;
 
 import java.util.ArrayList;
+import java.util.Map;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Random;
@@ -28,6 +29,7 @@
 import org.apache.hadoop.hive.serde2.ByteStream;
 import org.apache.hadoop.hive.serde2.thrift.test.Complex;
 import org.apache.hadoop.hive.serde2.thrift.test.IntString;
+import org.apache.hadoop.hive.serde2.thrift.test.PropValueUnion;
 import org.apache.hadoop.io.BytesWritable;
 import org.apache.hadoop.io.SequenceFile;
 import org.apache.hadoop.io.Writable;
@@ -125,16 +127,23 @@ conf, new Path(extraArgs.get(0)), BytesWritable.class,
       islist.add(new IntString(i * i, "" + i * i * i, i));
       HashMap<String, String> hash = new HashMap<String, String>();
       hash.put("key_" + i, "value_" + i);
+      Map<String, Map<String, Map<String,PropValueUnion>>> unionMap = new HashMap<String, Map<String, Map<String,PropValueUnion>>>();
+      Map<String, Map<String, PropValueUnion>> erMap = new HashMap<String, Map<String, PropValueUnion>>();
+      Map<String, PropValueUnion> attrMap = new HashMap<String, PropValueUnion>();
+
+      erMap.put("erVal" + i, attrMap);
+      attrMap.put("value_" + i, PropValueUnion.doubleValue(1.0));
+      unionMap.put("key_" + i,  erMap);
 
       Complex complex = new Complex(rand.nextInt(), "record_"
-          + (new Integer(i)).toString(), alist, slist, islist, hash);
+          + (new Integer(i)).toString(), alist, slist, islist, hash, unionMap, PropValueUnion.stringValue("test" + i), PropValueUnion.unionMStringString(hash), PropValueUnion.lString(slist));
 
       Writable value = serializer.serialize(complex);
       writer.append(key, value);
     }
 
     // Add an all-null record
-    Complex complex = new Complex(0, null, null, null, null, null);
+    Complex complex = new Complex(0, null, null, null, null, null, null, null, null, null);
     Writable value = serializer.serialize(complex);
     writer.append(key, value);
 
