diff --git a/itests/qtest/pom.xml b/itests/qtest/pom.xml
index 7d4072ad24..0fe3028596 100644
--- a/itests/qtest/pom.xml
+++ b/itests/qtest/pom.xml
@@ -39,7 +39,7 @@
     <minimr.query.files>stats_counter_partitioned.q,list_bucket_dml_10.q,input16_cc.q,scriptfile1.q,scriptfile1_win.q,bucket4.q,bucketmapjoin6.q,disable_merge_for_bucketing.q,reduce_deduplicate.q,smb_mapjoin_8.q,join1.q,groupby2.q,bucketizedhiveinputformat.q,bucketmapjoin7.q,optrstat_groupby.q,bucket_num_reducers.q,bucket5.q,load_fs2.q,bucket_num_reducers2.q,infer_bucket_sort_merge.q,infer_bucket_sort_reducers_power_two.q,infer_bucket_sort_dyn_part.q,infer_bucket_sort_bucketed_table.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_num_buckets.q,leftsemijoin_mr.q,schemeAuthority.q,schemeAuthority2.q,truncate_column_buckets.q,remote_script.q,,load_hdfs_file_with_space_in_the_name.q,parallel_orderby.q,import_exported_table.q,stats_counter.q</minimr.query.files>
     <minimr.query.negative.files>cluster_tasklog_retrieval.q,minimr_broken_pipe.q,mapreduce_stack_trace.q,mapreduce_stack_trace_turnoff.q,mapreduce_stack_trace_hadoop20.q,mapreduce_stack_trace_turnoff_hadoop20.q</minimr.query.negative.files>
     <minitez.query.files>tez_join_tests.q,tez_joins_explain.q,mrr.q,tez_dml.q,tez_insert_overwrite_local_directory_1.q</minitez.query.files>
-    <minitez.query.files.shared>join0.q,join1.q,auto_join0.q,auto_join1.q,bucket2.q,bucket3.q,bucket4.q,count.q,create_merge_compressed.q,cross_join.q,ctas.q,custom_input_output_format.q</minitez.query.files.shared>
+    <minitez.query.files.shared>join0.q,join1.q,auto_join0.q,auto_join1.q,bucket2.q,bucket3.q,bucket4.q,count.q,create_merge_compressed.q,cross_join.q,ctas.q,custom_input_output_format.q,disable_merge_for_bucketing.q,enforce_order.q,fileformat_mix.q,filter_join_breaktask.q,filter_join_breaktask2.q,groupby1.q,groupby2.q,groupby3.q,having.q,insert1.q,insert_into1.q,insert_into2.q,leftsemijoin.q,limit_pushdown.q</minitez.query.files.shared>
     <beeline.positive.exclude>add_part_exist.q,alter1.q,alter2.q,alter4.q,alter5.q,alter_rename_partition.q,alter_rename_partition_authorization.q,archive.q,archive_corrupt.q,archive_multi.q,archive_mr_1806.q,archive_multi_mr_1806.q,authorization_1.q,authorization_2.q,authorization_4.q,authorization_5.q,authorization_6.q,authorization_7.q,ba_table1.q,ba_table2.q,ba_table3.q,ba_table_udfs.q,binary_table_bincolserde.q,binary_table_colserde.q,cluster.q,columnarserde_create_shortcut.q,combine2.q,constant_prop.q,create_nested_type.q,create_or_replace_view.q,create_struct_table.q,create_union_table.q,database.q,database_location.q,database_properties.q,ddltime.q,describe_database_json.q,drop_database_removes_partition_dirs.q,escape1.q,escape2.q,exim_00_nonpart_empty.q,exim_01_nonpart.q,exim_02_00_part_empty.q,exim_02_part.q,exim_03_nonpart_over_compat.q,exim_04_all_part.q,exim_04_evolved_parts.q,exim_05_some_part.q,exim_06_one_part.q,exim_07_all_part_over_nonoverlap.q,exim_08_nonpart_rename.q,exim_09_part_spec_nonoverlap.q,exim_10_external_managed.q,exim_11_managed_external.q,exim_12_external_location.q,exim_13_managed_location.q,exim_14_managed_location_over_existing.q,exim_15_external_part.q,exim_16_part_external.q,exim_17_part_managed.q,exim_18_part_external.q,exim_19_00_part_external_location.q,exim_19_part_external_location.q,exim_20_part_managed_location.q,exim_21_export_authsuccess.q,exim_22_import_exist_authsuccess.q,exim_23_import_part_authsuccess.q,exim_24_import_nonexist_authsuccess.q,global_limit.q,groupby_complex_types.q,groupby_complex_types_multi_single_reducer.q,index_auth.q,index_auto.q,index_auto_empty.q,index_bitmap.q,index_bitmap1.q,index_bitmap2.q,index_bitmap3.q,index_bitmap_auto.q,index_bitmap_rc.q,index_compact.q,index_compact_1.q,index_compact_2.q,index_compact_3.q,index_stale_partitioned.q,init_file.q,input16.q,input16_cc.q,input46.q,input_columnarserde.q,input_dynamicserde.q,input_lazyserde.q,input_testxpath3.q,input_testxpath4.q,insert2_overwrite_partitions.q,insertexternal1.q,join_thrift.q,lateral_view.q,load_binary_data.q,load_exist_part_authsuccess.q,load_nonpart_authsuccess.q,load_part_authsuccess.q,loadpart_err.q,lock1.q,lock2.q,lock3.q,lock4.q,merge_dynamic_partition.q,multi_insert.q,multi_insert_move_tasks_share_dependencies.q,null_column.q,ppd_clusterby.q,query_with_semi.q,rename_column.q,sample6.q,sample_islocalmode_hook.q,set_processor_namespaces.q,show_tables.q,source.q,split_sample.q,str_to_map.q,transform1.q,udaf_collect_set.q,udaf_context_ngrams.q,udaf_histogram_numeric.q,udaf_ngrams.q,udaf_percentile_approx.q,udf_array.q,udf_bitmap_and.q,udf_bitmap_or.q,udf_explode.q,udf_format_number.q,udf_map.q,udf_map_keys.q,udf_map_values.q,udf_max.q,udf_min.q,udf_named_struct.q,udf_percentile.q,udf_printf.q,udf_sentences.q,udf_sort_array.q,udf_split.q,udf_struct.q,udf_substr.q,udf_translate.q,udf_union.q,udf_xpath.q,udtf_stack.q,view.q,virtual_column.q</beeline.positive.exclude>
   </properties>
 
diff --git a/ql/src/test/results/clientpositive/tez/ctas.q.out b/ql/src/test/results/clientpositive/tez/ctas.q.out
index 15b5fc43af..aeb2083659 100644
--- a/ql/src/test/results/clientpositive/tez/ctas.q.out
+++ b/ql/src/test/results/clientpositive/tez/ctas.q.out
@@ -226,7 +226,7 @@ STAGE DEPENDENCIES:
   Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
   Stage-5
   Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
-  Stage-9 depends on stages: Stage-2, Stage-0
+  Stage-9 depends on stages: Stage-0, Stage-2
   Stage-3 depends on stages: Stage-9
   Stage-0 depends on stages: Stage-5, Stage-4, Stage-7
   Stage-4
@@ -669,7 +669,7 @@ STAGE DEPENDENCIES:
   Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
   Stage-5
   Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
-  Stage-9 depends on stages: Stage-0, Stage-2
+  Stage-9 depends on stages: Stage-2, Stage-0
   Stage-3 depends on stages: Stage-9
   Stage-0 depends on stages: Stage-5, Stage-4, Stage-7
   Stage-4
diff --git a/ql/src/test/results/clientpositive/tez/disable_merge_for_bucketing.q.out b/ql/src/test/results/clientpositive/tez/disable_merge_for_bucketing.q.out
new file mode 100644
index 0000000000..9b3f3b7f08
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/disable_merge_for_bucketing.q.out
@@ -0,0 +1,499 @@
+PREHOOK: query: CREATE TABLE bucket2_1(key int, value string) CLUSTERED BY (key) INTO 2 BUCKETS
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE bucket2_1(key int, value string) CLUSTERED BY (key) INTO 2 BUCKETS
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@bucket2_1
+PREHOOK: query: explain extended
+insert overwrite table bucket2_1
+select * from src
+PREHOOK: type: QUERY
+POSTHOOK: query: explain extended
+insert overwrite table bucket2_1
+select * from src
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME bucket2_1))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-2 depends on stages: Stage-1
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Statistics:
+                numRows: 29 dataSize: 5812 basicStatsState: COMPLETE colStatsState: NONE
+            GatherStats: false
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Statistics:
+                  numRows: 29 dataSize: 5812 basicStatsState: COMPLETE colStatsState: NONE
+              Reduce Output Operator
+                sort order: 
+                Map-reduce partition columns:
+                      expr: UDFToInteger(_col0)
+                      type: int
+                Statistics:
+                    numRows: 29 dataSize: 5812 basicStatsState: COMPLETE colStatsState: NONE
+                tag: -1
+                value expressions:
+                      expr: _col0
+                      type: string
+                      expr: _col1
+                      type: string
+      Path -> Alias:
+#### A masked pattern was here ####
+      Path -> Partition:
+#### A masked pattern was here ####
+          Partition
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              COLUMN_STATS_ACCURATE true
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+#### A masked pattern was here ####
+              name default.src
+              numFiles 1
+              numRows 0
+              rawDataSize 0
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 5812
+#### A masked pattern was here ####
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                COLUMN_STATS_ACCURATE true
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+#### A masked pattern was here ####
+                name default.src
+                numFiles 1
+                numRows 0
+                rawDataSize 0
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 5812
+#### A masked pattern was here ####
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.src
+            name: default.src
+      Truncated Path -> Alias:
+        /src [src]
+      Needs Tagging: false
+      Reduce Operator Tree:
+        Extract
+          Statistics:
+              numRows: 29 dataSize: 5812 basicStatsState: COMPLETE colStatsState: NONE
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(_col0)
+                  type: int
+                  expr: _col1
+                  type: string
+            outputColumnNames: _col0, _col1
+            Statistics:
+                numRows: 29 dataSize: 5812 basicStatsState: COMPLETE colStatsState: NONE
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+#### A masked pattern was here ####
+              NumFilesPerFileSink: 2
+              Statistics:
+                  numRows: 29 dataSize: 5812 basicStatsState: COMPLETE colStatsState: NONE
+#### A masked pattern was here ####
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  properties:
+                    bucket_count 2
+                    bucket_field_name key
+                    columns key,value
+                    columns.types int:string
+#### A masked pattern was here ####
+                    name default.bucket2_1
+                    serialization.ddl struct bucket2_1 { i32 key, string value}
+                    serialization.format 1
+                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+#### A masked pattern was here ####
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.bucket2_1
+              TotalFiles: 2
+              GatherStats: true
+              MultiFileSpray: true
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+#### A masked pattern was here ####
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count 2
+                bucket_field_name key
+                columns key,value
+                columns.types int:string
+#### A masked pattern was here ####
+                name default.bucket2_1
+                serialization.ddl struct bucket2_1 { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+#### A masked pattern was here ####
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.bucket2_1
+#### A masked pattern was here ####
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+#### A masked pattern was here ####
+
+PREHOOK: query: insert overwrite table bucket2_1
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@bucket2_1
+POSTHOOK: query: insert overwrite table bucket2_1
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@bucket2_1
+POSTHOOK: Lineage: bucket2_1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket2_1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain
+select * from bucket2_1 tablesample (bucket 1 out of 2) s order by key
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+select * from bucket2_1 tablesample (bucket 1 out of 2) s order by key
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: bucket2_1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket2_1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME bucket2_1) (TOK_TABLEBUCKETSAMPLE 1 2) s)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL key)))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        s 
+          TableScan
+            alias: s
+            Filter Operator
+              predicate:
+                  expr: (((hash(key) & 2147483647) % 2) = 0)
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: int
+                      expr: value
+                      type: string
+                outputColumnNames: _col0, _col1
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: int
+                  sort order: +
+                  tag: -1
+                  value expressions:
+                        expr: _col0
+                        type: int
+                        expr: _col1
+                        type: string
+      Reduce Operator Tree:
+        Extract
+          File Output Operator
+            compressed: false
+            GlobalTableId: 0
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+PREHOOK: query: select * from bucket2_1 tablesample (bucket 1 out of 2) s order by key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucket2_1
+#### A masked pattern was here ####
+POSTHOOK: query: select * from bucket2_1 tablesample (bucket 1 out of 2) s order by key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucket2_1
+#### A masked pattern was here ####
+POSTHOOK: Lineage: bucket2_1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket2_1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+0	val_0
+0	val_0
+0	val_0
+2	val_2
+4	val_4
+8	val_8
+10	val_10
+12	val_12
+12	val_12
+18	val_18
+18	val_18
+20	val_20
+24	val_24
+24	val_24
+26	val_26
+26	val_26
+28	val_28
+30	val_30
+34	val_34
+42	val_42
+42	val_42
+44	val_44
+54	val_54
+58	val_58
+58	val_58
+64	val_64
+66	val_66
+70	val_70
+70	val_70
+70	val_70
+72	val_72
+72	val_72
+74	val_74
+76	val_76
+76	val_76
+78	val_78
+80	val_80
+82	val_82
+84	val_84
+84	val_84
+86	val_86
+90	val_90
+90	val_90
+90	val_90
+92	val_92
+96	val_96
+98	val_98
+98	val_98
+100	val_100
+100	val_100
+104	val_104
+104	val_104
+114	val_114
+116	val_116
+118	val_118
+118	val_118
+120	val_120
+120	val_120
+126	val_126
+128	val_128
+128	val_128
+128	val_128
+134	val_134
+134	val_134
+136	val_136
+138	val_138
+138	val_138
+138	val_138
+138	val_138
+146	val_146
+146	val_146
+150	val_150
+152	val_152
+152	val_152
+156	val_156
+158	val_158
+160	val_160
+162	val_162
+164	val_164
+164	val_164
+166	val_166
+168	val_168
+170	val_170
+172	val_172
+172	val_172
+174	val_174
+174	val_174
+176	val_176
+176	val_176
+178	val_178
+180	val_180
+186	val_186
+190	val_190
+192	val_192
+194	val_194
+196	val_196
+200	val_200
+200	val_200
+202	val_202
+208	val_208
+208	val_208
+208	val_208
+214	val_214
+216	val_216
+216	val_216
+218	val_218
+222	val_222
+224	val_224
+224	val_224
+226	val_226
+228	val_228
+230	val_230
+230	val_230
+230	val_230
+230	val_230
+230	val_230
+238	val_238
+238	val_238
+242	val_242
+242	val_242
+244	val_244
+248	val_248
+252	val_252
+256	val_256
+256	val_256
+258	val_258
+260	val_260
+262	val_262
+266	val_266
+272	val_272
+272	val_272
+274	val_274
+278	val_278
+278	val_278
+280	val_280
+280	val_280
+282	val_282
+282	val_282
+284	val_284
+286	val_286
+288	val_288
+288	val_288
+292	val_292
+296	val_296
+298	val_298
+298	val_298
+298	val_298
+302	val_302
+306	val_306
+308	val_308
+310	val_310
+316	val_316
+316	val_316
+316	val_316
+318	val_318
+318	val_318
+318	val_318
+322	val_322
+322	val_322
+332	val_332
+336	val_336
+338	val_338
+342	val_342
+342	val_342
+344	val_344
+344	val_344
+348	val_348
+348	val_348
+348	val_348
+348	val_348
+348	val_348
+356	val_356
+360	val_360
+362	val_362
+364	val_364
+366	val_366
+368	val_368
+374	val_374
+378	val_378
+382	val_382
+382	val_382
+384	val_384
+384	val_384
+384	val_384
+386	val_386
+392	val_392
+394	val_394
+396	val_396
+396	val_396
+396	val_396
+400	val_400
+402	val_402
+404	val_404
+404	val_404
+406	val_406
+406	val_406
+406	val_406
+406	val_406
+414	val_414
+414	val_414
+418	val_418
+424	val_424
+424	val_424
+430	val_430
+430	val_430
+430	val_430
+432	val_432
+436	val_436
+438	val_438
+438	val_438
+438	val_438
+444	val_444
+446	val_446
+448	val_448
+452	val_452
+454	val_454
+454	val_454
+454	val_454
+458	val_458
+458	val_458
+460	val_460
+462	val_462
+462	val_462
+466	val_466
+466	val_466
+466	val_466
+468	val_468
+468	val_468
+468	val_468
+468	val_468
+470	val_470
+472	val_472
+478	val_478
+478	val_478
+480	val_480
+480	val_480
+480	val_480
+482	val_482
+484	val_484
+490	val_490
+492	val_492
+492	val_492
+494	val_494
+496	val_496
+498	val_498
+498	val_498
+498	val_498
diff --git a/ql/src/test/results/clientpositive/tez/enforce_order.q.out b/ql/src/test/results/clientpositive/tez/enforce_order.q.out
new file mode 100644
index 0000000000..e87083751a
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/enforce_order.q.out
@@ -0,0 +1,84 @@
+PREHOOK: query: drop table table_asc
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table table_asc
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: drop table table_desc
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table table_desc
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: create table table_asc(key string, value string) clustered by (key) sorted by (key ASC) into 1 BUCKETS
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table table_asc(key string, value string) clustered by (key) sorted by (key ASC) into 1 BUCKETS
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@table_asc
+PREHOOK: query: create table table_desc(key string, value string) clustered by (key) sorted by (key DESC) into 1 BUCKETS
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table table_desc(key string, value string) clustered by (key) sorted by (key DESC) into 1 BUCKETS
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@table_desc
+PREHOOK: query: insert overwrite table table_asc select key, value from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@table_asc
+POSTHOOK: query: insert overwrite table table_asc select key, value from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@table_asc
+POSTHOOK: Lineage: table_asc.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: table_asc.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: insert overwrite table table_desc select key, value from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@table_desc
+POSTHOOK: query: insert overwrite table table_desc select key, value from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@table_desc
+POSTHOOK: Lineage: table_asc.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: table_asc.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: table_desc.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: table_desc.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: select * from table_asc limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@table_asc
+#### A masked pattern was here ####
+POSTHOOK: query: select * from table_asc limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@table_asc
+#### A masked pattern was here ####
+POSTHOOK: Lineage: table_asc.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: table_asc.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: table_desc.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: table_desc.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+0	val_0
+0	val_0
+0	val_0
+10	val_10
+100	val_100
+100	val_100
+103	val_103
+103	val_103
+104	val_104
+104	val_104
+PREHOOK: query: select * from table_desc limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@table_desc
+#### A masked pattern was here ####
+POSTHOOK: query: select * from table_desc limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@table_desc
+#### A masked pattern was here ####
+POSTHOOK: Lineage: table_asc.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: table_asc.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: table_desc.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: table_desc.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+98	val_98
+98	val_98
+97	val_97
+97	val_97
+96	val_96
+95	val_95
+95	val_95
+92	val_92
+90	val_90
+90	val_90
diff --git a/ql/src/test/results/clientpositive/tez/fileformat_mix.q.out b/ql/src/test/results/clientpositive/tez/fileformat_mix.q.out
new file mode 100644
index 0000000000..32ad9e8e24
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/fileformat_mix.q.out
@@ -0,0 +1,573 @@
+PREHOOK: query: create table fileformat_mix_test (src int, value string) partitioned by (ds string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table fileformat_mix_test (src int, value string) partitioned by (ds string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@fileformat_mix_test
+PREHOOK: query: alter table fileformat_mix_test set fileformat Sequencefile
+PREHOOK: type: ALTERTABLE_FILEFORMAT
+PREHOOK: Input: default@fileformat_mix_test
+PREHOOK: Output: default@fileformat_mix_test
+POSTHOOK: query: alter table fileformat_mix_test set fileformat Sequencefile
+POSTHOOK: type: ALTERTABLE_FILEFORMAT
+POSTHOOK: Input: default@fileformat_mix_test
+POSTHOOK: Output: default@fileformat_mix_test
+PREHOOK: query: insert overwrite table fileformat_mix_test partition (ds='1')
+select key, value from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@fileformat_mix_test@ds=1
+POSTHOOK: query: insert overwrite table fileformat_mix_test partition (ds='1')
+select key, value from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@fileformat_mix_test@ds=1
+POSTHOOK: Lineage: fileformat_mix_test PARTITION(ds=1).src EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: fileformat_mix_test PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: alter table fileformat_mix_test add partition (ds='2')
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: default@fileformat_mix_test
+POSTHOOK: query: alter table fileformat_mix_test add partition (ds='2')
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: default@fileformat_mix_test
+POSTHOOK: Output: default@fileformat_mix_test@ds=2
+POSTHOOK: Lineage: fileformat_mix_test PARTITION(ds=1).src EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: fileformat_mix_test PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: alter table fileformat_mix_test set fileformat rcfile
+PREHOOK: type: ALTERTABLE_FILEFORMAT
+PREHOOK: Input: default@fileformat_mix_test
+PREHOOK: Output: default@fileformat_mix_test
+POSTHOOK: query: alter table fileformat_mix_test set fileformat rcfile
+POSTHOOK: type: ALTERTABLE_FILEFORMAT
+POSTHOOK: Input: default@fileformat_mix_test
+POSTHOOK: Output: default@fileformat_mix_test
+POSTHOOK: Lineage: fileformat_mix_test PARTITION(ds=1).src EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: fileformat_mix_test PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: select count(1) from fileformat_mix_test
+PREHOOK: type: QUERY
+PREHOOK: Input: default@fileformat_mix_test
+PREHOOK: Input: default@fileformat_mix_test@ds=1
+PREHOOK: Input: default@fileformat_mix_test@ds=2
+#### A masked pattern was here ####
+POSTHOOK: query: select count(1) from fileformat_mix_test
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@fileformat_mix_test
+POSTHOOK: Input: default@fileformat_mix_test@ds=1
+POSTHOOK: Input: default@fileformat_mix_test@ds=2
+#### A masked pattern was here ####
+POSTHOOK: Lineage: fileformat_mix_test PARTITION(ds=1).src EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: fileformat_mix_test PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+500
+PREHOOK: query: select src from fileformat_mix_test
+PREHOOK: type: QUERY
+PREHOOK: Input: default@fileformat_mix_test
+PREHOOK: Input: default@fileformat_mix_test@ds=1
+PREHOOK: Input: default@fileformat_mix_test@ds=2
+#### A masked pattern was here ####
+POSTHOOK: query: select src from fileformat_mix_test
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@fileformat_mix_test
+POSTHOOK: Input: default@fileformat_mix_test@ds=1
+POSTHOOK: Input: default@fileformat_mix_test@ds=2
+#### A masked pattern was here ####
+POSTHOOK: Lineage: fileformat_mix_test PARTITION(ds=1).src EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: fileformat_mix_test PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+238
+86
+311
+27
+165
+409
+255
+278
+98
+484
+265
+193
+401
+150
+273
+224
+369
+66
+128
+213
+146
+406
+429
+374
+152
+469
+145
+495
+37
+327
+281
+277
+209
+15
+82
+403
+166
+417
+430
+252
+292
+219
+287
+153
+193
+338
+446
+459
+394
+237
+482
+174
+413
+494
+207
+199
+466
+208
+174
+399
+396
+247
+417
+489
+162
+377
+397
+309
+365
+266
+439
+342
+367
+325
+167
+195
+475
+17
+113
+155
+203
+339
+0
+455
+128
+311
+316
+57
+302
+205
+149
+438
+345
+129
+170
+20
+489
+157
+378
+221
+92
+111
+47
+72
+4
+280
+35
+427
+277
+208
+356
+399
+169
+382
+498
+125
+386
+437
+469
+192
+286
+187
+176
+54
+459
+51
+138
+103
+239
+213
+216
+430
+278
+176
+289
+221
+65
+318
+332
+311
+275
+137
+241
+83
+333
+180
+284
+12
+230
+181
+67
+260
+404
+384
+489
+353
+373
+272
+138
+217
+84
+348
+466
+58
+8
+411
+230
+208
+348
+24
+463
+431
+179
+172
+42
+129
+158
+119
+496
+0
+322
+197
+468
+393
+454
+100
+298
+199
+191
+418
+96
+26
+165
+327
+230
+205
+120
+131
+51
+404
+43
+436
+156
+469
+468
+308
+95
+196
+288
+481
+457
+98
+282
+197
+187
+318
+318
+409
+470
+137
+369
+316
+169
+413
+85
+77
+0
+490
+87
+364
+179
+118
+134
+395
+282
+138
+238
+419
+15
+118
+72
+90
+307
+19
+435
+10
+277
+273
+306
+224
+309
+389
+327
+242
+369
+392
+272
+331
+401
+242
+452
+177
+226
+5
+497
+402
+396
+317
+395
+58
+35
+336
+95
+11
+168
+34
+229
+233
+143
+472
+322
+498
+160
+195
+42
+321
+430
+119
+489
+458
+78
+76
+41
+223
+492
+149
+449
+218
+228
+138
+453
+30
+209
+64
+468
+76
+74
+342
+69
+230
+33
+368
+103
+296
+113
+216
+367
+344
+167
+274
+219
+239
+485
+116
+223
+256
+263
+70
+487
+480
+401
+288
+191
+5
+244
+438
+128
+467
+432
+202
+316
+229
+469
+463
+280
+2
+35
+283
+331
+235
+80
+44
+193
+321
+335
+104
+466
+366
+175
+403
+483
+53
+105
+257
+406
+409
+190
+406
+401
+114
+258
+90
+203
+262
+348
+424
+12
+396
+201
+217
+164
+431
+454
+478
+298
+125
+431
+164
+424
+187
+382
+5
+70
+397
+480
+291
+24
+351
+255
+104
+70
+163
+438
+119
+414
+200
+491
+237
+439
+360
+248
+479
+305
+417
+199
+444
+120
+429
+169
+443
+323
+325
+277
+230
+478
+178
+468
+310
+317
+333
+493
+460
+207
+249
+265
+480
+83
+136
+353
+172
+214
+462
+233
+406
+133
+175
+189
+454
+375
+401
+421
+407
+384
+256
+26
+134
+67
+384
+379
+18
+462
+492
+100
+298
+9
+341
+498
+146
+458
+362
+186
+285
+348
+167
+18
+273
+183
+281
+344
+97
+469
+315
+84
+28
+37
+448
+152
+348
+307
+194
+414
+477
+222
+126
+90
+169
+403
+400
+200
+97
diff --git a/ql/src/test/results/clientpositive/tez/filter_join_breaktask.q.out b/ql/src/test/results/clientpositive/tez/filter_join_breaktask.q.out
new file mode 100644
index 0000000000..03c47809f5
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/filter_join_breaktask.q.out
@@ -0,0 +1,360 @@
+PREHOOK: query: CREATE TABLE filter_join_breaktask(key int, value string) partitioned by (ds string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE filter_join_breaktask(key int, value string) partitioned by (ds string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@filter_join_breaktask
+PREHOOK: query: INSERT OVERWRITE TABLE filter_join_breaktask PARTITION(ds='2008-04-08')
+SELECT key, value from src1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src1
+PREHOOK: Output: default@filter_join_breaktask@ds=2008-04-08
+POSTHOOK: query: INSERT OVERWRITE TABLE filter_join_breaktask PARTITION(ds='2008-04-08')
+SELECT key, value from src1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src1
+POSTHOOK: Output: default@filter_join_breaktask@ds=2008-04-08
+POSTHOOK: Lineage: filter_join_breaktask PARTITION(ds=2008-04-08).key EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: filter_join_breaktask PARTITION(ds=2008-04-08).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: EXPLAIN EXTENDED  
+SELECT f.key, g.value 
+FROM filter_join_breaktask f JOIN filter_join_breaktask m ON( f.key = m.key AND f.ds='2008-04-08' AND m.ds='2008-04-08' AND f.key is not null) 
+JOIN filter_join_breaktask g ON(g.value = m.value AND g.ds='2008-04-08' AND m.ds='2008-04-08' AND m.value is not null AND m.value !='')
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN EXTENDED  
+SELECT f.key, g.value 
+FROM filter_join_breaktask f JOIN filter_join_breaktask m ON( f.key = m.key AND f.ds='2008-04-08' AND m.ds='2008-04-08' AND f.key is not null) 
+JOIN filter_join_breaktask g ON(g.value = m.value AND g.ds='2008-04-08' AND m.ds='2008-04-08' AND m.value is not null AND m.value !='')
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: filter_join_breaktask PARTITION(ds=2008-04-08).key EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: filter_join_breaktask PARTITION(ds=2008-04-08).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_JOIN (TOK_TABREF (TOK_TABNAME filter_join_breaktask) f) (TOK_TABREF (TOK_TABNAME filter_join_breaktask) m) (AND (AND (AND (= (. (TOK_TABLE_OR_COL f) key) (. (TOK_TABLE_OR_COL m) key)) (= (. (TOK_TABLE_OR_COL f) ds) '2008-04-08')) (= (. (TOK_TABLE_OR_COL m) ds) '2008-04-08')) (TOK_FUNCTION TOK_ISNOTNULL (. (TOK_TABLE_OR_COL f) key)))) (TOK_TABREF (TOK_TABNAME filter_join_breaktask) g) (AND (AND (AND (AND (= (. (TOK_TABLE_OR_COL g) value) (. (TOK_TABLE_OR_COL m) value)) (= (. (TOK_TABLE_OR_COL g) ds) '2008-04-08')) (= (. (TOK_TABLE_OR_COL m) ds) '2008-04-08')) (TOK_FUNCTION TOK_ISNOTNULL (. (TOK_TABLE_OR_COL m) value))) (!= (. (TOK_TABLE_OR_COL m) value) '')))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL f) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL g) value)))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        f 
+          TableScan
+            alias: f
+            Statistics:
+                numRows: 25 dataSize: 211 basicStatsState: COMPLETE colStatsState: NONE
+            GatherStats: false
+            Filter Operator
+              isSamplingPred: false
+              predicate:
+                  expr: key is not null
+                  type: boolean
+              Statistics:
+                  numRows: 13 dataSize: 109 basicStatsState: COMPLETE colStatsState: NONE
+              Reduce Output Operator
+                key expressions:
+                      expr: key
+                      type: int
+                sort order: +
+                Map-reduce partition columns:
+                      expr: key
+                      type: int
+                Statistics:
+                    numRows: 13 dataSize: 109 basicStatsState: COMPLETE colStatsState: NONE
+                tag: 0
+                value expressions:
+                      expr: key
+                      type: int
+      Path -> Alias:
+#### A masked pattern was here ####
+      Path -> Partition:
+#### A masked pattern was here ####
+          Partition
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+            properties:
+              COLUMN_STATS_ACCURATE true
+              bucket_count -1
+              columns key,value
+              columns.types int:string
+#### A masked pattern was here ####
+              name default.filter_join_breaktask
+              numFiles 1
+              numRows 25
+              partition_columns ds
+              rawDataSize 211
+              serialization.ddl struct filter_join_breaktask { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 236
+#### A masked pattern was here ####
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types int:string
+#### A masked pattern was here ####
+                name default.filter_join_breaktask
+                partition_columns ds
+                serialization.ddl struct filter_join_breaktask { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+#### A masked pattern was here ####
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.filter_join_breaktask
+            name: default.filter_join_breaktask
+      Truncated Path -> Alias:
+        /filter_join_breaktask/ds=2008-04-08 [f]
+      Alias -> Map Operator Tree:
+        m 
+          TableScan
+            alias: m
+            Statistics:
+                numRows: 25 dataSize: 211 basicStatsState: COMPLETE colStatsState: NONE
+            GatherStats: false
+            Filter Operator
+              isSamplingPred: false
+              predicate:
+                  expr: ((key is not null and value is not null) and (value <> ''))
+                  type: boolean
+              Statistics:
+                  numRows: 7 dataSize: 59 basicStatsState: COMPLETE colStatsState: NONE
+              Reduce Output Operator
+                key expressions:
+                      expr: key
+                      type: int
+                sort order: +
+                Map-reduce partition columns:
+                      expr: key
+                      type: int
+                Statistics:
+                    numRows: 7 dataSize: 59 basicStatsState: COMPLETE colStatsState: NONE
+                tag: 1
+                value expressions:
+                      expr: value
+                      type: string
+      Path -> Alias:
+#### A masked pattern was here ####
+      Path -> Partition:
+#### A masked pattern was here ####
+          Partition
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+            properties:
+              COLUMN_STATS_ACCURATE true
+              bucket_count -1
+              columns key,value
+              columns.types int:string
+#### A masked pattern was here ####
+              name default.filter_join_breaktask
+              numFiles 1
+              numRows 25
+              partition_columns ds
+              rawDataSize 211
+              serialization.ddl struct filter_join_breaktask { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 236
+#### A masked pattern was here ####
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types int:string
+#### A masked pattern was here ####
+                name default.filter_join_breaktask
+                partition_columns ds
+                serialization.ddl struct filter_join_breaktask { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+#### A masked pattern was here ####
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.filter_join_breaktask
+            name: default.filter_join_breaktask
+      Truncated Path -> Alias:
+        /filter_join_breaktask/ds=2008-04-08 [m]
+      Needs Tagging: true
+      Reduce Operator Tree:
+        Join Operator
+          condition map:
+               Inner Join 0 to 1
+          condition expressions:
+            0 {VALUE._col0}
+            1 {VALUE._col1}
+          handleSkewJoin: false
+          outputColumnNames: _col0, _col6
+          Statistics:
+              numRows: 14 dataSize: 119 basicStatsState: COMPLETE colStatsState: NONE
+          Reduce Output Operator
+            key expressions:
+                  expr: _col6
+                  type: string
+            sort order: +
+            Map-reduce partition columns:
+                  expr: _col6
+                  type: string
+            Statistics:
+                numRows: 14 dataSize: 119 basicStatsState: COMPLETE colStatsState: NONE
+            tag: 0
+            value expressions:
+                  expr: _col0
+                  type: int
+      Alias -> Map Operator Tree:
+        g 
+          TableScan
+            alias: g
+            Statistics:
+                numRows: 25 dataSize: 211 basicStatsState: COMPLETE colStatsState: NONE
+            GatherStats: false
+            Filter Operator
+              isSamplingPred: false
+              predicate:
+                  expr: (value <> '')
+                  type: boolean
+              Statistics:
+                  numRows: 25 dataSize: 211 basicStatsState: COMPLETE colStatsState: NONE
+              Reduce Output Operator
+                key expressions:
+                      expr: value
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: value
+                      type: string
+                Statistics:
+                    numRows: 25 dataSize: 211 basicStatsState: COMPLETE colStatsState: NONE
+                tag: 1
+                value expressions:
+                      expr: value
+                      type: string
+      Path -> Alias:
+#### A masked pattern was here ####
+      Path -> Partition:
+#### A masked pattern was here ####
+          Partition
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+            properties:
+              COLUMN_STATS_ACCURATE true
+              bucket_count -1
+              columns key,value
+              columns.types int:string
+#### A masked pattern was here ####
+              name default.filter_join_breaktask
+              numFiles 1
+              numRows 25
+              partition_columns ds
+              rawDataSize 211
+              serialization.ddl struct filter_join_breaktask { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 236
+#### A masked pattern was here ####
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types int:string
+#### A masked pattern was here ####
+                name default.filter_join_breaktask
+                partition_columns ds
+                serialization.ddl struct filter_join_breaktask { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+#### A masked pattern was here ####
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.filter_join_breaktask
+            name: default.filter_join_breaktask
+      Truncated Path -> Alias:
+        /filter_join_breaktask/ds=2008-04-08 [g]
+      Needs Tagging: true
+      Reduce Operator Tree:
+        Join Operator
+          condition map:
+               Inner Join 0 to 1
+          condition expressions:
+            0 {VALUE._col0}
+            1 {VALUE._col1}
+          handleSkewJoin: false
+          outputColumnNames: _col0, _col11
+          Statistics:
+              numRows: 27 dataSize: 232 basicStatsState: COMPLETE colStatsState: NONE
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: int
+                  expr: _col11
+                  type: string
+            outputColumnNames: _col0, _col1
+            Statistics:
+                numRows: 27 dataSize: 232 basicStatsState: COMPLETE colStatsState: NONE
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+#### A masked pattern was here ####
+              NumFilesPerFileSink: 1
+              Statistics:
+                  numRows: 27 dataSize: 232 basicStatsState: COMPLETE colStatsState: NONE
+#### A masked pattern was here ####
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  properties:
+                    columns _col0,_col1
+                    columns.types int:string
+                    escape.delim \
+                    hive.serialization.extend.nesting.levels true
+                    serialization.format 1
+                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              TotalFiles: 1
+              GatherStats: false
+              MultiFileSpray: false
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+PREHOOK: query: SELECT f.key, g.value 
+FROM filter_join_breaktask f JOIN filter_join_breaktask m ON( f.key = m.key AND f.ds='2008-04-08' AND m.ds='2008-04-08' AND f.key is not null) 
+JOIN filter_join_breaktask g ON(g.value = m.value AND g.ds='2008-04-08' AND m.ds='2008-04-08' AND m.value is not null AND m.value !='')
+PREHOOK: type: QUERY
+PREHOOK: Input: default@filter_join_breaktask
+PREHOOK: Input: default@filter_join_breaktask@ds=2008-04-08
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT f.key, g.value 
+FROM filter_join_breaktask f JOIN filter_join_breaktask m ON( f.key = m.key AND f.ds='2008-04-08' AND m.ds='2008-04-08' AND f.key is not null) 
+JOIN filter_join_breaktask g ON(g.value = m.value AND g.ds='2008-04-08' AND m.ds='2008-04-08' AND m.value is not null AND m.value !='')
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@filter_join_breaktask
+POSTHOOK: Input: default@filter_join_breaktask@ds=2008-04-08
+#### A masked pattern was here ####
+POSTHOOK: Lineage: filter_join_breaktask PARTITION(ds=2008-04-08).key EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: filter_join_breaktask PARTITION(ds=2008-04-08).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
+146	val_146
+150	val_150
+213	val_213
+238	val_238
+255	val_255
+273	val_273
+278	val_278
+311	val_311
+401	val_401
+406	val_406
+66	val_66
+98	val_98
diff --git a/ql/src/test/results/clientpositive/tez/filter_join_breaktask2.q.out b/ql/src/test/results/clientpositive/tez/filter_join_breaktask2.q.out
new file mode 100644
index 0000000000..158320796c
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/filter_join_breaktask2.q.out
@@ -0,0 +1,931 @@
+PREHOOK: query: create table T1(c1 string, c2 string, c3 string, c4 string, c5 string, c6 string, c7 string) 
+partitioned by (ds string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table T1(c1 string, c2 string, c3 string, c4 string, c5 string, c6 string, c7 string) 
+partitioned by (ds string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@T1
+PREHOOK: query: create table T2(c1 string, c2 string, c3 string, c0 string, c4 string, c5 string, c6 string, c7 string, c8 string, c9 string, c10 string, c11 string, c12 string, c13 string, c14 string, c15 string, c16 string, c17 string, c18 string, c19 string, c20 string, c21 string, c22 string, c23 string, c24 string,  c25 string) partitioned by (ds string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table T2(c1 string, c2 string, c3 string, c0 string, c4 string, c5 string, c6 string, c7 string, c8 string, c9 string, c10 string, c11 string, c12 string, c13 string, c14 string, c15 string, c16 string, c17 string, c18 string, c19 string, c20 string, c21 string, c22 string, c23 string, c24 string,  c25 string) partitioned by (ds string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@T2
+PREHOOK: query: create table T3 (c0 bigint,  c1 bigint, c2 int) partitioned by (ds string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table T3 (c0 bigint,  c1 bigint, c2 int) partitioned by (ds string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@T3
+PREHOOK: query: create table T4 (c0 bigint, c1 string, c2 string, c3 string, c4 string, c5 string, c6 string, c7 string, c8 string, c9 string, c10 string, c11 string, c12 string, c13 string, c14 string, c15 string, c16 string, c17 string, c18 string, c19 string, c20 string, c21 string, c22 string, c23 string, c24 string, c25 string, c26 string, c27 string, c28 string, c29 string, c30 string, c31 string, c32 string, c33 string, c34 string, c35 string, c36 string, c37 string, c38 string, c39 string, c40 string, c41 string, c42 string, c43 string, c44 string, c45 string, c46 string, c47 string, c48 string, c49 string, c50 string, c51 string, c52 string, c53 string, c54 string, c55 string, c56 string, c57 string, c58 string, c59 string, c60 string, c61 string, c62 string, c63 string, c64 string, c65 string, c66 string, c67 bigint, c68 string, c69 string, c70 bigint, c71 bigint, c72 bigint, c73 string, c74 string, c75 string, c76 string, c77 string, c78 string, c79 string, c80 string, c81 bigint, c82 bigint, c83 bigint) partitioned by (ds string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table T4 (c0 bigint, c1 string, c2 string, c3 string, c4 string, c5 string, c6 string, c7 string, c8 string, c9 string, c10 string, c11 string, c12 string, c13 string, c14 string, c15 string, c16 string, c17 string, c18 string, c19 string, c20 string, c21 string, c22 string, c23 string, c24 string, c25 string, c26 string, c27 string, c28 string, c29 string, c30 string, c31 string, c32 string, c33 string, c34 string, c35 string, c36 string, c37 string, c38 string, c39 string, c40 string, c41 string, c42 string, c43 string, c44 string, c45 string, c46 string, c47 string, c48 string, c49 string, c50 string, c51 string, c52 string, c53 string, c54 string, c55 string, c56 string, c57 string, c58 string, c59 string, c60 string, c61 string, c62 string, c63 string, c64 string, c65 string, c66 string, c67 bigint, c68 string, c69 string, c70 bigint, c71 bigint, c72 bigint, c73 string, c74 string, c75 string, c76 string, c77 string, c78 string, c79 string, c80 string, c81 bigint, c82 bigint, c83 bigint) partitioned by (ds string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@T4
+PREHOOK: query: insert overwrite table T1 partition (ds='2010-04-17') select '5', '1', '1', '1',  0, 0,4 from src tablesample (1 rows)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@t1@ds=2010-04-17
+POSTHOOK: query: insert overwrite table T1 partition (ds='2010-04-17') select '5', '1', '1', '1',  0, 0,4 from src tablesample (1 rows)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@t1@ds=2010-04-17
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c7 SIMPLE []
+PREHOOK: query: insert overwrite table T2 partition(ds='2010-04-17') select '5','name', NULL, '2', 'kavin',NULL, '9', 'c', '8', '0', '0', '7', '1','2', '0', '3','2', NULL, '1', NULL, '3','2','0','0','5','10' from src tablesample (1 rows)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@t2@ds=2010-04-17
+POSTHOOK: query: insert overwrite table T2 partition(ds='2010-04-17') select '5','name', NULL, '2', 'kavin',NULL, '9', 'c', '8', '0', '0', '7', '1','2', '0', '3','2', NULL, '1', NULL, '3','2','0','0','5','10' from src tablesample (1 rows)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@t2@ds=2010-04-17
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c0 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c9 SIMPLE []
+PREHOOK: query: insert overwrite table T3 partition (ds='2010-04-17') select 4,5,0 from src tablesample (1 rows)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@t3@ds=2010-04-17
+POSTHOOK: query: insert overwrite table T3 partition (ds='2010-04-17') select 4,5,0 from src tablesample (1 rows)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@t3@ds=2010-04-17
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c0 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c9 SIMPLE []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c1 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c2 SIMPLE []
+PREHOOK: query: insert overwrite table T4 partition(ds='2010-04-17') 
+select 4,'1','1','8','4','5','1','0','9','U','2','2', '0','2','1','1','J','C','A','U', '2','s', '2',NULL, NULL, NULL,NULL, NULL, NULL,'1','j', 'S', '6',NULL,'1', '2', 'J', 'g', '1', 'e', '2', '1', '2', 'U', 'P', 'p', '3', '0', '0', '0', '1', '1', '1', '0', '0', '0', '6', '2', 'j',NULL, NULL, NULL,NULL,NULL, NULL, '5',NULL, 'j', 'j', 2, 2, 1, '2', '2', '1', '1', '1', '1', '1', '1', 1, 1, 32,NULL from src limit 1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@t4@ds=2010-04-17
+POSTHOOK: query: insert overwrite table T4 partition(ds='2010-04-17') 
+select 4,'1','1','8','4','5','1','0','9','U','2','2', '0','2','1','1','J','C','A','U', '2','s', '2',NULL, NULL, NULL,NULL, NULL, NULL,'1','j', 'S', '6',NULL,'1', '2', 'J', 'g', '1', 'e', '2', '1', '2', 'U', 'P', 'p', '3', '0', '0', '0', '1', '1', '1', '0', '0', '0', '6', '2', 'j',NULL, NULL, NULL,NULL,NULL, NULL, '5',NULL, 'j', 'j', 2, 2, 1, '2', '2', '1', '1', '1', '1', '1', '1', 1, 1, 32,NULL from src limit 1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@t4@ds=2010-04-17
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c0 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c9 SIMPLE []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c1 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c26 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c27 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c28 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c29 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c30 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c31 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c32 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c33 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c34 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c35 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c36 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c37 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c38 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c39 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c40 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c41 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c42 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c43 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c44 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c45 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c46 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c47 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c48 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c49 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c50 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c51 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c52 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c53 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c54 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c55 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c56 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c57 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c58 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c59 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c60 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c61 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c62 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c63 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c64 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c65 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c66 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c67 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c68 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c69 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c70 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c71 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c72 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c73 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c74 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c75 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c76 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c77 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c78 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c79 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c80 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c81 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c82 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c83 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c9 SIMPLE []
+PREHOOK: query: select * from T2
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t2
+PREHOOK: Input: default@t2@ds=2010-04-17
+#### A masked pattern was here ####
+POSTHOOK: query: select * from T2
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t2
+POSTHOOK: Input: default@t2@ds=2010-04-17
+#### A masked pattern was here ####
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c0 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c9 SIMPLE []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c1 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c26 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c27 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c28 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c29 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c30 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c31 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c32 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c33 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c34 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c35 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c36 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c37 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c38 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c39 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c40 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c41 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c42 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c43 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c44 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c45 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c46 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c47 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c48 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c49 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c50 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c51 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c52 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c53 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c54 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c55 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c56 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c57 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c58 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c59 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c60 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c61 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c62 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c63 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c64 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c65 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c66 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c67 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c68 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c69 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c70 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c71 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c72 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c73 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c74 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c75 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c76 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c77 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c78 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c79 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c80 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c81 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c82 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c83 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c9 SIMPLE []
+5	name	NULL	2	kavin	NULL	9	c	8	0	0	7	1	2	0	3	2	NULL	1	NULL	3	2	0	0	5	10	2010-04-17
+PREHOOK: query: select * from T1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t1
+PREHOOK: Input: default@t1@ds=2010-04-17
+#### A masked pattern was here ####
+POSTHOOK: query: select * from T1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t1
+POSTHOOK: Input: default@t1@ds=2010-04-17
+#### A masked pattern was here ####
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c0 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c9 SIMPLE []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c1 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c26 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c27 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c28 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c29 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c30 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c31 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c32 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c33 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c34 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c35 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c36 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c37 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c38 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c39 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c40 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c41 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c42 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c43 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c44 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c45 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c46 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c47 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c48 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c49 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c50 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c51 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c52 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c53 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c54 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c55 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c56 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c57 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c58 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c59 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c60 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c61 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c62 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c63 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c64 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c65 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c66 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c67 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c68 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c69 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c70 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c71 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c72 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c73 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c74 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c75 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c76 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c77 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c78 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c79 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c80 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c81 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c82 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c83 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c9 SIMPLE []
+5	1	1	1	0	0	4	2010-04-17
+PREHOOK: query: select * from T3
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t3
+PREHOOK: Input: default@t3@ds=2010-04-17
+#### A masked pattern was here ####
+POSTHOOK: query: select * from T3
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t3
+POSTHOOK: Input: default@t3@ds=2010-04-17
+#### A masked pattern was here ####
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c0 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c9 SIMPLE []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c1 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c26 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c27 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c28 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c29 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c30 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c31 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c32 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c33 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c34 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c35 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c36 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c37 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c38 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c39 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c40 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c41 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c42 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c43 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c44 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c45 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c46 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c47 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c48 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c49 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c50 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c51 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c52 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c53 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c54 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c55 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c56 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c57 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c58 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c59 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c60 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c61 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c62 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c63 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c64 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c65 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c66 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c67 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c68 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c69 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c70 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c71 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c72 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c73 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c74 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c75 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c76 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c77 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c78 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c79 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c80 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c81 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c82 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c83 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c9 SIMPLE []
+4	5	0	2010-04-17
+PREHOOK: query: select * from T4
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t4
+PREHOOK: Input: default@t4@ds=2010-04-17
+#### A masked pattern was here ####
+POSTHOOK: query: select * from T4
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t4
+POSTHOOK: Input: default@t4@ds=2010-04-17
+#### A masked pattern was here ####
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c0 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c9 SIMPLE []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c1 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c26 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c27 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c28 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c29 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c30 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c31 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c32 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c33 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c34 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c35 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c36 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c37 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c38 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c39 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c40 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c41 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c42 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c43 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c44 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c45 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c46 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c47 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c48 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c49 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c50 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c51 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c52 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c53 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c54 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c55 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c56 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c57 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c58 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c59 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c60 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c61 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c62 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c63 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c64 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c65 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c66 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c67 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c68 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c69 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c70 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c71 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c72 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c73 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c74 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c75 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c76 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c77 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c78 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c79 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c80 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c81 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c82 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c83 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c9 SIMPLE []
+4	1	1	8	4	5	1	0	9	U	2	2	0	2	1	1	J	C	A	U	2	s	2	NULL	NULL	NULL	NULL	NULL	NULL	1	j	S	6	NULL	1	2	J	g	1	e	2	1	2	U	P	p	3	0	0	0	1	1	1	0	0	0	6	2	j	NULL	NULL	NULL	NULL	NULL	NULL	5	NULL	NULL	j	2	2	1	2	2	1	1	1	1	1	1	1	1	32	NULL	2010-04-17
+PREHOOK: query: SELECT a.c1 as a_c1, b.c1 b_c1, d.c0 as d_c0
+FROM T1 a JOIN T2 b 
+       ON (a.c1 = b.c1 AND a.ds='2010-04-17' AND b.ds='2010-04-17')
+     JOIN T3 c 
+       ON (a.c1 = c.c1 AND a.ds='2010-04-17' AND c.ds='2010-04-17')
+     JOIN T4 d 
+       ON (c.c0 = d.c0 AND c.ds='2010-04-17' AND d.ds='2010-04-17')
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t1
+PREHOOK: Input: default@t1@ds=2010-04-17
+PREHOOK: Input: default@t2
+PREHOOK: Input: default@t2@ds=2010-04-17
+PREHOOK: Input: default@t3
+PREHOOK: Input: default@t3@ds=2010-04-17
+PREHOOK: Input: default@t4
+PREHOOK: Input: default@t4@ds=2010-04-17
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT a.c1 as a_c1, b.c1 b_c1, d.c0 as d_c0
+FROM T1 a JOIN T2 b 
+       ON (a.c1 = b.c1 AND a.ds='2010-04-17' AND b.ds='2010-04-17')
+     JOIN T3 c 
+       ON (a.c1 = c.c1 AND a.ds='2010-04-17' AND c.ds='2010-04-17')
+     JOIN T4 d 
+       ON (c.c0 = d.c0 AND c.ds='2010-04-17' AND d.ds='2010-04-17')
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t1
+POSTHOOK: Input: default@t1@ds=2010-04-17
+POSTHOOK: Input: default@t2
+POSTHOOK: Input: default@t2@ds=2010-04-17
+POSTHOOK: Input: default@t3
+POSTHOOK: Input: default@t3@ds=2010-04-17
+POSTHOOK: Input: default@t4
+POSTHOOK: Input: default@t4@ds=2010-04-17
+#### A masked pattern was here ####
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t1 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c0 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-04-17).c9 SIMPLE []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c1 EXPRESSION []
+POSTHOOK: Lineage: t3 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c0 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c1 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c10 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c11 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c12 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c13 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c14 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c15 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c16 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c17 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c18 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c19 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c2 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c20 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c21 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c22 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c23 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c24 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c25 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c26 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c27 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c28 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c29 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c3 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c30 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c31 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c32 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c33 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c34 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c35 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c36 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c37 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c38 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c39 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c4 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c40 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c41 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c42 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c43 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c44 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c45 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c46 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c47 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c48 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c49 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c5 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c50 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c51 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c52 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c53 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c54 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c55 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c56 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c57 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c58 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c59 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c6 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c60 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c61 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c62 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c63 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c64 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c65 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c66 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c67 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c68 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c69 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c7 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c70 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c71 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c72 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c73 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c74 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c75 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c76 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c77 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c78 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c79 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c8 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c80 SIMPLE []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c81 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c82 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c83 EXPRESSION []
+POSTHOOK: Lineage: t4 PARTITION(ds=2010-04-17).c9 SIMPLE []
+5	5	4
diff --git a/ql/src/test/results/clientpositive/tez/groupby1.q.out b/ql/src/test/results/clientpositive/tez/groupby1.q.out
new file mode 100644
index 0000000000..de647fa3c8
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/groupby1.q.out
@@ -0,0 +1,487 @@
+PREHOOK: query: CREATE TABLE dest_g1(key INT, value DOUBLE) STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE dest_g1(key INT, value DOUBLE) STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@dest_g1
+PREHOOK: query: EXPLAIN
+FROM src INSERT OVERWRITE TABLE dest_g1 SELECT src.key, sum(substr(src.value,5)) GROUP BY src.key
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN
+FROM src INSERT OVERWRITE TABLE dest_g1 SELECT src.key, sum(substr(src.value,5)) GROUP BY src.key
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME dest_g1))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL src) key)) (TOK_SELEXPR (TOK_FUNCTION sum (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5)))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL src) key))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: key, value
+              Reduce Output Operator
+                key expressions:
+                      expr: key
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: rand()
+                      type: double
+                tag: -1
+                value expressions:
+                      expr: substr(value, 5)
+                      type: string
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: sum(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: partial1
+          outputColumnNames: _col0, _col1
+          Reduce Output Operator
+            key expressions:
+                  expr: _col0
+                  type: string
+            sort order: +
+            Map-reduce partition columns:
+                  expr: _col0
+                  type: string
+            tag: -1
+            value expressions:
+                  expr: _col1
+                  type: double
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: sum(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: final
+          outputColumnNames: _col0, _col1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(_col0)
+                  type: int
+                  expr: _col1
+                  type: double
+            outputColumnNames: _col0, _col1
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.dest_g1
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.dest_g1
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.dest_g1
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.dest_g1
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest_g1 SELECT src.key, sum(substr(src.value,5)) GROUP BY src.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@dest_g1
+POSTHOOK: query: FROM src INSERT OVERWRITE TABLE dest_g1 SELECT src.key, sum(substr(src.value,5)) GROUP BY src.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@dest_g1
+POSTHOOK: Lineage: dest_g1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: dest_g1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: SELECT dest_g1.* FROM dest_g1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@dest_g1
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT dest_g1.* FROM dest_g1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@dest_g1
+#### A masked pattern was here ####
+POSTHOOK: Lineage: dest_g1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: dest_g1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+0	0.0
+10	10.0
+100	200.0
+103	206.0
+104	208.0
+105	105.0
+11	11.0
+111	111.0
+113	226.0
+114	114.0
+116	116.0
+118	236.0
+119	357.0
+12	24.0
+120	240.0
+125	250.0
+126	126.0
+128	384.0
+129	258.0
+131	131.0
+133	133.0
+134	268.0
+136	136.0
+137	274.0
+138	552.0
+143	143.0
+145	145.0
+146	292.0
+149	298.0
+15	30.0
+150	150.0
+152	304.0
+153	153.0
+155	155.0
+156	156.0
+157	157.0
+158	158.0
+160	160.0
+162	162.0
+163	163.0
+164	328.0
+165	330.0
+166	166.0
+167	501.0
+168	168.0
+169	676.0
+17	17.0
+170	170.0
+172	344.0
+174	348.0
+175	350.0
+176	352.0
+177	177.0
+178	178.0
+179	358.0
+18	36.0
+180	180.0
+181	181.0
+183	183.0
+186	186.0
+187	561.0
+189	189.0
+19	19.0
+190	190.0
+191	382.0
+192	192.0
+193	579.0
+194	194.0
+195	390.0
+196	196.0
+197	394.0
+199	597.0
+2	2.0
+20	20.0
+200	400.0
+201	201.0
+202	202.0
+203	406.0
+205	410.0
+207	414.0
+208	624.0
+209	418.0
+213	426.0
+214	214.0
+216	432.0
+217	434.0
+218	218.0
+219	438.0
+221	442.0
+222	222.0
+223	446.0
+224	448.0
+226	226.0
+228	228.0
+229	458.0
+230	1150.0
+233	466.0
+235	235.0
+237	474.0
+238	476.0
+239	478.0
+24	48.0
+241	241.0
+242	484.0
+244	244.0
+247	247.0
+248	248.0
+249	249.0
+252	252.0
+255	510.0
+256	512.0
+257	257.0
+258	258.0
+26	52.0
+260	260.0
+262	262.0
+263	263.0
+265	530.0
+266	266.0
+27	27.0
+272	544.0
+273	819.0
+274	274.0
+275	275.0
+277	1108.0
+278	556.0
+28	28.0
+280	560.0
+281	562.0
+282	564.0
+283	283.0
+284	284.0
+285	285.0
+286	286.0
+287	287.0
+288	576.0
+289	289.0
+291	291.0
+292	292.0
+296	296.0
+298	894.0
+30	30.0
+302	302.0
+305	305.0
+306	306.0
+307	614.0
+308	308.0
+309	618.0
+310	310.0
+311	933.0
+315	315.0
+316	948.0
+317	634.0
+318	954.0
+321	642.0
+322	644.0
+323	323.0
+325	650.0
+327	981.0
+33	33.0
+331	662.0
+332	332.0
+333	666.0
+335	335.0
+336	336.0
+338	338.0
+339	339.0
+34	34.0
+341	341.0
+342	684.0
+344	688.0
+345	345.0
+348	1740.0
+35	105.0
+351	351.0
+353	706.0
+356	356.0
+360	360.0
+362	362.0
+364	364.0
+365	365.0
+366	366.0
+367	734.0
+368	368.0
+369	1107.0
+37	74.0
+373	373.0
+374	374.0
+375	375.0
+377	377.0
+378	378.0
+379	379.0
+382	764.0
+384	1152.0
+386	386.0
+389	389.0
+392	392.0
+393	393.0
+394	394.0
+395	790.0
+396	1188.0
+397	794.0
+399	798.0
+4	4.0
+400	400.0
+401	2005.0
+402	402.0
+403	1209.0
+404	808.0
+406	1624.0
+407	407.0
+409	1227.0
+41	41.0
+411	411.0
+413	826.0
+414	828.0
+417	1251.0
+418	418.0
+419	419.0
+42	84.0
+421	421.0
+424	848.0
+427	427.0
+429	858.0
+43	43.0
+430	1290.0
+431	1293.0
+432	432.0
+435	435.0
+436	436.0
+437	437.0
+438	1314.0
+439	878.0
+44	44.0
+443	443.0
+444	444.0
+446	446.0
+448	448.0
+449	449.0
+452	452.0
+453	453.0
+454	1362.0
+455	455.0
+457	457.0
+458	916.0
+459	918.0
+460	460.0
+462	924.0
+463	926.0
+466	1398.0
+467	467.0
+468	1872.0
+469	2345.0
+47	47.0
+470	470.0
+472	472.0
+475	475.0
+477	477.0
+478	956.0
+479	479.0
+480	1440.0
+481	481.0
+482	482.0
+483	483.0
+484	484.0
+485	485.0
+487	487.0
+489	1956.0
+490	490.0
+491	491.0
+492	984.0
+493	493.0
+494	494.0
+495	495.0
+496	496.0
+497	497.0
+498	1494.0
+5	15.0
+51	102.0
+53	53.0
+54	54.0
+57	57.0
+58	116.0
+64	64.0
+65	65.0
+66	66.0
+67	134.0
+69	69.0
+70	210.0
+72	144.0
+74	74.0
+76	152.0
+77	77.0
+78	78.0
+8	8.0
+80	80.0
+82	82.0
+83	166.0
+84	168.0
+85	85.0
+86	86.0
+87	87.0
+9	9.0
+90	270.0
+92	92.0
+95	190.0
+96	96.0
+97	194.0
+98	196.0
diff --git a/ql/src/test/results/clientpositive/tez/groupby2.q.out b/ql/src/test/results/clientpositive/tez/groupby2.q.out
new file mode 100644
index 0000000000..722369078e
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/groupby2.q.out
@@ -0,0 +1,174 @@
+PREHOOK: query: CREATE TABLE dest_g2(key STRING, c1 INT, c2 STRING) STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE dest_g2(key STRING, c1 INT, c2 STRING) STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@dest_g2
+PREHOOK: query: EXPLAIN
+FROM src
+INSERT OVERWRITE TABLE dest_g2 SELECT substr(src.key,1,1), count(DISTINCT substr(src.value,5)), concat(substr(src.key,1,1),sum(substr(src.value,5))) GROUP BY substr(src.key,1,1)
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN
+FROM src
+INSERT OVERWRITE TABLE dest_g2 SELECT substr(src.key,1,1), count(DISTINCT substr(src.value,5)), concat(substr(src.key,1,1),sum(substr(src.value,5))) GROUP BY substr(src.key,1,1)
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME dest_g2))) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) key) 1 1)) (TOK_SELEXPR (TOK_FUNCTIONDI count (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5))) (TOK_SELEXPR (TOK_FUNCTION concat (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) key) 1 1) (TOK_FUNCTION sum (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5))))) (TOK_GROUPBY (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) key) 1 1))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: key, value
+              Reduce Output Operator
+                key expressions:
+                      expr: substr(key, 1, 1)
+                      type: string
+                      expr: substr(value, 5)
+                      type: string
+                sort order: ++
+                Map-reduce partition columns:
+                      expr: substr(key, 1, 1)
+                      type: string
+                tag: -1
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: count(DISTINCT KEY._col1:0._col0)
+                expr: sum(KEY._col1:0._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: complete
+          outputColumnNames: _col0, _col1, _col2
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: UDFToInteger(_col1)
+                  type: int
+                  expr: concat(_col0, _col2)
+                  type: string
+            outputColumnNames: _col0, _col1, _col2
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.dest_g2
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.dest_g2
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.dest_g2
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.dest_g2
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: FROM src
+INSERT OVERWRITE TABLE dest_g2 SELECT substr(src.key,1,1), count(DISTINCT substr(src.value,5)), concat(substr(src.key,1,1),sum(substr(src.value,5))) GROUP BY substr(src.key,1,1)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@dest_g2
+POSTHOOK: query: FROM src
+INSERT OVERWRITE TABLE dest_g2 SELECT substr(src.key,1,1), count(DISTINCT substr(src.value,5)), concat(substr(src.key,1,1),sum(substr(src.value,5))) GROUP BY substr(src.key,1,1)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@dest_g2
+POSTHOOK: Lineage: dest_g2.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest_g2.c2 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest_g2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+PREHOOK: query: SELECT dest_g2.* FROM dest_g2
+PREHOOK: type: QUERY
+PREHOOK: Input: default@dest_g2
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT dest_g2.* FROM dest_g2
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@dest_g2
+#### A masked pattern was here ####
+POSTHOOK: Lineage: dest_g2.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest_g2.c2 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest_g2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+0	1	00.0
+1	71	116414.0
+2	69	225571.0
+3	62	332004.0
+4	74	452763.0
+5	6	5397.0
+6	5	6398.0
+7	6	7735.0
+8	8	8762.0
+9	7	91047.0
diff --git a/ql/src/test/results/clientpositive/tez/groupby3.q.out b/ql/src/test/results/clientpositive/tez/groupby3.q.out
new file mode 100644
index 0000000000..114757cf9b
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/groupby3.q.out
@@ -0,0 +1,262 @@
+PREHOOK: query: CREATE TABLE dest1(c1 DOUBLE, c2 DOUBLE, c3 DOUBLE, c4 DOUBLE, c5 DOUBLE, c6 DOUBLE, c7 DOUBLE, c8 DOUBLE, c9 DOUBLE) STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE dest1(c1 DOUBLE, c2 DOUBLE, c3 DOUBLE, c4 DOUBLE, c5 DOUBLE, c6 DOUBLE, c7 DOUBLE, c8 DOUBLE, c9 DOUBLE) STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@dest1
+PREHOOK: query: EXPLAIN
+FROM src
+INSERT OVERWRITE TABLE dest1 SELECT 
+  sum(substr(src.value,5)), 
+  avg(substr(src.value,5)), 
+  avg(DISTINCT substr(src.value,5)), 
+  max(substr(src.value,5)),
+  min(substr(src.value,5)), 
+  std(substr(src.value,5)),
+  stddev_samp(substr(src.value,5)),
+  variance(substr(src.value,5)),
+  var_samp(substr(src.value,5))
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN
+FROM src
+INSERT OVERWRITE TABLE dest1 SELECT 
+  sum(substr(src.value,5)), 
+  avg(substr(src.value,5)), 
+  avg(DISTINCT substr(src.value,5)), 
+  max(substr(src.value,5)),
+  min(substr(src.value,5)), 
+  std(substr(src.value,5)),
+  stddev_samp(substr(src.value,5)),
+  variance(substr(src.value,5)),
+  var_samp(substr(src.value,5))
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME dest1))) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION sum (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5))) (TOK_SELEXPR (TOK_FUNCTION avg (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5))) (TOK_SELEXPR (TOK_FUNCTIONDI avg (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5))) (TOK_SELEXPR (TOK_FUNCTION max (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5))) (TOK_SELEXPR (TOK_FUNCTION min (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5))) (TOK_SELEXPR (TOK_FUNCTION std (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5))) (TOK_SELEXPR (TOK_FUNCTION stddev_samp (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5))) (TOK_SELEXPR (TOK_FUNCTION variance (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5))) (TOK_SELEXPR (TOK_FUNCTION var_samp (TOK_FUNCTION substr (. (TOK_TABLE_OR_COL src) value) 5))))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: value
+                    type: string
+              outputColumnNames: value
+              Reduce Output Operator
+                key expressions:
+                      expr: substr(value, 5)
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: substr(value, 5)
+                      type: string
+                tag: -1
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: sum(KEY._col0:0._col0)
+                expr: avg(KEY._col0:0._col0)
+                expr: avg(DISTINCT KEY._col0:0._col0)
+                expr: max(KEY._col0:0._col0)
+                expr: min(KEY._col0:0._col0)
+                expr: std(KEY._col0:0._col0)
+                expr: stddev_samp(KEY._col0:0._col0)
+                expr: variance(KEY._col0:0._col0)
+                expr: var_samp(KEY._col0:0._col0)
+          bucketGroup: false
+          mode: partial1
+          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
+          Reduce Output Operator
+            sort order: 
+            tag: -1
+            value expressions:
+                  expr: _col0
+                  type: double
+                  expr: _col1
+                  type: struct<count:bigint,sum:double>
+                  expr: _col2
+                  type: struct<count:bigint,sum:double>
+                  expr: _col3
+                  type: string
+                  expr: _col4
+                  type: string
+                  expr: _col5
+                  type: struct<count:bigint,sum:double,variance:double>
+                  expr: _col6
+                  type: struct<count:bigint,sum:double,variance:double>
+                  expr: _col7
+                  type: struct<count:bigint,sum:double,variance:double>
+                  expr: _col8
+                  type: struct<count:bigint,sum:double,variance:double>
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: sum(VALUE._col0)
+                expr: avg(VALUE._col1)
+                expr: avg(VALUE._col2)
+                expr: max(VALUE._col3)
+                expr: min(VALUE._col4)
+                expr: std(VALUE._col5)
+                expr: stddev_samp(VALUE._col6)
+                expr: variance(VALUE._col7)
+                expr: var_samp(VALUE._col8)
+          bucketGroup: false
+          mode: final
+          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: double
+                  expr: _col1
+                  type: double
+                  expr: _col2
+                  type: double
+                  expr: UDFToDouble(_col3)
+                  type: double
+                  expr: UDFToDouble(_col4)
+                  type: double
+                  expr: _col5
+                  type: double
+                  expr: _col6
+                  type: double
+                  expr: _col7
+                  type: double
+                  expr: _col8
+                  type: double
+            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.dest1
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.dest1
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.dest1
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.dest1
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: FROM src
+INSERT OVERWRITE TABLE dest1 SELECT 
+  sum(substr(src.value,5)), 
+  avg(substr(src.value,5)), 
+  avg(DISTINCT substr(src.value,5)), 
+  max(substr(src.value,5)), 
+  min(substr(src.value,5)), 
+  std(substr(src.value,5)),
+  stddev_samp(substr(src.value,5)),
+  variance(substr(src.value,5)),
+  var_samp(substr(src.value,5))
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@dest1
+POSTHOOK: query: FROM src
+INSERT OVERWRITE TABLE dest1 SELECT 
+  sum(substr(src.value,5)), 
+  avg(substr(src.value,5)), 
+  avg(DISTINCT substr(src.value,5)), 
+  max(substr(src.value,5)), 
+  min(substr(src.value,5)), 
+  std(substr(src.value,5)),
+  stddev_samp(substr(src.value,5)),
+  variance(substr(src.value,5)),
+  var_samp(substr(src.value,5))
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@dest1
+POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c4 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c5 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c6 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c7 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c8 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c9 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: SELECT dest1.* FROM dest1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@dest1
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT dest1.* FROM dest1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@dest1
+#### A masked pattern was here ####
+POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c4 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c5 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c6 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c7 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c8 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: dest1.c9 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+130091.0	260.182	256.10355987055016	98.0	0.0	142.92680950752379	143.06995106518903	20428.07287599999	20469.010897795582
diff --git a/ql/src/test/results/clientpositive/tez/having.q.out b/ql/src/test/results/clientpositive/tez/having.q.out
new file mode 100644
index 0000000000..e498fddca6
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/having.q.out
@@ -0,0 +1,1274 @@
+PREHOOK: query: EXPLAIN SELECT count(value) AS c FROM src GROUP BY key HAVING c > 3
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT count(value) AS c FROM src GROUP BY key HAVING c > 3
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION count (TOK_TABLE_OR_COL value)) c)) (TOK_GROUPBY (TOK_TABLE_OR_COL key)) (TOK_HAVING (> (TOK_TABLE_OR_COL c) 3))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: key, value
+              Group By Operator
+                aggregations:
+                      expr: count(value)
+                bucketGroup: false
+                keys:
+                      expr: key
+                      type: string
+                mode: hash
+                outputColumnNames: _col0, _col1
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: string
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: _col0
+                        type: string
+                  tag: -1
+                  value expressions:
+                        expr: _col1
+                        type: bigint
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: count(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: mergepartial
+          outputColumnNames: _col0, _col1
+          Filter Operator
+            predicate:
+                expr: (_col1 > 3)
+                type: boolean
+            Select Operator
+              expressions:
+                    expr: _col1
+                    type: bigint
+              outputColumnNames: _col0
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+PREHOOK: query: SELECT count(value) AS c FROM src GROUP BY key HAVING c > 3
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT count(value) AS c FROM src GROUP BY key HAVING c > 3
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+4
+4
+5
+4
+5
+5
+4
+4
+5
+4
+PREHOOK: query: EXPLAIN SELECT key, max(value) AS c FROM src GROUP BY key HAVING key != 302
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key, max(value) AS c FROM src GROUP BY key HAVING key != 302
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_FUNCTION max (TOK_TABLE_OR_COL value)) c)) (TOK_GROUPBY (TOK_TABLE_OR_COL key)) (TOK_HAVING (!= (TOK_TABLE_OR_COL key) 302))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Filter Operator
+              predicate:
+                  expr: (key <> 302)
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: string
+                      expr: value
+                      type: string
+                outputColumnNames: key, value
+                Group By Operator
+                  aggregations:
+                        expr: max(value)
+                  bucketGroup: false
+                  keys:
+                        expr: key
+                        type: string
+                  mode: hash
+                  outputColumnNames: _col0, _col1
+                  Reduce Output Operator
+                    key expressions:
+                          expr: _col0
+                          type: string
+                    sort order: +
+                    Map-reduce partition columns:
+                          expr: _col0
+                          type: string
+                    tag: -1
+                    value expressions:
+                          expr: _col1
+                          type: string
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: max(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: mergepartial
+          outputColumnNames: _col0, _col1
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: string
+            outputColumnNames: _col0, _col1
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+PREHOOK: query: SELECT key, max(value) AS c FROM src GROUP BY key HAVING key != 302
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key, max(value) AS c FROM src GROUP BY key HAVING key != 302
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+0	val_0
+10	val_10
+100	val_100
+103	val_103
+104	val_104
+105	val_105
+11	val_11
+111	val_111
+113	val_113
+114	val_114
+116	val_116
+118	val_118
+119	val_119
+12	val_12
+120	val_120
+125	val_125
+126	val_126
+128	val_128
+129	val_129
+131	val_131
+133	val_133
+134	val_134
+136	val_136
+137	val_137
+138	val_138
+143	val_143
+145	val_145
+146	val_146
+149	val_149
+15	val_15
+150	val_150
+152	val_152
+153	val_153
+155	val_155
+156	val_156
+157	val_157
+158	val_158
+160	val_160
+162	val_162
+163	val_163
+164	val_164
+165	val_165
+166	val_166
+167	val_167
+168	val_168
+169	val_169
+17	val_17
+170	val_170
+172	val_172
+174	val_174
+175	val_175
+176	val_176
+177	val_177
+178	val_178
+179	val_179
+18	val_18
+180	val_180
+181	val_181
+183	val_183
+186	val_186
+187	val_187
+189	val_189
+19	val_19
+190	val_190
+191	val_191
+192	val_192
+193	val_193
+194	val_194
+195	val_195
+196	val_196
+197	val_197
+199	val_199
+2	val_2
+20	val_20
+200	val_200
+201	val_201
+202	val_202
+203	val_203
+205	val_205
+207	val_207
+208	val_208
+209	val_209
+213	val_213
+214	val_214
+216	val_216
+217	val_217
+218	val_218
+219	val_219
+221	val_221
+222	val_222
+223	val_223
+224	val_224
+226	val_226
+228	val_228
+229	val_229
+230	val_230
+233	val_233
+235	val_235
+237	val_237
+238	val_238
+239	val_239
+24	val_24
+241	val_241
+242	val_242
+244	val_244
+247	val_247
+248	val_248
+249	val_249
+252	val_252
+255	val_255
+256	val_256
+257	val_257
+258	val_258
+26	val_26
+260	val_260
+262	val_262
+263	val_263
+265	val_265
+266	val_266
+27	val_27
+272	val_272
+273	val_273
+274	val_274
+275	val_275
+277	val_277
+278	val_278
+28	val_28
+280	val_280
+281	val_281
+282	val_282
+283	val_283
+284	val_284
+285	val_285
+286	val_286
+287	val_287
+288	val_288
+289	val_289
+291	val_291
+292	val_292
+296	val_296
+298	val_298
+30	val_30
+305	val_305
+306	val_306
+307	val_307
+308	val_308
+309	val_309
+310	val_310
+311	val_311
+315	val_315
+316	val_316
+317	val_317
+318	val_318
+321	val_321
+322	val_322
+323	val_323
+325	val_325
+327	val_327
+33	val_33
+331	val_331
+332	val_332
+333	val_333
+335	val_335
+336	val_336
+338	val_338
+339	val_339
+34	val_34
+341	val_341
+342	val_342
+344	val_344
+345	val_345
+348	val_348
+35	val_35
+351	val_351
+353	val_353
+356	val_356
+360	val_360
+362	val_362
+364	val_364
+365	val_365
+366	val_366
+367	val_367
+368	val_368
+369	val_369
+37	val_37
+373	val_373
+374	val_374
+375	val_375
+377	val_377
+378	val_378
+379	val_379
+382	val_382
+384	val_384
+386	val_386
+389	val_389
+392	val_392
+393	val_393
+394	val_394
+395	val_395
+396	val_396
+397	val_397
+399	val_399
+4	val_4
+400	val_400
+401	val_401
+402	val_402
+403	val_403
+404	val_404
+406	val_406
+407	val_407
+409	val_409
+41	val_41
+411	val_411
+413	val_413
+414	val_414
+417	val_417
+418	val_418
+419	val_419
+42	val_42
+421	val_421
+424	val_424
+427	val_427
+429	val_429
+43	val_43
+430	val_430
+431	val_431
+432	val_432
+435	val_435
+436	val_436
+437	val_437
+438	val_438
+439	val_439
+44	val_44
+443	val_443
+444	val_444
+446	val_446
+448	val_448
+449	val_449
+452	val_452
+453	val_453
+454	val_454
+455	val_455
+457	val_457
+458	val_458
+459	val_459
+460	val_460
+462	val_462
+463	val_463
+466	val_466
+467	val_467
+468	val_468
+469	val_469
+47	val_47
+470	val_470
+472	val_472
+475	val_475
+477	val_477
+478	val_478
+479	val_479
+480	val_480
+481	val_481
+482	val_482
+483	val_483
+484	val_484
+485	val_485
+487	val_487
+489	val_489
+490	val_490
+491	val_491
+492	val_492
+493	val_493
+494	val_494
+495	val_495
+496	val_496
+497	val_497
+498	val_498
+5	val_5
+51	val_51
+53	val_53
+54	val_54
+57	val_57
+58	val_58
+64	val_64
+65	val_65
+66	val_66
+67	val_67
+69	val_69
+70	val_70
+72	val_72
+74	val_74
+76	val_76
+77	val_77
+78	val_78
+8	val_8
+80	val_80
+82	val_82
+83	val_83
+84	val_84
+85	val_85
+86	val_86
+87	val_87
+9	val_9
+90	val_90
+92	val_92
+95	val_95
+96	val_96
+97	val_97
+98	val_98
+PREHOOK: query: EXPLAIN SELECT key FROM src GROUP BY key HAVING max(value) > "val_255"
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key FROM src GROUP BY key HAVING max(value) > "val_255"
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key))) (TOK_GROUPBY (TOK_TABLE_OR_COL key)) (TOK_HAVING (> (TOK_FUNCTION max (TOK_TABLE_OR_COL value)) "val_255"))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: key, value
+              Group By Operator
+                aggregations:
+                      expr: max(value)
+                bucketGroup: false
+                keys:
+                      expr: key
+                      type: string
+                mode: hash
+                outputColumnNames: _col0, _col1
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: string
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: _col0
+                        type: string
+                  tag: -1
+                  value expressions:
+                        expr: _col1
+                        type: string
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: max(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: mergepartial
+          outputColumnNames: _col0, _col1
+          Filter Operator
+            predicate:
+                expr: (_col1 > 'val_255')
+                type: boolean
+            Select Operator
+              expressions:
+                    expr: _col0
+                    type: string
+              outputColumnNames: _col0
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+PREHOOK: query: SELECT key FROM src GROUP BY key HAVING max(value) > "val_255"
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key FROM src GROUP BY key HAVING max(value) > "val_255"
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+256
+257
+258
+26
+260
+262
+263
+265
+266
+27
+272
+273
+274
+275
+277
+278
+28
+280
+281
+282
+283
+284
+285
+286
+287
+288
+289
+291
+292
+296
+298
+30
+302
+305
+306
+307
+308
+309
+310
+311
+315
+316
+317
+318
+321
+322
+323
+325
+327
+33
+331
+332
+333
+335
+336
+338
+339
+34
+341
+342
+344
+345
+348
+35
+351
+353
+356
+360
+362
+364
+365
+366
+367
+368
+369
+37
+373
+374
+375
+377
+378
+379
+382
+384
+386
+389
+392
+393
+394
+395
+396
+397
+399
+4
+400
+401
+402
+403
+404
+406
+407
+409
+41
+411
+413
+414
+417
+418
+419
+42
+421
+424
+427
+429
+43
+430
+431
+432
+435
+436
+437
+438
+439
+44
+443
+444
+446
+448
+449
+452
+453
+454
+455
+457
+458
+459
+460
+462
+463
+466
+467
+468
+469
+47
+470
+472
+475
+477
+478
+479
+480
+481
+482
+483
+484
+485
+487
+489
+490
+491
+492
+493
+494
+495
+496
+497
+498
+5
+51
+53
+54
+57
+58
+64
+65
+66
+67
+69
+70
+72
+74
+76
+77
+78
+8
+80
+82
+83
+84
+85
+86
+87
+9
+90
+92
+95
+96
+97
+98
+PREHOOK: query: EXPLAIN SELECT key FROM src where key > 300 GROUP BY key HAVING max(value) > "val_255"
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key FROM src where key > 300 GROUP BY key HAVING max(value) > "val_255"
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key))) (TOK_WHERE (> (TOK_TABLE_OR_COL key) 300)) (TOK_GROUPBY (TOK_TABLE_OR_COL key)) (TOK_HAVING (> (TOK_FUNCTION max (TOK_TABLE_OR_COL value)) "val_255"))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Filter Operator
+              predicate:
+                  expr: (key > 300)
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: string
+                      expr: value
+                      type: string
+                outputColumnNames: key, value
+                Group By Operator
+                  aggregations:
+                        expr: max(value)
+                  bucketGroup: false
+                  keys:
+                        expr: key
+                        type: string
+                  mode: hash
+                  outputColumnNames: _col0, _col1
+                  Reduce Output Operator
+                    key expressions:
+                          expr: _col0
+                          type: string
+                    sort order: +
+                    Map-reduce partition columns:
+                          expr: _col0
+                          type: string
+                    tag: -1
+                    value expressions:
+                          expr: _col1
+                          type: string
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: max(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: mergepartial
+          outputColumnNames: _col0, _col1
+          Filter Operator
+            predicate:
+                expr: (_col1 > 'val_255')
+                type: boolean
+            Select Operator
+              expressions:
+                    expr: _col0
+                    type: string
+              outputColumnNames: _col0
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+PREHOOK: query: SELECT key FROM src where key > 300 GROUP BY key HAVING max(value) > "val_255"
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key FROM src where key > 300 GROUP BY key HAVING max(value) > "val_255"
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+302
+305
+306
+307
+308
+309
+310
+311
+315
+316
+317
+318
+321
+322
+323
+325
+327
+331
+332
+333
+335
+336
+338
+339
+341
+342
+344
+345
+348
+351
+353
+356
+360
+362
+364
+365
+366
+367
+368
+369
+373
+374
+375
+377
+378
+379
+382
+384
+386
+389
+392
+393
+394
+395
+396
+397
+399
+400
+401
+402
+403
+404
+406
+407
+409
+411
+413
+414
+417
+418
+419
+421
+424
+427
+429
+430
+431
+432
+435
+436
+437
+438
+439
+443
+444
+446
+448
+449
+452
+453
+454
+455
+457
+458
+459
+460
+462
+463
+466
+467
+468
+469
+470
+472
+475
+477
+478
+479
+480
+481
+482
+483
+484
+485
+487
+489
+490
+491
+492
+493
+494
+495
+496
+497
+498
+PREHOOK: query: EXPLAIN SELECT key, max(value) FROM src GROUP BY key HAVING max(value) > "val_255"
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN SELECT key, max(value) FROM src GROUP BY key HAVING max(value) > "val_255"
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_FUNCTION max (TOK_TABLE_OR_COL value)))) (TOK_GROUPBY (TOK_TABLE_OR_COL key)) (TOK_HAVING (> (TOK_FUNCTION max (TOK_TABLE_OR_COL value)) "val_255"))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: key, value
+              Group By Operator
+                aggregations:
+                      expr: max(value)
+                bucketGroup: false
+                keys:
+                      expr: key
+                      type: string
+                mode: hash
+                outputColumnNames: _col0, _col1
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: string
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: _col0
+                        type: string
+                  tag: -1
+                  value expressions:
+                        expr: _col1
+                        type: string
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: max(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: mergepartial
+          outputColumnNames: _col0, _col1
+          Filter Operator
+            predicate:
+                expr: (_col1 > 'val_255')
+                type: boolean
+            Select Operator
+              expressions:
+                    expr: _col0
+                    type: string
+                    expr: _col1
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+PREHOOK: query: SELECT key, max(value) FROM src GROUP BY key HAVING max(value) > "val_255"
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT key, max(value) FROM src GROUP BY key HAVING max(value) > "val_255"
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+256	val_256
+257	val_257
+258	val_258
+26	val_26
+260	val_260
+262	val_262
+263	val_263
+265	val_265
+266	val_266
+27	val_27
+272	val_272
+273	val_273
+274	val_274
+275	val_275
+277	val_277
+278	val_278
+28	val_28
+280	val_280
+281	val_281
+282	val_282
+283	val_283
+284	val_284
+285	val_285
+286	val_286
+287	val_287
+288	val_288
+289	val_289
+291	val_291
+292	val_292
+296	val_296
+298	val_298
+30	val_30
+302	val_302
+305	val_305
+306	val_306
+307	val_307
+308	val_308
+309	val_309
+310	val_310
+311	val_311
+315	val_315
+316	val_316
+317	val_317
+318	val_318
+321	val_321
+322	val_322
+323	val_323
+325	val_325
+327	val_327
+33	val_33
+331	val_331
+332	val_332
+333	val_333
+335	val_335
+336	val_336
+338	val_338
+339	val_339
+34	val_34
+341	val_341
+342	val_342
+344	val_344
+345	val_345
+348	val_348
+35	val_35
+351	val_351
+353	val_353
+356	val_356
+360	val_360
+362	val_362
+364	val_364
+365	val_365
+366	val_366
+367	val_367
+368	val_368
+369	val_369
+37	val_37
+373	val_373
+374	val_374
+375	val_375
+377	val_377
+378	val_378
+379	val_379
+382	val_382
+384	val_384
+386	val_386
+389	val_389
+392	val_392
+393	val_393
+394	val_394
+395	val_395
+396	val_396
+397	val_397
+399	val_399
+4	val_4
+400	val_400
+401	val_401
+402	val_402
+403	val_403
+404	val_404
+406	val_406
+407	val_407
+409	val_409
+41	val_41
+411	val_411
+413	val_413
+414	val_414
+417	val_417
+418	val_418
+419	val_419
+42	val_42
+421	val_421
+424	val_424
+427	val_427
+429	val_429
+43	val_43
+430	val_430
+431	val_431
+432	val_432
+435	val_435
+436	val_436
+437	val_437
+438	val_438
+439	val_439
+44	val_44
+443	val_443
+444	val_444
+446	val_446
+448	val_448
+449	val_449
+452	val_452
+453	val_453
+454	val_454
+455	val_455
+457	val_457
+458	val_458
+459	val_459
+460	val_460
+462	val_462
+463	val_463
+466	val_466
+467	val_467
+468	val_468
+469	val_469
+47	val_47
+470	val_470
+472	val_472
+475	val_475
+477	val_477
+478	val_478
+479	val_479
+480	val_480
+481	val_481
+482	val_482
+483	val_483
+484	val_484
+485	val_485
+487	val_487
+489	val_489
+490	val_490
+491	val_491
+492	val_492
+493	val_493
+494	val_494
+495	val_495
+496	val_496
+497	val_497
+498	val_498
+5	val_5
+51	val_51
+53	val_53
+54	val_54
+57	val_57
+58	val_58
+64	val_64
+65	val_65
+66	val_66
+67	val_67
+69	val_69
+70	val_70
+72	val_72
+74	val_74
+76	val_76
+77	val_77
+78	val_78
+8	val_8
+80	val_80
+82	val_82
+83	val_83
+84	val_84
+85	val_85
+86	val_86
+87	val_87
+9	val_9
+90	val_90
+92	val_92
+95	val_95
+96	val_96
+97	val_97
+98	val_98
diff --git a/ql/src/test/results/clientpositive/tez/insert1.q.out b/ql/src/test/results/clientpositive/tez/insert1.q.out
new file mode 100644
index 0000000000..8f1a9e7a82
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/insert1.q.out
@@ -0,0 +1,779 @@
+PREHOOK: query: create table insert1(key int, value string) stored as textfile
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table insert1(key int, value string) stored as textfile
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@insert1
+PREHOOK: query: create table insert2(key int, value string) stored as textfile
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table insert2(key int, value string) stored as textfile
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@insert2
+PREHOOK: query: insert overwrite table insert1 select a.key, a.value from insert2 a WHERE (a.key=-1)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert2
+PREHOOK: Output: default@insert1
+POSTHOOK: query: insert overwrite table insert1 select a.key, a.value from insert2 a WHERE (a.key=-1)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert2
+POSTHOOK: Output: default@insert1
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: explain insert into table insert1 select a.key, a.value from insert2 a WHERE (a.key=-1)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain insert into table insert1 select a.key, a.value from insert2 a WHERE (a.key=-1)
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME insert2) a)) (TOK_INSERT (TOK_INSERT_INTO (TOK_TAB (TOK_TABNAME insert1))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value))) (TOK_WHERE (= (. (TOK_TABLE_OR_COL a) key) (- 1)))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Filter Operator
+              predicate:
+                  expr: (key = (- 1))
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: int
+                      expr: value
+                      type: string
+                outputColumnNames: _col0, _col1
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: default.insert1
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: false
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.insert1
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert1
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert1
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: explain insert into table INSERT1 select a.key, a.value from insert2 a WHERE (a.key=-1)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain insert into table INSERT1 select a.key, a.value from insert2 a WHERE (a.key=-1)
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME insert2) a)) (TOK_INSERT (TOK_INSERT_INTO (TOK_TAB (TOK_TABNAME INSERT1))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value))) (TOK_WHERE (= (. (TOK_TABLE_OR_COL a) key) (- 1)))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Filter Operator
+              predicate:
+                  expr: (key = (- 1))
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: int
+                      expr: value
+                      type: string
+                outputColumnNames: _col0, _col1
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: default.insert1
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: false
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.insert1
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert1
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert1
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: -- HIVE-3465
+create database x
+PREHOOK: type: CREATEDATABASE
+POSTHOOK: query: -- HIVE-3465
+create database x
+POSTHOOK: type: CREATEDATABASE
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: create table x.insert1(key int, value string) stored as textfile
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table x.insert1(key int, value string) stored as textfile
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: x@insert1
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: explain insert into table x.INSERT1 select a.key, a.value from insert2 a WHERE (a.key=-1)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain insert into table x.INSERT1 select a.key, a.value from insert2 a WHERE (a.key=-1)
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME insert2) a)) (TOK_INSERT (TOK_INSERT_INTO (TOK_TAB (TOK_TABNAME x INSERT1))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value))) (TOK_WHERE (= (. (TOK_TABLE_OR_COL a) key) (- 1)))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Filter Operator
+              predicate:
+                  expr: (key = (- 1))
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: int
+                      expr: value
+                      type: string
+                outputColumnNames: _col0, _col1
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: x.insert1
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: false
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: x.insert1
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: x.insert1
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: x.insert1
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: explain insert into table default.INSERT1 select a.key, a.value from insert2 a WHERE (a.key=-1)
+PREHOOK: type: QUERY
+POSTHOOK: query: explain insert into table default.INSERT1 select a.key, a.value from insert2 a WHERE (a.key=-1)
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME insert2) a)) (TOK_INSERT (TOK_INSERT_INTO (TOK_TAB (TOK_TABNAME default INSERT1))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value))) (TOK_WHERE (= (. (TOK_TABLE_OR_COL a) key) (- 1)))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Filter Operator
+              predicate:
+                  expr: (key = (- 1))
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: int
+                      expr: value
+                      type: string
+                outputColumnNames: _col0, _col1
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: default.insert1
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: false
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.insert1
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert1
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert1
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: explain
+from insert2
+insert into table insert1 select * where key < 10
+insert overwrite table x.insert1 select * where key > 10 and key < 20
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+from insert2
+insert into table insert1 select * where key < 10
+insert overwrite table x.insert1 select * where key > 10 and key < 20
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME insert2))) (TOK_INSERT (TOK_INSERT_INTO (TOK_TAB (TOK_TABNAME insert1))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_WHERE (< (TOK_TABLE_OR_COL key) 10))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME x insert1))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_WHERE (and (> (TOK_TABLE_OR_COL key) 10) (< (TOK_TABLE_OR_COL key) 20)))))
+
+STAGE DEPENDENCIES:
+  Stage-2 is a root stage
+  Stage-9 depends on stages: Stage-2 , consists of Stage-6, Stage-5, Stage-7
+  Stage-6
+  Stage-3 depends on stages: Stage-6, Stage-5, Stage-8, Stage-12, Stage-11, Stage-14
+  Stage-0 depends on stages: Stage-3
+  Stage-4 depends on stages: Stage-0
+  Stage-1 depends on stages: Stage-3
+  Stage-10 depends on stages: Stage-1
+  Stage-5
+  Stage-7
+  Stage-8 depends on stages: Stage-7
+  Stage-15 depends on stages: Stage-2 , consists of Stage-12, Stage-11, Stage-13
+  Stage-12
+  Stage-11
+  Stage-13
+  Stage-14 depends on stages: Stage-13
+
+STAGE PLANS:
+  Stage: Stage-2
+    Tez
+      Alias -> Map Operator Tree:
+        insert2 
+          TableScan
+            alias: insert2
+            Filter Operator
+              predicate:
+                  expr: (key < 10)
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: int
+                      expr: value
+                      type: string
+                outputColumnNames: _col0, _col1
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: default.insert1
+            Filter Operator
+              predicate:
+                  expr: ((key > 10) and (key < 20))
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: int
+                      expr: value
+                      type: string
+                outputColumnNames: _col0, _col1
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 2
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: x.insert1
+
+  Stage: Stage-9
+    Conditional Operator
+
+  Stage: Stage-6
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-3
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: false
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.insert1
+
+  Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-1
+    Move Operator
+      tables:
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: x.insert1
+
+  Stage: Stage-10
+    Stats-Aggr Operator
+
+  Stage: Stage-5
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert1
+
+  Stage: Stage-7
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert1
+
+  Stage: Stage-8
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-15
+    Conditional Operator
+
+  Stage: Stage-12
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-11
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: x.insert1
+
+  Stage: Stage-13
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: x.insert1
+
+  Stage: Stage-14
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: -- HIVE-3676
+CREATE DATABASE db2
+PREHOOK: type: CREATEDATABASE
+POSTHOOK: query: -- HIVE-3676
+CREATE DATABASE db2
+POSTHOOK: type: CREATEDATABASE
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: USE db2
+PREHOOK: type: SWITCHDATABASE
+POSTHOOK: query: USE db2
+POSTHOOK: type: SWITCHDATABASE
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: CREATE TABLE result(col1 STRING)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE result(col1 STRING)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: db2@result
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: INSERT OVERWRITE TABLE result SELECT 'db2_insert1' FROM default.src LIMIT 1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: db2@result
+POSTHOOK: query: INSERT OVERWRITE TABLE result SELECT 'db2_insert1' FROM default.src LIMIT 1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: db2@result
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: result.col1 SIMPLE []
+PREHOOK: query: INSERT INTO TABLE result SELECT 'db2_insert2' FROM default.src LIMIT 1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: db2@result
+POSTHOOK: query: INSERT INTO TABLE result SELECT 'db2_insert2' FROM default.src LIMIT 1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: db2@result
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+PREHOOK: query: SELECT * FROM result order by col1
+PREHOOK: type: QUERY
+PREHOOK: Input: db2@result
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM result order by col1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: db2@result
+#### A masked pattern was here ####
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+db2_insert1
+db2_insert2
+PREHOOK: query: USE default
+PREHOOK: type: SWITCHDATABASE
+POSTHOOK: query: USE default
+POSTHOOK: type: SWITCHDATABASE
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+PREHOOK: query: CREATE DATABASE db1
+PREHOOK: type: CREATEDATABASE
+POSTHOOK: query: CREATE DATABASE db1
+POSTHOOK: type: CREATEDATABASE
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+PREHOOK: query: CREATE TABLE db1.result(col1 STRING)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE db1.result(col1 STRING)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: db1@result
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+PREHOOK: query: INSERT OVERWRITE TABLE db1.result SELECT 'db1_insert1' FROM src LIMIT 1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: db1@result
+POSTHOOK: query: INSERT OVERWRITE TABLE db1.result SELECT 'db1_insert1' FROM src LIMIT 1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: db1@result
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+PREHOOK: query: INSERT INTO TABLE db1.result SELECT 'db1_insert2' FROM src LIMIT 1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: db1@result
+POSTHOOK: query: INSERT INTO TABLE db1.result SELECT 'db1_insert2' FROM src LIMIT 1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: db1@result
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+PREHOOK: query: SELECT * FROM db1.result order by col1
+PREHOOK: type: QUERY
+PREHOOK: Input: db1@result
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM db1.result order by col1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: db1@result
+#### A masked pattern was here ####
+POSTHOOK: Lineage: insert1.key SIMPLE [(insert2)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: insert1.value SIMPLE [(insert2)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+POSTHOOK: Lineage: result.col1 SIMPLE []
+db1_insert1
+db1_insert2
diff --git a/ql/src/test/results/clientpositive/tez/insert_into1.q.out b/ql/src/test/results/clientpositive/tez/insert_into1.q.out
new file mode 100644
index 0000000000..fa324be706
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/insert_into1.q.out
@@ -0,0 +1,486 @@
+PREHOOK: query: DROP TABLE insert_into1
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: DROP TABLE insert_into1
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: CREATE TABLE insert_into1 (key int, value string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE insert_into1 (key int, value string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@insert_into1
+PREHOOK: query: EXPLAIN INSERT INTO TABLE insert_into1 SELECT * from src LIMIT 100
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN INSERT INTO TABLE insert_into1 SELECT * from src LIMIT 100
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_INSERT_INTO (TOK_TAB (TOK_TABNAME insert_into1))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 100)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Limit
+                Reduce Output Operator
+                  sort order: 
+                  tag: -1
+                  value expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+      Reduce Operator Tree:
+        Extract
+          Limit
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(_col0)
+                    type: int
+                    expr: _col1
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: default.insert_into1
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: false
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.insert_into1
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into1
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into1
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: INSERT INTO TABLE insert_into1 SELECT * from src LIMIT 100
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@insert_into1
+POSTHOOK: query: INSERT INTO TABLE insert_into1 SELECT * from src LIMIT 100
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@insert_into1
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into1
+) t
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into1
+) t
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+10226524244
+PREHOOK: query: EXPLAIN INSERT INTO TABLE insert_into1 SELECT * FROM src LIMIT 100
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN INSERT INTO TABLE insert_into1 SELECT * FROM src LIMIT 100
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_INSERT_INTO (TOK_TAB (TOK_TABNAME insert_into1))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 100)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Limit
+                Reduce Output Operator
+                  sort order: 
+                  tag: -1
+                  value expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+      Reduce Operator Tree:
+        Extract
+          Limit
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(_col0)
+                    type: int
+                    expr: _col1
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: default.insert_into1
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: false
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.insert_into1
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into1
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into1
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: INSERT INTO TABLE insert_into1 SELECT * FROM src LIMIT 100
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@insert_into1
+POSTHOOK: query: INSERT INTO TABLE insert_into1 SELECT * FROM src LIMIT 100
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@insert_into1
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into1
+) t
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into1
+) t
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+20453048488
+PREHOOK: query: SELECT COUNT(*) FROM insert_into1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT COUNT(*) FROM insert_into1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+200
+PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE insert_into1 SELECT * FROM src LIMIT 10
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN INSERT OVERWRITE TABLE insert_into1 SELECT * FROM src LIMIT 10
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME insert_into1))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 10)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Limit
+                Reduce Output Operator
+                  sort order: 
+                  tag: -1
+                  value expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+      Reduce Operator Tree:
+        Extract
+          Limit
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(_col0)
+                    type: int
+                    expr: _col1
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: default.insert_into1
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.insert_into1
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into1
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into1
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: INSERT OVERWRITE TABLE insert_into1 SELECT * FROM src LIMIT 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@insert_into1
+POSTHOOK: query: INSERT OVERWRITE TABLE insert_into1 SELECT * FROM src LIMIT 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@insert_into1
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into1
+) t
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into1
+) t
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into1
+#### A masked pattern was here ####
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+-826625916
+PREHOOK: query: DROP TABLE insert_into1
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@insert_into1
+PREHOOK: Output: default@insert_into1
+POSTHOOK: query: DROP TABLE insert_into1
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@insert_into1
+POSTHOOK: Output: default@insert_into1
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
diff --git a/ql/src/test/results/clientpositive/tez/insert_into2.q.out b/ql/src/test/results/clientpositive/tez/insert_into2.q.out
new file mode 100644
index 0000000000..9680bcda7a
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/insert_into2.q.out
@@ -0,0 +1,544 @@
+PREHOOK: query: DROP TABLE insert_into2
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: DROP TABLE insert_into2
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: CREATE TABLE insert_into2 (key int, value string) 
+  PARTITIONED BY (ds string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE insert_into2 (key int, value string) 
+  PARTITIONED BY (ds string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@insert_into2
+PREHOOK: query: EXPLAIN INSERT INTO TABLE insert_into2 PARTITION (ds='1') 
+  SELECT * FROM src LIMIT 100
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN INSERT INTO TABLE insert_into2 PARTITION (ds='1') 
+  SELECT * FROM src LIMIT 100
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_INSERT_INTO (TOK_TAB (TOK_TABNAME insert_into2) (TOK_PARTSPEC (TOK_PARTVAL ds '1')))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 100)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Limit
+                Reduce Output Operator
+                  sort order: 
+                  tag: -1
+                  value expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+      Reduce Operator Tree:
+        Extract
+          Limit
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(_col0)
+                    type: int
+                    expr: _col1
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: default.insert_into2
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          partition:
+            ds 1
+          replace: false
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.insert_into2
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into2
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into2
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: INSERT INTO TABLE insert_into2 PARTITION (ds='1') SELECT * FROM src limit 100
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@insert_into2@ds=1
+POSTHOOK: query: INSERT INTO TABLE insert_into2 PARTITION (ds='1') SELECT * FROM src limit 100
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@insert_into2@ds=1
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: INSERT INTO TABLE insert_into2 PARTITION (ds='1') SELECT * FROM src limit 100
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@insert_into2@ds=1
+POSTHOOK: query: INSERT INTO TABLE insert_into2 PARTITION (ds='1') SELECT * FROM src limit 100
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@insert_into2@ds=1
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='1'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into2
+PREHOOK: Input: default@insert_into2@ds=1
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT COUNT(*) FROM insert_into2 WHERE ds='1'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into2
+POSTHOOK: Input: default@insert_into2@ds=1
+#### A masked pattern was here ####
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+200
+PREHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into2
+) t
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into2
+PREHOOK: Input: default@insert_into2@ds=1
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into2
+) t
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into2
+POSTHOOK: Input: default@insert_into2@ds=1
+#### A masked pattern was here ####
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+-24159954504
+PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
+  SELECT * FROM src LIMIT 100
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
+  SELECT * FROM src LIMIT 100
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME insert_into2) (TOK_PARTSPEC (TOK_PARTVAL ds '2')))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 100)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Limit
+                Reduce Output Operator
+                  sort order: 
+                  tag: -1
+                  value expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+      Reduce Operator Tree:
+        Extract
+          Limit
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(_col0)
+                    type: int
+                    expr: _col1
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: default.insert_into2
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          partition:
+            ds 2
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.insert_into2
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into2
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into2
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
+  SELECT * FROM src LIMIT 100
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@insert_into2@ds=2
+POSTHOOK: query: INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
+  SELECT * FROM src LIMIT 100
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@insert_into2@ds=2
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into2
+) t
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into2
+PREHOOK: Input: default@insert_into2@ds=1
+PREHOOK: Input: default@insert_into2@ds=2
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into2
+) t
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into2
+POSTHOOK: Input: default@insert_into2@ds=1
+POSTHOOK: Input: default@insert_into2@ds=2
+#### A masked pattern was here ####
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+-36239931656
+PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
+  SELECT * FROM src LIMIT 50
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
+  SELECT * FROM src LIMIT 50
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME insert_into2) (TOK_PARTSPEC (TOK_PARTVAL ds '2')))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 50)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-8 depends on stages: Stage-1 , consists of Stage-5, Stage-4, Stage-6
+  Stage-5
+  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-6
+  Stage-7 depends on stages: Stage-6
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Limit
+                Reduce Output Operator
+                  sort order: 
+                  tag: -1
+                  value expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+      Reduce Operator Tree:
+        Extract
+          Limit
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(_col0)
+                    type: int
+                    expr: _col1
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: default.insert_into2
+
+  Stage: Stage-8
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+  Stage: Stage-2
+    Dependency Collection
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          partition:
+            ds 2
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: default.insert_into2
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into2
+
+  Stage: Stage-6
+    Tez
+      Alias -> Map Operator Tree:
+#### A masked pattern was here ####
+          TableScan
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.insert_into2
+
+  Stage: Stage-7
+    Move Operator
+      files:
+          hdfs directory: true
+#### A masked pattern was here ####
+
+PREHOOK: query: INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
+  SELECT * FROM src LIMIT 50
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@insert_into2@ds=2
+POSTHOOK: query: INSERT OVERWRITE TABLE insert_into2 PARTITION (ds='2')
+  SELECT * FROM src LIMIT 50
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@insert_into2@ds=2
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into2
+) t
+PREHOOK: type: QUERY
+PREHOOK: Input: default@insert_into2
+PREHOOK: Input: default@insert_into2@ds=1
+PREHOOK: Input: default@insert_into2@ds=2
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT SUM(HASH(c)) FROM (
+    SELECT TRANSFORM(*) USING 'tr \t _' AS (c) FROM insert_into2
+) t
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@insert_into2
+POSTHOOK: Input: default@insert_into2@ds=1
+POSTHOOK: Input: default@insert_into2@ds=2
+#### A masked pattern was here ####
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+-27100860056
+PREHOOK: query: DROP TABLE insert_into2
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@insert_into2
+PREHOOK: Output: default@insert_into2
+POSTHOOK: query: DROP TABLE insert_into2
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@insert_into2
+POSTHOOK: Output: default@insert_into2
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: insert_into2 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
diff --git a/ql/src/test/results/clientpositive/tez/leftsemijoin.q.out b/ql/src/test/results/clientpositive/tez/leftsemijoin.q.out
new file mode 100644
index 0000000000..d8ecfbfca9
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/leftsemijoin.q.out
@@ -0,0 +1,98 @@
+PREHOOK: query: drop table sales
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table sales
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: drop table things
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table things
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: CREATE TABLE sales (name STRING, id INT)
+ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE sales (name STRING, id INT)
+ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@sales
+PREHOOK: query: CREATE TABLE things (id INT, name STRING) partitioned by (ds string)
+ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE things (id INT, name STRING) partitioned by (ds string)
+ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@things
+PREHOOK: query: load data local inpath '../../data/files/sales.txt' INTO TABLE sales
+PREHOOK: type: LOAD
+PREHOOK: Output: default@sales
+POSTHOOK: query: load data local inpath '../../data/files/sales.txt' INTO TABLE sales
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@sales
+PREHOOK: query: load data local inpath '../../data/files/things.txt' INTO TABLE things partition(ds='2011-10-23')
+PREHOOK: type: LOAD
+PREHOOK: Output: default@things
+POSTHOOK: query: load data local inpath '../../data/files/things.txt' INTO TABLE things partition(ds='2011-10-23')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@things
+POSTHOOK: Output: default@things@ds=2011-10-23
+PREHOOK: query: load data local inpath '../../data/files/things2.txt' INTO TABLE things partition(ds='2011-10-24')
+PREHOOK: type: LOAD
+PREHOOK: Output: default@things
+POSTHOOK: query: load data local inpath '../../data/files/things2.txt' INTO TABLE things partition(ds='2011-10-24')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@things
+POSTHOOK: Output: default@things@ds=2011-10-24
+PREHOOK: query: SELECT name,id FROM sales ORDER BY name ASC, id ASC
+PREHOOK: type: QUERY
+PREHOOK: Input: default@sales
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT name,id FROM sales ORDER BY name ASC, id ASC
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@sales
+#### A masked pattern was here ####
+Hank	2
+Joe	2
+PREHOOK: query: SELECT id,name FROM things ORDER BY id ASC, name ASC
+PREHOOK: type: QUERY
+PREHOOK: Input: default@things
+PREHOOK: Input: default@things@ds=2011-10-23
+PREHOOK: Input: default@things@ds=2011-10-24
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT id,name FROM things ORDER BY id ASC, name ASC
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@things
+POSTHOOK: Input: default@things@ds=2011-10-23
+POSTHOOK: Input: default@things@ds=2011-10-24
+#### A masked pattern was here ####
+2	Tie
+2	Tie
+PREHOOK: query: SELECT name,id FROM sales LEFT SEMI JOIN things ON (sales.id = things.id) ORDER BY name ASC, id ASC
+PREHOOK: type: QUERY
+PREHOOK: Input: default@sales
+PREHOOK: Input: default@things
+PREHOOK: Input: default@things@ds=2011-10-23
+PREHOOK: Input: default@things@ds=2011-10-24
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT name,id FROM sales LEFT SEMI JOIN things ON (sales.id = things.id) ORDER BY name ASC, id ASC
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@sales
+POSTHOOK: Input: default@things
+POSTHOOK: Input: default@things@ds=2011-10-23
+POSTHOOK: Input: default@things@ds=2011-10-24
+#### A masked pattern was here ####
+Hank	2
+Joe	2
+PREHOOK: query: drop table sales
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@sales
+PREHOOK: Output: default@sales
+POSTHOOK: query: drop table sales
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@sales
+POSTHOOK: Output: default@sales
+PREHOOK: query: drop table things
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@things
+PREHOOK: Output: default@things
+POSTHOOK: query: drop table things
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@things
+POSTHOOK: Output: default@things
diff --git a/ql/src/test/results/clientpositive/tez/limit_pushdown.q.out b/ql/src/test/results/clientpositive/tez/limit_pushdown.q.out
new file mode 100644
index 0000000000..2f7ae00a7f
--- /dev/null
+++ b/ql/src/test/results/clientpositive/tez/limit_pushdown.q.out
@@ -0,0 +1,1584 @@
+PREHOOK: query: -- HIVE-3562 Some limit can be pushed down to map stage
+
+explain
+select key,value from src order by key limit 20
+PREHOOK: type: QUERY
+POSTHOOK: query: -- HIVE-3562 Some limit can be pushed down to map stage
+
+explain
+select key,value from src order by key limit 20
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value))) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL key))) (TOK_LIMIT 20)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Reduce Output Operator
+                key expressions:
+                      expr: _col0
+                      type: string
+                sort order: +
+                tag: -1
+                TopN: 20
+                TopN Hash Memory Usage: 0.3
+                value expressions:
+                      expr: _col0
+                      type: string
+                      expr: _col1
+                      type: string
+      Reduce Operator Tree:
+        Extract
+          Limit
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 20
+
+PREHOOK: query: select key,value from src order by key limit 20
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: select key,value from src order by key limit 20
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+0	val_0
+0	val_0
+0	val_0
+10	val_10
+100	val_100
+100	val_100
+103	val_103
+103	val_103
+104	val_104
+104	val_104
+105	val_105
+11	val_11
+111	val_111
+113	val_113
+113	val_113
+114	val_114
+116	val_116
+118	val_118
+118	val_118
+119	val_119
+PREHOOK: query: explain
+select key,value from src order by key desc limit 20
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+select key,value from src order by key desc limit 20
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value))) (TOK_ORDERBY (TOK_TABSORTCOLNAMEDESC (TOK_TABLE_OR_COL key))) (TOK_LIMIT 20)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Reduce Output Operator
+                key expressions:
+                      expr: _col0
+                      type: string
+                sort order: -
+                tag: -1
+                TopN: 20
+                TopN Hash Memory Usage: 0.3
+                value expressions:
+                      expr: _col0
+                      type: string
+                      expr: _col1
+                      type: string
+      Reduce Operator Tree:
+        Extract
+          Limit
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 20
+
+PREHOOK: query: select key,value from src order by key desc limit 20
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: select key,value from src order by key desc limit 20
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+98	val_98
+98	val_98
+97	val_97
+97	val_97
+96	val_96
+95	val_95
+95	val_95
+92	val_92
+90	val_90
+90	val_90
+90	val_90
+9	val_9
+87	val_87
+86	val_86
+85	val_85
+84	val_84
+84	val_84
+83	val_83
+83	val_83
+82	val_82
+PREHOOK: query: explain
+select value, sum(key + 1) as sum from src group by value limit 20
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+select value, sum(key + 1) as sum from src group by value limit 20
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_FUNCTION sum (+ (TOK_TABLE_OR_COL key) 1)) sum)) (TOK_GROUPBY (TOK_TABLE_OR_COL value)) (TOK_LIMIT 20)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: value
+                    type: string
+                    expr: key
+                    type: string
+              outputColumnNames: value, key
+              Group By Operator
+                aggregations:
+                      expr: sum((key + 1))
+                bucketGroup: false
+                keys:
+                      expr: value
+                      type: string
+                mode: hash
+                outputColumnNames: _col0, _col1
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: string
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: _col0
+                        type: string
+                  tag: -1
+                  TopN: 20
+                  TopN Hash Memory Usage: 0.3
+                  value expressions:
+                        expr: _col1
+                        type: double
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: sum(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: mergepartial
+          outputColumnNames: _col0, _col1
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: double
+            outputColumnNames: _col0, _col1
+            Limit
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 20
+
+PREHOOK: query: select value, sum(key + 1) as sum from src group by value limit 20
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: select value, sum(key + 1) as sum from src group by value limit 20
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+val_0	3.0
+val_10	11.0
+val_100	202.0
+val_103	208.0
+val_104	210.0
+val_105	106.0
+val_11	12.0
+val_111	112.0
+val_113	228.0
+val_114	115.0
+val_116	117.0
+val_118	238.0
+val_119	360.0
+val_12	26.0
+val_120	242.0
+val_125	252.0
+val_126	127.0
+val_128	387.0
+val_129	260.0
+val_131	132.0
+PREHOOK: query: -- deduped RS
+explain
+select value,avg(key + 1) from src group by value order by value limit 20
+PREHOOK: type: QUERY
+POSTHOOK: query: -- deduped RS
+explain
+select value,avg(key + 1) from src group by value order by value limit 20
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_FUNCTION avg (+ (TOK_TABLE_OR_COL key) 1)))) (TOK_GROUPBY (TOK_TABLE_OR_COL value)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value))) (TOK_LIMIT 20)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: value
+                    type: string
+                    expr: key
+                    type: string
+              outputColumnNames: value, key
+              Group By Operator
+                aggregations:
+                      expr: avg((key + 1))
+                bucketGroup: false
+                keys:
+                      expr: value
+                      type: string
+                mode: hash
+                outputColumnNames: _col0, _col1
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: string
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: _col0
+                        type: string
+                  tag: -1
+                  TopN: 20
+                  TopN Hash Memory Usage: 0.3
+                  value expressions:
+                        expr: _col1
+                        type: struct<count:bigint,sum:double>
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: avg(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: mergepartial
+          outputColumnNames: _col0, _col1
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: double
+            outputColumnNames: _col0, _col1
+            Limit
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 20
+
+PREHOOK: query: select value,avg(key + 1) from src group by value order by value limit 20
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: select value,avg(key + 1) from src group by value order by value limit 20
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+val_0	1.0
+val_10	11.0
+val_100	101.0
+val_103	104.0
+val_104	105.0
+val_105	106.0
+val_11	12.0
+val_111	112.0
+val_113	114.0
+val_114	115.0
+val_116	117.0
+val_118	119.0
+val_119	120.0
+val_12	13.0
+val_120	121.0
+val_125	126.0
+val_126	127.0
+val_128	129.0
+val_129	130.0
+val_131	132.0
+PREHOOK: query: -- distincts
+explain
+select distinct(cdouble) from alltypesorc limit 20
+PREHOOK: type: QUERY
+POSTHOOK: query: -- distincts
+explain
+select distinct(cdouble) from alltypesorc limit 20
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME alltypesorc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECTDI (TOK_SELEXPR (TOK_TABLE_OR_COL cdouble))) (TOK_LIMIT 20)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        alltypesorc 
+          TableScan
+            alias: alltypesorc
+            Select Operator
+              expressions:
+                    expr: cdouble
+                    type: double
+              outputColumnNames: cdouble
+              Group By Operator
+                bucketGroup: false
+                keys:
+                      expr: cdouble
+                      type: double
+                mode: hash
+                outputColumnNames: _col0
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: double
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: _col0
+                        type: double
+                  tag: -1
+                  TopN: 20
+                  TopN Hash Memory Usage: 0.3
+      Reduce Operator Tree:
+        Group By Operator
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: double
+          mode: mergepartial
+          outputColumnNames: _col0
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: double
+            outputColumnNames: _col0
+            Limit
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 20
+
+PREHOOK: query: select distinct(cdouble) from alltypesorc limit 20
+PREHOOK: type: QUERY
+PREHOOK: Input: default@alltypesorc
+#### A masked pattern was here ####
+POSTHOOK: query: select distinct(cdouble) from alltypesorc limit 20
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@alltypesorc
+#### A masked pattern was here ####
+NULL
+-16379.0
+-16373.0
+-16372.0
+-16369.0
+-16355.0
+-16339.0
+-16324.0
+-16311.0
+-16310.0
+-16309.0
+-16307.0
+-16306.0
+-16305.0
+-16300.0
+-16296.0
+-16280.0
+-16277.0
+-16274.0
+-16269.0
+PREHOOK: query: explain
+select ctinyint, count(distinct(cdouble)) from alltypesorc group by ctinyint limit 20
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+select ctinyint, count(distinct(cdouble)) from alltypesorc group by ctinyint limit 20
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME alltypesorc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL ctinyint)) (TOK_SELEXPR (TOK_FUNCTIONDI count (TOK_TABLE_OR_COL cdouble)))) (TOK_GROUPBY (TOK_TABLE_OR_COL ctinyint)) (TOK_LIMIT 20)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        alltypesorc 
+          TableScan
+            alias: alltypesorc
+            Select Operator
+              expressions:
+                    expr: ctinyint
+                    type: tinyint
+                    expr: cdouble
+                    type: double
+              outputColumnNames: ctinyint, cdouble
+              Group By Operator
+                aggregations:
+                      expr: count(DISTINCT cdouble)
+                bucketGroup: false
+                keys:
+                      expr: ctinyint
+                      type: tinyint
+                      expr: cdouble
+                      type: double
+                mode: hash
+                outputColumnNames: _col0, _col1, _col2
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: tinyint
+                        expr: _col1
+                        type: double
+                  sort order: ++
+                  Map-reduce partition columns:
+                        expr: _col0
+                        type: tinyint
+                  tag: -1
+                  TopN: 20
+                  TopN Hash Memory Usage: 0.3
+                  value expressions:
+                        expr: _col2
+                        type: bigint
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: count(DISTINCT KEY._col1:0._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: tinyint
+          mode: mergepartial
+          outputColumnNames: _col0, _col1
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: tinyint
+                  expr: _col1
+                  type: bigint
+            outputColumnNames: _col0, _col1
+            Limit
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 20
+
+PREHOOK: query: select ctinyint, count(distinct(cdouble)) from alltypesorc group by ctinyint limit 20
+PREHOOK: type: QUERY
+PREHOOK: Input: default@alltypesorc
+#### A masked pattern was here ####
+POSTHOOK: query: select ctinyint, count(distinct(cdouble)) from alltypesorc group by ctinyint limit 20
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@alltypesorc
+#### A masked pattern was here ####
+NULL	2932
+-64	24
+-63	19
+-62	27
+-61	25
+-60	27
+-59	31
+-58	23
+-57	35
+-56	36
+-55	29
+-54	26
+-53	22
+-52	33
+-51	21
+-50	30
+-49	26
+-48	29
+-47	22
+-46	24
+PREHOOK: query: -- multi distinct
+explain
+select ctinyint, count(distinct(cstring1)), count(distinct(cstring2)) from alltypesorc group by ctinyint limit 20
+PREHOOK: type: QUERY
+POSTHOOK: query: -- multi distinct
+explain
+select ctinyint, count(distinct(cstring1)), count(distinct(cstring2)) from alltypesorc group by ctinyint limit 20
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME alltypesorc))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL ctinyint)) (TOK_SELEXPR (TOK_FUNCTIONDI count (TOK_TABLE_OR_COL cstring1))) (TOK_SELEXPR (TOK_FUNCTIONDI count (TOK_TABLE_OR_COL cstring2)))) (TOK_GROUPBY (TOK_TABLE_OR_COL ctinyint)) (TOK_LIMIT 20)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        alltypesorc 
+          TableScan
+            alias: alltypesorc
+            Select Operator
+              expressions:
+                    expr: ctinyint
+                    type: tinyint
+                    expr: cstring1
+                    type: string
+                    expr: cstring2
+                    type: string
+              outputColumnNames: ctinyint, cstring1, cstring2
+              Group By Operator
+                aggregations:
+                      expr: count(DISTINCT cstring1)
+                      expr: count(DISTINCT cstring2)
+                bucketGroup: false
+                keys:
+                      expr: ctinyint
+                      type: tinyint
+                      expr: cstring1
+                      type: string
+                      expr: cstring2
+                      type: string
+                mode: hash
+                outputColumnNames: _col0, _col1, _col2, _col3, _col4
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: tinyint
+                        expr: _col1
+                        type: string
+                        expr: _col2
+                        type: string
+                  sort order: +++
+                  Map-reduce partition columns:
+                        expr: _col0
+                        type: tinyint
+                  tag: -1
+                  TopN: 20
+                  TopN Hash Memory Usage: 0.3
+                  value expressions:
+                        expr: _col3
+                        type: bigint
+                        expr: _col4
+                        type: bigint
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: count(DISTINCT KEY._col1:0._col0)
+                expr: count(DISTINCT KEY._col1:1._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: tinyint
+          mode: mergepartial
+          outputColumnNames: _col0, _col1, _col2
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: tinyint
+                  expr: _col1
+                  type: bigint
+                  expr: _col2
+                  type: bigint
+            outputColumnNames: _col0, _col1, _col2
+            Limit
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 20
+
+PREHOOK: query: select ctinyint, count(distinct(cstring1)), count(distinct(cstring2)) from alltypesorc group by ctinyint limit 20
+PREHOOK: type: QUERY
+PREHOOK: Input: default@alltypesorc
+#### A masked pattern was here ####
+POSTHOOK: query: select ctinyint, count(distinct(cstring1)), count(distinct(cstring2)) from alltypesorc group by ctinyint limit 20
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@alltypesorc
+#### A masked pattern was here ####
+NULL	3065	3
+-64	3	13
+-63	3	16
+-62	3	23
+-61	3	25
+-60	3	25
+-59	3	27
+-58	3	24
+-57	3	23
+-56	3	22
+-55	3	21
+-54	3	21
+-53	3	17
+-52	3	21
+-51	1012	1045
+-50	3	25
+-49	3	24
+-48	3	27
+-47	3	23
+-46	3	19
+PREHOOK: query: -- limit zero
+explain
+select key,value from src order by key limit 0
+PREHOOK: type: QUERY
+POSTHOOK: query: -- limit zero
+explain
+select key,value from src order by key limit 0
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value))) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL key))) (TOK_LIMIT 0)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Reduce Output Operator
+                key expressions:
+                      expr: _col0
+                      type: string
+                sort order: +
+                tag: -1
+                value expressions:
+                      expr: _col0
+                      type: string
+                      expr: _col1
+                      type: string
+      Reduce Operator Tree:
+        Extract
+          Limit
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 0
+
+PREHOOK: query: select key,value from src order by key limit 0
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: select key,value from src order by key limit 0
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+PREHOOK: query: -- 2MR (applied to last RS)
+explain
+select value, sum(key) as sum from src group by value order by sum limit 20
+PREHOOK: type: QUERY
+POSTHOOK: query: -- 2MR (applied to last RS)
+explain
+select value, sum(key) as sum from src group by value order by sum limit 20
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_FUNCTION sum (TOK_TABLE_OR_COL key)) sum)) (TOK_GROUPBY (TOK_TABLE_OR_COL value)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL sum))) (TOK_LIMIT 20)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: value
+                    type: string
+                    expr: key
+                    type: string
+              outputColumnNames: value, key
+              Group By Operator
+                aggregations:
+                      expr: sum(key)
+                bucketGroup: false
+                keys:
+                      expr: value
+                      type: string
+                mode: hash
+                outputColumnNames: _col0, _col1
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: string
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: _col0
+                        type: string
+                  tag: -1
+                  value expressions:
+                        expr: _col1
+                        type: double
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: sum(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: mergepartial
+          outputColumnNames: _col0, _col1
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: double
+            outputColumnNames: _col0, _col1
+            Reduce Output Operator
+              key expressions:
+                    expr: _col1
+                    type: double
+              sort order: +
+              tag: -1
+              TopN: 20
+              TopN Hash Memory Usage: 0.3
+              value expressions:
+                    expr: _col0
+                    type: string
+                    expr: _col1
+                    type: double
+      Reduce Operator Tree:
+        Extract
+          Limit
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 20
+
+PREHOOK: query: select value, sum(key) as sum from src group by value order by sum limit 20
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: select value, sum(key) as sum from src group by value order by sum limit 20
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+val_0	0.0
+val_2	2.0
+val_4	4.0
+val_8	8.0
+val_9	9.0
+val_10	10.0
+val_11	11.0
+val_5	15.0
+val_17	17.0
+val_19	19.0
+val_20	20.0
+val_12	24.0
+val_27	27.0
+val_28	28.0
+val_30	30.0
+val_15	30.0
+val_33	33.0
+val_34	34.0
+val_18	36.0
+val_41	41.0
+PREHOOK: query: -- subqueries
+explain
+select * from
+(select key, count(1) from src group by key order by key limit 2) subq
+join
+(select key, count(1) from src group by key limit 3) subq2
+on subq.key=subq2.key limit 4
+PREHOOK: type: QUERY
+POSTHOOK: query: -- subqueries
+explain
+select * from
+(select key, count(1) from src group by key order by key limit 2) subq
+join
+(select key, count(1) from src group by key limit 3) subq2
+on subq.key=subq2.key limit 4
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_FUNCTION count 1))) (TOK_GROUPBY (TOK_TABLE_OR_COL key)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL key))) (TOK_LIMIT 2))) subq) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_FUNCTION count 1))) (TOK_GROUPBY (TOK_TABLE_OR_COL key)) (TOK_LIMIT 3))) subq2) (= (. (TOK_TABLE_OR_COL subq) key) (. (TOK_TABLE_OR_COL subq2) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 4)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+              outputColumnNames: key
+              Group By Operator
+                aggregations:
+                      expr: count(1)
+                bucketGroup: false
+                keys:
+                      expr: key
+                      type: string
+                mode: hash
+                outputColumnNames: _col0, _col1
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: string
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: _col0
+                        type: string
+                  tag: -1
+                  TopN: 2
+                  TopN Hash Memory Usage: 0.3
+                  value expressions:
+                        expr: _col1
+                        type: bigint
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: count(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: mergepartial
+          outputColumnNames: _col0, _col1
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: bigint
+            outputColumnNames: _col0, _col1
+            Limit
+              Reduce Output Operator
+                key expressions:
+                      expr: _col0
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: _col0
+                      type: string
+                tag: 0
+                value expressions:
+                      expr: _col0
+                      type: string
+                      expr: _col1
+                      type: bigint
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+              outputColumnNames: key
+              Group By Operator
+                aggregations:
+                      expr: count(1)
+                bucketGroup: false
+                keys:
+                      expr: key
+                      type: string
+                mode: hash
+                outputColumnNames: _col0, _col1
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col0
+                        type: string
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: _col0
+                        type: string
+                  tag: -1
+                  TopN: 3
+                  TopN Hash Memory Usage: 0.3
+                  value expressions:
+                        expr: _col1
+                        type: bigint
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: count(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: mergepartial
+          outputColumnNames: _col0, _col1
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: bigint
+            outputColumnNames: _col0, _col1
+            Limit
+              Reduce Output Operator
+                sort order: 
+                tag: -1
+                TopN: 3
+                TopN Hash Memory Usage: 0.3
+                value expressions:
+                      expr: _col0
+                      type: string
+                      expr: _col1
+                      type: bigint
+      Reduce Operator Tree:
+        Extract
+          Limit
+            Reduce Output Operator
+              key expressions:
+                    expr: _col0
+                    type: string
+              sort order: +
+              Map-reduce partition columns:
+                    expr: _col0
+                    type: string
+              tag: 1
+              value expressions:
+                    expr: _col0
+                    type: string
+                    expr: _col1
+                    type: bigint
+      Reduce Operator Tree:
+        Join Operator
+          condition map:
+               Inner Join 0 to 1
+          condition expressions:
+            0 {VALUE._col0} {VALUE._col1}
+            1 {VALUE._col0} {VALUE._col1}
+          handleSkewJoin: false
+          outputColumnNames: _col0, _col1, _col2, _col3
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: bigint
+                  expr: _col2
+                  type: string
+                  expr: _col3
+                  type: bigint
+            outputColumnNames: _col0, _col1, _col2, _col3
+            Limit
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 4
+
+PREHOOK: query: -- map aggregation disabled
+explain
+select value, sum(key) as sum from src group by value limit 20
+PREHOOK: type: QUERY
+POSTHOOK: query: -- map aggregation disabled
+explain
+select value, sum(key) as sum from src group by value limit 20
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_FUNCTION sum (TOK_TABLE_OR_COL key)) sum)) (TOK_GROUPBY (TOK_TABLE_OR_COL value)) (TOK_LIMIT 20)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: value
+                    type: string
+                    expr: key
+                    type: string
+              outputColumnNames: value, key
+              Reduce Output Operator
+                key expressions:
+                      expr: value
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: value
+                      type: string
+                tag: -1
+                TopN: 20
+                TopN Hash Memory Usage: 0.3
+                value expressions:
+                      expr: key
+                      type: string
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: sum(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: complete
+          outputColumnNames: _col0, _col1
+          Select Operator
+            expressions:
+                  expr: _col0
+                  type: string
+                  expr: _col1
+                  type: double
+            outputColumnNames: _col0, _col1
+            Limit
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 20
+
+PREHOOK: query: select value, sum(key) as sum from src group by value limit 20
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: select value, sum(key) as sum from src group by value limit 20
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+val_0	0.0
+val_10	10.0
+val_100	200.0
+val_103	206.0
+val_104	208.0
+val_105	105.0
+val_11	11.0
+val_111	111.0
+val_113	226.0
+val_114	114.0
+val_116	116.0
+val_118	236.0
+val_119	357.0
+val_12	24.0
+val_120	240.0
+val_125	250.0
+val_126	126.0
+val_128	384.0
+val_129	258.0
+val_131	131.0
+PREHOOK: query: -- flush for order-by
+explain
+select key,value,value,value,value,value,value,value,value from src order by key limit 100
+PREHOOK: type: QUERY
+POSTHOOK: query: -- flush for order-by
+explain
+select key,value,value,value,value,value,value,value,value from src order by key limit 100
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL value))) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL key))) (TOK_LIMIT 100)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+                    expr: value
+                    type: string
+                    expr: value
+                    type: string
+                    expr: value
+                    type: string
+                    expr: value
+                    type: string
+                    expr: value
+                    type: string
+                    expr: value
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
+              Reduce Output Operator
+                key expressions:
+                      expr: _col0
+                      type: string
+                sort order: +
+                tag: -1
+                TopN: 100
+                TopN Hash Memory Usage: 2.0E-5
+                value expressions:
+                      expr: _col0
+                      type: string
+                      expr: _col1
+                      type: string
+                      expr: _col2
+                      type: string
+                      expr: _col3
+                      type: string
+                      expr: _col4
+                      type: string
+                      expr: _col5
+                      type: string
+                      expr: _col6
+                      type: string
+                      expr: _col7
+                      type: string
+                      expr: _col8
+                      type: string
+      Reduce Operator Tree:
+        Extract
+          Limit
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 100
+
+PREHOOK: query: select key,value,value,value,value,value,value,value,value from src order by key limit 100
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: select key,value,value,value,value,value,value,value,value from src order by key limit 100
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+0	val_0	val_0	val_0	val_0	val_0	val_0	val_0	val_0
+0	val_0	val_0	val_0	val_0	val_0	val_0	val_0	val_0
+0	val_0	val_0	val_0	val_0	val_0	val_0	val_0	val_0
+10	val_10	val_10	val_10	val_10	val_10	val_10	val_10	val_10
+100	val_100	val_100	val_100	val_100	val_100	val_100	val_100	val_100
+100	val_100	val_100	val_100	val_100	val_100	val_100	val_100	val_100
+103	val_103	val_103	val_103	val_103	val_103	val_103	val_103	val_103
+103	val_103	val_103	val_103	val_103	val_103	val_103	val_103	val_103
+104	val_104	val_104	val_104	val_104	val_104	val_104	val_104	val_104
+104	val_104	val_104	val_104	val_104	val_104	val_104	val_104	val_104
+105	val_105	val_105	val_105	val_105	val_105	val_105	val_105	val_105
+11	val_11	val_11	val_11	val_11	val_11	val_11	val_11	val_11
+111	val_111	val_111	val_111	val_111	val_111	val_111	val_111	val_111
+113	val_113	val_113	val_113	val_113	val_113	val_113	val_113	val_113
+113	val_113	val_113	val_113	val_113	val_113	val_113	val_113	val_113
+114	val_114	val_114	val_114	val_114	val_114	val_114	val_114	val_114
+116	val_116	val_116	val_116	val_116	val_116	val_116	val_116	val_116
+118	val_118	val_118	val_118	val_118	val_118	val_118	val_118	val_118
+118	val_118	val_118	val_118	val_118	val_118	val_118	val_118	val_118
+119	val_119	val_119	val_119	val_119	val_119	val_119	val_119	val_119
+119	val_119	val_119	val_119	val_119	val_119	val_119	val_119	val_119
+119	val_119	val_119	val_119	val_119	val_119	val_119	val_119	val_119
+12	val_12	val_12	val_12	val_12	val_12	val_12	val_12	val_12
+12	val_12	val_12	val_12	val_12	val_12	val_12	val_12	val_12
+120	val_120	val_120	val_120	val_120	val_120	val_120	val_120	val_120
+120	val_120	val_120	val_120	val_120	val_120	val_120	val_120	val_120
+125	val_125	val_125	val_125	val_125	val_125	val_125	val_125	val_125
+125	val_125	val_125	val_125	val_125	val_125	val_125	val_125	val_125
+126	val_126	val_126	val_126	val_126	val_126	val_126	val_126	val_126
+128	val_128	val_128	val_128	val_128	val_128	val_128	val_128	val_128
+128	val_128	val_128	val_128	val_128	val_128	val_128	val_128	val_128
+128	val_128	val_128	val_128	val_128	val_128	val_128	val_128	val_128
+129	val_129	val_129	val_129	val_129	val_129	val_129	val_129	val_129
+129	val_129	val_129	val_129	val_129	val_129	val_129	val_129	val_129
+131	val_131	val_131	val_131	val_131	val_131	val_131	val_131	val_131
+133	val_133	val_133	val_133	val_133	val_133	val_133	val_133	val_133
+134	val_134	val_134	val_134	val_134	val_134	val_134	val_134	val_134
+134	val_134	val_134	val_134	val_134	val_134	val_134	val_134	val_134
+136	val_136	val_136	val_136	val_136	val_136	val_136	val_136	val_136
+137	val_137	val_137	val_137	val_137	val_137	val_137	val_137	val_137
+137	val_137	val_137	val_137	val_137	val_137	val_137	val_137	val_137
+138	val_138	val_138	val_138	val_138	val_138	val_138	val_138	val_138
+138	val_138	val_138	val_138	val_138	val_138	val_138	val_138	val_138
+138	val_138	val_138	val_138	val_138	val_138	val_138	val_138	val_138
+138	val_138	val_138	val_138	val_138	val_138	val_138	val_138	val_138
+143	val_143	val_143	val_143	val_143	val_143	val_143	val_143	val_143
+145	val_145	val_145	val_145	val_145	val_145	val_145	val_145	val_145
+146	val_146	val_146	val_146	val_146	val_146	val_146	val_146	val_146
+146	val_146	val_146	val_146	val_146	val_146	val_146	val_146	val_146
+149	val_149	val_149	val_149	val_149	val_149	val_149	val_149	val_149
+149	val_149	val_149	val_149	val_149	val_149	val_149	val_149	val_149
+15	val_15	val_15	val_15	val_15	val_15	val_15	val_15	val_15
+15	val_15	val_15	val_15	val_15	val_15	val_15	val_15	val_15
+150	val_150	val_150	val_150	val_150	val_150	val_150	val_150	val_150
+152	val_152	val_152	val_152	val_152	val_152	val_152	val_152	val_152
+152	val_152	val_152	val_152	val_152	val_152	val_152	val_152	val_152
+153	val_153	val_153	val_153	val_153	val_153	val_153	val_153	val_153
+155	val_155	val_155	val_155	val_155	val_155	val_155	val_155	val_155
+156	val_156	val_156	val_156	val_156	val_156	val_156	val_156	val_156
+157	val_157	val_157	val_157	val_157	val_157	val_157	val_157	val_157
+158	val_158	val_158	val_158	val_158	val_158	val_158	val_158	val_158
+160	val_160	val_160	val_160	val_160	val_160	val_160	val_160	val_160
+162	val_162	val_162	val_162	val_162	val_162	val_162	val_162	val_162
+163	val_163	val_163	val_163	val_163	val_163	val_163	val_163	val_163
+164	val_164	val_164	val_164	val_164	val_164	val_164	val_164	val_164
+164	val_164	val_164	val_164	val_164	val_164	val_164	val_164	val_164
+165	val_165	val_165	val_165	val_165	val_165	val_165	val_165	val_165
+165	val_165	val_165	val_165	val_165	val_165	val_165	val_165	val_165
+166	val_166	val_166	val_166	val_166	val_166	val_166	val_166	val_166
+167	val_167	val_167	val_167	val_167	val_167	val_167	val_167	val_167
+167	val_167	val_167	val_167	val_167	val_167	val_167	val_167	val_167
+167	val_167	val_167	val_167	val_167	val_167	val_167	val_167	val_167
+168	val_168	val_168	val_168	val_168	val_168	val_168	val_168	val_168
+169	val_169	val_169	val_169	val_169	val_169	val_169	val_169	val_169
+169	val_169	val_169	val_169	val_169	val_169	val_169	val_169	val_169
+169	val_169	val_169	val_169	val_169	val_169	val_169	val_169	val_169
+169	val_169	val_169	val_169	val_169	val_169	val_169	val_169	val_169
+17	val_17	val_17	val_17	val_17	val_17	val_17	val_17	val_17
+170	val_170	val_170	val_170	val_170	val_170	val_170	val_170	val_170
+172	val_172	val_172	val_172	val_172	val_172	val_172	val_172	val_172
+172	val_172	val_172	val_172	val_172	val_172	val_172	val_172	val_172
+174	val_174	val_174	val_174	val_174	val_174	val_174	val_174	val_174
+174	val_174	val_174	val_174	val_174	val_174	val_174	val_174	val_174
+175	val_175	val_175	val_175	val_175	val_175	val_175	val_175	val_175
+175	val_175	val_175	val_175	val_175	val_175	val_175	val_175	val_175
+176	val_176	val_176	val_176	val_176	val_176	val_176	val_176	val_176
+176	val_176	val_176	val_176	val_176	val_176	val_176	val_176	val_176
+177	val_177	val_177	val_177	val_177	val_177	val_177	val_177	val_177
+178	val_178	val_178	val_178	val_178	val_178	val_178	val_178	val_178
+179	val_179	val_179	val_179	val_179	val_179	val_179	val_179	val_179
+179	val_179	val_179	val_179	val_179	val_179	val_179	val_179	val_179
+18	val_18	val_18	val_18	val_18	val_18	val_18	val_18	val_18
+18	val_18	val_18	val_18	val_18	val_18	val_18	val_18	val_18
+180	val_180	val_180	val_180	val_180	val_180	val_180	val_180	val_180
+181	val_181	val_181	val_181	val_181	val_181	val_181	val_181	val_181
+183	val_183	val_183	val_183	val_183	val_183	val_183	val_183	val_183
+186	val_186	val_186	val_186	val_186	val_186	val_186	val_186	val_186
+187	val_187	val_187	val_187	val_187	val_187	val_187	val_187	val_187
+187	val_187	val_187	val_187	val_187	val_187	val_187	val_187	val_187
+187	val_187	val_187	val_187	val_187	val_187	val_187	val_187	val_187
+PREHOOK: query: -- flush for group-by
+explain
+select sum(key) as sum from src group by concat(key,value,value,value,value,value,value,value,value,value) limit 100
+PREHOOK: type: QUERY
+POSTHOOK: query: -- flush for group-by
+explain
+select sum(key) as sum from src group by concat(key,value,value,value,value,value,value,value,value,value) limit 100
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION sum (TOK_TABLE_OR_COL key)) sum)) (TOK_GROUPBY (TOK_FUNCTION concat (TOK_TABLE_OR_COL key) (TOK_TABLE_OR_COL value) (TOK_TABLE_OR_COL value) (TOK_TABLE_OR_COL value) (TOK_TABLE_OR_COL value) (TOK_TABLE_OR_COL value) (TOK_TABLE_OR_COL value) (TOK_TABLE_OR_COL value) (TOK_TABLE_OR_COL value) (TOK_TABLE_OR_COL value))) (TOK_LIMIT 100)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: key, value
+              Reduce Output Operator
+                key expressions:
+                      expr: concat(key, value, value, value, value, value, value, value, value, value)
+                      type: string
+                sort order: +
+                Map-reduce partition columns:
+                      expr: concat(key, value, value, value, value, value, value, value, value, value)
+                      type: string
+                tag: -1
+                TopN: 100
+                TopN Hash Memory Usage: 2.0E-5
+                value expressions:
+                      expr: key
+                      type: string
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: sum(VALUE._col0)
+          bucketGroup: false
+          keys:
+                expr: KEY._col0
+                type: string
+          mode: complete
+          outputColumnNames: _col0, _col1
+          Select Operator
+            expressions:
+                  expr: _col1
+                  type: double
+            outputColumnNames: _col0
+            Limit
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 100
+
+PREHOOK: query: select sum(key) as sum from src group by concat(key,value,value,value,value,value,value,value,value,value) limit 100
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: select sum(key) as sum from src group by concat(key,value,value,value,value,value,value,value,value,value) limit 100
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+0.0
+200.0
+206.0
+208.0
+105.0
+10.0
+111.0
+226.0
+114.0
+116.0
+236.0
+357.0
+11.0
+240.0
+250.0
+126.0
+384.0
+258.0
+24.0
+131.0
+133.0
+268.0
+136.0
+274.0
+552.0
+143.0
+145.0
+292.0
+298.0
+150.0
+304.0
+153.0
+155.0
+156.0
+157.0
+158.0
+30.0
+160.0
+162.0
+163.0
+328.0
+330.0
+166.0
+501.0
+168.0
+676.0
+170.0
+344.0
+348.0
+350.0
+352.0
+177.0
+178.0
+358.0
+17.0
+180.0
+181.0
+183.0
+186.0
+561.0
+189.0
+36.0
+190.0
+382.0
+192.0
+579.0
+194.0
+390.0
+196.0
+394.0
+597.0
+19.0
+400.0
+201.0
+202.0
+406.0
+410.0
+414.0
+624.0
+418.0
+20.0
+426.0
+214.0
+432.0
+434.0
+218.0
+438.0
+442.0
+222.0
+446.0
+448.0
+226.0
+228.0
+458.0
+1150.0
+466.0
+235.0
+474.0
+476.0
+478.0
