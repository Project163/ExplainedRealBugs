diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
index 10c8dbee65..301d5fc7bc 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
@@ -63,7 +63,7 @@
 import org.apache.hadoop.hive.ql.parse.SemanticException;
 import org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
-import org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc;
+import org.apache.hadoop.hive.ql.plan.ExprNodeDescUtils;
 import org.apache.hadoop.hive.ql.plan.FetchWork;
 import org.apache.hadoop.hive.ql.plan.JoinCondDesc;
 import org.apache.hadoop.hive.ql.plan.JoinDesc;
@@ -323,8 +323,6 @@ public static MapJoinOperator convertMapJoin(
     List<Operator<? extends OperatorDesc>> oldReduceSinkParentOps =
        new ArrayList<Operator<? extends OperatorDesc>>();
     Map<String, ExprNodeDesc> colExprMap = new HashMap<String, ExprNodeDesc>();
-    HashMap<Byte, HashMap<String, ExprNodeDesc>> columnTransfer =
-      new HashMap<Byte, HashMap<String, ExprNodeDesc>>();
 
     // found a source which is not to be stored in memory
     if (leftSrc != null) {
@@ -334,7 +332,6 @@ public static MapJoinOperator convertMapJoin(
       Operator<? extends OperatorDesc> grandParentOp =
         parentOp.getParentOperators().get(0);
       oldReduceSinkParentOps.add(parentOp);
-      grandParentOp.removeChild(parentOp);
       newParentOps.add(grandParentOp);
     }
 
@@ -347,7 +344,6 @@ public static MapJoinOperator convertMapJoin(
         Operator<? extends OperatorDesc> grandParentOp =
           parentOp.getParentOperators().get(0);
 
-        grandParentOp.removeChild(parentOp);
         oldReduceSinkParentOps.add(parentOp);
         newParentOps.add(grandParentOp);
       }
@@ -360,10 +356,6 @@ public static MapJoinOperator convertMapJoin(
       ReduceSinkDesc rsconf = oldPar.getConf();
       List<ExprNodeDesc> keys = rsconf.getKeyCols();
       keyExprMap.put(pos, keys);
-
-      // set column transfer
-      HashMap<String, ExprNodeDesc> map = (HashMap<String, ExprNodeDesc>) oldPar.getColumnExprMap();
-      columnTransfer.put(pos, map);
     }
 
     // create the map-join operator
@@ -400,31 +392,20 @@ public static MapJoinOperator convertMapJoin(
     }
 
     Map<Byte, List<ExprNodeDesc>> filters = desc.getFilters();
+    Map<Byte, List<ExprNodeDesc>> newFilters = new HashMap<Byte, List<ExprNodeDesc>>();
     for (Map.Entry<Byte, List<ExprNodeDesc>> entry : filters.entrySet()) {
-      Byte srcAlias = entry.getKey();
-      List<ExprNodeDesc> columnDescList = entry.getValue();
+      byte srcTag = entry.getKey();
+      List<ExprNodeDesc> filter = entry.getValue();
 
-      for (ExprNodeDesc nodeExpr : columnDescList) {
-        ExprNodeGenericFuncDesc funcDesc = (ExprNodeGenericFuncDesc) nodeExpr;
-        for (ExprNodeDesc childDesc : funcDesc.getChildExprs()) {
-          if (!(childDesc instanceof ExprNodeColumnDesc)) {
-            continue;
-          }
-          ExprNodeColumnDesc columnDesc = (ExprNodeColumnDesc) childDesc;
-          // reset columns
-          String column = columnDesc.getColumn();
-          String newColumn = null;
-          HashMap<String, ExprNodeDesc> map = columnTransfer.get(srcAlias);
-          ExprNodeColumnDesc tmpDesc = (ExprNodeColumnDesc) map.get(column);
-          if (tmpDesc != null) {
-            newColumn = tmpDesc.getColumn();
-          }
-          if (newColumn == null) {
-            throw new SemanticException("No Column name found in parent reduce sink op");
-          }
-          columnDesc.setColumn(newColumn);
-        }
-      }
+      Operator<?> start = oldReduceSinkParentOps.get(srcTag);
+      Operator<?> terminal = newParentOps.get(srcTag);
+      newFilters.put(srcTag, ExprNodeDescUtils.backtrack(filter, start, terminal));
+    }
+    desc.setFilters(filters = newFilters);
+
+    // remove old parents
+    for (pos = 0; pos < newParentOps.size(); pos++) {
+      newParentOps.get(pos).removeChild(oldReduceSinkParentOps.get(pos));
     }
 
     JoinCondDesc[] joinCondns = op.getConf().getConds();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java
index c076c54896..18d6bb046a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java
@@ -20,8 +20,11 @@
 
 import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 
 import org.apache.hadoop.hive.ql.exec.FunctionRegistry;
+import org.apache.hadoop.hive.ql.exec.Operator;
+import org.apache.hadoop.hive.ql.parse.SemanticException;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 
 public class ExprNodeDescUtils {
@@ -113,4 +116,72 @@ public static String recommendInputName(ExprNodeDesc desc) {
     }
     return null;
   }
+
+  /**
+   * Convert expressions in current operator to those in terminal operator, which
+   * is an ancestor of current or null (back to top operator).
+   */
+  public static ArrayList<ExprNodeDesc> backtrack(List<ExprNodeDesc> sources,
+      Operator<?> current, Operator<?> terminal) throws SemanticException {
+    ArrayList<ExprNodeDesc> result = new ArrayList<ExprNodeDesc>();
+    for (ExprNodeDesc expr : sources) {
+      result.add(backtrack(expr, current, terminal));
+    }
+    return result;
+  }
+
+  private static ExprNodeDesc backtrack(ExprNodeDesc source, Operator<?> current,
+      Operator<?> terminal) throws SemanticException {
+    if (current == null || current == terminal) {
+      return source;
+    }
+    if (source instanceof ExprNodeGenericFuncDesc) {
+      // all children expression should be resolved
+      ExprNodeGenericFuncDesc function = (ExprNodeGenericFuncDesc) source.clone();
+      function.setChildExprs(backtrack(function.getChildren(), current, terminal));
+      return function;
+    }
+    if (source instanceof ExprNodeColumnDesc) {
+      ExprNodeColumnDesc column = (ExprNodeColumnDesc) source;
+      return backtrack(column, current, terminal);
+    }
+    if (source instanceof ExprNodeFieldDesc) {
+      // field epression should be resolved
+      ExprNodeFieldDesc field = (ExprNodeFieldDesc) source.clone();
+      field.setDesc(backtrack(field.getDesc(), current, terminal));
+      return field;
+    }
+    // constant or null expr, just return
+    return source;
+  }
+
+  // Resolve column expression to input expression by using expression mapping in current operator
+  private static ExprNodeDesc backtrack(ExprNodeColumnDesc column, Operator<?> current,
+      Operator<?> terminal) throws SemanticException {
+    if (current == null || current == terminal) {
+      return column;
+    }
+    Operator<?> parent = getSingleParent(current, terminal);
+    Map<String, ExprNodeDesc> mapping = current.getColumnExprMap();
+    if (mapping == null || !mapping.containsKey(column.getColumn())) {
+      return backtrack(column, parent, terminal);  // forward
+    }
+    ExprNodeDesc mapped = mapping.get(column.getColumn());
+    return backtrack(mapped, parent, terminal);    // forward with resolved expr
+  }
+
+  private static Operator<?> getSingleParent(Operator<?> current, Operator<?> terminal)
+      throws SemanticException {
+    List<Operator<?>> parents = current.getParentOperators();
+    if (parents == null || parents.isEmpty()) {
+      if (terminal != null) {
+        throw new SemanticException("Failed to meet terminal operator");
+      }
+      return null;
+    }
+    if (current.getParentOperators().size() > 1) {
+      throw new SemanticException("Met multiple parent operators");
+    }
+    return parents.get(0);
+  }
 }
diff --git a/ql/src/test/queries/clientpositive/mapjoin1.q b/ql/src/test/queries/clientpositive/mapjoin1.q
index 03b06d48ca..9c6a8b17ca 100644
--- a/ql/src/test/queries/clientpositive/mapjoin1.q
+++ b/ql/src/test/queries/clientpositive/mapjoin1.q
@@ -1,5 +1,40 @@
 set hive.mapjoin.cache.numrows=100;
 
 SELECT  /*+ MAPJOIN(b) */ sum(a.key) as sum_a
-	FROM srcpart a
-	JOIN src b ON a.key = b.key where a.ds is not null;
+    FROM srcpart a
+    JOIN src b ON a.key = b.key where a.ds is not null;
+
+set hive.outerjoin.supports.filters=true;
+
+-- const filter on outer join
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10;
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10;
+
+-- func filter on outer join
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10;
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10;
+
+-- field filter on outer join
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10;
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10;
+
+set hive.outerjoin.supports.filters=false;
+
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10;
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10;
+
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10;
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10;
+
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10;
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10;
diff --git a/ql/src/test/results/clientpositive/mapjoin1.q.out b/ql/src/test/results/clientpositive/mapjoin1.q.out
index bf39a3ea84..8452ba6061 100644
--- a/ql/src/test/results/clientpositive/mapjoin1.q.out
+++ b/ql/src/test/results/clientpositive/mapjoin1.q.out
@@ -1,6 +1,6 @@
 PREHOOK: query: SELECT  /*+ MAPJOIN(b) */ sum(a.key) as sum_a
-	FROM srcpart a
-	JOIN src b ON a.key = b.key where a.ds is not null
+    FROM srcpart a
+    JOIN src b ON a.key = b.key where a.ds is not null
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Input: default@srcpart
@@ -10,8 +10,8 @@ PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 #### A masked pattern was here ####
 POSTHOOK: query: SELECT  /*+ MAPJOIN(b) */ sum(a.key) as sum_a
-	FROM srcpart a
-	JOIN src b ON a.key = b.key where a.ds is not null
+    FROM srcpart a
+    JOIN src b ON a.key = b.key where a.ds is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@srcpart
@@ -21,3 +21,717 @@ POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
 #### A masked pattern was here ####
 1114788.0
+PREHOOK: query: -- const filter on outer join
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10
+PREHOOK: type: QUERY
+POSTHOOK: query: -- const filter on outer join
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_RIGHTOUTERJOIN (TOK_TABREF (TOK_TABNAME src) a) (TOK_TABREF (TOK_TABNAME src) b) (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)) true))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 10)))
+
+STAGE DEPENDENCIES:
+  Stage-3 is a root stage
+  Stage-1 depends on stages: Stage-3
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-3
+    Map Reduce Local Work
+      Alias -> Map Local Tables:
+        a 
+          Fetch Operator
+            limit: -1
+      Alias -> Map Local Operator Tree:
+        a 
+          TableScan
+            alias: a
+            HashTable Sink Operator
+              condition expressions:
+                0 {key} {value}
+                1 {key} {value}
+              filter predicates:
+                0 
+                1 {true}
+              handleSkewJoin: false
+              keys:
+                0 [Column[key]]
+                1 [Column[key]]
+              Position of Big Table: 1
+
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        b 
+          TableScan
+            alias: b
+            Map Join Operator
+              condition map:
+                   Right Outer Join0 to 1
+              condition expressions:
+                0 {key} {value}
+                1 {key} {value}
+              filter predicates:
+                0 
+                1 {true}
+              handleSkewJoin: false
+              keys:
+                0 [Column[key]]
+                1 [Column[key]]
+              outputColumnNames: _col0, _col1, _col4, _col5
+              Position of Big Table: 1
+              Select Operator
+                expressions:
+                      expr: _col0
+                      type: string
+                      expr: _col1
+                      type: string
+                      expr: _col4
+                      type: string
+                      expr: _col5
+                      type: string
+                outputColumnNames: _col0, _col1, _col4, _col5
+                Select Operator
+                  expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+                        expr: _col4
+                        type: string
+                        expr: _col5
+                        type: string
+                  outputColumnNames: _col0, _col1, _col2, _col3
+                  Limit
+                    File Output Operator
+                      compressed: false
+                      GlobalTableId: 0
+                      table:
+                          input format: org.apache.hadoop.mapred.TextInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+      Local Work:
+        Map Reduce Local Work
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 10
+
+
+PREHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+238	val_238	238	val_238
+238	val_238	238	val_238
+86	val_86	86	val_86
+311	val_311	311	val_311
+311	val_311	311	val_311
+311	val_311	311	val_311
+27	val_27	27	val_27
+165	val_165	165	val_165
+165	val_165	165	val_165
+409	val_409	409	val_409
+PREHOOK: query: -- func filter on outer join
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10
+PREHOOK: type: QUERY
+POSTHOOK: query: -- func filter on outer join
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_RIGHTOUTERJOIN (TOK_TABREF (TOK_TABNAME src) a) (TOK_TABREF (TOK_TABNAME src) b) (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)) (< (* (. (TOK_TABLE_OR_COL b) key) 10) '1000')))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 10)))
+
+STAGE DEPENDENCIES:
+  Stage-3 is a root stage
+  Stage-1 depends on stages: Stage-3
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-3
+    Map Reduce Local Work
+      Alias -> Map Local Tables:
+        a 
+          Fetch Operator
+            limit: -1
+      Alias -> Map Local Operator Tree:
+        a 
+          TableScan
+            alias: a
+            HashTable Sink Operator
+              condition expressions:
+                0 {key} {value}
+                1 {key} {value}
+              filter predicates:
+                0 
+                1 {((key * 10) < '1000')}
+              handleSkewJoin: false
+              keys:
+                0 [Column[key]]
+                1 [Column[key]]
+              Position of Big Table: 1
+
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        b 
+          TableScan
+            alias: b
+            Map Join Operator
+              condition map:
+                   Right Outer Join0 to 1
+              condition expressions:
+                0 {key} {value}
+                1 {key} {value}
+              filter predicates:
+                0 
+                1 {((key * 10) < '1000')}
+              handleSkewJoin: false
+              keys:
+                0 [Column[key]]
+                1 [Column[key]]
+              outputColumnNames: _col0, _col1, _col4, _col5
+              Position of Big Table: 1
+              Select Operator
+                expressions:
+                      expr: _col0
+                      type: string
+                      expr: _col1
+                      type: string
+                      expr: _col4
+                      type: string
+                      expr: _col5
+                      type: string
+                outputColumnNames: _col0, _col1, _col4, _col5
+                Select Operator
+                  expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+                        expr: _col4
+                        type: string
+                        expr: _col5
+                        type: string
+                  outputColumnNames: _col0, _col1, _col2, _col3
+                  Limit
+                    File Output Operator
+                      compressed: false
+                      GlobalTableId: 0
+                      table:
+                          input format: org.apache.hadoop.mapred.TextInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+      Local Work:
+        Map Reduce Local Work
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 10
+
+
+PREHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+NULL	NULL	238	val_238
+NULL	NULL	238	val_238
+86	val_86	86	val_86
+NULL	NULL	311	val_311
+NULL	NULL	311	val_311
+NULL	NULL	311	val_311
+27	val_27	27	val_27
+NULL	NULL	165	val_165
+NULL	NULL	165	val_165
+NULL	NULL	409	val_409
+PREHOOK: query: -- field filter on outer join
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10
+PREHOOK: type: QUERY
+POSTHOOK: query: -- field filter on outer join
+EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_RIGHTOUTERJOIN (TOK_TABREF (TOK_TABNAME src) a) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_FUNCTION named_struct 'key' (TOK_TABLE_OR_COL key) 'value' (TOK_TABLE_OR_COL value)) kv)))) b) (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)) (> (. (. (TOK_TABLE_OR_COL b) kv) key) 200)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 10)))
+
+STAGE DEPENDENCIES:
+  Stage-3 is a root stage
+  Stage-1 depends on stages: Stage-3
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-3
+    Map Reduce Local Work
+      Alias -> Map Local Tables:
+        a 
+          Fetch Operator
+            limit: -1
+      Alias -> Map Local Operator Tree:
+        a 
+          TableScan
+            alias: a
+            HashTable Sink Operator
+              condition expressions:
+                0 {key} {value}
+                1 {_col0} {_col1}
+              filter predicates:
+                0 
+                1 {(_col1.key > 200)}
+              handleSkewJoin: false
+              keys:
+                0 [Column[key]]
+                1 [Column[_col0]]
+              Position of Big Table: 1
+
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        b:src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: named_struct('key',key,'value',value)
+                    type: struct<key:string,value:string>
+              outputColumnNames: _col0, _col1
+              Map Join Operator
+                condition map:
+                     Right Outer Join0 to 1
+                condition expressions:
+                  0 {key} {value}
+                  1 {_col0} {_col1}
+                filter predicates:
+                  0 
+                  1 {(_col1.key > 200)}
+                handleSkewJoin: false
+                keys:
+                  0 [Column[key]]
+                  1 [Column[_col0]]
+                outputColumnNames: _col0, _col1, _col4, _col5
+                Position of Big Table: 1
+                Select Operator
+                  expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+                        expr: _col4
+                        type: string
+                        expr: _col5
+                        type: struct<key:string,value:string>
+                  outputColumnNames: _col0, _col1, _col4, _col5
+                  Select Operator
+                    expressions:
+                          expr: _col0
+                          type: string
+                          expr: _col1
+                          type: string
+                          expr: _col4
+                          type: string
+                          expr: _col5
+                          type: struct<key:string,value:string>
+                    outputColumnNames: _col0, _col1, _col2, _col3
+                    Limit
+                      File Output Operator
+                        compressed: false
+                        GlobalTableId: 0
+                        table:
+                            input format: org.apache.hadoop.mapred.TextInputFormat
+                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+      Local Work:
+        Map Reduce Local Work
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 10
+
+
+PREHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+238	val_238	238	{"key":"238","value":"val_238"}
+238	val_238	238	{"key":"238","value":"val_238"}
+NULL	NULL	86	{"key":"86","value":"val_86"}
+311	val_311	311	{"key":"311","value":"val_311"}
+311	val_311	311	{"key":"311","value":"val_311"}
+311	val_311	311	{"key":"311","value":"val_311"}
+NULL	NULL	27	{"key":"27","value":"val_27"}
+NULL	NULL	165	{"key":"165","value":"val_165"}
+NULL	NULL	165	{"key":"165","value":"val_165"}
+409	val_409	409	{"key":"409","value":"val_409"}
+PREHOOK: query: EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_RIGHTOUTERJOIN (TOK_TABREF (TOK_TABNAME src) a) (TOK_TABREF (TOK_TABNAME src) b) (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)) true))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 10)))
+
+STAGE DEPENDENCIES:
+  Stage-3 is a root stage
+  Stage-1 depends on stages: Stage-3
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-3
+    Map Reduce Local Work
+      Alias -> Map Local Tables:
+        a 
+          Fetch Operator
+            limit: -1
+      Alias -> Map Local Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Filter Operator
+              predicate:
+                  expr: true
+                  type: boolean
+              HashTable Sink Operator
+                condition expressions:
+                  0 {key} {value}
+                  1 {key} {value}
+                handleSkewJoin: false
+                keys:
+                  0 [Column[key]]
+                  1 [Column[key]]
+                Position of Big Table: 1
+
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        b 
+          TableScan
+            alias: b
+            Filter Operator
+              predicate:
+                  expr: true
+                  type: boolean
+              Map Join Operator
+                condition map:
+                     Right Outer Join0 to 1
+                condition expressions:
+                  0 {key} {value}
+                  1 {key} {value}
+                handleSkewJoin: false
+                keys:
+                  0 [Column[key]]
+                  1 [Column[key]]
+                outputColumnNames: _col0, _col1, _col4, _col5
+                Position of Big Table: 1
+                Select Operator
+                  expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+                        expr: _col4
+                        type: string
+                        expr: _col5
+                        type: string
+                  outputColumnNames: _col0, _col1, _col4, _col5
+                  Select Operator
+                    expressions:
+                          expr: _col0
+                          type: string
+                          expr: _col1
+                          type: string
+                          expr: _col4
+                          type: string
+                          expr: _col5
+                          type: string
+                    outputColumnNames: _col0, _col1, _col2, _col3
+                    Limit
+                      File Output Operator
+                        compressed: false
+                        GlobalTableId: 0
+                        table:
+                            input format: org.apache.hadoop.mapred.TextInputFormat
+                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+      Local Work:
+        Map Reduce Local Work
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 10
+
+
+PREHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND true limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+238	val_238	238	val_238
+238	val_238	238	val_238
+86	val_86	86	val_86
+311	val_311	311	val_311
+311	val_311	311	val_311
+311	val_311	311	val_311
+27	val_27	27	val_27
+165	val_165	165	val_165
+165	val_165	165	val_165
+409	val_409	409	val_409
+PREHOOK: query: EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_RIGHTOUTERJOIN (TOK_TABREF (TOK_TABNAME src) a) (TOK_TABREF (TOK_TABNAME src) b) (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)) (< (* (. (TOK_TABLE_OR_COL b) key) 10) '1000')))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 10)))
+
+STAGE DEPENDENCIES:
+  Stage-3 is a root stage
+  Stage-1 depends on stages: Stage-3
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-3
+    Map Reduce Local Work
+      Alias -> Map Local Tables:
+        a 
+          Fetch Operator
+            limit: -1
+      Alias -> Map Local Operator Tree:
+        a 
+          TableScan
+            alias: a
+            Filter Operator
+              predicate:
+                  expr: ((key * 10) < '1000')
+                  type: boolean
+              HashTable Sink Operator
+                condition expressions:
+                  0 {key} {value}
+                  1 {key} {value}
+                handleSkewJoin: false
+                keys:
+                  0 [Column[key]]
+                  1 [Column[key]]
+                Position of Big Table: 1
+
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        b 
+          TableScan
+            alias: b
+            Filter Operator
+              predicate:
+                  expr: ((key * 10) < '1000')
+                  type: boolean
+              Map Join Operator
+                condition map:
+                     Right Outer Join0 to 1
+                condition expressions:
+                  0 {key} {value}
+                  1 {key} {value}
+                handleSkewJoin: false
+                keys:
+                  0 [Column[key]]
+                  1 [Column[key]]
+                outputColumnNames: _col0, _col1, _col4, _col5
+                Position of Big Table: 1
+                Select Operator
+                  expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+                        expr: _col4
+                        type: string
+                        expr: _col5
+                        type: string
+                  outputColumnNames: _col0, _col1, _col4, _col5
+                  Select Operator
+                    expressions:
+                          expr: _col0
+                          type: string
+                          expr: _col1
+                          type: string
+                          expr: _col4
+                          type: string
+                          expr: _col5
+                          type: string
+                    outputColumnNames: _col0, _col1, _col2, _col3
+                    Limit
+                      File Output Operator
+                        compressed: false
+                        GlobalTableId: 0
+                        table:
+                            input format: org.apache.hadoop.mapred.TextInputFormat
+                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+      Local Work:
+        Map Reduce Local Work
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 10
+
+
+PREHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN src b on a.key=b.key AND b.key * 10 < '1000' limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+86	val_86	86	val_86
+27	val_27	27	val_27
+98	val_98	98	val_98
+98	val_98	98	val_98
+66	val_66	66	val_66
+37	val_37	37	val_37
+37	val_37	37	val_37
+15	val_15	15	val_15
+15	val_15	15	val_15
+82	val_82	82	val_82
+PREHOOK: query: EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN
+SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_RIGHTOUTERJOIN (TOK_TABREF (TOK_TABNAME src) a) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_FUNCTION named_struct 'key' (TOK_TABLE_OR_COL key) 'value' (TOK_TABLE_OR_COL value)) kv)))) b) (AND (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)) (> (. (. (TOK_TABLE_OR_COL b) kv) key) 200)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_LIMIT 10)))
+
+STAGE DEPENDENCIES:
+  Stage-3 is a root stage
+  Stage-1 depends on stages: Stage-3
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-3
+    Map Reduce Local Work
+      Alias -> Map Local Tables:
+        a 
+          Fetch Operator
+            limit: -1
+      Alias -> Map Local Operator Tree:
+        a 
+          TableScan
+            alias: a
+            HashTable Sink Operator
+              condition expressions:
+                0 {key} {value}
+                1 {_col0} {_col1}
+              handleSkewJoin: false
+              keys:
+                0 [Column[key]]
+                1 [Column[_col0]]
+              Position of Big Table: 1
+
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        b:src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: named_struct('key',key,'value',value)
+                    type: struct<key:string,value:string>
+              outputColumnNames: _col0, _col1
+              Filter Operator
+                predicate:
+                    expr: (_col1.key > 200)
+                    type: boolean
+                Map Join Operator
+                  condition map:
+                       Right Outer Join0 to 1
+                  condition expressions:
+                    0 {key} {value}
+                    1 {_col0} {_col1}
+                  handleSkewJoin: false
+                  keys:
+                    0 [Column[key]]
+                    1 [Column[_col0]]
+                  outputColumnNames: _col0, _col1, _col4, _col5
+                  Position of Big Table: 1
+                  Select Operator
+                    expressions:
+                          expr: _col0
+                          type: string
+                          expr: _col1
+                          type: string
+                          expr: _col4
+                          type: string
+                          expr: _col5
+                          type: struct<key:string,value:string>
+                    outputColumnNames: _col0, _col1, _col4, _col5
+                    Select Operator
+                      expressions:
+                            expr: _col0
+                            type: string
+                            expr: _col1
+                            type: string
+                            expr: _col4
+                            type: string
+                            expr: _col5
+                            type: struct<key:string,value:string>
+                      outputColumnNames: _col0, _col1, _col2, _col3
+                      Limit
+                        File Output Operator
+                          compressed: false
+                          GlobalTableId: 0
+                          table:
+                              input format: org.apache.hadoop.mapred.TextInputFormat
+                              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+      Local Work:
+        Map Reduce Local Work
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 10
+
+
+PREHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT /*+ MAPJOIN(a) */ * FROM src a RIGHT OUTER JOIN
+    (select key, named_struct('key', key, 'value', value) as kv from src) b on a.key=b.key AND b.kv.key > 200 limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+#### A masked pattern was here ####
+238	val_238	238	{"key":"238","value":"val_238"}
+238	val_238	238	{"key":"238","value":"val_238"}
+311	val_311	311	{"key":"311","value":"val_311"}
+311	val_311	311	{"key":"311","value":"val_311"}
+311	val_311	311	{"key":"311","value":"val_311"}
+409	val_409	409	{"key":"409","value":"val_409"}
+409	val_409	409	{"key":"409","value":"val_409"}
+409	val_409	409	{"key":"409","value":"val_409"}
+255	val_255	255	{"key":"255","value":"val_255"}
+255	val_255	255	{"key":"255","value":"val_255"}
