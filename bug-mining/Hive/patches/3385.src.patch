diff --git a/itests/hive-unit/pom.xml b/itests/hive-unit/pom.xml
index 02370c34c6..58e3e93dd3 100644
--- a/itests/hive-unit/pom.xml
+++ b/itests/hive-unit/pom.xml
@@ -110,13 +110,7 @@
       <classifier>tests</classifier>
     </dependency>
     <!-- test inter-project -->
-    <dependency>
-      <groupId>org.apache.spark</groupId>
-      <artifactId>spark-core_${scala.binary.version}</artifactId>
-      <version>${spark.version}</version>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
+   <dependency>
       <groupId>junit</groupId>
       <artifactId>junit</artifactId>
       <version>${junit.version}</version>
@@ -323,6 +317,46 @@
         </dependency>
       </dependencies>
     </profile>
+    <profile>
+      <id>spark-test</id>
+      <activation>
+	<property>
+          <name>!skipSparkTests</name>
+	</property>
+      </activation>
+      <dependencies>
+        <dependency>
+          <groupId>org.apache.spark</groupId>
+          <artifactId>spark-core_${scala.binary.version}</artifactId>
+          <version>${spark.version}</version>
+          <scope>test</scope>
+        </dependency>
+      </dependencies>
+      <build>
+        <plugins>
+          <plugin>
+            <groupId>org.apache.maven.plugins</groupId>
+            <artifactId>maven-antrun-plugin</artifactId>
+            <executions>
+              <execution>
+                <id>download-spark</id>
+                <phase>generate-sources</phase>
+                <goals>
+                  <goal>run</goal>
+                </goals>
+                <configuration>
+                  <target>
+                    <exec executable="bash" dir="${basedir}" failonerror="true">
+                      <arg line="../target/download.sh"/>
+                    </exec>
+                  </target>
+                </configuration>
+              </execution>
+            </executions>
+          </plugin>
+        </plugins>
+      </build>
+    </profile>
   </profiles>
 
   <build>
@@ -331,20 +365,6 @@
         <groupId>org.apache.maven.plugins</groupId>
         <artifactId>maven-antrun-plugin</artifactId>
         <executions>
-          <execution>
-            <id>download-spark</id>
-            <phase>generate-sources</phase>
-            <goals>
-              <goal>run</goal>
-            </goals>
-            <configuration>
-              <target>
-                <exec executable="bash" dir="${basedir}" failonerror="true">
-                  <arg line="../target/download.sh"/>
-                </exec>
-              </target>
-            </configuration>
-          </execution>
           <execution>
             <id>setup-metastore-scripts</id>
             <phase>process-test-resources</phase>
diff --git a/itests/pom.xml b/itests/pom.xml
index 7289ed4132..bf909eb3d4 100644
--- a/itests/pom.xml
+++ b/itests/pom.xml
@@ -45,63 +45,67 @@
     <profile>
       <id>hadoop-2</id>
       <modules>
-        <module>qtest-spark</module>
         <module>hive-unit-hadoop2</module>
         <module>hive-minikdc</module>
       </modules>
     </profile>
     <profile>
-      <id>hadoop-1</id>
+      <id>spark-test</id>
+      <activation>
+	<property>
+          <name>!skipSparkTests</name>
+	</property>
+      </activation>
       <modules>
         <module>qtest-spark</module>
       </modules>
+      <build>
+        <plugins>
+          <plugin>
+            <groupId>org.apache.maven.plugins</groupId>
+            <artifactId>maven-antrun-plugin</artifactId>
+            <executions>
+              <execution>
+                <id>download-spark</id>
+                <phase>generate-sources</phase>
+                <goals>
+                  <goal>run</goal>
+                </goals>
+                <configuration>
+                  <target>
+                    <echo file="target/download.sh">
+                      set -x
+                      /bin/pwd
+                      BASE_DIR=./target
+                      HIVE_ROOT=$BASE_DIR/../../../
+                      DOWNLOAD_DIR=./../thirdparty
+                      download() {
+                        url=$1;
+                        finalName=$2
+                        tarName=$(basename $url)
+                        rm -rf $BASE_DIR/$finalName
+                        if [[ ! -f $DOWNLOAD_DIR/$tarName ]]
+                        then
+                         curl -Sso $DOWNLOAD_DIR/$tarName $url
+                        fi
+                        tar -zxf $DOWNLOAD_DIR/$tarName -C $BASE_DIR
+                        mv $BASE_DIR/spark-${spark.version}-bin-hadoop2-without-hive $BASE_DIR/$finalName
+                      }
+                      mkdir -p $DOWNLOAD_DIR
+                      download "http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-${spark.version}-bin-hadoop2-without-hive.tgz" "spark"
+                      cp -f $HIVE_ROOT/data/conf/spark/log4j.properties $BASE_DIR/spark/conf/
+                      sed '/package /d' ${basedir}/${hive.path.to.root}/contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleAdd.java > /tmp/UDFExampleAdd.java
+                      javac -cp  ${settings.localRepository}/org/apache/hive/hive-exec/${project.version}/hive-exec-${project.version}.jar /tmp/UDFExampleAdd.java -d /tmp
+                      jar -cf /tmp/udfexampleadd-1.0.jar -C /tmp UDFExampleAdd.class
+                    </echo>
+                  </target>
+                </configuration>
+              </execution>
+            </executions>
+          </plugin>
+        </plugins>
+      </build>
     </profile>
   </profiles>
 
-  <build>
-    <plugins>
-      <plugin>
-        <groupId>org.apache.maven.plugins</groupId>
-        <artifactId>maven-antrun-plugin</artifactId>
-        <executions>
-          <execution>
-            <id>download-spark</id>
-            <phase>generate-sources</phase>
-            <goals>
-              <goal>run</goal>
-            </goals>
-            <configuration>
-              <target>
-                <echo file="target/download.sh">
-                  set -x
-                  /bin/pwd
-                  BASE_DIR=./target
-                  HIVE_ROOT=$BASE_DIR/../../../
-                  DOWNLOAD_DIR=./../thirdparty
-                  download() {
-                    url=$1;
-                    finalName=$2
-                    tarName=$(basename $url)
-                    rm -rf $BASE_DIR/$finalName
-                    if [[ ! -f $DOWNLOAD_DIR/$tarName ]]
-                    then
-                     curl -Sso $DOWNLOAD_DIR/$tarName $url
-                    fi
-                    tar -zxf $DOWNLOAD_DIR/$tarName -C $BASE_DIR
-                    mv $BASE_DIR/spark-${spark.version}-bin-hadoop2-without-hive $BASE_DIR/$finalName
-                  }
-                  mkdir -p $DOWNLOAD_DIR
-                  download "http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-${spark.version}-bin-hadoop2-without-hive.tgz" "spark"
-                  cp -f $HIVE_ROOT/data/conf/spark/log4j.properties $BASE_DIR/spark/conf/
-                  sed '/package /d' ${basedir}/${hive.path.to.root}/contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleAdd.java > /tmp/UDFExampleAdd.java
-                  javac -cp  ${settings.localRepository}/org/apache/hive/hive-exec/${project.version}/hive-exec-${project.version}.jar /tmp/UDFExampleAdd.java -d /tmp
-                  jar -cf /tmp/udfexampleadd-1.0.jar -C /tmp UDFExampleAdd.class
-                </echo>
-              </target>
-            </configuration>
-          </execution>
-        </executions>
-      </plugin>
-    </plugins>
-  </build>
 </project>
