diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index 4153e7da43..5a093e6822 100644
--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -79,6 +79,7 @@ public static enum ConfVars {
     METASTOREDIRECTORY("hive.metastore.metadb.dir", ""),
     METASTOREWAREHOUSE("hive.metastore.warehouse.dir", ""),
     METASTOREURIS("hive.metastore.uris", ""),
+    METASTOREPWD("javax.jdo.option.ConnectionPassword", ""),
 
     // Things we log in the jobconf
 
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java b/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
index ef546df37a..ce85d78529 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
@@ -41,6 +41,7 @@
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configurable;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.api.Database;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.InvalidObjectException;
@@ -158,7 +159,7 @@ private void initDataSourceProps() {
       Map.Entry<String, String> e = iter.next();
       if(e.getKey().contains("jpox") || e.getKey().contains("jdo")) {
         Object prevVal = prop.setProperty(e.getKey(), e.getValue());
-        if(LOG.isDebugEnabled()) {
+        if(LOG.isDebugEnabled() && !e.getKey().equals(HiveConf.ConfVars.METASTOREPWD.varname)) {
           LOG.debug("Overriding " + e.getKey() + " value " + prevVal 
               + " from  jpox.properties with " + e.getValue());
         }
@@ -167,7 +168,8 @@ private void initDataSourceProps() {
 
     if(LOG.isDebugEnabled()) {
       for (Entry<Object, Object> e: prop.entrySet()) {
-        LOG.debug(e.getKey() + " = " + e.getValue());
+        if(!e.getKey().equals(HiveConf.ConfVars.METASTOREPWD.varname))
+          LOG.debug(e.getKey() + " = " + e.getValue());
       }
     }
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
index bb658b74b1..6212b231f6 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
@@ -385,12 +385,17 @@ public int execute() {
         return 0;
       }
 
+      // remove the pwd from conf file so that job tracker doesn't show this logs
+      String pwd = job.get(HiveConf.ConfVars.METASTOREPWD.varname);
+      job.set(HiveConf.ConfVars.METASTOREPWD.varname, "HIVE");
       JobClient jc = new JobClient(job);
 
       // make this client wait if job trcker is not behaving well.
       Throttle.checkJobTracker(job, LOG);
 
       orig_rj = rj = jc.submitJob(job);
+      // replace it back
+      job.set(HiveConf.ConfVars.METASTOREPWD.varname, pwd);
 
       // add to list of running jobs so in case of abnormal shutdown can kill
       // it.
