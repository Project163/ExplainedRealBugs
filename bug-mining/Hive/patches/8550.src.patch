diff --git a/ql/src/test/queries/clientpositive/alter_table_column_stats.q b/ql/src/test/queries/clientpositive/alter_table_column_stats.q
index 9bb9ed74df..16888c049f 100644
--- a/ql/src/test/queries/clientpositive/alter_table_column_stats.q
+++ b/ql/src/test/queries/clientpositive/alter_table_column_stats.q
@@ -265,3 +265,44 @@ drop table statsdb2.testtable2;
 use default;
 drop database statsdb1;
 drop database statsdb2;
+
+-- Test for external tables with hive.metastore.try.direct.sql.ddl as false
+set hive.metastore.try.direct.sql.ddl=false;
+
+drop database if exists statsdb1;
+create database statsdb1;
+
+create external table statsdb1.testtable0 (col1 int, col2 string, col3 string) row format delimited fields terminated by ',' stored as textfile tblproperties ('external.table.purge'='true');
+insert into statsdb1.testtable0 select key, value, 'val3' from src limit 10;
+
+create external table statsdb1.testpart0 (col1 int, col2 string, col3 string) partitioned by (part string) row format delimited fields terminated by ',' stored as textfile tblproperties ('external.table.purge'='true');
+insert into statsdb1.testpart0 partition (part = 'part1') select key, value, 'val3' from src limit 10;
+
+use statsdb1;
+-- test non-partitioned table
+analyze table testtable0 compute statistics for columns;
+describe formatted statsdb1.testtable0;
+describe formatted statsdb1.testtable0 col1;
+
+-- rename non-partitioned table should not change its table and columns stats
+alter table statsdb1.testtable0 rename to statsdb1.testtable1;
+describe formatted statsdb1.testtable1;
+describe formatted statsdb1.testtable1 col1;
+
+-- test partitioned table
+analyze table testpart0 compute statistics for columns;
+describe formatted statsdb1.testpart0;
+describe formatted statsdb1.testpart0 partition (part = 'part1');
+describe formatted statsdb1.testpart0 partition (part = 'part1') col1;
+
+-- rename a partitioned table should not change its table, partition, and column stats
+alter table statsdb1.testpart0 rename to statsdb1.testpart1;
+describe formatted statsdb1.testpart1;
+describe formatted statsdb1.testpart1 partition (part = 'part1');
+describe formatted statsdb1.testpart1 partition (part = 'part1') col1;
+
+drop table statsdb1.testpart1;
+drop table statsdb1.testtable1;
+
+use default;
+drop database statsdb1;
\ No newline at end of file
diff --git a/ql/src/test/results/clientpositive/llap/alter_table_column_stats.q.out b/ql/src/test/results/clientpositive/llap/alter_table_column_stats.q.out
index 0db03b12b1..8b3bd1e6da 100644
--- a/ql/src/test/results/clientpositive/llap/alter_table_column_stats.q.out
+++ b/ql/src/test/results/clientpositive/llap/alter_table_column_stats.q.out
@@ -3992,3 +3992,459 @@ POSTHOOK: query: drop database statsdb2
 POSTHOOK: type: DROPDATABASE
 POSTHOOK: Input: database:statsdb2
 POSTHOOK: Output: database:statsdb2
+PREHOOK: query: drop database if exists statsdb1
+PREHOOK: type: DROPDATABASE
+POSTHOOK: query: drop database if exists statsdb1
+POSTHOOK: type: DROPDATABASE
+PREHOOK: query: create database statsdb1
+PREHOOK: type: CREATEDATABASE
+PREHOOK: Output: database:statsdb1
+POSTHOOK: query: create database statsdb1
+POSTHOOK: type: CREATEDATABASE
+POSTHOOK: Output: database:statsdb1
+PREHOOK: query: create external table statsdb1.testtable0 (col1 int, col2 string, col3 string) row format delimited fields terminated by ',' stored as textfile tblproperties ('external.table.purge'='true')
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:statsdb1
+PREHOOK: Output: statsdb1@testtable0
+POSTHOOK: query: create external table statsdb1.testtable0 (col1 int, col2 string, col3 string) row format delimited fields terminated by ',' stored as textfile tblproperties ('external.table.purge'='true')
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:statsdb1
+POSTHOOK: Output: statsdb1@testtable0
+PREHOOK: query: insert into statsdb1.testtable0 select key, value, 'val3' from src limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: statsdb1@testtable0
+POSTHOOK: query: insert into statsdb1.testtable0 select key, value, 'val3' from src limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: statsdb1@testtable0
+POSTHOOK: Lineage: testtable0.col1 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: testtable0.col2 SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: testtable0.col3 SIMPLE []
+PREHOOK: query: create external table statsdb1.testpart0 (col1 int, col2 string, col3 string) partitioned by (part string) row format delimited fields terminated by ',' stored as textfile tblproperties ('external.table.purge'='true')
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:statsdb1
+PREHOOK: Output: statsdb1@testpart0
+POSTHOOK: query: create external table statsdb1.testpart0 (col1 int, col2 string, col3 string) partitioned by (part string) row format delimited fields terminated by ',' stored as textfile tblproperties ('external.table.purge'='true')
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:statsdb1
+POSTHOOK: Output: statsdb1@testpart0
+PREHOOK: query: insert into statsdb1.testpart0 partition (part = 'part1') select key, value, 'val3' from src limit 10
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: statsdb1@testpart0@part=part1
+POSTHOOK: query: insert into statsdb1.testpart0 partition (part = 'part1') select key, value, 'val3' from src limit 10
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: statsdb1@testpart0@part=part1
+POSTHOOK: Lineage: testpart0 PARTITION(part=part1).col1 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: testpart0 PARTITION(part=part1).col2 SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: testpart0 PARTITION(part=part1).col3 SIMPLE []
+PREHOOK: query: use statsdb1
+PREHOOK: type: SWITCHDATABASE
+PREHOOK: Input: database:statsdb1
+POSTHOOK: query: use statsdb1
+POSTHOOK: type: SWITCHDATABASE
+POSTHOOK: Input: database:statsdb1
+PREHOOK: query: analyze table testtable0 compute statistics for columns
+PREHOOK: type: ANALYZE_TABLE
+PREHOOK: Input: statsdb1@testtable0
+#### A masked pattern was here ####
+PREHOOK: Output: statsdb1@testtable0
+POSTHOOK: query: analyze table testtable0 compute statistics for columns
+POSTHOOK: type: ANALYZE_TABLE
+POSTHOOK: Input: statsdb1@testtable0
+#### A masked pattern was here ####
+POSTHOOK: Output: statsdb1@testtable0
+PREHOOK: query: describe formatted statsdb1.testtable0
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: statsdb1@testtable0
+POSTHOOK: query: describe formatted statsdb1.testtable0
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: statsdb1@testtable0
+# col_name            	data_type           	comment             
+col1                	int                 	                    
+col2                	string              	                    
+col3                	string              	                    
+	 	 
+# Detailed Table Information	 	 
+Database:           	statsdb1            	 
+#### A masked pattern was here ####
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	EXTERNAL_TABLE      	 
+Table Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"col1\":\"true\",\"col2\":\"true\",\"col3\":\"true\"}}
+	EXTERNAL            	TRUE                
+	bucketing_version   	2                   
+	external.table.purge	true                
+	numFiles            	1                   
+	numRows             	10                  
+	rawDataSize         	154                 
+	totalSize           	164                 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	field.delim         	,                   
+	serialization.format	,                   
+PREHOOK: query: describe formatted statsdb1.testtable0 col1
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: statsdb1@testtable0
+POSTHOOK: query: describe formatted statsdb1.testtable0 col1
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: statsdb1@testtable0
+col_name            	col1                
+data_type           	int                 
+min                 	27                  
+max                 	484                 
+num_nulls           	0                   
+distinct_count      	10                  
+avg_col_len         	                    
+max_col_len         	                    
+num_trues           	                    
+num_falses          	                    
+bit_vector          	HL                  
+comment             	from deserializer   
+COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"col1\":\"true\",\"col2\":\"true\",\"col3\":\"true\"}}
+PREHOOK: query: alter table statsdb1.testtable0 rename to statsdb1.testtable1
+PREHOOK: type: ALTERTABLE_RENAME
+PREHOOK: Input: statsdb1@testtable0
+PREHOOK: Output: database:statsdb1
+PREHOOK: Output: statsdb1@testtable0
+PREHOOK: Output: statsdb1@testtable1
+POSTHOOK: query: alter table statsdb1.testtable0 rename to statsdb1.testtable1
+POSTHOOK: type: ALTERTABLE_RENAME
+POSTHOOK: Input: statsdb1@testtable0
+POSTHOOK: Output: database:statsdb1
+POSTHOOK: Output: statsdb1@testtable0
+POSTHOOK: Output: statsdb1@testtable1
+PREHOOK: query: describe formatted statsdb1.testtable1
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: statsdb1@testtable1
+POSTHOOK: query: describe formatted statsdb1.testtable1
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: statsdb1@testtable1
+# col_name            	data_type           	comment             
+col1                	int                 	                    
+col2                	string              	                    
+col3                	string              	                    
+	 	 
+# Detailed Table Information	 	 
+Database:           	statsdb1            	 
+#### A masked pattern was here ####
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	EXTERNAL_TABLE      	 
+Table Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"col1\":\"true\",\"col2\":\"true\",\"col3\":\"true\"}}
+	EXTERNAL            	TRUE                
+	bucketing_version   	2                   
+	external.table.purge	true                
+#### A masked pattern was here ####
+	numFiles            	1                   
+	numRows             	10                  
+	rawDataSize         	154                 
+	totalSize           	164                 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	field.delim         	,                   
+	serialization.format	,                   
+PREHOOK: query: describe formatted statsdb1.testtable1 col1
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: statsdb1@testtable1
+POSTHOOK: query: describe formatted statsdb1.testtable1 col1
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: statsdb1@testtable1
+col_name            	col1                
+data_type           	int                 
+min                 	27                  
+max                 	484                 
+num_nulls           	0                   
+distinct_count      	10                  
+avg_col_len         	                    
+max_col_len         	                    
+num_trues           	                    
+num_falses          	                    
+bit_vector          	HL                  
+comment             	from deserializer   
+COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"col1\":\"true\",\"col2\":\"true\",\"col3\":\"true\"}}
+PREHOOK: query: analyze table testpart0 compute statistics for columns
+PREHOOK: type: ANALYZE_TABLE
+PREHOOK: Input: statsdb1@testpart0
+PREHOOK: Input: statsdb1@testpart0@part=part1
+#### A masked pattern was here ####
+PREHOOK: Output: statsdb1@testpart0
+PREHOOK: Output: statsdb1@testpart0@part=part1
+POSTHOOK: query: analyze table testpart0 compute statistics for columns
+POSTHOOK: type: ANALYZE_TABLE
+POSTHOOK: Input: statsdb1@testpart0
+POSTHOOK: Input: statsdb1@testpart0@part=part1
+#### A masked pattern was here ####
+POSTHOOK: Output: statsdb1@testpart0
+POSTHOOK: Output: statsdb1@testpart0@part=part1
+PREHOOK: query: describe formatted statsdb1.testpart0
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: statsdb1@testpart0
+POSTHOOK: query: describe formatted statsdb1.testpart0
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: statsdb1@testpart0
+# col_name            	data_type           	comment             
+col1                	int                 	                    
+col2                	string              	                    
+col3                	string              	                    
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+part                	string              	                    
+	 	 
+# Detailed Table Information	 	 
+Database:           	statsdb1            	 
+#### A masked pattern was here ####
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	EXTERNAL_TABLE      	 
+Table Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\"}
+	EXTERNAL            	TRUE                
+	bucketing_version   	2                   
+	external.table.purge	true                
+	numFiles            	1                   
+	numPartitions       	1                   
+	numRows             	10                  
+	rawDataSize         	154                 
+	totalSize           	164                 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	field.delim         	,                   
+	serialization.format	,                   
+PREHOOK: query: describe formatted statsdb1.testpart0 partition (part = 'part1')
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: statsdb1@testpart0
+POSTHOOK: query: describe formatted statsdb1.testpart0 partition (part = 'part1')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: statsdb1@testpart0
+# col_name            	data_type           	comment             
+col1                	int                 	                    
+col2                	string              	                    
+col3                	string              	                    
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+part                	string              	                    
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[part1]             	 
+Database:           	statsdb1            	 
+Table:              	testpart0           	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"col1\":\"true\",\"col2\":\"true\",\"col3\":\"true\"}}
+	numFiles            	1                   
+	numRows             	10                  
+	rawDataSize         	154                 
+	totalSize           	164                 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	field.delim         	,                   
+	serialization.format	,                   
+PREHOOK: query: describe formatted statsdb1.testpart0 partition (part = 'part1') col1
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: statsdb1@testpart0
+POSTHOOK: query: describe formatted statsdb1.testpart0 partition (part = 'part1') col1
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: statsdb1@testpart0
+col_name            	col1                
+data_type           	int                 
+min                 	27                  
+max                 	484                 
+num_nulls           	0                   
+distinct_count      	10                  
+avg_col_len         	                    
+max_col_len         	                    
+num_trues           	                    
+num_falses          	                    
+bit_vector          	HL                  
+comment             	from deserializer   
+PREHOOK: query: alter table statsdb1.testpart0 rename to statsdb1.testpart1
+PREHOOK: type: ALTERTABLE_RENAME
+PREHOOK: Input: statsdb1@testpart0
+PREHOOK: Output: database:statsdb1
+PREHOOK: Output: statsdb1@testpart0
+PREHOOK: Output: statsdb1@testpart1
+POSTHOOK: query: alter table statsdb1.testpart0 rename to statsdb1.testpart1
+POSTHOOK: type: ALTERTABLE_RENAME
+POSTHOOK: Input: statsdb1@testpart0
+POSTHOOK: Output: database:statsdb1
+POSTHOOK: Output: statsdb1@testpart0
+POSTHOOK: Output: statsdb1@testpart1
+PREHOOK: query: describe formatted statsdb1.testpart1
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: statsdb1@testpart1
+POSTHOOK: query: describe formatted statsdb1.testpart1
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: statsdb1@testpart1
+# col_name            	data_type           	comment             
+col1                	int                 	                    
+col2                	string              	                    
+col3                	string              	                    
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+part                	string              	                    
+	 	 
+# Detailed Table Information	 	 
+Database:           	statsdb1            	 
+#### A masked pattern was here ####
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	EXTERNAL_TABLE      	 
+Table Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\"}
+	EXTERNAL            	TRUE                
+	bucketing_version   	2                   
+	external.table.purge	true                
+#### A masked pattern was here ####
+	numFiles            	1                   
+	numPartitions       	1                   
+	numRows             	10                  
+	rawDataSize         	154                 
+	totalSize           	164                 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	field.delim         	,                   
+	serialization.format	,                   
+PREHOOK: query: describe formatted statsdb1.testpart1 partition (part = 'part1')
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: statsdb1@testpart1
+POSTHOOK: query: describe formatted statsdb1.testpart1 partition (part = 'part1')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: statsdb1@testpart1
+# col_name            	data_type           	comment             
+col1                	int                 	                    
+col2                	string              	                    
+col3                	string              	                    
+	 	 
+# Partition Information	 	 
+# col_name            	data_type           	comment             
+part                	string              	                    
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[part1]             	 
+Database:           	statsdb1            	 
+Table:              	testpart1           	 
+#### A masked pattern was here ####
+Partition Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"col1\":\"true\",\"col2\":\"true\",\"col3\":\"true\"}}
+	numFiles            	1                   
+	numRows             	10                  
+	rawDataSize         	154                 
+	totalSize           	164                 
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	field.delim         	,                   
+	serialization.format	,                   
+PREHOOK: query: describe formatted statsdb1.testpart1 partition (part = 'part1') col1
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: statsdb1@testpart1
+POSTHOOK: query: describe formatted statsdb1.testpart1 partition (part = 'part1') col1
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: statsdb1@testpart1
+col_name            	col1                
+data_type           	int                 
+min                 	27                  
+max                 	484                 
+num_nulls           	0                   
+distinct_count      	10                  
+avg_col_len         	                    
+max_col_len         	                    
+num_trues           	                    
+num_falses          	                    
+bit_vector          	HL                  
+comment             	from deserializer   
+PREHOOK: query: drop table statsdb1.testpart1
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: statsdb1@testpart1
+PREHOOK: Output: database:statsdb1
+PREHOOK: Output: statsdb1@testpart1
+POSTHOOK: query: drop table statsdb1.testpart1
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: statsdb1@testpart1
+POSTHOOK: Output: database:statsdb1
+POSTHOOK: Output: statsdb1@testpart1
+PREHOOK: query: drop table statsdb1.testtable1
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: statsdb1@testtable1
+PREHOOK: Output: database:statsdb1
+PREHOOK: Output: statsdb1@testtable1
+POSTHOOK: query: drop table statsdb1.testtable1
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: statsdb1@testtable1
+POSTHOOK: Output: database:statsdb1
+POSTHOOK: Output: statsdb1@testtable1
+PREHOOK: query: use default
+PREHOOK: type: SWITCHDATABASE
+PREHOOK: Input: database:default
+POSTHOOK: query: use default
+POSTHOOK: type: SWITCHDATABASE
+POSTHOOK: Input: database:default
+PREHOOK: query: drop database statsdb1
+PREHOOK: type: DROPDATABASE
+PREHOOK: Input: database:statsdb1
+PREHOOK: Output: database:statsdb1
+POSTHOOK: query: drop database statsdb1
+POSTHOOK: type: DROPDATABASE
+POSTHOOK: Input: database:statsdb1
+POSTHOOK: Output: database:statsdb1
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
index 5df5c54331..571f5aae36 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
@@ -253,7 +253,8 @@ public void alterTable(RawStore msdb, Warehouse wh, String catName, String dbnam
 
       boolean renamedTranslatedToExternalTable = rename && MetaStoreUtils.isTranslatedToExternalTable(oldt)
           && MetaStoreUtils.isTranslatedToExternalTable(newt);
-
+      boolean renamedExternalTable = rename && MetaStoreUtils.isExternalTable(oldt)
+          && !MetaStoreUtils.isPropertyTrue(oldt.getParameters(), "TRANSLATED_TO_EXTERNAL");
       boolean isRenameIcebergTable =
           rename && HiveMetaHook.ICEBERG.equalsIgnoreCase(newt.getParameters().get(HiveMetaHook.TABLE_TYPE));
 
@@ -261,7 +262,8 @@ public void alterTable(RawStore msdb, Warehouse wh, String catName, String dbnam
       columnStatistics = deleteTableColumnStats(msdb, oldt, newt, columnStatistics);
 
       if (!isRenameIcebergTable &&
-          (replDataLocationChanged || renamedManagedTable || renamedTranslatedToExternalTable)) {
+          (replDataLocationChanged || renamedManagedTable || renamedTranslatedToExternalTable ||
+              renamedExternalTable)) {
         srcPath = new Path(oldt.getSd().getLocation());
 
         if (replDataLocationChanged) {
@@ -272,7 +274,7 @@ public void alterTable(RawStore msdb, Warehouse wh, String catName, String dbnam
           // separately.
           destPath = new Path(newt.getSd().getLocation());
           dataWasMoved = true;
-        } else {
+        } else if (!renamedExternalTable) {
           // Rename flow.
           // If a table was created in a user specified location using the DDL like
           // create table tbl ... location ...., it should be treated like an external table
