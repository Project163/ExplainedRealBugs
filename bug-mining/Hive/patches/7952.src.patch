diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
index eaa233d90a..2cbd60841e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
@@ -381,6 +381,7 @@ public final class FunctionRegistry {
     system.registerGenericUDF("=", GenericUDFOPEqual.class);
     system.registerGenericUDF("==", GenericUDFOPEqual.class);
     system.registerGenericUDF("<=>", GenericUDFOPEqualNS.class);
+    system.registerGenericUDF("is_not_distinct_from", GenericUDFOPEqualNS.class);
     system.registerGenericUDF("!=", GenericUDFOPNotEqual.class);
     system.registerGenericUDF("<>", GenericUDFOPNotEqual.class);
     system.registerGenericUDF("<", GenericUDFOPLessThan.class);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRexExecutorImpl.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRexExecutorImpl.java
index 08b4e8db4b..47ee70f8ad 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRexExecutorImpl.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRexExecutorImpl.java
@@ -51,7 +51,7 @@ public void reduce(RexBuilder rexBuilder, List<RexNode> constExps, List<RexNode>
     for (RexNode rexNode : constExps) {
       // initialize the converter
       ExprNodeConverter converter = new ExprNodeConverter("", null, null, null,
-          new HashSet<>(), rexBuilder.getTypeFactory());
+          new HashSet<>(), rexBuilder);
       // convert RexNode to ExprNodeGenericFuncDesc
       ExprNodeDesc expr = rexNode.accept(converter);
       if (expr instanceof ExprNodeGenericFuncDesc) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java
index 8ba3f0c92c..6ae72c3b70 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java
@@ -19,6 +19,7 @@
 
 import java.math.BigDecimal;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.Comparator;
 import java.util.LinkedList;
 import java.util.List;
@@ -59,6 +60,7 @@
 import org.apache.calcite.rex.RexWindowBound;
 import org.apache.calcite.sql.SqlKind;
 import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
 import org.apache.calcite.sql.type.SqlTypeName;
 import org.apache.calcite.util.ImmutableBitSet;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
@@ -788,6 +790,12 @@ public ASTNode visitCall(RexCall call) {
           }
         }
         break;
+      case IS_DISTINCT_FROM:
+        for (RexNode operand : call.operands) {
+          astNodeLst.add(operand.accept(this));
+        }
+        return SqlFunctionConverter.buildAST(SqlStdOperatorTable.NOT,
+          Collections.singletonList(SqlFunctionConverter.buildAST(SqlStdOperatorTable.IS_NOT_DISTINCT_FROM, astNodeLst)));
       case CAST:
         assert(call.getOperands().size() == 1);
         if (call.getType().isStruct() ||
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ExprNodeConverter.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ExprNodeConverter.java
index 3ef5869986..62c132545f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ExprNodeConverter.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ExprNodeConverter.java
@@ -29,6 +29,7 @@
 import org.apache.calcite.rel.type.RelDataType;
 import org.apache.calcite.rel.type.RelDataTypeFactory;
 import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
 import org.apache.calcite.rex.RexCall;
 import org.apache.calcite.rex.RexFieldAccess;
 import org.apache.calcite.rex.RexFieldCollation;
@@ -41,6 +42,7 @@
 import org.apache.calcite.rex.RexWindow;
 import org.apache.calcite.rex.RexWindowBound;
 import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
 import org.apache.calcite.sql.type.SqlTypeUtil;
 import org.apache.calcite.util.DateString;
 import org.apache.calcite.util.NlsString;
@@ -106,6 +108,7 @@ public class ExprNodeConverter extends RexVisitorImpl<ExprNodeDesc> {
   private final RelDataTypeFactory dTFactory;
   protected final Logger LOG = LoggerFactory.getLogger(this.getClass().getName());
   private static long uniqueCounter = 0;
+  private RexBuilder rexBuilder = null;
 
   public ExprNodeConverter(String tabAlias, RelDataType inputRowType,
       Set<Integer> vCols, RelDataTypeFactory dTFactory) {
@@ -122,6 +125,12 @@ public ExprNodeConverter(String tabAlias, String columnAlias, RelDataType inputR
     this(tabAlias, columnAlias, inputRowType, outputRowType, inputVCols, dTFactory, false);
   }
 
+  public ExprNodeConverter(String tabAlias, String columnAlias, RelDataType inputRowType,
+                           RelDataType outputRowType, Set<Integer> inputVCols, RexBuilder rexBuilder) {
+    this(tabAlias, columnAlias, inputRowType, outputRowType, inputVCols, rexBuilder.getTypeFactory(), false);
+    this.rexBuilder = rexBuilder;
+  }
+
   public ExprNodeConverter(String tabAlias, String columnAlias, RelDataType inputRowType,
           RelDataType outputRowType, Set<Integer> inputVCols, RelDataTypeFactory dTFactory,
           boolean foldExpr) {
@@ -189,6 +198,11 @@ public ExprNodeDesc visitCall(RexCall call) {
       // is implicit in the function name, thus translation will
       // proceed correctly if we just ignore the <time_unit>
       args.add(call.operands.get(0).accept(this));
+    } else if (call.getKind() == SqlKind.IS_DISTINCT_FROM) {
+      call = (RexCall) RexUtil.not(rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_DISTINCT_FROM, call.operands));
+      for (RexNode operand : call.operands) {
+        args.add(operand.accept(this));
+      }
     } else {
       for (RexNode operand : call.operands) {
         args.add(operand.accept(this));
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java
index bfbba92ef3..56fd6f5653 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java
@@ -392,7 +392,8 @@ private static class StaticBlockBuilder {
       registerFunction("istrue", SqlStdOperatorTable.IS_TRUE, hToken(HiveParser.Identifier, "istrue"));
       registerFunction("isnotfalse", SqlStdOperatorTable.IS_NOT_FALSE, hToken(HiveParser.Identifier, "isnotfalse"));
       registerFunction("isfalse", SqlStdOperatorTable.IS_FALSE, hToken(HiveParser.Identifier, "isfalse"));
-      registerFunction("<=>", SqlStdOperatorTable.IS_NOT_DISTINCT_FROM, hToken(HiveParser.EQUAL_NS, "<=>"));
+      registerFunction("is_not_distinct_from", SqlStdOperatorTable.IS_NOT_DISTINCT_FROM, hToken(HiveParser.EQUAL_NS, "<=>"));
+      registerDuplicateFunction("<=>", SqlStdOperatorTable.IS_NOT_DISTINCT_FROM, hToken(HiveParser.EQUAL_NS, "<=>"));
       registerFunction("when", SqlStdOperatorTable.CASE, hToken(HiveParser.Identifier, "when"));
       registerDuplicateFunction("case", SqlStdOperatorTable.CASE, hToken(HiveParser.Identifier, "when"));
       registerFunction("coalesce", SqlStdOperatorTable.COALESCE, hToken(HiveParser.Identifier, "coalesce"));
@@ -566,12 +567,6 @@ public static SqlOperator getCalciteFn(String hiveUdfName,
       boolean deterministic, boolean runtimeConstant)
       throws CalciteSemanticException {
 
-    if (hiveUdfName != null && hiveUdfName.trim().equals("<=>")) {
-      // We can create Calcite IS_DISTINCT_FROM operator for this. But since our
-      // join reordering algo cant handle this anyway there is no advantage of
-      // this.So, bail out for now.
-      throw new CalciteSemanticException("<=> is not yet supported for cbo.", UnsupportedFeature.Less_than_equal_greater_than);
-    }
     SqlOperator calciteOp;
     CalciteUDFInfo uInf = getUDFInfo(hiveUdfName, calciteArgTypes, calciteRetType);
     switch (hiveUdfName) {
diff --git a/ql/src/test/queries/clientnegative/cbo_fallback_never_semantic_exception.q b/ql/src/test/queries/clientnegative/cbo_fallback_never_semantic_exception.q
deleted file mode 100644
index c2d51b63a0..0000000000
--- a/ql/src/test/queries/clientnegative/cbo_fallback_never_semantic_exception.q
+++ /dev/null
@@ -1,5 +0,0 @@
---! qt:dataset:src
-set hive.cbo.fallback.strategy=NEVER;
--- The query generates initially a CalciteSemanticException on CBO but can be handled by the legacy optimizer
--- In NEVER mode we never fallback so the error should contain the CalciteSemanticException
-select count(*) from src where key <=> 100;
\ No newline at end of file
diff --git a/ql/src/test/queries/clientpositive/explainuser_1.q b/ql/src/test/queries/clientpositive/explainuser_1.q
index ce967f490b..747cc99486 100644
--- a/ql/src/test/queries/clientpositive/explainuser_1.q
+++ b/ql/src/test/queries/clientpositive/explainuser_1.q
@@ -327,20 +327,31 @@ select src1.key as k1, src1.value as v1,
 CREATE TABLE myinput1_n7(key int, value int);
 LOAD DATA LOCAL INPATH '../../data/files/in8.txt' INTO TABLE myinput1_n7;
 
+explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value;
 explain select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value;
 
+explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value join myinput1_n7 c on a.key=c.key;
 explain select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value join myinput1_n7 c on a.key=c.key;
 
+explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value join myinput1_n7 c on a.key<=>c.key;
 explain select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value join myinput1_n7 c on a.key<=>c.key;
 
+explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value AND a.value=b.key join myinput1_n7 c on a.key<=>c.key AND a.value=c.value;
 explain select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value AND a.value=b.key join myinput1_n7 c on a.key<=>c.key AND a.value=c.value;
 
+explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value AND a.value<=>b.key join myinput1_n7 c on a.key<=>c.key AND a.value<=>c.value;
 explain select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value AND a.value<=>b.key join myinput1_n7 c on a.key<=>c.key AND a.value<=>c.value;
 
+explain cbo select * FROM myinput1_n7 a LEFT OUTER JOIN myinput1_n7 b ON a.key<=>b.value;
 explain select * FROM myinput1_n7 a LEFT OUTER JOIN myinput1_n7 b ON a.key<=>b.value;
+
+explain cbo select * FROM myinput1_n7 a RIGHT OUTER JOIN myinput1_n7 b ON a.key<=>b.value;
 explain select * FROM myinput1_n7 a RIGHT OUTER JOIN myinput1_n7 b ON a.key<=>b.value;
+
+explain cbo select * FROM myinput1_n7 a FULL OUTER JOIN myinput1_n7 b ON a.key<=>b.value;
 explain select * FROM myinput1_n7 a FULL OUTER JOIN myinput1_n7 b ON a.key<=>b.value;
 
+explain cbo select /*+ MAPJOIN(b) */ * FROM myinput1_n7 a JOIN myinput1_n7 b ON a.key<=>b.value;
 explain select /*+ MAPJOIN(b) */ * FROM myinput1_n7 a JOIN myinput1_n7 b ON a.key<=>b.value;
 
 CREATE TABLE smb_input_n0(key int, value int);
@@ -363,10 +374,19 @@ SET hive.input.format = org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;
 
 analyze table smb_input1_n2 compute statistics;
 
+explain cbo select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key;
 explain select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key;
+
+explain cbo select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key AND a.value <=> b.value;
 explain select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key AND a.value <=> b.value;
+
+explain cbo select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a RIGHT OUTER JOIN smb_input1_n2 b ON a.key <=> b.key;
 explain select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a RIGHT OUTER JOIN smb_input1_n2 b ON a.key <=> b.key;
+
+explain cbo select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key;
 explain select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key;
+
+explain cbo select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a LEFT OUTER JOIN smb_input1_n2 b ON a.key <=> b.key;
 explain select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a LEFT OUTER JOIN smb_input1_n2 b ON a.key <=> b.key;
 
 drop table sales_n0;
diff --git a/ql/src/test/queries/clientpositive/is_distinct_from.q b/ql/src/test/queries/clientpositive/is_distinct_from.q
index cf417a7c24..40b55863dd 100644
--- a/ql/src/test/queries/clientpositive/is_distinct_from.q
+++ b/ql/src/test/queries/clientpositive/is_distinct_from.q
@@ -45,3 +45,17 @@ explain select * from part where p_size is not distinct from 2;
 select * from part where p_size is not distinct from 2;
 
 
+-- insert
+create table t2(c0 boolean, c1 float );
+insert into t2(c0) values (not (0.379 is not distinct from 641));
+insert into t2(c0,c1) values (not (0.379 is not distinct from 641), 0.2);
+
+select * from t2;
+
+
+create table if not exists t0(c0 boolean unique disable novalidate, c1 float, c2 boolean);
+insert into t0(c2, c1, c0)
+values (0.4144825 is distinct from 0.6828972,
+        0.14, true);
+
+select * from t0;
diff --git a/ql/src/test/queries/clientpositive/join_is_not_distinct_from.q b/ql/src/test/queries/clientpositive/join_is_not_distinct_from.q
index aec7deac54..6a1c013dec 100644
--- a/ql/src/test/queries/clientpositive/join_is_not_distinct_from.q
+++ b/ql/src/test/queries/clientpositive/join_is_not_distinct_from.q
@@ -5,20 +5,24 @@ CREATE TABLE myinput1_n10(key int, value int);
 LOAD DATA LOCAL INPATH '../../data/files/in8.txt' INTO TABLE myinput1_n10;
 
 -- merging
+explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value;
 explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value;
 -- SORT_QUERY_RESULTS
 select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value;
 
+explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key=c.key;
 explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key=c.key;
 select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key=c.key;
 
+explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key is not distinct from c.key;
 explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key is not distinct from c.key;
 select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key is not distinct from c.key;
 
+explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value=b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value=c.value;
 explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value=b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value=c.value;
-
 select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value=b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value=c.value;
 
+explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value is not distinct from b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value is not distinct from c.value;
 explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value is not distinct from b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value is not distinct from c.value;
 select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value is not distinct from b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value is not distinct from c.value;
 
@@ -67,5 +71,6 @@ SELECT /*+ MAPJOIN(b) */ * FROM smb_input2_n5 a JOIN smb_input2_n5 b ON a.value
 SELECT /*+ MAPJOIN(b) */ * FROM smb_input2_n5 a LEFT OUTER JOIN smb_input2_n5 b ON a.value  is not distinct from  b.value;
 
 --HIVE-3315 join predicate transitive
+explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.key is NULL;
 explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.key is NULL;
 select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.key is NULL;
diff --git a/ql/src/test/queries/clientpositive/join_nullsafe.q b/ql/src/test/queries/clientpositive/join_nullsafe.q
index 0cf0056bf4..f7cf2dd2ea 100644
--- a/ql/src/test/queries/clientpositive/join_nullsafe.q
+++ b/ql/src/test/queries/clientpositive/join_nullsafe.q
@@ -5,20 +5,24 @@ CREATE TABLE myinput1_n9(key int, value int);
 LOAD DATA LOCAL INPATH '../../data/files/in8.txt' INTO TABLE myinput1_n9;
 
 -- merging
+explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value;
 explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value;
 -- SORT_QUERY_RESULTS
 select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value;
 
+explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key=c.key;
 explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key=c.key;
 select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key=c.key;
 
+explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key<=>c.key;
 explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key<=>c.key;
 select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key<=>c.key;
 
+explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value=b.key join myinput1_n9 c on a.key<=>c.key AND a.value=c.value;
 explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value=b.key join myinput1_n9 c on a.key<=>c.key AND a.value=c.value;
-
 select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value=b.key join myinput1_n9 c on a.key<=>c.key AND a.value=c.value;
 
+explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value<=>b.key join myinput1_n9 c on a.key<=>c.key AND a.value<=>c.value;
 explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value<=>b.key join myinput1_n9 c on a.key<=>c.key AND a.value<=>c.value;
 select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value<=>b.key join myinput1_n9 c on a.key<=>c.key AND a.value<=>c.value;
 
@@ -67,5 +71,6 @@ SELECT /*+ MAPJOIN(b) */ * FROM smb_input2_n4 a JOIN smb_input2_n4 b ON a.value
 SELECT /*+ MAPJOIN(b) */ * FROM smb_input2_n4 a LEFT OUTER JOIN smb_input2_n4 b ON a.value <=> b.value;
 
 --HIVE-3315 join predicate transitive
+explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.key is NULL;
 explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.key is NULL;
 select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.key is NULL;
diff --git a/ql/src/test/queries/clientpositive/semijoin6.q b/ql/src/test/queries/clientpositive/semijoin6.q
index 86404f5aaa..c8890fed37 100644
--- a/ql/src/test/queries/clientpositive/semijoin6.q
+++ b/ql/src/test/queries/clientpositive/semijoin6.q
@@ -12,6 +12,9 @@ select * from tx1_n1 u left semi join tx2_n0 v on u.a=v.a;
 
 select * from tx1_n1 u left semi join tx2_n0 v on u.a=v.a;
 
+explain cbo
+select * from tx1_n1 u left semi join tx2_n0 v on u.b <=> v.b;
+
 explain
 select * from tx1_n1 u left semi join tx2_n0 v on u.b <=> v.b;
 
diff --git a/ql/src/test/queries/clientpositive/tez_union_group_by.q b/ql/src/test/queries/clientpositive/tez_union_group_by.q
index 5cd7ed7bf1..1788b600f0 100644
--- a/ql/src/test/queries/clientpositive/tez_union_group_by.q
+++ b/ql/src/test/queries/clientpositive/tez_union_group_by.q
@@ -34,7 +34,7 @@ id int
 STORED AS ORC 
 TBLPROPERTIES ("orc.compress"="ZLIB");
 
-EXPLAIN 
+EXPLAIN CBO
 SELECT o.u, n.u
 FROM 
 (
@@ -61,6 +61,33 @@ GROUP BY x_n3.u
 ON n.u = o.u 
 WHERE n.u <> 0 AND n.ft <= '2014-09-02';
 
+EXPLAIN
+SELECT o.u, n.u
+FROM
+(
+SELECT m.u, Min(`date`) as ft
+FROM
+(
+SELECT u, `date` FROM x_n3 WHERE `date` < '2014-09-02'
+UNION ALL
+SELECT u, `date` FROM y_n1 WHERE `date` < '2014-09-02'
+UNION ALL
+SELECT u, `date` FROM z_n0 WHERE `date` < '2014-09-02'
+) m
+GROUP BY m.u
+) n
+LEFT OUTER JOIN
+(
+SELECT x_n3.u
+FROM x_n3
+JOIN v_n15
+ON (x_n3.t = v_n15.t AND x_n3.st <=> v_n15.st)
+WHERE x_n3.`date` >= '2014-03-04' AND x_n3.`date` < '2014-09-03'
+GROUP BY x_n3.u
+) o
+ON n.u = o.u
+WHERE n.u <> 0 AND n.ft <= '2014-09-02';
+
 SELECT o.u, n.u
 FROM 
 (
diff --git a/ql/src/test/results/clientnegative/cbo_fallback_never_semantic_exception.q.out b/ql/src/test/results/clientnegative/cbo_fallback_never_semantic_exception.q.out
deleted file mode 100644
index 222def56e3..0000000000
--- a/ql/src/test/results/clientnegative/cbo_fallback_never_semantic_exception.q.out
+++ /dev/null
@@ -1 +0,0 @@
-FAILED: CalciteSemanticException <=> is not yet supported for cbo.
diff --git a/ql/src/test/results/clientpositive/llap/cbo_fallback_always_semantic_exception.q.out b/ql/src/test/results/clientpositive/llap/cbo_fallback_always_semantic_exception.q.out
index 146d34ee29..3b6531ad2b 100644
--- a/ql/src/test/results/clientpositive/llap/cbo_fallback_always_semantic_exception.q.out
+++ b/ql/src/test/results/clientpositive/llap/cbo_fallback_always_semantic_exception.q.out
@@ -6,7 +6,7 @@ POSTHOOK: query: explain select count(*) from src where key <=> 100
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
@@ -23,9 +23,9 @@ Stage-0
           PARTITION_ONLY_SHUFFLE [RS_12]
             Group By Operator [GBY_11] (rows=1 width=8)
               Output:["_col0"],aggregations:["count()"]
-              Select Operator [SEL_10] (rows=2 width=87)
-                Filter Operator [FIL_9] (rows=2 width=87)
-                  predicate:(key IS NOT DISTINCT FROM 100)
+              Select Operator [SEL_10] (rows=250 width=87)
+                Filter Operator [FIL_9] (rows=250 width=87)
+                  predicate:(UDFToDouble(key) IS NOT DISTINCT FROM 100.0D)
                   TableScan [TS_0] (rows=500 width=87)
                     default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key"]
 
diff --git a/ql/src/test/results/clientpositive/llap/cbo_fallback_conservative_semantic_exception.q.out b/ql/src/test/results/clientpositive/llap/cbo_fallback_conservative_semantic_exception.q.out
index 146d34ee29..3b6531ad2b 100644
--- a/ql/src/test/results/clientpositive/llap/cbo_fallback_conservative_semantic_exception.q.out
+++ b/ql/src/test/results/clientpositive/llap/cbo_fallback_conservative_semantic_exception.q.out
@@ -6,7 +6,7 @@ POSTHOOK: query: explain select count(*) from src where key <=> 100
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
@@ -23,9 +23,9 @@ Stage-0
           PARTITION_ONLY_SHUFFLE [RS_12]
             Group By Operator [GBY_11] (rows=1 width=8)
               Output:["_col0"],aggregations:["count()"]
-              Select Operator [SEL_10] (rows=2 width=87)
-                Filter Operator [FIL_9] (rows=2 width=87)
-                  predicate:(key IS NOT DISTINCT FROM 100)
+              Select Operator [SEL_10] (rows=250 width=87)
+                Filter Operator [FIL_9] (rows=250 width=87)
+                  predicate:(UDFToDouble(key) IS NOT DISTINCT FROM 100.0D)
                   TableScan [TS_0] (rows=500 width=87)
                     default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key"]
 
diff --git a/ql/src/test/results/clientpositive/llap/cbo_fallback_test_semantic_exception.q.out b/ql/src/test/results/clientpositive/llap/cbo_fallback_test_semantic_exception.q.out
index 146d34ee29..3b6531ad2b 100644
--- a/ql/src/test/results/clientpositive/llap/cbo_fallback_test_semantic_exception.q.out
+++ b/ql/src/test/results/clientpositive/llap/cbo_fallback_test_semantic_exception.q.out
@@ -6,7 +6,7 @@ POSTHOOK: query: explain select count(*) from src where key <=> 100
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
@@ -23,9 +23,9 @@ Stage-0
           PARTITION_ONLY_SHUFFLE [RS_12]
             Group By Operator [GBY_11] (rows=1 width=8)
               Output:["_col0"],aggregations:["count()"]
-              Select Operator [SEL_10] (rows=2 width=87)
-                Filter Operator [FIL_9] (rows=2 width=87)
-                  predicate:(key IS NOT DISTINCT FROM 100)
+              Select Operator [SEL_10] (rows=250 width=87)
+                Filter Operator [FIL_9] (rows=250 width=87)
+                  predicate:(UDFToDouble(key) IS NOT DISTINCT FROM 100.0D)
                   TableScan [TS_0] (rows=500 width=87)
                     default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key"]
 
diff --git a/ql/src/test/results/clientpositive/llap/compare_cols_null.q.out b/ql/src/test/results/clientpositive/llap/compare_cols_null.q.out
index e63f3a8f0f..44521cc933 100644
--- a/ql/src/test/results/clientpositive/llap/compare_cols_null.q.out
+++ b/ql/src/test/results/clientpositive/llap/compare_cols_null.q.out
@@ -113,6 +113,11 @@ POSTHOOK: query: explain cbo select * from ccn_table where key <=> '123a'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@ccn_table
 #### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[$0], value=[$1])
+  HiveFilter(condition=[IS NOT DISTINCT FROM(CAST($0):DOUBLE, null:DOUBLE)])
+    HiveTableScan(table=[[default, ccn_table]], table:alias=[ccn_table])
+
 PREHOOK: query: select * from ccn_table where key <=> '123a'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@ccn_table
@@ -121,6 +126,7 @@ POSTHOOK: query: select * from ccn_table where key <=> '123a'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@ccn_table
 #### A masked pattern was here ####
+NULL	t1
 PREHOOK: query: drop table ccn_table
 PREHOOK: type: DROPTABLE
 PREHOOK: Input: default@ccn_table
diff --git a/ql/src/test/results/clientpositive/llap/explainuser_1.q.out b/ql/src/test/results/clientpositive/llap/explainuser_1.q.out
index e4111dca92..b86695e81f 100644
--- a/ql/src/test/results/clientpositive/llap/explainuser_1.q.out
+++ b/ql/src/test/results/clientpositive/llap/explainuser_1.q.out
@@ -3932,6 +3932,21 @@ POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/in8.txt' INTO TABLE my
 POSTHOOK: type: LOAD
 #### A masked pattern was here ####
 POSTHOOK: Output: default@myinput1_n7
+PREHOOK: query: explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[IS NOT DISTINCT FROM($0, $3)], joinType=[inner], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n7]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n7]], table:alias=[b])
+
 PREHOOK: query: explain select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n7
@@ -3940,7 +3955,7 @@ POSTHOOK: query: explain select * from myinput1_n7 a join myinput1_n7 b on a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@myinput1_n7
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 3 (SIMPLE_EDGE)
@@ -3950,22 +3965,45 @@ Stage-0
     limit:-1
     Stage-1
       Reducer 2 llap
-      File Output Operator [FS_6]
-        Select Operator [SEL_5] (rows=1 width=8)
-          Output:["_col0","_col1","_col2","_col3"]
-          Merge Join Operator [MERGEJOIN_7] (rows=1 width=8)
-            Conds:RS_2.key=RS_3.value(Inner),Output:["_col0","_col1","_col6","_col7"]
-          <-Map 1 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_2]
-              PartitionCols:key
+      File Output Operator [FS_8]
+        Merge Join Operator [MERGEJOIN_9] (rows=1 width=8)
+          Conds:RS_4._col0=RS_5._col1(Inner),Output:["_col0","_col1","_col2","_col3"]
+        <-Map 1 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_4]
+            PartitionCols:_col0
+            Select Operator [SEL_1] (rows=1 width=8)
+              Output:["_col0","_col1"]
               TableScan [TS_0] (rows=1 width=8)
                 default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
-          <-Map 3 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_3]
-              PartitionCols:value
-              TableScan [TS_1] (rows=1 width=8)
+        <-Map 3 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_5]
+            PartitionCols:_col1
+            Select Operator [SEL_3] (rows=1 width=8)
+              Output:["_col0","_col1"]
+              TableScan [TS_2] (rows=1 width=8)
                 default@myinput1_n7,b,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
 
+PREHOOK: query: explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value join myinput1_n7 c on a.key=c.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value join myinput1_n7 c on a.key=c.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[$0], value=[$1], key0=[$4], value0=[$5], key1=[$2], value1=[$3])
+  HiveJoin(condition=[IS NOT DISTINCT FROM($0, $5)], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveJoin(condition=[=($0, $2)], joinType=[inner], algorithm=[none], cost=[not available])
+      HiveProject(key=[$0], value=[$1])
+        HiveFilter(condition=[IS NOT NULL($0)])
+          HiveTableScan(table=[[default, myinput1_n7]], table:alias=[a])
+      HiveProject(key=[$0], value=[$1])
+        HiveFilter(condition=[IS NOT NULL($0)])
+          HiveTableScan(table=[[default, myinput1_n7]], table:alias=[c])
+    HiveProject(key=[$0], value=[$1])
+      HiveTableScan(table=[[default, myinput1_n7]], table:alias=[b])
+
 PREHOOK: query: explain select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value join myinput1_n7 c on a.key=c.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n7
@@ -3974,45 +4012,70 @@ POSTHOOK: query: explain select * from myinput1_n7 a join myinput1_n7 b on a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@myinput1_n7
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
-Reducer 3 <- Map 1 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
+Reducer 3 <- Map 4 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
 
 Stage-0
   Fetch Operator
     limit:-1
     Stage-1
       Reducer 3 llap
-      File Output Operator [FS_12]
-        Select Operator [SEL_11] (rows=1 width=8)
+      File Output Operator [FS_15]
+        Select Operator [SEL_14] (rows=1 width=8)
           Output:["_col0","_col1","_col2","_col3","_col4","_col5"]
-          Merge Join Operator [MERGEJOIN_41] (rows=1 width=8)
-            Conds:RS_7._col0=RS_9.key(Inner),Output:["_col0","_col1","_col6","_col7","_col12","_col13"]
-          <-Map 1 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_9]
-              PartitionCols:key
-              Filter Operator [FIL_16] (rows=1 width=8)
-                predicate:key is not null
-                TableScan [TS_0] (rows=1 width=8)
-                  default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
+          Merge Join Operator [MERGEJOIN_31] (rows=1 width=8)
+            Conds:RS_11._col0=RS_12._col1(Inner),Output:["_col0","_col1","_col2","_col3","_col4","_col5"]
+          <-Map 4 [SIMPLE_EDGE] llap
+            SHUFFLE [RS_12]
+              PartitionCols:_col1
+              Select Operator [SEL_7] (rows=1 width=8)
+                Output:["_col0","_col1"]
+                TableScan [TS_6] (rows=1 width=8)
+                  default@myinput1_n7,b,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
           <-Reducer 2 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_7]
+            SHUFFLE [RS_11]
               PartitionCols:_col0
-              Merge Join Operator [MERGEJOIN_40] (rows=1 width=8)
-                Conds:RS_3.key=RS_4.value(Inner),Output:["_col0","_col1","_col6","_col7"]
-              <-Map 1 [SIMPLE_EDGE] llap
-                SHUFFLE [RS_3]
-                  PartitionCols:key
-                   Please refer to the previous Filter Operator [FIL_16]
+              Merge Join Operator [MERGEJOIN_30] (rows=1 width=8)
+                Conds:RS_8._col0=RS_9._col0(Inner),Output:["_col0","_col1","_col2","_col3"]
               <-Map 4 [SIMPLE_EDGE] llap
-                SHUFFLE [RS_4]
-                  PartitionCols:value
-                  Filter Operator [FIL_17] (rows=1 width=8)
-                    predicate:value is not null
-                    TableScan [TS_1] (rows=1 width=8)
-                      default@myinput1_n7,b,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
+                SHUFFLE [RS_9]
+                  PartitionCols:_col0
+                  Select Operator [SEL_5] (rows=1 width=8)
+                    Output:["_col0","_col1"]
+                    Filter Operator [FIL_19] (rows=1 width=8)
+                      predicate:key is not null
+                       Please refer to the previous TableScan [TS_6]
+              <-Map 1 [SIMPLE_EDGE] llap
+                SHUFFLE [RS_8]
+                  PartitionCols:_col0
+                  Select Operator [SEL_2] (rows=1 width=8)
+                    Output:["_col0","_col1"]
+                    Filter Operator [FIL_18] (rows=1 width=8)
+                      predicate:key is not null
+                      TableScan [TS_0] (rows=1 width=8)
+                        default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
+
+PREHOOK: query: explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value join myinput1_n7 c on a.key<=>c.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value join myinput1_n7 c on a.key<=>c.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[$0], value=[$1], key0=[$4], value0=[$5], key1=[$2], value1=[$3])
+  HiveJoin(condition=[IS NOT DISTINCT FROM($0, $5)], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveJoin(condition=[IS NOT DISTINCT FROM($0, $2)], joinType=[inner], algorithm=[none], cost=[not available])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n7]], table:alias=[a])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n7]], table:alias=[c])
+    HiveProject(key=[$0], value=[$1])
+      HiveTableScan(table=[[default, myinput1_n7]], table:alias=[b])
 
 PREHOOK: query: explain select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value join myinput1_n7 c on a.key<=>c.key
 PREHOOK: type: QUERY
@@ -4022,7 +4085,7 @@ POSTHOOK: query: explain select * from myinput1_n7 a join myinput1_n7 b on a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@myinput1_n7
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
@@ -4033,30 +4096,55 @@ Stage-0
     limit:-1
     Stage-1
       Reducer 3 llap
-      File Output Operator [FS_10]
-        Select Operator [SEL_9] (rows=1 width=8)
+      File Output Operator [FS_13]
+        Select Operator [SEL_12] (rows=1 width=8)
           Output:["_col0","_col1","_col2","_col3","_col4","_col5"]
-          Merge Join Operator [MERGEJOIN_12] (rows=1 width=8)
-            Conds:RS_6._col0=RS_7.key(Inner),Output:["_col0","_col1","_col6","_col7","_col12","_col13"]
+          Merge Join Operator [MERGEJOIN_15] (rows=1 width=8)
+            Conds:RS_9._col0=RS_10._col1(Inner),Output:["_col0","_col1","_col2","_col3","_col4","_col5"]
           <-Map 1 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_7]
-              PartitionCols:key
-              TableScan [TS_0] (rows=1 width=8)
-                default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
+            SHUFFLE [RS_10]
+              PartitionCols:_col1
+              Select Operator [SEL_1] (rows=1 width=8)
+                Output:["_col0","_col1"]
+                TableScan [TS_0] (rows=1 width=8)
+                  default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
           <-Reducer 2 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_6]
+            SHUFFLE [RS_9]
               PartitionCols:_col0
-              Merge Join Operator [MERGEJOIN_11] (rows=1 width=8)
-                Conds:RS_3.key=RS_4.value(Inner),Output:["_col0","_col1","_col6","_col7"]
+              Merge Join Operator [MERGEJOIN_14] (rows=1 width=8)
+                Conds:RS_6._col0=RS_7._col0(Inner),Output:["_col0","_col1","_col2","_col3"]
               <-Map 1 [SIMPLE_EDGE] llap
-                SHUFFLE [RS_3]
-                  PartitionCols:key
-                   Please refer to the previous TableScan [TS_0]
+                SHUFFLE [RS_6]
+                  PartitionCols:_col0
+                   Please refer to the previous Select Operator [SEL_1]
               <-Map 4 [SIMPLE_EDGE] llap
-                SHUFFLE [RS_4]
-                  PartitionCols:value
-                  TableScan [TS_1] (rows=1 width=8)
-                    default@myinput1_n7,b,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
+                SHUFFLE [RS_7]
+                  PartitionCols:_col0
+                  Select Operator [SEL_3] (rows=1 width=8)
+                    Output:["_col0","_col1"]
+                    TableScan [TS_2] (rows=1 width=8)
+                      default@myinput1_n7,c,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
+
+PREHOOK: query: explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value AND a.value=b.key join myinput1_n7 c on a.key<=>c.key AND a.value=c.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value AND a.value=b.key join myinput1_n7 c on a.key<=>c.key AND a.value=c.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $4), =($1, $5))], joinType=[inner], algorithm=[none], cost=[not available])
+  HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $3), =($1, $2))], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveProject(key=[$0], value=[$1])
+      HiveFilter(condition=[IS NOT NULL($1)])
+        HiveTableScan(table=[[default, myinput1_n7]], table:alias=[a])
+    HiveProject(key=[$0], value=[$1])
+      HiveFilter(condition=[IS NOT NULL($0)])
+        HiveTableScan(table=[[default, myinput1_n7]], table:alias=[b])
+  HiveProject(key=[$0], value=[$1])
+    HiveFilter(condition=[IS NOT NULL($1)])
+      HiveTableScan(table=[[default, myinput1_n7]], table:alias=[c])
 
 PREHOOK: query: explain select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value AND a.value=b.key join myinput1_n7 c on a.key<=>c.key AND a.value=c.value
 PREHOOK: type: QUERY
@@ -4066,7 +4154,7 @@ POSTHOOK: query: explain select * from myinput1_n7 a join myinput1_n7 b on a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@myinput1_n7
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
@@ -4077,35 +4165,56 @@ Stage-0
     limit:-1
     Stage-1
       Reducer 3 llap
-      File Output Operator [FS_14]
-        Select Operator [SEL_13] (rows=1 width=8)
-          Output:["_col0","_col1","_col2","_col3","_col4","_col5"]
-          Merge Join Operator [MERGEJOIN_19] (rows=1 width=8)
-            Conds:RS_9._col0, _col1=RS_11.key, value(Inner),Output:["_col0","_col1","_col6","_col7","_col12","_col13"]
-          <-Map 1 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_11]
-              PartitionCols:key, value
-              Filter Operator [FIL_15] (rows=1 width=8)
+      File Output Operator [FS_16]
+        Merge Join Operator [MERGEJOIN_21] (rows=1 width=8)
+          Conds:RS_12._col1, _col0=RS_13._col1, _col0(Inner),Output:["_col0","_col1","_col2","_col3","_col4","_col5"]
+        <-Map 1 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_13]
+            PartitionCols:_col1, _col0
+            Select Operator [SEL_2] (rows=1 width=8)
+              Output:["_col0","_col1"]
+              Filter Operator [FIL_17] (rows=1 width=8)
                 predicate:value is not null
                 TableScan [TS_0] (rows=1 width=8)
                   default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
-          <-Reducer 2 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_9]
-              PartitionCols:_col0, _col1
-              Merge Join Operator [MERGEJOIN_18] (rows=1 width=8)
-                Conds:RS_4.key, value=RS_6.value, key(Inner),Output:["_col0","_col1","_col6","_col7"]
-              <-Map 1 [SIMPLE_EDGE] llap
-                SHUFFLE [RS_4]
-                  PartitionCols:key, value
-                   Please refer to the previous Filter Operator [FIL_15]
-              <-Map 4 [SIMPLE_EDGE] llap
-                SHUFFLE [RS_6]
-                  PartitionCols:value, key
-                  Filter Operator [FIL_16] (rows=1 width=8)
+        <-Reducer 2 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_12]
+            PartitionCols:_col1, _col0
+            Merge Join Operator [MERGEJOIN_20] (rows=1 width=8)
+              Conds:RS_9._col1, _col0=RS_10._col0, _col1(Inner),Output:["_col0","_col1","_col2","_col3"]
+            <-Map 1 [SIMPLE_EDGE] llap
+              SHUFFLE [RS_9]
+                PartitionCols:_col1, _col0
+                 Please refer to the previous Select Operator [SEL_2]
+            <-Map 4 [SIMPLE_EDGE] llap
+              SHUFFLE [RS_10]
+                PartitionCols:_col0, _col1
+                Select Operator [SEL_5] (rows=1 width=8)
+                  Output:["_col0","_col1"]
+                  Filter Operator [FIL_18] (rows=1 width=8)
                     predicate:key is not null
-                    TableScan [TS_1] (rows=1 width=8)
+                    TableScan [TS_3] (rows=1 width=8)
                       default@myinput1_n7,b,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
 
+PREHOOK: query: explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value AND a.value<=>b.key join myinput1_n7 c on a.key<=>c.key AND a.value<=>c.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value AND a.value<=>b.key join myinput1_n7 c on a.key<=>c.key AND a.value<=>c.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[$0], value=[$1], key0=[$4], value0=[$5], key1=[$2], value1=[$3])
+  HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $5), IS NOT DISTINCT FROM($1, $4))], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $2), IS NOT DISTINCT FROM($1, $3))], joinType=[inner], algorithm=[none], cost=[not available])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n7]], table:alias=[a])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n7]], table:alias=[c])
+    HiveProject(key=[$0], value=[$1])
+      HiveTableScan(table=[[default, myinput1_n7]], table:alias=[b])
+
 PREHOOK: query: explain select * from myinput1_n7 a join myinput1_n7 b on a.key<=>b.value AND a.value<=>b.key join myinput1_n7 c on a.key<=>c.key AND a.value<=>c.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n7
@@ -4114,7 +4223,7 @@ POSTHOOK: query: explain select * from myinput1_n7 a join myinput1_n7 b on a.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@myinput1_n7
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
@@ -4125,30 +4234,49 @@ Stage-0
     limit:-1
     Stage-1
       Reducer 3 llap
-      File Output Operator [FS_10]
-        Select Operator [SEL_9] (rows=1 width=8)
+      File Output Operator [FS_13]
+        Select Operator [SEL_12] (rows=1 width=8)
           Output:["_col0","_col1","_col2","_col3","_col4","_col5"]
-          Merge Join Operator [MERGEJOIN_12] (rows=1 width=8)
-            Conds:RS_6._col0, _col1=RS_7.key, value(Inner),Output:["_col0","_col1","_col6","_col7","_col12","_col13"]
+          Merge Join Operator [MERGEJOIN_15] (rows=1 width=8)
+            Conds:RS_9._col0, _col1=RS_10._col1, _col0(Inner),Output:["_col0","_col1","_col2","_col3","_col4","_col5"]
           <-Map 1 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_7]
-              PartitionCols:key, value
-              TableScan [TS_0] (rows=1 width=8)
-                default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
+            SHUFFLE [RS_10]
+              PartitionCols:_col1, _col0
+              Select Operator [SEL_1] (rows=1 width=8)
+                Output:["_col0","_col1"]
+                TableScan [TS_0] (rows=1 width=8)
+                  default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
           <-Reducer 2 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_6]
+            SHUFFLE [RS_9]
               PartitionCols:_col0, _col1
-              Merge Join Operator [MERGEJOIN_11] (rows=1 width=8)
-                Conds:RS_3.key, value=RS_4.value, key(Inner),Output:["_col0","_col1","_col6","_col7"]
+              Merge Join Operator [MERGEJOIN_14] (rows=1 width=8)
+                Conds:RS_6._col0, _col1=RS_7._col0, _col1(Inner),Output:["_col0","_col1","_col2","_col3"]
               <-Map 1 [SIMPLE_EDGE] llap
-                SHUFFLE [RS_3]
-                  PartitionCols:key, value
-                   Please refer to the previous TableScan [TS_0]
+                SHUFFLE [RS_6]
+                  PartitionCols:_col0, _col1
+                   Please refer to the previous Select Operator [SEL_1]
               <-Map 4 [SIMPLE_EDGE] llap
-                SHUFFLE [RS_4]
-                  PartitionCols:value, key
-                  TableScan [TS_1] (rows=1 width=8)
-                    default@myinput1_n7,b,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
+                SHUFFLE [RS_7]
+                  PartitionCols:_col0, _col1
+                  Select Operator [SEL_3] (rows=1 width=8)
+                    Output:["_col0","_col1"]
+                    TableScan [TS_2] (rows=1 width=8)
+                      default@myinput1_n7,c,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
+
+PREHOOK: query: explain cbo select * FROM myinput1_n7 a LEFT OUTER JOIN myinput1_n7 b ON a.key<=>b.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * FROM myinput1_n7 a LEFT OUTER JOIN myinput1_n7 b ON a.key<=>b.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[IS NOT DISTINCT FROM($0, $3)], joinType=[left], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n7]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n7]], table:alias=[b])
 
 PREHOOK: query: explain select * FROM myinput1_n7 a LEFT OUTER JOIN myinput1_n7 b ON a.key<=>b.value
 PREHOOK: type: QUERY
@@ -4158,7 +4286,7 @@ POSTHOOK: query: explain select * FROM myinput1_n7 a LEFT OUTER JOIN myinput1_n7
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@myinput1_n7
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 3 (SIMPLE_EDGE)
@@ -4168,22 +4296,39 @@ Stage-0
     limit:-1
     Stage-1
       Reducer 2 llap
-      File Output Operator [FS_6]
-        Select Operator [SEL_5] (rows=1 width=8)
-          Output:["_col0","_col1","_col2","_col3"]
-          Merge Join Operator [MERGEJOIN_7] (rows=1 width=8)
-            Conds:RS_2.key=RS_3.value(Left Outer),Output:["_col0","_col1","_col6","_col7"]
-          <-Map 1 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_2]
-              PartitionCols:key
+      File Output Operator [FS_8]
+        Merge Join Operator [MERGEJOIN_9] (rows=1 width=8)
+          Conds:RS_4._col0=RS_5._col1(Left Outer),Output:["_col0","_col1","_col2","_col3"]
+        <-Map 1 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_4]
+            PartitionCols:_col0
+            Select Operator [SEL_1] (rows=1 width=8)
+              Output:["_col0","_col1"]
               TableScan [TS_0] (rows=1 width=8)
                 default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
-          <-Map 3 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_3]
-              PartitionCols:value
-              TableScan [TS_1] (rows=1 width=8)
+        <-Map 3 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_5]
+            PartitionCols:_col1
+            Select Operator [SEL_3] (rows=1 width=8)
+              Output:["_col0","_col1"]
+              TableScan [TS_2] (rows=1 width=8)
                 default@myinput1_n7,b,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
 
+PREHOOK: query: explain cbo select * FROM myinput1_n7 a RIGHT OUTER JOIN myinput1_n7 b ON a.key<=>b.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * FROM myinput1_n7 a RIGHT OUTER JOIN myinput1_n7 b ON a.key<=>b.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[IS NOT DISTINCT FROM($0, $3)], joinType=[right], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n7]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n7]], table:alias=[b])
+
 PREHOOK: query: explain select * FROM myinput1_n7 a RIGHT OUTER JOIN myinput1_n7 b ON a.key<=>b.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n7
@@ -4192,7 +4337,7 @@ POSTHOOK: query: explain select * FROM myinput1_n7 a RIGHT OUTER JOIN myinput1_n
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@myinput1_n7
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 3 (SIMPLE_EDGE)
@@ -4202,22 +4347,39 @@ Stage-0
     limit:-1
     Stage-1
       Reducer 2 llap
-      File Output Operator [FS_6]
-        Select Operator [SEL_5] (rows=1 width=8)
-          Output:["_col0","_col1","_col2","_col3"]
-          Merge Join Operator [MERGEJOIN_7] (rows=1 width=8)
-            Conds:RS_2.key=RS_3.value(Right Outer),Output:["_col0","_col1","_col6","_col7"]
-          <-Map 1 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_2]
-              PartitionCols:key
+      File Output Operator [FS_8]
+        Merge Join Operator [MERGEJOIN_9] (rows=1 width=8)
+          Conds:RS_4._col0=RS_5._col1(Right Outer),Output:["_col0","_col1","_col2","_col3"]
+        <-Map 1 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_4]
+            PartitionCols:_col0
+            Select Operator [SEL_1] (rows=1 width=8)
+              Output:["_col0","_col1"]
               TableScan [TS_0] (rows=1 width=8)
                 default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
-          <-Map 3 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_3]
-              PartitionCols:value
-              TableScan [TS_1] (rows=1 width=8)
+        <-Map 3 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_5]
+            PartitionCols:_col1
+            Select Operator [SEL_3] (rows=1 width=8)
+              Output:["_col0","_col1"]
+              TableScan [TS_2] (rows=1 width=8)
                 default@myinput1_n7,b,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
 
+PREHOOK: query: explain cbo select * FROM myinput1_n7 a FULL OUTER JOIN myinput1_n7 b ON a.key<=>b.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * FROM myinput1_n7 a FULL OUTER JOIN myinput1_n7 b ON a.key<=>b.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[IS NOT DISTINCT FROM($0, $3)], joinType=[full], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n7]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n7]], table:alias=[b])
+
 PREHOOK: query: explain select * FROM myinput1_n7 a FULL OUTER JOIN myinput1_n7 b ON a.key<=>b.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n7
@@ -4226,7 +4388,7 @@ POSTHOOK: query: explain select * FROM myinput1_n7 a FULL OUTER JOIN myinput1_n7
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@myinput1_n7
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 3 (SIMPLE_EDGE)
@@ -4236,22 +4398,39 @@ Stage-0
     limit:-1
     Stage-1
       Reducer 2 llap
-      File Output Operator [FS_6]
-        Select Operator [SEL_5] (rows=1 width=8)
-          Output:["_col0","_col1","_col2","_col3"]
-          Merge Join Operator [MERGEJOIN_7] (rows=1 width=8)
-            Conds:RS_2.key=RS_3.value(Outer),Output:["_col0","_col1","_col6","_col7"]
-          <-Map 1 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_2]
-              PartitionCols:key
+      File Output Operator [FS_8]
+        Merge Join Operator [MERGEJOIN_9] (rows=1 width=8)
+          Conds:RS_4._col0=RS_5._col1(Outer),Output:["_col0","_col1","_col2","_col3"]
+        <-Map 1 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_4]
+            PartitionCols:_col0
+            Select Operator [SEL_1] (rows=1 width=8)
+              Output:["_col0","_col1"]
               TableScan [TS_0] (rows=1 width=8)
                 default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
-          <-Map 3 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_3]
-              PartitionCols:value
-              TableScan [TS_1] (rows=1 width=8)
+        <-Map 3 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_5]
+            PartitionCols:_col1
+            Select Operator [SEL_3] (rows=1 width=8)
+              Output:["_col0","_col1"]
+              TableScan [TS_2] (rows=1 width=8)
                 default@myinput1_n7,b,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
 
+PREHOOK: query: explain cbo select /*+ MAPJOIN(b) */ * FROM myinput1_n7 a JOIN myinput1_n7 b ON a.key<=>b.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select /*+ MAPJOIN(b) */ * FROM myinput1_n7 a JOIN myinput1_n7 b ON a.key<=>b.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n7
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[IS NOT DISTINCT FROM($0, $3)], joinType=[inner], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n7]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n7]], table:alias=[b])
+
 PREHOOK: query: explain select /*+ MAPJOIN(b) */ * FROM myinput1_n7 a JOIN myinput1_n7 b ON a.key<=>b.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n7
@@ -4260,7 +4439,7 @@ POSTHOOK: query: explain select /*+ MAPJOIN(b) */ * FROM myinput1_n7 a JOIN myin
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@myinput1_n7
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 3 (SIMPLE_EDGE)
@@ -4270,20 +4449,22 @@ Stage-0
     limit:-1
     Stage-1
       Reducer 2 llap
-      File Output Operator [FS_6]
-        Select Operator [SEL_5] (rows=1 width=8)
-          Output:["_col0","_col1","_col2","_col3"]
-          Merge Join Operator [MERGEJOIN_7] (rows=1 width=8)
-            Conds:RS_2.key=RS_3.value(Inner),Output:["_col0","_col1","_col6","_col7"]
-          <-Map 1 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_2]
-              PartitionCols:key
+      File Output Operator [FS_8]
+        Merge Join Operator [MERGEJOIN_9] (rows=1 width=8)
+          Conds:RS_4._col0=RS_5._col1(Inner),Output:["_col0","_col1","_col2","_col3"]
+        <-Map 1 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_4]
+            PartitionCols:_col0
+            Select Operator [SEL_1] (rows=1 width=8)
+              Output:["_col0","_col1"]
               TableScan [TS_0] (rows=1 width=8)
                 default@myinput1_n7,a,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
-          <-Map 3 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_3]
-              PartitionCols:value
-              TableScan [TS_1] (rows=1 width=8)
+        <-Map 3 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_5]
+            PartitionCols:_col1
+            Select Operator [SEL_3] (rows=1 width=8)
+              Output:["_col0","_col1"]
+              TableScan [TS_2] (rows=1 width=8)
                 default@myinput1_n7,b,Tbl:COMPLETE,Col:NONE,Output:["key","value"]
 
 PREHOOK: query: CREATE TABLE smb_input_n0(key int, value int)
@@ -4352,6 +4533,21 @@ POSTHOOK: query: analyze table smb_input1_n2 compute statistics
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_input1_n2
 POSTHOOK: Output: default@smb_input1_n2
+PREHOOK: query: explain cbo select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@smb_input1_n2
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@smb_input1_n2
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[IS NOT DISTINCT FROM($0, $2)], joinType=[inner], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, smb_input1_n2]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, smb_input1_n2]], table:alias=[b])
+
 PREHOOK: query: explain select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_input1_n2
@@ -4360,24 +4556,41 @@ POSTHOOK: query: explain select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN sm
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_input1_n2
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Stage-0
   Fetch Operator
     limit:-1
     Stage-1
       Map 1 llap
-      File Output Operator [FS_6]
-        Select Operator [SEL_5] (rows=48 width=15)
-          Output:["_col0","_col1","_col2","_col3"]
-          Merge Join Operator [MERGEJOIN_7] (rows=48 width=15)
-            Conds:TS_0.key=DUMMY_STORE_8.key(Inner),Output:["_col0","_col1","_col6","_col7"]
-          <-Dummy Store [DUMMY_STORE_8]
-              TableScan [TS_1] (rows=26 width=7)
+      File Output Operator [FS_8]
+        Merge Join Operator [MERGEJOIN_9] (rows=48 width=15)
+          Conds:SEL_1._col0=DUMMY_STORE_10._col0(Inner),Output:["_col0","_col1","_col2","_col3"]
+        <-Dummy Store [DUMMY_STORE_10]
+            Select Operator [SEL_3] (rows=26 width=7)
+              Output:["_col0","_col1"]
+              TableScan [TS_2] (rows=26 width=7)
                 default@smb_input1_n2,b,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
-          <-TableScan [TS_0] (rows=26 width=7)
+        <-Select Operator [SEL_1] (rows=26 width=7)
+            Output:["_col0","_col1"]
+            TableScan [TS_0] (rows=26 width=7)
               default@smb_input1_n2,a,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
 
+PREHOOK: query: explain cbo select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key AND a.value <=> b.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@smb_input1_n2
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key AND a.value <=> b.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@smb_input1_n2
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $2), IS NOT DISTINCT FROM($1, $3))], joinType=[inner], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, smb_input1_n2]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, smb_input1_n2]], table:alias=[b])
+
 PREHOOK: query: explain select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key AND a.value <=> b.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_input1_n2
@@ -4386,7 +4599,7 @@ POSTHOOK: query: explain select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a JOIN sm
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_input1_n2
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Vertex dependency in root stage
 Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 3 (SIMPLE_EDGE)
@@ -4396,22 +4609,39 @@ Stage-0
     limit:-1
     Stage-1
       Reducer 2 llap
-      File Output Operator [FS_6]
-        Select Operator [SEL_5] (rows=48 width=15)
-          Output:["_col0","_col1","_col2","_col3"]
-          Merge Join Operator [MERGEJOIN_7] (rows=48 width=15)
-            Conds:RS_2.key, value=RS_3.key, value(Inner),Output:["_col0","_col1","_col6","_col7"]
-          <-Map 1 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_2]
-              PartitionCols:key, value
+      File Output Operator [FS_8]
+        Merge Join Operator [MERGEJOIN_9] (rows=48 width=15)
+          Conds:RS_4._col0, _col1=RS_5._col0, _col1(Inner),Output:["_col0","_col1","_col2","_col3"]
+        <-Map 1 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_4]
+            PartitionCols:_col0, _col1
+            Select Operator [SEL_1] (rows=26 width=7)
+              Output:["_col0","_col1"]
               TableScan [TS_0] (rows=26 width=7)
                 default@smb_input1_n2,a,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
-          <-Map 3 [SIMPLE_EDGE] llap
-            SHUFFLE [RS_3]
-              PartitionCols:key, value
-              TableScan [TS_1] (rows=26 width=7)
+        <-Map 3 [SIMPLE_EDGE] llap
+          SHUFFLE [RS_5]
+            PartitionCols:_col0, _col1
+            Select Operator [SEL_3] (rows=26 width=7)
+              Output:["_col0","_col1"]
+              TableScan [TS_2] (rows=26 width=7)
                 default@smb_input1_n2,b,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
 
+PREHOOK: query: explain cbo select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a RIGHT OUTER JOIN smb_input1_n2 b ON a.key <=> b.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@smb_input1_n2
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a RIGHT OUTER JOIN smb_input1_n2 b ON a.key <=> b.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@smb_input1_n2
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[IS NOT DISTINCT FROM($0, $2)], joinType=[right], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, smb_input1_n2]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, smb_input1_n2]], table:alias=[b])
+
 PREHOOK: query: explain select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a RIGHT OUTER JOIN smb_input1_n2 b ON a.key <=> b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_input1_n2
@@ -4420,24 +4650,41 @@ POSTHOOK: query: explain select /*+ MAPJOIN(a) */ * FROM smb_input1_n2 a RIGHT O
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_input1_n2
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Stage-0
   Fetch Operator
     limit:-1
     Stage-1
       Map 2 llap
-      File Output Operator [FS_6]
-        Select Operator [SEL_5] (rows=48 width=15)
-          Output:["_col0","_col1","_col2","_col3"]
-          Merge Join Operator [MERGEJOIN_7] (rows=48 width=15)
-            Conds:DUMMY_STORE_8.key=TS_1.key(Right Outer),Output:["_col0","_col1","_col6","_col7"]
-          <-Dummy Store [DUMMY_STORE_8]
+      File Output Operator [FS_8]
+        Merge Join Operator [MERGEJOIN_9] (rows=48 width=15)
+          Conds:DUMMY_STORE_10._col0=SEL_3._col0(Right Outer),Output:["_col0","_col1","_col2","_col3"]
+        <-Dummy Store [DUMMY_STORE_10]
+            Select Operator [SEL_1] (rows=26 width=7)
+              Output:["_col0","_col1"]
               TableScan [TS_0] (rows=26 width=7)
                 default@smb_input1_n2,a,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
-          <-TableScan [TS_1] (rows=26 width=7)
+        <-Select Operator [SEL_3] (rows=26 width=7)
+            Output:["_col0","_col1"]
+            TableScan [TS_2] (rows=26 width=7)
               default@smb_input1_n2,b,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
 
+PREHOOK: query: explain cbo select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@smb_input1_n2
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@smb_input1_n2
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[IS NOT DISTINCT FROM($0, $2)], joinType=[inner], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, smb_input1_n2]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, smb_input1_n2]], table:alias=[b])
+
 PREHOOK: query: explain select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a JOIN smb_input1_n2 b ON a.key <=> b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_input1_n2
@@ -4446,24 +4693,41 @@ POSTHOOK: query: explain select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a JOIN sm
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_input1_n2
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Stage-0
   Fetch Operator
     limit:-1
     Stage-1
       Map 1 llap
-      File Output Operator [FS_6]
-        Select Operator [SEL_5] (rows=48 width=15)
-          Output:["_col0","_col1","_col2","_col3"]
-          Merge Join Operator [MERGEJOIN_7] (rows=48 width=15)
-            Conds:TS_0.key=DUMMY_STORE_8.key(Inner),Output:["_col0","_col1","_col6","_col7"]
-          <-Dummy Store [DUMMY_STORE_8]
-              TableScan [TS_1] (rows=26 width=7)
+      File Output Operator [FS_8]
+        Merge Join Operator [MERGEJOIN_9] (rows=48 width=15)
+          Conds:SEL_1._col0=DUMMY_STORE_10._col0(Inner),Output:["_col0","_col1","_col2","_col3"]
+        <-Dummy Store [DUMMY_STORE_10]
+            Select Operator [SEL_3] (rows=26 width=7)
+              Output:["_col0","_col1"]
+              TableScan [TS_2] (rows=26 width=7)
                 default@smb_input1_n2,b,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
-          <-TableScan [TS_0] (rows=26 width=7)
+        <-Select Operator [SEL_1] (rows=26 width=7)
+            Output:["_col0","_col1"]
+            TableScan [TS_0] (rows=26 width=7)
               default@smb_input1_n2,a,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
 
+PREHOOK: query: explain cbo select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a LEFT OUTER JOIN smb_input1_n2 b ON a.key <=> b.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@smb_input1_n2
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a LEFT OUTER JOIN smb_input1_n2 b ON a.key <=> b.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@smb_input1_n2
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[IS NOT DISTINCT FROM($0, $2)], joinType=[left], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, smb_input1_n2]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, smb_input1_n2]], table:alias=[b])
+
 PREHOOK: query: explain select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a LEFT OUTER JOIN smb_input1_n2 b ON a.key <=> b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_input1_n2
@@ -4472,22 +4736,24 @@ POSTHOOK: query: explain select /*+ MAPJOIN(b) */ * FROM smb_input1_n2 a LEFT OU
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_input1_n2
 #### A masked pattern was here ####
-Plan not optimized by CBO due to missing feature [Less_than_equal_greater_than].
+Plan optimized by CBO.
 
 Stage-0
   Fetch Operator
     limit:-1
     Stage-1
       Map 1 llap
-      File Output Operator [FS_6]
-        Select Operator [SEL_5] (rows=48 width=15)
-          Output:["_col0","_col1","_col2","_col3"]
-          Merge Join Operator [MERGEJOIN_7] (rows=48 width=15)
-            Conds:TS_0.key=DUMMY_STORE_8.key(Left Outer),Output:["_col0","_col1","_col6","_col7"]
-          <-Dummy Store [DUMMY_STORE_8]
-              TableScan [TS_1] (rows=26 width=7)
+      File Output Operator [FS_8]
+        Merge Join Operator [MERGEJOIN_9] (rows=48 width=15)
+          Conds:SEL_1._col0=DUMMY_STORE_10._col0(Left Outer),Output:["_col0","_col1","_col2","_col3"]
+        <-Dummy Store [DUMMY_STORE_10]
+            Select Operator [SEL_3] (rows=26 width=7)
+              Output:["_col0","_col1"]
+              TableScan [TS_2] (rows=26 width=7)
                 default@smb_input1_n2,b,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
-          <-TableScan [TS_0] (rows=26 width=7)
+        <-Select Operator [SEL_1] (rows=26 width=7)
+            Output:["_col0","_col1"]
+            TableScan [TS_0] (rows=26 width=7)
               default@smb_input1_n2,a,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
 
 PREHOOK: query: drop table sales_n0
diff --git a/ql/src/test/results/clientpositive/llap/is_distinct_from.q.out b/ql/src/test/results/clientpositive/llap/is_distinct_from.q.out
index fa581f768e..2bca7ac310 100644
--- a/ql/src/test/results/clientpositive/llap/is_distinct_from.q.out
+++ b/ql/src/test/results/clientpositive/llap/is_distinct_from.q.out
@@ -206,9 +206,9 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: test_n5
-          filterExpr: (y IS DISTINCT FROM null) (type: boolean)
+          filterExpr: (not (y IS NOT DISTINCT FROM null)) (type: boolean)
           Filter Operator
-            predicate: (y IS DISTINCT FROM null) (type: boolean)
+            predicate: (not (y IS NOT DISTINCT FROM null)) (type: boolean)
             Select Operator
               expressions: x (type: string), y (type: string)
               outputColumnNames: _col0, _col1
@@ -247,7 +247,7 @@ STAGE PLANS:
           Filter Operator
             predicate: (y IS NOT DISTINCT FROM null) (type: boolean)
             Select Operator
-              expressions: x (type: string), null (type: string)
+              expressions: x (type: string), y (type: string)
               outputColumnNames: _col0, _col1
               ListSink
 
@@ -287,9 +287,9 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: part
-          filterExpr: (p_size IS DISTINCT FROM 2) (type: boolean)
+          filterExpr: (not (p_size IS NOT DISTINCT FROM 2)) (type: boolean)
           Filter Operator
-            predicate: (p_size IS DISTINCT FROM 2) (type: boolean)
+            predicate: (not (p_size IS NOT DISTINCT FROM 2)) (type: boolean)
             Select Operator
               expressions: p_partkey (type: int), p_name (type: string), p_mfgr (type: string), p_brand (type: string), p_type (type: string), p_size (type: int), p_container (type: string), p_retailprice (type: double), p_comment (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
@@ -347,7 +347,7 @@ STAGE PLANS:
           Filter Operator
             predicate: (p_size IS NOT DISTINCT FROM 2) (type: boolean)
             Select Operator
-              expressions: p_partkey (type: int), p_name (type: string), p_mfgr (type: string), p_brand (type: string), p_type (type: string), 2 (type: int), p_container (type: string), p_retailprice (type: double), p_comment (type: string)
+              expressions: p_partkey (type: int), p_name (type: string), p_mfgr (type: string), p_brand (type: string), p_type (type: string), p_size (type: int), p_container (type: string), p_retailprice (type: double), p_comment (type: string)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
               ListSink
 
@@ -363,3 +363,73 @@ POSTHOOK: Input: default@part
 121152	almond antique burnished rose metallic	Manufacturer#1	Brand#14	PROMO PLATED TIN	2	JUMBO BOX	1173.15	e pinto beans h
 146985	almond aquamarine midnight light salmon	Manufacturer#2	Brand#23	MEDIUM BURNISHED COPPER	2	SM CASE	2031.98	s cajole caref
 155733	almond antique sky peru orange	Manufacturer#5	Brand#53	SMALL PLATED BRASS	2	WRAP DRUM	1788.73	furiously. bra
+PREHOOK: query: create table t2(c0 boolean, c1 float )
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t2
+POSTHOOK: query: create table t2(c0 boolean, c1 float )
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t2
+PREHOOK: query: insert into t2(c0) values (not (0.379 is not distinct from 641))
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@t2
+POSTHOOK: query: insert into t2(c0) values (not (0.379 is not distinct from 641))
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@t2
+POSTHOOK: Lineage: t2.c0 SCRIPT []
+POSTHOOK: Lineage: t2.c1 SIMPLE []
+PREHOOK: query: insert into t2(c0,c1) values (not (0.379 is not distinct from 641), 0.2)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@t2
+POSTHOOK: query: insert into t2(c0,c1) values (not (0.379 is not distinct from 641), 0.2)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@t2
+POSTHOOK: Lineage: t2.c0 SCRIPT []
+POSTHOOK: Lineage: t2.c1 SCRIPT []
+PREHOOK: query: select * from t2
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t2
+#### A masked pattern was here ####
+POSTHOOK: query: select * from t2
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t2
+#### A masked pattern was here ####
+true	NULL
+true	0.2
+PREHOOK: query: create table if not exists t0(c0 boolean unique disable novalidate, c1 float, c2 boolean)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t0
+POSTHOOK: query: create table if not exists t0(c0 boolean unique disable novalidate, c1 float, c2 boolean)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t0
+PREHOOK: query: insert into t0(c2, c1, c0)
+values (0.4144825 is distinct from 0.6828972,
+        0.14, true)
+PREHOOK: type: QUERY
+PREHOOK: Input: _dummy_database@_dummy_table
+PREHOOK: Output: default@t0
+POSTHOOK: query: insert into t0(c2, c1, c0)
+values (0.4144825 is distinct from 0.6828972,
+        0.14, true)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: _dummy_database@_dummy_table
+POSTHOOK: Output: default@t0
+POSTHOOK: Lineage: t0.c0 SCRIPT []
+POSTHOOK: Lineage: t0.c1 SCRIPT []
+POSTHOOK: Lineage: t0.c2 SCRIPT []
+PREHOOK: query: select * from t0
+PREHOOK: type: QUERY
+PREHOOK: Input: default@t0
+#### A masked pattern was here ####
+POSTHOOK: query: select * from t0
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@t0
+#### A masked pattern was here ####
+true	0.14	true
diff --git a/ql/src/test/results/clientpositive/llap/join_by_range_rule_not_null.q.out b/ql/src/test/results/clientpositive/llap/join_by_range_rule_not_null.q.out
index 9ecce9ef96..a1eb1322a5 100644
--- a/ql/src/test/results/clientpositive/llap/join_by_range_rule_not_null.q.out
+++ b/ql/src/test/results/clientpositive/llap/join_by_range_rule_not_null.q.out
@@ -439,7 +439,7 @@ STAGE PLANS:
       Processor Tree:
         ListSink
 
-Warning: Shuffle Join MERGEJOIN[7][tables = [a, b]] in Stage 'Reducer 2' is a cross product
+Warning: Shuffle Join MERGEJOIN[9][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 2' is a cross product
 PREHOOK: query: EXPLAIN SELECT * FROM src a JOIN src1 b ON a.key IS DISTINCT FROM b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -467,11 +467,15 @@ STAGE PLANS:
                 TableScan
                   alias: a
                   Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
-                  Reduce Output Operator
-                    null sort order: 
-                    sort order: 
+                  Select Operator
+                    expressions: key (type: string), value (type: string)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: key (type: string), value (type: string)
+                    Reduce Output Operator
+                      null sort order: 
+                      sort order: 
+                      Statistics: Num rows: 500 Data size: 89000 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col0 (type: string), _col1 (type: string)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 3 
@@ -479,11 +483,15 @@ STAGE PLANS:
                 TableScan
                   alias: b
                   Statistics: Num rows: 25 Data size: 4375 Basic stats: COMPLETE Column stats: COMPLETE
-                  Reduce Output Operator
-                    null sort order: 
-                    sort order: 
+                  Select Operator
+                    expressions: key (type: string), value (type: string)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 25 Data size: 4375 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: key (type: string), value (type: string)
+                    Reduce Output Operator
+                      null sort order: 
+                      sort order: 
+                      Statistics: Num rows: 25 Data size: 4375 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col0 (type: string), _col1 (type: string)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -495,20 +503,16 @@ STAGE PLANS:
                 keys:
                   0 
                   1 
-                outputColumnNames: _col0, _col1, _col6, _col7
-                residual filter predicates: {(not (_col0 IS NOT DISTINCT FROM _col6))}
+                outputColumnNames: _col0, _col1, _col2, _col3
+                residual filter predicates: {(not (_col0 IS NOT DISTINCT FROM _col2))}
                 Statistics: Num rows: 6250 Data size: 2206250 Basic stats: COMPLETE Column stats: COMPLETE
-                Select Operator
-                  expressions: _col0 (type: string), _col1 (type: string), _col6 (type: string), _col7 (type: string)
-                  outputColumnNames: _col0, _col1, _col2, _col3
+                File Output Operator
+                  compressed: false
                   Statistics: Num rows: 6250 Data size: 2206250 Basic stats: COMPLETE Column stats: COMPLETE
-                  File Output Operator
-                    compressed: false
-                    Statistics: Num rows: 6250 Data size: 2206250 Basic stats: COMPLETE Column stats: COMPLETE
-                    table:
-                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-0
     Fetch Operator
diff --git a/ql/src/test/results/clientpositive/llap/join_is_not_distinct_from.q.out b/ql/src/test/results/clientpositive/llap/join_is_not_distinct_from.q.out
index 98fa3a1fee..77ec6269f4 100644
--- a/ql/src/test/results/clientpositive/llap/join_is_not_distinct_from.q.out
+++ b/ql/src/test/results/clientpositive/llap/join_is_not_distinct_from.q.out
@@ -14,6 +14,21 @@ POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/in8.txt' INTO TABLE my
 POSTHOOK: type: LOAD
 #### A masked pattern was here ####
 POSTHOOK: Output: default@myinput1_n10
+PREHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[IS NOT DISTINCT FROM($0, $3)], joinType=[inner], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n10]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n10]], table:alias=[b])
+
 PREHOOK: query: explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n10
@@ -39,13 +54,17 @@ STAGE PLANS:
                 TableScan
                   alias: a
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: key (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: key (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    value expressions: value (type: int)
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col0 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 3 
@@ -53,13 +72,17 @@ STAGE PLANS:
                 TableScan
                   alias: b
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: value (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: value (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    value expressions: key (type: int)
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col1 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col0 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -69,22 +92,18 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 key (type: int)
-                  1 value (type: int)
+                  0 _col0 (type: int)
+                  1 _col1 (type: int)
                 nullSafes: [true]
-                outputColumnNames: _col0, _col1, _col6, _col7
+                outputColumnNames: _col0, _col1, _col2, _col3
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                Select Operator
-                  expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int)
-                  outputColumnNames: _col0, _col1, _col2, _col3
+                File Output Operator
+                  compressed: false
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  File Output Operator
-                    compressed: false
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    table:
-                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-0
     Fetch Operator
@@ -111,6 +130,27 @@ NULL	35	NULL	NULL
 NULL	NULL	10	NULL
 NULL	NULL	48	NULL
 NULL	NULL	NULL	NULL
+PREHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key=c.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key=c.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[$0], value=[$1], key0=[$4], value0=[$5], key1=[$2], value1=[$3])
+  HiveJoin(condition=[IS NOT DISTINCT FROM($0, $5)], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveJoin(condition=[=($0, $2)], joinType=[inner], algorithm=[none], cost=[not available])
+      HiveProject(key=[$0], value=[$1])
+        HiveFilter(condition=[IS NOT NULL($0)])
+          HiveTableScan(table=[[default, myinput1_n10]], table:alias=[a])
+      HiveProject(key=[$0], value=[$1])
+        HiveFilter(condition=[IS NOT NULL($0)])
+          HiveTableScan(table=[[default, myinput1_n10]], table:alias=[c])
+    HiveProject(key=[$0], value=[$1])
+      HiveTableScan(table=[[default, myinput1_n10]], table:alias=[b])
+
 PREHOOK: query: explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key=c.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n10
@@ -129,7 +169,7 @@ STAGE PLANS:
 #### A masked pattern was here ####
       Edges:
         Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
-        Reducer 3 <- Map 1 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
+        Reducer 3 <- Map 4 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
 #### A masked pattern was here ####
       Vertices:
         Map 1 
@@ -141,38 +181,49 @@ STAGE PLANS:
                   Filter Operator
                     predicate: key is not null (type: boolean)
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: key (type: int)
-                      null sort order: z
-                      sort order: +
-                      Map-reduce partition columns: key (type: int)
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                      value expressions: value (type: int)
-                    Reduce Output Operator
-                      key expressions: key (type: int)
-                      null sort order: z
-                      sort order: +
-                      Map-reduce partition columns: key (type: int)
-                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                      value expressions: value (type: int)
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: int)
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 4 
             Map Operator Tree:
                 TableScan
                   alias: b
-                  filterExpr: value is not null (type: boolean)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Filter Operator
-                    predicate: value is not null (type: boolean)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                     Reduce Output Operator
-                      key expressions: value (type: int)
+                      key expressions: _col1 (type: int)
                       null sort order: z
                       sort order: +
-                      Map-reduce partition columns: value (type: int)
+                      Map-reduce partition columns: _col1 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col0 (type: int)
+                  Filter Operator
+                    predicate: key is not null (type: boolean)
+                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                      value expressions: key (type: int)
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: int)
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -182,10 +233,9 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 key (type: int)
-                  1 value (type: int)
-                nullSafes: [true]
-                outputColumnNames: _col0, _col1, _col6, _col7
+                  0 _col0 (type: int)
+                  1 _col0 (type: int)
+                outputColumnNames: _col0, _col1, _col2, _col3
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
                   key expressions: _col0 (type: int)
@@ -193,7 +243,7 @@ STAGE PLANS:
                   sort order: +
                   Map-reduce partition columns: _col0 (type: int)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  value expressions: _col1 (type: int), _col6 (type: int), _col7 (type: int)
+                  value expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int)
         Reducer 3 
             Execution mode: llap
             Reduce Operator Tree:
@@ -202,11 +252,12 @@ STAGE PLANS:
                      Inner Join 0 to 1
                 keys:
                   0 _col0 (type: int)
-                  1 key (type: int)
-                outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                  1 _col1 (type: int)
+                nullSafes: [true]
+                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Select Operator
-                  expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                  expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                   File Output Operator
@@ -233,6 +284,25 @@ POSTHOOK: Input: default@myinput1_n10
 #### A masked pattern was here ####
 10	NULL	NULL	10	10	NULL
 100	100	100	100	100	100
+PREHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key is not distinct from c.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key is not distinct from c.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[$0], value=[$1], key0=[$4], value0=[$5], key1=[$2], value1=[$3])
+  HiveJoin(condition=[IS NOT DISTINCT FROM($0, $5)], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveJoin(condition=[IS NOT DISTINCT FROM($0, $2)], joinType=[inner], algorithm=[none], cost=[not available])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n10]], table:alias=[a])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n10]], table:alias=[c])
+    HiveProject(key=[$0], value=[$1])
+      HiveTableScan(table=[[default, myinput1_n10]], table:alias=[b])
+
 PREHOOK: query: explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value join myinput1_n10 c on a.key is not distinct from c.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n10
@@ -259,34 +329,42 @@ STAGE PLANS:
                 TableScan
                   alias: a
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: key (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: key (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    value expressions: value (type: int)
-                  Reduce Output Operator
-                    key expressions: key (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: key (type: int)
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    value expressions: value (type: int)
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col0 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col1 (type: int)
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col1 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col0 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 4 
             Map Operator Tree:
                 TableScan
-                  alias: b
+                  alias: c
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: value (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: value (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    value expressions: key (type: int)
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col0 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -296,10 +374,10 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 key (type: int)
-                  1 value (type: int)
+                  0 _col0 (type: int)
+                  1 _col0 (type: int)
                 nullSafes: [true]
-                outputColumnNames: _col0, _col1, _col6, _col7
+                outputColumnNames: _col0, _col1, _col2, _col3
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
                   key expressions: _col0 (type: int)
@@ -307,7 +385,7 @@ STAGE PLANS:
                   sort order: +
                   Map-reduce partition columns: _col0 (type: int)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  value expressions: _col1 (type: int), _col6 (type: int), _col7 (type: int)
+                  value expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int)
         Reducer 3 
             Execution mode: llap
             Reduce Operator Tree:
@@ -316,12 +394,12 @@ STAGE PLANS:
                      Inner Join 0 to 1
                 keys:
                   0 _col0 (type: int)
-                  1 key (type: int)
+                  1 _col1 (type: int)
                 nullSafes: [true]
-                outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Select Operator
-                  expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                  expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                   File Output Operator
@@ -375,6 +453,27 @@ NULL	NULL	48	NULL	NULL	NULL
 NULL	NULL	NULL	NULL	NULL	10
 NULL	NULL	NULL	NULL	NULL	35
 NULL	NULL	NULL	NULL	NULL	NULL
+PREHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value=b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value=c.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value=b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value=c.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $4), =($1, $5))], joinType=[inner], algorithm=[none], cost=[not available])
+  HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $3), =($1, $2))], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveProject(key=[$0], value=[$1])
+      HiveFilter(condition=[IS NOT NULL($1)])
+        HiveTableScan(table=[[default, myinput1_n10]], table:alias=[a])
+    HiveProject(key=[$0], value=[$1])
+      HiveFilter(condition=[IS NOT NULL($0)])
+        HiveTableScan(table=[[default, myinput1_n10]], table:alias=[b])
+  HiveProject(key=[$0], value=[$1])
+    HiveFilter(condition=[IS NOT NULL($1)])
+      HiveTableScan(table=[[default, myinput1_n10]], table:alias=[c])
+
 PREHOOK: query: explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value=b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value=c.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n10
@@ -405,18 +504,22 @@ STAGE PLANS:
                   Filter Operator
                     predicate: value is not null (type: boolean)
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: key (type: int), value (type: int)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: key (type: int), value (type: int)
-                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: key (type: int), value (type: int)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: key (type: int), value (type: int)
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        key expressions: _col1 (type: int), _col0 (type: int)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        key expressions: _col1 (type: int), _col0 (type: int)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 4 
@@ -428,12 +531,16 @@ STAGE PLANS:
                   Filter Operator
                     predicate: key is not null (type: boolean)
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: value (type: int), key (type: int)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: value (type: int), key (type: int)
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int), _col1 (type: int)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -443,18 +550,18 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 key (type: int), value (type: int)
-                  1 value (type: int), key (type: int)
-                nullSafes: [true, false]
-                outputColumnNames: _col0, _col1, _col6, _col7
+                  0 _col1 (type: int), _col0 (type: int)
+                  1 _col0 (type: int), _col1 (type: int)
+                nullSafes: [false, true]
+                outputColumnNames: _col0, _col1, _col2, _col3
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
-                  key expressions: _col0 (type: int), _col1 (type: int)
+                  key expressions: _col1 (type: int), _col0 (type: int)
                   null sort order: zz
                   sort order: ++
-                  Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                  Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  value expressions: _col6 (type: int), _col7 (type: int)
+                  value expressions: _col2 (type: int), _col3 (type: int)
         Reducer 3 
             Execution mode: llap
             Reduce Operator Tree:
@@ -462,22 +569,18 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 _col0 (type: int), _col1 (type: int)
-                  1 key (type: int), value (type: int)
-                nullSafes: [true, false]
-                outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                  0 _col1 (type: int), _col0 (type: int)
+                  1 _col1 (type: int), _col0 (type: int)
+                nullSafes: [false, true]
+                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                Select Operator
-                  expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
-                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
+                File Output Operator
+                  compressed: false
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  File Output Operator
-                    compressed: false
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    table:
-                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-0
     Fetch Operator
@@ -495,6 +598,25 @@ POSTHOOK: Input: default@myinput1_n10
 #### A masked pattern was here ####
 100	100	100	100	100	100
 NULL	10	10	NULL	NULL	10
+PREHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value is not distinct from b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value is not distinct from c.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value is not distinct from b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value is not distinct from c.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[$0], value=[$1], key0=[$4], value0=[$5], key1=[$2], value1=[$3])
+  HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $5), IS NOT DISTINCT FROM($1, $4))], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $2), IS NOT DISTINCT FROM($1, $3))], joinType=[inner], algorithm=[none], cost=[not available])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n10]], table:alias=[a])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n10]], table:alias=[c])
+    HiveProject(key=[$0], value=[$1])
+      HiveTableScan(table=[[default, myinput1_n10]], table:alias=[b])
+
 PREHOOK: query: explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.value is not distinct from b.key join myinput1_n10 c on a.key is not distinct from c.key AND a.value is not distinct from c.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n10
@@ -521,31 +643,39 @@ STAGE PLANS:
                 TableScan
                   alias: a
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: key (type: int), value (type: int)
-                    null sort order: zz
-                    sort order: ++
-                    Map-reduce partition columns: key (type: int), value (type: int)
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: key (type: int), value (type: int)
-                    null sort order: zz
-                    sort order: ++
-                    Map-reduce partition columns: key (type: int), value (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int), _col1 (type: int)
+                      null sort order: zz
+                      sort order: ++
+                      Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int), _col0 (type: int)
+                      null sort order: zz
+                      sort order: ++
+                      Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 4 
             Map Operator Tree:
                 TableScan
-                  alias: b
+                  alias: c
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: value (type: int), key (type: int)
-                    null sort order: zz
-                    sort order: ++
-                    Map-reduce partition columns: value (type: int), key (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int), _col1 (type: int)
+                      null sort order: zz
+                      sort order: ++
+                      Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -555,10 +685,10 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 key (type: int), value (type: int)
-                  1 value (type: int), key (type: int)
+                  0 _col0 (type: int), _col1 (type: int)
+                  1 _col0 (type: int), _col1 (type: int)
                 nullSafes: [true, true]
-                outputColumnNames: _col0, _col1, _col6, _col7
+                outputColumnNames: _col0, _col1, _col2, _col3
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
                   key expressions: _col0 (type: int), _col1 (type: int)
@@ -566,7 +696,7 @@ STAGE PLANS:
                   sort order: ++
                   Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  value expressions: _col6 (type: int), _col7 (type: int)
+                  value expressions: _col2 (type: int), _col3 (type: int)
         Reducer 3 
             Execution mode: llap
             Reduce Operator Tree:
@@ -575,12 +705,12 @@ STAGE PLANS:
                      Inner Join 0 to 1
                 keys:
                   0 _col0 (type: int), _col1 (type: int)
-                  1 key (type: int), value (type: int)
+                  1 _col1 (type: int), _col0 (type: int)
                 nullSafes: [true, true]
-                outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Select Operator
-                  expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                  expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                   File Output Operator
@@ -1652,6 +1782,26 @@ NULL	10050	NULL	10050
 NULL	35	NULL	35
 NULL	NULL	12	NULL
 NULL	NULL	NULL	NULL
+Warning: Shuffle Join MERGEJOIN[13][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 2' is a cross product
+PREHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.key is NULL
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.key is NULL
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n10
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[null:INTEGER], value=[$0], key1=[$1], value1=[$2])
+  HiveJoin(condition=[true], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveProject(value=[$1])
+      HiveFilter(condition=[IS NULL($0)])
+        HiveTableScan(table=[[default, myinput1_n10]], table:alias=[a])
+    HiveProject(key=[$0], value=[$1])
+      HiveFilter(condition=[IS NOT DISTINCT FROM(null:INTEGER, $1)])
+        HiveTableScan(table=[[default, myinput1_n10]], table:alias=[b])
+
+Warning: Shuffle Join MERGEJOIN[13][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 2' is a cross product
 PREHOOK: query: explain select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.key is NULL
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n10
@@ -1669,7 +1819,7 @@ STAGE PLANS:
     Tez
 #### A masked pattern was here ####
       Edges:
-        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 3 (SIMPLE_EDGE)
+        Reducer 2 <- Map 1 (XPROD_EDGE), Map 3 (XPROD_EDGE)
 #### A masked pattern was here ####
       Vertices:
         Map 1 
@@ -1681,31 +1831,35 @@ STAGE PLANS:
                   Filter Operator
                     predicate: key is null (type: boolean)
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: null (type: int)
-                      null sort order: z
-                      sort order: +
-                      Map-reduce partition columns: null (type: int)
+                    Select Operator
+                      expressions: value (type: int)
+                      outputColumnNames: _col0
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                      value expressions: value (type: int)
+                      Reduce Output Operator
+                        null sort order: 
+                        sort order: 
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col0 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 3 
             Map Operator Tree:
                 TableScan
                   alias: b
-                  filterExpr: value is null (type: boolean)
+                  filterExpr: (null IS NOT DISTINCT FROM value) (type: boolean)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                   Filter Operator
-                    predicate: value is null (type: boolean)
+                    predicate: (null IS NOT DISTINCT FROM value) (type: boolean)
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: null (type: int)
-                      null sort order: z
-                      sort order: +
-                      Map-reduce partition columns: null (type: int)
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                      value expressions: key (type: int)
+                      Reduce Output Operator
+                        null sort order: 
+                        sort order: 
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col0 (type: int), _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -1715,18 +1869,17 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 null (type: int)
-                  1 null (type: int)
-                nullSafes: [true]
-                outputColumnNames: _col1, _col6
-                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                  0 
+                  1 
+                outputColumnNames: _col0, _col1, _col2
+                Statistics: Num rows: 1 Data size: 17 Basic stats: COMPLETE Column stats: NONE
                 Select Operator
-                  expressions: null (type: int), _col1 (type: int), _col6 (type: int), null (type: int)
+                  expressions: null (type: int), _col0 (type: int), _col1 (type: int), _col2 (type: int)
                   outputColumnNames: _col0, _col1, _col2, _col3
-                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 1 Data size: 17 Basic stats: COMPLETE Column stats: NONE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                    Statistics: Num rows: 1 Data size: 17 Basic stats: COMPLETE Column stats: NONE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1738,6 +1891,7 @@ STAGE PLANS:
       Processor Tree:
         ListSink
 
+Warning: Shuffle Join MERGEJOIN[13][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 2' is a cross product
 PREHOOK: query: select * from myinput1_n10 a join myinput1_n10 b on a.key is not distinct from b.value AND a.key is NULL
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n10
diff --git a/ql/src/test/results/clientpositive/llap/join_nullsafe.q.out b/ql/src/test/results/clientpositive/llap/join_nullsafe.q.out
index 81341d02ed..cd93844990 100644
--- a/ql/src/test/results/clientpositive/llap/join_nullsafe.q.out
+++ b/ql/src/test/results/clientpositive/llap/join_nullsafe.q.out
@@ -14,6 +14,21 @@ POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/in8.txt' INTO TABLE my
 POSTHOOK: type: LOAD
 #### A masked pattern was here ####
 POSTHOOK: Output: default@myinput1_n9
+PREHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[IS NOT DISTINCT FROM($0, $3)], joinType=[inner], algorithm=[none], cost=[not available])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n9]], table:alias=[a])
+  HiveProject(key=[$0], value=[$1])
+    HiveTableScan(table=[[default, myinput1_n9]], table:alias=[b])
+
 PREHOOK: query: explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n9
@@ -39,13 +54,17 @@ STAGE PLANS:
                 TableScan
                   alias: a
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: key (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: key (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    value expressions: value (type: int)
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col0 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 3 
@@ -53,13 +72,17 @@ STAGE PLANS:
                 TableScan
                   alias: b
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: value (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: value (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    value expressions: key (type: int)
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col1 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col0 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -69,22 +92,18 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 key (type: int)
-                  1 value (type: int)
+                  0 _col0 (type: int)
+                  1 _col1 (type: int)
                 nullSafes: [true]
-                outputColumnNames: _col0, _col1, _col6, _col7
+                outputColumnNames: _col0, _col1, _col2, _col3
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                Select Operator
-                  expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int)
-                  outputColumnNames: _col0, _col1, _col2, _col3
+                File Output Operator
+                  compressed: false
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  File Output Operator
-                    compressed: false
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    table:
-                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-0
     Fetch Operator
@@ -111,6 +130,27 @@ NULL	35	NULL	NULL
 NULL	NULL	10	NULL
 NULL	NULL	48	NULL
 NULL	NULL	NULL	NULL
+PREHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key=c.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key=c.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[$0], value=[$1], key0=[$4], value0=[$5], key1=[$2], value1=[$3])
+  HiveJoin(condition=[IS NOT DISTINCT FROM($0, $5)], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveJoin(condition=[=($0, $2)], joinType=[inner], algorithm=[none], cost=[not available])
+      HiveProject(key=[$0], value=[$1])
+        HiveFilter(condition=[IS NOT NULL($0)])
+          HiveTableScan(table=[[default, myinput1_n9]], table:alias=[a])
+      HiveProject(key=[$0], value=[$1])
+        HiveFilter(condition=[IS NOT NULL($0)])
+          HiveTableScan(table=[[default, myinput1_n9]], table:alias=[c])
+    HiveProject(key=[$0], value=[$1])
+      HiveTableScan(table=[[default, myinput1_n9]], table:alias=[b])
+
 PREHOOK: query: explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key=c.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n9
@@ -129,7 +169,7 @@ STAGE PLANS:
 #### A masked pattern was here ####
       Edges:
         Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
-        Reducer 3 <- Map 1 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
+        Reducer 3 <- Map 4 (SIMPLE_EDGE), Reducer 2 (SIMPLE_EDGE)
 #### A masked pattern was here ####
       Vertices:
         Map 1 
@@ -141,38 +181,49 @@ STAGE PLANS:
                   Filter Operator
                     predicate: key is not null (type: boolean)
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: key (type: int)
-                      null sort order: z
-                      sort order: +
-                      Map-reduce partition columns: key (type: int)
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                      value expressions: value (type: int)
-                    Reduce Output Operator
-                      key expressions: key (type: int)
-                      null sort order: z
-                      sort order: +
-                      Map-reduce partition columns: key (type: int)
-                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                      value expressions: value (type: int)
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: int)
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 4 
             Map Operator Tree:
                 TableScan
                   alias: b
-                  filterExpr: value is not null (type: boolean)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Filter Operator
-                    predicate: value is not null (type: boolean)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                     Reduce Output Operator
-                      key expressions: value (type: int)
+                      key expressions: _col1 (type: int)
                       null sort order: z
                       sort order: +
-                      Map-reduce partition columns: value (type: int)
+                      Map-reduce partition columns: _col1 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col0 (type: int)
+                  Filter Operator
+                    predicate: key is not null (type: boolean)
+                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                      value expressions: key (type: int)
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: int)
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -182,10 +233,9 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 key (type: int)
-                  1 value (type: int)
-                nullSafes: [true]
-                outputColumnNames: _col0, _col1, _col6, _col7
+                  0 _col0 (type: int)
+                  1 _col0 (type: int)
+                outputColumnNames: _col0, _col1, _col2, _col3
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
                   key expressions: _col0 (type: int)
@@ -193,7 +243,7 @@ STAGE PLANS:
                   sort order: +
                   Map-reduce partition columns: _col0 (type: int)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  value expressions: _col1 (type: int), _col6 (type: int), _col7 (type: int)
+                  value expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int)
         Reducer 3 
             Execution mode: llap
             Reduce Operator Tree:
@@ -202,11 +252,12 @@ STAGE PLANS:
                      Inner Join 0 to 1
                 keys:
                   0 _col0 (type: int)
-                  1 key (type: int)
-                outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                  1 _col1 (type: int)
+                nullSafes: [true]
+                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Select Operator
-                  expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                  expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                   File Output Operator
@@ -233,6 +284,25 @@ POSTHOOK: Input: default@myinput1_n9
 #### A masked pattern was here ####
 10	NULL	NULL	10	10	NULL
 100	100	100	100	100	100
+PREHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key<=>c.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key<=>c.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[$0], value=[$1], key0=[$4], value0=[$5], key1=[$2], value1=[$3])
+  HiveJoin(condition=[IS NOT DISTINCT FROM($0, $5)], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveJoin(condition=[IS NOT DISTINCT FROM($0, $2)], joinType=[inner], algorithm=[none], cost=[not available])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n9]], table:alias=[a])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n9]], table:alias=[c])
+    HiveProject(key=[$0], value=[$1])
+      HiveTableScan(table=[[default, myinput1_n9]], table:alias=[b])
+
 PREHOOK: query: explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value join myinput1_n9 c on a.key<=>c.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n9
@@ -259,34 +329,42 @@ STAGE PLANS:
                 TableScan
                   alias: a
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: key (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: key (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    value expressions: value (type: int)
-                  Reduce Output Operator
-                    key expressions: key (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: key (type: int)
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    value expressions: value (type: int)
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col0 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col1 (type: int)
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col1 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col0 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 4 
             Map Operator Tree:
                 TableScan
-                  alias: b
+                  alias: c
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: value (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: value (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    value expressions: key (type: int)
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col0 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -296,10 +374,10 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 key (type: int)
-                  1 value (type: int)
+                  0 _col0 (type: int)
+                  1 _col0 (type: int)
                 nullSafes: [true]
-                outputColumnNames: _col0, _col1, _col6, _col7
+                outputColumnNames: _col0, _col1, _col2, _col3
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
                   key expressions: _col0 (type: int)
@@ -307,7 +385,7 @@ STAGE PLANS:
                   sort order: +
                   Map-reduce partition columns: _col0 (type: int)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  value expressions: _col1 (type: int), _col6 (type: int), _col7 (type: int)
+                  value expressions: _col1 (type: int), _col2 (type: int), _col3 (type: int)
         Reducer 3 
             Execution mode: llap
             Reduce Operator Tree:
@@ -316,12 +394,12 @@ STAGE PLANS:
                      Inner Join 0 to 1
                 keys:
                   0 _col0 (type: int)
-                  1 key (type: int)
+                  1 _col1 (type: int)
                 nullSafes: [true]
-                outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Select Operator
-                  expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                  expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                   File Output Operator
@@ -375,6 +453,27 @@ NULL	NULL	48	NULL	NULL	NULL
 NULL	NULL	NULL	NULL	NULL	10
 NULL	NULL	NULL	NULL	NULL	35
 NULL	NULL	NULL	NULL	NULL	NULL
+PREHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value=b.key join myinput1_n9 c on a.key<=>c.key AND a.value=c.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value=b.key join myinput1_n9 c on a.key<=>c.key AND a.value=c.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $4), =($1, $5))], joinType=[inner], algorithm=[none], cost=[not available])
+  HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $3), =($1, $2))], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveProject(key=[$0], value=[$1])
+      HiveFilter(condition=[IS NOT NULL($1)])
+        HiveTableScan(table=[[default, myinput1_n9]], table:alias=[a])
+    HiveProject(key=[$0], value=[$1])
+      HiveFilter(condition=[IS NOT NULL($0)])
+        HiveTableScan(table=[[default, myinput1_n9]], table:alias=[b])
+  HiveProject(key=[$0], value=[$1])
+    HiveFilter(condition=[IS NOT NULL($1)])
+      HiveTableScan(table=[[default, myinput1_n9]], table:alias=[c])
+
 PREHOOK: query: explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value=b.key join myinput1_n9 c on a.key<=>c.key AND a.value=c.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n9
@@ -405,18 +504,22 @@ STAGE PLANS:
                   Filter Operator
                     predicate: value is not null (type: boolean)
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: key (type: int), value (type: int)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: key (type: int), value (type: int)
-                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: key (type: int), value (type: int)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: key (type: int), value (type: int)
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        key expressions: _col1 (type: int), _col0 (type: int)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        key expressions: _col1 (type: int), _col0 (type: int)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 4 
@@ -428,12 +531,16 @@ STAGE PLANS:
                   Filter Operator
                     predicate: key is not null (type: boolean)
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: value (type: int), key (type: int)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: value (type: int), key (type: int)
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int), _col1 (type: int)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -443,18 +550,18 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 key (type: int), value (type: int)
-                  1 value (type: int), key (type: int)
-                nullSafes: [true, false]
-                outputColumnNames: _col0, _col1, _col6, _col7
+                  0 _col1 (type: int), _col0 (type: int)
+                  1 _col0 (type: int), _col1 (type: int)
+                nullSafes: [false, true]
+                outputColumnNames: _col0, _col1, _col2, _col3
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
-                  key expressions: _col0 (type: int), _col1 (type: int)
+                  key expressions: _col1 (type: int), _col0 (type: int)
                   null sort order: zz
                   sort order: ++
-                  Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                  Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  value expressions: _col6 (type: int), _col7 (type: int)
+                  value expressions: _col2 (type: int), _col3 (type: int)
         Reducer 3 
             Execution mode: llap
             Reduce Operator Tree:
@@ -462,22 +569,18 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 _col0 (type: int), _col1 (type: int)
-                  1 key (type: int), value (type: int)
-                nullSafes: [true, false]
-                outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                  0 _col1 (type: int), _col0 (type: int)
+                  1 _col1 (type: int), _col0 (type: int)
+                nullSafes: [false, true]
+                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                Select Operator
-                  expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
-                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
+                File Output Operator
+                  compressed: false
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  File Output Operator
-                    compressed: false
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    table:
-                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-0
     Fetch Operator
@@ -495,6 +598,25 @@ POSTHOOK: Input: default@myinput1_n9
 #### A masked pattern was here ####
 100	100	100	100	100	100
 NULL	10	10	NULL	NULL	10
+PREHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value<=>b.key join myinput1_n9 c on a.key<=>c.key AND a.value<=>c.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value<=>b.key join myinput1_n9 c on a.key<=>c.key AND a.value<=>c.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[$0], value=[$1], key0=[$4], value0=[$5], key1=[$2], value1=[$3])
+  HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $5), IS NOT DISTINCT FROM($1, $4))], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveJoin(condition=[AND(IS NOT DISTINCT FROM($0, $2), IS NOT DISTINCT FROM($1, $3))], joinType=[inner], algorithm=[none], cost=[not available])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n9]], table:alias=[a])
+      HiveProject(key=[$0], value=[$1])
+        HiveTableScan(table=[[default, myinput1_n9]], table:alias=[c])
+    HiveProject(key=[$0], value=[$1])
+      HiveTableScan(table=[[default, myinput1_n9]], table:alias=[b])
+
 PREHOOK: query: explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.value<=>b.key join myinput1_n9 c on a.key<=>c.key AND a.value<=>c.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n9
@@ -521,31 +643,39 @@ STAGE PLANS:
                 TableScan
                   alias: a
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: key (type: int), value (type: int)
-                    null sort order: zz
-                    sort order: ++
-                    Map-reduce partition columns: key (type: int), value (type: int)
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: key (type: int), value (type: int)
-                    null sort order: zz
-                    sort order: ++
-                    Map-reduce partition columns: key (type: int), value (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int), _col1 (type: int)
+                      null sort order: zz
+                      sort order: ++
+                      Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int), _col0 (type: int)
+                      null sort order: zz
+                      sort order: ++
+                      Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 4 
             Map Operator Tree:
                 TableScan
-                  alias: b
+                  alias: c
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  Reduce Output Operator
-                    key expressions: value (type: int), key (type: int)
-                    null sort order: zz
-                    sort order: ++
-                    Map-reduce partition columns: value (type: int), key (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int), _col1 (type: int)
+                      null sort order: zz
+                      sort order: ++
+                      Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -555,10 +685,10 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 key (type: int), value (type: int)
-                  1 value (type: int), key (type: int)
+                  0 _col0 (type: int), _col1 (type: int)
+                  1 _col0 (type: int), _col1 (type: int)
                 nullSafes: [true, true]
-                outputColumnNames: _col0, _col1, _col6, _col7
+                outputColumnNames: _col0, _col1, _col2, _col3
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
                   key expressions: _col0 (type: int), _col1 (type: int)
@@ -566,7 +696,7 @@ STAGE PLANS:
                   sort order: ++
                   Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  value expressions: _col6 (type: int), _col7 (type: int)
+                  value expressions: _col2 (type: int), _col3 (type: int)
         Reducer 3 
             Execution mode: llap
             Reduce Operator Tree:
@@ -575,12 +705,12 @@ STAGE PLANS:
                      Inner Join 0 to 1
                 keys:
                   0 _col0 (type: int), _col1 (type: int)
-                  1 key (type: int), value (type: int)
+                  1 _col1 (type: int), _col0 (type: int)
                 nullSafes: [true, true]
-                outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                 Select Operator
-                  expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                  expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                   File Output Operator
@@ -1652,6 +1782,26 @@ NULL	10050	NULL	10050
 NULL	35	NULL	35
 NULL	NULL	12	NULL
 NULL	NULL	NULL	NULL
+Warning: Shuffle Join MERGEJOIN[13][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 2' is a cross product
+PREHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.key is NULL
+PREHOOK: type: QUERY
+PREHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.key is NULL
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@myinput1_n9
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(key=[null:INTEGER], value=[$0], key1=[$1], value1=[$2])
+  HiveJoin(condition=[true], joinType=[inner], algorithm=[none], cost=[not available])
+    HiveProject(value=[$1])
+      HiveFilter(condition=[IS NULL($0)])
+        HiveTableScan(table=[[default, myinput1_n9]], table:alias=[a])
+    HiveProject(key=[$0], value=[$1])
+      HiveFilter(condition=[IS NOT DISTINCT FROM(null:INTEGER, $1)])
+        HiveTableScan(table=[[default, myinput1_n9]], table:alias=[b])
+
+Warning: Shuffle Join MERGEJOIN[13][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 2' is a cross product
 PREHOOK: query: explain select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.key is NULL
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n9
@@ -1669,7 +1819,7 @@ STAGE PLANS:
     Tez
 #### A masked pattern was here ####
       Edges:
-        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 3 (SIMPLE_EDGE)
+        Reducer 2 <- Map 1 (XPROD_EDGE), Map 3 (XPROD_EDGE)
 #### A masked pattern was here ####
       Vertices:
         Map 1 
@@ -1681,31 +1831,35 @@ STAGE PLANS:
                   Filter Operator
                     predicate: key is null (type: boolean)
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: null (type: int)
-                      null sort order: z
-                      sort order: +
-                      Map-reduce partition columns: null (type: int)
+                    Select Operator
+                      expressions: value (type: int)
+                      outputColumnNames: _col0
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                      value expressions: value (type: int)
+                      Reduce Output Operator
+                        null sort order: 
+                        sort order: 
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col0 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 3 
             Map Operator Tree:
                 TableScan
                   alias: b
-                  filterExpr: value is null (type: boolean)
+                  filterExpr: (null IS NOT DISTINCT FROM value) (type: boolean)
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                   Filter Operator
-                    predicate: value is null (type: boolean)
+                    predicate: (null IS NOT DISTINCT FROM value) (type: boolean)
                     Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: null (type: int)
-                      null sort order: z
-                      sort order: +
-                      Map-reduce partition columns: null (type: int)
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
                       Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                      value expressions: key (type: int)
+                      Reduce Output Operator
+                        null sort order: 
+                        sort order: 
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                        value expressions: _col0 (type: int), _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Reducer 2 
@@ -1715,18 +1869,17 @@ STAGE PLANS:
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 null (type: int)
-                  1 null (type: int)
-                nullSafes: [true]
-                outputColumnNames: _col1, _col6
-                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                  0 
+                  1 
+                outputColumnNames: _col0, _col1, _col2
+                Statistics: Num rows: 1 Data size: 17 Basic stats: COMPLETE Column stats: NONE
                 Select Operator
-                  expressions: null (type: int), _col1 (type: int), _col6 (type: int), null (type: int)
+                  expressions: null (type: int), _col0 (type: int), _col1 (type: int), _col2 (type: int)
                   outputColumnNames: _col0, _col1, _col2, _col3
-                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 1 Data size: 17 Basic stats: COMPLETE Column stats: NONE
                   File Output Operator
                     compressed: false
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
+                    Statistics: Num rows: 1 Data size: 17 Basic stats: COMPLETE Column stats: NONE
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1738,6 +1891,7 @@ STAGE PLANS:
       Processor Tree:
         ListSink
 
+Warning: Shuffle Join MERGEJOIN[13][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 2' is a cross product
 PREHOOK: query: select * from myinput1_n9 a join myinput1_n9 b on a.key<=>b.value AND a.key is NULL
 PREHOOK: type: QUERY
 PREHOOK: Input: default@myinput1_n9
diff --git a/ql/src/test/results/clientpositive/llap/orc_predicate_pushdown.q.out b/ql/src/test/results/clientpositive/llap/orc_predicate_pushdown.q.out
index c9c46548b1..da44adf943 100644
--- a/ql/src/test/results/clientpositive/llap/orc_predicate_pushdown.q.out
+++ b/ql/src/test/results/clientpositive/llap/orc_predicate_pushdown.q.out
@@ -511,9 +511,9 @@ STAGE PLANS:
         TableScan
           alias: orc_pred
           Filter Operator
-            predicate: ((t IS NOT DISTINCT FROM -1Y) and s is not null and (s like 'bob%')) (type: boolean)
+            predicate: ((t IS NOT DISTINCT FROM -1Y) and (s like 'bob%') and s is not null) (type: boolean)
             Select Operator
-              expressions: -1Y (type: tinyint), s (type: string)
+              expressions: t (type: tinyint), s (type: string)
               outputColumnNames: _col0, _col1
               ListSink
 
@@ -541,11 +541,11 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: orc_pred
-          filterExpr: ((t IS NOT DISTINCT FROM -1Y) and s is not null and (s like 'bob%')) (type: boolean)
+          filterExpr: ((t IS NOT DISTINCT FROM -1Y) and (s like 'bob%') and s is not null) (type: boolean)
           Filter Operator
-            predicate: ((t IS NOT DISTINCT FROM -1Y) and s is not null and (s like 'bob%')) (type: boolean)
+            predicate: ((t IS NOT DISTINCT FROM -1Y) and (s like 'bob%') and s is not null) (type: boolean)
             Select Operator
-              expressions: -1Y (type: tinyint), s (type: string)
+              expressions: t (type: tinyint), s (type: string)
               outputColumnNames: _col0, _col1
               ListSink
 
diff --git a/ql/src/test/results/clientpositive/llap/parquet_predicate_pushdown.q.out b/ql/src/test/results/clientpositive/llap/parquet_predicate_pushdown.q.out
index cceab7cf3c..15733b2ef3 100644
--- a/ql/src/test/results/clientpositive/llap/parquet_predicate_pushdown.q.out
+++ b/ql/src/test/results/clientpositive/llap/parquet_predicate_pushdown.q.out
@@ -445,9 +445,9 @@ STAGE PLANS:
         TableScan
           alias: tbl_pred
           Filter Operator
-            predicate: ((t IS NOT DISTINCT FROM -1Y) and s is not null and (s like 'bob%')) (type: boolean)
+            predicate: ((t IS NOT DISTINCT FROM -1Y) and (s like 'bob%') and s is not null) (type: boolean)
             Select Operator
-              expressions: -1Y (type: tinyint), s (type: string)
+              expressions: t (type: tinyint), s (type: string)
               outputColumnNames: _col0, _col1
               ListSink
 
@@ -475,11 +475,11 @@ STAGE PLANS:
       Processor Tree:
         TableScan
           alias: tbl_pred
-          filterExpr: ((t IS NOT DISTINCT FROM -1Y) and s is not null and (s like 'bob%')) (type: boolean)
+          filterExpr: ((t IS NOT DISTINCT FROM -1Y) and (s like 'bob%') and s is not null) (type: boolean)
           Filter Operator
-            predicate: ((t IS NOT DISTINCT FROM -1Y) and s is not null and (s like 'bob%')) (type: boolean)
+            predicate: ((t IS NOT DISTINCT FROM -1Y) and (s like 'bob%') and s is not null) (type: boolean)
             Select Operator
-              expressions: -1Y (type: tinyint), s (type: string)
+              expressions: t (type: tinyint), s (type: string)
               outputColumnNames: _col0, _col1
               ListSink
 
diff --git a/ql/src/test/results/clientpositive/llap/semijoin6.q.out b/ql/src/test/results/clientpositive/llap/semijoin6.q.out
index 5d18babec8..b1d83766ee 100644
--- a/ql/src/test/results/clientpositive/llap/semijoin6.q.out
+++ b/ql/src/test/results/clientpositive/llap/semijoin6.q.out
@@ -145,6 +145,25 @@ POSTHOOK: Input: default@tx2_n0
 1	105
 2	203
 4	400
+PREHOOK: query: explain cbo
+select * from tx1_n1 u left semi join tx2_n0 v on u.b <=> v.b
+PREHOOK: type: QUERY
+PREHOOK: Input: default@tx1_n1
+PREHOOK: Input: default@tx2_n0
+#### A masked pattern was here ####
+POSTHOOK: query: explain cbo
+select * from tx1_n1 u left semi join tx2_n0 v on u.b <=> v.b
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@tx1_n1
+POSTHOOK: Input: default@tx2_n0
+#### A masked pattern was here ####
+CBO PLAN:
+HiveSemiJoin(condition=[IS NOT DISTINCT FROM($1, $2)], joinType=[semi])
+  HiveProject(a=[$0], b=[$1])
+    HiveTableScan(table=[[default, tx1_n1]], table:alias=[u])
+  HiveProject(b=[$1])
+    HiveTableScan(table=[[default, tx2_n0]], table:alias=[v])
+
 PREHOOK: query: explain
 select * from tx1_n1 u left semi join tx2_n0 v on u.b <=> v.b
 PREHOOK: type: QUERY
@@ -174,13 +193,17 @@ STAGE PLANS:
                 TableScan
                   alias: u
                   Statistics: Num rows: 6 Data size: 44 Basic stats: COMPLETE Column stats: COMPLETE
-                  Reduce Output Operator
-                    key expressions: b (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: b (type: int)
+                  Select Operator
+                    expressions: a (type: int), b (type: int)
+                    outputColumnNames: _col0, _col1
                     Statistics: Num rows: 6 Data size: 44 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: a (type: int)
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col1 (type: int)
+                      Statistics: Num rows: 6 Data size: 44 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col0 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
         Map 3 
@@ -213,7 +236,7 @@ STAGE PLANS:
                 condition map:
                      Left Semi Join 0 to 1
                 keys:
-                  0 b (type: int)
+                  0 _col1 (type: int)
                   1 _col0 (type: int)
                 nullSafes: [true]
                 outputColumnNames: _col0, _col1
diff --git a/ql/src/test/results/clientpositive/llap/show_functions.q.out b/ql/src/test/results/clientpositive/llap/show_functions.q.out
index 122b3bc061..c05d208703 100644
--- a/ql/src/test/results/clientpositive/llap/show_functions.q.out
+++ b/ql/src/test/results/clientpositive/llap/show_functions.q.out
@@ -214,6 +214,7 @@ initcap
 inline
 instr
 internal_interval
+is_not_distinct_from
 isfalse
 isnotfalse
 isnotnull
@@ -730,6 +731,7 @@ initcap
 inline
 instr
 internal_interval
+is_not_distinct_from
 isfalse
 isnotfalse
 isnotnull
diff --git a/ql/src/test/results/clientpositive/llap/tez_union_group_by.q.out b/ql/src/test/results/clientpositive/llap/tez_union_group_by.q.out
index 115a9e9a0a..9a7fc7cbb6 100644
--- a/ql/src/test/results/clientpositive/llap/tez_union_group_by.q.out
+++ b/ql/src/test/results/clientpositive/llap/tez_union_group_by.q.out
@@ -84,7 +84,7 @@ TBLPROPERTIES ("orc.compress"="ZLIB")
 POSTHOOK: type: CREATETABLE
 POSTHOOK: Output: database:default
 POSTHOOK: Output: default@v_n15
-PREHOOK: query: EXPLAIN 
+PREHOOK: query: EXPLAIN CBO
 SELECT o.u, n.u
 FROM 
 (
@@ -116,7 +116,7 @@ PREHOOK: Input: default@x_n3
 PREHOOK: Input: default@y_n1
 PREHOOK: Input: default@z_n0
 #### A masked pattern was here ####
-POSTHOOK: query: EXPLAIN 
+POSTHOOK: query: EXPLAIN CBO
 SELECT o.u, n.u
 FROM 
 (
@@ -148,6 +148,96 @@ POSTHOOK: Input: default@x_n3
 POSTHOOK: Input: default@y_n1
 POSTHOOK: Input: default@z_n0
 #### A masked pattern was here ####
+CBO PLAN:
+HiveJoin(condition=[=($1, $0)], joinType=[right], algorithm=[none], cost=[not available])
+  HiveProject(u=[$0])
+    HiveAggregate(group=[{0}])
+      HiveJoin(condition=[AND(=($1, $3), IS NOT DISTINCT FROM($2, $4))], joinType=[inner], algorithm=[none], cost=[not available])
+        HiveProject(u=[$0], t=[$1], st=[$2])
+          HiveFilter(condition=[AND(>=($3, _UTF-16LE'2014-03-04'), <($3, _UTF-16LE'2014-09-03'), <>($0, 0), IS NOT NULL($1))])
+            HiveTableScan(table=[[default, x_n3]], table:alias=[x_n3])
+        HiveProject(t=[$0], st=[$1])
+          HiveFilter(condition=[IS NOT NULL($0)])
+            HiveTableScan(table=[[default, v_n15]], table:alias=[v_n15])
+  HiveProject($f0=[$0])
+    HiveFilter(condition=[<=($1, _UTF-16LE'2014-09-02')])
+      HiveAggregate(group=[{0}], agg#0=[min($1)])
+        HiveProject(u=[$0], date=[$1])
+          HiveUnion(all=[true])
+            HiveProject(u=[$0], date=[$3])
+              HiveFilter(condition=[AND(<($3, _UTF-16LE'2014-09-02'), <>($0, 0))])
+                HiveTableScan(table=[[default, x_n3]], table:alias=[x_n3])
+            HiveProject(u=[$0], date=[$1])
+              HiveFilter(condition=[AND(<($1, _UTF-16LE'2014-09-02'), <>($0, 0))])
+                HiveTableScan(table=[[default, y_n1]], table:alias=[y_n1])
+            HiveProject(u=[$0], date=[$1])
+              HiveFilter(condition=[AND(<($1, _UTF-16LE'2014-09-02'), <>($0, 0))])
+                HiveTableScan(table=[[default, z_n0]], table:alias=[z_n0])
+
+PREHOOK: query: EXPLAIN
+SELECT o.u, n.u
+FROM
+(
+SELECT m.u, Min(`date`) as ft
+FROM
+(
+SELECT u, `date` FROM x_n3 WHERE `date` < '2014-09-02'
+UNION ALL
+SELECT u, `date` FROM y_n1 WHERE `date` < '2014-09-02'
+UNION ALL
+SELECT u, `date` FROM z_n0 WHERE `date` < '2014-09-02'
+) m
+GROUP BY m.u
+) n
+LEFT OUTER JOIN
+(
+SELECT x_n3.u
+FROM x_n3
+JOIN v_n15
+ON (x_n3.t = v_n15.t AND x_n3.st <=> v_n15.st)
+WHERE x_n3.`date` >= '2014-03-04' AND x_n3.`date` < '2014-09-03'
+GROUP BY x_n3.u
+) o
+ON n.u = o.u
+WHERE n.u <> 0 AND n.ft <= '2014-09-02'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@v_n15
+PREHOOK: Input: default@x_n3
+PREHOOK: Input: default@y_n1
+PREHOOK: Input: default@z_n0
+#### A masked pattern was here ####
+POSTHOOK: query: EXPLAIN
+SELECT o.u, n.u
+FROM
+(
+SELECT m.u, Min(`date`) as ft
+FROM
+(
+SELECT u, `date` FROM x_n3 WHERE `date` < '2014-09-02'
+UNION ALL
+SELECT u, `date` FROM y_n1 WHERE `date` < '2014-09-02'
+UNION ALL
+SELECT u, `date` FROM z_n0 WHERE `date` < '2014-09-02'
+) m
+GROUP BY m.u
+) n
+LEFT OUTER JOIN
+(
+SELECT x_n3.u
+FROM x_n3
+JOIN v_n15
+ON (x_n3.t = v_n15.t AND x_n3.st <=> v_n15.st)
+WHERE x_n3.`date` >= '2014-03-04' AND x_n3.`date` < '2014-09-03'
+GROUP BY x_n3.u
+) o
+ON n.u = o.u
+WHERE n.u <> 0 AND n.ft <= '2014-09-02'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@v_n15
+POSTHOOK: Input: default@x_n3
+POSTHOOK: Input: default@y_n1
+POSTHOOK: Input: default@z_n0
+#### A masked pattern was here ####
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
@@ -157,45 +247,67 @@ STAGE PLANS:
     Tez
 #### A masked pattern was here ####
       Edges:
-        Map 1 <- Union 2 (CONTAINS)
-        Map 5 <- Union 2 (CONTAINS)
-        Map 6 <- Union 2 (CONTAINS)
-        Reducer 3 <- Union 2 (SIMPLE_EDGE)
-        Reducer 4 <- Reducer 3 (SIMPLE_EDGE), Reducer 9 (SIMPLE_EDGE)
-        Reducer 8 <- Map 10 (SIMPLE_EDGE), Map 7 (SIMPLE_EDGE)
-        Reducer 9 <- Reducer 8 (SIMPLE_EDGE)
+        Map 10 <- Union 7 (CONTAINS)
+        Map 6 <- Union 7 (CONTAINS)
+        Map 9 <- Union 7 (CONTAINS)
+        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 5 (SIMPLE_EDGE)
+        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
+        Reducer 4 <- Reducer 3 (SIMPLE_EDGE), Reducer 8 (SIMPLE_EDGE)
+        Reducer 8 <- Union 7 (SIMPLE_EDGE)
 #### A masked pattern was here ####
       Vertices:
         Map 1 
             Map Operator Tree:
                 TableScan
                   alias: x_n3
+                  filterExpr: ((date >= '2014-03-04') and (date < '2014-09-03') and (u <> 0L) and t is not null) (type: boolean)
+                  Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: COMPLETE
+                  Filter Operator
+                    predicate: ((date >= '2014-03-04') and (date < '2014-09-03') and (u <> 0L) and t is not null) (type: boolean)
+                    Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: COMPLETE
+                    Select Operator
+                      expressions: u (type: bigint), t (type: string), st (type: string)
+                      outputColumnNames: _col0, _col1, _col2
+                      Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
+                      Reduce Output Operator
+                        key expressions: _col1 (type: string), _col2 (type: string)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col1 (type: string), _col2 (type: string)
+                        Statistics: Num rows: 1 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
+                        value expressions: _col0 (type: bigint)
+            Execution mode: vectorized, llap
+            LLAP IO: unknown
+        Map 10 
+            Map Operator Tree:
+                TableScan
+                  alias: z_n0
                   filterExpr: ((date < '2014-09-02') and (u <> 0L)) (type: boolean)
-                  Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: ((date < '2014-09-02') and (u <> 0L)) (type: boolean)
-                    Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: u (type: bigint), date (type: string)
                       outputColumnNames: _col0, _col1
-                      Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                       Group By Operator
                         aggregations: min(_col1)
                         keys: _col0 (type: bigint)
                         minReductionHashAggr: 0.99
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                        Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: bigint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: bigint)
-                          Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                          Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: COMPLETE
                           value expressions: _col1 (type: string)
             Execution mode: vectorized, llap
             LLAP IO: unknown
-        Map 10 
+        Map 5 
             Map Operator Tree:
                 TableScan
                   alias: v_n15
@@ -204,174 +316,156 @@ STAGE PLANS:
                   Filter Operator
                     predicate: t is not null (type: boolean)
                     Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
-                    Reduce Output Operator
-                      key expressions: t (type: string), st (type: string)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: t (type: string), st (type: string)
+                    Select Operator
+                      expressions: t (type: string), st (type: string)
+                      outputColumnNames: _col0, _col1
                       Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: string), _col1 (type: string)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
+                        Statistics: Num rows: 1 Data size: 368 Basic stats: COMPLETE Column stats: NONE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
-        Map 5 
+        Map 6 
             Map Operator Tree:
                 TableScan
-                  alias: y_n1
+                  alias: x_n3
                   filterExpr: ((date < '2014-09-02') and (u <> 0L)) (type: boolean)
-                  Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: ((date < '2014-09-02') and (u <> 0L)) (type: boolean)
-                    Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: u (type: bigint), date (type: string)
                       outputColumnNames: _col0, _col1
-                      Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                       Group By Operator
                         aggregations: min(_col1)
                         keys: _col0 (type: bigint)
                         minReductionHashAggr: 0.99
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                        Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: bigint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: bigint)
-                          Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                          Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: COMPLETE
                           value expressions: _col1 (type: string)
             Execution mode: vectorized, llap
             LLAP IO: unknown
-        Map 6 
+        Map 9 
             Map Operator Tree:
                 TableScan
-                  alias: z_n0
+                  alias: y_n1
                   filterExpr: ((date < '2014-09-02') and (u <> 0L)) (type: boolean)
-                  Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     predicate: ((date < '2014-09-02') and (u <> 0L)) (type: boolean)
-                    Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                    Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                     Select Operator
                       expressions: u (type: bigint), date (type: string)
                       outputColumnNames: _col0, _col1
-                      Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                      Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                       Group By Operator
                         aggregations: min(_col1)
                         keys: _col0 (type: bigint)
                         minReductionHashAggr: 0.99
                         mode: hash
                         outputColumnNames: _col0, _col1
-                        Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                        Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: COMPLETE
                         Reduce Output Operator
                           key expressions: _col0 (type: bigint)
                           null sort order: z
                           sort order: +
                           Map-reduce partition columns: _col0 (type: bigint)
-                          Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
+                          Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: COMPLETE
                           value expressions: _col1 (type: string)
             Execution mode: vectorized, llap
             LLAP IO: unknown
-        Map 7 
-            Map Operator Tree:
-                TableScan
-                  alias: x_n3
-                  filterExpr: (t is not null and (date >= '2014-03-04') and (date < '2014-09-03') and (u <> 0L)) (type: boolean)
-                  Statistics: Num rows: 1 Data size: 560 Basic stats: COMPLETE Column stats: PARTIAL
-                  Filter Operator
-                    predicate: (t is not null and (date >= '2014-03-04') and (date < '2014-09-03') and (u <> 0L)) (type: boolean)
-                    Statistics: Num rows: 1 Data size: 560 Basic stats: COMPLETE Column stats: PARTIAL
-                    Reduce Output Operator
-                      key expressions: t (type: string), st (type: string)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: t (type: string), st (type: string)
-                      Statistics: Num rows: 1 Data size: 560 Basic stats: COMPLETE Column stats: PARTIAL
-                      value expressions: u (type: bigint)
-            Execution mode: vectorized, llap
-            LLAP IO: unknown
-        Reducer 3 
-            Execution mode: vectorized, llap
-            Reduce Operator Tree:
-              Group By Operator
-                aggregations: min(VALUE._col0)
-                keys: KEY._col0 (type: bigint)
-                mode: mergepartial
-                outputColumnNames: _col0, _col1
-                Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
-                Filter Operator
-                  predicate: (_col1 <= '2014-09-02') (type: boolean)
-                  Statistics: Num rows: 1 Data size: 192 Basic stats: COMPLETE Column stats: PARTIAL
-                  Select Operator
-                    expressions: _col0 (type: bigint)
-                    outputColumnNames: _col0
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: PARTIAL
-                    Reduce Output Operator
-                      key expressions: _col0 (type: bigint)
-                      null sort order: z
-                      sort order: +
-                      Map-reduce partition columns: _col0 (type: bigint)
-                      Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: PARTIAL
-        Reducer 4 
-            Execution mode: llap
-            Reduce Operator Tree:
-              Merge Join Operator
-                condition map:
-                     Left Outer Join 0 to 1
-                keys:
-                  0 _col0 (type: bigint)
-                  1 _col0 (type: bigint)
-                outputColumnNames: _col0, _col2
-                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                Select Operator
-                  expressions: _col2 (type: bigint), _col0 (type: bigint)
-                  outputColumnNames: _col0, _col1
-                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  File Output Operator
-                    compressed: false
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    table:
-                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-        Reducer 8 
+        Reducer 2 
             Execution mode: llap
             Reduce Operator Tree:
               Merge Join Operator
                 condition map:
                      Inner Join 0 to 1
                 keys:
-                  0 t (type: string), st (type: string)
-                  1 t (type: string), st (type: string)
+                  0 _col1 (type: string), _col2 (type: string)
+                  1 _col0 (type: string), _col1 (type: string)
                 nullSafes: [false, true]
                 outputColumnNames: _col0
-                Statistics: Num rows: 1 Data size: 616 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                 Group By Operator
                   keys: _col0 (type: bigint)
                   minReductionHashAggr: 0.99
                   mode: hash
                   outputColumnNames: _col0
-                  Statistics: Num rows: 1 Data size: 616 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                   Reduce Output Operator
                     key expressions: _col0 (type: bigint)
                     null sort order: z
                     sort order: +
                     Map-reduce partition columns: _col0 (type: bigint)
-                    Statistics: Num rows: 1 Data size: 616 Basic stats: COMPLETE Column stats: NONE
-        Reducer 9 
+                    Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
+        Reducer 3 
             Execution mode: vectorized, llap
             Reduce Operator Tree:
               Group By Operator
                 keys: KEY._col0 (type: bigint)
                 mode: mergepartial
                 outputColumnNames: _col0
-                Statistics: Num rows: 1 Data size: 616 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
                 Reduce Output Operator
                   key expressions: _col0 (type: bigint)
                   null sort order: z
                   sort order: +
                   Map-reduce partition columns: _col0 (type: bigint)
-                  Statistics: Num rows: 1 Data size: 616 Basic stats: COMPLETE Column stats: NONE
-        Union 2 
-            Vertex: Union 2
+                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE
+        Reducer 4 
+            Execution mode: llap
+            Reduce Operator Tree:
+              Merge Join Operator
+                condition map:
+                     Right Outer Join 0 to 1
+                keys:
+                  0 _col0 (type: bigint)
+                  1 _col0 (type: bigint)
+                outputColumnNames: _col0, _col1
+                Statistics: Num rows: 1 Data size: 202 Basic stats: PARTIAL Column stats: NONE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 1 Data size: 202 Basic stats: PARTIAL Column stats: NONE
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+        Reducer 8 
+            Execution mode: vectorized, llap
+            Reduce Operator Tree:
+              Group By Operator
+                aggregations: min(VALUE._col0)
+                keys: KEY._col0 (type: bigint)
+                mode: mergepartial
+                outputColumnNames: _col0, _col1
+                Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: COMPLETE
+                Filter Operator
+                  predicate: (_col1 <= '2014-09-02') (type: boolean)
+                  Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: COMPLETE
+                  Select Operator
+                    expressions: _col0 (type: bigint)
+                    outputColumnNames: _col0
+                    Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: COMPLETE
+                    Reduce Output Operator
+                      key expressions: _col0 (type: bigint)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col0 (type: bigint)
+                      Statistics: Num rows: 1 Data size: 184 Basic stats: PARTIAL Column stats: COMPLETE
+        Union 7 
+            Vertex: Union 7
 
   Stage: Stage-0
     Fetch Operator
diff --git a/ql/src/test/results/clientpositive/llap/udf_equal.q.out b/ql/src/test/results/clientpositive/llap/udf_equal.q.out
index 5ccfac0513..13795e9469 100644
--- a/ql/src/test/results/clientpositive/llap/udf_equal.q.out
+++ b/ql/src/test/results/clientpositive/llap/udf_equal.q.out
@@ -43,6 +43,7 @@ PREHOOK: type: DESCFUNCTION
 POSTHOOK: query: DESCRIBE FUNCTION EXTENDED <=>
 POSTHOOK: type: DESCFUNCTION
 a <=> b - Returns same result with EQUALNS (IS NOT DISTINCT FROM) operator for non-null operands, but returns TRUE if both are NULL, FALSE if one of the them is NULL
+Synonyms: is_not_distinct_from
 Function class:org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqualNS
 Function type:BUILTIN
 PREHOOK: query: SELECT true<=>false, false<=>true, false<=>false, true<=>true, NULL<=>NULL, true<=>NULL, NULL<=>true, false<=>NULL, NULL<=>false FROM src tablesample (1 rows)
diff --git a/ql/src/test/results/clientpositive/llap/vector_nullsafe_join.q.out b/ql/src/test/results/clientpositive/llap/vector_nullsafe_join.q.out
index 6d647f5fcb..9753bb0b5c 100644
--- a/ql/src/test/results/clientpositive/llap/vector_nullsafe_join.q.out
+++ b/ql/src/test/results/clientpositive/llap/vector_nullsafe_join.q.out
@@ -57,31 +57,31 @@ STAGE PLANS:
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Map Join Operator
-                    condition map:
-                         Inner Join 0 to 1
-                    keys:
-                      0 key (type: int)
-                      1 value (type: int)
-                    Map Join Vectorization:
-                        bigTableKeyExpressions: col 0:int
-                        bigTableValueExpressions: col 0:int, col 1:int
-                        className: VectorMapJoinOperator
-                        native: false
-                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
-                        nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
-                    nullSafes: [true]
-                    outputColumnNames: _col0, _col1, _col6, _col7
-                    input vertices:
-                      1 Map 2
-                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
-                    Select Operator
-                      expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
+                        native: true
+                        projectedOutputColumnNums: [0, 1]
+                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Map Join Operator
+                      condition map:
+                           Inner Join 0 to 1
+                      keys:
+                        0 _col0 (type: int)
+                        1 _col1 (type: int)
+                      Map Join Vectorization:
+                          bigTableKeyExpressions: col 0:int
+                          bigTableValueExpressions: col 0:int, col 1:int
+                          className: VectorMapJoinOperator
+                          native: false
+                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
+                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
+                      nullSafes: [true]
                       outputColumnNames: _col0, _col1, _col2, _col3
-                      Select Vectorization:
-                          className: VectorSelectOperator
-                          native: true
-                          projectedOutputColumnNums: [0, 1, 2, 3]
+                      input vertices:
+                        1 Map 2
                       Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                       File Output Operator
                         compressed: false
@@ -111,17 +111,25 @@ STAGE PLANS:
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Reduce Output Operator
-                    key expressions: value (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: value (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkLongOperator
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
                         native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        projectedOutputColumnNums: [0, 1]
                     Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: key (type: int)
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col1 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkLongOperator
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col0 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -189,6 +197,7 @@ STAGE PLANS:
                 TableScan
                   alias: a
                   filterExpr: key is not null (type: boolean)
+                  probeDecodeDetails: cacheKey:HASH_MAP_MAPJOIN_30_container, bigKeyColName:key, smallTablePos:1, keyRatio:0.5
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
@@ -199,59 +208,67 @@ STAGE PLANS:
                         predicateExpression: SelectColumnIsNotNull(col 0:int)
                     predicate: key is not null (type: boolean)
                     Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                    Map Join Operator
-                      condition map:
-                           Inner Join 0 to 1
-                      keys:
-                        0 key (type: int)
-                        1 value (type: int)
-                      Map Join Vectorization:
-                          bigTableKeyExpressions: col 0:int
-                          bigTableValueExpressions: col 0:int, col 1:int
-                          className: VectorMapJoinOperator
-                          native: false
-                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
-                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
-                      nullSafes: [true]
-                      outputColumnNames: _col0, _col1, _col6, _col7
-                      input vertices:
-                        1 Reducer 3
-                      Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
+                      Select Vectorization:
+                          className: VectorSelectOperator
+                          native: true
+                          projectedOutputColumnNums: [0, 1]
+                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                       Map Join Operator
                         condition map:
                              Inner Join 0 to 1
                         keys:
                           0 _col0 (type: int)
-                          1 key (type: int)
+                          1 _col0 (type: int)
                         Map Join Vectorization:
                             bigTableKeyExpressions: col 0:int
-                            bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                            bigTableValueExpressions: col 0:int, col 1:int
                             className: VectorMapJoinOperator
                             native: false
                             nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                             nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false
-                        outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                        outputColumnNames: _col0, _col1, _col2, _col3
                         input vertices:
                           1 Map 2
-                        Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
-                        Select Operator
-                          expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                        Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                        Map Join Operator
+                          condition map:
+                               Inner Join 0 to 1
+                          keys:
+                            0 _col0 (type: int)
+                            1 _col1 (type: int)
+                          Map Join Vectorization:
+                              bigTableKeyExpressions: col 0:int
+                              bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                              className: VectorMapJoinOperator
+                              native: false
+                              nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
+                              nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
+                          nullSafes: [true]
                           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                          Select Vectorization:
-                              className: VectorSelectOperator
-                              native: true
-                              projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
-                          Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
-                          File Output Operator
-                            compressed: false
-                            File Sink Vectorization:
-                                className: VectorFileSinkOperator
-                                native: false
-                            Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
-                            table:
-                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          input vertices:
+                            1 Reducer 3
+                          Statistics: Num rows: 6 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
+                          Select Operator
+                            expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
+                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
+                            Select Vectorization:
+                                className: VectorSelectOperator
+                                native: true
+                                projectedOutputColumnNums: [0, 1, 4, 5, 2, 3]
+                            Statistics: Num rows: 6 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
+                            File Output Operator
+                              compressed: false
+                              File Sink Vectorization:
+                                  className: VectorFileSinkOperator
+                                  native: false
+                              Statistics: Num rows: 6 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
+                              table:
+                                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -267,28 +284,28 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: b
-                  filterExpr: (value is not null or key is not null) (type: boolean)
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Filter Operator
-                    Filter Vectorization:
-                        className: VectorFilterOperator
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
                         native: true
-                        predicateExpression: SelectColumnIsNotNull(col 1:int)
-                    predicate: value is not null (type: boolean)
-                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
+                        projectedOutputColumnNums: [0, 1]
+                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                     Reduce Output Operator
-                      key expressions: value (type: int)
+                      key expressions: _col1 (type: int)
                       null sort order: z
                       sort order: +
-                      Map-reduce partition columns: value (type: int)
+                      Map-reduce partition columns: _col1 (type: int)
                       Reduce Sink Vectorization:
                           className: VectorReduceSinkLongOperator
                           native: true
                           nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                      value expressions: key (type: int)
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col0 (type: int)
                   Filter Operator
                     Filter Vectorization:
                         className: VectorFilterOperator
@@ -296,17 +313,25 @@ STAGE PLANS:
                         predicateExpression: SelectColumnIsNotNull(col 0:int)
                     predicate: key is not null (type: boolean)
                     Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                    Reduce Output Operator
-                      key expressions: key (type: int)
-                      null sort order: z
-                      sort order: +
-                      Map-reduce partition columns: key (type: int)
-                      Reduce Sink Vectorization:
-                          className: VectorReduceSinkLongOperator
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
+                      Select Vectorization:
+                          className: VectorSelectOperator
                           native: true
-                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                          projectedOutputColumnNums: [0, 1]
                       Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                      value expressions: value (type: int)
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: int)
+                        Reduce Sink Vectorization:
+                            className: VectorReduceSinkLongOperator
+                            native: true
+                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
+                        value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -329,22 +354,22 @@ STAGE PLANS:
             Reduce Operator Tree:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: int)
-                outputColumnNames: value, key
+                outputColumnNames: _col1, _col0
                 Select Vectorization:
                     className: VectorSelectOperator
                     native: true
                     projectedOutputColumnNums: [0, 1]
                 Reduce Output Operator
-                  key expressions: value (type: int)
+                  key expressions: _col1 (type: int)
                   null sort order: z
                   sort order: +
-                  Map-reduce partition columns: value (type: int)
+                  Map-reduce partition columns: _col1 (type: int)
                   Reduce Sink Vectorization:
                       className: VectorReduceSinkLongOperator
                       native: true
                       nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                  Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                  value expressions: key (type: int)
+                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                  value expressions: _col0 (type: int)
 
   Stage: Stage-0
     Fetch Operator
@@ -394,60 +419,68 @@ STAGE PLANS:
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Map Join Operator
-                    condition map:
-                         Inner Join 0 to 1
-                    keys:
-                      0 key (type: int)
-                      1 value (type: int)
-                    Map Join Vectorization:
-                        bigTableKeyExpressions: col 0:int
-                        bigTableValueExpressions: col 0:int, col 1:int
-                        className: VectorMapJoinOperator
-                        native: false
-                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
-                        nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
-                    nullSafes: [true]
-                    outputColumnNames: _col0, _col1, _col6, _col7
-                    input vertices:
-                      1 Reducer 3
-                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
+                        native: true
+                        projectedOutputColumnNums: [0, 1]
+                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                     Map Join Operator
                       condition map:
                            Inner Join 0 to 1
                       keys:
                         0 _col0 (type: int)
-                        1 key (type: int)
+                        1 _col0 (type: int)
                       Map Join Vectorization:
                           bigTableKeyExpressions: col 0:int
-                          bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                          bigTableValueExpressions: col 0:int, col 1:int
                           className: VectorMapJoinOperator
                           native: false
                           nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                           nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
                       nullSafes: [true]
-                      outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                      outputColumnNames: _col0, _col1, _col2, _col3
                       input vertices:
                         1 Map 2
-                      Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                      Select Operator
-                        expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                      Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                      Map Join Operator
+                        condition map:
+                             Inner Join 0 to 1
+                        keys:
+                          0 _col0 (type: int)
+                          1 _col1 (type: int)
+                        Map Join Vectorization:
+                            bigTableKeyExpressions: col 0:int
+                            bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                            className: VectorMapJoinOperator
+                            native: false
+                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
+                            nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
+                        nullSafes: [true]
                         outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                        Select Vectorization:
-                            className: VectorSelectOperator
-                            native: true
-                            projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
+                        input vertices:
+                          1 Reducer 3
                         Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                        File Output Operator
-                          compressed: false
-                          File Sink Vectorization:
-                              className: VectorFileSinkOperator
-                              native: false
+                        Select Operator
+                          expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
+                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
+                          Select Vectorization:
+                              className: VectorSelectOperator
+                              native: true
+                              projectedOutputColumnNums: [0, 1, 4, 5, 2, 3]
                           Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                          table:
-                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          File Output Operator
+                            compressed: false
+                            File Sink Vectorization:
+                                className: VectorFileSinkOperator
+                                native: false
+                            Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
+                            table:
+                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -462,32 +495,40 @@ STAGE PLANS:
         Map 2 
             Map Operator Tree:
                 TableScan
-                  alias: b
+                  alias: c
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Reduce Output Operator
-                    key expressions: value (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: value (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkLongOperator
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
                         native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        projectedOutputColumnNums: [0, 1]
                     Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: key (type: int)
-                  Reduce Output Operator
-                    key expressions: key (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: key (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkLongOperator
-                        native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: value (type: int)
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col0 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkLongOperator
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col1 (type: int)
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col1 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkLongOperator
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col0 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -510,22 +551,22 @@ STAGE PLANS:
             Reduce Operator Tree:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: int)
-                outputColumnNames: value, key
+                outputColumnNames: _col1, _col0
                 Select Vectorization:
                     className: VectorSelectOperator
                     native: true
                     projectedOutputColumnNums: [0, 1]
                 Reduce Output Operator
-                  key expressions: value (type: int)
+                  key expressions: _col1 (type: int)
                   null sort order: z
                   sort order: +
-                  Map-reduce partition columns: value (type: int)
+                  Map-reduce partition columns: _col1 (type: int)
                   Reduce Sink Vectorization:
                       className: VectorReduceSinkLongOperator
                       native: true
                       nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                  value expressions: key (type: int)
+                  value expressions: _col0 (type: int)
 
   Stage: Stage-0
     Fetch Operator
@@ -610,49 +651,49 @@ STAGE PLANS:
                         predicateExpression: SelectColumnIsNotNull(col 1:int)
                     predicate: value is not null (type: boolean)
                     Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                    Map Join Operator
-                      condition map:
-                           Inner Join 0 to 1
-                      keys:
-                        0 key (type: int), value (type: int)
-                        1 value (type: int), key (type: int)
-                      Map Join Vectorization:
-                          bigTableKeyExpressions: col 0:int, col 1:int
-                          bigTableValueExpressions: col 0:int, col 1:int
-                          className: VectorMapJoinOperator
-                          native: false
-                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
-                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
-                      nullSafes: [true, false]
-                      outputColumnNames: _col0, _col1, _col6, _col7
-                      input vertices:
-                        1 Map 2
-                      Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
+                      Select Vectorization:
+                          className: VectorSelectOperator
+                          native: true
+                          projectedOutputColumnNums: [0, 1]
+                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                       Map Join Operator
                         condition map:
                              Inner Join 0 to 1
                         keys:
-                          0 _col0 (type: int), _col1 (type: int)
-                          1 key (type: int), value (type: int)
+                          0 _col1 (type: int), _col0 (type: int)
+                          1 _col0 (type: int), _col1 (type: int)
                         Map Join Vectorization:
-                            bigTableKeyExpressions: col 0:int, col 1:int
-                            bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                            bigTableKeyExpressions: col 1:int, col 0:int
+                            bigTableValueExpressions: col 0:int, col 1:int
                             className: VectorMapJoinOperator
                             native: false
                             nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                             nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
-                        nullSafes: [true, false]
-                        outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                        nullSafes: [false, true]
+                        outputColumnNames: _col0, _col1, _col2, _col3
                         input vertices:
                           1 Reducer 3
-                        Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
-                        Select Operator
-                          expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                        Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                        Map Join Operator
+                          condition map:
+                               Inner Join 0 to 1
+                          keys:
+                            0 _col1 (type: int), _col0 (type: int)
+                            1 _col1 (type: int), _col0 (type: int)
+                          Map Join Vectorization:
+                              bigTableKeyExpressions: col 1:int, col 0:int
+                              bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                              className: VectorMapJoinOperator
+                              native: false
+                              nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
+                              nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
+                          nullSafes: [false, true]
                           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                          Select Vectorization:
-                              className: VectorSelectOperator
-                              native: true
-                              projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
+                          input vertices:
+                            1 Map 2
                           Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                           File Output Operator
                             compressed: false
@@ -690,16 +731,24 @@ STAGE PLANS:
                         predicateExpression: SelectColumnIsNotNull(col 0:int)
                     predicate: key is not null (type: boolean)
                     Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                    Reduce Output Operator
-                      key expressions: value (type: int), key (type: int)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: value (type: int), key (type: int)
-                      Reduce Sink Vectorization:
-                          className: VectorReduceSinkMultiKeyOperator
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
+                      Select Vectorization:
+                          className: VectorSelectOperator
                           native: true
-                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                          projectedOutputColumnNums: [0, 1]
                       Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int), _col1 (type: int)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                        Reduce Sink Vectorization:
+                            className: VectorReduceSinkMultiKeyOperator
+                            native: true
+                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     Filter Vectorization:
                         className: VectorFilterOperator
@@ -707,16 +756,24 @@ STAGE PLANS:
                         predicateExpression: SelectColumnIsNotNull(col 1:int)
                     predicate: value is not null (type: boolean)
                     Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                    Reduce Output Operator
-                      key expressions: key (type: int), value (type: int)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: key (type: int), value (type: int)
-                      Reduce Sink Vectorization:
-                          className: VectorReduceSinkMultiKeyOperator
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
+                      Select Vectorization:
+                          className: VectorSelectOperator
                           native: true
-                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                          projectedOutputColumnNums: [0, 1]
                       Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
+                      Reduce Output Operator
+                        key expressions: _col1 (type: int), _col0 (type: int)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
+                        Reduce Sink Vectorization:
+                            className: VectorReduceSinkMultiKeyOperator
+                            native: true
+                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -739,16 +796,16 @@ STAGE PLANS:
             Reduce Operator Tree:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: int)
-                outputColumnNames: key, value
+                outputColumnNames: _col0, _col1
                 Select Vectorization:
                     className: VectorSelectOperator
                     native: true
                     projectedOutputColumnNums: [0, 1]
                 Reduce Output Operator
-                  key expressions: key (type: int), value (type: int)
+                  key expressions: _col0 (type: int), _col1 (type: int)
                   null sort order: zz
                   sort order: ++
-                  Map-reduce partition columns: key (type: int), value (type: int)
+                  Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
                   Reduce Sink Vectorization:
                       className: VectorReduceSinkMultiKeyOperator
                       native: true
@@ -803,60 +860,68 @@ STAGE PLANS:
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Map Join Operator
-                    condition map:
-                         Inner Join 0 to 1
-                    keys:
-                      0 key (type: int), value (type: int)
-                      1 value (type: int), key (type: int)
-                    Map Join Vectorization:
-                        bigTableKeyExpressions: col 0:int, col 1:int
-                        bigTableValueExpressions: col 0:int, col 1:int
-                        className: VectorMapJoinOperator
-                        native: false
-                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
-                        nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
-                    nullSafes: [true, true]
-                    outputColumnNames: _col0, _col1, _col6, _col7
-                    input vertices:
-                      1 Reducer 3
-                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
+                        native: true
+                        projectedOutputColumnNums: [0, 1]
+                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                     Map Join Operator
                       condition map:
                            Inner Join 0 to 1
                       keys:
                         0 _col0 (type: int), _col1 (type: int)
-                        1 key (type: int), value (type: int)
+                        1 _col0 (type: int), _col1 (type: int)
                       Map Join Vectorization:
                           bigTableKeyExpressions: col 0:int, col 1:int
-                          bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                          bigTableValueExpressions: col 0:int, col 1:int
                           className: VectorMapJoinOperator
                           native: false
                           nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                           nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
                       nullSafes: [true, true]
-                      outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                      outputColumnNames: _col0, _col1, _col2, _col3
                       input vertices:
                         1 Map 2
-                      Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                      Select Operator
-                        expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                      Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                      Map Join Operator
+                        condition map:
+                             Inner Join 0 to 1
+                        keys:
+                          0 _col0 (type: int), _col1 (type: int)
+                          1 _col1 (type: int), _col0 (type: int)
+                        Map Join Vectorization:
+                            bigTableKeyExpressions: col 0:int, col 1:int
+                            bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                            className: VectorMapJoinOperator
+                            native: false
+                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
+                            nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
+                        nullSafes: [true, true]
                         outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                        Select Vectorization:
-                            className: VectorSelectOperator
-                            native: true
-                            projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
+                        input vertices:
+                          1 Reducer 3
                         Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                        File Output Operator
-                          compressed: false
-                          File Sink Vectorization:
-                              className: VectorFileSinkOperator
-                              native: false
+                        Select Operator
+                          expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
+                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
+                          Select Vectorization:
+                              className: VectorSelectOperator
+                              native: true
+                              projectedOutputColumnNums: [0, 1, 4, 5, 2, 3]
                           Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                          table:
-                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          File Output Operator
+                            compressed: false
+                            File Sink Vectorization:
+                                className: VectorFileSinkOperator
+                                native: false
+                            Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
+                            table:
+                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -871,30 +936,38 @@ STAGE PLANS:
         Map 2 
             Map Operator Tree:
                 TableScan
-                  alias: b
+                  alias: c
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Reduce Output Operator
-                    key expressions: value (type: int), key (type: int)
-                    null sort order: zz
-                    sort order: ++
-                    Map-reduce partition columns: value (type: int), key (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkMultiKeyOperator
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
                         native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                  Reduce Output Operator
-                    key expressions: key (type: int), value (type: int)
-                    null sort order: zz
-                    sort order: ++
-                    Map-reduce partition columns: key (type: int), value (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkMultiKeyOperator
-                        native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        projectedOutputColumnNums: [0, 1]
                     Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int), _col1 (type: int)
+                      null sort order: zz
+                      sort order: ++
+                      Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkMultiKeyOperator
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int), _col0 (type: int)
+                      null sort order: zz
+                      sort order: ++
+                      Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkMultiKeyOperator
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -917,16 +990,16 @@ STAGE PLANS:
             Reduce Operator Tree:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: int)
-                outputColumnNames: value, key
+                outputColumnNames: _col1, _col0
                 Select Vectorization:
                     className: VectorSelectOperator
                     native: true
                     projectedOutputColumnNums: [0, 1]
                 Reduce Output Operator
-                  key expressions: value (type: int), key (type: int)
+                  key expressions: _col1 (type: int), _col0 (type: int)
                   null sort order: zz
                   sort order: ++
-                  Map-reduce partition columns: value (type: int), key (type: int)
+                  Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
                   Reduce Sink Vectorization:
                       className: VectorReduceSinkMultiKeyOperator
                       native: true
@@ -1005,21 +1078,29 @@ STAGE PLANS:
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:key:int, 1:value:int, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
-                  Reduce Output Operator
-                    key expressions: key (type: int)
-                    null sort order: z
-                    sort order: +
-                    output key column names: KEY.reducesinkkey0
-                    output value column names: VALUE._col0
-                    Map-reduce partition columns: key (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkLongOperator
-                        keyColumns: 0:int
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
                         native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                        valueColumns: 1:int
+                        projectedOutputColumnNums: [0, 1]
                     Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: value (type: int)
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int)
+                      null sort order: z
+                      sort order: +
+                      output key column names: KEY.reducesinkkey0
+                      output value column names: VALUE._col0
+                      Map-reduce partition columns: _col0 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkLongOperator
+                          keyColumns: 0:int
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                          valueColumns: 1:int
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -1045,44 +1126,44 @@ STAGE PLANS:
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:key:int, 1:value:int, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
-                  Map Join Operator
-                    condition map:
-                         Right Outer Join 0 to 1
-                    keyContext: [types [int], serde=org.apache.hadoop.hive.serde2.binarysortable.BinarySortableSerDe, hasFilter=false]
-                    outer filter mappings: [null, [0, 0]]
-                    valueContexts: [0:[types [int], serde=org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe, hasFilter=false]]
-                    keyExpressions:
-                      0 [Column[key]]
-                      1 [Column[value]]
-                    keys:
-                      0 key (type: int)
-                      1 value (type: int)
-                    Map Join Vectorization:
-                        bigTableKeyExpressions: col 1:int
-                        bigTableValueExpressions: col 0:int, col 1:int
-                        className: VectorMapJoinOperator
-                        native: false
-                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
-                        nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
-                    nullSafes: [true]
-                    outputColumnNames: _col0, _col1, _col6, _col7
-                    input vertices:
-                      0 Map 1
-                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
-                    Select Operator
-                      expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
+                        native: true
+                        projectedOutputColumnNums: [0, 1]
+                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Map Join Operator
+                      condition map:
+                           Right Outer Join 0 to 1
+                      keyContext: [types [int], serde=org.apache.hadoop.hive.serde2.binarysortable.BinarySortableSerDe, hasFilter=false]
+                      outer filter mappings: [null, [0, 0]]
+                      valueContexts: [0:[types [int], serde=org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe, hasFilter=false]]
+                      keyExpressions:
+                        0 [Column[_col0]]
+                        1 [Column[_col1]]
+                      keys:
+                        0 _col0 (type: int)
+                        1 _col1 (type: int)
+                      Map Join Vectorization:
+                          bigTableKeyExpressions: col 1:int
+                          bigTableValueExpressions: col 0:int, col 1:int
+                          className: VectorMapJoinOperator
+                          native: false
+                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
+                          nativeConditionsNotMet: hive.vectorized.execution.mapjoin.native.enabled IS false, No nullsafe IS false
+                      nullSafes: [true]
                       outputColumnNames: _col0, _col1, _col2, _col3
-                      Select Vectorization:
-                          className: VectorSelectOperator
-                          native: true
-                          projectedOutputColumnNums: [0, 1, 2, 3]
-                      Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                      input vertices:
+                        0 Map 1
+                      Statistics: Num rows: 12 Data size: 176 Basic stats: COMPLETE Column stats: COMPLETE
                       File Output Operator
                         compressed: false
                         File Sink Vectorization:
                             className: VectorFileSinkOperator
                             native: false
-                        Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 12 Data size: 176 Basic stats: COMPLETE Column stats: COMPLETE
                         table:
                             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
@@ -1201,31 +1282,31 @@ STAGE PLANS:
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Map Join Operator
-                    condition map:
-                         Inner Join 0 to 1
-                    keys:
-                      0 key (type: int)
-                      1 value (type: int)
-                    Map Join Vectorization:
-                        bigTableKeyExpressions: col 0:int
-                        bigTableValueExpressions: col 0:int, col 1:int
-                        className: VectorMapJoinOperator
-                        native: false
-                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
-                        nativeConditionsNotMet: No nullsafe IS false
-                    nullSafes: [true]
-                    outputColumnNames: _col0, _col1, _col6, _col7
-                    input vertices:
-                      1 Map 2
-                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
-                    Select Operator
-                      expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
+                        native: true
+                        projectedOutputColumnNums: [0, 1]
+                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Map Join Operator
+                      condition map:
+                           Inner Join 0 to 1
+                      keys:
+                        0 _col0 (type: int)
+                        1 _col1 (type: int)
+                      Map Join Vectorization:
+                          bigTableKeyExpressions: col 0:int
+                          bigTableValueExpressions: col 0:int, col 1:int
+                          className: VectorMapJoinOperator
+                          native: false
+                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
+                          nativeConditionsNotMet: No nullsafe IS false
+                      nullSafes: [true]
                       outputColumnNames: _col0, _col1, _col2, _col3
-                      Select Vectorization:
-                          className: VectorSelectOperator
-                          native: true
-                          projectedOutputColumnNums: [0, 1, 2, 3]
+                      input vertices:
+                        1 Map 2
                       Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                       File Output Operator
                         compressed: false
@@ -1255,17 +1336,25 @@ STAGE PLANS:
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Reduce Output Operator
-                    key expressions: value (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: value (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkLongOperator
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
                         native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        projectedOutputColumnNums: [0, 1]
                     Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: key (type: int)
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col1 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkLongOperator
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col0 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -1333,6 +1422,7 @@ STAGE PLANS:
                 TableScan
                   alias: a
                   filterExpr: key is not null (type: boolean)
+                  probeDecodeDetails: cacheKey:HASH_MAP_MAPJOIN_30_container, bigKeyColName:key, smallTablePos:1, keyRatio:0.5
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
@@ -1343,57 +1433,65 @@ STAGE PLANS:
                         predicateExpression: SelectColumnIsNotNull(col 0:int)
                     predicate: key is not null (type: boolean)
                     Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                    Map Join Operator
-                      condition map:
-                           Inner Join 0 to 1
-                      keys:
-                        0 key (type: int)
-                        1 value (type: int)
-                      Map Join Vectorization:
-                          bigTableKeyExpressions: col 0:int
-                          bigTableValueExpressions: col 0:int, col 1:int
-                          className: VectorMapJoinOperator
-                          native: false
-                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
-                          nativeConditionsNotMet: No nullsafe IS false
-                      nullSafes: [true]
-                      outputColumnNames: _col0, _col1, _col6, _col7
-                      input vertices:
-                        1 Reducer 3
-                      Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
+                      Select Vectorization:
+                          className: VectorSelectOperator
+                          native: true
+                          projectedOutputColumnNums: [0, 1]
+                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                       Map Join Operator
                         condition map:
                              Inner Join 0 to 1
                         keys:
                           0 _col0 (type: int)
-                          1 key (type: int)
+                          1 _col0 (type: int)
                         Map Join Vectorization:
                             className: VectorMapJoinInnerLongOperator
                             native: true
                             nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, No nullsafe IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                             hashTableImplementationType: OPTIMIZED
-                        outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                        outputColumnNames: _col0, _col1, _col2, _col3
                         input vertices:
                           1 Map 2
-                        Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
-                        Select Operator
-                          expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                        Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                        Map Join Operator
+                          condition map:
+                               Inner Join 0 to 1
+                          keys:
+                            0 _col0 (type: int)
+                            1 _col1 (type: int)
+                          Map Join Vectorization:
+                              bigTableKeyExpressions: col 0:int
+                              bigTableValueExpressions: col 0:int, col 1:int, col 0:int, col 3:int
+                              className: VectorMapJoinOperator
+                              native: false
+                              nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
+                              nativeConditionsNotMet: No nullsafe IS false
+                          nullSafes: [true]
                           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                          Select Vectorization:
-                              className: VectorSelectOperator
-                              native: true
-                              projectedOutputColumnNums: [0, 1, 2, 3, 0, 4]
-                          Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
-                          File Output Operator
-                            compressed: false
-                            File Sink Vectorization:
-                                className: VectorFileSinkOperator
-                                native: false
-                            Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
-                            table:
-                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          input vertices:
+                            1 Reducer 3
+                          Statistics: Num rows: 6 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
+                          Select Operator
+                            expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
+                            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
+                            Select Vectorization:
+                                className: VectorSelectOperator
+                                native: true
+                                projectedOutputColumnNums: [0, 1, 4, 5, 2, 3]
+                            Statistics: Num rows: 6 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
+                            File Output Operator
+                              compressed: false
+                              File Sink Vectorization:
+                                  className: VectorFileSinkOperator
+                                  native: false
+                              Statistics: Num rows: 6 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
+                              table:
+                                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -1409,28 +1507,28 @@ STAGE PLANS:
             Map Operator Tree:
                 TableScan
                   alias: b
-                  filterExpr: (value is not null or key is not null) (type: boolean)
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Filter Operator
-                    Filter Vectorization:
-                        className: VectorFilterOperator
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
                         native: true
-                        predicateExpression: SelectColumnIsNotNull(col 1:int)
-                    predicate: value is not null (type: boolean)
-                    Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
+                        projectedOutputColumnNums: [0, 1]
+                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                     Reduce Output Operator
-                      key expressions: value (type: int)
+                      key expressions: _col1 (type: int)
                       null sort order: z
                       sort order: +
-                      Map-reduce partition columns: value (type: int)
+                      Map-reduce partition columns: _col1 (type: int)
                       Reduce Sink Vectorization:
                           className: VectorReduceSinkLongOperator
                           native: true
                           nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                      value expressions: key (type: int)
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col0 (type: int)
                   Filter Operator
                     Filter Vectorization:
                         className: VectorFilterOperator
@@ -1438,17 +1536,25 @@ STAGE PLANS:
                         predicateExpression: SelectColumnIsNotNull(col 0:int)
                     predicate: key is not null (type: boolean)
                     Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                    Reduce Output Operator
-                      key expressions: key (type: int)
-                      null sort order: z
-                      sort order: +
-                      Map-reduce partition columns: key (type: int)
-                      Reduce Sink Vectorization:
-                          className: VectorReduceSinkLongOperator
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
+                      Select Vectorization:
+                          className: VectorSelectOperator
                           native: true
-                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                          projectedOutputColumnNums: [0, 1]
                       Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                      value expressions: value (type: int)
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int)
+                        null sort order: z
+                        sort order: +
+                        Map-reduce partition columns: _col0 (type: int)
+                        Reduce Sink Vectorization:
+                            className: VectorReduceSinkLongOperator
+                            native: true
+                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
+                        value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -1471,22 +1577,22 @@ STAGE PLANS:
             Reduce Operator Tree:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: int)
-                outputColumnNames: value, key
+                outputColumnNames: _col1, _col0
                 Select Vectorization:
                     className: VectorSelectOperator
                     native: true
                     projectedOutputColumnNums: [0, 1]
                 Reduce Output Operator
-                  key expressions: value (type: int)
+                  key expressions: _col1 (type: int)
                   null sort order: z
                   sort order: +
-                  Map-reduce partition columns: value (type: int)
+                  Map-reduce partition columns: _col1 (type: int)
                   Reduce Sink Vectorization:
                       className: VectorReduceSinkLongOperator
                       native: true
                       nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                  Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                  value expressions: key (type: int)
+                  Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                  value expressions: _col0 (type: int)
 
   Stage: Stage-0
     Fetch Operator
@@ -1536,60 +1642,68 @@ STAGE PLANS:
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Map Join Operator
-                    condition map:
-                         Inner Join 0 to 1
-                    keys:
-                      0 key (type: int)
-                      1 value (type: int)
-                    Map Join Vectorization:
-                        bigTableKeyExpressions: col 0:int
-                        bigTableValueExpressions: col 0:int, col 1:int
-                        className: VectorMapJoinOperator
-                        native: false
-                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
-                        nativeConditionsNotMet: No nullsafe IS false
-                    nullSafes: [true]
-                    outputColumnNames: _col0, _col1, _col6, _col7
-                    input vertices:
-                      1 Reducer 3
-                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
+                        native: true
+                        projectedOutputColumnNums: [0, 1]
+                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                     Map Join Operator
                       condition map:
                            Inner Join 0 to 1
                       keys:
                         0 _col0 (type: int)
-                        1 key (type: int)
+                        1 _col0 (type: int)
                       Map Join Vectorization:
                           bigTableKeyExpressions: col 0:int
-                          bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                          bigTableValueExpressions: col 0:int, col 1:int
                           className: VectorMapJoinOperator
                           native: false
                           nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                           nativeConditionsNotMet: No nullsafe IS false
                       nullSafes: [true]
-                      outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                      outputColumnNames: _col0, _col1, _col2, _col3
                       input vertices:
                         1 Map 2
-                      Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                      Select Operator
-                        expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                      Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                      Map Join Operator
+                        condition map:
+                             Inner Join 0 to 1
+                        keys:
+                          0 _col0 (type: int)
+                          1 _col1 (type: int)
+                        Map Join Vectorization:
+                            bigTableKeyExpressions: col 0:int
+                            bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                            className: VectorMapJoinOperator
+                            native: false
+                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
+                            nativeConditionsNotMet: No nullsafe IS false
+                        nullSafes: [true]
                         outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                        Select Vectorization:
-                            className: VectorSelectOperator
-                            native: true
-                            projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
+                        input vertices:
+                          1 Reducer 3
                         Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                        File Output Operator
-                          compressed: false
-                          File Sink Vectorization:
-                              className: VectorFileSinkOperator
-                              native: false
+                        Select Operator
+                          expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
+                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
+                          Select Vectorization:
+                              className: VectorSelectOperator
+                              native: true
+                              projectedOutputColumnNums: [0, 1, 4, 5, 2, 3]
                           Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                          table:
-                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          File Output Operator
+                            compressed: false
+                            File Sink Vectorization:
+                                className: VectorFileSinkOperator
+                                native: false
+                            Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
+                            table:
+                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -1604,32 +1718,40 @@ STAGE PLANS:
         Map 2 
             Map Operator Tree:
                 TableScan
-                  alias: b
+                  alias: c
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Reduce Output Operator
-                    key expressions: value (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: value (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkLongOperator
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
                         native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        projectedOutputColumnNums: [0, 1]
                     Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: key (type: int)
-                  Reduce Output Operator
-                    key expressions: key (type: int)
-                    null sort order: z
-                    sort order: +
-                    Map-reduce partition columns: key (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkLongOperator
-                        native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: value (type: int)
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col0 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkLongOperator
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col1 (type: int)
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int)
+                      null sort order: z
+                      sort order: +
+                      Map-reduce partition columns: _col1 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkLongOperator
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col0 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -1652,22 +1774,22 @@ STAGE PLANS:
             Reduce Operator Tree:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: int)
-                outputColumnNames: value, key
+                outputColumnNames: _col1, _col0
                 Select Vectorization:
                     className: VectorSelectOperator
                     native: true
                     projectedOutputColumnNums: [0, 1]
                 Reduce Output Operator
-                  key expressions: value (type: int)
+                  key expressions: _col1 (type: int)
                   null sort order: z
                   sort order: +
-                  Map-reduce partition columns: value (type: int)
+                  Map-reduce partition columns: _col1 (type: int)
                   Reduce Sink Vectorization:
                       className: VectorReduceSinkLongOperator
                       native: true
                       nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                  value expressions: key (type: int)
+                  value expressions: _col0 (type: int)
 
   Stage: Stage-0
     Fetch Operator
@@ -1752,49 +1874,49 @@ STAGE PLANS:
                         predicateExpression: SelectColumnIsNotNull(col 1:int)
                     predicate: value is not null (type: boolean)
                     Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                    Map Join Operator
-                      condition map:
-                           Inner Join 0 to 1
-                      keys:
-                        0 key (type: int), value (type: int)
-                        1 value (type: int), key (type: int)
-                      Map Join Vectorization:
-                          bigTableKeyExpressions: col 0:int, col 1:int
-                          bigTableValueExpressions: col 0:int, col 1:int
-                          className: VectorMapJoinOperator
-                          native: false
-                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
-                          nativeConditionsNotMet: No nullsafe IS false
-                      nullSafes: [true, false]
-                      outputColumnNames: _col0, _col1, _col6, _col7
-                      input vertices:
-                        1 Map 2
-                      Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
+                      Select Vectorization:
+                          className: VectorSelectOperator
+                          native: true
+                          projectedOutputColumnNums: [0, 1]
+                      Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                       Map Join Operator
                         condition map:
                              Inner Join 0 to 1
                         keys:
-                          0 _col0 (type: int), _col1 (type: int)
-                          1 key (type: int), value (type: int)
+                          0 _col1 (type: int), _col0 (type: int)
+                          1 _col0 (type: int), _col1 (type: int)
                         Map Join Vectorization:
-                            bigTableKeyExpressions: col 0:int, col 1:int
-                            bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                            bigTableKeyExpressions: col 1:int, col 0:int
+                            bigTableValueExpressions: col 0:int, col 1:int
                             className: VectorMapJoinOperator
                             native: false
                             nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                             nativeConditionsNotMet: No nullsafe IS false
-                        nullSafes: [true, false]
-                        outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                        nullSafes: [false, true]
+                        outputColumnNames: _col0, _col1, _col2, _col3
                         input vertices:
                           1 Reducer 3
-                        Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
-                        Select Operator
-                          expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                        Statistics: Num rows: 3 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                        Map Join Operator
+                          condition map:
+                               Inner Join 0 to 1
+                          keys:
+                            0 _col1 (type: int), _col0 (type: int)
+                            1 _col1 (type: int), _col0 (type: int)
+                          Map Join Vectorization:
+                              bigTableKeyExpressions: col 1:int, col 0:int
+                              bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                              className: VectorMapJoinOperator
+                              native: false
+                              nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
+                              nativeConditionsNotMet: No nullsafe IS false
+                          nullSafes: [false, true]
                           outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                          Select Vectorization:
-                              className: VectorSelectOperator
-                              native: true
-                              projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
+                          input vertices:
+                            1 Map 2
                           Statistics: Num rows: 3 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
                           File Output Operator
                             compressed: false
@@ -1832,16 +1954,24 @@ STAGE PLANS:
                         predicateExpression: SelectColumnIsNotNull(col 0:int)
                     predicate: key is not null (type: boolean)
                     Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                    Reduce Output Operator
-                      key expressions: value (type: int), key (type: int)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: value (type: int), key (type: int)
-                      Reduce Sink Vectorization:
-                          className: VectorReduceSinkMultiKeyOperator
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
+                      Select Vectorization:
+                          className: VectorSelectOperator
                           native: true
-                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                          projectedOutputColumnNums: [0, 1]
                       Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
+                      Reduce Output Operator
+                        key expressions: _col0 (type: int), _col1 (type: int)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                        Reduce Sink Vectorization:
+                            className: VectorReduceSinkMultiKeyOperator
+                            native: true
+                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                   Filter Operator
                     Filter Vectorization:
                         className: VectorFilterOperator
@@ -1849,16 +1979,24 @@ STAGE PLANS:
                         predicateExpression: SelectColumnIsNotNull(col 1:int)
                     predicate: value is not null (type: boolean)
                     Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
-                    Reduce Output Operator
-                      key expressions: key (type: int), value (type: int)
-                      null sort order: zz
-                      sort order: ++
-                      Map-reduce partition columns: key (type: int), value (type: int)
-                      Reduce Sink Vectorization:
-                          className: VectorReduceSinkMultiKeyOperator
+                    Select Operator
+                      expressions: key (type: int), value (type: int)
+                      outputColumnNames: _col0, _col1
+                      Select Vectorization:
+                          className: VectorSelectOperator
                           native: true
-                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                          projectedOutputColumnNums: [0, 1]
                       Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
+                      Reduce Output Operator
+                        key expressions: _col1 (type: int), _col0 (type: int)
+                        null sort order: zz
+                        sort order: ++
+                        Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
+                        Reduce Sink Vectorization:
+                            className: VectorReduceSinkMultiKeyOperator
+                            native: true
+                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        Statistics: Num rows: 3 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -1881,16 +2019,16 @@ STAGE PLANS:
             Reduce Operator Tree:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: int)
-                outputColumnNames: key, value
+                outputColumnNames: _col0, _col1
                 Select Vectorization:
                     className: VectorSelectOperator
                     native: true
                     projectedOutputColumnNums: [0, 1]
                 Reduce Output Operator
-                  key expressions: key (type: int), value (type: int)
+                  key expressions: _col0 (type: int), _col1 (type: int)
                   null sort order: zz
                   sort order: ++
-                  Map-reduce partition columns: key (type: int), value (type: int)
+                  Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
                   Reduce Sink Vectorization:
                       className: VectorReduceSinkMultiKeyOperator
                       native: true
@@ -1945,60 +2083,68 @@ STAGE PLANS:
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Map Join Operator
-                    condition map:
-                         Inner Join 0 to 1
-                    keys:
-                      0 key (type: int), value (type: int)
-                      1 value (type: int), key (type: int)
-                    Map Join Vectorization:
-                        bigTableKeyExpressions: col 0:int, col 1:int
-                        bigTableValueExpressions: col 0:int, col 1:int
-                        className: VectorMapJoinOperator
-                        native: false
-                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
-                        nativeConditionsNotMet: No nullsafe IS false
-                    nullSafes: [true, true]
-                    outputColumnNames: _col0, _col1, _col6, _col7
-                    input vertices:
-                      1 Reducer 3
-                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
+                        native: true
+                        projectedOutputColumnNums: [0, 1]
+                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                     Map Join Operator
                       condition map:
                            Inner Join 0 to 1
                       keys:
                         0 _col0 (type: int), _col1 (type: int)
-                        1 key (type: int), value (type: int)
+                        1 _col0 (type: int), _col1 (type: int)
                       Map Join Vectorization:
                           bigTableKeyExpressions: col 0:int, col 1:int
-                          bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                          bigTableValueExpressions: col 0:int, col 1:int
                           className: VectorMapJoinOperator
                           native: false
                           nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
                           nativeConditionsNotMet: No nullsafe IS false
                       nullSafes: [true, true]
-                      outputColumnNames: _col0, _col1, _col6, _col7, _col12, _col13
+                      outputColumnNames: _col0, _col1, _col2, _col3
                       input vertices:
                         1 Map 2
-                      Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                      Select Operator
-                        expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int), _col12 (type: int), _col13 (type: int)
+                      Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                      Map Join Operator
+                        condition map:
+                             Inner Join 0 to 1
+                        keys:
+                          0 _col0 (type: int), _col1 (type: int)
+                          1 _col1 (type: int), _col0 (type: int)
+                        Map Join Vectorization:
+                            bigTableKeyExpressions: col 0:int, col 1:int
+                            bigTableValueExpressions: col 0:int, col 1:int, col 2:int, col 3:int
+                            className: VectorMapJoinOperator
+                            native: false
+                            nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Optimized Table and Supports Key Types IS true
+                            nativeConditionsNotMet: No nullsafe IS false
+                        nullSafes: [true, true]
                         outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
-                        Select Vectorization:
-                            className: VectorSelectOperator
-                            native: true
-                            projectedOutputColumnNums: [0, 1, 2, 3, 4, 5]
+                        input vertices:
+                          1 Reducer 3
                         Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                        File Output Operator
-                          compressed: false
-                          File Sink Vectorization:
-                              className: VectorFileSinkOperator
-                              native: false
+                        Select Operator
+                          expressions: _col0 (type: int), _col1 (type: int), _col4 (type: int), _col5 (type: int), _col2 (type: int), _col3 (type: int)
+                          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
+                          Select Vectorization:
+                              className: VectorSelectOperator
+                              native: true
+                              projectedOutputColumnNums: [0, 1, 4, 5, 2, 3]
                           Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
-                          table:
-                              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
-                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          File Output Operator
+                            compressed: false
+                            File Sink Vectorization:
+                                className: VectorFileSinkOperator
+                                native: false
+                            Statistics: Num rows: 24 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
+                            table:
+                                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -2013,30 +2159,38 @@ STAGE PLANS:
         Map 2 
             Map Operator Tree:
                 TableScan
-                  alias: b
+                  alias: c
                   Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                   TableScan Vectorization:
                       native: true
-                  Reduce Output Operator
-                    key expressions: value (type: int), key (type: int)
-                    null sort order: zz
-                    sort order: ++
-                    Map-reduce partition columns: value (type: int), key (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkMultiKeyOperator
-                        native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                  Reduce Output Operator
-                    key expressions: key (type: int), value (type: int)
-                    null sort order: zz
-                    sort order: ++
-                    Map-reduce partition columns: key (type: int), value (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkMultiKeyOperator
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
                         native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                        projectedOutputColumnNums: [0, 1]
                     Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int), _col1 (type: int)
+                      null sort order: zz
+                      sort order: ++
+                      Map-reduce partition columns: _col0 (type: int), _col1 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkMultiKeyOperator
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Reduce Output Operator
+                      key expressions: _col1 (type: int), _col0 (type: int)
+                      null sort order: zz
+                      sort order: ++
+                      Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkMultiKeyOperator
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -2059,16 +2213,16 @@ STAGE PLANS:
             Reduce Operator Tree:
               Select Operator
                 expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: int)
-                outputColumnNames: value, key
+                outputColumnNames: _col1, _col0
                 Select Vectorization:
                     className: VectorSelectOperator
                     native: true
                     projectedOutputColumnNums: [0, 1]
                 Reduce Output Operator
-                  key expressions: value (type: int), key (type: int)
+                  key expressions: _col1 (type: int), _col0 (type: int)
                   null sort order: zz
                   sort order: ++
-                  Map-reduce partition columns: value (type: int), key (type: int)
+                  Map-reduce partition columns: _col1 (type: int), _col0 (type: int)
                   Reduce Sink Vectorization:
                       className: VectorReduceSinkMultiKeyOperator
                       native: true
@@ -2147,21 +2301,29 @@ STAGE PLANS:
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:key:int, 1:value:int, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
-                  Reduce Output Operator
-                    key expressions: key (type: int)
-                    null sort order: z
-                    sort order: +
-                    output key column names: KEY.reducesinkkey0
-                    output value column names: VALUE._col0
-                    Map-reduce partition columns: key (type: int)
-                    Reduce Sink Vectorization:
-                        className: VectorReduceSinkLongOperator
-                        keyColumns: 0:int
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
                         native: true
-                        nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
-                        valueColumns: 1:int
+                        projectedOutputColumnNums: [0, 1]
                     Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: value (type: int)
+                    Reduce Output Operator
+                      key expressions: _col0 (type: int)
+                      null sort order: z
+                      sort order: +
+                      output key column names: KEY.reducesinkkey0
+                      output value column names: VALUE._col0
+                      Map-reduce partition columns: _col0 (type: int)
+                      Reduce Sink Vectorization:
+                          className: VectorReduceSinkLongOperator
+                          keyColumns: 0:int
+                          native: true
+                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
+                          valueColumns: 1:int
+                      Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                      value expressions: _col1 (type: int)
             Execution mode: vectorized, llap
             LLAP IO: all inputs
             Map Vectorization:
@@ -2187,44 +2349,44 @@ STAGE PLANS:
                   TableScan Vectorization:
                       native: true
                       vectorizationSchemaColumns: [0:key:int, 1:value:int, 2:ROW__ID:struct<writeid:bigint,bucketid:int,rowid:bigint>]
-                  Map Join Operator
-                    condition map:
-                         Right Outer Join 0 to 1
-                    keyContext: [types [int], serde=org.apache.hadoop.hive.serde2.binarysortable.BinarySortableSerDe, hasFilter=false]
-                    outer filter mappings: [null, [0, 0]]
-                    valueContexts: [0:[types [int], serde=org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe, hasFilter=false]]
-                    keyExpressions:
-                      0 [Column[key]]
-                      1 [Column[value]]
-                    keys:
-                      0 key (type: int)
-                      1 value (type: int)
-                    Map Join Vectorization:
-                        bigTableKeyExpressions: col 1:int
-                        bigTableValueExpressions: col 0:int, col 1:int
-                        className: VectorMapJoinOperator
-                        native: false
-                        nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
-                        nativeConditionsNotMet: No nullsafe IS false
-                    nullSafes: [true]
-                    outputColumnNames: _col0, _col1, _col6, _col7
-                    input vertices:
-                      0 Map 1
-                    Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
-                    Select Operator
-                      expressions: _col0 (type: int), _col1 (type: int), _col6 (type: int), _col7 (type: int)
+                  Select Operator
+                    expressions: key (type: int), value (type: int)
+                    outputColumnNames: _col0, _col1
+                    Select Vectorization:
+                        className: VectorSelectOperator
+                        native: true
+                        projectedOutputColumnNums: [0, 1]
+                    Statistics: Num rows: 6 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
+                    Map Join Operator
+                      condition map:
+                           Right Outer Join 0 to 1
+                      keyContext: [types [int], serde=org.apache.hadoop.hive.serde2.binarysortable.BinarySortableSerDe, hasFilter=false]
+                      outer filter mappings: [null, [0, 0]]
+                      valueContexts: [0:[types [int], serde=org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe, hasFilter=false]]
+                      keyExpressions:
+                        0 [Column[_col0]]
+                        1 [Column[_col1]]
+                      keys:
+                        0 _col0 (type: int)
+                        1 _col1 (type: int)
+                      Map Join Vectorization:
+                          bigTableKeyExpressions: col 1:int
+                          bigTableValueExpressions: col 0:int, col 1:int
+                          className: VectorMapJoinOperator
+                          native: false
+                          nativeConditionsMet: hive.mapjoin.optimized.hashtable IS true, hive.vectorized.execution.mapjoin.native.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, One MapJoin Condition IS true, Small table vectorizes IS true, Outer Join has keys IS true, Optimized Table and Supports Key Types IS true
+                          nativeConditionsNotMet: No nullsafe IS false
+                      nullSafes: [true]
                       outputColumnNames: _col0, _col1, _col2, _col3
-                      Select Vectorization:
-                          className: VectorSelectOperator
-                          native: true
-                          projectedOutputColumnNums: [0, 1, 2, 3]
-                      Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                      input vertices:
+                        0 Map 1
+                      Statistics: Num rows: 12 Data size: 176 Basic stats: COMPLETE Column stats: COMPLETE
                       File Output Operator
                         compressed: false
                         File Sink Vectorization:
                             className: VectorFileSinkOperator
                             native: false
-                        Statistics: Num rows: 12 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
+                        Statistics: Num rows: 12 Data size: 176 Basic stats: COMPLETE Column stats: COMPLETE
                         table:
                             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
