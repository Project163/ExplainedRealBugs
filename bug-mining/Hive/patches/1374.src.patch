diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/parser/ExpressionTree.java b/metastore/src/java/org/apache/hadoop/hive/metastore/parser/ExpressionTree.java
index 6cce03759e..1609ce12f6 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/parser/ExpressionTree.java
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/parser/ExpressionTree.java
@@ -17,9 +17,7 @@
  */
 package org.apache.hadoop.hive.metastore.parser;
 
-import java.util.ArrayList;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.Stack;
@@ -28,9 +26,9 @@
 import org.antlr.runtime.CharStream;
 import org.apache.hadoop.hive.common.FileUtils;
 import org.apache.hadoop.hive.metastore.Warehouse;
-import org.apache.hadoop.hive.metastore.api.hive_metastoreConstants;
 import org.apache.hadoop.hive.metastore.api.MetaException;
 import org.apache.hadoop.hive.metastore.api.Table;
+import org.apache.hadoop.hive.metastore.api.hive_metastoreConstants;
 
 import com.google.common.collect.Sets;
 
@@ -158,6 +156,7 @@ public String generateJDOFilter(Table table, Map<String, Object> params)
   public static class LeafNode extends TreeNode {
     public String keyName;
     public Operator operator;
+    /** Constant expression side of the operator. Can currently be a String or a Long. */
     public Object value;
     public boolean isReverseOrder = false;
     private static final String PARAM_PREFIX = "hive_filter_param_";
@@ -196,7 +195,7 @@ private String generateJDOFilterOverTables(Map<String, Object> params)
         String paramKeyName = keyName.substring(hive_metastoreConstants.HIVE_FILTER_FIELD_PARAMS.length());
         keyName = "this.parameters.get(\"" + paramKeyName + "\")";
         //value is persisted as a string in the db, so make sure it's a string here
-        // in case we get an integer.
+        // in case we get a long.
         value = value.toString();
       } else {
         throw new MetaException("Invalid key name in filter.  " +
@@ -210,8 +209,8 @@ private String generateJDOFilterOverTables(Map<String, Object> params)
      * generates a statement of the form:
      * key1 operator value2 (&& | || ) key2 operator value2 ...
      *
-     * Currently supported types for value are String and Integer.
-     * The LIKE operator for Integers is unsupported.
+     * Currently supported types for value are String and Long.
+     * The LIKE operator for Longs is unsupported.
      */
     private String generateJDOFilterGeneral(Map<String, Object> params)
         throws MetaException {
@@ -257,23 +256,37 @@ private String generateJDOFilterOverPartitions(Table table, Map<String, Object>
             "> is not a partitioning key for the table");
       }
 
-      //Can only support partitions whose types are string
-      if( ! table.getPartitionKeys().get(partitionColumnIndex).
-          getType().equals(org.apache.hadoop.hive.serde.serdeConstants.STRING_TYPE_NAME) ) {
-        throw new MetaException
-        ("Filtering is supported only on partition keys of type string");
+      String keyType = table.getPartitionKeys().get(partitionColumnIndex).getType();
+      boolean isIntegralSupported = doesOperatorSupportIntegral(operator);
+
+      // Can only support partitions whose types are string, or maybe integers
+      if (!keyType.equals(org.apache.hadoop.hive.serde.serdeConstants.STRING_TYPE_NAME)
+          && (!isIntegralSupported || !isIntegralType(keyType))) {
+        throw new MetaException("Filtering is supported only on partition keys of type " +
+            "string" + (isIntegralSupported ? ", or integral types" : ""));
+      }
+
+      boolean isStringValue = value instanceof String;
+      if (!isStringValue && (!isIntegralSupported || !(value instanceof Long))) {
+        throw new MetaException("Filtering is supported only on partition keys of type " +
+            "string" + (isIntegralSupported ? ", or integral types" : ""));
       }
 
-      String valueParam = null;
+      String valueAsString = null;
       try {
-        valueParam = (String) value;
+        valueAsString = isStringValue ? (String) value : Long.toString((Long) value);
       } catch (ClassCastException e) {
-        throw new MetaException("Filtering is supported only on partition keys of type string");
+        throw new MetaException("Unable to cast the constexpr to "
+            + (isStringValue ? "string" : "long"));
       }
 
       String paramName = PARAM_PREFIX + params.size();
-      params.put(paramName, valueParam);
-      String filter;
+      params.put(paramName, valueAsString);
+      boolean isOpEquals = operator == Operator.EQUALS;
+      if (isOpEquals || operator == Operator.NOTEQUALS || operator == Operator.NOTEQUALS2) {
+        return makeFilterForEquals(keyName, valueAsString, paramName, params,
+            partitionColumnIndex, partitionColumnCount, isOpEquals);
+      }
 
       String keyEqual = FileUtils.escapePathName(keyName) + "=";
       int keyEqualLength = keyEqual.length();
@@ -286,43 +299,52 @@ private String generateJDOFilterOverPartitions(Table table, Map<String, Object>
         valString = "partitionName.substring(partitionName.indexOf(\"" + keyEqual + "\")+" + keyEqualLength + ").substring(0, partitionName.substring(partitionName.indexOf(\"" + keyEqual + "\")+" + keyEqualLength + ").indexOf(\"/\"))";
       }
 
-      //Handle "a > 10" and "10 > a" appropriately
-      if (isReverseOrder){
-        //For LIKE, the value should be on the RHS
-        if( operator == Operator.LIKE ) {
+      if (operator == Operator.LIKE) {
+        if (isReverseOrder) {
+          //For LIKE, the value should be on the RHS
           throw new MetaException(
-              "Value should be on the RHS for LIKE operator : " +
-              "Key <" + keyName + ">");
-        } else if (operator == Operator.EQUALS) {
-          filter = makeFilterForEquals(keyName, valueParam, paramName, params,
-              partitionColumnIndex, partitionColumnCount);
-        } else {
-          filter = paramName +
-          " " + operator.getJdoOp() + " " + valString;
-        }
-      } else {
-        if (operator == Operator.LIKE ) {
-          //generate this.values.get(i).matches("abc%")
-          filter = " " + valString + "."
-              + operator.getJdoOp() + "(" + paramName + ") ";
-        } else if (operator == Operator.EQUALS) {
-          filter = makeFilterForEquals(keyName, valueParam, paramName, params,
-              partitionColumnIndex, partitionColumnCount);
-        } else {
-          filter = " " + valString + " "
-              + operator.getJdoOp() + " " + paramName;
+              "Value should be on the RHS for LIKE operator : Key <" + keyName + ">");
         }
+        //generate this.values.get(i).matches("abc%")
+        return " " + valString + "." + operator.getJdoOp() + "(" + paramName + ") ";
       }
-      return filter;
+
+      // TODO: support for other ops for numbers to be handled in HIVE-4888.
+      return isReverseOrder
+          ? paramName + " " + operator.getJdoOp() + " " + valString
+          : " " + valString + " " + operator.getJdoOp() + " " + paramName;
+    }
+
+    /**
+     * @param operator operator
+     * @return true iff filter pushdown for this operator can be done for integral types.
+     */
+    private static boolean doesOperatorSupportIntegral(Operator operator) {
+      return (operator == Operator.EQUALS)
+          || (operator == Operator.NOTEQUALS)
+          || (operator == Operator.NOTEQUALS2);
+    }
+
+    /**
+     * @param type type
+     * @return true iff type is an integral type.
+     */
+    private static boolean isIntegralType(String type) {
+      return type.equals(org.apache.hadoop.hive.serde.serdeConstants.TINYINT_TYPE_NAME)
+          || type.equals(org.apache.hadoop.hive.serde.serdeConstants.SMALLINT_TYPE_NAME)
+          || type.equals(org.apache.hadoop.hive.serde.serdeConstants.INT_TYPE_NAME)
+          || type.equals(org.apache.hadoop.hive.serde.serdeConstants.BIGINT_TYPE_NAME);
     }
   }
 
   /**
-   * For equals, we can make the JDO query much faster by filtering based on the
-   * partition name. For a condition like ds="2010-10-01", we can see if there
-   * are any partitions with a name that contains the substring "ds=2010-10-01/"
+   * For equals and not-equals, we can make the JDO query much faster by filtering
+   * based on the partition name. For a condition like ds="2010-10-01", we can see
+   * if there are any partitions with a name that contains the substring "ds=2010-10-01/"
    * False matches aren't possible since "=" is escaped for partition names
    * and the trailing '/' ensures that we won't get a match with ds=2010-10-011
+   * Note that filters on integral type equality also work correctly by virtue of
+   * comparing them as part of ds=1234 string.
    *
    * Two cases to keep in mind: Case with only one partition column (no '/'s)
    * Case where the partition key column is at the end of the name. (no
@@ -332,11 +354,12 @@ private String generateJDOFilterOverPartitions(Table table, Map<String, Object>
    * @param value
    * @param paramName name of the parameter to use for JDOQL
    * @param params a map from the parameter name to their values
+   * @param isEq whether the operator is equals, or not-equals.
    * @return
    * @throws MetaException
    */
-  private static String makeFilterForEquals(String keyName, String value,
-      String paramName, Map<String, Object> params, int keyPos, int keyCount)
+  private static String makeFilterForEquals(String keyName, String value, String paramName,
+      Map<String, Object> params, int keyPos, int keyCount, boolean isEq)
       throws MetaException {
     Map<String, String> partKeyToVal = new HashMap<String, String>();
     partKeyToVal.put(keyName, value);
@@ -348,22 +371,25 @@ private static String makeFilterForEquals(String keyName, String value,
     if (keyCount == 1) {
       // Case where this is no other partition columns
       params.put(paramName, escapedNameFragment);
-      fltr.append("partitionName == ").append(paramName);
+      fltr.append("partitionName ").append(isEq ? "== " : "!= ").append(paramName);
     } else if (keyPos + 1 == keyCount) {
       // Case where the partition column is at the end of the name. There will
       // be a leading '/' but no trailing '/'
       params.put(paramName, "/" + escapedNameFragment);
-      fltr.append("partitionName.endsWith(").append(paramName).append(')');
+      fltr.append(isEq ? "" : "!").append("partitionName.endsWith(")
+        .append(paramName).append(')');
     } else if (keyPos == 0) {
       // Case where the parttion column is at the beginning of the name. There will
       // be a trailing '/' but no leading '/'
       params.put(paramName, escapedNameFragment + "/");
-      fltr.append("partitionName.startsWith(").append(paramName).append(')');
+      fltr.append(isEq ? "" : "!").append("partitionName.startsWith(")
+        .append(paramName).append(')');
     } else {
       // Case where the partition column is in the middle of the name. There will
       // be a leading '/' and an trailing '/'
       params.put(paramName, "/" + escapedNameFragment + "/");
-      fltr.append("partitionName.indexOf(").append(paramName).append(") >= 0");
+      fltr.append("partitionName.indexOf(").append(paramName).append(")")
+        .append(isEq ? ">= 0" : "< 0");
     }
     return fltr.toString();
   }
diff --git a/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g b/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g
index eae2cd623d..425d800a7d 100644
--- a/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g
+++ b/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g
@@ -100,10 +100,10 @@ operatorExpression
        ) { val = TrimQuotes(value.getText()); }
        |
        (
-	       (key = Identifier op = operator value = IntLiteral)
+	       (key = Identifier op = operator value = IntegralLiteral)
 	       |
-	       (value = IntLiteral op = operator key = Identifier) { isReverseOrder = true; }
-       ) { val = Integer.parseInt(value.getText()); }
+	       (value = IntegralLiteral op = operator key = Identifier) { isReverseOrder = true; }
+       ) { val = Long.parseLong(value.getText()); }
     )
     {
         LeafNode node = new LeafNode();
@@ -157,9 +157,9 @@ StringLiteral
     ;
 
 
-IntLiteral
+IntegralLiteral
     :
-    (Digit)+
+    ('-')? (Digit)+
     ;
 
 Identifier
diff --git a/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java b/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
index 00eb0b4fec..09deecfcd2 100644
--- a/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
+++ b/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
@@ -64,6 +64,8 @@
 import org.apache.hadoop.util.StringUtils;
 import org.apache.thrift.TException;
 
+import com.google.common.collect.Lists;
+
 public abstract class TestHiveMetaStore extends TestCase {
   protected static HiveMetaStoreClient client;
   protected static HiveConf hiveConf;
@@ -1919,31 +1921,6 @@ public void testPartitionFilter() throws Exception {
     String dbName = "filterdb";
     String tblName = "filtertbl";
 
-    List<String> vals = new ArrayList<String>(3);
-    vals.add("p11");
-    vals.add("p21");
-    vals.add("p31");
-    List <String> vals2 = new ArrayList<String>(3);
-    vals2.add("p11");
-    vals2.add("p22");
-    vals2.add("p31");
-    List <String> vals3 = new ArrayList<String>(3);
-    vals3.add("p12");
-    vals3.add("p21");
-    vals3.add("p31");
-    List <String> vals4 = new ArrayList<String>(3);
-    vals4.add("p12");
-    vals4.add("p23");
-    vals4.add("p31");
-    List <String> vals5 = new ArrayList<String>(3);
-    vals5.add("p13");
-    vals5.add("p24");
-    vals5.add("p31");
-    List <String> vals6 = new ArrayList<String>(3);
-    vals6.add("p13");
-    vals6.add("p25");
-    vals6.add("p31");
-
     silentDropDatabase(dbName);
 
     Database db = new Database();
@@ -1981,21 +1958,49 @@ public void testPartitionFilter() throws Exception {
 
     tbl = client.getTable(dbName, tblName);
 
-    add_partition(client, tbl, vals, "part1");
-    add_partition(client, tbl, vals2, "part2");
-    add_partition(client, tbl, vals3, "part3");
-    add_partition(client, tbl, vals4, "part4");
-    add_partition(client, tbl, vals5, "part5");
-    add_partition(client, tbl, vals6, "part6");
+    add_partition(client, tbl, Lists.newArrayList("p11", "p21", "31"), "part1");
+    add_partition(client, tbl, Lists.newArrayList("p11", "p22", "32"), "part2");
+    add_partition(client, tbl, Lists.newArrayList("p12", "p21", "31"), "part3");
+    add_partition(client, tbl, Lists.newArrayList("p12", "p23", "32"), "part4");
+    add_partition(client, tbl, Lists.newArrayList("p13", "p24", "31"), "part5");
+    add_partition(client, tbl, Lists.newArrayList("p13", "p25", "-33"), "part6");
 
+    // Test equals operator for strings and integers.
     checkFilter(client, dbName, tblName, "p1 = \"p11\"", 2);
     checkFilter(client, dbName, tblName, "p1 = \"p12\"", 2);
     checkFilter(client, dbName, tblName, "p2 = \"p21\"", 2);
     checkFilter(client, dbName, tblName, "p2 = \"p23\"", 1);
+    checkFilter(client, dbName, tblName, "p3 = 31", 3);
+    checkFilter(client, dbName, tblName, "p3 = 33", 0);
+    checkFilter(client, dbName, tblName, "p3 = -33", 1);
     checkFilter(client, dbName, tblName, "p1 = \"p11\" and p2=\"p22\"", 1);
     checkFilter(client, dbName, tblName, "p1 = \"p11\" or p2=\"p23\"", 3);
     checkFilter(client, dbName, tblName, "p1 = \"p11\" or p1=\"p12\"", 4);
-
+    checkFilter(client, dbName, tblName, "p1 = \"p11\" or p1=\"p12\"", 4);
+    checkFilter(client, dbName, tblName, "p1 = \"p11\" or p1=\"p12\"", 4);
+    checkFilter(client, dbName, tblName, "p1 = \"p11\" and p3 = 31", 1);
+    checkFilter(client, dbName, tblName, "p3 = -33 or p1 = \"p12\"", 3);
+
+    // Test not-equals operator for strings and integers.
+    checkFilter(client, dbName, tblName, "p1 != \"p11\"", 4);
+    checkFilter(client, dbName, tblName, "p2 != \"p23\"", 5);
+    checkFilter(client, dbName, tblName, "p2 != \"p33\"", 6);
+    checkFilter(client, dbName, tblName, "p3 != 32", 4);
+    checkFilter(client, dbName, tblName, "p3 != 8589934592", 6);
+    checkFilter(client, dbName, tblName, "p1 != \"p11\" and p1 != \"p12\"", 2);
+    checkFilter(client, dbName, tblName, "p1 != \"p11\" and p2 != \"p22\"", 4);
+    checkFilter(client, dbName, tblName, "p1 != \"p11\" or p2 != \"p22\"", 5);
+    checkFilter(client, dbName, tblName, "p1 != \"p12\" and p2 != \"p25\"", 3);
+    checkFilter(client, dbName, tblName, "p1 != \"p12\" or p2 != \"p25\"", 6);
+    checkFilter(client, dbName, tblName, "p3 != -33 or p1 != \"p13\"", 5);
+    checkFilter(client, dbName, tblName, "p1 != \"p11\" and p3 = 31", 2);
+    checkFilter(client, dbName, tblName, "p3 != 31 and p1 = \"p12\"", 1);
+
+    // Test reverse order.
+    checkFilter(client, dbName, tblName, "31 != p3 and p1 = \"p12\"", 1);
+    checkFilter(client, dbName, tblName, "\"p23\" = p2", 1);
+
+    // Test and/or more...
     checkFilter(client, dbName, tblName,
         "p1 = \"p11\" or (p1=\"p12\" and p2=\"p21\")", 3);
     checkFilter(client, dbName, tblName,
@@ -2007,11 +2012,11 @@ public void testPartitionFilter() throws Exception {
     checkFilter(client, dbName, tblName,
        "p1=\"p12\" and p2=\"p27\" Or p2=\"p21\"", 2);
 
+    // Test gt/lt/lte/gte/like for strings.
     checkFilter(client, dbName, tblName, "p1 > \"p12\"", 2);
     checkFilter(client, dbName, tblName, "p1 >= \"p12\"", 4);
     checkFilter(client, dbName, tblName, "p1 < \"p12\"", 2);
     checkFilter(client, dbName, tblName, "p1 <= \"p12\"", 4);
-    checkFilter(client, dbName, tblName, "p1 <> \"p12\"", 4);
     checkFilter(client, dbName, tblName, "p1 like \"p1.*\"", 6);
     checkFilter(client, dbName, tblName, "p2 like \"p.*3\"", 1);
 
@@ -2033,6 +2038,17 @@ public void testPartitionFilter() throws Exception {
     assertTrue("Filter on int partition key", me.getMessage().contains(
           "Filtering is supported only on partition keys of type string"));
 
+    try {
+      client.listPartitionsByFilter(dbName,
+          tblName, "p3 >= 31", (short) -1);
+    } catch(MetaException e) {
+      me = e;
+    }
+    assertNotNull(me);
+    assertTrue("Filter on int partition key", me.getMessage().contains(
+          "Filtering is supported only on partition keys of type string"));
+
+
     me = null;
     try {
       client.listPartitionsByFilter(dbName,
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
index bfa74e5f66..4423645d27 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
@@ -136,8 +136,10 @@
 import org.apache.hadoop.hive.ql.stats.StatsFactory;
 import org.apache.hadoop.hive.ql.stats.StatsPublisher;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDF;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFBaseCompare;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPAnd;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqual;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNotEqual;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr;
 import org.apache.hadoop.hive.serde.serdeConstants;
 import org.apache.hadoop.hive.serde2.SerDeException;
@@ -2154,16 +2156,44 @@ public static double showTime(long time) {
 
   /**
    * Check if a function can be pushed down to JDO.
-   * Now only {=, AND, OR} are supported.
+   * Now only {compares, AND, OR} are supported.
    * @param func a generic function.
    * @return true if this function can be pushed down to JDO filter.
    */
   private static boolean supportedJDOFuncs(GenericUDF func) {
+    // TODO: we might also want to add "not" and "between" here in future.
+    // TODO: change to GenericUDFBaseCompare once DN is upgraded
+    //       (see HIVE-2609 - in DN 2.0, substrings do not work in MySQL).
     return func instanceof GenericUDFOPEqual ||
+           func instanceof GenericUDFOPNotEqual ||
            func instanceof GenericUDFOPAnd ||
            func instanceof GenericUDFOPOr;
   }
 
+  /**
+   * Check if a function can be pushed down to JDO for integral types.
+   * Only {=, !=} are supported. lt/gt/etc. to be dealt with in HIVE-4888.
+   * @param func a generic function.
+   * @return true iff this function can be pushed down to JDO filter for integral types.
+   */
+  private static boolean doesJDOFuncSupportIntegral(GenericUDF func) {
+    // AND, OR etc. don't need to be specified here.
+    return func instanceof GenericUDFOPEqual ||
+           func instanceof GenericUDFOPNotEqual;
+  }
+
+  /**
+   * @param type type
+   * @param constant The constant, if any.
+   * @return true iff type is an integral type.
+   */
+  private static boolean isIntegralType(String type) {
+    return type.equals(serdeConstants.TINYINT_TYPE_NAME) ||
+           type.equals(serdeConstants.SMALLINT_TYPE_NAME) ||
+           type.equals(serdeConstants.INT_TYPE_NAME) ||
+           type.equals(serdeConstants.BIGINT_TYPE_NAME);
+  }
+
   /**
    * Check if the partition pruning expression can be pushed down to JDO filtering.
    * The partition expression contains only partition columns.
@@ -2174,32 +2204,47 @@ private static boolean supportedJDOFuncs(GenericUDF func) {
    *     restriction by the current JDO filtering implementation.
    * @param tab The table that contains the partition columns.
    * @param expr the partition pruning expression
+   * @param parent parent UDF of expr if parent exists and contains a UDF; otherwise null.
    * @return null if the partition pruning expression can be pushed down to JDO filtering.
    */
-  public static String checkJDOPushDown(Table tab, ExprNodeDesc expr) {
-    if (expr instanceof ExprNodeConstantDesc) {
-      // JDO filter now only support String typed literal -- see Filter.g and ExpressionTree.java
+  public static String checkJDOPushDown(
+      Table tab, ExprNodeDesc expr, GenericUDF parent) {
+    boolean isConst = expr instanceof ExprNodeConstantDesc;
+    boolean isCol = !isConst && (expr instanceof ExprNodeColumnDesc);
+    boolean isIntegralSupported = (parent != null) && (isConst || isCol)
+        && doesJDOFuncSupportIntegral(parent);
+
+    // JDO filter now only support String typed literals, as well as integers
+    // for some operators; see Filter.g and ExpressionTree.java.
+    if (isConst) {
       Object value = ((ExprNodeConstantDesc)expr).getValue();
       if (value instanceof String) {
         return null;
       }
-      return "Constant " + value + " is not string type";
-    } else if (expr instanceof ExprNodeColumnDesc) {
-      // JDO filter now only support String typed literal -- see Filter.g and ExpressionTree.java
+      if (isIntegralSupported && isIntegralType(expr.getTypeInfo().getTypeName())) {
+        return null;
+      }
+      return "Constant " + value + " is not string "
+        + (isIntegralSupported ? "or integral ": "") + "type: " + expr.getTypeInfo().getTypeName();
+    } else if (isCol) {
       TypeInfo type = expr.getTypeInfo();
-      if (type.getTypeName().equals(serdeConstants.STRING_TYPE_NAME)) {
+      if (type.getTypeName().equals(serdeConstants.STRING_TYPE_NAME)
+          || (isIntegralSupported && isIntegralType(type.getTypeName()))) {
         String colName = ((ExprNodeColumnDesc)expr).getColumn();
         for (FieldSchema fs: tab.getPartCols()) {
           if (fs.getName().equals(colName)) {
-            if (fs.getType().equals(serdeConstants.STRING_TYPE_NAME)) {
+            if (fs.getType().equals(serdeConstants.STRING_TYPE_NAME)
+                || (isIntegralSupported && isIntegralType(fs.getType()))) {
               return null;
             }
-            return "Partition column " + fs.getName() + " is not string type";
+            return "Partition column " + fs.getName() + " is not string "
+              + (isIntegralSupported ? "or integral ": "") + "type: " + fs.getType();
           }
         }
         assert(false); // cannot find the partition column!
      } else {
-        return "Column " + expr.getExprString() + " is not string type";
+        return "Column " + expr.getExprString() + " is not string "
+          + (isIntegralSupported ? "or integral ": "") + "type: " + type.getTypeName();
      }
     } else if (expr instanceof ExprNodeGenericFuncDesc) {
       ExprNodeGenericFuncDesc funcDesc = (ExprNodeGenericFuncDesc) expr;
@@ -2213,7 +2258,7 @@ public static String checkJDOPushDown(Table tab, ExprNodeDesc expr) {
         if (!(child instanceof ExprNodeConstantDesc)) {
           allChildrenConstant = false;
         }
-        String message = checkJDOPushDown(tab, child);
+        String message = checkJDOPushDown(tab, child, func);
         if (message != null) {
           return message;
         }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java
index 4fa5f2a6a8..1531e6b085 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java
@@ -201,7 +201,7 @@ public static PrunedPartitionList prune(Table tab, ExprNodeDesc prunerExpr,
             // are on non-partition columns.
             unkn_parts.addAll(Hive.get().getPartitions(tab));
           } else {
-            String message = Utilities.checkJDOPushDown(tab, compactExpr);
+            String message = Utilities.checkJDOPushDown(tab, compactExpr, null);
             if (message == null) {
               String filter = compactExpr.getExprString();
               String oldFilter = prunerExpr.getExprString();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 79457b4db2..a6c28ed4f1 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -7698,7 +7698,7 @@ private Operator genTablePlan(String alias, QB qb) throws SemanticException {
       for (FieldSchema part_col : tab.getPartCols()) {
         LOG.trace("Adding partition col: " + part_col);
         // TODO: use the right type by calling part_col.getType() instead of
-        // String.class
+        // String.class. See HIVE-3059.
         rwsch.put(alias, part_col.getName(), new ColumnInfo(part_col.getName(),
             TypeInfoFactory.stringTypeInfo, alias, true));
       }
diff --git a/ql/src/test/results/clientpositive/alter_partition_coltype.q.out b/ql/src/test/results/clientpositive/alter_partition_coltype.q.out
index 8bc845c3b1..42d4b02077 100644
--- a/ql/src/test/results/clientpositive/alter_partition_coltype.q.out
+++ b/ql/src/test/results/clientpositive/alter_partition_coltype.q.out
@@ -217,12 +217,10 @@ STAGE PLANS:
 PREHOOK: query: select count(*) from alter_coltype where dt = 100
 PREHOOK: type: QUERY
 PREHOOK: Input: default@alter_coltype
-PREHOOK: Input: default@alter_coltype@dt=100x/ts=6%3A30pm
 #### A masked pattern was here ####
 POSTHOOK: query: select count(*) from alter_coltype where dt = 100
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alter_coltype
-POSTHOOK: Input: default@alter_coltype@dt=100x/ts=6%3A30pm
 #### A masked pattern was here ####
 POSTHOOK: Lineage: alter_coltype PARTITION(dt=10,ts=3.0).key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: alter_coltype PARTITION(dt=10,ts=3.0).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
