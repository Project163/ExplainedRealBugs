diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index 63578aac81..57acddd8db 100644
--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -5119,7 +5119,7 @@ public static enum ConfVars {
 
     HIVE_QUERY_REEXECUTION_ENABLED("hive.query.reexecution.enabled", true,
         "Enable query reexecutions"),
-    HIVE_QUERY_REEXECUTION_STRATEGIES("hive.query.reexecution.strategies", "overlay,reoptimize,reexecute_lost_am",
+    HIVE_QUERY_REEXECUTION_STRATEGIES("hive.query.reexecution.strategies", "overlay,reoptimize,reexecute_lost_am,dagsubmit",
         "comma separated list of plugin can be used:\n"
             + "  overlay: hiveconf subtree 'reexec.overlay' is used as an overlay in case of an execution errors out\n"
             + "  reoptimize: collects operator statistics during execution and recompile the query after a failure\n"
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/DriverFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/DriverFactory.java
index 33275f602c..f2be56a1be 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/DriverFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/DriverFactory.java
@@ -27,6 +27,7 @@
 import org.apache.hadoop.hive.ql.reexec.ReExecutionRetryLockPlugin;
 import org.apache.hadoop.hive.ql.reexec.ReExecuteLostAMQueryPlugin;
 import org.apache.hadoop.hive.ql.reexec.ReExecutionOverlayPlugin;
+import org.apache.hadoop.hive.ql.reexec.ReExecutionDagSubmitPlugin;
 import org.apache.hadoop.hive.ql.reexec.ReOptimizePlugin;
 
 import com.google.common.base.Strings;
@@ -75,6 +76,9 @@ private static IReExecutionPlugin buildReExecPlugin(String name) throws RuntimeE
     if("reexecute_lost_am".equals(name)) {
       return new ReExecuteLostAMQueryPlugin();
     }
+    if (name.equals("dagsubmit")) {
+      return new ReExecutionDagSubmitPlugin();
+    }
     throw new RuntimeException(
         "Unknown re-execution plugin: " + name + " (" + ConfVars.HIVE_QUERY_REEXECUTION_STRATEGIES.varname + ")");
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/reexec/ReExecuteLostAMQueryPlugin.java b/ql/src/java/org/apache/hadoop/hive/ql/reexec/ReExecuteLostAMQueryPlugin.java
index da4b470b9b..6ada8f3643 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/reexec/ReExecuteLostAMQueryPlugin.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/reexec/ReExecuteLostAMQueryPlugin.java
@@ -24,26 +24,38 @@
 import org.apache.hadoop.hive.ql.hooks.HookContext;
 import org.apache.hadoop.hive.ql.plan.mapper.PlanMapper;
 import org.apache.hadoop.hive.ql.processors.CommandProcessorException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 import java.util.regex.Pattern;
 
+/**
+ * Re-Executes a query if tez AM failed because of node/container failure.
+ */
 public class ReExecuteLostAMQueryPlugin implements IReExecutionPlugin {
+  private static final Logger LOG = LoggerFactory.getLogger(ReExecuteLostAMQueryPlugin.class);
   private boolean retryPossible;
   private int maxExecutions = 1;
 
-  // Lost am container have exit code -100, due to node failures.
-  private Pattern lostAMContainerErrorPattern = Pattern.compile(".*AM Container for .* exited .* exitCode: -100.*");
+  // Lost am container have exit code -100, due to node failures. This pattern of exception is thrown when AM is managed
+  // by HS2.
+  private final Pattern lostAMContainerErrorPattern = Pattern.compile(".*AM Container for .* exited .* exitCode: -100.*");
 
   class LocalHook implements ExecuteWithHookContext {
-
     @Override
     public void run(HookContext hookContext) throws Exception {
       if (hookContext.getHookType() == HookContext.HookType.ON_FAILURE_HOOK) {
         Throwable exception = hookContext.getException();
 
-        if (exception != null && exception.getMessage() != null
-            && lostAMContainerErrorPattern.matcher(exception.getMessage()).matches()) {
-          retryPossible = true;
+        if (exception != null && exception.getMessage() != null) {
+          // When HS2 does not manage the AMs, tez AMs are registered with zookeeper and HS2 discovers it,
+          // failure of unmanaged AMs will throw AM record not being found in zookeeper.
+          String unmanagedAMFailure = "AM record not found (likely died)";
+          if (lostAMContainerErrorPattern.matcher(exception.getMessage()).matches()
+                  || exception.getMessage().contains(unmanagedAMFailure)) {
+            retryPossible = true;
+          }
+          LOG.info("Got exception message: {} retryPossible: {}", exception.getMessage(), retryPossible);
         }
       }
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/reexec/ReExecutionDagSubmitPlugin.java b/ql/src/java/org/apache/hadoop/hive/ql/reexec/ReExecutionDagSubmitPlugin.java
new file mode 100644
index 0000000000..b6e76dabbe
--- /dev/null
+++ b/ql/src/java/org/apache/hadoop/hive/ql/reexec/ReExecutionDagSubmitPlugin.java
@@ -0,0 +1,87 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.reexec;
+
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.ql.Driver;
+import org.apache.hadoop.hive.ql.hooks.ExecuteWithHookContext;
+import org.apache.hadoop.hive.ql.hooks.HookContext;
+import org.apache.hadoop.hive.ql.hooks.HookContext.HookType;
+import org.apache.hadoop.hive.ql.plan.mapper.PlanMapper;
+import org.apache.hadoop.hive.ql.processors.CommandProcessorException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Re-Executes a query when DAG submission fails after get session returned successfully. There could be race condition
+ * where getSession could return a healthy AM but by the time DAG is submitted the AM could become unhealthy/unreachable
+ * (possible DNS or network issues) which can fail tez DAG submission. Since the DAG hasn't started execution yet this
+ * failure can be safely restarted/retried.
+ */
+public class ReExecutionDagSubmitPlugin implements IReExecutionPlugin {
+
+  private static final Logger LOG = LoggerFactory.getLogger(ReExecutionDagSubmitPlugin.class);
+  private int maxExecutions = 1;
+  class LocalHook implements ExecuteWithHookContext {
+
+    @Override
+    public void run(HookContext hookContext) throws Exception {
+      if (hookContext.getHookType() == HookType.ON_FAILURE_HOOK) {
+        Throwable exception = hookContext.getException();
+        if (exception != null && exception.getMessage() != null) {
+          if (exception.getMessage().contains("Dag submit failed")) {
+            retryPossible = true;
+          }
+          LOG.info("Got exception message: {} retryPossible: {}", exception.getMessage(), retryPossible);
+        }
+      }
+    }
+  }
+
+  @Override
+  public void initialize(Driver driver) {
+    driver.getHookRunner().addOnFailureHook(new LocalHook());
+    maxExecutions = 1 + driver.getConf().getIntVar(HiveConf.ConfVars.HIVE_QUERY_MAX_REEXECUTION_COUNT);
+  }
+
+  private boolean retryPossible;
+
+  @Override
+  public void prepareToReExecute() {
+  }
+
+  @Override
+  public boolean shouldReExecute(int executionNum, PlanMapper pm1, PlanMapper pm2) {
+    return (executionNum < maxExecutions) && retryPossible;
+  }
+
+  @Override
+  public void beforeExecute(int executionIndex, boolean explainReOptimization) {
+  }
+
+  @Override
+  public boolean shouldReExecute(int executionNum, CommandProcessorException ex) {
+    return (executionNum < maxExecutions) && retryPossible;
+  }
+
+  @Override
+  public void afterExecute(PlanMapper planMapper, boolean success) {
+  }
+
+}
