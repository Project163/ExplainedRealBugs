diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ObjectCacheFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ObjectCacheFactory.java
index ef5c9b163b..c51723264b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ObjectCacheFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ObjectCacheFactory.java
@@ -45,10 +45,23 @@ private ObjectCacheFactory() {
    * Returns the appropriate cache
    */
   public static ObjectCache getCache(Configuration conf, String queryId, boolean isPlanCache) {
+    // LLAP cache can be disabled via config or isPlanCache
+    return getCache(conf, queryId, isPlanCache, false);
+  }
+
+  /**
+   * Returns the appropriate cache
+   * @param conf
+   * @param queryId
+   * @param isPlanCache
+   * @param llapCacheAlwaysEnabled  Whether to always return LLAP cache regardless
+   *        of config settings disabling LLAP cache. Valid only if running LLAP.
+   * @return
+   */
+  public static ObjectCache getCache(Configuration conf, String queryId, boolean isPlanCache, boolean llapCacheAlwaysEnabled) {
     if (HiveConf.getVar(conf, HiveConf.ConfVars.HIVE_EXECUTION_ENGINE).equals("tez")) {
       if (LlapProxy.isDaemon()) { // daemon
-        if (HiveConf.getBoolVar(conf, HiveConf.ConfVars.LLAP_OBJECT_CACHE_ENABLED)
-            && !isPlanCache) {
+        if (isLlapCacheEnabled(conf, isPlanCache, llapCacheAlwaysEnabled)) {
           // LLAP object cache, unlike others, does not use globals. Thus, get the existing one.
           return getLlapObjectCache(queryId);
         } else { // no cache
@@ -70,6 +83,11 @@ public static ObjectCache getCache(Configuration conf, String queryId, boolean i
     }
   }
 
+  private static boolean isLlapCacheEnabled(Configuration conf, boolean isPlanCache, boolean llapCacheAlwaysEnabled) {
+    return (llapCacheAlwaysEnabled ||
+        (HiveConf.getBoolVar(conf, HiveConf.ConfVars.LLAP_OBJECT_CACHE_ENABLED) && !isPlanCache));
+  }
+
   private static ObjectCache getLlapObjectCache(String queryId) {
     // If order of events (i.e. dagstart and fragmentstart) was guaranteed, we could just
     // create the cache when dag starts, and blindly return it to execution here.
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MapRecordProcessor.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MapRecordProcessor.java
index 24d3526dda..8ca8be66f6 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MapRecordProcessor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MapRecordProcessor.java
@@ -100,7 +100,7 @@ public MapRecordProcessor(final JobConf jconf, final ProcessorContext context) t
       setLlapOfFragmentId(context);
     }
     cache = ObjectCacheFactory.getCache(jconf, queryId, true);
-    dynamicValueCache = ObjectCacheFactory.getCache(jconf, queryId, false);
+    dynamicValueCache = ObjectCacheFactory.getCache(jconf, queryId, false, true);
     execContext = new ExecMapperContext(jconf);
     execContext.setJc(jconf);
     cacheKeys = new ArrayList<String>();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordProcessor.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordProcessor.java
index 9de3850809..ce3e07f721 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordProcessor.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordProcessor.java
@@ -90,7 +90,7 @@ public ReduceRecordProcessor(final JobConf jconf, final ProcessorContext context
 
     String queryId = HiveConf.getVar(jconf, HiveConf.ConfVars.HIVEQUERYID);
     cache = ObjectCacheFactory.getCache(jconf, queryId, true);
-    dynamicValueCache = ObjectCacheFactory.getCache(jconf, queryId, false);
+    dynamicValueCache = ObjectCacheFactory.getCache(jconf, queryId, false, true);
 
     String cacheKey = processorContext.getTaskVertexName() + REDUCE_PLAN_KEY;
     cacheKeys = Lists.newArrayList(cacheKey);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/DynamicValue.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/DynamicValue.java
index 613c60750c..a20328cb69 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/DynamicValue.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/DynamicValue.java
@@ -113,7 +113,7 @@ public Object getValue() {
     try {
       // Get object cache
       String queryId = HiveConf.getVar(conf, HiveConf.ConfVars.HIVEQUERYID);
-      ObjectCache cache = ObjectCacheFactory.getCache(conf, queryId, false);
+      ObjectCache cache = ObjectCacheFactory.getCache(conf, queryId, false, true);
 
       if (cache == null) {
         return null;
diff --git a/ql/src/test/queries/clientpositive/dynamic_semijoin_reduction.q b/ql/src/test/queries/clientpositive/dynamic_semijoin_reduction.q
index 6cc0a7f7a9..1d10dce9d9 100644
--- a/ql/src/test/queries/clientpositive/dynamic_semijoin_reduction.q
+++ b/ql/src/test/queries/clientpositive/dynamic_semijoin_reduction.q
@@ -121,6 +121,7 @@ set hive.tez.dynamic.semijoin.reduction=false;
 EXPLAIN select count(*) from srcpart_small10, srcpart_small, srcpart_date where srcpart_small.key1 = srcpart_small10.key1 and srcpart_date.ds = srcpart_small.ds;
 select count(*) from srcpart_small10, srcpart_small, srcpart_date where srcpart_small.key1 = srcpart_small10.key1 and srcpart_date.ds = srcpart_small.ds;
 set hive.tez.dynamic.semijoin.reduction=true;
+set hive.llap.object.cache.enabled=false;
 EXPLAIN select count(*) from srcpart_small10, srcpart_small, srcpart_date where srcpart_small.key1 = srcpart_small10.key1 and srcpart_date.ds = srcpart_small.ds;
 select count(*) from srcpart_small10, srcpart_small, srcpart_date where srcpart_small.key1 = srcpart_small10.key1 and srcpart_date.ds = srcpart_small.ds;
 
