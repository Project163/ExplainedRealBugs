diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupByOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupByOperator.java
index 505db9e5e6..b719c5190d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupByOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupByOperator.java
@@ -155,7 +155,7 @@ public class VectorGroupByOperator extends Operator<GroupByDesc>
 
   private transient long maxMemory;
 
-  private float memoryThreshold;
+  private float hashTableMemoryPercentage;
 
   private boolean isLlap = false;
 
@@ -626,20 +626,20 @@ private void computeMemoryLimits() {
 
       MemoryMXBean memoryMXBean = ManagementFactory.getMemoryMXBean();
       maxMemory = isLlap ? getConf().getMaxMemoryAvailable() : memoryMXBean.getHeapMemoryUsage().getMax();
-      memoryThreshold = conf.getMemoryThreshold();
+      hashTableMemoryPercentage = conf.getGroupByMemoryUsage();
       // Tests may leave this unitialized, so better set it to 1
-      if (memoryThreshold == 0.0f) {
-        memoryThreshold = 1.0f;
+      if (hashTableMemoryPercentage == 0.0f) {
+        hashTableMemoryPercentage = 1.0f;
       }
 
-      maxHashTblMemory = (int)(maxMemory * memoryThreshold);
+      maxHashTblMemory = (int)(maxMemory * hashTableMemoryPercentage);
 
       if (LOG.isDebugEnabled()) {
         LOG.debug("GBY memory limits - isLlap: {} maxMemory: {} ({} * {}) fixSize:{} (key:{} agg:{})",
           isLlap,
           LlapUtil.humanReadableByteCount(maxHashTblMemory),
           LlapUtil.humanReadableByteCount(maxMemory),
-          memoryThreshold,
+          hashTableMemoryPercentage,
           fixedHashEntrySize,
           keyWrappersBatch.getKeysFixedSize(),
           aggregationBatchInfo.getAggregatorsFixedSize());
diff --git a/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorGroupByOperator.java b/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorGroupByOperator.java
index f189894169..f0a2667371 100644
--- a/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorGroupByOperator.java
+++ b/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorGroupByOperator.java
@@ -285,12 +285,12 @@ public void testMemoryPressureFlush() throws HiveException {
     GroupByDesc desc = pair.left;
     VectorGroupByDesc vectorDesc = pair.right;
 
-    // Set the memory treshold so that we get 100Kb before we need to flush.
+    // Set the memory threshold so that we get 100Kb before we need to flush.
     MemoryMXBean memoryMXBean = ManagementFactory.getMemoryMXBean();
     long maxMemory = memoryMXBean.getHeapMemoryUsage().getMax();
 
-    float treshold = 100.0f*1024.0f/maxMemory;
-    desc.setMemoryThreshold(treshold);
+    float threshold = 100.0f*1024.0f/maxMemory;
+    desc.setGroupByMemoryUsage(threshold);
 
     CompilationOpContext cCtx = new CompilationOpContext();
 
@@ -352,7 +352,7 @@ public void remove() {
         break;
       }
       // Set an upper bound how much we're willing to push before it should flush
-      // we've set the memory treshold at 100kb, each key is distinct
+      // we've set the memory threshold at 100kb, each key is distinct
       // It should not go beyond 100k/16 (key+data)
       assertTrue(countRowsProduced < 100*1024/16);
     }
@@ -389,7 +389,7 @@ public void testMemoryPressureFlushLlap() throws HiveException {
       long maxMemory=512*1024*1024L;
       vgo.getConf().setMaxMemoryAvailable(maxMemory);
       float threshold = 100.0f*1024.0f/maxMemory;
-      desc.setMemoryThreshold(threshold);
+      desc.setGroupByMemoryUsage(threshold);
       vgo.initialize(hconf, null);
 
       long got = vgo.getMaxMemory();
@@ -442,7 +442,7 @@ public void remove() {
           break;
         }
         // Set an upper bound how much we're willing to push before it should flush
-        // we've set the memory treshold at 100kb, each key is distinct
+        // we've set the memory threshold at 100kb, each key is distinct
         // It should not go beyond 100k/16 (key+data)
         assertTrue(countRowsProduced < 100 * 1024 / 16);
       }
@@ -816,13 +816,13 @@ public void testMaxHTEntriesFlush() throws HiveException {
     GroupByDesc desc = pair.left;
     VectorGroupByDesc vectorDesc = pair.right;
 
-    // Set the memory treshold so that we get 100Kb before we need to flush.
+    // Set the memory threshold so that we get 100Kb before we need to flush.
     MemoryMXBean memoryMXBean = ManagementFactory.getMemoryMXBean();
     long maxMemory = memoryMXBean.getHeapMemoryUsage().getMax();
 
     // 1 MB should be able to store 1M/16bytes(key+data) = 62500 entries
-    float treshold = 10 * 100.0f*1024.0f/maxMemory;
-    desc.setMemoryThreshold(treshold);
+    float threshold = 10 * 100.0f*1024.0f/maxMemory;
+    desc.setGroupByMemoryUsage(threshold);
 
     // Set really low MAXENTRIES setting
     hconf.set("hive.vectorized.groupby.maxentries", "100");
