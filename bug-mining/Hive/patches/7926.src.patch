diff --git a/common/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java b/common/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
index 643f537cf9..e60653938c 100644
--- a/common/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
+++ b/common/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
@@ -471,6 +471,7 @@ public enum ErrorMsg {
   AMBIGUOUS_STRUCT_ATTRIBUTE(10423, "Attribute \"{0}\" specified more than once in structured type.", true),
   OFFSET_NOT_SUPPORTED_IN_SUBQUERY(10424, "OFFSET is not supported in subquery of exists", true),
   WITH_COL_LIST_NUM_OVERFLOW(10425, "WITH-clause query {0} returns {1} columns, but {2} labels were specified. The number of column labels must be smaller or equal to the number of expressions returned by the query.", true),
+  NULL_TREATMENT_NOT_SUPPORTED(10426, "Function {0} does not support null treatment.", true),
 
   //========================== 20000 range starts here ========================//
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
index 149c3972c3..eaa233d90a 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
@@ -1079,12 +1079,12 @@ public static GenericUDAFEvaluator getGenericUDAFEvaluator(String name,
 
   public static GenericUDAFEvaluator getGenericWindowingEvaluator(String name,
       List<ObjectInspector> argumentOIs, boolean isDistinct,
-      boolean isAllColumns) throws SemanticException {
+      boolean isAllColumns, boolean respectNulls) throws SemanticException {
     Registry registry = SessionState.getRegistry();
     GenericUDAFEvaluator evaluator = registry == null ? null :
-        registry.getGenericWindowingEvaluator(name, argumentOIs, isDistinct, isAllColumns);
+        registry.getGenericWindowingEvaluator(name, argumentOIs, isDistinct, isAllColumns, respectNulls);
     return evaluator != null ? evaluator :
-        system.getGenericWindowingEvaluator(name, argumentOIs, isDistinct, isAllColumns);
+        system.getGenericWindowingEvaluator(name, argumentOIs, isDistinct, isAllColumns, respectNulls);
   }
 
   public static GenericUDAFResolver getGenericUDAFResolver(String functionName)
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/Registry.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/Registry.java
index d686cf5705..e72356caba 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/Registry.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/Registry.java
@@ -477,7 +477,7 @@ public void getFunctionSynonyms(
   @SuppressWarnings("deprecation")
   public GenericUDAFEvaluator getGenericUDAFEvaluator(String name,
       List<ObjectInspector> argumentOIs, boolean isWindowing, boolean isDistinct,
-      boolean isAllColumns) throws SemanticException {
+      boolean isAllColumns, boolean respectNulls) throws SemanticException {
 
     GenericUDAFResolver udafResolver = getGenericUDAFResolver(name);
     if (udafResolver == null) {
@@ -494,7 +494,7 @@ public GenericUDAFEvaluator getGenericUDAFEvaluator(String name,
 
     GenericUDAFParameterInfo paramInfo =
         new SimpleGenericUDAFParameterInfo(
-            args, isWindowing, isDistinct, isAllColumns);
+            args, isWindowing, isDistinct, isAllColumns, respectNulls);
     if (udafResolver instanceof GenericUDAFResolver2) {
       udafEvaluator =
           ((GenericUDAFResolver2) udafResolver).getEvaluator(paramInfo);
@@ -505,7 +505,7 @@ public GenericUDAFEvaluator getGenericUDAFEvaluator(String name,
   }
 
   public GenericUDAFEvaluator getGenericWindowingEvaluator(String functionName,
-      List<ObjectInspector> argumentOIs, boolean isDistinct, boolean isAllColumns)
+      List<ObjectInspector> argumentOIs, boolean isDistinct, boolean isAllColumns, boolean respectNulls)
       throws SemanticException {
     functionName = functionName.toLowerCase();
     WindowFunctionInfo info = getWindowFunctionInfo(functionName);
@@ -514,7 +514,7 @@ public GenericUDAFEvaluator getGenericWindowingEvaluator(String functionName,
     }
     if (!functionName.equals(FunctionRegistry.LEAD_FUNC_NAME) &&
         !functionName.equals(FunctionRegistry.LAG_FUNC_NAME)) {
-      return getGenericUDAFEvaluator(functionName, argumentOIs, true, isDistinct, isAllColumns);
+      return getGenericUDAFEvaluator(functionName, argumentOIs, true, isDistinct, isAllColumns, respectNulls);
     }
 
     // this must be lead/lag UDAF
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/WindowFunctionDescription.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/WindowFunctionDescription.java
index 015c26a30e..60932be297 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/WindowFunctionDescription.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/WindowFunctionDescription.java
@@ -84,4 +84,13 @@
    * @return true if the function can be used as an ordered-set aggregate
    */
   boolean orderedAggregate() default false;
+
+  /**
+   * Some aggregate functions allow specifying null treatment.
+   * Example:
+   *   SELECT last_value(b) IGNORE NULLS OVER (ORDER BY b) FROM table1;
+   *
+   * @return true if this aggregate functions support null treatment.
+   */
+  boolean supportsNullTreatment() default false;
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/WindowFunctionInfo.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/WindowFunctionInfo.java
index 8e626436d3..d57cefb691 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/WindowFunctionInfo.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/WindowFunctionInfo.java
@@ -28,6 +28,7 @@ public class WindowFunctionInfo extends FunctionInfo {
   private final boolean pivotResult;
   private final boolean impliesOrder;
   private final boolean orderedAggregate;
+  private final boolean supportsNullTreatment;
 
   public WindowFunctionInfo(FunctionType functionType, String functionName,
       GenericUDAFResolver resolver, FunctionResource[] resources) {
@@ -38,6 +39,7 @@ public WindowFunctionInfo(FunctionType functionType, String functionName,
     pivotResult = def == null ? false : def.pivotResult();
     impliesOrder = def == null ? false : def.impliesOrder();
     orderedAggregate = def == null ? false : def.orderedAggregate();
+    supportsNullTreatment = def == null ? false : def.supportsNullTreatment();
   }
 
   public boolean isSupportsWindow() {
@@ -68,4 +70,8 @@ public boolean isImpliesOrder() {
   public boolean isOrderedAggregate() {
     return orderedAggregate;
   }
+
+  public boolean isSupportsNullTreatment() {
+    return supportsNullTreatment;
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java
index cc90476335..8ba3f0c92c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java
@@ -740,10 +740,6 @@ public ASTNode visitOver(RexOver over) {
 
       // 1. Translate the UDAF
       final ASTNode wUDAFAst = visitCall(over);
-      if (over.ignoreNulls()) {
-        ASTNode trueLiteral = ASTBuilder.createAST(HiveParser.KW_TRUE, "true");
-        wUDAFAst.addChild(trueLiteral);
-      }
 
       // 2. Add TOK_WINDOW as child of UDAF
       ASTNode wSpec = ASTBuilder.createAST(HiveParser.TOK_WINDOWSPEC, "TOK_WINDOWSPEC");
@@ -759,6 +755,10 @@ public ASTNode visitOver(RexOver over) {
       if (wRangeAst != null) {
         wSpec.addChild(wRangeAst);
       }
+      if (over.ignoreNulls()) {
+        ASTNode ignoreNulls = ASTBuilder.createAST(HiveParser.TOK_IGNORE_NULLS, "TOK_IGNORE_NULLS");
+        wSpec.addChild(ignoreNulls);
+      }
 
       return wUDAFAst;
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
index eb5838eba0..b6c2db45fb 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
@@ -108,7 +108,6 @@
 import org.apache.calcite.rex.RexLiteral;
 import org.apache.calcite.rex.RexNode;
 import org.apache.calcite.rex.RexShuttle;
-import org.apache.calcite.rex.RexSubQuery;
 import org.apache.calcite.rex.RexUtil;
 import org.apache.calcite.rex.RexWindowBound;
 import org.apache.calcite.schema.SchemaPlus;
@@ -123,8 +122,6 @@
 import org.apache.calcite.sql.SqlOperator;
 import org.apache.calcite.sql.SqlWindow;
 import org.apache.calcite.sql.dialect.HiveSqlDialect;
-import org.apache.calcite.sql.fun.SqlQuantifyOperator;
-import org.apache.calcite.sql.fun.SqlStdOperatorTable;
 import org.apache.calcite.sql.parser.SqlParserPos;
 import org.apache.calcite.sql.type.SqlTypeName;
 import org.apache.calcite.sql.validate.SqlValidatorUtil;
@@ -304,7 +301,6 @@
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
 import org.apache.hadoop.hive.ql.plan.HiveOperation;
 import org.apache.hadoop.hive.ql.plan.SelectDesc;
-import org.apache.hadoop.hive.ql.plan.SubqueryType;
 import org.apache.hadoop.hive.ql.plan.mapper.EmptyStatsSource;
 import org.apache.hadoop.hive.ql.plan.mapper.StatsSource;
 import org.apache.hadoop.hive.ql.session.SessionState;
@@ -352,7 +348,6 @@
 import static java.util.Collections.singletonList;
 import static org.apache.hadoop.hive.ql.optimizer.calcite.rules.views.HiveMaterializedViewUtils.copyMaterializationToNewCluster;
 import static org.apache.hadoop.hive.ql.optimizer.calcite.rules.views.HiveMaterializedViewUtils.extractTable;
-import static org.apache.hadoop.hive.ql.parse.type.RexNodeExprFactory.convertSubquerySomeAll;
 
 
 public class CalcitePlanner extends SemanticAnalyzer {
@@ -4524,7 +4519,8 @@ private Pair<RexNode, TypeInfo> genWindowingProj(WindowExpressionSpec wExpSpec,
 
         // 6. Translate Window spec
         RowResolver inputRR = relToHiveRR.get(srcRel);
-        WindowSpec wndSpec = ((WindowFunctionSpec) wExpSpec).getWindowSpec();
+        WindowFunctionSpec wndFuncSpec = (WindowFunctionSpec) wExpSpec;
+        WindowSpec wndSpec = wndFuncSpec.getWindowSpec();
         List<RexNode> partitionKeys = getPartitionKeys(wndSpec.getPartition(), inputRR);
         List<RexFieldCollation> orderKeys = getOrderKeys(wndSpec.getOrder(), inputRR);
         RexWindowBound lowerBound = getBound(wndSpec.getWindowFrame().getStart());
@@ -4533,7 +4529,7 @@ private Pair<RexNode, TypeInfo> genWindowingProj(WindowExpressionSpec wExpSpec,
 
         w = cluster.getRexBuilder().makeOver(calciteAggFnRetType, calciteAggFn, calciteAggFnArgs,
             partitionKeys, ImmutableList.<RexFieldCollation> copyOf(orderKeys), lowerBound,
-            upperBound, isRows, true, false, hiveAggInfo.isDistinct(), wndSpec.ignoreNulls());
+            upperBound, isRows, true, false, hiveAggInfo.isDistinct(), !wndFuncSpec.isRespectNulls());
       } else {
         // TODO: Convert to Semantic Exception
         throw new RuntimeException("Unsupported window Spec");
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java
index f5aeedc54c..d69be80cd1 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java
@@ -79,7 +79,6 @@
 import org.apache.hadoop.hive.ql.udf.ptf.WindowingTableFunction.WindowingTableFunctionResolver;
 import org.apache.hadoop.hive.serde2.AbstractSerDe;
 import org.apache.hadoop.hive.serde2.SerDeException;
-import org.apache.hadoop.hive.serde2.SerDeUtils;
 import org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe;
 import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
@@ -90,8 +89,6 @@
 import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;
 import org.apache.hadoop.hive.serde2.objectinspector.StructField;
 import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
-import org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo;
-import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -356,6 +353,7 @@ private WindowFunctionDef translate(WindowTableFunctionDef wdwTFnDef,
     def.setExpressionTreeString(spec.getExpression().toStringTree());
     def.setStar(spec.isStar());
     def.setPivotResult(wFnInfo.isPivotResult());
+    def.setRespectNulls(spec.isRespectNulls());
     ShapeDetails inpShape = wdwTFnDef.getRawInputShape();
 
     /*
@@ -585,7 +583,7 @@ static void setupWdwFnEvaluator(WindowFunctionDef def) throws HiveException {
 
     GenericUDAFEvaluator wFnEval = FunctionRegistry.getGenericWindowingEvaluator(def.getName(),
         argOIs,
-        def.isDistinct(), def.isStar());
+        def.isDistinct(), def.isStar(), def.respectNulls());
     ObjectInspector OI = wFnEval.init(GenericUDAFEvaluator.Mode.COMPLETE, funcArgOIs);
     def.setWFnEval(wFnEval);
     def.setOI(OI);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index b79cbe58f2..812bee3626 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -144,6 +144,7 @@
 import org.apache.hadoop.hive.ql.exec.UnionOperator;
 import org.apache.hadoop.hive.ql.exec.Utilities;
 import org.apache.hadoop.hive.ql.exec.Utilities.ReduceField;
+import org.apache.hadoop.hive.ql.exec.WindowFunctionInfo;
 import org.apache.hadoop.hive.ql.exec.tez.TezTask;
 import org.apache.hadoop.hive.ql.hooks.Entity;
 import org.apache.hadoop.hive.ql.hooks.ReadEntity;
@@ -14366,12 +14367,39 @@ private WindowFunctionSpec processWindowFunction(ASTNode node, ASTNode wsNode)
     }
 
     if ( wsNode != null ) {
+      WindowFunctionInfo functionInfo = FunctionRegistry.getWindowFunctionInfo(wfSpec.name);
+      if (functionInfo == null) {
+        throw new SemanticException(ErrorMsg.INVALID_FUNCTION.getMsg(wfSpec.name));
+      }
+      wfSpec.setRespectNulls(processRespectIgnoreNulls(functionInfo, wsNode));
       wfSpec.setWindowSpec(processWindowSpec(wsNode));
     }
 
     return wfSpec;
   }
 
+  private boolean processRespectIgnoreNulls(WindowFunctionInfo functionInfo, ASTNode node)
+      throws SemanticException {
+
+    for(int i=0; i < node.getChildCount(); i++) {
+      int type = node.getChild(i).getType();
+      switch(type) {
+      case HiveParser.TOK_RESPECT_NULLS:
+        if (!functionInfo.isSupportsNullTreatment()) {
+          throw new SemanticException(ErrorMsg.NULL_TREATMENT_NOT_SUPPORTED, functionInfo.getDisplayName());
+        }
+        return true;
+      case HiveParser.TOK_IGNORE_NULLS:
+        if (!functionInfo.isSupportsNullTreatment()) {
+          throw new SemanticException(ErrorMsg.NULL_TREATMENT_NOT_SUPPORTED, functionInfo.getDisplayName());
+        }
+        return false;
+      }
+    }
+
+    return true;
+  }
+
   private boolean containsLeadLagUDF(ASTNode expressionTree) {
     int exprTokenType = expressionTree.getToken().getType();
     if (exprTokenType == HiveParser.TOK_FUNCTION) {
@@ -14410,7 +14438,6 @@ private void processQueryWindowClause(WindowingSpec spec, ASTNode node)
 
   private WindowSpec processWindowSpec(ASTNode node) throws SemanticException {
     boolean hasSrcId = false, hasPartSpec = false, hasWF = false;
-    boolean ignoreNulls = false;
     int srcIdIdx = -1, partIdx = -1, wfIdx = -1;
 
     for(int i=0; i < node.getChildCount(); i++)
@@ -14428,12 +14455,6 @@ private WindowSpec processWindowSpec(ASTNode node) throws SemanticException {
       case HiveParser.TOK_WINDOWVALUES:
         hasWF = true; wfIdx = i;
         break;
-      case HiveParser.TOK_RESPECT_NULLS:
-        ignoreNulls = false;
-        break;
-      case HiveParser.TOK_IGNORE_NULLS:
-        ignoreNulls = true;
-        break;
       }
     }
 
@@ -14456,8 +14477,6 @@ private WindowSpec processWindowSpec(ASTNode node) throws SemanticException {
       ws.setWindowFrame(wfSpec);
     }
 
-    ws.setIgnoreNulls(ignoreNulls);
-
     return ws;
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/WindowingSpec.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/WindowingSpec.java
index eec47208b4..5a8d48da6f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/WindowingSpec.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/WindowingSpec.java
@@ -346,6 +346,7 @@ public static class WindowFunctionSpec extends WindowExpressionSpec
     String name;
     boolean isStar;
     boolean isDistinct;
+    boolean respectNulls;
     ArrayList<ASTNode> args;
     WindowSpec windowSpec;
 
@@ -384,6 +385,15 @@ public WindowSpec getWindowSpec() {
     public void setWindowSpec(WindowSpec windowSpec) {
       this.windowSpec = windowSpec;
     }
+
+    public boolean isRespectNulls() {
+      return respectNulls;
+    }
+
+    public void setRespectNulls(boolean respectNulls) {
+      this.respectNulls = respectNulls;
+    }
+
     @Override
     public String toString() {
       StringBuilder buf = new StringBuilder();
@@ -415,6 +425,10 @@ public String toString() {
 
       buf.append(")");
 
+      if (!respectNulls) {
+        buf.append(" ignore nulls ");
+      }
+
       if ( windowSpec != null )
       {
         buf.append(" ").append(windowSpec.toString());
@@ -446,7 +460,6 @@ public static class WindowSpec
     private String sourceId;
     private PartitioningSpec partitioning;
     private WindowFrameSpec windowFrame;
-    private boolean ignoreNulls;
 
     public String getSourceId() {
       return sourceId;
@@ -504,14 +517,6 @@ public String toString() {
           partitioning == null ? "" : partitioning,
           windowFrame == null ? "" : windowFrame);
     }
-
-    public void setIgnoreNulls(boolean ignoreNulls) {
-      this.ignoreNulls = ignoreNulls;
-    }
-
-    public boolean ignoreNulls() {
-      return ignoreNulls;
-    }
   };
 
   /*
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/type/HiveFunctionHelper.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/type/HiveFunctionHelper.java
index 7ee9672062..51acac269e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/type/HiveFunctionHelper.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/type/HiveFunctionHelper.java
@@ -412,7 +412,7 @@ public AggregateInfo getWindowAggregateFunctionInfo(boolean isDistinct, boolean
         if (aggregateName.toLowerCase().equals(FunctionRegistry.LEAD_FUNC_NAME)
             || aggregateName.toLowerCase().equals(FunctionRegistry.LAG_FUNC_NAME)) {
           GenericUDAFEvaluator genericUDAFEvaluator = FunctionRegistry.getGenericWindowingEvaluator(aggregateName,
-              aggParameterOIs, isDistinct, isAllColumns);
+              aggParameterOIs, isDistinct, isAllColumns, true);
           GenericUDAFInfo udaf = SemanticAnalyzer.getGenericUDAFInfo2(
               genericUDAFEvaluator, udafMode, aggParameterOIs);
           returnType = ((ListTypeInfo) udaf.returnType).getListElementTypeInfo();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFunctionDef.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFunctionDef.java
index 3011fc9031..a88e1eda59 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFunctionDef.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/ptf/WindowFunctionDef.java
@@ -33,6 +33,7 @@ public class WindowFunctionDef extends WindowExpressionDef {
   WindowFrameDef windowFrame;
   GenericUDAFEvaluator wFnEval;
   boolean pivotResult;
+  boolean respectNulls = true;
 
   @Explain(displayName = "name")
   public String getName() {
@@ -124,4 +125,11 @@ public void setPivotResult(boolean pivotResult) {
     this.pivotResult = pivotResult;
   }
 
+  public boolean respectNulls() {
+    return respectNulls;
+  }
+
+  public void setRespectNulls(boolean respectNulls) {
+    this.respectNulls = respectNulls;
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFFirstValue.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFFirstValue.java
index e9120e59ff..4dd3cd1b4b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFFirstValue.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFFirstValue.java
@@ -28,8 +28,6 @@
 import org.apache.hadoop.hive.ql.exec.WindowFunctionDescription;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.parse.SemanticException;
-import org.apache.hadoop.hive.ql.parse.WindowingSpec.BoundarySpec;
-import org.apache.hadoop.hive.ql.plan.ptf.BoundaryDef;
 import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.AggregationBuffer;
 import org.apache.hadoop.hive.ql.util.JavaDataModel;
@@ -47,24 +45,26 @@
 @WindowFunctionDescription(
         supportsWindow = true,
         pivotResult = false,
-        impliesOrder = true)
+        impliesOrder = true,
+        supportsNullTreatment = true)
 public class GenericUDAFFirstValue extends AbstractGenericUDAFResolver {
 
   static final Logger LOG = LoggerFactory.getLogger(GenericUDAFFirstValue.class.getName());
 
   @Override
-  public GenericUDAFEvaluator getEvaluator(TypeInfo[] parameters) throws SemanticException {
+  public GenericUDAFEvaluator getEvaluator(GenericUDAFParameterInfo info) throws SemanticException {
+    TypeInfo[] parameters = info.getParameters();
     if (parameters.length > 2) {
       throw new UDFArgumentTypeException(2, "At most 2 arguments expected");
     }
     if (parameters.length > 1 && !parameters[1].equals(TypeInfoFactory.booleanTypeInfo)) {
       throw new UDFArgumentTypeException(1, "second argument must be a boolean expression");
     }
-    return createEvaluator();
+    return createEvaluator(!info.respectNulls());
   }
 
-  protected GenericUDAFFirstValueEvaluator createEvaluator() {
-    return new GenericUDAFFirstValueEvaluator();
+  protected GenericUDAFFirstValueEvaluator createEvaluator(boolean skipNulls) {
+    return new GenericUDAFFirstValueEvaluator(skipNulls);
   }
 
   static class FirstValueBuffer implements AggregationBuffer {
@@ -74,15 +74,15 @@ static class FirstValueBuffer implements AggregationBuffer {
     boolean firstRow;
     boolean skipNulls;
 
-    FirstValueBuffer() {
-      init();
+    FirstValueBuffer(boolean skipNulls) {
+      init(skipNulls);
     }
 
-    void init() {
+    void init(boolean skipNulls) {
       val = null;
       valSet = false;
       firstRow = true;
-      skipNulls = false;
+      this.skipNulls = skipNulls;
     }
 
   }
@@ -91,6 +91,11 @@ public static class GenericUDAFFirstValueEvaluator extends GenericUDAFEvaluator
 
     ObjectInspector inputOI;
     ObjectInspector outputOI;
+    final boolean skipNulls;
+
+    public GenericUDAFFirstValueEvaluator(boolean skipNulls) {
+      this.skipNulls = skipNulls;
+    }
 
     @Override
     public ObjectInspector init(Mode m, ObjectInspector[] parameters) throws HiveException {
@@ -106,12 +111,12 @@ public ObjectInspector init(Mode m, ObjectInspector[] parameters) throws HiveExc
 
     @Override
     public AggregationBuffer getNewAggregationBuffer() throws HiveException {
-      return new FirstValueBuffer();
+      return new FirstValueBuffer(skipNulls);
     }
 
     @Override
     public void reset(AggregationBuffer agg) throws HiveException {
-      ((FirstValueBuffer) agg).init();
+      ((FirstValueBuffer) agg).init(skipNulls);
     }
 
     @Override
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFLastValue.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFLastValue.java
index 2f40183e67..512f14a19b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFLastValue.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFLastValue.java
@@ -25,8 +25,6 @@
 import org.apache.hadoop.hive.ql.exec.WindowFunctionDescription;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.parse.SemanticException;
-import org.apache.hadoop.hive.ql.parse.WindowingSpec.BoundarySpec;
-import org.apache.hadoop.hive.ql.plan.ptf.BoundaryDef;
 import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.AggregationBuffer;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
@@ -39,24 +37,25 @@
 
 @Description(name = "last_value", value = "_FUNC_(x)")
 @WindowFunctionDescription(
-  supportsWindow = true, pivotResult = false, impliesOrder = true)
+  supportsWindow = true, pivotResult = false, impliesOrder = true, supportsNullTreatment = true)
 public class GenericUDAFLastValue extends AbstractGenericUDAFResolver {
 
   static final Logger LOG = LoggerFactory.getLogger(GenericUDAFLastValue.class.getName());
 
   @Override
-  public GenericUDAFEvaluator getEvaluator(TypeInfo[] parameters) throws SemanticException {
+  public GenericUDAFEvaluator getEvaluator(GenericUDAFParameterInfo info) throws SemanticException {
+    TypeInfo[] parameters = info.getParameters();
     if (parameters.length > 2) {
       throw new UDFArgumentTypeException(2, "At most 2 arguments expected");
     }
     if (parameters.length > 1 && !parameters[1].equals(TypeInfoFactory.booleanTypeInfo)) {
       throw new UDFArgumentTypeException(1, "second argument must be a boolean expression");
     }
-    return createEvaluator();
+    return createEvaluator(!info.respectNulls());
   }
 
-  protected GenericUDAFLastValueEvaluator createEvaluator() {
-    return new GenericUDAFLastValueEvaluator();
+  protected GenericUDAFLastValueEvaluator createEvaluator(boolean skipNulls) {
+    return new GenericUDAFLastValueEvaluator(skipNulls);
   }
 
   static class LastValueBuffer implements AggregationBuffer {
@@ -65,14 +64,14 @@ static class LastValueBuffer implements AggregationBuffer {
     boolean firstRow;
     boolean skipNulls;
 
-    LastValueBuffer() {
-      init();
+    LastValueBuffer(boolean skipNulls) {
+      init(skipNulls);
     }
 
-    void init() {
+    void init(boolean skipNulls) {
       val = null;
       firstRow = true;
-      skipNulls = false;
+      this.skipNulls = skipNulls;
     }
 
   }
@@ -81,6 +80,11 @@ public static class GenericUDAFLastValueEvaluator extends GenericUDAFEvaluator {
 
     ObjectInspector inputOI;
     ObjectInspector outputOI;
+    final boolean skipNulls;
+
+    public GenericUDAFLastValueEvaluator(boolean skipNulls) {
+      this.skipNulls = skipNulls;
+    }
 
     @Override
     public ObjectInspector init(Mode m, ObjectInspector[] parameters) throws HiveException {
@@ -96,12 +100,12 @@ public ObjectInspector init(Mode m, ObjectInspector[] parameters) throws HiveExc
 
     @Override
     public AggregationBuffer getNewAggregationBuffer() throws HiveException {
-      return new LastValueBuffer();
+      return new LastValueBuffer(skipNulls);
     }
 
     @Override
     public void reset(AggregationBuffer agg) throws HiveException {
-      ((LastValueBuffer) agg).init();
+      ((LastValueBuffer) agg).init(skipNulls);
     }
 
     @Override
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFParameterInfo.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFParameterInfo.java
index c1161abf97..1afa1ebf00 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFParameterInfo.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFParameterInfo.java
@@ -88,4 +88,5 @@ public interface GenericUDAFParameterInfo {
    */
   boolean isAllColumns();
 
+  boolean respectNulls();
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/SimpleGenericUDAFParameterInfo.java b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/SimpleGenericUDAFParameterInfo.java
index a3a9969e67..b0c75affa9 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/SimpleGenericUDAFParameterInfo.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/SimpleGenericUDAFParameterInfo.java
@@ -32,13 +32,20 @@ public class SimpleGenericUDAFParameterInfo implements GenericUDAFParameterInfo
   private final boolean isWindowing;
   private final boolean distinct;
   private final boolean allColumns;
+  private final boolean respectNulls;
 
   public SimpleGenericUDAFParameterInfo(ObjectInspector[] params, boolean isWindowing, boolean distinct,
       boolean allColumns) {
+    this(params, isWindowing, distinct, allColumns, true);
+  }
+
+  public SimpleGenericUDAFParameterInfo(ObjectInspector[] params, boolean isWindowing, boolean distinct,
+      boolean allColumns, boolean respectNulls) {
     this.parameters = params;
     this.isWindowing = isWindowing;
     this.distinct = distinct;
     this.allColumns = allColumns;
+    this.respectNulls = respectNulls;
   }
 
   @Override
@@ -70,4 +77,9 @@ public boolean isAllColumns() {
   public boolean isWindowing() {
     return isWindowing;
   }
+
+  @Override
+  public boolean respectNulls() {
+    return respectNulls;
+  }
 }
diff --git a/ql/src/test/queries/clientnegative/nulltreatment.q b/ql/src/test/queries/clientnegative/nulltreatment.q
new file mode 100644
index 0000000000..c030d77fa6
--- /dev/null
+++ b/ql/src/test/queries/clientnegative/nulltreatment.q
@@ -0,0 +1,3 @@
+CREATE TABLE t1(a int);
+
+SELECT sum(a) IGNORE NULLS OVER (ORDER BY a) FROM t1;
diff --git a/ql/src/test/results/clientnegative/nulltreatment.q.out b/ql/src/test/results/clientnegative/nulltreatment.q.out
new file mode 100644
index 0000000000..40b0fe63f8
--- /dev/null
+++ b/ql/src/test/results/clientnegative/nulltreatment.q.out
@@ -0,0 +1,9 @@
+PREHOOK: query: CREATE TABLE t1(a int)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t1
+POSTHOOK: query: CREATE TABLE t1(a int)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t1
+FAILED: SemanticException [Error 10426]: Function sum does not support null treatment.
diff --git a/ql/src/test/results/clientnegative/windowing_invalid_udaf.q.out b/ql/src/test/results/clientnegative/windowing_invalid_udaf.q.out
index de9fc2c125..885435d90c 100644
--- a/ql/src/test/results/clientnegative/windowing_invalid_udaf.q.out
+++ b/ql/src/test/results/clientnegative/windowing_invalid_udaf.q.out
@@ -1,2 +1 @@
-FAILED: SemanticException Failed to breakup Windowing invocations into Groups. At least 1 group must only depend on input columns. Also check for circular dependencies.
-Underlying error: Invalid function nonexistfunc
+FAILED: SemanticException [Error 10011]: Invalid function nonexistfunc
