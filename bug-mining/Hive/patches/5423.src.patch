diff --git a/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/SerDeEncodedDataReader.java b/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/SerDeEncodedDataReader.java
index a4fde6da49..907200a6e3 100644
--- a/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/SerDeEncodedDataReader.java
+++ b/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/SerDeEncodedDataReader.java
@@ -17,6 +17,8 @@
  */
 package org.apache.hadoop.hive.llap.io.encoded;
 
+import org.apache.orc.impl.MemoryManager;
+
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.security.PrivilegedExceptionAction;
@@ -1532,13 +1534,29 @@ public List<VectorizedRowBatch> extractCurrentVrbs() {
     }
   }
 
+  private static final class NoopMemoryManager extends MemoryManager {
+    public NoopMemoryManager() {
+      super(null);
+    }
+
+    @Override
+    public void addedRow(int rows) {}
+    @Override
+    public void addWriter(Path path, long requestedAllocation, Callback callback) {}
+    @Override
+    public void notifyWriters() {}
+    @Override
+    public void removeWriter(Path path) throws IOException {}
+  }
+  private static final NoopMemoryManager MEMORY_MANAGER = new NoopMemoryManager();
+
   static WriterOptions createOrcWriterOptions(ObjectInspector sourceOi,
       Configuration conf, CacheWriter cacheWriter, int allocSize) throws IOException {
     return OrcFile.writerOptions(conf).stripeSize(Long.MAX_VALUE).blockSize(Long.MAX_VALUE)
         .rowIndexStride(Integer.MAX_VALUE) // For now, do not limit this - one RG per split
         .blockPadding(false).compress(CompressionKind.NONE).version(Version.CURRENT)
         .encodingStrategy(EncodingStrategy.SPEED).bloomFilterColumns(null).inspector(sourceOi)
-        .physicalWriter(cacheWriter).bufferSize(allocSize);
+        .physicalWriter(cacheWriter).memory(MEMORY_MANAGER).bufferSize(allocSize);
   }
 
   private ObjectInspector getOiFromSerDe() throws IOException {
