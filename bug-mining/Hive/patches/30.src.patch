diff --git a/CHANGES.txt b/CHANGES.txt
index 85370e5165..efe914702c 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -43,6 +43,9 @@ Trunk (unreleased changes)
 
   BUG FIXES
 
+    HIVE-104. Tables with at least 1 non-string columns to use DynamicSerDe.
+    (zshao)
+
     HIVE-158. Make table aliases work for sampled tables in joins.
     (Raghotham Murthy via zshao)
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
index 508e6512f1..ba7cf29b89 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
@@ -57,6 +57,7 @@
 import org.apache.hadoop.hive.serde.Constants;
 import org.apache.hadoop.hive.serde.thrift.columnsetSerDe;
 import org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe;
+import org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe;
 import org.apache.hadoop.mapred.SequenceFileInputFormat;
 import org.apache.hadoop.mapred.SequenceFileOutputFormat;
 import org.apache.hadoop.mapred.TextInputFormat;
@@ -396,7 +397,9 @@ else if (alterTbl.getOp() == alterTableDesc.alterTableTypes.ADDCOLS) {
             .printInfo("Replacing columns for columnsetSerDe and changing to typed SerDe");
         tbl.setSerializationLib(MetadataTypedColumnsetSerDe.class.getName());
       } else if (!tbl.getSerializationLib().equals(
-          MetadataTypedColumnsetSerDe.class.getName())) {
+          MetadataTypedColumnsetSerDe.class.getName())
+          && !tbl.getSerializationLib().equals(
+          DynamicSerDe.class.getName())) {
         console
             .printError("Replace columns is not supported for this table. SerDe may be incompatible.");
         return 1;
@@ -524,19 +527,23 @@ private int createTable(Hive db, createTableDesc crtTbl) throws HiveException {
     }
 
     /**
-     * For now, if the user specifies either the map or the collections
-     * delimiter, we infer the table to DynamicSerDe/TCTLSeparatedProtocol. In
-     * the future, we should infer this for any delimiters specified, but this
-     * will break older hive tables, so not for now.
+     * If the user didn't specify a SerDe, and any of the columns are not of type String, 
+     * we will have to use DynamicSerDe instead.
      */
-    if (crtTbl.getCollItemDelim() != null || crtTbl.getMapKeyDelim() != null) {
-      tbl
-          .setSerializationLib(org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe.class
-              .getName());
-      tbl.setSerdeParam(
-          org.apache.hadoop.hive.serde.Constants.SERIALIZATION_FORMAT,
-          org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol.class
-              .getName());
+    if (crtTbl.getSerName() == null) {
+      boolean useDynamicSerDe = false;
+      if (crtTbl.getCols() != null) {
+        for (FieldSchema field: crtTbl.getCols()) {
+          if (!Constants.STRING_TYPE_NAME.equalsIgnoreCase(field.getType())) {
+            useDynamicSerDe = true;
+          }
+        }
+      }
+      if (useDynamicSerDe) {
+        LOG.info("Default to DynamicSerDe for table " + crtTbl.getTableName() );
+        tbl.setSerializationLib(org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe.class.getName());
+        tbl.setSerdeParam(org.apache.hadoop.hive.serde.Constants.SERIALIZATION_FORMAT, org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol.class.getName());
+      }
     }
 
     if (crtTbl.getComment() != null)
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
index f926fcea5c..68ac441aa0 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
@@ -203,6 +203,8 @@ public void createTable(Table tbl) throws HiveException {
       }
       tbl.checkValidity();
       msc.createTable(tbl.getTTable());
+    } catch (HiveException e) {
+      throw e;
     } catch (Exception e) {
       throw new HiveException(e);
     }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 55efc3a4c4..5270746453 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -1086,6 +1086,7 @@ private Operator genSelectPlan(String dest, QB qb,
     RowResolver inputRR = opParseCtx.get(input).getRR();
     boolean selectStar = false;
     
+    LOG.debug("genSelectPlan: input = " + inputRR.toString());
     // Iterate over the selects
     for (int i = 0; i < selExprList.getChildCount(); ++i) {
 
@@ -1203,6 +1204,13 @@ UDAFInfo getUDAFInfo(String aggName, groupByDesc.Mode mode, ArrayList<Class<?>>
     return r;
   }
   
+  /**
+   * Generate the GroupByOperator for the Query Block (parseInfo.getXXX(dest)).
+   * The new GroupByOperator will be a child of the reduceSinkOperatorInfo.
+   * 
+   * @param mode The mode of the aggregation (PARTIAL1 or COMPLETE)
+   * @return the new GroupByOperator
+   */
   @SuppressWarnings("nls")
   private Operator genGroupByPlanGroupByOperator(
         QBParseInfo parseInfo, String dest, Operator reduceSinkOperatorInfo,
@@ -1271,6 +1279,13 @@ private Operator genGroupByPlanGroupByOperator(
     );
   }
 
+  /**
+   * Generate the GroupByOperator for the Query Block (parseInfo.getXXX(dest)).
+   * The new GroupByOperator will be a child of the reduceSinkOperatorInfo.
+   * 
+   * @param mode The mode of the aggregation (PARTIAL2)
+   * @return the new GroupByOperator
+   */
   @SuppressWarnings("nls")
   private Operator genGroupByPlanGroupByOperator1(
         QBParseInfo parseInfo, String dest, Operator reduceSinkOperatorInfo,
@@ -1337,6 +1352,7 @@ private Operator genGroupByPlanGroupByOperator1(
 
       String aggName = value.getChild(0).getText();
       Class<? extends UDAF> aggClass = FunctionRegistry.getUDAF(aggName);
+      Method aggEvaluateMethod = FunctionRegistry.getUDAFEvaluateMethod(aggName, mode);
       assert (aggClass != null);
       ArrayList<exprNodeDesc> aggParameters = new ArrayList<exprNodeDesc>();
       String text = entry.getKey();
@@ -1350,7 +1366,7 @@ private Operator genGroupByPlanGroupByOperator1(
       aggregations.add(new aggregationDesc(aggClass, aggParameters, ((mode == groupByDesc.Mode.FINAL) ? false : (value.getToken().getType() == HiveParser.TOK_FUNCTIONDI))));
       groupByOutputRowResolver.put("", value.toStringTree(),
                                     new ColumnInfo(Integer.valueOf(groupByKeys.size() + aggregations.size() - 1).toString(),
-                                                   paraExprInfo.getType()));
+                                        aggEvaluateMethod.getReturnType()));
     }
 
     return putOpInsertMap(
@@ -1360,6 +1376,13 @@ private Operator genGroupByPlanGroupByOperator1(
         groupByOutputRowResolver);
   }
 
+  /**
+   * Generate the map-side GroupByOperator for the Query Block (qb.getParseInfo().getXXX(dest)).
+   * The new GroupByOperator will be a child of the inputOperatorInfo.
+   * 
+   * @param mode The mode of the aggregation (HASH)
+   * @return the new GroupByOperator
+   */
   @SuppressWarnings("nls")
   private Operator genGroupByPlanMapGroupByOperator(QB qb, String dest, Operator inputOperatorInfo, 
                                                     groupByDesc.Mode mode) throws SemanticException {
@@ -1472,6 +1495,19 @@ private ArrayList<exprNodeDesc> convertParameters(Method m, ArrayList<exprNodeDe
     return newParameters;
   }
 
+  /**
+   * Generate the ReduceSinkOperator for the Group By Query Block (parseInfo.getXXX(dest)).
+   * The new ReduceSinkOperator will be a child of inputOperatorInfo.
+   * 
+   * It will put all Group By keys and the distinct field (if any) in the map-reduce sort key,
+   * and all other fields in the map-reduce value.
+   * 
+   * The map-reduce partition key will be random() if there is no distinct, or the same as
+   * the map-reduce sort key otherwise.  
+   * 
+   * @return the new ReduceSinkOperator.
+   * @throws SemanticException
+   */
   @SuppressWarnings("nls")
   private Operator genGroupByPlanReduceSinkOperator(QBParseInfo parseInfo,
       String dest, Operator inputOperatorInfo)
@@ -1539,6 +1575,18 @@ private Operator genGroupByPlanReduceSinkOperator(QBParseInfo parseInfo,
       reduceSinkOutputRowResolver);
   }
 
+  /**
+   * Generate the ReduceSinkOperator for the Group By Query Block (qb.getPartInfo().getXXX(dest)).
+   * The new ReduceSinkOperator will be a child of inputOperatorInfo.
+   * 
+   * It will put all Group By keys and the distinct field (if any) in the map-reduce sort key,
+   * and all other fields in the map-reduce value.
+   * 
+   * @param numPartitionFields  the number of fields for map-reduce partitioning.
+   *      This is usually the number of fields in the Group By keys.
+   * @return the new ReduceSinkOperator.
+   * @throws SemanticException
+   */
   @SuppressWarnings("nls")
   private Operator genGroupByPlanReduceSinkOperator(QB qb,
       String dest, Operator inputOperatorInfo, int numPartitionFields) throws SemanticException {
@@ -1607,6 +1655,19 @@ private Operator genGroupByPlanReduceSinkOperator(QB qb,
     );
   }
 
+  /**
+   * Generate the second ReduceSinkOperator for the Group By Plan (parseInfo.getXXX(dest)).
+   * The new ReduceSinkOperator will be a child of groupByOperatorInfo.
+   * 
+   * The second ReduceSinkOperator will put the group by keys in the map-reduce sort
+   * key, and put the partial aggregation results in the map-reduce value. 
+   *  
+   * @param numPartitionFields the number of fields in the map-reduce partition key.
+   *     This should always be the same as the number of Group By keys.  We should be 
+   *     able to remove this parameter since in this phase there is no distinct any more.  
+   * @return the new ReduceSinkOperator.
+   * @throws SemanticException
+   */
   @SuppressWarnings("nls")
   private Operator genGroupByPlanReduceSinkOperator2MR(
       QBParseInfo parseInfo, String dest, Operator groupByOperatorInfo, int numPartitionFields)
@@ -1651,6 +1712,15 @@ private Operator genGroupByPlanReduceSinkOperator2MR(
     );
   }
 
+  /**
+   * Generate the second GroupByOperator for the Group By Plan (parseInfo.getXXX(dest)).
+   * The new GroupByOperator will do the second aggregation based on the partial aggregation 
+   * results.
+   * 
+   * @param mode the mode of aggregation (FINAL)  
+   * @return the new GroupByOperator
+   * @throws SemanticException
+   */
   @SuppressWarnings("nls")
   private Operator genGroupByPlanGroupByOperator2MR(
     QBParseInfo parseInfo, String dest, Operator reduceSinkOperatorInfo2, groupByDesc.Mode mode)
@@ -1681,6 +1751,7 @@ private Operator genGroupByPlanGroupByOperator2MR(
       CommonTree value = entry.getValue();
       String aggName = value.getChild(0).getText();
       Class<? extends UDAF> aggClass = FunctionRegistry.getUDAF(aggName);
+      Method aggEvaluateMethod = FunctionRegistry.getUDAFEvaluateMethod(aggName, mode);
       assert (aggClass != null);
       ArrayList<exprNodeDesc> aggParameters = new ArrayList<exprNodeDesc>();
       String text = entry.getKey();
@@ -1694,7 +1765,7 @@ private Operator genGroupByPlanGroupByOperator2MR(
       aggregations.add(new aggregationDesc(aggClass, aggParameters, ((mode == groupByDesc.Mode.FINAL) ? false : (value.getToken().getType() == HiveParser.TOK_FUNCTIONDI))));
       groupByOutputRowResolver2.put("", value.toStringTree(),
                                     new ColumnInfo(Integer.valueOf(groupByKeys.size() + aggregations.size() - 1).toString(),
-                                                   paraExprInfo.getType()));
+                                        aggEvaluateMethod.getReturnType()));
     }
 
     return putOpInsertMap(
@@ -1994,9 +2065,8 @@ Operator genConversionSelectOperator(String dest, QB qb,
             throw new SemanticException(ErrorMsg.TARGET_TABLE_COLUMN_MISMATCH.getMsg(
                 qb.getParseInfo().getDestForClause(dest), reason));
           }
-        } else {
-          expressions.add(column);
         }
+        expressions.add(column);
       }
     }
     
@@ -3433,7 +3503,8 @@ else if (myt.getCategory() == Category.MAP) {
         desc = new exprNodeIndexDesc(t, children.get(0), children.get(1));
       }
       else {
-        throw new SemanticException(ErrorMsg.NON_COLLECTION_TYPE.getMsg(expr));
+        throw new SemanticException(ErrorMsg.NON_COLLECTION_TYPE.getMsg(expr, 
+            myt.getTypeName()));
       }
     } else {
       // other operators or functions
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/groupByDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/groupByDesc.java
index 983d000f3a..8ff46ce6df 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/groupByDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/groupByDesc.java
@@ -55,6 +55,8 @@ public String getModeString() {
       return "partial2";
     case HASH:
       return "hash";
+    case FINAL:
+      return "final";
     }
   
     return "unknown";
diff --git a/ql/src/test/queries/clientpositive/cast1.q b/ql/src/test/queries/clientpositive/cast1.q
index 922c607833..7f5f8a58de 100644
--- a/ql/src/test/queries/clientpositive/cast1.q
+++ b/ql/src/test/queries/clientpositive/cast1.q
@@ -1,4 +1,4 @@
-CREATE TABLE dest1(c1 INT, c2 DOUBLE, c3 DOUBLE, c4 DOUBLE, c5 INT, c6 INT, c7 INT) STORED AS TEXTFILE;
+CREATE TABLE dest1(c1 INT, c2 DOUBLE, c3 DOUBLE, c4 DOUBLE, c5 INT, c6 STRING, c7 INT) STORED AS TEXTFILE;
 
 EXPLAIN
 FROM src INSERT OVERWRITE TABLE dest1 SELECT 3 + 2, 3.0 + 2, 3 + 2.0, 3.0 + 2.0, 3 + CAST(2.0 AS INT) + CAST(CAST(0 AS SMALLINT) AS INT), CAST(1 AS BOOLEAN), CAST(TRUE AS INT) WHERE src.key = 86;
diff --git a/ql/src/test/queries/clientpositive/create_1.q b/ql/src/test/queries/clientpositive/create_1.q
new file mode 100644
index 0000000000..e91bf06cde
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/create_1.q
@@ -0,0 +1,17 @@
+DROP TABLE table1;
+CREATE TABLE table1 (a STRING, b STRING) STORED AS TEXTFILE;
+DESCRIBE table1;
+DESCRIBE EXTENDED table1;
+
+DROP TABLE table2;
+CREATE TABLE table2 (a STRING, b INT) STORED AS TEXTFILE;
+DESCRIBE table2;
+DESCRIBE EXTENDED table2;
+
+DROP TABLE table3;
+CREATE TABLE table3 (a STRING, b STRING)
+ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
+STORED AS TEXTFILE;
+DESCRIBE table3;
+DESCRIBE EXTENDED table3;
+
diff --git a/ql/src/test/queries/clientpositive/groupby3.q b/ql/src/test/queries/clientpositive/groupby3.q
index 69869d2713..1cb4af6c19 100755
--- a/ql/src/test/queries/clientpositive/groupby3.q
+++ b/ql/src/test/queries/clientpositive/groupby3.q
@@ -1,4 +1,4 @@
-CREATE TABLE dest1(c1 INT, c2 INT, c3 INT, c4 INT, c5 INT) STORED AS TEXTFILE;
+CREATE TABLE dest1(c1 DOUBLE, c2 DOUBLE, c3 DOUBLE, c4 DOUBLE, c5 DOUBLE) STORED AS TEXTFILE;
 
 EXPLAIN
 FROM src
diff --git a/ql/src/test/queries/clientpositive/groupby3_map.q b/ql/src/test/queries/clientpositive/groupby3_map.q
index 328fedefb9..746f6ab78e 100644
--- a/ql/src/test/queries/clientpositive/groupby3_map.q
+++ b/ql/src/test/queries/clientpositive/groupby3_map.q
@@ -1,6 +1,6 @@
 set hive.map.aggr=true;
 
-CREATE TABLE dest1(c1 INT, c2 INT, c3 INT, c4 INT, c5 INT) STORED AS TEXTFILE;
+CREATE TABLE dest1(c1 DOUBLE, c2 DOUBLE, c3 DOUBLE, c4 DOUBLE, c5 DOUBLE) STORED AS TEXTFILE;
 
 EXPLAIN
 FROM src
diff --git a/ql/src/test/queries/clientpositive/input1.q b/ql/src/test/queries/clientpositive/input1.q
index 12bd6d8702..b745ca334b 100644
--- a/ql/src/test/queries/clientpositive/input1.q
+++ b/ql/src/test/queries/clientpositive/input1.q
@@ -1,4 +1,4 @@
-CREATE TABLE TEST1(A INT, B FLOAT) STORED AS TEXTFILE; 
+CREATE TABLE TEST1(A INT, B DOUBLE) STORED AS TEXTFILE; 
 
 EXPLAIN
 DESCRIBE TEST1; 
diff --git a/ql/src/test/queries/clientpositive/input2.q b/ql/src/test/queries/clientpositive/input2.q
index 9efd78fa84..094b920d16 100644
--- a/ql/src/test/queries/clientpositive/input2.q
+++ b/ql/src/test/queries/clientpositive/input2.q
@@ -1,8 +1,8 @@
 DROP TABLE TEST2a;
-CREATE TABLE TEST2a(A INT, B FLOAT) STORED AS TEXTFILE; 
+CREATE TABLE TEST2a(A INT, B DOUBLE) STORED AS TEXTFILE; 
 DESCRIBE TEST2a; 
 DROP TABLE TEST2b;
-CREATE TABLE TEST2b(A ARRAY<INT>, B FLOAT, C MAP<FLOAT, INT>) STORED AS TEXTFILE; 
+CREATE TABLE TEST2b(A ARRAY<INT>, B DOUBLE, C MAP<DOUBLE, INT>) STORED AS TEXTFILE; 
 DESCRIBE TEST2b; 
 SHOW TABLES;
 DROP TABLE TEST2a;
diff --git a/ql/src/test/queries/clientpositive/input3.q b/ql/src/test/queries/clientpositive/input3.q
index 9782f11326..ea079bdd4e 100644
--- a/ql/src/test/queries/clientpositive/input3.q
+++ b/ql/src/test/queries/clientpositive/input3.q
@@ -1,14 +1,14 @@
 DROP TABLE TEST3a;
 DROP TABLE TEST3b;
 DROP TABLE TEST3c;
-CREATE TABLE TEST3a(A INT, B FLOAT) STORED AS TEXTFILE; 
+CREATE TABLE TEST3a(A INT, B DOUBLE) STORED AS TEXTFILE; 
 DESCRIBE TEST3a; 
-CREATE TABLE TEST3b(A ARRAY<INT>, B FLOAT, C MAP<FLOAT, INT>) STORED AS TEXTFILE; 
+CREATE TABLE TEST3b(A ARRAY<INT>, B DOUBLE, C MAP<DOUBLE, INT>) STORED AS TEXTFILE; 
 DESCRIBE TEST3b; 
 SHOW TABLES;
 EXPLAIN
-ALTER TABLE TEST3b ADD COLUMNS (X FLOAT);
-ALTER TABLE TEST3b ADD COLUMNS (X FLOAT);
+ALTER TABLE TEST3b ADD COLUMNS (X DOUBLE);
+ALTER TABLE TEST3b ADD COLUMNS (X DOUBLE);
 DESCRIBE TEST3b; 
 EXPLAIN
 ALTER TABLE TEST3b RENAME TO TEST3c;
@@ -16,8 +16,8 @@ ALTER TABLE TEST3b RENAME TO TEST3c;
 DESCRIBE TEST3c; 
 SHOW TABLES;
 EXPLAIN
-ALTER TABLE TEST3c REPLACE COLUMNS (R1 INT, R2 FLOAT);
-ALTER TABLE TEST3c REPLACE COLUMNS (R1 INT, R2 FLOAT);
+ALTER TABLE TEST3c REPLACE COLUMNS (R1 INT, R2 DOUBLE);
+ALTER TABLE TEST3c REPLACE COLUMNS (R1 INT, R2 DOUBLE);
 DESCRIBE EXTENDED TEST3c;
 DROP TABLE TEST3c;
 DROP TABLE TEST3a;
diff --git a/ql/src/test/queries/clientpositive/input5.q b/ql/src/test/queries/clientpositive/input5.q
index 5daad27676..2a2784cba5 100644
--- a/ql/src/test/queries/clientpositive/input5.q
+++ b/ql/src/test/queries/clientpositive/input5.q
@@ -1,4 +1,4 @@
-CREATE TABLE dest1(key INT, value STRING) STORED AS TEXTFILE;
+CREATE TABLE dest1(key STRING, value STRING) STORED AS TEXTFILE;
 
 EXPLAIN
 FROM (
diff --git a/ql/src/test/queries/clientpositive/inputddl4.q b/ql/src/test/queries/clientpositive/inputddl4.q
index 924e186c5a..2e4311cf86 100644
--- a/ql/src/test/queries/clientpositive/inputddl4.q
+++ b/ql/src/test/queries/clientpositive/inputddl4.q
@@ -1,6 +1,6 @@
 -- a simple test to test sorted/clustered syntax
 DROP TABLE INPUTDDL4;
-CREATE TABLE INPUTDDL4(viewTime DATETIME, userid INT,
+CREATE TABLE INPUTDDL4(viewTime STRING, userid INT,
                        page_url STRING, referrer_url STRING, 
                        friends ARRAY<BIGINT>, properties MAP<STRING, STRING>,
                        ip STRING COMMENT 'IP Address of the User') 
diff --git a/ql/src/test/results/clientnegative/invalid_create_tbl1.q.out b/ql/src/test/results/clientnegative/invalid_create_tbl1.q.out
index 1279b24fb5..4c61317d13 100644
--- a/ql/src/test/results/clientnegative/invalid_create_tbl1.q.out
+++ b/ql/src/test/results/clientnegative/invalid_create_tbl1.q.out
@@ -1,2 +1,2 @@
-FAILED: Error in metadata: org.apache.hadoop.hive.ql.metadata.HiveException: Partition collumn name aint conflicts with table columns.
+FAILED: Error in metadata: Partition collumn name aint conflicts with table columns.
 FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
diff --git a/ql/src/test/results/clientpositive/case_sensitivity.q.out b/ql/src/test/results/clientpositive/case_sensitivity.q.out
index 9a9966bfbe..c6c504ea5a 100644
--- a/ql/src/test/results/clientpositive/case_sensitivity.q.out
+++ b/ql/src/test/results/clientpositive/case_sensitivity.q.out
@@ -31,7 +31,7 @@ STAGE PLANS:
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                         name: dest1
 
   Stage: Stage-0
@@ -41,7 +41,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/cast1.q.out b/ql/src/test/results/clientpositive/cast1.q.out
index 325c3b8d55..730aa36a68 100644
--- a/ql/src/test/results/clientpositive/cast1.q.out
+++ b/ql/src/test/results/clientpositive/cast1.q.out
@@ -34,13 +34,29 @@ STAGE PLANS:
                         type: boolean
                         expr: UDFToInteger(true)
                         type: int
-                  File Output Operator
-                    compressed: false
-                    table:
-                        input format: org.apache.hadoop.mapred.TextInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                        name: dest1
+                  Select Operator
+                    expressions:
+                          expr: 0
+                          type: int
+                          expr: 1
+                          type: double
+                          expr: 2
+                          type: double
+                          expr: 3
+                          type: double
+                          expr: 4
+                          type: int
+                          expr: UDFToString(5)
+                          type: string
+                          expr: 6
+                          type: int
+                    File Output Operator
+                      compressed: false
+                      table:
+                          input format: org.apache.hadoop.mapred.TextInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                          name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -49,8 +65,8 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
-5	5.0	5.0	5.0	5	false	1
+5	5.0	5.0	5.0	5	FALSE	1
diff --git a/ql/src/test/results/clientpositive/create_1.q.out b/ql/src/test/results/clientpositive/create_1.q.out
new file mode 100644
index 0000000000..e9d7162f64
--- /dev/null
+++ b/ql/src/test/results/clientpositive/create_1.q.out
@@ -0,0 +1,18 @@
+a	string
+b	string
+a	string
+b	string
+Detailed Table Information:
+Table(tableName:table1,dbName:default,owner:zshao,createTime:1228887062,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:a,type:string,comment:null), FieldSchema(name:b,type:string,comment:null)],location:file:/data/users/zshao/sync/apache-trunk/build/ql/test/data/warehouse/table1,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),partitionKeys:[],parameters:{})
+a	string
+b	int
+a	string
+b	int
+Detailed Table Information:
+Table(tableName:table2,dbName:default,owner:zshao,createTime:1228887063,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:a,type:string,comment:null), FieldSchema(name:b,type:int,comment:null)],location:file:/data/users/zshao/sync/apache-trunk/build/ql/test/data/warehouse/table2,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,parameters:{serialization.format=org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol}),bucketCols:[],sortCols:[],parameters:{}),partitionKeys:[],parameters:{})
+a	string
+b	string
+a	string
+b	string
+Detailed Table Information:
+Table(tableName:table3,dbName:default,owner:zshao,createTime:1228887063,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:a,type:string,comment:null), FieldSchema(name:b,type:string,comment:null)],location:file:/data/users/zshao/sync/apache-trunk/build/ql/test/data/warehouse/table3,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,parameters:{serialization.format=9,field.delim=	}),bucketCols:[],sortCols:[],parameters:{}),partitionKeys:[],parameters:{})
diff --git a/ql/src/test/results/clientpositive/groupby1.q.out b/ql/src/test/results/clientpositive/groupby1.q.out
index 4fb11b03c0..33aaeca64d 100644
--- a/ql/src/test/results/clientpositive/groupby1.q.out
+++ b/ql/src/test/results/clientpositive/groupby1.q.out
@@ -41,7 +41,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/69808444/374659791.10001 
+        /tmp/hive-zshao/67494501/106593589.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -61,20 +61,26 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest_g1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest_g1
 
   Stage: Stage-0
     Move Operator
@@ -83,7 +89,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest_g1
 
 
diff --git a/ql/src/test/results/clientpositive/groupby1_limit.q.out b/ql/src/test/results/clientpositive/groupby1_limit.q.out
index 5be731fe98..86dd788bd6 100644
--- a/ql/src/test/results/clientpositive/groupby1_limit.q.out
+++ b/ql/src/test/results/clientpositive/groupby1_limit.q.out
@@ -42,7 +42,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/786365372/1698354371.10001 
+        /tmp/hive-zshao/618493432/49810635.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -62,7 +62,7 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
@@ -80,7 +80,7 @@ STAGE PLANS:
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/786365372/1698354371.10002 
+        /tmp/hive-zshao/618493432/49810635.10002 
           Reduce Output Operator
             sort order: 
             tag: -1
@@ -93,13 +93,19 @@ STAGE PLANS:
       Reduce Operator Tree:
         Extract
           Limit
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -108,7 +114,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/groupby1_map.q.out b/ql/src/test/results/clientpositive/groupby1_map.q.out
index 5e89ef9306..a5babcd98c 100644
--- a/ql/src/test/results/clientpositive/groupby1_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby1_map.q.out
@@ -48,7 +48,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/176699107/318789303.10001 
+        /tmp/hive-zshao/632752964/335784834.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -68,20 +68,26 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: double
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -90,7 +96,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/groupby2.q.out b/ql/src/test/results/clientpositive/groupby2.q.out
index f2ee952832..f5d62dc5fd 100644
--- a/ql/src/test/results/clientpositive/groupby2.q.out
+++ b/ql/src/test/results/clientpositive/groupby2.q.out
@@ -43,7 +43,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/190784876/1532193204.10001 
+        /tmp/hive-zshao/75837910/35360202.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -66,7 +66,7 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
@@ -75,13 +75,21 @@ STAGE PLANS:
                   type: bigint
                   expr: concat(0, UDFToString(2))
                   type: string
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest_g2
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: string
+                    expr: UDFToInteger(1)
+                    type: int
+                    expr: 2
+                    type: string
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest_g2
 
   Stage: Stage-0
     Move Operator
@@ -90,7 +98,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest_g2
 
 
diff --git a/ql/src/test/results/clientpositive/groupby2_limit.q.out b/ql/src/test/results/clientpositive/groupby2_limit.q.out
index dbef75923c..d02ce31bde 100644
--- a/ql/src/test/results/clientpositive/groupby2_limit.q.out
+++ b/ql/src/test/results/clientpositive/groupby2_limit.q.out
@@ -41,7 +41,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/426666771/995404034.10002 
+        /tmp/hive-zshao/42329253/238260652.10002 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -61,7 +61,7 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
diff --git a/ql/src/test/results/clientpositive/groupby2_map.q.out b/ql/src/test/results/clientpositive/groupby2_map.q.out
index e3f8b9db1c..df42def1c0 100644
--- a/ql/src/test/results/clientpositive/groupby2_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby2_map.q.out
@@ -58,7 +58,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/729182472/421148418.10001 
+        /tmp/hive-zshao/107370008/1090440963.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -81,7 +81,7 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
@@ -90,13 +90,21 @@ STAGE PLANS:
                   type: bigint
                   expr: concat(0, UDFToString(2))
                   type: string
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: string
+                    expr: UDFToInteger(1)
+                    type: int
+                    expr: 2
+                    type: string
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -105,7 +113,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/groupby3.q.out b/ql/src/test/results/clientpositive/groupby3.q.out
index fd74baf737..182f773525 100644
--- a/ql/src/test/results/clientpositive/groupby3.q.out
+++ b/ql/src/test/results/clientpositive/groupby3.q.out
@@ -43,7 +43,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/793012867/112314829.10001 
+        /tmp/hive-zshao/695280947/659390410.10001 
           Reduce Output Operator
             sort order: 
             tag: -1
@@ -66,15 +66,15 @@ STAGE PLANS:
                 expr: avg(VALUE.2)
                 expr: min(VALUE.3)
                 expr: max(VALUE.4)
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 1
                   type: double
                   expr: 2
-                  type: string
+                  type: double
                   expr: 0
-                  type: string
+                  type: double
                   expr: 4
                   type: double
                   expr: 3
@@ -84,7 +84,7 @@ STAGE PLANS:
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   name: dest1
 
   Stage: Stage-0
@@ -94,7 +94,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/groupby3_map.q.out b/ql/src/test/results/clientpositive/groupby3_map.q.out
index 623821c030..e2b007ad78 100644
--- a/ql/src/test/results/clientpositive/groupby3_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby3_map.q.out
@@ -65,7 +65,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/16311816/1248542091.10001 
+        /tmp/hive-zshao/151053238/135596442.10001 
           Reduce Output Operator
             sort order: 
             tag: -1
@@ -88,15 +88,15 @@ STAGE PLANS:
                 expr: avg(VALUE.2)
                 expr: min(VALUE.3)
                 expr: max(VALUE.4)
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 1
                   type: double
                   expr: 2
-                  type: string
+                  type: double
                   expr: 0
-                  type: string
+                  type: double
                   expr: 4
                   type: double
                   expr: 3
@@ -106,7 +106,7 @@ STAGE PLANS:
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   name: dest1
 
   Stage: Stage-0
@@ -116,7 +116,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/groupby4.q.out b/ql/src/test/results/clientpositive/groupby4.q.out
index 4d9eb71c94..163786d15e 100644
--- a/ql/src/test/results/clientpositive/groupby4.q.out
+++ b/ql/src/test/results/clientpositive/groupby4.q.out
@@ -40,7 +40,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/1453689426/82458415.10001 
+        /tmp/hive-zshao/1491006708/287075280.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -55,7 +55,7 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
diff --git a/ql/src/test/results/clientpositive/groupby4_map.q.out b/ql/src/test/results/clientpositive/groupby4_map.q.out
index 32f6449614..c70699987a 100644
--- a/ql/src/test/results/clientpositive/groupby4_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby4_map.q.out
@@ -28,18 +28,22 @@ STAGE PLANS:
         Group By Operator
           aggregations:
                 expr: count(VALUE.0)
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
                   type: bigint
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -48,7 +52,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/groupby5.q.out b/ql/src/test/results/clientpositive/groupby5.q.out
index 651769d439..0ef8c99a64 100644
--- a/ql/src/test/results/clientpositive/groupby5.q.out
+++ b/ql/src/test/results/clientpositive/groupby5.q.out
@@ -41,7 +41,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/46132837/471661111.10001 
+        /tmp/hive-zshao/350108858/95672649.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -61,20 +61,26 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
                   type: string
                   expr: 1
                   type: double
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: UDFToString(1)
+                    type: string
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -83,7 +89,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/groupby5_map.q.out b/ql/src/test/results/clientpositive/groupby5_map.q.out
index dd4f57a6d8..0546e4fc7c 100644
--- a/ql/src/test/results/clientpositive/groupby5_map.q.out
+++ b/ql/src/test/results/clientpositive/groupby5_map.q.out
@@ -31,18 +31,22 @@ STAGE PLANS:
         Group By Operator
           aggregations:
                 expr: sum(VALUE.0)
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
                   type: double
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -51,8 +55,8 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
-130091.0
+130091
diff --git a/ql/src/test/results/clientpositive/groupby6.q.out b/ql/src/test/results/clientpositive/groupby6.q.out
index 3f35e60a16..7521396f01 100644
--- a/ql/src/test/results/clientpositive/groupby6.q.out
+++ b/ql/src/test/results/clientpositive/groupby6.q.out
@@ -40,7 +40,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/486205309/55090089.10001 
+        /tmp/hive-zshao/454201677/52450507.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -55,7 +55,7 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
diff --git a/ql/src/test/results/clientpositive/input1.q.out b/ql/src/test/results/clientpositive/input1.q.out
index 4d8560b30f..cde21e2d68 100644
--- a/ql/src/test/results/clientpositive/input1.q.out
+++ b/ql/src/test/results/clientpositive/input1.q.out
@@ -12,4 +12,4 @@ STAGE PLANS:
 
 
 a	int
-b	float
+b	double
diff --git a/ql/src/test/results/clientpositive/input11.q.out b/ql/src/test/results/clientpositive/input11.q.out
index 7c407f04c0..6acb5ab520 100644
--- a/ql/src/test/results/clientpositive/input11.q.out
+++ b/ql/src/test/results/clientpositive/input11.q.out
@@ -20,13 +20,19 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -35,7 +41,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input11_limit.q.out b/ql/src/test/results/clientpositive/input11_limit.q.out
index f7a296fced..2656847533 100644
--- a/ql/src/test/results/clientpositive/input11_limit.q.out
+++ b/ql/src/test/results/clientpositive/input11_limit.q.out
@@ -33,13 +33,19 @@ STAGE PLANS:
       Reduce Operator Tree:
         Extract
           Limit
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -48,7 +54,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input12.q.out b/ql/src/test/results/clientpositive/input12.q.out
index ba55b3c7ae..252138464b 100644
--- a/ql/src/test/results/clientpositive/input12.q.out
+++ b/ql/src/test/results/clientpositive/input12.q.out
@@ -20,13 +20,19 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
             Filter Operator
               predicate:
                   expr: ((key >= 100) and (key < 200))
@@ -37,13 +43,19 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest2
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest2
             Filter Operator
               predicate:
                   expr: (key >= 200)
@@ -52,13 +64,17 @@ STAGE PLANS:
                 expressions:
                       expr: key
                       type: string
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest3
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest3
 
   Stage: Stage-0
     Move Operator
@@ -67,13 +83,13 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
             replace: true
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest2
             partition:
               ds 2008-04-08
@@ -82,7 +98,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest3
 
 
diff --git a/ql/src/test/results/clientpositive/input13.q.out b/ql/src/test/results/clientpositive/input13.q.out
index 6eaf2d865b..7ed39d5aad 100644
--- a/ql/src/test/results/clientpositive/input13.q.out
+++ b/ql/src/test/results/clientpositive/input13.q.out
@@ -20,13 +20,19 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
             Filter Operator
               predicate:
                   expr: ((key >= 100) and (key < 200))
@@ -37,13 +43,19 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest2
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest2
             Filter Operator
               predicate:
                   expr: ((key >= 200) and (key < 300))
@@ -52,13 +64,17 @@ STAGE PLANS:
                 expressions:
                       expr: key
                       type: string
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest3
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest3
             Filter Operator
               predicate:
                   expr: (key >= 300)
@@ -83,13 +99,13 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
             replace: true
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest2
             partition:
               ds 2008-04-08
@@ -98,7 +114,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest3
 
 
diff --git a/ql/src/test/results/clientpositive/input14.q.out b/ql/src/test/results/clientpositive/input14.q.out
index eb1f4712ab..43d827263e 100644
--- a/ql/src/test/results/clientpositive/input14.q.out
+++ b/ql/src/test/results/clientpositive/input14.q.out
@@ -47,13 +47,19 @@ STAGE PLANS:
                     type: string
                     expr: 1
                     type: string
-              File Output Operator
-                compressed: false
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -62,7 +68,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input14_limit.q.out b/ql/src/test/results/clientpositive/input14_limit.q.out
index 0f3dad675a..d7a4f333f0 100644
--- a/ql/src/test/results/clientpositive/input14_limit.q.out
+++ b/ql/src/test/results/clientpositive/input14_limit.q.out
@@ -49,7 +49,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/606891034/24901173.10001 
+        /tmp/hive-zshao/2396737/195622561.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -78,13 +78,19 @@ STAGE PLANS:
                       type: string
                       expr: 1
                       type: string
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -93,7 +99,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input17.q.out b/ql/src/test/results/clientpositive/input17.q.out
index d6c5762800..2e1f3cdf75 100644
--- a/ql/src/test/results/clientpositive/input17.q.out
+++ b/ql/src/test/results/clientpositive/input17.q.out
@@ -51,13 +51,19 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: string
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -66,7 +72,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input18.q.out b/ql/src/test/results/clientpositive/input18.q.out
index 67043920d7..b7e1dfe502 100644
--- a/ql/src/test/results/clientpositive/input18.q.out
+++ b/ql/src/test/results/clientpositive/input18.q.out
@@ -51,13 +51,19 @@ STAGE PLANS:
                     type: string
                     expr: regexp_replace(1, '	', '+')
                     type: string
-              File Output Operator
-                compressed: false
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -66,7 +72,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input19.q.out b/ql/src/test/results/clientpositive/input19.q.out
index 3ecb833ad3..db9438946f 100644
--- a/ql/src/test/results/clientpositive/input19.q.out
+++ b/ql/src/test/results/clientpositive/input19.q.out
@@ -1 +1 @@
-127.0.0.1		frank	10/Oct/2000:13:55:36 -0700	GET /apache_pb.gif HTTP/1.0	200	2326
+127.0.0.1	NULL	frank	10/Oct/2000:13:55:36 -0700	GET /apache_pb.gif HTTP/1.0	200	2326
diff --git a/ql/src/test/results/clientpositive/input1_limit.q.out b/ql/src/test/results/clientpositive/input1_limit.q.out
index e5ec3b4bff..d18d5966f3 100644
--- a/ql/src/test/results/clientpositive/input1_limit.q.out
+++ b/ql/src/test/results/clientpositive/input1_limit.q.out
@@ -52,13 +52,19 @@ STAGE PLANS:
       Reduce Operator Tree:
         Extract
           Limit
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -67,19 +73,19 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
             replace: true
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest2
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/891215760/586361272.10002 
+        /tmp/hive-zshao/196681773/625336699.10002 
           Reduce Output Operator
             sort order: 
             tag: -1
@@ -92,13 +98,19 @@ STAGE PLANS:
       Reduce Operator Tree:
         Extract
           Limit
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest2
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest2
 
 
 86	val_86
diff --git a/ql/src/test/results/clientpositive/input2.q.out b/ql/src/test/results/clientpositive/input2.q.out
index 31be6cc6b6..b0d0f7a738 100644
--- a/ql/src/test/results/clientpositive/input2.q.out
+++ b/ql/src/test/results/clientpositive/input2.q.out
@@ -1,8 +1,8 @@
 a	int
-b	float
+b	double
 a	array<int>
-b	float
-c	map<float,int>
+b	double
+c	map<double,int>
 src	src1	src_sequencefile	src_thrift	srcbucket	srcpart	test2a	test2b
 src	src1	src_sequencefile	src_thrift	srcbucket	srcpart	test2b
 ABSTRACT SYNTAX TREE:
diff --git a/ql/src/test/results/clientpositive/input20.q.out b/ql/src/test/results/clientpositive/input20.q.out
index fc4699006f..8cc136b132 100644
--- a/ql/src/test/results/clientpositive/input20.q.out
+++ b/ql/src/test/results/clientpositive/input20.q.out
@@ -52,13 +52,19 @@ STAGE PLANS:
               output info:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-              File Output Operator
-                compressed: false
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -67,7 +73,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input3.q.out b/ql/src/test/results/clientpositive/input3.q.out
index 28ac73692a..c082670ca0 100644
--- a/ql/src/test/results/clientpositive/input3.q.out
+++ b/ql/src/test/results/clientpositive/input3.q.out
@@ -1,11 +1,11 @@
 a	int
-b	float
+b	double
 a	array<int>
-b	float
-c	map<float,int>
+b	double
+c	map<double,int>
 src	src1	src_sequencefile	src_thrift	srcbucket	srcpart	test3a	test3b
 ABSTRACT SYNTAX TREE:
-  (TOK_ALTERTABLE_ADDCOLS TEST3b (TOK_TABCOLLIST (TOK_TABCOL X TOK_FLOAT)))
+  (TOK_ALTERTABLE_ADDCOLS TEST3b (TOK_TABCOLLIST (TOK_TABCOL X TOK_DOUBLE)))
 
 STAGE DEPENDENCIES:
   Stage-0 is a root stage
@@ -15,14 +15,14 @@ STAGE PLANS:
       Alter Table Operator:
         Alter Table
           type: add columns
-          new columns: X float
+          new columns: X double
           old name: TEST3b
 
 
 a	array<int>
-b	float
-c	map<float,int>
-x	float
+b	double
+c	map<double,int>
+x	double
 ABSTRACT SYNTAX TREE:
   (TOK_ALTERTABLE_RENAME TEST3b TEST3c)
 
@@ -39,12 +39,12 @@ STAGE PLANS:
 
 
 a	array<int>
-b	float
-c	map<float,int>
-x	float
+b	double
+c	map<double,int>
+x	double
 src	src1	src_sequencefile	src_thrift	srcbucket	srcpart	test3a	test3c
 ABSTRACT SYNTAX TREE:
-  (TOK_ALTERTABLE_REPLACECOLS TEST3c (TOK_TABCOLLIST (TOK_TABCOL R1 TOK_INT) (TOK_TABCOL R2 TOK_FLOAT)))
+  (TOK_ALTERTABLE_REPLACECOLS TEST3c (TOK_TABCOLLIST (TOK_TABCOL R1 TOK_INT) (TOK_TABCOL R2 TOK_DOUBLE)))
 
 STAGE DEPENDENCIES:
   Stage-0 is a root stage
@@ -54,11 +54,11 @@ STAGE PLANS:
       Alter Table Operator:
         Alter Table
           type: replace columns
-          new columns: R1 int, R2 float
+          new columns: R1 int, R2 double
           old name: TEST3c
 
 
 r1	int
-r2	float
+r2	double
 Detailed Table Information:
-Table(tableName:test3c,dbName:default,owner:njain,createTime:1225993819,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:r1,type:int,comment:null), FieldSchema(name:r2,type:float,comment:null)],location:file:/home/njain/workspace/hadoop-0.17/build/contrib/hive/ql/test/data/warehouse/test3b,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,parameters:{serialization.format=1}),bucketCols:[],sortCols:[],parameters:{}),partitionKeys:[],parameters:{last_modified_by=njain,last_modified_time=1225993820})
+Table(tableName:test3c,dbName:default,owner:zshao,createTime:1229498330,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:r1,type:int,comment:null), FieldSchema(name:r2,type:double,comment:null)],location:file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/test3b,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat,compressed:false,numBuckets:-1,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,parameters:{serialization.format=org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol}),bucketCols:[],sortCols:[],parameters:{}),partitionKeys:[],parameters:{last_modified_by=zshao,last_modified_time=1229498331})
diff --git a/ql/src/test/results/clientpositive/input7.q.out b/ql/src/test/results/clientpositive/input7.q.out
index e6809edaec..ef104ae0d6 100644
--- a/ql/src/test/results/clientpositive/input7.q.out
+++ b/ql/src/test/results/clientpositive/input7.q.out
@@ -20,13 +20,19 @@ STAGE PLANS:
                       type: string
                       expr: 0
                       type: string
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToDouble(UDFToBoolean(0))
+                        type: double
+                        expr: UDFToInteger(1)
+                        type: int
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -35,22 +41,22 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
 NULL	238
-NULL	
+NULL	NULL
 NULL	311
-NULL	
-NULL	
-NULL	
+NULL	NULL
+NULL	NULL
+NULL	NULL
 NULL	255
 NULL	278
 NULL	98
-NULL	
-NULL	
-NULL	
+NULL	NULL
+NULL	NULL
+NULL	NULL
 NULL	401
 NULL	150
 NULL	273
@@ -61,6 +67,6 @@ NULL	128
 NULL	213
 NULL	146
 NULL	406
-NULL	
-NULL	
-NULL	
+NULL	NULL
+NULL	NULL
+NULL	NULL
diff --git a/ql/src/test/results/clientpositive/input8.q.out b/ql/src/test/results/clientpositive/input8.q.out
index 731e4ada17..ab62341ef4 100644
--- a/ql/src/test/results/clientpositive/input8.q.out
+++ b/ql/src/test/results/clientpositive/input8.q.out
@@ -22,13 +22,21 @@ STAGE PLANS:
                       type: double
                       expr: (null + null)
                       type: tinyint
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToString(0)
+                        type: string
+                        expr: UDFToInteger(1)
+                        type: int
+                        expr: UDFToDouble(2)
+                        type: double
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -37,7 +45,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input9.q.out b/ql/src/test/results/clientpositive/input9.q.out
index cec340f498..df008bd9a8 100644
--- a/ql/src/test/results/clientpositive/input9.q.out
+++ b/ql/src/test/results/clientpositive/input9.q.out
@@ -24,13 +24,19 @@ STAGE PLANS:
                         type: string
                         expr: 0
                         type: string
-                  File Output Operator
-                    compressed: false
-                    table:
-                        input format: org.apache.hadoop.mapred.TextInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                        name: dest1
+                  Select Operator
+                    expressions:
+                          expr: UDFToString(UDFToBoolean(0))
+                          type: string
+                          expr: UDFToInteger(1)
+                          type: int
+                    File Output Operator
+                      compressed: false
+                      table:
+                          input format: org.apache.hadoop.mapred.TextInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                          name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -39,7 +45,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input_part1.q.out b/ql/src/test/results/clientpositive/input_part1.q.out
index fdec91b650..4b51030bbe 100644
--- a/ql/src/test/results/clientpositive/input_part1.q.out
+++ b/ql/src/test/results/clientpositive/input_part1.q.out
@@ -24,29 +24,39 @@ STAGE PLANS:
                       type: string
                       expr: ds
                       type: string
-                File Output Operator
-                  compressed: false
-                  directory: /tmp/hive-jssarma/547047746/265807002.10000.insclause-0
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      properties:
-                        name dest1
-                        serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
-                        serialization.format 1
-                        columns key,value,hr,ds
-                        bucket_count -1
-                        serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                        expr: 2
+                        type: string
+                        expr: 3
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    directory: /tmp/hive-zshao/293656751/393363001.10000.insclause-0
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        properties:
+                          name dest1
+                          serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
+                          serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
+                          columns key,value,hr,ds
+                          bucket_count -1
+                          serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             partition values:
               ds 2008-04-08
@@ -64,7 +74,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: srcpart
 
@@ -72,21 +82,21 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /tmp/hive-jssarma/547047746/265807002.10000.insclause-0
+            source: /tmp/hive-zshao/293656751/393363001.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
                 properties:
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
-                  serialization.format 1
+                  serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
                   columns key,value,hr,ds
                   bucket_count -1
-                  serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input_part2.q.out b/ql/src/test/results/clientpositive/input_part2.q.out
index c442d276dd..c6587ff7e2 100644
--- a/ql/src/test/results/clientpositive/input_part2.q.out
+++ b/ql/src/test/results/clientpositive/input_part2.q.out
@@ -24,24 +24,34 @@ STAGE PLANS:
                       type: string
                       expr: ds
                       type: string
-                File Output Operator
-                  compressed: false
-                  directory: /tmp/hive-jssarma/478508083/234898564.10000.insclause-0
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      properties:
-                        name dest1
-                        serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
-                        serialization.format 1
-                        columns key,value,hr,ds
-                        bucket_count -1
-                        serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                        expr: 2
+                        type: string
+                        expr: 3
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    directory: /tmp/hive-zshao/591856793/204210378.10000.insclause-0
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        properties:
+                          name dest1
+                          serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
+                          serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
+                          columns key,value,hr,ds
+                          bucket_count -1
+                          serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
             Filter Operator
               predicate:
                   expr: (((key < 100) and (ds = '2008-04-09')) and (hr = '12'))
@@ -56,30 +66,40 @@ STAGE PLANS:
                       type: string
                       expr: ds
                       type: string
-                File Output Operator
-                  compressed: false
-                  directory: /tmp/hive-jssarma/478508083/234898564.10001.insclause-1
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      properties:
-                        name dest2
-                        serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
-                        serialization.format 1
-                        columns key,value,hr,ds
-                        bucket_count -1
-                        serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest2
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest2
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                        expr: 2
+                        type: string
+                        expr: 3
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    directory: /tmp/hive-zshao/591856793/204210378.10001.insclause-1
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        properties:
+                          name dest2
+                          serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
+                          serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
+                          columns key,value,hr,ds
+                          bucket_count -1
+                          serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest2
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest2
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             partition values:
               ds 2008-04-08
@@ -97,10 +117,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: srcpart
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             partition values:
               ds 2008-04-09
@@ -118,7 +138,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: srcpart
 
@@ -126,38 +146,38 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /tmp/hive-jssarma/478508083/234898564.10000.insclause-0
+            source: /tmp/hive-zshao/591856793/204210378.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
                 properties:
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
-                  serialization.format 1
+                  serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
                   columns key,value,hr,ds
                   bucket_count -1
-                  serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
             replace: true
-            source: /tmp/hive-jssarma/478508083/234898564.10001.insclause-1
+            source: /tmp/hive-zshao/591856793/204210378.10001.insclause-1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
                 properties:
                   name dest2
                   serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
-                  serialization.format 1
+                  serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
                   columns key,value,hr,ds
                   bucket_count -1
-                  serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest2
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest2
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest2
 
 
diff --git a/ql/src/test/results/clientpositive/input_testsequencefile.q.out b/ql/src/test/results/clientpositive/input_testsequencefile.q.out
index dd33dcc841..5fd7043456 100644
--- a/ql/src/test/results/clientpositive/input_testsequencefile.q.out
+++ b/ql/src/test/results/clientpositive/input_testsequencefile.q.out
@@ -16,13 +16,19 @@ STAGE PLANS:
                     type: string
                     expr: value
                     type: string
-              File Output Operator
-                compressed: false
-                table:
-                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
-                    output format: org.apache.hadoop.mapred.SequenceFileOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    name: dest4_sequencefile
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.mapred.SequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      name: dest4_sequencefile
 
   Stage: Stage-0
     Move Operator
@@ -31,7 +37,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.mapred.SequenceFileOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest4_sequencefile
 
 
diff --git a/ql/src/test/results/clientpositive/input_testxpath.q.out b/ql/src/test/results/clientpositive/input_testxpath.q.out
index def43e944e..7458353abe 100644
--- a/ql/src/test/results/clientpositive/input_testxpath.q.out
+++ b/ql/src/test/results/clientpositive/input_testxpath.q.out
@@ -31,7 +31,7 @@ STAGE PLANS:
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                       name: dest1
 
   Stage: Stage-0
@@ -41,7 +41,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/input_testxpath2.q.out b/ql/src/test/results/clientpositive/input_testxpath2.q.out
index bf1177ba8b..cc0e2cc415 100644
--- a/ql/src/test/results/clientpositive/input_testxpath2.q.out
+++ b/ql/src/test/results/clientpositive/input_testxpath2.q.out
@@ -35,7 +35,7 @@ STAGE PLANS:
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                         name: dest1
 
   Stage: Stage-0
@@ -45,7 +45,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/inputddl4.q.out b/ql/src/test/results/clientpositive/inputddl4.q.out
index 14b10bed1d..2d115bb485 100644
--- a/ql/src/test/results/clientpositive/inputddl4.q.out
+++ b/ql/src/test/results/clientpositive/inputddl4.q.out
@@ -1,4 +1,4 @@
-viewtime	datetime
+viewtime	string
 userid	int
 page_url	string
 referrer_url	string
@@ -7,7 +7,7 @@ properties	map<string,string>
 ip	string	'IP Address of the User'
 ds	datetime
 country	string
-viewtime	datetime
+viewtime	string
 userid	int
 page_url	string
 referrer_url	string
@@ -17,4 +17,4 @@ ip	string	'IP Address of the User'
 ds	datetime
 country	string
 Detailed Table Information:
-Table(tableName:inputddl4,dbName:default,owner:njain,createTime:1225993821,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:viewtime,type:datetime,comment:null), FieldSchema(name:userid,type:int,comment:null), FieldSchema(name:page_url,type:string,comment:null), FieldSchema(name:referrer_url,type:string,comment:null), FieldSchema(name:friends,type:array<bigint>,comment:null), FieldSchema(name:properties,type:map<string,string>,comment:null), FieldSchema(name:ip,type:string,comment:IP Address of the User)],location:file:/home/njain/workspace/hadoop-0.17/build/contrib/hive/ql/test/data/warehouse/inputddl4,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat,compressed:false,numBuckets:32,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,parameters:{serialization.format=1}),bucketCols:[userid],sortCols:[Order(col:viewtime,order:1)],parameters:{}),partitionKeys:[FieldSchema(name:ds,type:datetime,comment:null), FieldSchema(name:country,type:string,comment:null)],parameters:{comment=This is the page view table})
+Table(tableName:inputddl4,dbName:default,owner:zshao,createTime:1229475935,lastAccessTime:0,retention:0,sd:StorageDescriptor(cols:[FieldSchema(name:viewtime,type:string,comment:null), FieldSchema(name:userid,type:int,comment:null), FieldSchema(name:page_url,type:string,comment:null), FieldSchema(name:referrer_url,type:string,comment:null), FieldSchema(name:friends,type:array<bigint>,comment:null), FieldSchema(name:properties,type:map<string,string>,comment:null), FieldSchema(name:ip,type:string,comment:IP Address of the User)],location:file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/inputddl4,inputFormat:org.apache.hadoop.mapred.TextInputFormat,outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat,compressed:false,numBuckets:32,serdeInfo:SerDeInfo(name:null,serializationLib:org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,parameters:{serialization.format=org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol}),bucketCols:[userid],sortCols:[Order(col:viewtime,order:1)],parameters:{}),partitionKeys:[FieldSchema(name:ds,type:datetime,comment:null), FieldSchema(name:country,type:string,comment:null)],parameters:{comment=This is the page view table})
diff --git a/ql/src/test/results/clientpositive/join1.q.out b/ql/src/test/results/clientpositive/join1.q.out
index 55811babd4..a55f0c24df 100644
--- a/ql/src/test/results/clientpositive/join1.q.out
+++ b/ql/src/test/results/clientpositive/join1.q.out
@@ -54,13 +54,19 @@ STAGE PLANS:
                   type: string
                   expr: 2
                   type: string
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest_j1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest_j1
 
   Stage: Stage-0
     Move Operator
@@ -69,7 +75,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest_j1
 
 
diff --git a/ql/src/test/results/clientpositive/join14.q.out b/ql/src/test/results/clientpositive/join14.q.out
index 8c0e80e259..c369c075f5 100644
--- a/ql/src/test/results/clientpositive/join14.q.out
+++ b/ql/src/test/results/clientpositive/join14.q.out
@@ -72,13 +72,19 @@ STAGE PLANS:
                   type: string
                   expr: 2
                   type: string
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -87,7 +93,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/join17.q.out b/ql/src/test/results/clientpositive/join17.q.out
index f77e5369c9..fffde17ba7 100644
--- a/ql/src/test/results/clientpositive/join17.q.out
+++ b/ql/src/test/results/clientpositive/join17.q.out
@@ -41,9 +41,9 @@ STAGE PLANS:
                     type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/src 
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/src 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -57,7 +57,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/src
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/src
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: src
       Reduce Operator Tree:
@@ -77,44 +77,54 @@ STAGE PLANS:
                   type: string
                   expr: 3
                   type: string
-            File Output Operator
-              compressed: false
-              directory: /tmp/hive-jssarma/658145143/35270689.10000.insclause-0
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  properties:
-                    name dest1
-                    serialization.ddl struct dest1 { i32 key1, string value1, i32 key2, string value2}
-                    serialization.format 1
-                    columns key1,value1,key2,value2
-                    bucket_count -1
-                    serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                    file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+                    expr: UDFToInteger(2)
+                    type: int
+                    expr: 3
+                    type: string
+              File Output Operator
+                compressed: false
+                directory: /tmp/hive-zshao/58811470/801571048.10000.insclause-0
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    properties:
+                      name dest1
+                      serialization.ddl struct dest1 { i32 key1, string value1, i32 key2, string value2}
+                      serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
+                      columns key1,value1,key2,value2
+                      bucket_count -1
+                      serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                      file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
       tables:
             replace: true
-            source: /tmp/hive-jssarma/658145143/35270689.10000.insclause-0
+            source: /tmp/hive-zshao/58811470/801571048.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
                 properties:
                   name dest1
                   serialization.ddl struct dest1 { i32 key1, string value1, i32 key2, string value2}
-                  serialization.format 1
+                  serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
                   columns key1,value1,key2,value2
                   bucket_count -1
-                  serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/join18.q.out b/ql/src/test/results/clientpositive/join18.q.out
index d125e6932f..4e14cf447b 100644
--- a/ql/src/test/results/clientpositive/join18.q.out
+++ b/ql/src/test/results/clientpositive/join18.q.out
@@ -46,7 +46,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-njain/73868771/373350713.10002 
+        /tmp/hive-zshao/356667681/95990945.10002 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -66,7 +66,7 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
@@ -191,7 +191,7 @@ STAGE PLANS:
   Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-njain/73868771/373350713.10004 
+        /tmp/hive-zshao/356667681/95990945.10004 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -211,7 +211,7 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
diff --git a/ql/src/test/results/clientpositive/join2.q.out b/ql/src/test/results/clientpositive/join2.q.out
index 8b195f2a9a..8adca7b7bf 100644
--- a/ql/src/test/results/clientpositive/join2.q.out
+++ b/ql/src/test/results/clientpositive/join2.q.out
@@ -104,13 +104,19 @@ STAGE PLANS:
                   type: string
                   expr: 3
                   type: string
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest_j2
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest_j2
 
   Stage: Stage-0
     Move Operator
@@ -119,7 +125,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest_j2
 
 
diff --git a/ql/src/test/results/clientpositive/join3.q.out b/ql/src/test/results/clientpositive/join3.q.out
index e6fd91946d..5b2d4413c7 100644
--- a/ql/src/test/results/clientpositive/join3.q.out
+++ b/ql/src/test/results/clientpositive/join3.q.out
@@ -73,13 +73,19 @@ STAGE PLANS:
                   type: string
                   expr: 3
                   type: string
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: UDFToInteger(0)
+                    type: int
+                    expr: 1
+                    type: string
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -88,7 +94,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/join4.q.out b/ql/src/test/results/clientpositive/join4.q.out
index 7515d40107..b2c35a8ae5 100644
--- a/ql/src/test/results/clientpositive/join4.q.out
+++ b/ql/src/test/results/clientpositive/join4.q.out
@@ -86,13 +86,23 @@ STAGE PLANS:
                     type: string
                     expr: 3
                     type: string
-              File Output Operator
-                compressed: false
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                      expr: UDFToInteger(2)
+                      type: int
+                      expr: 3
+                      type: string
+                File Output Operator
+                  compressed: false
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -101,7 +111,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/join5.q.out b/ql/src/test/results/clientpositive/join5.q.out
index 6ba3877626..47ebc07055 100644
--- a/ql/src/test/results/clientpositive/join5.q.out
+++ b/ql/src/test/results/clientpositive/join5.q.out
@@ -86,13 +86,23 @@ STAGE PLANS:
                     type: string
                     expr: 3
                     type: string
-              File Output Operator
-                compressed: false
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                      expr: UDFToInteger(2)
+                      type: int
+                      expr: 3
+                      type: string
+                File Output Operator
+                  compressed: false
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -101,7 +111,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/join6.q.out b/ql/src/test/results/clientpositive/join6.q.out
index 9d528da3ca..f353424264 100644
--- a/ql/src/test/results/clientpositive/join6.q.out
+++ b/ql/src/test/results/clientpositive/join6.q.out
@@ -86,13 +86,23 @@ STAGE PLANS:
                     type: string
                     expr: 3
                     type: string
-              File Output Operator
-                compressed: false
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                      expr: UDFToInteger(2)
+                      type: int
+                      expr: 3
+                      type: string
+                File Output Operator
+                  compressed: false
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -101,7 +111,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/join7.q.out b/ql/src/test/results/clientpositive/join7.q.out
index 0b22e297d2..a01831f827 100644
--- a/ql/src/test/results/clientpositive/join7.q.out
+++ b/ql/src/test/results/clientpositive/join7.q.out
@@ -121,13 +121,27 @@ STAGE PLANS:
                     type: string
                     expr: 5
                     type: string
-              File Output Operator
-                compressed: false
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                      expr: UDFToInteger(2)
+                      type: int
+                      expr: 3
+                      type: string
+                      expr: UDFToInteger(4)
+                      type: int
+                      expr: 5
+                      type: string
+                File Output Operator
+                  compressed: false
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -136,7 +150,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/join8.q.out b/ql/src/test/results/clientpositive/join8.q.out
index bf6e2ccb51..2c41eebcd9 100644
--- a/ql/src/test/results/clientpositive/join8.q.out
+++ b/ql/src/test/results/clientpositive/join8.q.out
@@ -90,13 +90,23 @@ STAGE PLANS:
                       type: string
                       expr: 3
                       type: string
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                        expr: UDFToInteger(2)
+                        type: int
+                        expr: 3
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -105,7 +115,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/join9.q.out b/ql/src/test/results/clientpositive/join9.q.out
index 4ab3eb6518..559c94d4b6 100644
--- a/ql/src/test/results/clientpositive/join9.q.out
+++ b/ql/src/test/results/clientpositive/join9.q.out
@@ -51,10 +51,10 @@ STAGE PLANS:
                       type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/src 
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/src 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/src 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -68,10 +68,10 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/src
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/src
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: src
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             partition values:
               ds 2008-04-08
@@ -89,7 +89,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: srcpart
       Reduce Operator Tree:
@@ -109,44 +109,50 @@ STAGE PLANS:
                     type: string
                     expr: 4
                     type: string
-              File Output Operator
-                compressed: false
-                directory: /tmp/hive-jssarma/851341425.10000.insclause-0
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    properties:
-                      name dest1
-                      serialization.ddl struct dest1 { i32 key, string value}
-                      serialization.format 1
-                      columns key,value
-                      bucket_count -1
-                      serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                      file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                    serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  directory: /tmp/hive-zshao/1146110304.10000.insclause-0
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      properties:
+                        name dest1
+                        serialization.ddl struct dest1 { i32 key, string value}
+                        serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
+                        columns key,value
+                        bucket_count -1
+                        serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      name: dest1
 
   Stage: Stage-0
     Move Operator
       tables:
             replace: true
-            source: /tmp/hive-jssarma/851341425.10000.insclause-0
+            source: /tmp/hive-zshao/1146110304.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
                 properties:
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
-                  serialization.format 1
+                  serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
                   columns key,value
                   bucket_count -1
-                  serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/mapreduce1.q.out b/ql/src/test/results/clientpositive/mapreduce1.q.out
index ca3273f0ec..97ab7d4850 100644
--- a/ql/src/test/results/clientpositive/mapreduce1.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce1.q.out
@@ -49,13 +49,23 @@ STAGE PLANS:
                         type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: UDFToInteger(1)
+                  type: int
+                  expr: UDFToInteger(2)
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -64,7 +74,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/mapreduce2.q.out b/ql/src/test/results/clientpositive/mapreduce2.q.out
index b91f7b92af..9daa5198f5 100644
--- a/ql/src/test/results/clientpositive/mapreduce2.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce2.q.out
@@ -44,13 +44,23 @@ STAGE PLANS:
                         type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: UDFToInteger(1)
+                  type: int
+                  expr: UDFToInteger(2)
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -59,14 +69,94 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
 0	0	0	val_0
 0	0	0	val_0
 0	0	0	val_0
+2	0	2	val_2
+4	0	4	val_4
+5	0	5	val_5
+5	0	5	val_5
+5	0	5	val_5
+8	0	8	val_8
+9	0	9	val_9
 10	1	0	val_10
+11	1	1	val_11
+12	1	2	val_12
+12	1	2	val_12
+15	1	5	val_15
+15	1	5	val_15
+17	1	7	val_17
+18	1	8	val_18
+18	1	8	val_18
+19	1	9	val_19
+20	2	0	val_20
+24	2	4	val_24
+24	2	4	val_24
+26	2	6	val_26
+26	2	6	val_26
+27	2	7	val_27
+28	2	8	val_28
+30	3	0	val_30
+33	3	3	val_33
+34	3	4	val_34
+35	3	5	val_35
+35	3	5	val_35
+35	3	5	val_35
+37	3	7	val_37
+37	3	7	val_37
+41	4	1	val_41
+42	4	2	val_42
+42	4	2	val_42
+43	4	3	val_43
+44	4	4	val_44
+47	4	7	val_47
+51	5	1	val_51
+51	5	1	val_51
+53	5	3	val_53
+54	5	4	val_54
+57	5	7	val_57
+58	5	8	val_58
+58	5	8	val_58
+64	6	4	val_64
+65	6	5	val_65
+66	6	6	val_66
+67	6	7	val_67
+67	6	7	val_67
+69	6	9	val_69
+70	7	0	val_70
+70	7	0	val_70
+70	7	0	val_70
+72	7	2	val_72
+72	7	2	val_72
+74	7	4	val_74
+76	7	6	val_76
+76	7	6	val_76
+77	7	7	val_77
+78	7	8	val_78
+80	8	0	val_80
+82	8	2	val_82
+83	8	3	val_83
+83	8	3	val_83
+84	8	4	val_84
+84	8	4	val_84
+85	8	5	val_85
+86	8	6	val_86
+87	8	7	val_87
+90	9	0	val_90
+90	9	0	val_90
+90	9	0	val_90
+92	9	2	val_92
+95	9	5	val_95
+95	9	5	val_95
+96	9	6	val_96
+97	9	7	val_97
+97	9	7	val_97
+98	9	8	val_98
+98	9	8	val_98
 100	10	0	val_100
 100	10	0	val_100
 103	10	3	val_103
@@ -74,7 +164,6 @@ STAGE PLANS:
 104	10	4	val_104
 104	10	4	val_104
 105	10	5	val_105
-11	1	1	val_11
 111	11	1	val_111
 113	11	3	val_113
 113	11	3	val_113
@@ -85,8 +174,6 @@ STAGE PLANS:
 119	11	9	val_119
 119	11	9	val_119
 119	11	9	val_119
-12	1	2	val_12
-12	1	2	val_12
 120	12	0	val_120
 120	12	0	val_120
 125	12	5	val_125
@@ -114,8 +201,6 @@ STAGE PLANS:
 146	14	6	val_146
 149	14	9	val_149
 149	14	9	val_149
-15	1	5	val_15
-15	1	5	val_15
 150	15	0	val_150
 152	15	2	val_152
 152	15	2	val_152
@@ -140,7 +225,6 @@ STAGE PLANS:
 169	16	9	val_169
 169	16	9	val_169
 169	16	9	val_169
-17	1	7	val_17
 170	17	0	val_170
 172	17	2	val_172
 172	17	2	val_172
@@ -154,8 +238,6 @@ STAGE PLANS:
 178	17	8	val_178
 179	17	9	val_179
 179	17	9	val_179
-18	1	8	val_18
-18	1	8	val_18
 180	18	0	val_180
 181	18	1	val_181
 183	18	3	val_183
@@ -164,7 +246,6 @@ STAGE PLANS:
 187	18	7	val_187
 187	18	7	val_187
 189	18	9	val_189
-19	1	9	val_19
 190	19	0	val_190
 191	19	1	val_191
 191	19	1	val_191
@@ -181,8 +262,6 @@ STAGE PLANS:
 199	19	9	val_199
 199	19	9	val_199
 199	19	9	val_199
-2	0	2	val_2
-20	2	0	val_20
 200	20	0	val_200
 200	20	0	val_200
 201	20	1	val_201
@@ -233,8 +312,6 @@ STAGE PLANS:
 238	23	8	val_238
 239	23	9	val_239
 239	23	9	val_239
-24	2	4	val_24
-24	2	4	val_24
 241	24	1	val_241
 242	24	2	val_242
 242	24	2	val_242
@@ -249,15 +326,12 @@ STAGE PLANS:
 256	25	6	val_256
 257	25	7	val_257
 258	25	8	val_258
-26	2	6	val_26
-26	2	6	val_26
 260	26	0	val_260
 262	26	2	val_262
 263	26	3	val_263
 265	26	5	val_265
 265	26	5	val_265
 266	26	6	val_266
-27	2	7	val_27
 272	27	2	val_272
 272	27	2	val_272
 273	27	3	val_273
@@ -271,7 +345,6 @@ STAGE PLANS:
 277	27	7	val_277
 278	27	8	val_278
 278	27	8	val_278
-28	2	8	val_28
 280	28	0	val_280
 280	28	0	val_280
 281	28	1	val_281
@@ -292,7 +365,6 @@ STAGE PLANS:
 298	29	8	val_298
 298	29	8	val_298
 298	29	8	val_298
-30	3	0	val_30
 302	30	2	val_302
 305	30	5	val_305
 306	30	6	val_306
@@ -324,7 +396,6 @@ STAGE PLANS:
 327	32	7	val_327
 327	32	7	val_327
 327	32	7	val_327
-33	3	3	val_33
 331	33	1	val_331
 331	33	1	val_331
 332	33	2	val_332
@@ -334,7 +405,6 @@ STAGE PLANS:
 336	33	6	val_336
 338	33	8	val_338
 339	33	9	val_339
-34	3	4	val_34
 341	34	1	val_341
 342	34	2	val_342
 342	34	2	val_342
@@ -346,9 +416,6 @@ STAGE PLANS:
 348	34	8	val_348
 348	34	8	val_348
 348	34	8	val_348
-35	3	5	val_35
-35	3	5	val_35
-35	3	5	val_35
 351	35	1	val_351
 353	35	3	val_353
 353	35	3	val_353
@@ -364,8 +431,6 @@ STAGE PLANS:
 369	36	9	val_369
 369	36	9	val_369
 369	36	9	val_369
-37	3	7	val_37
-37	3	7	val_37
 373	37	3	val_373
 374	37	4	val_374
 375	37	5	val_375
@@ -391,7 +456,6 @@ STAGE PLANS:
 397	39	7	val_397
 399	39	9	val_399
 399	39	9	val_399
-4	0	4	val_4
 400	40	0	val_400
 401	40	1	val_401
 401	40	1	val_401
@@ -412,7 +476,6 @@ STAGE PLANS:
 409	40	9	val_409
 409	40	9	val_409
 409	40	9	val_409
-41	4	1	val_41
 411	41	1	val_411
 413	41	3	val_413
 413	41	3	val_413
@@ -423,15 +486,12 @@ STAGE PLANS:
 417	41	7	val_417
 418	41	8	val_418
 419	41	9	val_419
-42	4	2	val_42
-42	4	2	val_42
 421	42	1	val_421
 424	42	4	val_424
 424	42	4	val_424
 427	42	7	val_427
 429	42	9	val_429
 429	42	9	val_429
-43	4	3	val_43
 430	43	0	val_430
 430	43	0	val_430
 430	43	0	val_430
@@ -447,7 +507,6 @@ STAGE PLANS:
 438	43	8	val_438
 439	43	9	val_439
 439	43	9	val_439
-44	4	4	val_44
 443	44	3	val_443
 444	44	4	val_444
 446	44	6	val_446
@@ -482,7 +541,6 @@ STAGE PLANS:
 469	46	9	val_469
 469	46	9	val_469
 469	46	9	val_469
-47	4	7	val_47
 470	47	0	val_470
 472	47	2	val_472
 475	47	5	val_475
@@ -515,51 +573,3 @@ STAGE PLANS:
 498	49	8	val_498
 498	49	8	val_498
 498	49	8	val_498
-5	0	5	val_5
-5	0	5	val_5
-5	0	5	val_5
-51	5	1	val_51
-51	5	1	val_51
-53	5	3	val_53
-54	5	4	val_54
-57	5	7	val_57
-58	5	8	val_58
-58	5	8	val_58
-64	6	4	val_64
-65	6	5	val_65
-66	6	6	val_66
-67	6	7	val_67
-67	6	7	val_67
-69	6	9	val_69
-70	7	0	val_70
-70	7	0	val_70
-70	7	0	val_70
-72	7	2	val_72
-72	7	2	val_72
-74	7	4	val_74
-76	7	6	val_76
-76	7	6	val_76
-77	7	7	val_77
-78	7	8	val_78
-8	0	8	val_8
-80	8	0	val_80
-82	8	2	val_82
-83	8	3	val_83
-83	8	3	val_83
-84	8	4	val_84
-84	8	4	val_84
-85	8	5	val_85
-86	8	6	val_86
-87	8	7	val_87
-9	0	9	val_9
-90	9	0	val_90
-90	9	0	val_90
-90	9	0	val_90
-92	9	2	val_92
-95	9	5	val_95
-95	9	5	val_95
-96	9	6	val_96
-97	9	7	val_97
-97	9	7	val_97
-98	9	8	val_98
-98	9	8	val_98
diff --git a/ql/src/test/results/clientpositive/mapreduce3.q.out b/ql/src/test/results/clientpositive/mapreduce3.q.out
index 5da98e7525..8cc1191f87 100644
--- a/ql/src/test/results/clientpositive/mapreduce3.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce3.q.out
@@ -44,13 +44,23 @@ STAGE PLANS:
                         type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: UDFToInteger(1)
+                  type: int
+                  expr: UDFToInteger(2)
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -59,7 +69,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/mapreduce4.q.out b/ql/src/test/results/clientpositive/mapreduce4.q.out
index d773c0455a..e022c58bef 100644
--- a/ql/src/test/results/clientpositive/mapreduce4.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce4.q.out
@@ -49,13 +49,23 @@ STAGE PLANS:
                         type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: UDFToInteger(1)
+                  type: int
+                  expr: UDFToInteger(2)
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -64,7 +74,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/mapreduce5.q.out b/ql/src/test/results/clientpositive/mapreduce5.q.out
index c1a867c28a..b4750013b2 100644
--- a/ql/src/test/results/clientpositive/mapreduce5.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce5.q.out
@@ -44,13 +44,23 @@ STAGE PLANS:
                       type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: 1
+                  type: int
+                  expr: 2
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -59,7 +69,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/mapreduce6.q.out b/ql/src/test/results/clientpositive/mapreduce6.q.out
index 12859eef0a..bcbecb97bf 100644
--- a/ql/src/test/results/clientpositive/mapreduce6.q.out
+++ b/ql/src/test/results/clientpositive/mapreduce6.q.out
@@ -44,13 +44,23 @@ STAGE PLANS:
                       type: string
       Reduce Operator Tree:
         Extract
-          File Output Operator
-            compressed: false
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                name: dest1
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(0)
+                  type: int
+                  expr: 1
+                  type: int
+                  expr: 2
+                  type: int
+                  expr: 3
+                  type: string
+            File Output Operator
+              compressed: false
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                  name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -59,7 +69,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/notable_alias1.q.out b/ql/src/test/results/clientpositive/notable_alias1.q.out
index c3dde5e031..c184d06638 100644
--- a/ql/src/test/results/clientpositive/notable_alias1.q.out
+++ b/ql/src/test/results/clientpositive/notable_alias1.q.out
@@ -49,7 +49,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/238416396/213974514.10001 
+        /tmp/hive-zshao/10020404/161743246.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -69,7 +69,7 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: '1234'
@@ -78,13 +78,21 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: string
+                    expr: UDFToInteger(1)
+                    type: int
+                    expr: UDFToDouble(2)
+                    type: double
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -93,64 +101,64 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
-1234	0	3
-1234	10	1
-1234	11	1
-1234	12	2
-1234	15	2
-1234	17	1
-1234	18	2
-1234	19	1
-1234	2	1
-1234	20	1
-1234	24	2
-1234	26	2
-1234	27	1
-1234	28	1
-1234	30	1
-1234	33	1
-1234	34	1
-1234	35	3
-1234	37	2
-1234	4	1
-1234	41	1
-1234	42	2
-1234	43	1
-1234	44	1
-1234	47	1
-1234	5	3
-1234	51	2
-1234	53	1
-1234	54	1
-1234	57	1
-1234	58	2
-1234	64	1
-1234	65	1
-1234	66	1
-1234	67	2
-1234	69	1
-1234	70	3
-1234	72	2
-1234	74	1
-1234	76	2
-1234	77	1
-1234	78	1
-1234	8	1
-1234	80	1
-1234	82	1
-1234	83	2
-1234	84	2
-1234	85	1
-1234	86	1
-1234	87	1
-1234	9	1
-1234	90	3
-1234	92	1
-1234	95	2
-1234	96	1
-1234	97	2
-1234	98	2
+1234	0	3.0
+1234	10	1.0
+1234	11	1.0
+1234	12	2.0
+1234	15	2.0
+1234	17	1.0
+1234	18	2.0
+1234	19	1.0
+1234	2	1.0
+1234	20	1.0
+1234	24	2.0
+1234	26	2.0
+1234	27	1.0
+1234	28	1.0
+1234	30	1.0
+1234	33	1.0
+1234	34	1.0
+1234	35	3.0
+1234	37	2.0
+1234	4	1.0
+1234	41	1.0
+1234	42	2.0
+1234	43	1.0
+1234	44	1.0
+1234	47	1.0
+1234	5	3.0
+1234	51	2.0
+1234	53	1.0
+1234	54	1.0
+1234	57	1.0
+1234	58	2.0
+1234	64	1.0
+1234	65	1.0
+1234	66	1.0
+1234	67	2.0
+1234	69	1.0
+1234	70	3.0
+1234	72	2.0
+1234	74	1.0
+1234	76	2.0
+1234	77	1.0
+1234	78	1.0
+1234	8	1.0
+1234	80	1.0
+1234	82	1.0
+1234	83	2.0
+1234	84	2.0
+1234	85	1.0
+1234	86	1.0
+1234	87	1.0
+1234	9	1.0
+1234	90	3.0
+1234	92	1.0
+1234	95	2.0
+1234	96	1.0
+1234	97	2.0
+1234	98	2.0
diff --git a/ql/src/test/results/clientpositive/notable_alias2.q.out b/ql/src/test/results/clientpositive/notable_alias2.q.out
index 7939c446ac..c30acb922f 100644
--- a/ql/src/test/results/clientpositive/notable_alias2.q.out
+++ b/ql/src/test/results/clientpositive/notable_alias2.q.out
@@ -49,7 +49,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/506681419/141455468.10001 
+        /tmp/hive-zshao/55994326/602553370.10001 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -69,7 +69,7 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: '1234'
@@ -78,13 +78,21 @@ STAGE PLANS:
                   type: string
                   expr: 1
                   type: bigint
-            File Output Operator
-              compressed: false
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                  name: dest1
+            Select Operator
+              expressions:
+                    expr: 0
+                    type: string
+                    expr: UDFToInteger(1)
+                    type: int
+                    expr: UDFToDouble(2)
+                    type: double
+              File Output Operator
+                compressed: false
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                    name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -93,64 +101,64 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
-1234	0	3
-1234	10	1
-1234	11	1
-1234	12	2
-1234	15	2
-1234	17	1
-1234	18	2
-1234	19	1
-1234	2	1
-1234	20	1
-1234	24	2
-1234	26	2
-1234	27	1
-1234	28	1
-1234	30	1
-1234	33	1
-1234	34	1
-1234	35	3
-1234	37	2
-1234	4	1
-1234	41	1
-1234	42	2
-1234	43	1
-1234	44	1
-1234	47	1
-1234	5	3
-1234	51	2
-1234	53	1
-1234	54	1
-1234	57	1
-1234	58	2
-1234	64	1
-1234	65	1
-1234	66	1
-1234	67	2
-1234	69	1
-1234	70	3
-1234	72	2
-1234	74	1
-1234	76	2
-1234	77	1
-1234	78	1
-1234	8	1
-1234	80	1
-1234	82	1
-1234	83	2
-1234	84	2
-1234	85	1
-1234	86	1
-1234	87	1
-1234	9	1
-1234	90	3
-1234	92	1
-1234	95	2
-1234	96	1
-1234	97	2
-1234	98	2
+1234	0	3.0
+1234	10	1.0
+1234	11	1.0
+1234	12	2.0
+1234	15	2.0
+1234	17	1.0
+1234	18	2.0
+1234	19	1.0
+1234	2	1.0
+1234	20	1.0
+1234	24	2.0
+1234	26	2.0
+1234	27	1.0
+1234	28	1.0
+1234	30	1.0
+1234	33	1.0
+1234	34	1.0
+1234	35	3.0
+1234	37	2.0
+1234	4	1.0
+1234	41	1.0
+1234	42	2.0
+1234	43	1.0
+1234	44	1.0
+1234	47	1.0
+1234	5	3.0
+1234	51	2.0
+1234	53	1.0
+1234	54	1.0
+1234	57	1.0
+1234	58	2.0
+1234	64	1.0
+1234	65	1.0
+1234	66	1.0
+1234	67	2.0
+1234	69	1.0
+1234	70	3.0
+1234	72	2.0
+1234	74	1.0
+1234	76	2.0
+1234	77	1.0
+1234	78	1.0
+1234	8	1.0
+1234	80	1.0
+1234	82	1.0
+1234	83	2.0
+1234	84	2.0
+1234	85	1.0
+1234	86	1.0
+1234	87	1.0
+1234	9	1.0
+1234	90	3.0
+1234	92	1.0
+1234	95	2.0
+1234	96	1.0
+1234	97	2.0
+1234	98	2.0
diff --git a/ql/src/test/results/clientpositive/quote1.q.out b/ql/src/test/results/clientpositive/quote1.q.out
index b4d488c763..3728a61e11 100644
--- a/ql/src/test/results/clientpositive/quote1.q.out
+++ b/ql/src/test/results/clientpositive/quote1.q.out
@@ -20,13 +20,19 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
 
   Stage: Stage-0
     Move Operator
@@ -37,7 +43,7 @@ STAGE PLANS:
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
@@ -60,7 +66,7 @@ STAGE PLANS:
               Select Operator
                 expressions:
                       expr: location
-                      type: string
+                      type: int
                       expr: type
                       type: string
                       expr: table
diff --git a/ql/src/test/results/clientpositive/sample1.q.out b/ql/src/test/results/clientpositive/sample1.q.out
index 5b10342ffb..9a6b40ca08 100644
--- a/ql/src/test/results/clientpositive/sample1.q.out
+++ b/ql/src/test/results/clientpositive/sample1.q.out
@@ -28,29 +28,39 @@ STAGE PLANS:
                         type: string
                         expr: hr
                         type: string
-                  File Output Operator
-                    compressed: false
-                    directory: /tmp/hive-jssarma/37742099/114802476.10000.insclause-0
-                    table:
-                        input format: org.apache.hadoop.mapred.TextInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        properties:
-                          name dest1
-                          serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
-                          serialization.format 1
-                          columns key,value,dt,hr
-                          bucket_count -1
-                          serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                          location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                        serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                        name: dest1
+                  Select Operator
+                    expressions:
+                          expr: UDFToInteger(0)
+                          type: int
+                          expr: 1
+                          type: string
+                          expr: 2
+                          type: string
+                          expr: 3
+                          type: string
+                    File Output Operator
+                      compressed: false
+                      directory: /tmp/hive-zshao/860547727/34027035.10000.insclause-0
+                      table:
+                          input format: org.apache.hadoop.mapred.TextInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          properties:
+                            name dest1
+                            serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
+                            serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
+                            columns key,value,dt,hr
+                            bucket_count -1
+                            serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                            file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                            location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                          serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                          name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             partition values:
               ds 2008-04-08
@@ -68,7 +78,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcpart
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcpart
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: srcpart
 
@@ -76,21 +86,21 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /tmp/hive-jssarma/37742099/114802476.10000.insclause-0
+            source: /tmp/hive-zshao/860547727/34027035.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
                 properties:
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
-                  serialization.format 1
+                  serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
                   columns key,value,dt,hr
                   bucket_count -1
-                  serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/sample2.q.out b/ql/src/test/results/clientpositive/sample2.q.out
index d9ce0c10e6..ed96d73b35 100644
--- a/ql/src/test/results/clientpositive/sample2.q.out
+++ b/ql/src/test/results/clientpositive/sample2.q.out
@@ -16,29 +16,35 @@ STAGE PLANS:
                     type: string
                     expr: value
                     type: string
-              File Output Operator
-                compressed: false
-                directory: /tmp/hive-jssarma/515988900/822291761.10000.insclause-0
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    properties:
-                      name dest1
-                      serialization.ddl struct dest1 { i32 key, string value}
-                      serialization.format 1
-                      columns key,value
-                      bucket_count -1
-                      serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                      file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                    serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  directory: /tmp/hive-zshao/427867399/126053246.10000.insclause-0
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      properties:
+                        name dest1
+                        serialization.ddl struct dest1 { i32 key, string value}
+                        serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
+                        columns key,value
+                        bucket_count -1
+                        serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -53,7 +59,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: srcbucket
 
@@ -61,21 +67,21 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /tmp/hive-jssarma/515988900/822291761.10000.insclause-0
+            source: /tmp/hive-zshao/427867399/126053246.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
                 properties:
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
-                  serialization.format 1
+                  serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
                   columns key,value
                   bucket_count -1
-                  serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/sample4.q.out b/ql/src/test/results/clientpositive/sample4.q.out
index c9ca2eb5ad..d8221b4fd6 100644
--- a/ql/src/test/results/clientpositive/sample4.q.out
+++ b/ql/src/test/results/clientpositive/sample4.q.out
@@ -16,29 +16,35 @@ STAGE PLANS:
                     type: string
                     expr: value
                     type: string
-              File Output Operator
-                compressed: false
-                directory: /tmp/hive-jssarma/1539308576/222195283.10000.insclause-0
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                    properties:
-                      name dest1
-                      serialization.ddl struct dest1 { i32 key, string value}
-                      serialization.format 1
-                      columns key,value
-                      bucket_count -1
-                      serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                      file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                    serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                    name: dest1
+              Select Operator
+                expressions:
+                      expr: UDFToInteger(0)
+                      type: int
+                      expr: 1
+                      type: string
+                File Output Operator
+                  compressed: false
+                  directory: /tmp/hive-zshao/134470671/579412318.10000.insclause-0
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                      properties:
+                        name dest1
+                        serialization.ddl struct dest1 { i32 key, string value}
+                        serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
+                        columns key,value
+                        bucket_count -1
+                        serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                      serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                      name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -53,7 +59,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: srcbucket
 
@@ -61,21 +67,21 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /tmp/hive-jssarma/1539308576/222195283.10000.insclause-0
+            source: /tmp/hive-zshao/134470671/579412318.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
                 properties:
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
-                  serialization.format 1
+                  serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
                   columns key,value
                   bucket_count -1
-                  serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/sample5.q.out b/ql/src/test/results/clientpositive/sample5.q.out
index adfeda5a5b..ee76a23099 100644
--- a/ql/src/test/results/clientpositive/sample5.q.out
+++ b/ql/src/test/results/clientpositive/sample5.q.out
@@ -20,29 +20,35 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  directory: /tmp/hive-jssarma/611887541/74229442.10000.insclause-0
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      properties:
-                        name dest1
-                        serialization.ddl struct dest1 { i32 key, string value}
-                        serialization.format 1
-                        columns key,value
-                        bucket_count -1
-                        serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    directory: /tmp/hive-zshao/211838955/159322479.10000.insclause-0
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        properties:
+                          name dest1
+                          serialization.ddl struct dest1 { i32 key, string value}
+                          serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
+                          columns key,value
+                          bucket_count -1
+                          serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket 
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -57,7 +63,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: srcbucket
 
@@ -65,21 +71,21 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /tmp/hive-jssarma/611887541/74229442.10000.insclause-0
+            source: /tmp/hive-zshao/211838955/159322479.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
                 properties:
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
-                  serialization.format 1
+                  serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
                   columns key,value
                   bucket_count -1
-                  serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/sample6.q.out b/ql/src/test/results/clientpositive/sample6.q.out
index 728061238b..6e4b905848 100644
--- a/ql/src/test/results/clientpositive/sample6.q.out
+++ b/ql/src/test/results/clientpositive/sample6.q.out
@@ -20,29 +20,35 @@ STAGE PLANS:
                       type: string
                       expr: value
                       type: string
-                File Output Operator
-                  compressed: false
-                  directory: /tmp/hive-jssarma/862051292/1235999863.10000.insclause-0
-                  table:
-                      input format: org.apache.hadoop.mapred.TextInputFormat
-                      output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                      properties:
-                        name dest1
-                        serialization.ddl struct dest1 { i32 key, string value}
-                        serialization.format 1
-                        columns key,value
-                        bucket_count -1
-                        serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                        file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                      serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                      name: dest1
+                Select Operator
+                  expressions:
+                        expr: UDFToInteger(0)
+                        type: int
+                        expr: 1
+                        type: string
+                  File Output Operator
+                    compressed: false
+                    directory: /tmp/hive-zshao/25298408/261228818.10000.insclause-0
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                        properties:
+                          name dest1
+                          serialization.ddl struct dest1 { i32 key, string value}
+                          serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
+                          columns key,value
+                          bucket_count -1
+                          serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                        serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                        name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -57,7 +63,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: srcbucket
 
@@ -65,21 +71,21 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /tmp/hive-jssarma/862051292/1235999863.10000.insclause-0
+            source: /tmp/hive-zshao/25298408/261228818.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
                 properties:
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
-                  serialization.format 1
+                  serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
                   columns key,value
                   bucket_count -1
-                  serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/sample7.q.out b/ql/src/test/results/clientpositive/sample7.q.out
index 826ff0613c..2355f2c72c 100644
--- a/ql/src/test/results/clientpositive/sample7.q.out
+++ b/ql/src/test/results/clientpositive/sample7.q.out
@@ -24,29 +24,35 @@ STAGE PLANS:
                         type: string
                         expr: value
                         type: string
-                  File Output Operator
-                    compressed: false
-                    directory: /tmp/hive-jssarma/429463772/457590891.10000.insclause-0
-                    table:
-                        input format: org.apache.hadoop.mapred.TextInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                        properties:
-                          name dest1
-                          serialization.ddl struct dest1 { i32 key, string value}
-                          serialization.format 1
-                          columns key,value
-                          bucket_count -1
-                          serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
-                          file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                          location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                        serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
-                        name: dest1
+                  Select Operator
+                    expressions:
+                          expr: UDFToInteger(0)
+                          type: int
+                          expr: 1
+                          type: string
+                    File Output Operator
+                      compressed: false
+                      directory: /tmp/hive-zshao/444520495/211065154.10000.insclause-0
+                      table:
+                          input format: org.apache.hadoop.mapred.TextInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                          properties:
+                            name dest1
+                            serialization.ddl struct dest1 { i32 key, string value}
+                            serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
+                            columns key,value
+                            bucket_count -1
+                            serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                            file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
+                            location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                          serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
+                          name: dest1
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket/kv1.txt 
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket/kv1.txt 
+        file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket/kv1.txt 
           Partition
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -61,7 +67,7 @@ STAGE PLANS:
                 serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/srcbucket
+                location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/srcbucket
               serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
               name: srcbucket
 
@@ -69,21 +75,21 @@ STAGE PLANS:
     Move Operator
       tables:
             replace: true
-            source: /tmp/hive-jssarma/429463772/457590891.10000.insclause-0
+            source: /tmp/hive-zshao/444520495/211065154.10000.insclause-0
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
                 properties:
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
-                  serialization.format 1
+                  serialization.format org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol
                   columns key,value
                   bucket_count -1
-                  serialization.lib org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  serialization.lib org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
-                  location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive-trunk-compress/build/ql/test/data/warehouse/dest1
-                serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
+                  location file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/dest1
+                serde: org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe
                 name: dest1
 
 
diff --git a/ql/src/test/results/clientpositive/subq2.q.out b/ql/src/test/results/clientpositive/subq2.q.out
index 5d8e09aafa..48f0ad9252 100644
--- a/ql/src/test/results/clientpositive/subq2.q.out
+++ b/ql/src/test/results/clientpositive/subq2.q.out
@@ -45,7 +45,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/438302216/1483130688.10002 
+        /tmp/hive-zshao/368989435/823759952.10002 
           Reduce Output Operator
             key expressions:
                   expr: 0
@@ -65,7 +65,7 @@ STAGE PLANS:
           keys:
                 expr: KEY.0
                 type: string
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
diff --git a/ql/src/test/results/clientpositive/udf3.q.out b/ql/src/test/results/clientpositive/udf3.q.out
index 2d28343380..9252d8f5ab 100644
--- a/ql/src/test/results/clientpositive/udf3.q.out
+++ b/ql/src/test/results/clientpositive/udf3.q.out
@@ -40,7 +40,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/1415018212/1021817615.10001 
+        /tmp/hive-zshao/546652046/1647731334.10001 
           Reduce Output Operator
             sort order: 
             tag: -1
@@ -63,7 +63,7 @@ STAGE PLANS:
                 expr: count(VALUE.2)
                 expr: sum(VALUE.3)
                 expr: min(VALUE.4)
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 2
@@ -71,7 +71,7 @@ STAGE PLANS:
                   expr: 3
                   type: double
                   expr: 1
-                  type: string
+                  type: double
                   expr: 4
                   type: double
                   expr: 0
diff --git a/ql/src/test/results/clientpositive/union2.q.out b/ql/src/test/results/clientpositive/union2.q.out
index d42c934abd..3016c28f7b 100644
--- a/ql/src/test/results/clientpositive/union2.q.out
+++ b/ql/src/test/results/clientpositive/union2.q.out
@@ -57,7 +57,7 @@ STAGE PLANS:
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        /tmp/hive-jssarma/32027196/47394207.10002 
+        /tmp/hive-zshao/175321401/121204523.10002 
           Reduce Output Operator
             sort order: 
             tag: -1
@@ -68,7 +68,7 @@ STAGE PLANS:
         Group By Operator
           aggregations:
                 expr: count(VALUE.0)
-          mode: unknown
+          mode: final
           Select Operator
             expressions:
                   expr: 0
diff --git a/ql/src/test/results/compiler/errors/invalid_index.q.out b/ql/src/test/results/compiler/errors/invalid_index.q.out
index fa7e917854..940fb60fec 100644
--- a/ql/src/test/results/compiler/errors/invalid_index.q.out
+++ b/ql/src/test/results/compiler/errors/invalid_index.q.out
@@ -1,2 +1,2 @@
 Semantic Exception: 
-line 2:36 [] not Valid on Non Collection Types 0
\ No newline at end of file
+line 2:36 [] not Valid on Non Collection Types 0: string
\ No newline at end of file
diff --git a/ql/src/test/results/compiler/plan/groupby3.q.xml b/ql/src/test/results/compiler/plan/groupby3.q.xml
index 4b3f68859d..4ec6eea476 100644
--- a/ql/src/test/results/compiler/plan/groupby3.q.xml
+++ b/ql/src/test/results/compiler/plan/groupby3.q.xml
@@ -20,7 +20,7 @@
         <void property="aliasToWork"> 
          <object class="java.util.HashMap"> 
           <void method="put"> 
-           <string>/tmp/hive-njain/332856862/73535516.10002</string> 
+           <string>/tmp/hive-zshao/1268121/343796403.10002</string> 
            <object id="ReduceSinkOperator0" class="org.apache.hadoop.hive.ql.exec.ReduceSinkOperator"> 
             <void property="conf"> 
              <object class="org.apache.hadoop.hive.ql.plan.reduceSinkDesc"> 
@@ -176,7 +176,7 @@
                     <void property="conf"> 
                      <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                       <void property="dirName"> 
-                       <string>/tmp/hive-njain/332856862/73535516.10002</string> 
+                       <string>/tmp/hive-zshao/1268121/343796403.10002</string> 
                       </void> 
                       <void property="tableInfo"> 
                        <object id="tableDesc2" class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -853,10 +853,10 @@
         <void property="pathToAliases"> 
          <object class="java.util.LinkedHashMap"> 
           <void method="put"> 
-           <string>/tmp/hive-njain/332856862/73535516.10002</string> 
+           <string>/tmp/hive-zshao/1268121/343796403.10002</string> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
-             <string>/tmp/hive-njain/332856862/73535516.10002</string> 
+             <string>/tmp/hive-zshao/1268121/343796403.10002</string> 
             </void> 
            </object> 
           </void> 
@@ -865,7 +865,7 @@
         <void property="pathToPartitionInfo"> 
          <object class="java.util.LinkedHashMap"> 
           <void method="put"> 
-           <string>/tmp/hive-njain/332856862/73535516.10002</string> 
+           <string>/tmp/hive-zshao/1268121/343796403.10002</string> 
            <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
             <void property="tableDesc"> 
              <object idref="tableDesc2"/> 
@@ -887,7 +887,7 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.fileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>/tmp/hive-njain/229394155.10001.insclause-0</string> 
+                     <string>/tmp/hive-zshao/147248168.10001.insclause-0</string> 
                     </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.tableDesc"> 
@@ -943,7 +943,7 @@
                          <string>1</string> 
                         </void> 
                         <void property="type"> 
-                         <object idref="PrimitiveTypeInfo0"/> 
+                         <object idref="PrimitiveTypeInfo1"/> 
                         </void> 
                        </object> 
                       </void> 
@@ -953,7 +953,7 @@
                          <string>2</string> 
                         </void> 
                         <void property="type"> 
-                         <object idref="PrimitiveTypeInfo0"/> 
+                         <object idref="PrimitiveTypeInfo1"/> 
                         </void> 
                        </object> 
                       </void> 
@@ -1005,7 +1005,7 @@
                      <string>2</string> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object idref="PrimitiveTypeInfo0"/> 
+                     <object idref="PrimitiveTypeInfo1"/> 
                     </void> 
                    </object> 
                   </void> 
@@ -1015,7 +1015,7 @@
                      <string>0</string> 
                     </void> 
                     <void property="typeInfo"> 
-                     <object idref="PrimitiveTypeInfo0"/> 
+                     <object idref="PrimitiveTypeInfo1"/> 
                     </void> 
                    </object> 
                   </void> 
@@ -1199,7 +1199,7 @@
                  <string>0</string> 
                 </void> 
                 <void property="type"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
+                 <object idref="PrimitiveTypeInfo1"/> 
                 </void> 
                </object> 
               </void> 
@@ -1219,7 +1219,7 @@
                  <string>2</string> 
                 </void> 
                 <void property="type"> 
-                 <object idref="PrimitiveTypeInfo0"/> 
+                 <object idref="PrimitiveTypeInfo1"/> 
                 </void> 
                </object> 
               </void> 
@@ -1281,7 +1281,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/home/njain/workspace/hadoophive/trunk/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -1293,7 +1293,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>file:/home/njain/workspace/hadoophive/trunk/build/ql/test/data/warehouse/src</string> 
+       <string>file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.partitionDesc"> 
         <void property="partSpec"> 
          <object class="java.util.LinkedHashMap"/> 
@@ -1345,7 +1345,7 @@
             </void> 
             <void method="put"> 
              <string>location</string> 
-             <string>file:/home/njain/workspace/hadoophive/trunk/build/ql/test/data/warehouse/src</string> 
+             <string>file:/data/users/zshao/sync/apache-trunk-HIVE-104/build/ql/test/data/warehouse/src</string> 
             </void> 
            </object> 
           </void> 
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/thrift/TCTLSeparatedProtocol.java b/serde/src/java/org/apache/hadoop/hive/serde2/thrift/TCTLSeparatedProtocol.java
index 8ab26c3018..1fc5ef29ac 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/thrift/TCTLSeparatedProtocol.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/thrift/TCTLSeparatedProtocol.java
@@ -266,11 +266,11 @@ public String nextToken() throws EOFException {
    */
 
   public TCTLSeparatedProtocol(TTransport trans) {
-    this(trans, defaultPrimarySeparator, defaultSecondarySeparator, defaultMapSeparator, defaultRowSeparator, false, 4096);
+    this(trans, defaultPrimarySeparator, defaultSecondarySeparator, defaultMapSeparator, defaultRowSeparator, true, 4096);
   }
 
   public TCTLSeparatedProtocol(TTransport trans, int buffer_size) {
-    this(trans, defaultPrimarySeparator, defaultSecondarySeparator, defaultMapSeparator, defaultRowSeparator, false, buffer_size);
+    this(trans, defaultPrimarySeparator, defaultSecondarySeparator, defaultMapSeparator, defaultRowSeparator, true, buffer_size);
   }
 
   /**
@@ -287,8 +287,7 @@ public TCTLSeparatedProtocol(TTransport trans, String primarySeparator, String s
                                int bufferSize) {
     super(trans);
 
-    returnNulls = returnNulls;
-
+    this.returnNulls = returnNulls;
 
     this.primarySeparator = primarySeparator;
     this.secondarySeparator = secondarySeparator;
@@ -702,31 +701,56 @@ public boolean readBool() throws TException {
   public byte readByte() throws TException {
     String val = readString();
     lastPrimitiveWasNullFlag = val == null;
-    return  val == null || val.isEmpty() ? 0 : Byte.valueOf(val).byteValue();
+    try {
+      return val == null || val.isEmpty() ? 0 : Byte.valueOf(val).byteValue();
+    } catch (NumberFormatException e) {
+      lastPrimitiveWasNullFlag = true;
+      return 0;
+    }
   }
 
   public short readI16() throws TException {
     String val = readString();
     lastPrimitiveWasNullFlag = val == null;
-    return val == null || val.isEmpty() ? 0 : Short.valueOf(val).shortValue();
+    try {
+      return val == null || val.isEmpty() ? 0 : Short.valueOf(val).shortValue();
+    } catch (NumberFormatException e) {
+      lastPrimitiveWasNullFlag = true;
+      return 0;
+    }
   }
 
   public int readI32() throws TException {
     String val = readString();
     lastPrimitiveWasNullFlag = val == null;
-    return val == null || val.isEmpty() ? 0 : Integer.valueOf(val).intValue();
+    try {
+      return val == null || val.isEmpty() ? 0 : Integer.valueOf(val).intValue();
+    } catch (NumberFormatException e) {
+      lastPrimitiveWasNullFlag = true;
+      return 0;
+    }
   }
 
   public long readI64() throws TException {
     String val = readString();
     lastPrimitiveWasNullFlag = val == null;
-    return val == null || val.isEmpty() ? 0 : Long.valueOf(val).longValue();
+    try {
+      return val == null || val.isEmpty() ? 0 : Long.valueOf(val).longValue();
+    } catch (NumberFormatException e) {
+      lastPrimitiveWasNullFlag = true;
+      return 0;
+    }
   }
 
   public double readDouble() throws TException {
     String val = readString();
     lastPrimitiveWasNullFlag = val == null;
-    return val == null || val.isEmpty() ? 0 :Double.valueOf(val).doubleValue();
+    try {
+      return val == null || val.isEmpty() ? 0 :Double.valueOf(val).doubleValue();
+    } catch (NumberFormatException e) {
+      lastPrimitiveWasNullFlag = true;
+      return 0;
+    }
   }
 
   public String readString() throws TException {
