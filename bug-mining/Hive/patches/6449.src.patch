diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersTezSessionPoolManager.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersTezSessionPoolManager.java
index 27c5164f22..de0f31e442 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersTezSessionPoolManager.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersTezSessionPoolManager.java
@@ -29,15 +29,12 @@
 import org.apache.hadoop.hive.ql.wm.Expression;
 import org.apache.hadoop.hive.ql.wm.ExpressionFactory;
 import org.apache.hadoop.hive.ql.wm.Trigger;
-import org.apache.hive.common.util.RetryTestRunner;
 import org.junit.Test;
 import com.google.common.collect.Lists;
-import org.junit.runner.RunWith;
 
-@RunWith(RetryTestRunner.class)
 public class TestTriggersTezSessionPoolManager extends AbstractJdbcTriggersTest {
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerSlowQueryElapsedTime() throws Exception {
     Expression expression = ExpressionFactory.fromString("ELAPSED_TIME > 20000");
     Trigger trigger = new ExecutionTrigger("slow_query", expression, new Action(Action.Type.KILL_QUERY));
@@ -47,7 +44,7 @@ public void testTriggerSlowQueryElapsedTime() throws Exception {
     runQueryWithTrigger(query, null, trigger + " violated");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerShortQueryElapsedTime() throws Exception {
     Expression expression = ExpressionFactory.fromString("ELAPSED_TIME > 100");
     Trigger trigger = new ExecutionTrigger("slow_query", expression, new Action(Action.Type.KILL_QUERY));
@@ -57,7 +54,7 @@ public void testTriggerShortQueryElapsedTime() throws Exception {
     runQueryWithTrigger(query, null, trigger + " violated");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerSlowQueryExecutionTime() throws Exception {
     Expression expression = ExpressionFactory.fromString("EXECUTION_TIME > 1000");
     Trigger trigger = new ExecutionTrigger("slow_query", expression, new Action(Action.Type.KILL_QUERY));
@@ -67,7 +64,7 @@ public void testTriggerSlowQueryExecutionTime() throws Exception {
     runQueryWithTrigger(query, null, trigger + " violated");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerHighShuffleBytes() throws Exception {
     Expression expression = ExpressionFactory.fromString("SHUFFLE_BYTES > 100");
     Trigger trigger = new ExecutionTrigger("big_shuffle", expression, new Action(Action.Type.KILL_QUERY));
@@ -82,7 +79,7 @@ public void testTriggerHighShuffleBytes() throws Exception {
     runQueryWithTrigger(query, cmds, trigger + " violated");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerHighBytesRead() throws Exception {
     Expression expression = ExpressionFactory.fromString("HDFS_BYTES_READ > 100");
     Trigger trigger = new ExecutionTrigger("big_read", expression, new Action(Action.Type.KILL_QUERY));
@@ -92,7 +89,7 @@ public void testTriggerHighBytesRead() throws Exception {
     runQueryWithTrigger(query, null, trigger + " violated");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerHighBytesWrite() throws Exception {
     Expression expression = ExpressionFactory.fromString("FILE_BYTES_WRITTEN > 100");
     Trigger trigger = new ExecutionTrigger("big_write", expression, new Action(Action.Type.KILL_QUERY));
@@ -102,7 +99,7 @@ public void testTriggerHighBytesWrite() throws Exception {
     runQueryWithTrigger(query, null, trigger + " violated");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerTotalTasks() throws Exception {
     Expression expression = ExpressionFactory.fromString("VERTEX_TOTAL_TASKS > 50");
     Trigger trigger = new ExecutionTrigger("highly_parallel", expression, new Action(Action.Type.KILL_QUERY));
@@ -112,7 +109,7 @@ public void testTriggerTotalTasks() throws Exception {
     runQueryWithTrigger(query, getConfigs(), trigger + " violated");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerDagTotalTasks() throws Exception {
     Expression expression = ExpressionFactory.fromString("DAG_TOTAL_TASKS > 50");
     Trigger trigger = new ExecutionTrigger("highly_parallel", expression, new Action(Action.Type.KILL_QUERY));
@@ -122,7 +119,7 @@ public void testTriggerDagTotalTasks() throws Exception {
     runQueryWithTrigger(query, getConfigs(), trigger + " violated");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerCustomReadOps() throws Exception {
     Expression expression = ExpressionFactory.fromString("HDFS_READ_OPS > 50");
     Trigger trigger = new ExecutionTrigger("high_read_ops", expression, new Action(Action.Type.KILL_QUERY));
@@ -194,7 +191,7 @@ public void testTriggerCustomCreatedDynamicPartitions() throws Exception {
     runQueryWithTrigger(query, cmds, null);
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerCustomCreatedDynamicPartitionsMultiInsert() throws Exception {
     List<String> cmds = getConfigs();
     cmds.add("drop table src2");
@@ -212,7 +209,7 @@ public void testTriggerCustomCreatedDynamicPartitionsMultiInsert() throws Except
     runQueryWithTrigger(query, cmds, trigger + " violated");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerCustomCreatedDynamicPartitionsUnionAll() throws Exception {
     List<String> cmds = getConfigs();
     cmds.add("drop table src2");
@@ -231,7 +228,7 @@ public void testTriggerCustomCreatedDynamicPartitionsUnionAll() throws Exception
     runQueryWithTrigger(query, cmds, trigger + " violated");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerCustomNonExistent() throws Exception {
     Expression expression = ExpressionFactory.fromString("OPEN_FILES > 50");
     Trigger trigger = new ExecutionTrigger("non_existent", expression, new Action(Action.Type.KILL_QUERY));
@@ -241,7 +238,7 @@ public void testTriggerCustomNonExistent() throws Exception {
     runQueryWithTrigger(query, null, null);
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerDagRawInputSplitsKill() throws Exception {
     // Map 1 - 55 splits
     // Map 3 - 55 splits
@@ -253,7 +250,7 @@ public void testTriggerDagRawInputSplitsKill() throws Exception {
     runQueryWithTrigger(query, getConfigs(), "Query was cancelled");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerVertexRawInputSplitsNoKill() throws Exception {
     // Map 1 - 55 splits
     // Map 3 - 55 splits
@@ -265,7 +262,7 @@ public void testTriggerVertexRawInputSplitsNoKill() throws Exception {
     runQueryWithTrigger(query, getConfigs(), null);
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerVertexRawInputSplitsKill() throws Exception {
     // Map 1 - 55 splits
     // Map 3 - 55 splits
@@ -277,7 +274,7 @@ public void testTriggerVertexRawInputSplitsKill() throws Exception {
     runQueryWithTrigger(query, getConfigs(), "Query was cancelled");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testTriggerDefaultRawInputSplits() throws Exception {
     // Map 1 - 55 splits
     // Map 3 - 55 splits
@@ -289,7 +286,7 @@ public void testTriggerDefaultRawInputSplits() throws Exception {
     runQueryWithTrigger(query, getConfigs(), "Query was cancelled");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testMultipleTriggers1() throws Exception {
     Expression shuffleExpression = ExpressionFactory.fromString("HDFS_BYTES_READ > 1000000");
     Trigger shuffleTrigger = new ExecutionTrigger("big_shuffle", shuffleExpression, new Action(Action.Type.KILL_QUERY));
@@ -301,7 +298,7 @@ public void testMultipleTriggers1() throws Exception {
     runQueryWithTrigger(query, null, execTimeTrigger + " violated");
   }
 
-  @Test(timeout = 60000)
+  @Test(timeout = 120000)
   public void testMultipleTriggers2() throws Exception {
     Expression shuffleExpression = ExpressionFactory.fromString("HDFS_BYTES_READ > 100");
     Trigger shuffleTrigger = new ExecutionTrigger("big_shuffle", shuffleExpression, new Action(Action.Type.KILL_QUERY));
diff --git a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersWorkloadManager.java b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersWorkloadManager.java
index 948d4d6188..85391aca10 100644
--- a/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersWorkloadManager.java
+++ b/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersWorkloadManager.java
@@ -32,15 +32,12 @@
 import org.apache.hadoop.hive.metastore.api.WMResourcePlan;
 import org.apache.hadoop.hive.ql.exec.tez.WorkloadManager;
 import org.apache.hadoop.hive.ql.wm.Trigger;
-import org.apache.hive.common.util.RetryTestRunner;
 import org.apache.hive.jdbc.miniHS2.MiniHS2;
 import org.apache.hive.jdbc.miniHS2.MiniHS2.MiniClusterType;
 import org.junit.BeforeClass;
-import org.junit.runner.RunWith;
 
 import com.google.common.collect.Lists;
 
-@RunWith(RetryTestRunner.class)
 public class TestTriggersWorkloadManager extends TestTriggersTezSessionPoolManager {
 
   @BeforeClass
