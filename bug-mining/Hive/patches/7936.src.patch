diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/functions/HiveSqlAverageAggFunction.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/functions/HiveSqlAverageAggFunction.java
index b6563d9753..361611e9d0 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/functions/HiveSqlAverageAggFunction.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/functions/HiveSqlAverageAggFunction.java
@@ -25,12 +25,13 @@
 import org.apache.calcite.sql.type.SqlOperandTypeChecker;
 import org.apache.calcite.sql.type.SqlOperandTypeInference;
 import org.apache.calcite.sql.type.SqlReturnTypeInference;
+import org.apache.calcite.util.Optionality;
 
-public class HiveSqlAverageAggFunction extends SqlAggFunction {
-  public HiveSqlAverageAggFunction(SqlReturnTypeInference returnTypeInference,
-      SqlOperandTypeInference operandTypeInference, SqlOperandTypeChecker operandTypeChecker
-  )
-  {
+public class HiveSqlAverageAggFunction extends SqlAggFunction implements CanAggregateDistinct {
+  private final boolean isDistinct;
+
+  public HiveSqlAverageAggFunction(boolean isDistinct, SqlReturnTypeInference returnTypeInference,
+      SqlOperandTypeInference operandTypeInference, SqlOperandTypeChecker operandTypeChecker) {
     super(
         "avg",
         null,
@@ -40,7 +41,9 @@ public HiveSqlAverageAggFunction(SqlReturnTypeInference returnTypeInference,
         operandTypeChecker,
         SqlFunctionCategory.NUMERIC,
         false,
-        false);
+        false,
+        Optionality.FORBIDDEN);
+    this.isDistinct = isDistinct;
   }
 
   @Override
@@ -50,4 +53,9 @@ public <T> T unwrap(Class<T> clazz) {
     }
     return super.unwrap(clazz);
   }
+
+  @Override
+  public boolean isDistinct() {
+    return isDistinct;
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java
index 71d993d60c..bfbba92ef3 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java
@@ -276,7 +276,7 @@ public static ASTNode buildAST(SqlOperator op, List<ASTNode> children) {
           // Handle COUNT/SUM/AVG function for the case of COUNT(*) and COUNT(DISTINCT)
           if (op instanceof HiveSqlCountAggFunction ||
               op instanceof HiveSqlSumAggFunction ||
-              (op instanceof CalciteUDAF && op.getName().equalsIgnoreCase(SqlStdOperatorTable.AVG.getName()))) {
+              op instanceof HiveSqlAverageAggFunction) {
             if (children.size() == 0) {
               node = (ASTNode) ParseDriver.adaptor.create(HiveParser.TOK_FUNCTIONSTAR,
                 "TOK_FUNCTIONSTAR");
@@ -634,6 +634,7 @@ public static SqlAggFunction getCalciteAggFn(String hiveUdfName, boolean isDisti
         break;
       case "avg":
         calciteAggFn = new HiveSqlAverageAggFunction(
+            isDistinct,
             udfInfo.returnTypeInference,
             udfInfo.operandTypeInference,
             udfInfo.operandTypeChecker);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java
index 165c06ece0..00d52e369b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java
@@ -2895,6 +2895,7 @@ private boolean validatePTFOperator(PTFOperator op, VectorizationContext vContex
       }
     }
 
+    boolean[] distinctEvaluator = vectorPTFDesc.getEvaluatorsAreDistinct();
     String[] evaluatorFunctionNames = vectorPTFDesc.getEvaluatorFunctionNames();
     final int count = evaluatorFunctionNames.length;
     WindowFrameDef[] evaluatorWindowFrameDefs = vectorPTFDesc.getEvaluatorWindowFrameDefs();
@@ -2907,6 +2908,12 @@ private boolean validatePTFOperator(PTFOperator op, VectorizationContext vContex
         setOperatorIssue(functionName + " not in supported functions " + VectorPTFDesc.supportedFunctionNames);
         return false;
       }
+
+      if (distinctEvaluator[i] && !supportedFunctionType.isSupportDistinct()) {
+        setOperatorIssue(functionName + " distinct is not supported ");
+        return false;
+      }
+
       WindowFrameDef windowFrameDef = evaluatorWindowFrameDefs[i];
       if (!windowFrameDef.isStartUnbounded()) {
         setOperatorIssue(functionName + " only UNBOUNDED start frame is supported");
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
index c04f8d96f7..2c73c7ae13 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
@@ -4908,8 +4908,9 @@ && isRegex(
                     unescapeIdentifier(expr.getChild(0).getChild(0).getText().toLowerCase()),
                     expr, columnList, excludedColumns, inputRR, starRR, pos,
                     outputRR, qb.getAliases(), true);
-          } else if (ParseUtils.containsTokenOfType(expr, HiveParser.TOK_FUNCTIONDI)
-                  && !(srcRel instanceof HiveAggregate ||
+          } else if (ParseUtils.containsTokenOfType(expr, HiveParser.TOK_FUNCTIONDI) &&
+              !ParseUtils.containsTokenOfType(expr, HiveParser.TOK_WINDOWSPEC) &&
+              !(srcRel instanceof HiveAggregate ||
               (srcRel.getInputs().size() == 1 && srcRel.getInput(0) instanceof HiveAggregate))) {
             // Likely a malformed query eg, select hash(distinct c1) from t1;
             throw new CalciteSemanticException("Distinct without an aggregation.",
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/VectorPTFDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/VectorPTFDesc.java
index 3639e276b7..0f0a4fbd30 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/VectorPTFDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/VectorPTFDesc.java
@@ -83,7 +83,7 @@ public class VectorPTFDesc extends AbstractVectorDesc  {
 
   private static final long serialVersionUID = 1L;
 
-  public static enum SupportedFunctionType {
+  public enum SupportedFunctionType {
     ROW_NUMBER,
     RANK,
     DENSE_RANK,
@@ -93,7 +93,21 @@ public static enum SupportedFunctionType {
     AVG,
     FIRST_VALUE,
     LAST_VALUE,
-    COUNT
+    COUNT(true);
+
+    private final boolean supportDistinct;
+
+    SupportedFunctionType() {
+      supportDistinct = false;
+    }
+
+    SupportedFunctionType(boolean supportDistinct) {
+      this.supportDistinct = supportDistinct;
+    }
+
+    public boolean isSupportDistinct() {
+      return supportDistinct;
+    }
   }
 
   public static HashMap<String, SupportedFunctionType> supportedFunctionsMap =
diff --git a/ql/src/test/queries/clientpositive/windowing_distinct.q b/ql/src/test/queries/clientpositive/windowing_distinct.q
index 19042f3dc5..7c39de57ba 100644
--- a/ql/src/test/queries/clientpositive/windowing_distinct.q
+++ b/ql/src/test/queries/clientpositive/windowing_distinct.q
@@ -19,6 +19,27 @@ create table windowing_distinct(
 
 load data local inpath '../../data/files/windowing_distinct.txt' into table windowing_distinct;
 
+EXPLAIN CBO
+SELECT COUNT(DISTINCT t) OVER (PARTITION BY index),
+       COUNT(DISTINCT d) OVER (PARTITION BY index),
+       COUNT(DISTINCT bo) OVER (PARTITION BY index),
+       COUNT(DISTINCT s) OVER (PARTITION BY index),
+       COUNT(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       COUNT(DISTINCT ts) OVER (PARTITION BY index),
+       COUNT(DISTINCT `dec`) OVER (PARTITION BY index),
+       COUNT(DISTINCT bin) OVER (PARTITION BY index)
+FROM windowing_distinct;
+
+EXPLAIN VECTORIZATION
+SELECT COUNT(DISTINCT t) OVER (PARTITION BY index),
+       COUNT(DISTINCT d) OVER (PARTITION BY index),
+       COUNT(DISTINCT bo) OVER (PARTITION BY index),
+       COUNT(DISTINCT s) OVER (PARTITION BY index),
+       COUNT(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       COUNT(DISTINCT ts) OVER (PARTITION BY index),
+       COUNT(DISTINCT `dec`) OVER (PARTITION BY index),
+       COUNT(DISTINCT bin) OVER (PARTITION BY index)
+FROM windowing_distinct;
 
 SELECT COUNT(DISTINCT t) OVER (PARTITION BY index),
        COUNT(DISTINCT d) OVER (PARTITION BY index),
@@ -30,6 +51,17 @@ SELECT COUNT(DISTINCT t) OVER (PARTITION BY index),
        COUNT(DISTINCT bin) OVER (PARTITION BY index)
 FROM windowing_distinct;
 
+
+EXPLAIN CBO
+SELECT SUM(DISTINCT t) OVER (PARTITION BY index),
+       SUM(DISTINCT d) OVER (PARTITION BY index),
+       SUM(DISTINCT s) OVER (PARTITION BY index),
+       SUM(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       SUM(DISTINCT ts) OVER (PARTITION BY index),
+       SUM(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct;
+
+EXPLAIN VECTORIZATION
 SELECT SUM(DISTINCT t) OVER (PARTITION BY index),
        SUM(DISTINCT d) OVER (PARTITION BY index),
        SUM(DISTINCT s) OVER (PARTITION BY index),
@@ -38,6 +70,32 @@ SELECT SUM(DISTINCT t) OVER (PARTITION BY index),
        SUM(DISTINCT `dec`) OVER (PARTITION BY index)
 FROM windowing_distinct;
 
+SELECT SUM(DISTINCT t) OVER (PARTITION BY index),
+       SUM(DISTINCT d) OVER (PARTITION BY index),
+       SUM(DISTINCT s) OVER (PARTITION BY index),
+       SUM(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       SUM(DISTINCT ts) OVER (PARTITION BY index),
+       SUM(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct;
+
+EXPLAIN CBO
+SELECT AVG(DISTINCT t) OVER (PARTITION BY index),
+       AVG(DISTINCT d) OVER (PARTITION BY index),
+       AVG(DISTINCT s) OVER (PARTITION BY index),
+       AVG(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       AVG(DISTINCT ts) OVER (PARTITION BY index),
+       AVG(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct;
+
+EXPLAIN VECTORIZATION
+SELECT AVG(DISTINCT t) OVER (PARTITION BY index),
+       AVG(DISTINCT d) OVER (PARTITION BY index),
+       AVG(DISTINCT s) OVER (PARTITION BY index),
+       AVG(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       AVG(DISTINCT ts) OVER (PARTITION BY index),
+       AVG(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct;
+
 SELECT AVG(DISTINCT t) OVER (PARTITION BY index),
        AVG(DISTINCT d) OVER (PARTITION BY index),
        AVG(DISTINCT s) OVER (PARTITION BY index),
diff --git a/ql/src/test/results/clientpositive/llap/windowing_distinct.q.out b/ql/src/test/results/clientpositive/llap/windowing_distinct.q.out
index 72e9587a60..faca8a2301 100644
--- a/ql/src/test/results/clientpositive/llap/windowing_distinct.q.out
+++ b/ql/src/test/results/clientpositive/llap/windowing_distinct.q.out
@@ -48,6 +48,202 @@ POSTHOOK: query: load data local inpath '../../data/files/windowing_distinct.txt
 POSTHOOK: type: LOAD
 #### A masked pattern was here ####
 POSTHOOK: Output: default@windowing_distinct
+PREHOOK: query: EXPLAIN CBO
+SELECT COUNT(DISTINCT t) OVER (PARTITION BY index),
+       COUNT(DISTINCT d) OVER (PARTITION BY index),
+       COUNT(DISTINCT bo) OVER (PARTITION BY index),
+       COUNT(DISTINCT s) OVER (PARTITION BY index),
+       COUNT(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       COUNT(DISTINCT ts) OVER (PARTITION BY index),
+       COUNT(DISTINCT `dec`) OVER (PARTITION BY index),
+       COUNT(DISTINCT bin) OVER (PARTITION BY index)
+FROM windowing_distinct
+PREHOOK: type: QUERY
+PREHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+POSTHOOK: query: EXPLAIN CBO
+SELECT COUNT(DISTINCT t) OVER (PARTITION BY index),
+       COUNT(DISTINCT d) OVER (PARTITION BY index),
+       COUNT(DISTINCT bo) OVER (PARTITION BY index),
+       COUNT(DISTINCT s) OVER (PARTITION BY index),
+       COUNT(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       COUNT(DISTINCT ts) OVER (PARTITION BY index),
+       COUNT(DISTINCT `dec`) OVER (PARTITION BY index),
+       COUNT(DISTINCT bin) OVER (PARTITION BY index)
+FROM windowing_distinct
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(COUNT_window_0=[count(DISTINCT $1) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], COUNT_window_1=[count(DISTINCT $6) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], COUNT_window_2=[count(DISTINCT $7) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], COUNT_window_3=[count(DISTINCT $8) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], _o__col21=[count(DISTINCT ||(_UTF-16LE'Mr.':VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $8)) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], COUNT_window_5=[count(DISTINCT $9) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], COUNT_window_6=[count(DISTINCT $10) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], COUNT_window_7=[count(DISTINCT $11) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)])
+  HiveTableScan(table=[[default, windowing_distinct]], table:alias=[windowing_distinct])
+
+PREHOOK: query: EXPLAIN VECTORIZATION
+SELECT COUNT(DISTINCT t) OVER (PARTITION BY index),
+       COUNT(DISTINCT d) OVER (PARTITION BY index),
+       COUNT(DISTINCT bo) OVER (PARTITION BY index),
+       COUNT(DISTINCT s) OVER (PARTITION BY index),
+       COUNT(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       COUNT(DISTINCT ts) OVER (PARTITION BY index),
+       COUNT(DISTINCT `dec`) OVER (PARTITION BY index),
+       COUNT(DISTINCT bin) OVER (PARTITION BY index)
+FROM windowing_distinct
+PREHOOK: type: QUERY
+PREHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+POSTHOOK: query: EXPLAIN VECTORIZATION
+SELECT COUNT(DISTINCT t) OVER (PARTITION BY index),
+       COUNT(DISTINCT d) OVER (PARTITION BY index),
+       COUNT(DISTINCT bo) OVER (PARTITION BY index),
+       COUNT(DISTINCT s) OVER (PARTITION BY index),
+       COUNT(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       COUNT(DISTINCT ts) OVER (PARTITION BY index),
+       COUNT(DISTINCT `dec`) OVER (PARTITION BY index),
+       COUNT(DISTINCT bin) OVER (PARTITION BY index)
+FROM windowing_distinct
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+PLAN VECTORIZATION:
+  enabled: true
+  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+#### A masked pattern was here ####
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: windowing_distinct
+                  Statistics: Num rows: 1 Data size: 500 Basic stats: COMPLETE Column stats: NONE
+                  Reduce Output Operator
+                    key expressions: index (type: int)
+                    null sort order: a
+                    sort order: +
+                    Map-reduce partition columns: index (type: int)
+                    Statistics: Num rows: 1 Data size: 500 Basic stats: COMPLETE Column stats: NONE
+                    value expressions: t (type: tinyint), d (type: double), bo (type: boolean), s (type: string), ts (type: timestamp), dec (type: decimal(10,0)), bin (type: binary)
+            Execution mode: vectorized, llap
+            LLAP IO: all inputs
+            Map Vectorization:
+                enabled: true
+                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
+                inputFormatFeatureSupport: [DECIMAL_64]
+                featureSupportInUse: [DECIMAL_64]
+                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
+                allNative: true
+                usesVectorUDFAdaptor: false
+                vectorized: true
+        Reducer 2 
+            Execution mode: vectorized, llap
+            Reduce Vectorization:
+                enabled: true
+                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
+                allNative: false
+                usesVectorUDFAdaptor: false
+                vectorized: true
+            Reduce Operator Tree:
+              Select Operator
+                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: tinyint), VALUE._col5 (type: double), VALUE._col6 (type: boolean), VALUE._col7 (type: string), VALUE._col8 (type: timestamp), VALUE._col9 (type: decimal(10,0)), VALUE._col10 (type: binary)
+                outputColumnNames: _col0, _col1, _col6, _col7, _col8, _col9, _col10, _col11
+                Statistics: Num rows: 1 Data size: 500 Basic stats: COMPLETE Column stats: NONE
+                PTF Operator
+                  Function definitions:
+                      Input definition
+                        input alias: ptf_0
+                        output shape: _col0: int, _col1: tinyint, _col6: double, _col7: boolean, _col8: string, _col9: timestamp, _col10: decimal(10,0), _col11: binary
+                        type: WINDOWING
+                      Windowing table definition
+                        input alias: ptf_1
+                        name: windowingtablefunction
+                        order by: _col0 ASC NULLS FIRST
+                        partition by: _col0
+                        raw input shape:
+                        window functions:
+                            window function definition
+                              alias: count_window_0
+                              arguments: _col1
+                              name: count
+                              window function: GenericUDAFCountEvaluator
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: count_window_1
+                              arguments: _col6
+                              name: count
+                              window function: GenericUDAFCountEvaluator
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: count_window_2
+                              arguments: _col7
+                              name: count
+                              window function: GenericUDAFCountEvaluator
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: count_window_3
+                              arguments: _col8
+                              name: count
+                              window function: GenericUDAFCountEvaluator
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: count_window_4
+                              arguments: concat('Mr.', _col8)
+                              name: count
+                              window function: GenericUDAFCountEvaluator
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: count_window_5
+                              arguments: _col9
+                              name: count
+                              window function: GenericUDAFCountEvaluator
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: count_window_6
+                              arguments: _col10
+                              name: count
+                              window function: GenericUDAFCountEvaluator
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: count_window_7
+                              arguments: _col11
+                              name: count
+                              window function: GenericUDAFCountEvaluator
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                  Statistics: Num rows: 1 Data size: 500 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: count_window_0 (type: bigint), count_window_1 (type: bigint), count_window_2 (type: bigint), count_window_3 (type: bigint), count_window_4 (type: bigint), count_window_5 (type: bigint), count_window_6 (type: bigint), count_window_7 (type: bigint)
+                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
+                    Statistics: Num rows: 1 Data size: 500 Basic stats: COMPLETE Column stats: NONE
+                    File Output Operator
+                      compressed: false
+                      Statistics: Num rows: 1 Data size: 500 Basic stats: COMPLETE Column stats: NONE
+                      table:
+                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
 PREHOOK: query: SELECT COUNT(DISTINCT t) OVER (PARTITION BY index),
        COUNT(DISTINCT d) OVER (PARTITION BY index),
        COUNT(DISTINCT bo) OVER (PARTITION BY index),
@@ -78,6 +274,179 @@ POSTHOOK: Input: default@windowing_distinct
 2	2	2	2	2	2	2	2
 2	2	2	2	2	2	2	2
 2	2	2	2	2	2	2	2
+PREHOOK: query: EXPLAIN CBO
+SELECT SUM(DISTINCT t) OVER (PARTITION BY index),
+       SUM(DISTINCT d) OVER (PARTITION BY index),
+       SUM(DISTINCT s) OVER (PARTITION BY index),
+       SUM(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       SUM(DISTINCT ts) OVER (PARTITION BY index),
+       SUM(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct
+PREHOOK: type: QUERY
+PREHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+POSTHOOK: query: EXPLAIN CBO
+SELECT SUM(DISTINCT t) OVER (PARTITION BY index),
+       SUM(DISTINCT d) OVER (PARTITION BY index),
+       SUM(DISTINCT s) OVER (PARTITION BY index),
+       SUM(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       SUM(DISTINCT ts) OVER (PARTITION BY index),
+       SUM(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(SUM_window_0=[sum(DISTINCT $1) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], SUM_window_1=[sum(DISTINCT $6) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], SUM_window_2=[sum(DISTINCT $8) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], _o__col20=[sum(DISTINCT ||(_UTF-16LE'Mr.':VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $8)) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], SUM_window_4=[sum(DISTINCT $9) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], SUM_window_5=[sum(DISTINCT $10) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)])
+  HiveTableScan(table=[[default, windowing_distinct]], table:alias=[windowing_distinct])
+
+PREHOOK: query: EXPLAIN VECTORIZATION
+SELECT SUM(DISTINCT t) OVER (PARTITION BY index),
+       SUM(DISTINCT d) OVER (PARTITION BY index),
+       SUM(DISTINCT s) OVER (PARTITION BY index),
+       SUM(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       SUM(DISTINCT ts) OVER (PARTITION BY index),
+       SUM(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct
+PREHOOK: type: QUERY
+PREHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+POSTHOOK: query: EXPLAIN VECTORIZATION
+SELECT SUM(DISTINCT t) OVER (PARTITION BY index),
+       SUM(DISTINCT d) OVER (PARTITION BY index),
+       SUM(DISTINCT s) OVER (PARTITION BY index),
+       SUM(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       SUM(DISTINCT ts) OVER (PARTITION BY index),
+       SUM(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+PLAN VECTORIZATION:
+  enabled: true
+  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+#### A masked pattern was here ####
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: windowing_distinct
+                  Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                  Reduce Output Operator
+                    key expressions: index (type: int)
+                    null sort order: a
+                    sort order: +
+                    Map-reduce partition columns: index (type: int)
+                    Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                    value expressions: t (type: tinyint), d (type: double), s (type: string), ts (type: timestamp), dec (type: decimal(10,0))
+            Execution mode: vectorized, llap
+            LLAP IO: all inputs
+            Map Vectorization:
+                enabled: true
+                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
+                inputFormatFeatureSupport: [DECIMAL_64]
+                featureSupportInUse: [DECIMAL_64]
+                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
+                allNative: true
+                usesVectorUDFAdaptor: false
+                vectorized: true
+        Reducer 2 
+            Execution mode: llap
+            Reduce Vectorization:
+                enabled: true
+                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
+                notVectorizedReason: PTF operator: sum distinct is not supported 
+                vectorized: false
+            Reduce Operator Tree:
+              Select Operator
+                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: tinyint), VALUE._col5 (type: double), VALUE._col7 (type: string), VALUE._col8 (type: timestamp), VALUE._col9 (type: decimal(10,0))
+                outputColumnNames: _col0, _col1, _col6, _col8, _col9, _col10
+                Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                PTF Operator
+                  Function definitions:
+                      Input definition
+                        input alias: ptf_0
+                        output shape: _col0: int, _col1: tinyint, _col6: double, _col8: string, _col9: timestamp, _col10: decimal(10,0)
+                        type: WINDOWING
+                      Windowing table definition
+                        input alias: ptf_1
+                        name: windowingtablefunction
+                        order by: _col0 ASC NULLS FIRST
+                        partition by: _col0
+                        raw input shape:
+                        window functions:
+                            window function definition
+                              alias: sum_window_0
+                              arguments: _col1
+                              name: sum
+                              window function: GenericUDAFSumLong
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: sum_window_1
+                              arguments: _col6
+                              name: sum
+                              window function: GenericUDAFSumDouble
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: sum_window_2
+                              arguments: _col8
+                              name: sum
+                              window function: GenericUDAFSumDouble
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: sum_window_3
+                              arguments: concat('Mr.', _col8)
+                              name: sum
+                              window function: GenericUDAFSumDouble
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: sum_window_4
+                              arguments: _col9
+                              name: sum
+                              window function: GenericUDAFSumDouble
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: sum_window_5
+                              arguments: _col10
+                              name: sum
+                              window function: GenericUDAFSumHiveDecimal
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                  Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: sum_window_0 (type: bigint), sum_window_1 (type: double), sum_window_2 (type: double), sum_window_3 (type: double), sum_window_4 (type: double), sum_window_5 (type: decimal(20,0))
+                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
+                    Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                    File Output Operator
+                      compressed: false
+                      Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                      table:
+                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
 PREHOOK: query: SELECT SUM(DISTINCT t) OVER (PARTITION BY index),
        SUM(DISTINCT d) OVER (PARTITION BY index),
        SUM(DISTINCT s) OVER (PARTITION BY index),
@@ -104,6 +473,179 @@ POSTHOOK: Input: default@windowing_distinct
 235	77.42	0.0	0.0	2.724258237406612E9	69
 235	77.42	0.0	0.0	2.724258237406612E9	69
 235	77.42	0.0	0.0	2.724258237406612E9	69
+PREHOOK: query: EXPLAIN CBO
+SELECT AVG(DISTINCT t) OVER (PARTITION BY index),
+       AVG(DISTINCT d) OVER (PARTITION BY index),
+       AVG(DISTINCT s) OVER (PARTITION BY index),
+       AVG(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       AVG(DISTINCT ts) OVER (PARTITION BY index),
+       AVG(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct
+PREHOOK: type: QUERY
+PREHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+POSTHOOK: query: EXPLAIN CBO
+SELECT AVG(DISTINCT t) OVER (PARTITION BY index),
+       AVG(DISTINCT d) OVER (PARTITION BY index),
+       AVG(DISTINCT s) OVER (PARTITION BY index),
+       AVG(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       AVG(DISTINCT ts) OVER (PARTITION BY index),
+       AVG(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+CBO PLAN:
+HiveProject(AVG_window_0=[avg(DISTINCT $1) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], AVG_window_1=[avg(DISTINCT $6) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], AVG_window_2=[avg(DISTINCT $8) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], _o__col20=[avg(DISTINCT ||(_UTF-16LE'Mr.':VARCHAR(2147483647) CHARACTER SET "UTF-16LE", $8)) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], AVG_window_4=[avg(DISTINCT $9) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)], AVG_window_5=[avg(DISTINCT $10) OVER (PARTITION BY $0 ORDER BY $0 NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)])
+  HiveTableScan(table=[[default, windowing_distinct]], table:alias=[windowing_distinct])
+
+PREHOOK: query: EXPLAIN VECTORIZATION
+SELECT AVG(DISTINCT t) OVER (PARTITION BY index),
+       AVG(DISTINCT d) OVER (PARTITION BY index),
+       AVG(DISTINCT s) OVER (PARTITION BY index),
+       AVG(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       AVG(DISTINCT ts) OVER (PARTITION BY index),
+       AVG(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct
+PREHOOK: type: QUERY
+PREHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+POSTHOOK: query: EXPLAIN VECTORIZATION
+SELECT AVG(DISTINCT t) OVER (PARTITION BY index),
+       AVG(DISTINCT d) OVER (PARTITION BY index),
+       AVG(DISTINCT s) OVER (PARTITION BY index),
+       AVG(DISTINCT concat('Mr.', s)) OVER (PARTITION BY index),
+       AVG(DISTINCT ts) OVER (PARTITION BY index),
+       AVG(DISTINCT `dec`) OVER (PARTITION BY index)
+FROM windowing_distinct
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@windowing_distinct
+#### A masked pattern was here ####
+PLAN VECTORIZATION:
+  enabled: true
+  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+#### A masked pattern was here ####
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: windowing_distinct
+                  Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                  Reduce Output Operator
+                    key expressions: index (type: int)
+                    null sort order: a
+                    sort order: +
+                    Map-reduce partition columns: index (type: int)
+                    Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                    value expressions: t (type: tinyint), d (type: double), s (type: string), ts (type: timestamp), dec (type: decimal(10,0))
+            Execution mode: vectorized, llap
+            LLAP IO: all inputs
+            Map Vectorization:
+                enabled: true
+                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
+                inputFormatFeatureSupport: [DECIMAL_64]
+                featureSupportInUse: [DECIMAL_64]
+                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
+                allNative: true
+                usesVectorUDFAdaptor: false
+                vectorized: true
+        Reducer 2 
+            Execution mode: llap
+            Reduce Vectorization:
+                enabled: true
+                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
+                notVectorizedReason: PTF operator: avg distinct is not supported 
+                vectorized: false
+            Reduce Operator Tree:
+              Select Operator
+                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: tinyint), VALUE._col5 (type: double), VALUE._col7 (type: string), VALUE._col8 (type: timestamp), VALUE._col9 (type: decimal(10,0))
+                outputColumnNames: _col0, _col1, _col6, _col8, _col9, _col10
+                Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                PTF Operator
+                  Function definitions:
+                      Input definition
+                        input alias: ptf_0
+                        output shape: _col0: int, _col1: tinyint, _col6: double, _col8: string, _col9: timestamp, _col10: decimal(10,0)
+                        type: WINDOWING
+                      Windowing table definition
+                        input alias: ptf_1
+                        name: windowingtablefunction
+                        order by: _col0 ASC NULLS FIRST
+                        partition by: _col0
+                        raw input shape:
+                        window functions:
+                            window function definition
+                              alias: avg_window_0
+                              arguments: _col1
+                              name: avg
+                              window function: GenericUDAFAverageEvaluatorDouble
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: avg_window_1
+                              arguments: _col6
+                              name: avg
+                              window function: GenericUDAFAverageEvaluatorDouble
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: avg_window_2
+                              arguments: _col8
+                              name: avg
+                              window function: GenericUDAFAverageEvaluatorDouble
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: avg_window_3
+                              arguments: concat('Mr.', _col8)
+                              name: avg
+                              window function: GenericUDAFAverageEvaluatorDouble
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: avg_window_4
+                              arguments: _col9
+                              name: avg
+                              window function: GenericUDAFAverageEvaluatorDouble
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                            window function definition
+                              alias: avg_window_5
+                              arguments: _col10
+                              name: avg
+                              window function: GenericUDAFAverageEvaluatorDecimal
+                              window frame: ROWS PRECEDING(MAX)~FOLLOWING(MAX)
+                              isDistinct: true
+                  Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                  Select Operator
+                    expressions: avg_window_0 (type: double), avg_window_1 (type: double), avg_window_2 (type: double), avg_window_3 (type: double), avg_window_4 (type: double), avg_window_5 (type: decimal(14,4))
+                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
+                    Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                    File Output Operator
+                      compressed: false
+                      Statistics: Num rows: 1 Data size: 352 Basic stats: COMPLETE Column stats: NONE
+                      table:
+                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
 PREHOOK: query: SELECT AVG(DISTINCT t) OVER (PARTITION BY index),
        AVG(DISTINCT d) OVER (PARTITION BY index),
        AVG(DISTINCT s) OVER (PARTITION BY index),
