diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
index 32c2fb06a5..5e5cf97c7b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
@@ -242,7 +242,7 @@ public static void clearWork(Configuration conf) {
     Path reducePath = getPlanPath(conf, REDUCE_PLAN_NAME);
 
     // if the plan path hasn't been initialized just return, nothing to clean.
-    if (mapPath == null || reducePath == null) {
+    if (mapPath == null && reducePath == null) {
       return;
     }
 
@@ -260,12 +260,7 @@ public static void clearWork(Configuration conf) {
     } finally {
       // where a single process works with multiple plans - we must clear
       // the cache before working with the next plan.
-      if (mapPath != null) {
-        gWorkMap.remove(mapPath);
-      }
-      if (reducePath != null) {
-        gWorkMap.remove(reducePath);
-      }
+      clearWorkMapForConf(conf);
     }
   }
 
@@ -3314,7 +3309,19 @@ public static boolean isVectorMode(Configuration conf) {
     return false;
   }
 
-    public static void clearWorkMap() {
+  public static void clearWorkMapForConf(Configuration conf) {
+    // Remove cached query plans for the current query only
+    Path mapPath = getPlanPath(conf, MAP_PLAN_NAME);
+    Path reducePath = getPlanPath(conf, REDUCE_PLAN_NAME);
+    if (mapPath != null) {
+      gWorkMap.remove(mapPath);
+    }
+    if (reducePath != null) {
+      gWorkMap.remove(reducePath);
+    }
+  }
+
+  public static void clearWorkMap() {
     gWorkMap.clear();
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java b/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java
index 7ba58b936a..61cc874dfe 100755
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java
@@ -393,7 +393,7 @@ public InputSplit[] getSplits(JobConf job, int numSplits) throws IOException {
           currentTable, result);
     }
 
-    Utilities.clearWorkMap();
+    Utilities.clearWorkMapForConf(job);
     LOG.info("number of splits " + result.size());
     perfLogger.PerfLogEnd(CLASS_NAME, PerfLogger.GET_SPLITS);
     return result.toArray(new HiveInputSplit[result.size()]);
