diff --git a/data/files/map_null_schema.avro b/data/files/map_null_schema.avro
new file mode 100644
index 0000000000..d8ceaa7a10
--- /dev/null
+++ b/data/files/map_null_schema.avro
@@ -0,0 +1 @@
+{"type":"record","name":"dku_record_0","namespace":"com.dataiku.dss","doc":"","fields":[{"name":"avreau_col_1","type":["null",{"type":"map","values":["null","string"]}],"default":null}]}
diff --git a/data/files/map_null_val.avro b/data/files/map_null_val.avro
new file mode 100644
index 0000000000..0d89d89cf3
Binary files /dev/null and b/data/files/map_null_val.avro differ
diff --git a/ql/src/test/queries/clientpositive/avro_deserialize_map_null.q b/ql/src/test/queries/clientpositive/avro_deserialize_map_null.q
new file mode 100644
index 0000000000..fa170db53f
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/avro_deserialize_map_null.q
@@ -0,0 +1,14 @@
+-- These test attempts to deserialize an Avro file that contains map null values, and the file schema
+-- vs record schema have the null values in different positions
+-- i.e.
+-- fileSchema   = [{ "type" : "map", "values" : ["string","null"]}, "null"]
+-- recordSchema = ["null", { "type" : "map", "values" : ["string","null"]}]
+
+
+DROP TABLE IF EXISTS avro_table;
+
+CREATE TABLE avro_table (avreau_col_1 map<string,string>) STORED AS AVRO;
+LOAD DATA LOCAL INPATH '../../data/files/map_null_val.avro' OVERWRITE INTO TABLE avro_table;
+SELECT * FROM avro_table;
+
+DROP TABLE avro_table;
\ No newline at end of file
diff --git a/ql/src/test/results/clientpositive/avro_deserialize_map_null.q.out b/ql/src/test/results/clientpositive/avro_deserialize_map_null.q.out
new file mode 100644
index 0000000000..de79d6228f
--- /dev/null
+++ b/ql/src/test/results/clientpositive/avro_deserialize_map_null.q.out
@@ -0,0 +1,55 @@
+PREHOOK: query: -- These test attempts to deserialize an Avro file that contains map null values, and the file schema
+-- vs record schema have the null values in different positions
+-- i.e.
+-- fileSchema   = [{ "type" : "map", "values" : ["string","null"]}, "null"]
+-- recordSchema = ["null", { "type" : "map", "values" : ["string","null"]}]
+
+
+DROP TABLE IF EXISTS avro_table
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: -- These test attempts to deserialize an Avro file that contains map null values, and the file schema
+-- vs record schema have the null values in different positions
+-- i.e.
+-- fileSchema   = [{ "type" : "map", "values" : ["string","null"]}, "null"]
+-- recordSchema = ["null", { "type" : "map", "values" : ["string","null"]}]
+
+
+DROP TABLE IF EXISTS avro_table
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: CREATE TABLE avro_table (avreau_col_1 map<string,string>) STORED AS AVRO
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@avro_table
+POSTHOOK: query: CREATE TABLE avro_table (avreau_col_1 map<string,string>) STORED AS AVRO
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@avro_table
+PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/map_null_val.avro' OVERWRITE INTO TABLE avro_table
+PREHOOK: type: LOAD
+#### A masked pattern was here ####
+PREHOOK: Output: default@avro_table
+POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/map_null_val.avro' OVERWRITE INTO TABLE avro_table
+POSTHOOK: type: LOAD
+#### A masked pattern was here ####
+POSTHOOK: Output: default@avro_table
+PREHOOK: query: SELECT * FROM avro_table
+PREHOOK: type: QUERY
+PREHOOK: Input: default@avro_table
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT * FROM avro_table
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@avro_table
+#### A masked pattern was here ####
+{"key4":null,"key3":"val3"}
+{"key4":null,"key3":"val3"}
+{"key2":"val2","key1":null}
+{"key4":null,"key3":"val3"}
+{"key4":null,"key3":"val3"}
+PREHOOK: query: DROP TABLE avro_table
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@avro_table
+PREHOOK: Output: default@avro_table
+POSTHOOK: query: DROP TABLE avro_table
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@avro_table
+POSTHOOK: Output: default@avro_table
diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java b/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java
index 50c14e244a..07c5ecf081 100644
--- a/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java
+++ b/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java
@@ -200,7 +200,7 @@ private Object worker(Object datum, Schema fileSchema, Schema recordSchema, Type
     // Avro requires NULLable types to be defined as unions of some type T
     // and NULL.  This is annoying and we're going to hide it from the user.
     if(AvroSerdeUtils.isNullableType(recordSchema)) {
-      return deserializeNullableUnion(datum, fileSchema, recordSchema, columnType);
+      return deserializeNullableUnion(datum, fileSchema, recordSchema);
     }
 
     switch(columnType.getCategory()) {
@@ -296,8 +296,8 @@ private Object deserializePrimitive(Object datum, Schema fileSchema, Schema reco
    * Extract either a null or the correct type from a Nullable type.  This is
    * horrible in that we rebuild the TypeInfo every time.
    */
-  private Object deserializeNullableUnion(Object datum, Schema fileSchema, Schema recordSchema,
-                                          TypeInfo columnType) throws AvroSerdeException {
+  private Object deserializeNullableUnion(Object datum, Schema fileSchema, Schema recordSchema)
+                                            throws AvroSerdeException {
     int tag = GenericData.get().resolveUnion(recordSchema, datum); // Determine index of value
     Schema schema = recordSchema.getTypes().get(tag);
     if (schema.getType().equals(Schema.Type.NULL)) {
@@ -306,8 +306,14 @@ private Object deserializeNullableUnion(Object datum, Schema fileSchema, Schema
 
     Schema currentFileSchema = null;
     if (fileSchema != null) {
-       currentFileSchema =
-           fileSchema.getType() == Type.UNION ? fileSchema.getTypes().get(tag) : fileSchema;
+      if (fileSchema.getType() == Type.UNION) {
+        // The fileSchema may have the null value in a different position, so
+        // we need to get the correct tag
+        tag = GenericData.get().resolveUnion(fileSchema, datum);
+        currentFileSchema = fileSchema.getTypes().get(tag);
+      } else {
+        currentFileSchema = fileSchema;
+      }
     }
     return worker(datum, currentFileSchema, schema, SchemaToTypeInfo.generateTypeInfo(schema));
 
