diff --git a/ql/src/java/org/apache/hadoop/hive/ql/QueryProperties.java b/ql/src/java/org/apache/hadoop/hive/ql/QueryProperties.java
index 1ba5654dfe..a73256fe0e 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/QueryProperties.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/QueryProperties.java
@@ -143,4 +143,22 @@ public boolean isHasMapGroupBy() {
   public void setHasMapGroupBy(boolean hasMapGroupBy) {
     this.hasMapGroupBy = hasMapGroupBy;
   }
+
+  public void clear() {
+    hasJoin = false;
+    hasGroupBy = false;
+    hasOrderBy = false;
+    hasSortBy = false;
+    hasJoinFollowedByGroupBy = false;
+    hasPTF = false;
+    hasWindowing = false;
+
+    // does the query have a using clause
+    usesScript = false;
+
+    hasDistributeBy = false;
+    hasClusterBy = false;
+    mapJoinRemoved = false;
+    hasMapGroupBy = false;
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/ColumnStatsSemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/ColumnStatsSemanticAnalyzer.java
index 44c193ff46..9fc1aa0ef5 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/ColumnStatsSemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/ColumnStatsSemanticAnalyzer.java
@@ -346,48 +346,6 @@ private ASTNode genRewrittenTree(String rewrittenQuery) throws SemanticException
     return rewrittenTree;
   }
 
-  public ColumnStatsSemanticAnalyzer(HiveConf conf, ASTNode tree) throws SemanticException {
-    super(conf);
-    // check if it is no scan. grammar prevents coexit noscan/columns
-    super.processNoScanCommand(tree);
-    // check if it is partial scan. grammar prevents coexit partialscan/columns
-    super.processPartialScanCommand(tree);
-    /* Rewrite only analyze table <> column <> compute statistics; Don't rewrite analyze table
-     * command - table stats are collected by the table scan operator and is not rewritten to
-     * an aggregation.
-     */
-    if (shouldRewrite(tree)) {
-      tbl = getTable(tree);
-      colNames = getColumnName(tree);
-      // Save away the original AST
-      originalTree = tree;
-      boolean isPartitionStats = isPartitionLevelStats(tree);
-      Map<String,String> partSpec = null;
-      checkForPartitionColumns(colNames, Utilities.getColumnNamesFromFieldSchema(tbl.getPartitionKeys()));
-      validateSpecifiedColumnNames(colNames);
-      if (conf.getBoolVar(ConfVars.HIVE_STATS_COLLECT_PART_LEVEL_STATS) && tbl.isPartitioned()) {
-        isPartitionStats = true;
-      }
-
-      if (isPartitionStats) {
-        isTableLevel = false;
-        partSpec = getPartKeyValuePairsFromAST(tree);
-        handlePartialPartitionSpec(partSpec);
-      } else {
-        isTableLevel = true;
-      }
-      colType = getColumnTypes(colNames);
-      int numBitVectors = getNumBitVectorsForNDVEstimation(conf);
-      rewrittenQuery = genRewrittenQuery(colNames, numBitVectors, partSpec, isPartitionStats);
-      rewrittenTree = genRewrittenTree(rewrittenQuery);
-    } else {
-      // Not an analyze table column compute statistics statement - don't do any rewrites
-      originalTree = rewrittenTree = tree;
-      rewrittenQuery = null;
-      isRewritten = false;
-    }
-  }
-
   // fail early if the columns specified for column statistics are not valid
   private void validateSpecifiedColumnNames(List<String> specifiedCols)
       throws SemanticException {
@@ -421,6 +379,46 @@ public void analyze(ASTNode ast, Context origCtx) throws SemanticException {
     // initialize QB
     init();
 
+    // check if it is no scan. grammar prevents coexit noscan/columns
+    super.processNoScanCommand(ast);
+    // check if it is partial scan. grammar prevents coexit partialscan/columns
+    super.processPartialScanCommand(ast);
+    /* Rewrite only analyze table <> column <> compute statistics; Don't rewrite analyze table
+     * command - table stats are collected by the table scan operator and is not rewritten to
+     * an aggregation.
+     */
+    if (shouldRewrite(ast)) {
+      tbl = getTable(ast);
+      colNames = getColumnName(ast);
+      // Save away the original AST
+      originalTree = ast;
+      boolean isPartitionStats = isPartitionLevelStats(ast);
+      Map<String,String> partSpec = null;
+      checkForPartitionColumns(
+          colNames, Utilities.getColumnNamesFromFieldSchema(tbl.getPartitionKeys()));
+      validateSpecifiedColumnNames(colNames);
+      if (conf.getBoolVar(ConfVars.HIVE_STATS_COLLECT_PART_LEVEL_STATS) && tbl.isPartitioned()) {
+        isPartitionStats = true;
+      }
+
+      if (isPartitionStats) {
+        isTableLevel = false;
+        partSpec = getPartKeyValuePairsFromAST(ast);
+        handlePartialPartitionSpec(partSpec);
+      } else {
+        isTableLevel = true;
+      }
+      colType = getColumnTypes(colNames);
+      int numBitVectors = getNumBitVectorsForNDVEstimation(conf);
+      rewrittenQuery = genRewrittenQuery(colNames, numBitVectors, partSpec, isPartitionStats);
+      rewrittenTree = genRewrittenTree(rewrittenQuery);
+    } else {
+      // Not an analyze table column compute statistics statement - don't do any rewrites
+      originalTree = rewrittenTree = ast;
+      rewrittenQuery = null;
+      isRewritten = false;
+    }
+
     // Setup the necessary metadata if originating from analyze rewrite
     if (isRewritten) {
       qb = getQB();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/GlobalLimitCtx.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/GlobalLimitCtx.java
index 8d7bac2524..6cd636cad5 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/GlobalLimitCtx.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/GlobalLimitCtx.java
@@ -25,10 +25,14 @@
  */
 public class GlobalLimitCtx {
 
-  private boolean enable = false;
-  private int globalLimit = -1;
-  private boolean hasTransformOrUDTF = false;
-  private LimitDesc lastReduceLimitDesc = null;
+  private boolean enable;
+  private int globalLimit;
+  private boolean hasTransformOrUDTF;
+  private LimitDesc lastReduceLimitDesc;
+
+  public GlobalLimitCtx() {
+    reset();
+  }
 
   public int getGlobalLimit() {
     return globalLimit;
@@ -64,4 +68,11 @@ public void disableOpt() {
     this.globalLimit = -1;
     this.lastReduceLimitDesc = null;
   }
+
+  public void reset() {
+    enable = false;
+    globalLimit = -1;
+    hasTransformOrUDTF = false;
+    lastReduceLimitDesc = null;
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 97fa52c8d6..496f6a6ee7 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -206,6 +206,8 @@ public class SemanticAnalyzer extends BaseSemanticAnalyzer {
 
   public static final String DUMMY_DATABASE = "_dummy_database";
   public static final String DUMMY_TABLE = "_dummy_table";
+  // Max characters when auto generating the column name with func name
+  private static final int AUTOGEN_COLALIAS_PRFX_MAXLENGTH = 20;
 
   private HashMap<TableScanOperator, ExprNodeDesc> opToPartPruner;
   private HashMap<TableScanOperator, PrunedPartitionList> opToPartList;
@@ -228,7 +230,7 @@ public class SemanticAnalyzer extends BaseSemanticAnalyzer {
   private HashMap<TableScanOperator, sampleDesc> opToSamplePruner;
   private final Map<TableScanOperator, Map<String, ExprNodeDesc>> opToPartToSkewedPruner;
   /**
-   * a map for the split sampling, from ailias to an instance of SplitSample
+   * a map for the split sampling, from alias to an instance of SplitSample
    * that describes percentage and number.
    */
   private final HashMap<String, SplitSample> nameToSplitSample;
@@ -239,7 +241,7 @@ public class SemanticAnalyzer extends BaseSemanticAnalyzer {
   private ArrayList<String> viewsExpanded;
   private ASTNode viewSelect;
   private final UnparseTranslator unparseTranslator;
-  private final GlobalLimitCtx globalLimitCtx = new GlobalLimitCtx();
+  private final GlobalLimitCtx globalLimitCtx;
 
   // prefix for column names auto generated by hive
   private final String autogenColAliasPrfxLbl;
@@ -250,16 +252,13 @@ public class SemanticAnalyzer extends BaseSemanticAnalyzer {
   // keeps track of aliases for V3, V3:V2, V3:V2:V1.
   // This is used when T is added as an input for the query, the parents of T is
   // derived from the alias V3:V2:V1:T
-  private final Map<String, ReadEntity> viewAliasToInput = new HashMap<String, ReadEntity>();
-
-  // Max characters when auto generating the column name with func name
-  private static final int AUTOGEN_COLALIAS_PRFX_MAXLENGTH = 20;
+  private final Map<String, ReadEntity> viewAliasToInput;
 
   // flag for no scan during analyze ... compute statistics
-  protected boolean noscan = false;
+  protected boolean noscan;
 
   //flag for partial scan during analyze ... compute statistics
-  protected boolean partialscan = false;
+  protected boolean partialscan;
 
   /*
    * Capture the CTE definitions in a Query.
@@ -276,7 +275,6 @@ private static class Phase1Ctx {
   }
 
   public SemanticAnalyzer(HiveConf conf) throws SemanticException {
-
     super(conf);
     opToPartPruner = new HashMap<TableScanOperator, ExprNodeDesc>();
     opToPartList = new HashMap<TableScanOperator, PrunedPartitionList>();
@@ -306,6 +304,9 @@ public SemanticAnalyzer(HiveConf conf) throws SemanticException {
     queryProperties = new QueryProperties();
     opToPartToSkewedPruner = new HashMap<TableScanOperator, Map<String, ExprNodeDesc>>();
     aliasToCTEs = new HashMap<String, ASTNode>();
+    globalLimitCtx = new GlobalLimitCtx();
+    viewAliasToInput = new HashMap<String, ReadEntity>();
+    noscan = partialscan = false;
   }
 
   @Override
@@ -326,6 +327,29 @@ protected void reset() {
     groupOpToInputTables.clear();
     prunedPartitions.clear();
     aliasToCTEs.clear();
+    topToTable.clear();
+    opToPartPruner.clear();
+    opToPartList.clear();
+    opToPartToSkewedPruner.clear();
+    opToSamplePruner.clear();
+    nameToSplitSample.clear();
+    fsopToTable.clear();
+    resultSchema = null;
+    createVwDesc = null;
+    viewsExpanded = null;
+    viewSelect = null;
+    ctesExpanded = null;
+    noscan = false;
+    partialscan = false;
+    globalLimitCtx.disableOpt();
+    viewAliasToInput.clear();
+    reduceSinkOperatorsAddedByEnforceBucketingSorting.clear();
+    topToTableProps.clear();
+    listMapJoinOpsNoReducer.clear();
+    unparseTranslator.clear();
+    queryProperties.clear();
+    outputs.clear();
+    globalLimitCtx.reset();
   }
 
   public void initParseCtx(ParseContext pctx) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
index 026efe824f..3e3926ed2c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
@@ -263,7 +263,7 @@ public static BaseSemanticAnalyzer get(HiveConf conf, ASTNode tree)
         return new FunctionSemanticAnalyzer(conf);
 
       case HiveParser.TOK_ANALYZE:
-        return new ColumnStatsSemanticAnalyzer(conf, tree);
+        return new ColumnStatsSemanticAnalyzer(conf);
 
       case HiveParser.TOK_CREATEMACRO:
       case HiveParser.TOK_DROPMACRO:
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/UnparseTranslator.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/UnparseTranslator.java
index c69f74796a..9ad6714510 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/UnparseTranslator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/UnparseTranslator.java
@@ -262,4 +262,10 @@ private static class CopyTranslation {
     ASTNode targetNode;
     ASTNode sourceNode;
   }
+
+  public void clear() {
+    translations.clear();
+    copyTranslations.clear();
+    enabled = false;
+  }
 }
