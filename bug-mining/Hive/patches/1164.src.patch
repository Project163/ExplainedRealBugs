diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
index 5ce28c9b40..df9fe87837 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
@@ -1144,8 +1144,8 @@ public int execute() throws CommandNeedRetryException {
         int exitVal = tskRes.getExitVal();
         if (exitVal != 0) {
           if (tsk.ifRetryCmdWhenFail()) {
-            if (running.size() != 0) {
-              taskCleanup();
+            if (!running.isEmpty()) {
+              taskCleanup(running);
             }
             // in case we decided to run everything in local mode, restore the
             // the jobtracker setting to its initial value
@@ -1189,8 +1189,8 @@ public int execute() throws CommandNeedRetryException {
             }
             SQLState = "08S01";
             console.printError(errorMessage);
-            if (running.size() != 0) {
-              taskCleanup();
+            if (!running.isEmpty()) {
+              taskCleanup(running);
             }
             // in case we decided to run everything in local mode, restore the
             // the jobtracker setting to its initial value
@@ -1355,12 +1355,18 @@ public void launchTask(Task<? extends Serializable> tsk, String queryId, boolean
   /**
    * Cleans up remaining tasks in case of failure
    */
-
-  public void taskCleanup() {
-    // The currently existing Shutdown hooks will be automatically called,
-    // killing the map-reduce processes.
-    // The non MR processes will be killed as well.
-    System.exit(9);
+  public void taskCleanup(Map<TaskResult, TaskRunner> running) {
+    for (Map.Entry<TaskResult, TaskRunner> entry : running.entrySet()) {
+      if (entry.getKey().isRunning()) {
+        Task<?> task = entry.getValue().getTask();
+        try {
+          task.shutdown();
+        } catch (Exception e) {
+          console.printError("Exception on shutting down task " + task.getId() + ": " + e);
+        }
+      }
+    }
+    running.clear();
   }
 
   /**
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
index 805e91c9bf..2ad6227f5f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
@@ -25,7 +25,6 @@
 import java.io.Serializable;
 import java.lang.management.ManagementFactory;
 import java.lang.management.MemoryMXBean;
-import java.net.URL;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
@@ -89,7 +88,6 @@
 import org.apache.log4j.BasicConfigurator;
 import org.apache.log4j.FileAppender;
 import org.apache.log4j.LogManager;
-import org.apache.log4j.PropertyConfigurator;
 import org.apache.log4j.varia.NullAppender;
 
 /**
@@ -107,6 +105,8 @@ public class ExecDriver extends Task<MapredWork> implements Serializable, Hadoop
 
   protected static transient final Log LOG = LogFactory.getLog(ExecDriver.class);
 
+  private RunningJob rj;
+
   /**
    * Constructor when invoked from QL.
    */
@@ -358,7 +358,6 @@ public int execute(DriverContext driverContext) {
       initializeFiles("tmpfiles", addedFiles);
     }
     int returnVal = 0;
-    RunningJob rj = null;
     boolean noName = StringUtils.isEmpty(HiveConf.getVar(job, HiveConf.ConfVars.HADOOPJOBNAME));
 
     if (noName) {
@@ -980,4 +979,17 @@ public void updateCounters(Counters ctrs, RunningJob rj) throws IOException {
   public void logPlanProgress(SessionState ss) throws IOException {
     ss.getHiveHistory().logPlanProgress(queryPlan);
   }
+
+  @Override
+  public void shutdown() {
+    super.shutdown();
+    if (rj != null) {
+      try {
+        rj.killJob();
+      } catch (Exception e) {
+        LOG.warn("failed to kill job " + rj.getID(), e);
+      }
+      rj = null;
+    }
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java
index 589fed3428..b2127fc294 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java
@@ -69,6 +69,8 @@ public class MapRedTask extends ExecDriver implements Serializable {
   private transient long totalInputFileSize;
   private transient long totalInputNumFiles;
 
+  private Process executor;
+
   public MapRedTask() {
     super();
   }
@@ -210,7 +212,6 @@ public int execute(DriverContext driverContext) {
       }
 
       LOG.info("Executing: " + cmdLine);
-      Process executor = null;
 
       // Inherit Java system variables
       String hadoopOpts;
@@ -579,4 +580,13 @@ public static String isEligibleForLocalMode(HiveConf conf,
   public Operator<? extends OperatorDesc> getReducer() {
     return getWork().getReducer();
   }
+
+  @Override
+  public void shutdown() {
+    super.shutdown();
+    if (executor != null) {
+      executor.destroy();
+      executor = null;
+    }
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java
index 5d2017d27f..d8ba9d9c0d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java
@@ -77,6 +77,8 @@ public class MapredLocalTask extends Task<MapredLocalWork> implements Serializab
   // will pass this context throught
   private final ExecMapperContext execContext = new ExecMapperContext();
 
+  private Process executor;
+
   public MapredLocalTask() {
     super();
   }
@@ -155,7 +157,6 @@ public int execute(DriverContext driverContext) {
       }
 
       LOG.info("Executing: " + cmdLine);
-      Process executor = null;
 
       // Inherit Java system variables
       String hadoopOpts;
@@ -462,4 +463,12 @@ public StageType getType() {
     return StageType.MAPREDLOCAL;
   }
 
+  @Override
+  public void shutdown() {
+    super.shutdown();
+    if (executor != null) {
+      executor.destroy();
+      executor = null;
+    }
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java
index 43463d3280..6c7d9a4eba 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java
@@ -518,6 +518,9 @@ public String getJobID() {
     return jobID;
   }
 
+  public void shutdown() {
+  }
+
   public List<FieldSchema> getResultSchema() {
     return null;
   }
