diff --git a/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/IcebergTableUtil.java b/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/IcebergTableUtil.java
index 6e471f7be3..3fe2eee39d 100644
--- a/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/IcebergTableUtil.java
+++ b/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/IcebergTableUtil.java
@@ -77,8 +77,12 @@ static Table getTable(Configuration configuration, org.apache.hadoop.hive.metast
   static Table getTable(Configuration configuration, Properties properties) {
     String metaTable = properties.getProperty("metaTable");
     String tableName = properties.getProperty(Catalogs.NAME);
+    String location = properties.getProperty(Catalogs.LOCATION);
     if (metaTable != null) {
+      // HiveCatalog, HadoopCatalog uses NAME to identify the metadata table
       properties.setProperty(Catalogs.NAME, tableName + "." + metaTable);
+      // HadoopTable uses LOCATION to identify the metadata table
+      properties.setProperty(Catalogs.LOCATION, location + "#" + metaTable);
     }
 
     String tableIdentifier = properties.getProperty(Catalogs.NAME);
diff --git a/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergSelects.java b/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergSelects.java
index a9c692d12e..6ab6e3e4ff 100644
--- a/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergSelects.java
+++ b/iceberg/iceberg-handler/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergSelects.java
@@ -24,6 +24,7 @@
 import java.util.stream.Collectors;
 import org.apache.iceberg.FileFormat;
 import org.apache.iceberg.Schema;
+import org.apache.iceberg.Table;
 import org.apache.iceberg.catalog.TableIdentifier;
 import org.apache.iceberg.data.Record;
 import org.apache.iceberg.mr.InputFormatConfig;
@@ -263,4 +264,17 @@ public void testVectorizedOrcMultipleSplits() throws Exception {
     Assert.assertEquals(20000, result.size());
 
   }
+
+  @Test
+  public void testHistory() throws IOException, InterruptedException {
+    TableIdentifier identifier = TableIdentifier.of("default", "source");
+    Table table = testTables.createTableWithVersions(shell, identifier.name(),
+        HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA, fileFormat,
+        HiveIcebergStorageHandlerTestUtils.CUSTOMER_RECORDS, 1);
+    List<Object[]> history = shell.executeStatement("SELECT snapshot_id FROM default.source.history");
+    Assert.assertEquals(table.history().size(), history.size());
+    for (int i = 0; i < table.history().size(); ++i) {
+      Assert.assertEquals(table.history().get(i).snapshotId(), history.get(i)[0]);
+    }
+  }
 }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java
index 56b3843c00..f493bfebc6 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java
@@ -262,6 +262,7 @@ private static Statistics collectStatistics(HiveConf conf, PrunedPartitionList p
     boolean fetchColStats =
         HiveConf.getBoolVar(conf, HiveConf.ConfVars.HIVE_STATS_FETCH_COLUMN_STATS);
     boolean estimateStats = HiveConf.getBoolVar(conf, ConfVars.HIVE_STATS_ESTIMATE_STATS);
+    boolean metaTable = table.getMetaTable() != null;
 
     if (!table.isPartitioned()) {
 
@@ -285,7 +286,7 @@ private static Statistics collectStatistics(HiveConf conf, PrunedPartitionList p
 
       long numErasureCodedFiles = getErasureCodedFiles(table);
 
-      if (needColStats) {
+      if (needColStats && !metaTable) {
         colStats = getTableColumnStats(table, schema, neededColumns, colStatsCache, fetchColStats);
         if (estimateStats) {
           estimateStatsForMissingCols(neededColumns, colStats, table, conf, nr, schema);
