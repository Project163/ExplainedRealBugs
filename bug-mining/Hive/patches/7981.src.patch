diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonMergeJoinOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonMergeJoinOperator.java
index 54728f3fdd..e574fb950c 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonMergeJoinOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonMergeJoinOperator.java
@@ -179,12 +179,18 @@ public void initializeOp(Configuration hconf) throws HiveException {
         }
       }
       nullOrdering = NullOrdering.defaultNullOrder(hconf);
-      if (parentOperators != null && !parentOperators.isEmpty()) {
-        // Tell ReduceRecordSource to flush last record as this is a reduce
-        // side SMB
-        for (RecordSource source : sources) {
-          ((ReduceRecordSource) source).setFlushLastRecord(true);
-        }
+    }
+
+    if (parentOperators != null && !parentOperators.isEmpty()) {
+      // Tell RecordSource to flush last record even if its a map side SMB. SMB expect its
+      // parent group by operators to emit the record as and when aggregation is done.
+      // In case of group by with FINAL/MERGE_PARTIAL mode, the records are expected to come
+      // in a sorted order to group by operator and the group by operator is suppose to
+      // emit the aggregated value to next node once a record with different value
+      // is received. In case we dont flush here, the last aggregate value will not be
+      // emitted as it will keep waiting for the next different record.
+      for (RecordSource source : sources) {
+        source.setFlushLastRecord(true);
       }
     }
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MapRecordSource.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MapRecordSource.java
index a9c250b2ce..661c7d7855 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MapRecordSource.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MapRecordSource.java
@@ -44,6 +44,9 @@ public class MapRecordSource implements RecordSource {
   private KeyValueReader reader = null;
   private final boolean grouped = false;
 
+  // Flush the last record when reader is out of records
+  private boolean flushLastRecord = false;
+
   void init(JobConf jconf, AbstractMapOperator mapOp, KeyValueReader reader) throws IOException {
     execContext = mapOp.getExecContext();
     this.mapOp = mapOp;
@@ -59,6 +62,11 @@ public final boolean isGrouped() {
     return grouped;
   }
 
+  @Override
+  public void setFlushLastRecord(boolean flushLastRecord) {
+    this.flushLastRecord = flushLastRecord;
+  }
+
   @Override
   public boolean pushRecord() throws HiveException {
     execContext.resetRow();
@@ -73,6 +81,8 @@ public boolean pushRecord() throws HiveException {
           throw new HiveException(e);
         }
         return processRow(value);
+      } else if (flushLastRecord) {
+        mapOp.flushRecursive();
       }
     } catch (IOException e) {
       closeReader();
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/RecordSource.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/RecordSource.java
index 6e5491f8e7..33ec3f903b 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/RecordSource.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/RecordSource.java
@@ -22,4 +22,5 @@
 public interface RecordSource {
   public boolean pushRecord() throws HiveException;
   public boolean isGrouped();
+  public void setFlushLastRecord(boolean flushLastRecord);
 }
\ No newline at end of file
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java
index c42d293854..276d9bb7d4 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java
@@ -532,6 +532,7 @@ public ObjectInspector getObjectInspector() {
     return rowObjectInspector;
   }
 
+  @Override
   public void setFlushLastRecord(boolean flushLastRecord) {
     this.flushLastRecord = flushLastRecord;
   }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConvertJoinMapJoin.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConvertJoinMapJoin.java
index e49717b9a8..1e49879c47 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConvertJoinMapJoin.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConvertJoinMapJoin.java
@@ -62,6 +62,7 @@
 import org.apache.hadoop.hive.ql.plan.DynamicPruningEventDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc;
 import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;
+import org.apache.hadoop.hive.ql.plan.GroupByDesc;
 import org.apache.hadoop.hive.ql.plan.JoinCondDesc;
 import org.apache.hadoop.hive.ql.plan.JoinDesc;
 import org.apache.hadoop.hive.ql.plan.MapJoinDesc;
@@ -588,6 +589,18 @@ private void convertJoinSMBJoin(JoinOperator joinOp, OptimizeTezProcContext cont
           continue;
         }
 
+        // In case of SMB join, the parent group by has to be FINAL where it streams the
+        // aggregate as and when its calculated. This is required, as the sort merge join
+        // pulls the data from the parent operators and expect it to get the records
+        // during join processing, not at the time of close.
+        if (parentOp instanceof GroupByOperator) {
+          GroupByOperator gpbyOp = (GroupByOperator )parentOp;
+          if (gpbyOp.getConf().getMode() == GroupByDesc.Mode.HASH) {
+            // No need to change for MERGE_PARTIAL etc.
+            gpbyOp.getConf().setMode(GroupByDesc.Mode.FINAL);
+          }
+        }
+
         // insert the dummy store operator here
         DummyStoreOperator dummyStoreOp = new TezDummyStoreOperator(mergeJoinOp.getCompilationOpContext());
         dummyStoreOp.setConf(new DummyStoreDesc());
diff --git a/ql/src/test/queries/clientpositive/auto_sortmerge_join_10.q b/ql/src/test/queries/clientpositive/auto_sortmerge_join_10.q
index 429d08b898..3be73fe000 100644
--- a/ql/src/test/queries/clientpositive/auto_sortmerge_join_10.q
+++ b/ql/src/test/queries/clientpositive/auto_sortmerge_join_10.q
@@ -48,7 +48,7 @@ select count(*) from
   (select a.key as key, a.value as value from tbl2_n4 a where key < 6) subq2
   on subq1.key = subq2.key;
 
-set hive.auto.convert.sortmerge.join=false;
+set hive.auto.convert.sortmerge.join=true;
 
 -- One of the subqueries contains a groupby, so it should not be converted to a sort-merge join.
 explain
@@ -80,3 +80,32 @@ select count(*) from
     join
   (select a.key as key, a.value as value from tbl2_n4 a where key < 6) subq2
   on subq1.key = subq2.key;
+
+explain
+select subq2.key from
+  (select a.key as key, count(*) as value from tbl1_n5 a where key < 6 group by a.key) subq1
+    join
+  (select a.key as key, a.value as value from tbl2_n4 a where key < 6) subq2
+  on subq1.key = subq2.key order by subq2.key;
+
+select subq2.key from
+  (select a.key as key, count(*) as value from tbl1_n5 a where key < 6 group by a.key) subq1
+    join
+  (select a.key as key, a.value as value from tbl2_n4 a where key < 6) subq2
+  on subq1.key = subq2.key order by subq2.key;
+
+explain
+select count(t1.key) from tbl1_n5 as t1 where not exists
+    (select 1 from tbl2_n4 as t2 where t1.key = t2.key);
+
+select count(t1.key) from tbl1_n5 as t1 where not exists
+     (select 1 from tbl2_n4 as t2 where t1.key = t2.key);
+
+set hive.auto.convert.anti.join=false;
+
+explain
+select count(t1.key) from tbl1_n5 as t1 where not exists
+    (select 1 from tbl2_n4 as t2 where t1.key = t2.key);
+
+select count(t1.key) from tbl1_n5 as t1 where not exists
+     (select 1 from tbl2_n4 as t2 where t1.key = t2.key);
diff --git a/ql/src/test/results/clientpositive/llap/auto_sortmerge_join_10.q.out b/ql/src/test/results/clientpositive/llap/auto_sortmerge_join_10.q.out
index 38dbe79eae..7b93c1d6a5 100644
--- a/ql/src/test/results/clientpositive/llap/auto_sortmerge_join_10.q.out
+++ b/ql/src/test/results/clientpositive/llap/auto_sortmerge_join_10.q.out
@@ -249,8 +249,7 @@ STAGE PLANS:
     Tez
 #### A masked pattern was here ####
       Edges:
-        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
-        Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
+        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
 #### A masked pattern was here ####
       Vertices:
         Map 1 
@@ -266,15 +265,12 @@ STAGE PLANS:
                       expressions: key (type: int)
                       outputColumnNames: _col0
                       Statistics: Num rows: 7 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
-                      Reduce Output Operator
-                        key expressions: _col0 (type: int)
-                        null sort order: z
-                        sort order: +
-                        Map-reduce partition columns: _col0 (type: int)
-                        Statistics: Num rows: 7 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
-            Execution mode: vectorized, llap
-            LLAP IO: all inputs
-        Map 4 
+                      Group By Operator
+                        keys: _col0 (type: int)
+                        mode: final
+                        outputColumnNames: _col0
+                        Statistics: Num rows: 5 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
+                        Dummy Store
             Map Operator Tree:
                 TableScan
                   alias: a
@@ -287,42 +283,26 @@ STAGE PLANS:
                       expressions: key (type: int)
                       outputColumnNames: _col0
                       Statistics: Num rows: 7 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
-                      Group By Operator
-                        keys: _col0 (type: int)
-                        minReductionHashAggr: 0.4
-                        mode: hash
-                        outputColumnNames: _col0
-                        Statistics: Num rows: 5 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
-                        Reduce Output Operator
-                          key expressions: _col0 (type: int)
-                          null sort order: z
-                          sort order: +
-                          Map-reduce partition columns: _col0 (type: int)
-                          Statistics: Num rows: 5 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
-            Execution mode: vectorized, llap
-            LLAP IO: all inputs
-        Reducer 2 
+                      Merge Join Operator
+                        condition map:
+                             Left Semi Join 0 to 1
+                        keys:
+                          0 _col0 (type: int)
+                          1 _col0 (type: int)
+                        Statistics: Num rows: 7 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
+                        Group By Operator
+                          aggregations: count()
+                          minReductionHashAggr: 0.85714287
+                          mode: hash
+                          outputColumnNames: _col0
+                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                          Reduce Output Operator
+                            null sort order: 
+                            sort order: 
+                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                            value expressions: _col0 (type: bigint)
             Execution mode: llap
-            Reduce Operator Tree:
-              Merge Join Operator
-                condition map:
-                     Left Semi Join 0 to 1
-                keys:
-                  0 _col0 (type: int)
-                  1 _col0 (type: int)
-                Statistics: Num rows: 7 Data size: 56 Basic stats: COMPLETE Column stats: COMPLETE
-                Group By Operator
-                  aggregations: count()
-                  minReductionHashAggr: 0.85714287
-                  mode: hash
-                  outputColumnNames: _col0
-                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
-                  Reduce Output Operator
-                    null sort order: 
-                    sort order: 
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
-                    value expressions: _col0 (type: bigint)
-        Reducer 3 
+        Reducer 2 
             Execution mode: vectorized, llap
             Reduce Operator Tree:
               Group By Operator
@@ -482,3 +462,350 @@ POSTHOOK: Input: default@tbl1_n5
 POSTHOOK: Input: default@tbl2_n4
 #### A masked pattern was here ####
 8
+PREHOOK: query: explain
+select subq2.key from
+  (select a.key as key, count(*) as value from tbl1_n5 a where key < 6 group by a.key) subq1
+    join
+  (select a.key as key, a.value as value from tbl2_n4 a where key < 6) subq2
+  on subq1.key = subq2.key order by subq2.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@tbl1_n5
+PREHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+POSTHOOK: query: explain
+select subq2.key from
+  (select a.key as key, count(*) as value from tbl1_n5 a where key < 6 group by a.key) subq1
+    join
+  (select a.key as key, a.value as value from tbl2_n4 a where key < 6) subq2
+  on subq1.key = subq2.key order by subq2.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@tbl1_n5
+POSTHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+#### A masked pattern was here ####
+      Edges:
+        Reducer 2 <- Map 1 (SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: a
+                  filterExpr: (key < 6) (type: boolean)
+                  Statistics: Num rows: 10 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
+                  Filter Operator
+                    predicate: (key < 6) (type: boolean)
+                    Statistics: Num rows: 7 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
+                    Select Operator
+                      expressions: key (type: int)
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 7 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
+                      Dummy Store
+            Map Operator Tree:
+                TableScan
+                  alias: a
+                  filterExpr: (key < 6) (type: boolean)
+                  Statistics: Num rows: 10 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
+                  Filter Operator
+                    predicate: (key < 6) (type: boolean)
+                    Statistics: Num rows: 7 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
+                    Group By Operator
+                      keys: key (type: int)
+                      mode: final
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 5 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
+                      Merge Join Operator
+                        condition map:
+                             Inner Join 0 to 1
+                        keys:
+                          0 _col0 (type: int)
+                          1 _col0 (type: int)
+                        outputColumnNames: _col1
+                        Statistics: Num rows: 7 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
+                        Select Operator
+                          expressions: _col1 (type: int)
+                          outputColumnNames: _col0
+                          Statistics: Num rows: 7 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
+                          Reduce Output Operator
+                            key expressions: _col0 (type: int)
+                            null sort order: z
+                            sort order: +
+                            Statistics: Num rows: 7 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
+            Execution mode: llap
+        Reducer 2 
+            Execution mode: vectorized, llap
+            Reduce Operator Tree:
+              Select Operator
+                expressions: KEY.reducesinkkey0 (type: int)
+                outputColumnNames: _col0
+                Statistics: Num rows: 7 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 7 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: select subq2.key from
+  (select a.key as key, count(*) as value from tbl1_n5 a where key < 6 group by a.key) subq1
+    join
+  (select a.key as key, a.value as value from tbl2_n4 a where key < 6) subq2
+  on subq1.key = subq2.key order by subq2.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@tbl1_n5
+PREHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+POSTHOOK: query: select subq2.key from
+  (select a.key as key, count(*) as value from tbl1_n5 a where key < 6 group by a.key) subq1
+    join
+  (select a.key as key, a.value as value from tbl2_n4 a where key < 6) subq2
+  on subq1.key = subq2.key order by subq2.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@tbl1_n5
+POSTHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+0
+0
+0
+2
+4
+5
+5
+5
+PREHOOK: query: explain
+select count(t1.key) from tbl1_n5 as t1 where not exists
+    (select 1 from tbl2_n4 as t2 where t1.key = t2.key)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@tbl1_n5
+PREHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+POSTHOOK: query: explain
+select count(t1.key) from tbl1_n5 as t1 where not exists
+    (select 1 from tbl2_n4 as t2 where t1.key = t2.key)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@tbl1_n5
+POSTHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+#### A masked pattern was here ####
+      Edges:
+        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: t2
+                  filterExpr: key is not null (type: boolean)
+                  Statistics: Num rows: 10 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
+                  Filter Operator
+                    predicate: key is not null (type: boolean)
+                    Statistics: Num rows: 10 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
+                    Select Operator
+                      expressions: key (type: int)
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 10 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
+                      Group By Operator
+                        keys: _col0 (type: int)
+                        mode: final
+                        outputColumnNames: _col0
+                        Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
+                        Dummy Store
+            Map Operator Tree:
+                TableScan
+                  alias: t1
+                  Statistics: Num rows: 10 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
+                  Select Operator
+                    expressions: key (type: int)
+                    outputColumnNames: _col0
+                    Statistics: Num rows: 10 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
+                    Merge Join Operator
+                      condition map:
+                           Anti Join 0 to 1
+                      keys:
+                        0 _col0 (type: int)
+                        1 _col0 (type: int)
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
+                      Group By Operator
+                        aggregations: count(_col0)
+                        minReductionHashAggr: 0.4
+                        mode: hash
+                        outputColumnNames: _col0
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                        Reduce Output Operator
+                          null sort order: 
+                          sort order: 
+                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                          value expressions: _col0 (type: bigint)
+            Execution mode: llap
+        Reducer 2 
+            Execution mode: vectorized, llap
+            Reduce Operator Tree:
+              Group By Operator
+                aggregations: count(VALUE._col0)
+                mode: mergepartial
+                outputColumnNames: _col0
+                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: select count(t1.key) from tbl1_n5 as t1 where not exists
+     (select 1 from tbl2_n4 as t2 where t1.key = t2.key)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@tbl1_n5
+PREHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+POSTHOOK: query: select count(t1.key) from tbl1_n5 as t1 where not exists
+     (select 1 from tbl2_n4 as t2 where t1.key = t2.key)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@tbl1_n5
+POSTHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+0
+PREHOOK: query: explain
+select count(t1.key) from tbl1_n5 as t1 where not exists
+    (select 1 from tbl2_n4 as t2 where t1.key = t2.key)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@tbl1_n5
+PREHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+POSTHOOK: query: explain
+select count(t1.key) from tbl1_n5 as t1 where not exists
+    (select 1 from tbl2_n4 as t2 where t1.key = t2.key)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@tbl1_n5
+POSTHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Tez
+#### A masked pattern was here ####
+      Edges:
+        Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
+#### A masked pattern was here ####
+      Vertices:
+        Map 1 
+            Map Operator Tree:
+                TableScan
+                  alias: t2
+                  filterExpr: key is not null (type: boolean)
+                  Statistics: Num rows: 10 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
+                  Filter Operator
+                    predicate: key is not null (type: boolean)
+                    Statistics: Num rows: 10 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
+                    Group By Operator
+                      keys: key (type: int)
+                      mode: final
+                      outputColumnNames: _col0
+                      Statistics: Num rows: 6 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE
+                      Select Operator
+                        expressions: true (type: boolean), _col0 (type: int)
+                        outputColumnNames: _col0, _col1
+                        Statistics: Num rows: 6 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE
+                        Dummy Store
+            Map Operator Tree:
+                TableScan
+                  alias: t1
+                  Statistics: Num rows: 10 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
+                  Select Operator
+                    expressions: key (type: int)
+                    outputColumnNames: _col0
+                    Statistics: Num rows: 10 Data size: 40 Basic stats: COMPLETE Column stats: COMPLETE
+                    Merge Join Operator
+                      condition map:
+                           Left Outer Join 0 to 1
+                      keys:
+                        0 _col0 (type: int)
+                        1 _col1 (type: int)
+                      outputColumnNames: _col0, _col1
+                      Statistics: Num rows: 10 Data size: 80 Basic stats: COMPLETE Column stats: COMPLETE
+                      Filter Operator
+                        predicate: _col1 is null (type: boolean)
+                        Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                        Select Operator
+                          expressions: _col0 (type: int)
+                          outputColumnNames: _col0
+                          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                          Group By Operator
+                            aggregations: count(_col0)
+                            minReductionHashAggr: 0.4
+                            mode: hash
+                            outputColumnNames: _col0
+                            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                            Reduce Output Operator
+                              null sort order: 
+                              sort order: 
+                              Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                              value expressions: _col0 (type: bigint)
+            Execution mode: llap
+        Reducer 2 
+            Execution mode: vectorized, llap
+            Reduce Operator Tree:
+              Group By Operator
+                aggregations: count(VALUE._col0)
+                mode: mergepartial
+                outputColumnNames: _col0
+                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                File Output Operator
+                  compressed: false
+                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
+                  table:
+                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+      Processor Tree:
+        ListSink
+
+PREHOOK: query: select count(t1.key) from tbl1_n5 as t1 where not exists
+     (select 1 from tbl2_n4 as t2 where t1.key = t2.key)
+PREHOOK: type: QUERY
+PREHOOK: Input: default@tbl1_n5
+PREHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+POSTHOOK: query: select count(t1.key) from tbl1_n5 as t1 where not exists
+     (select 1 from tbl2_n4 as t2 where t1.key = t2.key)
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@tbl1_n5
+POSTHOOK: Input: default@tbl2_n4
+#### A masked pattern was here ####
+0
diff --git a/ql/src/test/results/clientpositive/llap/groupby_sort_1_23.q.out b/ql/src/test/results/clientpositive/llap/groupby_sort_1_23.q.out
index bc5b949109..ea550137cf 100644
--- a/ql/src/test/results/clientpositive/llap/groupby_sort_1_23.q.out
+++ b/ql/src/test/results/clientpositive/llap/groupby_sort_1_23.q.out
@@ -3149,6 +3149,7 @@ POSTHOOK: Input: default@outputtbl1_n18
 2	2
 3	2
 7	2
+8	4
 PREHOOK: query: EXPLAIN EXTENDED 
 SELECT * FROM 
 (SELECT key, count(1) FROM T1_n80 GROUP BY key) subq1
diff --git a/ql/src/test/results/clientpositive/llap/groupby_sort_skew_1_23.q.out b/ql/src/test/results/clientpositive/llap/groupby_sort_skew_1_23.q.out
index 74a8d57f4a..89d5f887ab 100644
--- a/ql/src/test/results/clientpositive/llap/groupby_sort_skew_1_23.q.out
+++ b/ql/src/test/results/clientpositive/llap/groupby_sort_skew_1_23.q.out
@@ -3259,6 +3259,7 @@ POSTHOOK: Input: default@outputtbl1_n13
 2	2
 3	2
 7	2
+8	4
 PREHOOK: query: EXPLAIN EXTENDED 
 SELECT * FROM 
 (SELECT key, count(1) FROM T1_n56 GROUP BY key) subq1
diff --git a/ql/src/test/results/clientpositive/llap/subquery_in_having.q.out b/ql/src/test/results/clientpositive/llap/subquery_in_having.q.out
index 81dbd625ff..b8a2847a6f 100644
--- a/ql/src/test/results/clientpositive/llap/subquery_in_having.q.out
+++ b/ql/src/test/results/clientpositive/llap/subquery_in_having.q.out
@@ -350,8 +350,7 @@ STAGE PLANS:
                     Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                     Group By Operator
                       keys: _col0 (type: string)
-                      minReductionHashAggr: 0.99
-                      mode: hash
+                      mode: final
                       outputColumnNames: _col0
                       Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                       Dummy Store
@@ -494,8 +493,7 @@ STAGE PLANS:
                     Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                     Group By Operator
                       keys: _col0 (type: string)
-                      minReductionHashAggr: 0.99
-                      mode: hash
+                      mode: final
                       outputColumnNames: _col0
                       Statistics: Num rows: 1 Data size: 188 Basic stats: COMPLETE Column stats: NONE
                       Dummy Store
