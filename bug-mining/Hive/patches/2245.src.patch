diff --git a/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java b/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
index e6493eb8b8..bcb2660172 100644
--- a/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
+++ b/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
@@ -23,7 +23,6 @@
 import java.net.URL;
 import java.util.Arrays;
 import java.util.Comparator;
-import java.util.Iterator;
 import java.net.URI;
 import java.util.HashMap;
 import java.util.List;
@@ -41,9 +40,8 @@
 import org.apache.hadoop.fs.ProxyFileSystem;
 import org.apache.hadoop.fs.Trash;
 import org.apache.hadoop.hdfs.MiniDFSCluster;
-import org.apache.hadoop.hive.shims.HadoopShims.DirectDecompressorShim;
 import org.apache.hadoop.io.LongWritable;
-import org.apache.hadoop.io.compress.CompressionCodec;
+import org.apache.hadoop.mapred.JobInProgress;
 import org.apache.hadoop.mapred.JobTracker;
 import org.apache.hadoop.mapred.MiniMRCluster;
 import org.apache.hadoop.mapred.ClusterStatus;
@@ -204,7 +202,18 @@ public int getJobTrackerPort() throws UnsupportedOperationException {
 
     @Override
     public void shutdown() throws IOException {
-      mr.shutdown();
+      MiniMRCluster.JobTrackerRunner runner = mr.getJobTrackerRunner();
+      JobTracker tracker = runner.getJobTracker();
+      if (tracker != null) {
+        for (JobInProgress running : tracker.getRunningJobs()) {
+          try {
+            running.kill();
+          } catch (Exception e) {
+            // ignore
+          }
+        }
+      }
+      runner.shutdown();
     }
 
     @Override
