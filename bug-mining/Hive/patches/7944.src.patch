diff --git a/data/conf/hivemetastore-site.xml b/data/conf/hivemetastore-site.xml
index 2e926784b7..516571ef87 100644
--- a/data/conf/hivemetastore-site.xml
+++ b/data/conf/hivemetastore-site.xml
@@ -38,5 +38,9 @@
   <description>Using property defined in HiveConf.ConfVars to test System property overriding</description>
 </property>
 
+<property>
+  <name>metastore.metadata.transformer.class</name>
+  <value>  </value>
+</property>
 
 </configuration>
diff --git a/data/conf/llap/hivemetastore-site.xml b/data/conf/llap/hivemetastore-site.xml
index f033caab38..412ddd2fc0 100644
--- a/data/conf/llap/hivemetastore-site.xml
+++ b/data/conf/llap/hivemetastore-site.xml
@@ -18,4 +18,10 @@
 -->
 
 <configuration>
+
+<property>
+  <name>metastore.metadata.transformer.class</name>
+  <value> </value>
+</property>
+
 </configuration>
diff --git a/ql/src/test/queries/clientpositive/translated_external_qopt.q b/ql/src/test/queries/clientpositive/translated_external_qopt.q
new file mode 100644
index 0000000000..dc79b17242
--- /dev/null
+++ b/ql/src/test/queries/clientpositive/translated_external_qopt.q
@@ -0,0 +1,4 @@
+set metastore.metadata.transformer.class=org.apache.hadoop.hive.metastore.MetastoreDefaultTransformer;
+
+create table t (a integer);
+desc formatted t;
diff --git a/ql/src/test/results/clientpositive/llap/translated_external_qopt.q.out b/ql/src/test/results/clientpositive/llap/translated_external_qopt.q.out
new file mode 100644
index 0000000000..918e7d2a0f
--- /dev/null
+++ b/ql/src/test/results/clientpositive/llap/translated_external_qopt.q.out
@@ -0,0 +1,45 @@
+PREHOOK: query: create table t (a integer)
+PREHOOK: type: CREATETABLE
+PREHOOK: Output: database:default
+PREHOOK: Output: default@t
+POSTHOOK: query: create table t (a integer)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: database:default
+POSTHOOK: Output: default@t
+PREHOOK: query: desc formatted t
+PREHOOK: type: DESCTABLE
+PREHOOK: Input: default@t
+POSTHOOK: query: desc formatted t
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Input: default@t
+# col_name            	data_type           	comment             
+a                   	int                 	                    
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+#### A masked pattern was here ####
+Retention:          	0                   	 
+#### A masked pattern was here ####
+Table Type:         	EXTERNAL_TABLE      	 
+Table Parameters:	 	 
+	COLUMN_STATS_ACCURATE	{\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"a\":\"true\"}}
+	EXTERNAL            	TRUE                
+	TRANSLATED_TO_EXTERNAL	TRUE                
+	bucketing_version   	2                   
+	external.table.purge	TRUE                
+	numFiles            	0                   
+	numRows             	0                   
+	rawDataSize         	0                   
+	totalSize           	0                   
+#### A masked pattern was here ####
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
index 386291d5d2..771a201516 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
@@ -1583,7 +1583,7 @@ public Database get_database_req(GetDatabaseRequest request) throws NoSuchObject
     try {
       db = getMS().getDatabase(request.getCatalogName(), request.getName());
       firePreEvent(new PreReadDatabaseEvent(db, this));
-      if (transformer != null && !isInTest) {
+      if (transformer != null) {
         db = transformer.transformDatabase(db, processorCapabilities, processorId);
       }
     } catch (MetaException | NoSuchObjectException e) {
@@ -2357,7 +2357,7 @@ private void create_table_core(final RawStore ms, final CreateTableRequest req)
       return;
     }
 
-    if (transformer != null && !isInTest) {
+    if (transformer != null) {
       tbl = transformer.transformCreateTable(tbl, processorCapabilities, processorId);
     }
     if (tbl.getParameters() != null) {
@@ -6011,7 +6011,7 @@ private void alter_table_core(String catName, String dbname, String name, Table
     Exception ex = null;
     try {
       Table oldt = get_table_core(catName, dbname, name, null);
-      if (transformer != null && !isInTest) {
+      if (transformer != null) {
         newTable = transformer.transformAlterTable(newTable, processorCapabilities, processorId);
       }
       firePreEvent(new PreAlterTableEvent(oldt, newTable, this));
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/NonCatCallsWithCatalog.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/NonCatCallsWithCatalog.java
index fdfa9d4e96..82e3fefdea 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/NonCatCallsWithCatalog.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/NonCatCallsWithCatalog.java
@@ -99,6 +99,7 @@ public abstract class NonCatCallsWithCatalog {
   public void setUp() throws Exception {
     conf = MetastoreConf.newMetastoreConf();
     MetastoreConf.setBoolVar(this.conf, ConfVars.HIVE_IN_TEST, true);
+    MetastoreConf.setVar(conf, ConfVars.METASTORE_METADATA_TRANSFORMER_CLASS, " ");
     MetaStoreTestUtils.setConfForStandloneMode(conf);
 
     // Get new client
@@ -234,11 +235,15 @@ public void databases() throws TException, URISyntaxException {
     Assert.assertEquals(expectedCatalog(), fetched.getCatalogName());
 
     Set<String> fetchedDbs = new HashSet<>(client.getAllDatabases());
-    for (String dbName : dbNames) Assert.assertTrue(fetchedDbs.contains(dbName));
+    for (String dbName : dbNames) {
+      Assert.assertTrue(fetchedDbs.contains(dbName));
+    }
 
     fetchedDbs = new HashSet<>(client.getDatabases("db*"));
     Assert.assertEquals(2, fetchedDbs.size());
-    for (String dbName : dbNames) Assert.assertTrue(fetchedDbs.contains(dbName));
+    for (String dbName : dbNames) {
+      Assert.assertTrue(fetchedDbs.contains(dbName));
+    }
 
     client.dropDatabase(dbNames[0], true, false, false);
     dir = new File(db0Location);
@@ -249,7 +254,9 @@ public void databases() throws TException, URISyntaxException {
     Assert.assertFalse(dir.exists());
 
     fetchedDbs = new HashSet<>(client.getAllDatabases());
-    for (String dbName : dbNames) Assert.assertFalse(fetchedDbs.contains(dbName));
+    for (String dbName : dbNames) {
+      Assert.assertFalse(fetchedDbs.contains(dbName));
+    }
   }
 
   @Test
@@ -271,9 +278,13 @@ public void tablesCreateDropAlterTruncate() throws TException, URISyntaxExceptio
           .addCol("col1_" + i, ColumnType.STRING_TYPE_NAME)
           .addCol("col2_" + i, ColumnType.INT_TYPE_NAME);
       // Make one have a non-standard location
-      if (i == 0) builder.setLocation(MetaStoreTestUtils.getTestWarehouseDir(tableNames[i]));
+      if (i == 0) {
+        builder.setLocation(MetaStoreTestUtils.getTestWarehouseDir(tableNames[i]));
+      }
       // Make one partitioned
-      if (i == 2) builder.addPartCol("pcol1", ColumnType.STRING_TYPE_NAME);
+      if (i == 2) {
+        builder.addPartCol("pcol1", ColumnType.STRING_TYPE_NAME);
+      }
       // Make one a materialized view
       /*
       // TODO HIVE-18991
@@ -328,10 +339,14 @@ public void tablesCreateDropAlterTruncate() throws TException, URISyntaxExceptio
     // test getAllTables
     Set<String> fetchedNames = new HashSet<>(client.getAllTables(dbName));
     Assert.assertEquals(tableNames.length, fetchedNames.size());
-    for (String tableName : tableNames) Assert.assertTrue(fetchedNames.contains(tableName));
+    for (String tableName : tableNames) {
+      Assert.assertTrue(fetchedNames.contains(tableName));
+    }
 
     fetchedNames = new HashSet<>(client.getAllTables(DEFAULT_DATABASE_NAME));
-    for (String tableName : tableNames) Assert.assertFalse(fetchedNames.contains(tableName));
+    for (String tableName : tableNames) {
+      Assert.assertFalse(fetchedNames.contains(tableName));
+    }
 
     // test getMaterializedViewsForRewriting
     /* TODO HIVE-18991
@@ -378,7 +393,9 @@ public void tablesCreateDropAlterTruncate() throws TException, URISyntaxExceptio
     */
 
     List<String> partNames = new ArrayList<>();
-    for (String partVal : partVals) partNames.add("pcol1=" + partVal);
+    for (String partVal : partVals) {
+      partNames.add("pcol1=" + partVal);
+    }
     // Truncate a table
     client.truncateTable(dbName, tableNames[0], partNames);
 
@@ -424,7 +441,9 @@ public void tablesGetExists() throws TException {
 
     Set<String> tables = new HashSet<>(client.getTables(dbName, "*e_in_other_*"));
     Assert.assertEquals(4, tables.size());
-    for (String tableName : tableNames) Assert.assertTrue(tables.contains(tableName));
+    for (String tableName : tableNames) {
+      Assert.assertTrue(tables.contains(tableName));
+    }
 
     List<String> fetchedNames = client.getTables(dbName, "*_3");
     Assert.assertEquals(1, fetchedNames.size());
@@ -452,7 +471,9 @@ public void tablesList() throws TException {
           .setTableName(tableNames[i])
           .addCol("col1_" + i, ColumnType.STRING_TYPE_NAME)
           .addCol("col2_" + i, ColumnType.INT_TYPE_NAME);
-      if (i == 0) builder.addTableParam("the_key", "the_value");
+      if (i == 0) {
+        builder.addTableParam("the_key", "the_value");
+      }
       Table table = builder.build(conf);
       table.unsetCatName();
       client.createTable(table);
@@ -586,7 +607,9 @@ public void getPartitions() throws TException {
         Arrays.asList("partcol=a0", "partcol=a1"));
     Assert.assertEquals(2, fetchedParts.size());
     Set<String> vals = new HashSet<>(fetchedParts.size());
-    for (Partition part : fetchedParts) vals.add(part.getValues().get(0));
+    for (Partition part : fetchedParts) {
+      vals.add(part.getValues().get(0));
+    }
     Assert.assertTrue(vals.contains("a0"));
     Assert.assertTrue(vals.contains("a1"));
 
@@ -961,47 +984,61 @@ public void createTableWithConstraints() throws TException {
         .onTable(parentTable)
         .addColumn("test_col1")
         .build(conf);
-    for (SQLPrimaryKey pkcol : parentPk) pkcol.unsetCatName();
+    for (SQLPrimaryKey pkcol : parentPk) {
+      pkcol.unsetCatName();
+    }
     client.addPrimaryKey(parentPk);
 
     List<SQLPrimaryKey> pk = new SQLPrimaryKeyBuilder()
         .onTable(table)
         .addColumn("col2")
         .build(conf);
-    for (SQLPrimaryKey pkcol : pk) pkcol.unsetCatName();
+    for (SQLPrimaryKey pkcol : pk) {
+      pkcol.unsetCatName();
+    }
 
     List<SQLForeignKey> fk = new SQLForeignKeyBuilder()
         .fromPrimaryKey(parentPk)
         .onTable(table)
         .addColumn("col1")
         .build(conf);
-    for (SQLForeignKey fkcol : fk) fkcol.unsetCatName();
+    for (SQLForeignKey fkcol : fk) {
+      fkcol.unsetCatName();
+    }
 
     List<SQLDefaultConstraint> dv = new SQLDefaultConstraintBuilder()
         .onTable(table)
         .addColumn("col3")
         .setDefaultVal(0)
         .build(conf);
-    for (SQLDefaultConstraint dccol : dv) dccol.unsetCatName();
+    for (SQLDefaultConstraint dccol : dv) {
+      dccol.unsetCatName();
+    }
 
     List<SQLNotNullConstraint> nn = new SQLNotNullConstraintBuilder()
         .onTable(table)
         .addColumn("col4")
         .build(conf);
-    for (SQLNotNullConstraint nncol : nn) nncol.unsetCatName();
+    for (SQLNotNullConstraint nncol : nn) {
+      nncol.unsetCatName();
+    }
 
     List<SQLUniqueConstraint> uc = new SQLUniqueConstraintBuilder()
         .onTable(table)
         .addColumn("col5")
         .build(conf);
-    for (SQLUniqueConstraint uccol : uc) uccol.unsetCatName();
+    for (SQLUniqueConstraint uccol : uc) {
+      uccol.unsetCatName();
+    }
 
     List<SQLCheckConstraint> cc = new SQLCheckConstraintBuilder()
         .onTable(table)
         .addColumn("col6")
         .setCheckExpression("> 0")
         .build(conf);
-    for (SQLCheckConstraint cccol : cc) cccol.unsetCatName();
+    for (SQLCheckConstraint cccol : cc) {
+      cccol.unsetCatName();
+    }
 
     client.createTableWithConstraints(table, pk, fk, uc, nn, dv, cc);
 
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
index 9743c92110..f71d1fdd91 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
@@ -140,6 +140,7 @@ public void setUp() throws Exception {
     conf.set("hive.key4", "0");
     conf.set("datanucleus.autoCreateTables", "false");
     conf.set("hive.in.test", "true");
+    MetastoreConf.setVar(conf, ConfVars.METASTORE_METADATA_TRANSFORMER_CLASS, " ");
 
     MetaStoreTestUtils.setConfForStandloneMode(conf);
     MetastoreConf.setLongVar(conf, ConfVars.BATCH_RETRIEVE_MAX, 2);
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStoreTxns.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStoreTxns.java
index faf6cfa5aa..3030d2aeb6 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStoreTxns.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestHiveMetaStoreTxns.java
@@ -76,7 +76,7 @@
 @Category(MetastoreUnitTest.class)
 public class TestHiveMetaStoreTxns {
 
-  private static Configuration conf = MetastoreConf.newMetastoreConf();
+  private static Configuration conf;
   private static IMetaStoreClient client;
   private Connection conn;
 
@@ -321,9 +321,13 @@ public void stringifyValidTxns() throws Exception {
     Assert.assertEquals(2, validTxns.getInvalidTransactions().length);
     boolean sawThree = false, sawFive = false;
     for (long tid : validTxns.getInvalidTransactions()) {
-      if (tid == 3)  sawThree = true;
-      else if (tid == 5) sawFive = true;
-      else  Assert.fail("Unexpected value " + tid);
+      if (tid == 3) {
+        sawThree = true;
+      } else if (tid == 5) {
+        sawFive = true;
+      } else {
+        Assert.fail("Unexpected value " + tid);
+      }
     }
     Assert.assertTrue(sawThree);
     Assert.assertTrue(sawFive);
@@ -443,6 +447,8 @@ public void testGetLatestCommittedCompactionInfo() throws Exception {
 
   @BeforeClass
   public static void setUpDB() throws Exception {
+    conf = MetastoreConf.newMetastoreConf();
+    MetastoreConf.setVar(conf, ConfVars.METASTORE_METADATA_TRANSFORMER_CLASS, " ");
     conf.setBoolean(ConfVars.HIVE_IN_TEST.getVarname(), true);
     MetaStoreTestUtils.setConfForStandloneMode(conf);
     TestTxnDbUtil.setConfValues(conf);
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreEventListener.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreEventListener.java
index 338ca57510..67d6989d72 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreEventListener.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreEventListener.java
@@ -231,7 +231,7 @@ public void testListener() throws Exception {
         .addCol("a", "string")
         .addPartCol("b", "string")
         .create(msc, conf);
-    PreCreateTableEvent preTblEvent = (PreCreateTableEvent)(preNotifyList.get(preNotifyList.size() - 1));
+    PreCreateTableEvent preTblEvent = (PreCreateTableEvent) (preNotifyList.get(preNotifyList.size() - 1));
     listSize++;
     Table tbl = msc.getTable(dbName, tblName);
     validateCreateTable(tbl, preTblEvent.getTable());
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestPartitionManagement.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestPartitionManagement.java
index b0853f2db4..9d0727495f 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestPartitionManagement.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestPartitionManagement.java
@@ -69,6 +69,7 @@ public void setUp() throws Exception {
     conf = MetastoreConf.newMetastoreConf();
     conf.setClass(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),
       MsckPartitionExpressionProxy.class, PartitionExpressionProxy.class);
+    MetastoreConf.setVar(conf, ConfVars.METASTORE_METADATA_TRANSFORMER_CLASS, " ");
     MetaStoreTestUtils.setConfForStandloneMode(conf);
     conf.setBoolean(ConfVars.MULTITHREADED.getVarname(), false);
     conf.setBoolean(ConfVars.HIVE_IN_TEST.getVarname(), true);
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java
index b9fa89e081..c684683807 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java
@@ -22,8 +22,6 @@
 
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hive.metastore.annotation.MetastoreCheckinTest;
-import org.apache.hadoop.hive.metastore.api.Database;
-import org.apache.hadoop.hive.metastore.api.Table;
 import org.apache.hadoop.hive.metastore.client.builder.DatabaseBuilder;
 import org.apache.hadoop.hive.metastore.client.builder.TableBuilder;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestTablesCreateDropAlterTruncate.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestTablesCreateDropAlterTruncate.java
index 41e8ee6a2a..bc5f35f7c7 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestTablesCreateDropAlterTruncate.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestTablesCreateDropAlterTruncate.java
@@ -52,7 +52,6 @@
 import org.apache.thrift.TApplicationException;
 import org.apache.thrift.TException;
 import org.apache.thrift.protocol.TProtocolException;
-import org.apache.thrift.transport.TTransportException;
 import org.junit.After;
 import org.junit.Assert;
 import org.junit.Before;
@@ -104,6 +103,8 @@ public static void startMetaStores() {
     extraConf.put("fs.trash.checkpoint.interval", "30");  // FS_TRASH_CHECKPOINT_INTERVAL_KEY
     extraConf.put("fs.trash.interval", "30");             // FS_TRASH_INTERVAL_KEY (hadoop-2)
     extraConf.put(ConfVars.HIVE_IN_TEST.getVarname(), "true");
+    extraConf.put(ConfVars.METASTORE_METADATA_TRANSFORMER_CLASS.getVarname(), " ");
+
     startMetaStores(msConf, extraConf);
   }
 
@@ -153,7 +154,7 @@ public void setUp() throws Exception {
         new TableBuilder()
             .setTableName("external_table_for_test")
             .addCol("test_col", "int")
-            .setLocation(metaStore.getWarehouseRoot() + "/external/table_dir")
+            .setLocation(metaStore.getExternalWarehouseRoot() + "/external/table_dir")
             .addTableParam("EXTERNAL", "TRUE")
             .setType("EXTERNAL_TABLE")
             .create(client, metaStore.getConf());
@@ -1182,9 +1183,13 @@ public void tablesInOtherCatalogs() throws TException, URISyntaxException {
           .addCol("col1_" + i, ColumnType.STRING_TYPE_NAME)
           .addCol("col2_" + i, ColumnType.INT_TYPE_NAME);
       // Make one have a non-standard location
-      if (i == 0) builder.setLocation(MetaStoreTestUtils.getTestWarehouseDir(tableNames[i]));
+      if (i == 0) {
+        builder.setLocation(MetaStoreTestUtils.getTestWarehouseDir(tableNames[i]));
+      }
       // Make one partitioned
-      if (i == 2) builder.addPartCol("pcol1", ColumnType.STRING_TYPE_NAME);
+      if (i == 2) {
+        builder.addPartCol("pcol1", ColumnType.STRING_TYPE_NAME);
+      }
       // Make one a materialized view
       if (i == 3) {
         builder.setType(TableType.MATERIALIZED_VIEW.name())
@@ -1232,10 +1237,14 @@ public void tablesInOtherCatalogs() throws TException, URISyntaxException {
     // test getAllTables
     Set<String> fetchedNames = new HashSet<>(client.getAllTables(catName, dbName));
     Assert.assertEquals(tableNames.length, fetchedNames.size());
-    for (String tableName : tableNames) Assert.assertTrue(fetchedNames.contains(tableName));
+    for (String tableName : tableNames) {
+      Assert.assertTrue(fetchedNames.contains(tableName));
+    }
 
     fetchedNames = new HashSet<>(client.getAllTables(DEFAULT_DATABASE_NAME));
-    for (String tableName : tableNames) Assert.assertFalse(fetchedNames.contains(tableName));
+    for (String tableName : tableNames) {
+      Assert.assertFalse(fetchedNames.contains(tableName));
+    }
 
     // test getMaterializedViewsForRewriting
     List<String> materializedViews = client.getMaterializedViewsForRewriting(catName, dbName);
@@ -1279,7 +1288,9 @@ public void tablesInOtherCatalogs() throws TException, URISyntaxException {
     client.updateCreationMetadata(catName, dbName, tableNames[3], cm);
 
     List<String> partNames = new ArrayList<>();
-    for (String partVal : partVals) partNames.add("pcol1=" + partVal);
+    for (String partVal : partVals) {
+      partNames.add("pcol1=" + partVal);
+    }
     // Truncate a table
     client.truncateTable(catName, dbName, tableNames[0], partNames);
 
