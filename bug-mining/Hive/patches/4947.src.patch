diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java
index cda5f39dda..f1eba5d21f 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java
@@ -866,7 +866,6 @@ else if (prev != null && next.maxTransaction == prev.maxTransaction
        * {@link txnList}.  Note that 'original' files are logically a base_Long.MIN_VALUE and thus
        * cannot have any data for an open txn.  We could check {@link deltas} has files to cover
        * [1,n] w/o gaps but this would almost never happen...*/
-      //todo: this should only care about 'open' tnxs (HIVE-14211)
       long[] exceptions = txnList.getInvalidTransactions();
       String minOpenTxn = exceptions != null && exceptions.length > 0 ?
         Long.toString(exceptions[0]) : "x";
@@ -910,11 +909,6 @@ public List<FileStatus> getObsolete() {
    * files within the snapshot.
    */
   private static boolean isValidBase(long baseTxnId, ValidTxnList txnList) {
-    /*This implementation is suboptimal.  It considers open/aborted txns invalid while we are only
-    * concerned with 'open' ones.  (Compaction removes any data that belongs to aborted txns and
-    * reads skip anything that belongs to aborted txn, thus base_7 is still OK if the only exception
-    * is txn 5 which is aborted).  So this implementation can generate false positives. (HIVE-14211)
-    * */
     if(baseTxnId == Long.MIN_VALUE) {
       //such base is created by 1st compaction in case of non-acid to acid table conversion
       //By definition there are no open txns with id < 1.
