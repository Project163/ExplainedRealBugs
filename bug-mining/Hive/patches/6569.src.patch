diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
index e06949928d..46a9f7d1e6 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
@@ -5090,7 +5090,7 @@ private int createTableLike(Hive db, CreateTableLikeDesc crtTbl) throws Exceptio
 
     // If location is specified - ensure that it is a full qualified name
     if (DDLTask.doesTableNeedLocation(tbl)) {
-      makeLocationQualified(tbl.getDbName(), tbl.getTTable().getSd(), tbl.getTableName(), conf);
+      makeLocationQualified(tbl.getDbName(), tbl, conf);
     }
 
     if (crtTbl.getLocation() == null && !tbl.isPartitioned()
@@ -5267,17 +5267,21 @@ public String getName() {
    * @param name
    *          Object name.
    */
-  public static void makeLocationQualified(String databaseName, StorageDescriptor sd,
-      String name, HiveConf conf) throws HiveException {
+  public static void makeLocationQualified(String databaseName, Table table, HiveConf conf) throws HiveException {
     Path path = null;
+    StorageDescriptor sd = table.getTTable().getSd();
+    String name = table.getTableName();
     if (!sd.isSetLocation())
     {
-      // Location is not set, leave it as-is if this is not a default DB
-      if (databaseName.equalsIgnoreCase(Warehouse.DEFAULT_DATABASE_NAME))
-      {
-        // Default database name path is always ignored, use METASTOREWAREHOUSE and object name
-        // instead
-        path = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.METASTOREWAREHOUSE), org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.encodeTableName(name.toLowerCase()));
+      // Leave temp tables as-is, default location will be handled by SessionHiveMetastoreClient.
+      if (!table.isTemporary()) {
+        // Location is not set, leave it as-is if this is not a default DB
+        if (databaseName.equalsIgnoreCase(Warehouse.DEFAULT_DATABASE_NAME))
+        {
+          // Default database name path is always ignored, use METASTOREWAREHOUSE and object name
+          // instead
+          path = new Path(HiveConf.getVar(conf, HiveConf.ConfVars.METASTOREWAREHOUSE), org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.encodeTableName(name.toLowerCase()));
+        }
       }
     }
     else
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java
index 209fdfb287..58c8960c09 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java
@@ -456,6 +456,11 @@ private void createTempTable(org.apache.hadoop.hive.metastore.api.Table tbl,
 
     // Create temp table directory
     Warehouse wh = getWh();
+    if (tbl.getSd().getLocation() == null) {
+      // Temp tables that do not go through SemanticAnalyzer may not have location set - do it here.
+      // For example export of acid tables generates a query plan that creates a temp table.
+      tbl.getSd().setLocation(SessionState.generateTempTableLocation(conf));
+    }
     Path tblPath = wh.getDnsPath(new Path(tbl.getSd().getLocation()));
     if (tblPath == null) {
       throw new MetaException("Temp table path not set for " + tbl.getTableName());
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 2e055aba4b..00957ea6ef 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -13144,9 +13144,7 @@ ASTNode analyzeCreateTable(
         try {
           // Generate a unique ID for temp table path.
           // This path will be fixed for the life of the temp table.
-          Path path = new Path(SessionState.getTempTableSpace(conf), UUID.randomUUID().toString());
-          path = Warehouse.getDnsPath(path, conf);
-          location = path.toString();
+          location = SessionState.generateTempTableLocation(conf);
         } catch (MetaException err) {
           throw new SemanticException("Error while generating temp table path:", err);
         }
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java
index 04292787a8..871844b30d 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java
@@ -822,7 +822,7 @@ public Table toTable(HiveConf conf) throws HiveException {
 
     if (DDLTask.doesTableNeedLocation(tbl)) {
       // If location is specified - ensure that it is a full qualified name
-      DDLTask.makeLocationQualified(tbl.getDbName(), tbl.getTTable().getSd(), tableName, conf);
+      DDLTask.makeLocationQualified(tbl.getDbName(), tbl, conf);
     }
 
     if (isExternal()) {
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java b/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
index 6ff8f99a0c..81864f5f67 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java
@@ -59,7 +59,9 @@
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
 import org.apache.hadoop.hive.conf.HiveConfUtil;
 import org.apache.hadoop.hive.metastore.ObjectStore;
+import org.apache.hadoop.hive.metastore.Warehouse;
 import org.apache.hadoop.hive.metastore.api.ColumnStatisticsObj;
+import org.apache.hadoop.hive.metastore.api.MetaException;
 import org.apache.hadoop.hive.metastore.cache.CachedStore;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
 import org.apache.hadoop.hive.metastore.utils.MetaStoreUtils;
@@ -844,6 +846,12 @@ public Path getTempTableSpace() {
     return this.hdfsTmpTableSpace;
   }
 
+  public static String generateTempTableLocation(Configuration conf) throws MetaException {
+    Path path = new Path(SessionState.getTempTableSpace(conf), UUID.randomUUID().toString());
+    path = Warehouse.getDnsPath(path, conf);
+    return path.toString();
+  }
+
   @VisibleForTesting
   void releaseSessionLockFile() throws IOException {
     if (hdfsSessionPath != null && hdfsSessionPathLockFile != null) {
