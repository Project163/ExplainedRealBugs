diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java
index 2b1438d539..c8003f5678 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java
@@ -263,7 +263,9 @@ private boolean hasFilter(int alias) {
   @Override
   public void closeOp(boolean abort) throws HiveException {
     try {
-      if (mapJoinTables != null) {
+      if (mapJoinTables == null) {
+        LOG.debug("mapJoinTables is null");
+      } else {
         flushToFile();
       }
       super.closeOp(abort);
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java
index 1104a2b1a1..055d13eefb 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java
@@ -248,8 +248,10 @@ public void processOp(Object row, int tag) throws HiveException {
           storage[pos] = null;
         }
       }
-    } catch (SerDeException e) {
-      throw new HiveException(e);
+    } catch (Exception e) {
+      String msg = "Unxpected exception: " + e.getMessage();
+      LOG.error(msg, e);
+      throw new HiveException(msg, e);
     }
   }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
index 36671b6dff..22374b20d4 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
@@ -546,6 +546,7 @@ protected boolean allInitializedParentsAreClosed() {
         if(parent==null){
           continue;
         }
+        LOG.debug("allInitializedParentsAreClosed? parent.state = " + parent.state);
         if (!(parent.state == State.CLOSE || parent.state == State.UNINIT)) {
           return false;
         }
@@ -565,6 +566,7 @@ public void close(boolean abort) throws HiveException {
 
     // check if all parents are finished
     if (!allInitializedParentsAreClosed()) {
+      LOG.debug("Not all parent operators are closed. Not closing.");
       return;
     }
 
@@ -585,6 +587,7 @@ public void close(boolean abort) throws HiveException {
       }
 
       for (Operator<? extends OperatorDesc> op : childOperators) {
+        LOG.debug("Closing child = " + op);
         op.close(abort);
       }
 
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
index 55ce0fc6d9..c951fcabbb 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
@@ -349,14 +349,15 @@ private void startForward(boolean inputFileChangeSenstive, String bigTableBucket
         setUpFetchOpContext(fetchOp, alias, bigTableBucket);
       }
 
+      // get the root operator
+      Operator<? extends OperatorDesc> forwardOp = work.getAliasToWork().get(alias);
       if (fetchOp.isEmptyTable()) {
         //generate empty hashtable for empty table
         this.generateDummyHashTable(alias, bigTableBucket);
+        forwardOp.close(false);
         continue;
       }
 
-      // get the root operator
-      Operator<? extends OperatorDesc> forwardOp = work.getAliasToWork().get(alias);
       // walk through the operator tree
       while (!forwardOp.getDone()) {
         InspectableObject row = fetchOp.getNextRow();
@@ -375,6 +376,9 @@ private void startForward(boolean inputFileChangeSenstive, String bigTableBucket
 
   private void initializeOperators(Map<FetchOperator, JobConf> fetchOpJobConfMap)
       throws HiveException {
+    for (Map.Entry<String, Operator<? extends OperatorDesc>> entry : work.getAliasToWork().entrySet()) {
+      LOG.debug("initializeOperators: " +  entry.getKey() + ", children = "  + entry.getValue().getChildOperators());
+    }
     // this mapper operator is used to initialize all the operators
     for (Map.Entry<String, FetchWork> entry : work.getAliasToFetchWork().entrySet()) {
       if (entry.getValue() == null) {
@@ -419,6 +423,7 @@ private void initializeOperators(Map<FetchOperator, JobConf> fetchOpJobConfMap)
 
   private void generateDummyHashTable(String alias, String bigBucketFileName)
       throws HiveException,IOException {
+    LOG.debug("generating dummy for " + alias);
     // find the (byte)tag for the map join(HashTableSinkOperator)
     Operator<? extends OperatorDesc> parentOp = work.getAliasToWork().get(alias);
     Operator<? extends OperatorDesc> childOp = parentOp.getChildOperators().get(0);
