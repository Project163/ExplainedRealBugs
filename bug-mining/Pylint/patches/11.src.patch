diff --git a/checkers/format.py b/checkers/format.py
index e7eafa8aa..602a1574f 100644
--- a/checkers/format.py
+++ b/checkers/format.py
@@ -31,6 +31,7 @@ from logilab.astng import nodes
 
 from pylint.interfaces import IRawChecker, IASTNGChecker
 from pylint.checkers import BaseRawChecker
+from pylint.checkers.misc import guess_encoding, is_ascii
 
 MSGS = {
     'C0301': ('Line too long (%s/%s)',
@@ -178,6 +179,25 @@ class FormatChecker(BaseRawChecker):
         self._lines = None
         self._visited_lines = None
 
+    def process_module(self, stream):
+        """extracts encoding from the stream and
+        decodes each line, so that international
+        text's lenght properly calculated.
+        """
+        data = stream.read()
+        line_generator = stream.readline
+
+        ascii, lineno = is_ascii(data)
+        if not ascii:
+            encoding = guess_encoding(data)
+            if encoding is not None:
+                line_generator = lambda: stream.readline().decode(encoding,
+                                                                  'replace')
+        del data
+
+        stream.seek(0)
+        self.process_tokens(tokenize.generate_tokens(line_generator))
+
     def new_line(self, tok_type, line, line_num, junk):
         """a new line has been encountered, process it if necessary"""
         if not tok_type in junk:
diff --git a/test/input/func_noerror_long_utf8_line.py b/test/input/func_noerror_long_utf8_line.py
new file mode 100644
index 000000000..b4114f2f5
--- /dev/null
+++ b/test/input/func_noerror_long_utf8_line.py
@@ -0,0 +1,8 @@
+# -*- coding: utf-8 -*-
+"""this utf-8 doc string have some     non ASCII caracters like 'é', or '¢»ß'"""
+### check also comments with some     more non ASCII caracters like 'é' or '¢»ß'
+
+__revision__ = 1100
+print "------------------------------------------------------------------------"
+print "-----------------------------------------------------------------------é"
+
