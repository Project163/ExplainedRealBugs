{"url":"https://api.github.com/repos/sqlalchemy/sqlalchemy/issues/2985","repository_url":"https://api.github.com/repos/sqlalchemy/sqlalchemy","labels_url":"https://api.github.com/repos/sqlalchemy/sqlalchemy/issues/2985/labels{/name}","comments_url":"https://api.github.com/repos/sqlalchemy/sqlalchemy/issues/2985/comments","events_url":"https://api.github.com/repos/sqlalchemy/sqlalchemy/issues/2985/events","html_url":"https://github.com/sqlalchemy/sqlalchemy/issues/2985","id":384629864,"node_id":"MDU6SXNzdWUzODQ2Mjk4NjQ=","number":2985,"title":"simplify pool recycle logic","user":{"login":"sqlalchemy-bot","id":36047385,"node_id":"MDQ6VXNlcjM2MDQ3Mzg1","avatar_url":"https://avatars.githubusercontent.com/u/36047385?v=4","gravatar_id":"","url":"https://api.github.com/users/sqlalchemy-bot","html_url":"https://github.com/sqlalchemy-bot","followers_url":"https://api.github.com/users/sqlalchemy-bot/followers","following_url":"https://api.github.com/users/sqlalchemy-bot/following{/other_user}","gists_url":"https://api.github.com/users/sqlalchemy-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/sqlalchemy-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sqlalchemy-bot/subscriptions","organizations_url":"https://api.github.com/users/sqlalchemy-bot/orgs","repos_url":"https://api.github.com/users/sqlalchemy-bot/repos","events_url":"https://api.github.com/users/sqlalchemy-bot/events{/privacy}","received_events_url":"https://api.github.com/users/sqlalchemy-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":1141269142,"node_id":"MDU6TGFiZWwxMTQxMjY5MTQy","url":"https://api.github.com/repos/sqlalchemy/sqlalchemy/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":1141273873,"node_id":"MDU6TGFiZWwxMTQxMjczODcz","url":"https://api.github.com/repos/sqlalchemy/sqlalchemy/labels/high%20priority","name":"high priority","color":"C0B0E0","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":{"url":"https://api.github.com/repos/sqlalchemy/sqlalchemy/milestones/74","html_url":"https://github.com/sqlalchemy/sqlalchemy/milestone/74","labels_url":"https://api.github.com/repos/sqlalchemy/sqlalchemy/milestones/74/labels","id":3850658,"node_id":"MDk6TWlsZXN0b25lMzg1MDY1OA==","number":74,"title":"0.9.4","description":null,"creator":{"login":"sqlalchemy-bot","id":36047385,"node_id":"MDQ6VXNlcjM2MDQ3Mzg1","avatar_url":"https://avatars.githubusercontent.com/u/36047385?v=4","gravatar_id":"","url":"https://api.github.com/users/sqlalchemy-bot","html_url":"https://github.com/sqlalchemy-bot","followers_url":"https://api.github.com/users/sqlalchemy-bot/followers","following_url":"https://api.github.com/users/sqlalchemy-bot/following{/other_user}","gists_url":"https://api.github.com/users/sqlalchemy-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/sqlalchemy-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sqlalchemy-bot/subscriptions","organizations_url":"https://api.github.com/users/sqlalchemy-bot/orgs","repos_url":"https://api.github.com/users/sqlalchemy-bot/repos","events_url":"https://api.github.com/users/sqlalchemy-bot/events{/privacy}","received_events_url":"https://api.github.com/users/sqlalchemy-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":0,"closed_issues":32,"state":"closed","created_at":"2018-11-27T04:30:13Z","updated_at":"2018-11-28T16:50:02Z","due_on":null,"closed_at":"2018-11-28T16:50:02Z"},"comments":5,"created_at":"2014-03-05T05:22:08Z","updated_at":"2014-05-10T19:51:45Z","closed_at":"2014-03-22T22:46:07Z","author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"**Migrated issue, originally created by Michael Bayer ([@zzzeek](https://github.com/zzzeek))**\n\nusing a simple invalidation time we can do away with all the \"pool replacement\" logic.    the current logic is subject to a pretty obvious race condition, where as many connections all hit a disconnect wall, all of the Connection objects hosting them will simultaneously call upon self.engine.dispose().  this means we could have N pools generated and immediately chucked within a disconnect cycle.\n\nthe patch below removes all of that and replaces with a simple timeout which incurs no overhead and no race conditions.   the only difference is that the \"bad\" connections hang around until they are invalidated on checkout.\n\n\n```\ndiff --git a/lib/sqlalchemy/engine/base.py b/lib/sqlalchemy/engine/base.py\nindex 888a15f..20b5227 100644\n--- a/lib/sqlalchemy/engine/base.py\n+++ b/lib/sqlalchemy/engine/base.py\n@@ -1084,9 +1084,7 @@ class Connection(Connectable):\n                 del self._is_disconnect\n                 dbapi_conn_wrapper = self.connection\n                 self.invalidate(e)\n-                if not hasattr(dbapi_conn_wrapper, '_pool') or \\\n-                        dbapi_conn_wrapper._pool is self.engine.pool:\n-                    self.engine.dispose()\n+                self.engine.pool._invalidate(dbapi_conn_wrapper)\n             if self.should_close_with_result:\n                 self.close()\n \n@@ -1496,7 +1494,7 @@ class Engine(Connectable, log.Identified):\n         the engine are not affected.\n \n         \"\"\"\n-        self.pool = self.pool._replace()\n+        self.pool.dispose()\n \n     def _execute_default(self, default):\n         with self.contextual_connect() as conn:\ndiff --git a/lib/sqlalchemy/orm/strategies.py b/lib/sqlalchemy/orm/strategies.py\nindex 473b665..4a07e78 100644\n--- a/lib/sqlalchemy/orm/strategies.py\n+++ b/lib/sqlalchemy/orm/strategies.py\n@@ -528,7 +528,6 @@ class LazyLoader(AbstractRelationshipLoader):\n     def _emit_lazyload(self, strategy_options, session, state, ident_key, passive):\n         q = session.query(self.mapper)._adapt_all_clauses()\n \n-\n         if self.parent_property.secondary is not None:\n             q = q.select_from(self.mapper, self.parent_property.secondary)\n \ndiff --git a/lib/sqlalchemy/pool.py b/lib/sqlalchemy/pool.py\nindex af9b8fc..f78825e 100644\n--- a/lib/sqlalchemy/pool.py\n+++ b/lib/sqlalchemy/pool.py\n@@ -210,6 +210,7 @@ class Pool(log.Identified):\n         self._threadconns = threading.local()\n         self._creator = creator\n         self._recycle = recycle\n+        self._invalidate_time = 0\n         self._use_threadlocal = use_threadlocal\n         if reset_on_return in ('rollback', True, reset_rollback):\n             self._reset_on_return = reset_rollback\n@@ -276,6 +277,22 @@ class Pool(log.Identified):\n \n         return _ConnectionRecord(self)\n \n+    def _invalidate(self, connection):\n+        \"\"\"Mark all connections established within the generation\n+        of the given connection as invalidated.\n+\n+        If this pool's last invalidate time is before when the given\n+        connection was created, update the timestamp til now.  Otherwise,\n+        no action is performed.\n+\n+        Connections with a start time prior to this pool's invalidation\n+        time will be recycled upon next checkout.\n+        \"\"\"\n+        rec = getattr(connection, \"_connection_record\", None)\n+        if not rec or self._invalidate_time < rec.starttime:\n+            self._invalidate_time = time.time()\n+\n+\n     def recreate(self):\n         \"\"\"Return a new :class:`.Pool`, of the same class as this one\n         and configured with identical creation arguments.\n@@ -301,17 +318,6 @@ class Pool(log.Identified):\n \n         raise NotImplementedError()\n \n-    def _replace(self):\n-        \"\"\"Dispose + recreate this pool.\n-\n-        Subclasses may employ special logic to\n-        move threads waiting on this pool to the\n-        new one.\n-\n-        \"\"\"\n-        self.dispose()\n-        return self.recreate()\n-\n     def connect(self):\n         \"\"\"Return a DBAPI connection from the pool.\n \n@@ -483,6 +489,7 @@ class _ConnectionRecord(object):\n         self.connection = None\n \n     def get_connection(self):\n+        recycle = False\n         if self.connection is None:\n             self.connection = self.__connect()\n             self.info.clear()\n@@ -493,6 +500,15 @@ class _ConnectionRecord(object):\n             self.__pool.logger.info(\n                     \"Connection %r exceeded timeout; recycling\",\n                     self.connection)\n+            recycle = True\n+        elif self.__pool._invalidate_time > self.starttime:\n+            self.__pool.logger.info(\n+                    \"Connection %r invalidated due to pool invalidation; recycling\",\n+                    self.connection\n+                    )\n+            recycle = True\n+\n+        if recycle:\n             self.__close()\n             self.connection = self.__connect()\n             self.info.clear()\n@@ -911,8 +927,6 @@ class QueuePool(Pool):\n         try:\n             wait = use_overflow and self._overflow >= self._max_overflow\n             return self._pool.get(wait, self._timeout)\n-        except sqla_queue.SAAbort as aborted:\n-            return aborted.context._do_get()\n         except sqla_queue.Empty:\n             if use_overflow and self._overflow >= self._max_overflow:\n                 if not wait:\n@@ -974,12 +988,6 @@ class QueuePool(Pool):\n         self._overflow = 0 - self.size()\n         self.logger.info(\"Pool disposed. %s\", self.status())\n \n-    def _replace(self):\n-        self.dispose()\n-        np = self.recreate()\n-        self._pool.abort(np)\n-        return np\n-\n     def status(self):\n         return \"Pool size: %d  Connections in pool: %d \"\\\n                 \"Current Overflow: %d Current Checked out \"\\\ndiff --git a/test/engine/test_pool.py b/test/engine/test_pool.py\nindex fc6f3dc..cde19b3 100644\n--- a/test/engine/test_pool.py\n+++ b/test/engine/test_pool.py\n@@ -1069,7 +1069,8 @@ class QueuePoolTest(PoolTestBase):\n                 # inside the queue, before we invalidate the other\n                 # two conns\n                 time.sleep(.2)\n-                p2 = p._replace()\n+                p._invalidate(c2)\n+                c2.invalidate()\n \n                 for t in threads:\n                     t.join(join_timeout)\n@@ -1079,19 +1080,18 @@ class QueuePoolTest(PoolTestBase):\n     @testing.requires.threading_with_mock\n     def test_notify_waiters(self):\n         dbapi = MockDBAPI()\n+\n         canary = []\n-        def creator1():\n+        def creator():\n             canary.append(1)\n             return dbapi.connect()\n-        def creator2():\n-            canary.append(2)\n-            return dbapi.connect()\n-        p1 = pool.QueuePool(creator=creator1,\n+        p1 = pool.QueuePool(creator=creator,\n                            pool_size=1, timeout=None,\n                            max_overflow=0)\n-        p2 = pool.NullPool(creator=creator2)\n+        #p2 = pool.NullPool(creator=creator2)\n         def waiter(p):\n             conn = p.connect()\n+            canary.append(2)\n             time.sleep(.5)\n             conn.close()\n \n@@ -1104,12 +1104,14 @@ class QueuePoolTest(PoolTestBase):\n             threads.append(t)\n         time.sleep(.5)\n         eq_(canary, [1])\n-        p1._pool.abort(p2)\n+\n+        c1.invalidate()\n+        p1._invalidate(c1)\n \n         for t in threads:\n             t.join(join_timeout)\n \n-        eq_(canary, [1, 2, 2, 2, 2, 2])\n+        eq_(canary, [1, 1, 2, 2, 2, 2, 2])\n \n     def test_dispose_closes_pooled(self):\n         dbapi = MockDBAPI()\ndiff --git a/test/engine/test_reconnect.py b/test/engine/test_reconnect.py\nindex ba336a1..a3ad9c5 100644\n--- a/test/engine/test_reconnect.py\n+++ b/test/engine/test_reconnect.py\n@@ -146,16 +146,20 @@ class MockReconnectTest(fixtures.TestBase):\n         # close shouldnt break\n \n         conn.close()\n-        is_not_(self.db.pool, db_pool)\n-\n-        # ensure all connections closed (pool was recycled)\n \n+        # ensure one connection closed...\n         eq_(\n             [c.close.mock_calls for c in self.dbapi.connections],\n-            [[call()], [call()]]\n+            [[call()], []]\n         )\n \n         conn = self.db.connect()\n+\n+        eq_(\n+            [c.close.mock_calls for c in self.dbapi.connections],\n+            [[call()], [call()], []]\n+        )\n+\n         conn.execute(select([1]))\n         conn.close()\n \n@@ -534,8 +538,6 @@ class RealReconnectTest(fixtures.TestBase):\n         # invalidate() also doesn't screw up\n         assert_raises(exc.DBAPIError, engine.connect)\n \n-        # pool was recreated\n-        assert engine.pool is not p1\n \n     def test_null_pool(self):\n         engine = \\\n\n```\n\n\n","closed_by":{"login":"sqlalchemy-bot","id":36047385,"node_id":"MDQ6VXNlcjM2MDQ3Mzg1","avatar_url":"https://avatars.githubusercontent.com/u/36047385?v=4","gravatar_id":"","url":"https://api.github.com/users/sqlalchemy-bot","html_url":"https://github.com/sqlalchemy-bot","followers_url":"https://api.github.com/users/sqlalchemy-bot/followers","following_url":"https://api.github.com/users/sqlalchemy-bot/following{/other_user}","gists_url":"https://api.github.com/users/sqlalchemy-bot/gists{/gist_id}","starred_url":"https://api.github.com/users/sqlalchemy-bot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sqlalchemy-bot/subscriptions","organizations_url":"https://api.github.com/users/sqlalchemy-bot/orgs","repos_url":"https://api.github.com/users/sqlalchemy-bot/repos","events_url":"https://api.github.com/users/sqlalchemy-bot/events{/privacy}","received_events_url":"https://api.github.com/users/sqlalchemy-bot/received_events","type":"User","user_view_type":"public","site_admin":false},"reactions":{"url":"https://api.github.com/repos/sqlalchemy/sqlalchemy/issues/2985/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sqlalchemy/sqlalchemy/issues/2985/timeline","performed_via_github_app":null,"state_reason":"completed"}