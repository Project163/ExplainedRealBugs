{"url":"https://api.github.com/repos/streamlit/streamlit/issues/6103","repository_url":"https://api.github.com/repos/streamlit/streamlit","labels_url":"https://api.github.com/repos/streamlit/streamlit/issues/6103/labels{/name}","comments_url":"https://api.github.com/repos/streamlit/streamlit/issues/6103/comments","events_url":"https://api.github.com/repos/streamlit/streamlit/issues/6103/events","html_url":"https://github.com/streamlit/streamlit/issues/6103","id":1580843486,"node_id":"I_kwDODCoeTs5eOcHe","number":6103,"title":"st.cache_resource (v 1.18) vs st.experimental_singleton (v 1.17): attributeerror with cache_resource ","user":{"login":"francesco12357","id":72600937,"node_id":"MDQ6VXNlcjcyNjAwOTM3","avatar_url":"https://avatars.githubusercontent.com/u/72600937?v=4","gravatar_id":"","url":"https://api.github.com/users/francesco12357","html_url":"https://github.com/francesco12357","followers_url":"https://api.github.com/users/francesco12357/followers","following_url":"https://api.github.com/users/francesco12357/following{/other_user}","gists_url":"https://api.github.com/users/francesco12357/gists{/gist_id}","starred_url":"https://api.github.com/users/francesco12357/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/francesco12357/subscriptions","organizations_url":"https://api.github.com/users/francesco12357/orgs","repos_url":"https://api.github.com/users/francesco12357/repos","events_url":"https://api.github.com/users/francesco12357/events{/privacy}","received_events_url":"https://api.github.com/users/francesco12357/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":1516285324,"node_id":"MDU6TGFiZWwxNTE2Mjg1MzI0","url":"https://api.github.com/repos/streamlit/streamlit/labels/type:bug","name":"type:bug","color":"D93F0B","default":false,"description":"Something isn't working"},{"id":3230104487,"node_id":"MDU6TGFiZWwzMjMwMTA0NDg3","url":"https://api.github.com/repos/streamlit/streamlit/labels/priority:P1","name":"priority:P1","color":"ff4b4b","default":false,"description":""}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2023-02-11T13:31:17Z","updated_at":"2023-02-14T20:52:26Z","closed_at":"2023-02-14T20:52:26Z","author_association":"NONE","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"### Checklist\n\n- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.\n- [X] I added a very descriptive title to this issue.\n- [X] I have provided sufficient information below to help reproduce this issue.\n\n### Summary\n\nAttributeError\r\nTraceback:\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\scriptrunner\\script_runner.py\", line 565, in _run_script\r\n    exec(code, module.__dict__)\r\nFile \"C:\\Users\\A260219\\Jupyter\\bloomberg\\prova.py\", line 2126, in <module>\r\n    ottimizzazione(num_variabili, fun_varianza, ptf_weights_equally, expected_returns, lista_asset_pairplot)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py\", line 186, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py\", line 211, in _get_or_create_cached_value\r\n    return self._handle_cache_miss(cache, value_key, func_args, func_kwargs)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py\", line 265, in _handle_cache_miss\r\n    computed_value = self._info.func(*func_args, **func_kwargs)\r\nFile \"C:\\Users\\A260219\\Jupyter\\bloomberg\\prova.py\", line 1555, in ottimizzazione\r\n    st.write(pd.DataFrame(data=np.round(ptf_weights.reshape([1, num_variabili])*100, decimals=1), columns=dati_ritorni.columns, index=[\"Pesi\"]))\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\metrics_util.py\", line 311, in wrapped_func\r\n    result = non_optional_func(*args, **kwargs)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\elements\\write.py\", line 200, in write\r\n    self.dg.dataframe(arg)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\metrics_util.py\", line 311, in wrapped_func\r\n    result = non_optional_func(*args, **kwargs)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\elements\\dataframe_selector.py\", line 116, in dataframe\r\n    return self.dg._arrow_dataframe(\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\metrics_util.py\", line 311, in wrapped_func\r\n    result = non_optional_func(*args, **kwargs)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\elements\\arrow.py\", line 117, in _arrow_dataframe\r\n    return self.dg._enqueue(\"arrow_data_frame\", proto)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\delta_generator.py\", line 563, in _enqueue\r\n    caching.save_element_message(\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\caching\\__init__.py\", line 50, in save_element_message\r\n    CACHE_RESOURCE_MESSAGE_REPLAY_CTX.save_element_message(\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\caching\\cached_message_replay.py\", line 293, in save_element_message\r\n    raise AttributeError\n\n### Reproducible Code Example\n\n```Python\n@st.cache_resource  ##al momento non funzionante con la funzione di cui di seguito e la versione 1.18 di Streamlit (ma st.experimental_singleton funzionava nella 1.17)\r\n    def ottimizzazione(num_variabili: int, _fun_varianza: Callable[[np.array], float], ptf_weights_equally: np.array, expected_returns: np.array, lista_asset_pairplot: list) -> None:\r\n        \r\n        #l'underscore serviva per dire a streamlit di non fare l'hash della funzione\r\n        fun_varianza=_fun_varianza\r\n\r\n        #qui si specificano i vincoli (min, max) per le singole variabili (NB: il numero di vincoli deve essere esattamente uguale al numero di variabili)\r\n        bnds = tuple([(valore_minimo_per_singola_asset_class, valore_massimo_per_singola_asset_class) for i in range(num_variabili)])\r\n\r\n        st.write(\"--------------------------------------------------------------------\")\r\n        st.write(\"Elaborazione portafoglio di minima varianza\")\r\n        #di seguito la chiamata all'ottimizzatore con argomenti: la funzione-oggetto da minimizzare, X0 ovvero un initial guess delle variabili, il metodo scelto ('SLSQP' é\r\n        #l'unico metodo che supporta ogni tipo di vincolo), i bounds sui valori delle singole variabili, i vincoli su piú variabili simultaneamente, infine le opzioni\r\n        opt={'maxiter': maxiter, 'disp': True, 'ftol': 1e-12, 'eps': 1.4901161193847656e-08} #valori di default 'eps': 1.4901161193847656e-08, 'ftol': 1e-06 (si tratta rispettivamente della step size (eps) usata per l'approssimazione numerica della jacobiana ovvero il vettore del gradiente, e dell'obbiettivo di precisione (ftol) sulla funzione obbiettivo)\r\n        res = minimize(fun_varianza, x0=ptf_weights_equally, method='SLSQP', bounds=bnds, constraints=st.session_state.vincoli_generali, options=opt)\r\n\r\n        ptf_weights=res.x #attribuisce al vettore pesi i pesi ottimali calcolati da minimize (relativi al portafoglio di minima varianza)\r\n\r\n        st.write(\"Di seguito i pesi degli asset in portafoglio espressi in percentuale:\")\r\n        st.write(pd.DataFrame(data=np.round(ptf_weights.reshape([1, num_variabili])*100, decimals=1), columns=dati_ritorni.columns, index=[\"Pesi\"]))\r\n\r\n        ptf_min_var_return=(ptf_weights.T).dot(expected_returns) #calcola il rendimento del portafoglio ottimale di minima varianza\r\n        ptf_min_var_variance=res.fun #attribuisce ad apposita variabile il valore finale minimizzato della funzione obbiettivo (ovvero la varianza dei rendimenti di portafoglio)\r\n\r\n        st.write(\"La deviazione standard annualizzata percentuale del portafoglio é %0.03f\" % (np.sqrt(ptf_min_var_variance)*np.sqrt(periodicity)*100))\r\n        st.write(\"Il rendimento percentuale del portafoglio é %0.03f\" % (ptf_min_var_return*100))\r\n\r\n        ##di seguito si calcola il portafoglio di massimo rendimento (da fare per il caso in cui vi siano vincoli complessi)\r\n        #qui si specifica la funzione da minimizzare per il portafoglio di massimo rendimento\r\n        def fun_rendimento(ptf_weights: np.array) -> float:\r\n            return -(ptf_weights.T).dot(expected_returns) #si minimizza l'opposto del rendimento per massimizzarlo\r\n\r\n        st.write(\"--------------------------------------------------------------------\")\r\n        st.write(\"Elaborazione portafoglio di massimo rendimento\")\r\n\r\n        #di seguito la massimizzazione del rendimento (minimizza l'opposto) con vincoli invariati\r\n        res_return = minimize(fun_rendimento, x0=ptf_weights_equally, method='SLSQP', bounds=bnds, constraints=st.session_state.vincoli_generali, options=opt)\r\n\r\n        #estrae il valore finale del rendimento (massimizato); ovviamente va invertito di segno perché la funzione obbiettivo é l'opposto del rendimento\r\n        ptf_max_risk_return=-res_return.fun\r\n\r\n        st.write(\"Di seguito i pesi degli asset in portafoglio espressi in percentuale:\")\r\n        st.write(pd.DataFrame(data=np.round((res_return.x).reshape([1, num_variabili])*100, decimals=1), columns=dati_ritorni.columns, index=[\"Pesi\"]))\r\n\r\n        st.write(\"Il rendimento percentuale del portafoglio é %0.03f\" % (ptf_max_risk_return*100))\r\n\r\n        step=(ptf_max_risk_return-ptf_min_var_return)/n_step\r\n\r\n        #si specifica la matrice dei pesi di portafoglio con shape variabili*portafogli\r\n        ptf_weights_matrix=np.zeros([num_variabili, (n_step+1)])\r\n        ptf_weights_matrix[:, 0]=ptf_weights #il primo portafoglio é quello di minima varianza di cui giá abbiamo calcolato i pesi\r\n\r\n        #si specifica il vettore delle varianze dei vari portafogli sulla frontiera efficiente\r\n        variance_vector=np.zeros([(n_step+1),])\r\n        variance_vector[0]=ptf_min_var_variance\r\n\r\n        #si specifica il vettore dei rendimenti dei vari portafogli sulla frontiera efficiente\r\n        returns_vector=np.zeros([(n_step+1),])\r\n        returns_vector[0]=ptf_min_var_return\r\n\r\n        desired_return=ptf_min_var_return+step\r\n\r\n        #la funzione destinata ad essere usata per il vincolo sul rendimento nella costruzione\r\n        #del resto della frontiera\r\n        def vincolo_rendimento(ptf_weights: np.array) -> float:\r\n            return (ptf_weights.T).dot(expected_returns) - desired_return\r\n\r\n        for i in range(n_step):\r\n            st.write(\"--------------------------------------------------------------------\")\r\n            st.write(\"Elaborazione portafoglio n.ro %s\" % (i+1))\r\n            #qui si specificano i vincoli (generali, ovvero su piú variabili) nella forma di un dictionary che contiene la specifica del tipo ('eq' per equality ed \r\n            #'ineq' per inequality) e la funzione del vincolo (che verrá posta uguale a zero per i vincoli di equality e non-negativa per i vincoli di inequality)\r\n                                \r\n            res = minimize(fun_varianza, x0=ptf_weights, method='SLSQP', bounds=bnds,\r\n                        constraints=[i for i in st.session_state.vincoli_generali] + [{'type': 'eq', 'fun': vincolo_rendimento}], #aggiunge il vincolo sul rendimento desiderato\r\n                        options=opt)\r\n            \r\n            ptf_weights=res.x\r\n            ptf_weights_matrix[:, i+1]=ptf_weights\r\n            st.write(\"Di seguito i pesi degli asset in portafoglio espressi in percentuale:\")\r\n            st.write(pd.DataFrame(data=np.round(ptf_weights.reshape([1, num_variabili])*100, decimals=1), columns=dati_ritorni.columns, index=[\"Pesi\"]))\r\n            variance_vector[i+1]=res.fun\r\n            st.write(\"La deviazione standard annualizzata percentuale del portafoglio é %0.03f\" % (np.sqrt(variance_vector[i+1])*np.sqrt(periodicity)*100))\r\n            returns_vector[i+1]=(ptf_weights.T).dot(expected_returns)\r\n            st.write(\"Il rendimento percentuale del portafoglio é %0.03f\" % (returns_vector[i+1]*100))\r\n            desired_return=desired_return+step\r\n\r\n        st.write(\"---------------------------------------------------------------------------------------------\")\r\n        st.write(\"A seguire un riepilogo della composizione dei portafogli componenti la frontiera di Markowitz:\")\r\n        sintesi_composizione_portafogli_markowitz=pd.DataFrame(data=np.round(ptf_weights_matrix*100, decimals=2), #i pesi in portafoglio\r\n                                                            columns=[(\"Ptf n.ro \"+str(i)) for i in range(n_step+1)],\r\n                                                            index=dati_ritorni.columns, dtype=\"float\")\r\n        sintesi_composizione_portafogli_markowitz.to_csv(\"sintesi_composizione_portafogli_markowitz.csv\", sep=\";\", decimal=\".\")\r\n        st.write(sintesi_composizione_portafogli_markowitz)\r\n        st.write(\"Di seguito un riepilogo di rendimenti, rischio ed efficienza dei portafogli componenti la frontiera di Markowitz:\")\r\n        sintesi_rendimento_rischio_portafogli_markowitz=pd.DataFrame(data=np.round([returns_vector*100, #i rendimenti\r\n                                                                                    np.sqrt(variance_vector)*np.sqrt(periodicity)*100, #le deviazioni standard annualizzate\r\n                                                                                    np.sqrt(variance_vector)*np.sqrt(periodicity)*2.566*100, #il VaR parametrico t-Student 6df con livello di confidenza 99%, orizzonte annuale, espresso in percentuale\r\n                                                                                    np.divide((returns_vector*100-risk_free_rate*100), np.sqrt(variance_vector)*np.sqrt(periodicity)*100)], #gli sharpe ratio\r\n                                                                                    decimals=2),\r\n                                                                                    columns=[(\"Ptf n.ro \"+str(i)) for i in range(n_step+1)],\r\n                                                                                    index=[\"Rendimenti (%)\", \"Deviazioni Standard (%)\", \"VaR 99% t-Student 6df (%)\", \"Sharpe Ratio\"],\r\n                                                                                    dtype=\"float\")\r\n        sintesi_rendimento_rischio_portafogli_markowitz.to_csv(\"sintesi_rendimento_rischio_portafogli_markowitz.csv\", sep=\";\", decimal=\".\")\r\n        st.write(sintesi_rendimento_rischio_portafogli_markowitz)\r\n\r\n        #concateniamo i dati essenziali della frontiera di Markowitz, inframezzando una riga vuota e le intestazioni di colonna prima della parte rendimento-rischio\r\n        empty_row=pd.Series([None for _ in range(len(sintesi_composizione_portafogli_markowitz.columns.values.tolist()))], index=sintesi_composizione_portafogli_markowitz.columns.values.tolist(), name=\" \")\r\n        sintesi_composizione_portafogli_markowitz_format=sintesi_composizione_portafogli_markowitz.append(empty_row, ignore_index=False)\r\n        intestazione_row=pd.Series([f\"Ptf n.ro {i}\" for i in range(len(sintesi_composizione_portafogli_markowitz.columns.values.tolist()))], index=sintesi_composizione_portafogli_markowitz.columns.values.tolist(), name=\" \")\r\n        sintesi_composizione_portafogli_markowitz_format=sintesi_composizione_portafogli_markowitz_format.append(intestazione_row, ignore_index=False)\r\n        st.session_state.riassuntivo_markowitz=pd.concat([sintesi_composizione_portafogli_markowitz_format, sintesi_rendimento_rischio_portafogli_markowitz], axis=0)\r\n\r\n        #plotto il grafico con la composizione della frontiera di Markowitz\r\n        fig=px.area(sintesi_composizione_portafogli_markowitz.T, \\\r\n                    x=sintesi_composizione_portafogli_markowitz.T.index, \\\r\n                    y=sintesi_composizione_portafogli_markowitz.T.columns, \\\r\n                    labels = dict(index = \"N.ro Portafoglio\", value = \"Percentuale in portafoglio\"), \\\r\n                    title=\"Andamento composizione frontiera di Markowitz\")\r\n        st.plotly_chart(fig, use_container_width=True)\r\n\r\n        #calcolo le deviazioni standard annualizzate\r\n        std_dev_annualized_vector=np.sqrt(variance_vector)*np.sqrt(periodicity)\r\n\r\n        #plotto la frontiera di Markowitz\r\n        fig=px.line(x=std_dev_annualized_vector*100, \\\r\n                    y=returns_vector*100, \\\r\n                    labels = dict(x = \"Deviazione standard annualizzata di portafoglio (%)\", y = \"Rendimento annuale (%)\"), \\\r\n                    title=\"Frontiera di Markowitz\")\r\n        st.plotly_chart(fig, use_container_width=True)\r\n\r\n        st.write(\"Di seguito la matrice di correlazione:\")\r\n        #calcolo la matrice di correlazione\r\n        df_corr=pd.DataFrame.corr(pd.DataFrame(data=returns, columns=dati_ritorni.columns), method='pearson')\r\n        #plotto la heatmap\r\n        fig=px.imshow(df_corr)\r\n        st.plotly_chart(fig, use_container_width=True)\r\n\r\n        if plotting_grafico_pairplot==\"y\":\r\n\r\n            st.write(\"Di seguito il grafico pairplot:\")\r\n            #la riga di codice seguente elimina eventuali indici che fossero superiori al consentito (ad esempio 12 o 8 su un numero di variabili/asset pari a 8)\r\n            lista_asset_pairplot=[lista_asset_pairplot[i] for i in range(len(lista_asset_pairplot)) if lista_asset_pairplot[i]<num_variabili]\r\n            df_ritorni=pd.DataFrame(data=returns, columns=dati_ritorni.columns)\r\n            df_ritorni=df_ritorni.loc[:, [dati_ritorni.columns[i] for i in lista_asset_pairplot]]\r\n            ##per debug\r\n            #st.write(df_ritorni)\r\n            #creo uno scatter plot\r\n            fig_scatter = px.scatter_matrix(df_ritorni, width=1500, height=1000)\r\n            #cambiamo dimensione ed opacitá dei punti\r\n            fig_scatter.update_traces(marker={\"size\": 4,\"opacity\":0.7})\r\n            #stampo a schermo lo scatterplot (nota bene il mancato uso del metodo show)\r\n            fig_scatter\r\n\r\n\r\n        if uso_resampled_frontiers:\r\n\r\n            ##di seguito il codice per il calcolo delle resampled frontiers\r\n\r\n            #crea un vettore numpy contenente le medie attese delle variabili, ovvero in questo caso i rendimenti periodicizzati (ovvero trasformati da annuali in settimanali o mensili)\r\n            means=(1+expected_returns)**(1/periodicity)-1 #esempio di come si possa vettorializzare il calcolo (velocizzandolo)\r\n\r\n            #inizializza la matrice 3d che contiene i pesi di tutte le frontiere efficienti\r\n            ptf_weights_3darray=np.zeros([num_variabili, (n_step+1), n_scenari])\r\n\r\n            #inizializza le matrici destinate a contenere varianze e ritorni (da resampling) delle varie frontiere efficienti\r\n            variance_vector_2darray=np.zeros([(n_step+1), n_scenari])\r\n            returns_vector_2darray=np.zeros([(n_step+1), n_scenari])\r\n\r\n            #inizializza le matrici destinate a contenere di volta in volta le covarianze ed i\r\n            #rendimenti ricampionati dei singoli scenari\r\n            covariance_matrix_sampling=np.zeros([num_variabili, num_variabili])\r\n            returns_sampling=np.zeros([num_variabili])\r\n\r\n            #crea matrice vuota n*num_variabili destinata ad accogliere i returns periodali ricampionati con t-Student multivariata\r\n            output_t=np.empty([n, num_variabili])\r\n\r\n            if plottare_andamenti_simulati==\"y\":\r\n                #crea matrice vuota n*num_variabili*n_scenari destinata alla storicizzazione dei dati contenuti nella matrice di cui sopra\r\n                output_t_3d=np.empty([n, num_variabili, n_scenari])\r\n\r\n            #qui si specifica la funzione da minimizzare che deve essere espressa come funzione di un array numpy\r\n            #notare che ora si usa la covarianza calcolata sui rendimenti campionati, ovvero covariance_matrix_sampling\r\n            def fun_varianza_resampling(ptf_weights: np.array) -> float:\r\n                return ((ptf_weights.T).dot(covariance_matrix_sampling)).dot(ptf_weights) #w*VAR*w ovvero la varianza di portafoglio\r\n\r\n            #notare che si usa returns_sampling in luogo di expected_returns (perché si usano i rendimenti dello scenario)\r\n            def vincolo_rendimento_resampling(ptf_weights: np.array) -> float:\r\n                return (ptf_weights.T).dot(returns_sampling) - desired_return\r\n\r\n            #qui si specifica la funzione da minimizzare per il portafoglio di massimo rendimento\r\n            #notare che si usa return_sampling ovvero i rendimenti ricampionati in luogo degli expected returns originali\r\n            def fun_rendimento_resampling(ptf_weights: np.array) -> float:\r\n                return -(ptf_weights.T).dot(returns_sampling) #si minimizza l'opposto del rendimento per massimizzarlo\r\n\r\n            #inizializza le grandezze destinate a tenere traccia di eventuali anomalie nell'ottimizzatore di scipy (minimize)\r\n            anomalies_count=0\r\n            anomalies_status=[]\r\n\r\n            ##da qui si parte con la generazione degli scenari (via simulazioni monte carlo) e successivo calcolo delle relative\r\n            ##frontiere efficienti\r\n            #annuncio ed inizializzo barra avanzamento per le simulazioni\r\n            st.write(\"\\n\")\r\n            st.write(\"\\n\")\r\n            st.write(\"\\n\")\r\n            st.write(\"\\n\")\r\n            st.write(\"\\n\")\r\n            st.write(\"Avanzamento elaborazione scenari e relative frontiere ricampionate (Resampled Frontiers)\")\r\n            barra_avanzamento_simulazioni = st.progress(0)\r\n            st.write(\"\\n\")\r\n\r\n            for z in range(n_scenari):\r\n                \r\n                #aggiorno barra avanzamento simulazioni\r\n                barra_avanzamento_simulazioni.progress(float((z+1)/n_scenari))\r\n\r\n                #genera n estrazioni (vettori) da una gaussiana multivariata con medie nulle e covarianza covariance_matrix\r\n                #(ergo una matrice n*num_variabili, ovvero estrazioni*variabili)\r\n                output_n=np.random.multivariate_normal(np.zeros(num_variabili), covariance_matrix, n)\r\n                \r\n                ##codice seguente é necessario se si vuole trasformare l'estrazione di cui sopra in una estrazione da t-student multivariata\r\n                #degree of freedom di una t-student multivariata da cui si vuole estrarre campioni\r\n                df=6\r\n                \r\n                #n estrazioni da distribuzione chi quadro che servono per il fattore di correzione del vettore dell'estrazione dalla gaussiana\r\n                w=np.random.chisquare(df, n) #attenzione che w é un vettore di dimensione n, come del resto il fattore_correzione a seguire\r\n                \r\n                #il fattore di correzione é pari a radice_quadrata(df/estrazione_chi_q)\r\n                fattore_correzione=np.sqrt(w/df) #np.sqrt funziona element-wise\r\n                fattore_correzione=fattore_correzione**(-1) #inverte per ottenere radice_quadrata(df/estrazione_chi_q) ovvero il fattore di correzione da moltiplicare per l'estrazione dalla normale\r\n                    \r\n                #a seguire la moltiplicazione di ciascuna estrazione dalla gaussiana per il fattore di correzione corrispondente (element-wise)\r\n                for i in range(n):\r\n                    output_t[i, :]=np.multiply(output_n[i, :], fattore_correzione[i]) #np.multiply funziona element-wise\r\n                    #occorre risommare il vettore delle medie in quanto le estrazioni sono fatte da distribuzioni con medie nulle\r\n                    output_n[i, :]=means+output_n[i, :] \r\n                    #nel caso della t-student si normalizza anche per la deviazione standard della t-student standardizzata (che NON é 1 come invece nel caso della gaussiana standardizzata)\r\n                    output_t[i, :]=means+output_t[i, :]/(np.sqrt(df/(df-2))) #serve quindi per avere una matrice covarianza finale (calcolata sul sample multivariato estratto) asintoticamente uguale alla matrice covariance_matrix originale\r\n                \r\n                if plottare_andamenti_simulati==\"y\":\r\n                    #storicizza i rendimenti ricampionati con t-Student ad uso successivo (grafici)\r\n                    output_t_3d[:, :, z]=output_t\r\n                \r\n                #calcola i nuovi rendimenti medi (dello scenario z)\r\n                returns_sampling=np.mean(output_t, axis=0)\r\n                \r\n                #calcola la nuova matrice covarianza a valere sui rendimenti da scenario z\r\n                covariance_matrix_sampling=np.cov(output_t, rowvar=False)\r\n                \r\n                #riannualizza i rendimenti\r\n                returns_sampling=(1+returns_sampling)**(periodicity)-1 \r\n                \r\n                #qui si specificano i vincoli (min, max) per le singole variabili (NB: il numero di vincoli deve essere esattamente uguale al numero di variabili)\r\n                bnds = tuple([(valore_minimo_per_singola_asset_class, valore_massimo_per_singola_asset_class) for i in range(num_variabili)])\r\n                \r\n                #di seguito la chiamata all'ottimizzatore con argomenti: la funzione-oggetto da minimizzare, X0 ovvero un initial guess delle variabili, il metodo scelto ('SLSQP' é\r\n                #l'unico metodo che supporta ogni tipo di vincolo), i bounds sui valori delle singole variabili, i vincoli su piú variabili simultaneamente, infine le opzioni\r\n                opt={'maxiter': maxiter, 'disp': False, 'ftol': 1e-12, 'eps': 1.4901161193847656e-08} #valori di default 'eps': 1.4901161193847656e-08, 'ftol': 1e-06 (si tratta rispettivamente della step size (eps) usata per l'approssimazione numerica della jacobiana ovvero il vettore del gradiente, e dell'obbiettivo di precisione (ftol) sulla funzione obbiettivo)\r\n                res = minimize(fun_varianza_resampling, x0=ptf_weights_equally, method='SLSQP', bounds=bnds, constraints=st.session_state.vincoli_generali, options=opt)\r\n                \r\n                #di seguito il codice che serve per tenere traccia di eventuali anomalie nell'ottimizzatore di scipy (minimize)\r\n                if res.success!=True:\r\n                    anomalies_count+=1\r\n                    anomalies_status.append(res.message)\r\n                \r\n                ptf_weights=res.x #attribuisce al vettore pesi i pesi ottimali calcolati da minimize (relativi al portafoglio di minima varianza)\r\n                \r\n                ptf_min_var_return=(ptf_weights.T).dot(returns_sampling) #calcola il rendimento del portafoglio ottimale di minima varianza\r\n                ptf_min_var_variance=res.fun #attribuisce ad apposita variabile il valore finale minimizzato della funzione obbiettivo (ovvero la varianza dei rendimenti di portafoglio)\r\n                \r\n                ##di seguito si calcola il portafoglio di massimo rendimento (da fare per il caso in cui vi siano vincoli complessi)\r\n                \r\n                #di seguito la massimizzazione del rendimento (minimizza l'opposto) con vincoli invariati\r\n                res_return = minimize(fun_rendimento_resampling, x0=ptf_weights_equally, method='SLSQP', bounds=bnds, constraints=st.session_state.vincoli_generali, options=opt)\r\n                \r\n                #di seguito il codice che serve per tenere traccia di eventuali anomalie nell'ottimizzatore di scipy (minimize)\r\n                if res_return.success!=True:\r\n                    anomalies_count+=1\r\n                    anomalies_status.append(res.message)\r\n                \r\n                #estrae il valore finale del rendimento (massimizato); ovviamente va invertito di segno perché la funzione obbiettivo é l'opposto del rendimento\r\n                ptf_max_risk_return=-res_return.fun\r\n                \r\n                #come in precedenza calcola lo step di aumento dei rendimenti da aggiungere per ogni nuovo portafoglio da ottimizzare sulla frontiera\r\n                step=(ptf_max_risk_return-ptf_min_var_return)/n_step\r\n                    \r\n                ptf_weights_3darray[:, 0, z]=ptf_weights #il primo portafoglio é quello di minima varianza di cui giá abbiamo calcolato i pesi\r\n                    \r\n                #la matrice (resampled frontiers) delle varianze con shape n_step+1, n_scenari\r\n                variance_vector_2darray[0, z]=ptf_min_var_variance\r\n                \r\n                #la matrice (resampled frontiers) dei rendimenti con shape n_step+1, n_scenari\r\n                returns_vector_2darray[0, z]=ptf_min_var_return\r\n                \r\n                desired_return=ptf_min_var_return+step\r\n                \r\n                for i in range(n_step):\r\n                    \r\n                    #si minimizza la varianza ricampionata sotto il vincolo dei rendimenti ricampionati       \r\n                    res = minimize(fun_varianza_resampling, x0=ptf_weights, method='SLSQP', bounds=bnds,\r\n                                constraints=[i for i in st.session_state.vincoli_generali] + [{'type': 'eq', 'fun': vincolo_rendimento_resampling}], #aggiunge il vincolo sul rendimento desiderato\r\n                                options=opt)\r\n                    \r\n                    #di seguito il codice che serve per tenere traccia di eventuali anomalie nell'ottimizzatore di scipy (minimize)\r\n                    if res.success!=True:\r\n                        anomalies_count+=1\r\n                        anomalies_status.append(res.message)\r\n                    \r\n                    ptf_weights=res.x\r\n                    \r\n                    ptf_weights_3darray[:, i+1, z]=ptf_weights #si salvano i pesi di portafoglio nel cubo di dimensioni num_variabili, (n_step+1), n_scenari\r\n                            \r\n                    variance_vector_2darray[i+1, z]=res.fun\r\n                    \r\n                    returns_vector_2darray[i+1, z]=(ptf_weights.T).dot(returns_sampling)\r\n                    \r\n                    desired_return=desired_return+step\r\n\r\n            #si inizializza la matrice dei pesi dei portafogli sulla frontiera ricampionata\r\n            ptf_weights_resampled=np.zeros([num_variabili, (n_step+1)])\r\n\r\n            #a seguire l'averaging dei pesi lungo la direzione degli scenari\r\n            for j in range(n_step+1):\r\n                for a in range(num_variabili):\r\n                    ptf_weights_resampled[a, j]=np.average(ptf_weights_3darray[a, j, :])\r\n\r\n            #si inizializzano vettori contenenti varianze e rendimenti della resampled frontier\r\n            varianze_frontiera_ricampionata=np.zeros([(n_step+1)])\r\n            rendimenti_frontiera_ricampionata=np.zeros([(n_step+1)])\r\n\r\n            #qui si popolano i vettori di cui sopra\r\n            #si tenga ovviamente presente che si usa varianze e rendimenti \"storici\" (o comunque\r\n            #quelli usati nell'ottimizzazione di Markowitz)\r\n            for s in range(n_step+1):\r\n                varianze_frontiera_ricampionata[s]=((ptf_weights_resampled[:, s].T).dot(covariance_matrix)).dot(ptf_weights_resampled[:, s])\r\n                rendimenti_frontiera_ricampionata[s]=(ptf_weights_resampled[:, s].T).dot(expected_returns)\r\n\r\n            #si passa alle deviazioni standard annualizzate\r\n            dev_std_frontiera_ricampionata=(np.sqrt(varianze_frontiera_ricampionata))*np.sqrt(periodicity)\r\n\r\n            st.write(\"---------------------------------------------------------------------------------------------\")\r\n            st.write(\"A seguire un riepilogo della composizione dei portafogli componenti la resampled frontier:\")\r\n            sintesi_composizione_portafogli_resampled_frontiers=pd.DataFrame(data=np.round(ptf_weights_resampled*100, decimals=2), #i pesi in portafoglio\r\n                                                                            columns=[(\"Ptf n.ro \"+str(i)) for i in range(n_step+1)],\r\n                                                                            index=dati_ritorni.columns, dtype=\"float\")\r\n            sintesi_composizione_portafogli_resampled_frontiers.to_csv(\"sintesi_composizione_portafogli_resampled_frontiers.csv\", sep=\";\", decimal=\".\")\r\n            st.write(sintesi_composizione_portafogli_resampled_frontiers)\r\n            st.write(\"Di seguito un riepilogo di rendimenti, rischio ed efficienza dei portafogli componenti la resampled frontier:\")\r\n            sintesi_rendimento_rischio_portafogli_resampled_frontiers=pd.DataFrame(data=np.round([rendimenti_frontiera_ricampionata*100, #i rendimenti\r\n                                                                                                dev_std_frontiera_ricampionata*100, #le deviazioni standard annualizzate\r\n                                                                                                dev_std_frontiera_ricampionata*2.566*100, #il VaR parametrico t-Student 6df con livello di confidenza 99%, orizzonte annuale, espresso in percentuale\r\n                                                                                                np.divide((rendimenti_frontiera_ricampionata*100-risk_free_rate*100), dev_std_frontiera_ricampionata*100)], #gli sharpe ratio\r\n                                                                                                decimals=2),\r\n                                                                                                columns=[(\"Ptf n.ro \"+str(i)) for i in range(n_step+1)],\r\n                                                                                                index=[\"Rendimenti (%)\", \"Deviazioni Standard (%)\", \"VaR 99% t-Student 6df (%)\", \"Sharpe Ratio\"],\r\n                                                                                                dtype=\"float\")\r\n            sintesi_rendimento_rischio_portafogli_resampled_frontiers.to_csv(\"sintesi_rendimento_rischio_portafogli_resampled_frontiers.csv\", sep=\";\", decimal=\".\")\r\n            st.write(sintesi_rendimento_rischio_portafogli_resampled_frontiers)\r\n\r\n            #concateniamo i dati essenziali della Frontiera Ricampionata, inframezzando una riga vuota e le intestazioni di colonna prima della parte rendimento-rischio\r\n            empty_row=pd.Series([None for _ in range(len(sintesi_composizione_portafogli_resampled_frontiers.columns.values.tolist()))], index=sintesi_composizione_portafogli_resampled_frontiers.columns.values.tolist(), name=\" \")\r\n            sintesi_composizione_portafogli_resampled_frontiers_format=sintesi_composizione_portafogli_resampled_frontiers.append(empty_row, ignore_index=False)\r\n            intestazione_row=pd.Series([f\"Ptf n.ro {i}\" for i in range(len(sintesi_composizione_portafogli_resampled_frontiers.columns.values.tolist()))], index=sintesi_composizione_portafogli_resampled_frontiers.columns.values.tolist(), name=\" \")\r\n            sintesi_composizione_portafogli_resampled_frontiers_format=sintesi_composizione_portafogli_resampled_frontiers_format.append(intestazione_row, ignore_index=False)\r\n            st.session_state.riassuntivo_resampled=pd.concat([sintesi_composizione_portafogli_resampled_frontiers_format, sintesi_rendimento_rischio_portafogli_resampled_frontiers], axis=0)\r\n\r\n            #plotto il grafico con la composizione della Frontiera Ricampionata\r\n            fig=px.area(sintesi_composizione_portafogli_resampled_frontiers.T, \\\r\n                        x=sintesi_composizione_portafogli_resampled_frontiers.T.index, \\\r\n                        y=sintesi_composizione_portafogli_resampled_frontiers.T.columns, \\\r\n                        labels = dict(index = \"N.ro Portafoglio\", value = \"Percentuale in portafoglio\"), \\\r\n                        title=\"Andamento composizione Frontiera Ricampionata\")\r\n            st.plotly_chart(fig, use_container_width=True)\r\n\r\n            #calcola le deviazioni standard annualizzate\r\n            std_dev_annualized_vector_resampled=np.sqrt(variance_vector_2darray)*np.sqrt(periodicity)\r\n            returns_vector_resampled=returns_vector_2darray\r\n\r\n            ##facciamo uno stack dei dati per il grafico a seguire\r\n            ##shape degli array numpy coinvolti di seguito\r\n            #std_dev_annualized_vector_resampled: shape portafogli*scenari\r\n            #returns_vector_resampled: shape portafogli*scenari\r\n            #shape del risultato: portafogli*scenari*tipo_variabile (dove tipo_variabile é pari a 2, ovvero: deviazioni standard e rendimenti)\r\n            array_resampled_frontiers=np.stack([std_dev_annualized_vector_resampled*100, returns_vector_resampled*100], axis=2)\r\n\r\n            #creiamo e visualizziamo il grafico inerente le singole frontiere di Markowitz ricampionate\r\n            fig = go.Figure([   \r\n                        go.Scatter(\r\n                            x=array_resampled_frontiers[:, i, 0],\r\n                            y=array_resampled_frontiers[:, i, 1],\r\n                            mode='lines',\r\n                            #marker=dict(color=\"#444\"),\r\n                            line=dict(width=1),\r\n                            showlegend=False,\r\n                            hoverinfo='none'\r\n                            ) for i in range(n_scenari)])\r\n            fig.update_layout(\r\n                yaxis_title='Return',\r\n                xaxis_title='Standard Deviation',\r\n                title='Resampled Frontiers',\r\n                xaxis={\"tickformat\": \".2f\"},\r\n                yaxis={\"tickformat\": \".2f\"},\r\n                width=1500, \r\n                height=1000\r\n            )\r\n            if n_scenari<=1000 or forza_plotting_interattivo:\r\n                st.plotly_chart(fig, staticPlot=True, use_container_width=True) #possibile aggiungere render_mode='auto' (oppure \"webgl\" o \"svg\")\r\n            else:\r\n                fig_png=pio.to_image(fig.update_layout(template='plotly_dark'), format=\"png\", width=1500, height=1000, scale=None, validate=True, engine='auto')\r\n                st.image(fig_png)\r\n\r\n            #creiamo e visualizziamo il grafico inerente le singole frontiere di Markowitz ricampionate\r\n            #rappresentate sotto forma di punti invece che linee continue\r\n            fig = go.Figure([   \r\n                        go.Scatter(\r\n                            x=array_resampled_frontiers[:, i, 0],\r\n                            y=array_resampled_frontiers[:, i, 1],\r\n                            mode='markers',\r\n                            marker=dict(color='LightSkyBlue', size=3),\r\n                            opacity=0.5,  #effetto gradevole ma peggiora le performance\r\n                            #line=dict(width=1),\r\n                            showlegend=False,\r\n                            hoverinfo='none'\r\n                            ) for i in range(n_scenari)])\r\n            fig.update_layout(\r\n                yaxis_title='Return',\r\n                xaxis_title='Standard Deviation',\r\n                title='Resampled Frontiers (singoli portafogli)',\r\n                xaxis={\"tickformat\": \".2f\"},\r\n                yaxis={\"tickformat\": \".2f\"},\r\n                width=1500, \r\n                height=1000\r\n            )\r\n            if n_scenari<=1000 or forza_plotting_interattivo:\r\n                st.plotly_chart(fig, staticPlot=True, use_container_width=True) #possibile aggiungere render_mode='auto' (oppure \"webgl\" o \"svg\")\r\n            else:\r\n                fig_png=pio.to_image(fig.update_layout(template='plotly_dark'), format=\"png\", width=1500, height=1000, scale=None, validate=True, engine='auto')\r\n                st.image(fig_png)\r\n\r\n            #plottiamo la frontiera di Markowitz vs la Frontiera Ricampionata nel caso i rendimenti attesi e le volatilitá e correlazioni\r\n            #siano perfette (nel qual caso ovviamente Markowitz si trova necessariamente sopra la Frontiera Ricampionata)\r\n            fig = go.Figure([   \r\n                        go.Scatter(\r\n                            name='Frontiera di Markowitz',\r\n                            x=std_dev_annualized_vector*100,\r\n                            y=returns_vector*100,\r\n                            mode='lines',\r\n                            line=dict(width=1),\r\n                            showlegend=True\r\n                            ),\r\n                        go.Scatter(\r\n                            name='Frontiera Ricampionata',\r\n                            x=dev_std_frontiera_ricampionata*100,\r\n                            y=rendimenti_frontiera_ricampionata*100,\r\n                            mode='lines',\r\n                            line=dict(width=1),\r\n                            showlegend=True,\r\n                            hoverinfo='none'\r\n                            )\r\n                            ])\r\n            fig.update_layout(\r\n                yaxis_title='Return',\r\n                xaxis_title='Standard Deviation',\r\n                title='Resampled Frontiers vs Markowitz',\r\n                xaxis={\"tickformat\": \".2f\"},\r\n                yaxis={\"tickformat\": \".2f\"},\r\n                width=1500, \r\n                height=1000\r\n            )\r\n            st.plotly_chart(fig, staticPlot=True, use_container_width=True)\r\n\r\n            #di seguito si ricalcolano rendimenti e rischi di tutti i portafogli simulati\r\n            #ipotizzando che lo scenario base sia corretto (dunque usando i suoi rendimenti\r\n            #attesi e la sua matrice di covarianza)\r\n            if plotting_grafico_ptf_simulati_spazio_originario==\"y\":\r\n                #inizializza le matrici destinate a contenere varianze e ritorni (da resampling) delle varie frontiere efficienti ricalcolate sullo scenario base (rendimenti attesi e matrice covarianza originali)\r\n                variance_vector_2darray_recalc=np.zeros([(n_step+1), n_scenari])\r\n                returns_vector_2darray_recalc=np.zeros([(n_step+1), n_scenari])\r\n                \r\n                #effettua il ricalcolo per singolo portafoglio\r\n                for s in range(n_scenari):\r\n                    for p in range(n_step+1):\r\n                        variance_vector_2darray_recalc[p, s]=fun_varianza(ptf_weights_3darray[:, p, s])\r\n                        returns_vector_2darray_recalc[p, s]=-fun_rendimento(ptf_weights_3darray[:, p, s]) #si usa il segno meno perchè la funzione restituiva l'opposto causa uso con il minimizer\r\n                \r\n                #calcola le deviazioni standard annualizzate\r\n                std_dev_ann_vector_2darray_recalc=np.sqrt(variance_vector_2darray_recalc)*np.sqrt(periodicity)\r\n\r\n                ##shape degli array numpy coinvolti di seguito\r\n                #array_resampled_frontiers_spazio_originario=np.stack([(std_dev_ann_vector_2darray_recalc.flatten())*100, (returns_vector_2darray_recalc.flatten())*100], axis=2)\r\n\r\n                #creiamo e visualizziamo il grafico inerente le singole frontiere di Markowitz ricampionate\r\n                fig = go.Figure([   \r\n                            go.Scatter(\r\n                                x=(std_dev_ann_vector_2darray_recalc.flatten())*100,\r\n                                y=(returns_vector_2darray_recalc.flatten())*100,\r\n                                mode='markers',\r\n                                marker=dict(color='LightSkyBlue', size=3),\r\n                                opacity=0.5, #effetto gradevole ma peggiora le performance\r\n                                showlegend=False,\r\n                                hoverinfo='none'\r\n                                )])\r\n                fig.update_layout(\r\n                    yaxis_title='Return',\r\n                    xaxis_title='Standard Deviation',\r\n                    title=\"Portafogli simulati in spazio rischio-rendimento originario\",\r\n                    xaxis={\"tickformat\": \".2f\"},\r\n                    yaxis={\"tickformat\": \".2f\"},\r\n                    width=1500, \r\n                    height=1000\r\n                )\r\n                if n_scenari<=1000 or forza_plotting_interattivo:\r\n                    st.plotly_chart(fig, staticPlot=True, use_container_width=True) #possibile aggiungere render_mode='auto' (oppure \"webgl\" o \"svg\")\r\n                else:\r\n                    fig_png=pio.to_image(fig.update_layout(template='plotly_dark'), format=\"png\", width=1500, height=1000, scale=None, validate=True, engine='auto')\r\n                    st.image(fig_png)\r\n\r\n            #si recuperano e si plottano gli andamenti di portafoglio nei diversi portafogli/scenari\r\n            if plottare_andamenti_simulati==\"y\":\r\n                \r\n                for n_ro_ptf in range(0, n_step+1, step_ptf_resamp_graph):\r\n                    #inizializza la matrice destinata a contenere i rendimenti di portafoglio relativi ai diversi scenari\r\n                    portfolio_returns_scenari=np.zeros([n, n_scenari])\r\n                    \r\n                    #qui si calcolano i rendimenti di portafoglio partendo dai rendimenti ricampionati degli asset ed i relativi pesi (da frontiera ricampionata)\r\n                    for z in range(n_scenari):\r\n                        portfolio_returns_scenari[:, z]=(output_t_3d[:, :, z]).dot(ptf_weights_resampled[:, n_ro_ptf])\r\n                    \r\n                    #di seguito si setta il numero di periodi di tempo (settimane o mesi) in modo tale che l'orizzonte temporale del grafico non superi l'anno\r\n                    tempo_grafico=min(n, periodicity)\r\n                    \r\n                    #inizializza la matrice destinata ad accogliere i valori del portafoglio nel suo andamento temporale e per i diversi scenari\r\n                    andamento_portafoglio=np.zeros([tempo_grafico+1, n_scenari])\r\n                    \r\n                    #ovviamente si parte dal valore di 100 ad inizio periodo\r\n                    andamento_portafoglio[0, :]=np.array([100 for i in range(n_scenari)])\r\n                    \r\n                    #di seguito si calcola l'andamento del portafoglio nel tempo e per i diversi scenari\r\n                    for z in range(n_scenari):\r\n                        for t in range(tempo_grafico):\r\n                            andamento_portafoglio[t+1, z]=andamento_portafoglio[t, z]*(1+portfolio_returns_scenari[t, z])\r\n\r\n                    #plottiamo gli andamenti di portafoglio\r\n                    fig = go.Figure([   \r\n                                    go.Scatter(\r\n                                        #name='Resampled Frontier',\r\n                                        #x=andamento_portafoglio[:, i],\r\n                                        y=andamento_portafoglio[:, i],\r\n                                        mode='lines',\r\n                                        line=dict(width=0.5, color='#c44e52'),  #'#c44e52' oppure '#d62728'\r\n                                        showlegend=False,\r\n                                        hoverinfo='none'\r\n                                        ) for i in range(n_scenari)])\r\n                    fig.update_layout(\r\n                        yaxis_title=\"Valore del portafoglio (fatto 100 iniziale)\",\r\n                        xaxis_title=\"Tempo\",\r\n                        title=f\"Portafoglio simulato n.ro {n_ro_ptf} (da Resampled Fr.)\",\r\n                        width=1500, \r\n                        height=1000\r\n                    )\r\n                    st.plotly_chart(fig, staticPlot=True, use_container_width=True)\n```\n\n\n### Steps To Reproduce\n\nplease read only the error\r\n\n\n### Expected Behavior\n\ncache the function\n\n### Current Behavior\n\nAttributeError\r\nTraceback:\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\scriptrunner\\script_runner.py\", line 565, in _run_script\r\n    exec(code, module.__dict__)\r\nFile \"C:\\Users\\A260219\\Jupyter\\bloomberg\\prova.py\", line 2126, in <module>\r\n    ottimizzazione(num_variabili, fun_varianza, ptf_weights_equally, expected_returns, lista_asset_pairplot)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py\", line 186, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py\", line 211, in _get_or_create_cached_value\r\n    return self._handle_cache_miss(cache, value_key, func_args, func_kwargs)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py\", line 265, in _handle_cache_miss\r\n    computed_value = self._info.func(*func_args, **func_kwargs)\r\nFile \"C:\\Users\\A260219\\Jupyter\\bloomberg\\prova.py\", line 1555, in ottimizzazione\r\n    st.write(pd.DataFrame(data=np.round(ptf_weights.reshape([1, num_variabili])*100, decimals=1), columns=dati_ritorni.columns, index=[\"Pesi\"]))\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\metrics_util.py\", line 311, in wrapped_func\r\n    result = non_optional_func(*args, **kwargs)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\elements\\write.py\", line 200, in write\r\n    self.dg.dataframe(arg)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\metrics_util.py\", line 311, in wrapped_func\r\n    result = non_optional_func(*args, **kwargs)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\elements\\dataframe_selector.py\", line 116, in dataframe\r\n    return self.dg._arrow_dataframe(\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\metrics_util.py\", line 311, in wrapped_func\r\n    result = non_optional_func(*args, **kwargs)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\elements\\arrow.py\", line 117, in _arrow_dataframe\r\n    return self.dg._enqueue(\"arrow_data_frame\", proto)\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\delta_generator.py\", line 563, in _enqueue\r\n    caching.save_element_message(\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\caching\\__init__.py\", line 50, in save_element_message\r\n    CACHE_RESOURCE_MESSAGE_REPLAY_CTX.save_element_message(\r\nFile \"C:\\Users\\A260219\\Anaconda3\\envs\\lavoro\\lib\\site-packages\\streamlit\\runtime\\caching\\cached_message_replay.py\", line 293, in save_element_message\r\n    raise AttributeError\n\n### Is this a regression?\n\n- [X] Yes, this used to work in a previous version.\n\n### Debug info\n\n- Streamlit version: 1.18\r\n- Python version: 3.10\r\n- Operating System:  windows\r\n- Browser: chrome\r\n- Virtual environment: -\r\n\n\n### Additional Information\n\nno problems at all with st.experimental_singleton (streamlit version 1.17)\r\nbut with st.cache_resource in streamlit 1.18 i get the error above\r\nthe function is very very large and computationally expensive, but the behavior was very fine with st.experimental_singleton and streamlit version 1.17\n\n### Are you willing to submit a PR?\n\n- [ ] Yes, I am willing to submit a PR!","closed_by":{"login":"AnOctopus","id":7356217,"node_id":"MDQ6VXNlcjczNTYyMTc=","avatar_url":"https://avatars.githubusercontent.com/u/7356217?v=4","gravatar_id":"","url":"https://api.github.com/users/AnOctopus","html_url":"https://github.com/AnOctopus","followers_url":"https://api.github.com/users/AnOctopus/followers","following_url":"https://api.github.com/users/AnOctopus/following{/other_user}","gists_url":"https://api.github.com/users/AnOctopus/gists{/gist_id}","starred_url":"https://api.github.com/users/AnOctopus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AnOctopus/subscriptions","organizations_url":"https://api.github.com/users/AnOctopus/orgs","repos_url":"https://api.github.com/users/AnOctopus/repos","events_url":"https://api.github.com/users/AnOctopus/events{/privacy}","received_events_url":"https://api.github.com/users/AnOctopus/received_events","type":"User","user_view_type":"public","site_admin":false},"reactions":{"url":"https://api.github.com/repos/streamlit/streamlit/issues/6103/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/streamlit/streamlit/issues/6103/timeline","performed_via_github_app":null,"state_reason":"completed"}