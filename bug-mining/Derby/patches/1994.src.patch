diff --git a/java/engine/org/apache/derby/impl/sql/execute/AlterTableConstantAction.java b/java/engine/org/apache/derby/impl/sql/execute/AlterTableConstantAction.java
index 18462025e..bcf4c3adf 100644
--- a/java/engine/org/apache/derby/impl/sql/execute/AlterTableConstantAction.java
+++ b/java/engine/org/apache/derby/impl/sql/execute/AlterTableConstantAction.java
@@ -2458,6 +2458,12 @@ class AlterTableConstantAction extends DDLSingleTableConstantAction
 			properties.put(
                 "nUniqueColumns", Integer.toString(indexRowLength));
 		}
+		if(cd.getIndexDescriptor().isUniqueWithDuplicateNulls())
+		{
+			properties.put(
+                    "uniqueWithDuplicateNulls", Boolean.toString(true));
+		}
+
 		properties.put(
             "rowLocationColumn", Integer.toString(indexRowLength - 1));
 		properties.put(
diff --git a/java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java b/java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java
index 484a39bc9..aeb981ca6 100644
--- a/java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java
+++ b/java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java
@@ -1869,6 +1869,11 @@ class InsertResultSet extends DMLWriteResultSet implements TargetResultSet
 				properties.put("nUniqueColumns", 
 							   Integer.toString(indexRowLength));
 			}
+			if(cd.getIndexDescriptor().isUniqueWithDuplicateNulls())
+			{
+				properties.put(
+	                    "uniqueWithDuplicateNulls", Boolean.toString(true));
+			}
 			properties.put("rowLocationColumn", 
 							Integer.toString(indexRowLength - 1));
 			properties.put("nKeyFields", Integer.toString(indexRowLength));
@@ -2343,6 +2348,11 @@ class InsertResultSet extends DMLWriteResultSet implements TargetResultSet
 				properties.put("nUniqueColumns", 
 							   Integer.toString(indexRowLength));
 			}
+			if(cd.getIndexDescriptor().isUniqueWithDuplicateNulls())
+			{
+				properties.put(
+	                    "uniqueWithDuplicateNulls", Boolean.toString(true));
+			}
 			properties.put("rowLocationColumn", 
 							Integer.toString(indexRowLength - 1));
 			properties.put("nKeyFields", Integer.toString(indexRowLength));
diff --git a/java/testing/org/apache/derbyTesting/functionTests/tests/lang/NullableUniqueConstraintTest.java b/java/testing/org/apache/derbyTesting/functionTests/tests/lang/NullableUniqueConstraintTest.java
index 4753dae11..8cbaf9132 100644
--- a/java/testing/org/apache/derbyTesting/functionTests/tests/lang/NullableUniqueConstraintTest.java
+++ b/java/testing/org/apache/derbyTesting/functionTests/tests/lang/NullableUniqueConstraintTest.java
@@ -21,6 +21,7 @@
 
 package org.apache.derbyTesting.functionTests.tests.lang;
 
+import java.sql.CallableStatement;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
@@ -36,6 +37,7 @@ import junit.framework.TestResult;
 import junit.framework.TestSuite;
 
 import org.apache.derbyTesting.junit.BaseJDBCTestCase;
+import org.apache.derbyTesting.junit.SupportFilesSetup;
 import org.apache.derbyTesting.junit.TestConfiguration;
 
 /**
@@ -145,6 +147,30 @@ public class NullableUniqueConstraintTest extends BaseJDBCTestCase {
         stmt.close ();
         ps.close();
     }
+
+    /**
+     * Compress table should recreate the indexes correctly rather
+     * than ignoring the unique nullable property of the index
+     * @throws SQLException
+     */
+    public void testDerby4677CompressTable() throws SQLException {
+        Connection con = getConnection();
+        Statement stmt = con.createStatement();
+        stmt.executeUpdate("CREATE TABLE TABLE1(NAME1 INT UNIQUE, "+
+        		"name2 int unique not null, name3 int primary key)");
+        stmt.execute("call syscs_util.syscs_compress_table('APP','TABLE1',1)");
+        stmt.executeUpdate("INSERT INTO TABLE1 VALUES(1,11,111)");
+        //following should run into problem because of constraint on name1
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(1,22,222)");
+        //following should run into problem because of constraint on name2
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(3,11,333)");
+        //following should run into problem because of constraint on name3
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(4,44,111)");
+        stmt.executeUpdate("DROP TABLE TABLE1");    
+    }
     
     /**
      * Basic test of Unique Constraint using multipart part key.
diff --git a/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java b/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java
index e2b9f6d6e..ae63b6e4f 100644
--- a/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java
+++ b/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java
@@ -21,6 +21,7 @@
  */
 package org.apache.derbyTesting.functionTests.tests.tools;
 
+import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
@@ -124,6 +125,79 @@ public class ImportExportBinaryDataTest extends ImportExportBaseTest {
 	    doImportTable("APP", "BIN_TAB_IMP", fileName, null, null, null, 0);
         verifyData(" * ");
     }
+    
+    /**
+     * Bulk insert into a table should recreate the indexes correctly rather
+     * than ignoring the unique nullable property of the index.
+     * In the following test case, we have an empty table in which we are
+     * 	trying to do an import from a file with one row worth's data.
+     * 	This combination used to cause bulk insert functionality to 
+     * 	recreate index incorrectly for unique nullable index. This allowed
+     * 	duplicate rows for unique nullable index. Fix for DERBY-4677 resolves
+     * 	the issue.
+     * @throws SQLException
+     */
+    public void testDerby4677BulkInsertIntoEmptyTable() throws SQLException {
+        Connection con = getConnection();
+        Statement stmt = con.createStatement();
+        stmt.executeUpdate("CREATE TABLE TABLE1(NAME1 INT UNIQUE, "+
+        		"name2 int unique not null, name3 int primary key)");
+        stmt.executeUpdate("INSERT INTO TABLE1 VALUES(1,11,111)");
+        String dataFileName =
+            (SupportFilesSetup.getReadWrite("data_file.dat")).getPath();
+        doExportTable("APP", "TABLE1", dataFileName, null, null, "UTF-16");
+        stmt.executeUpdate("DELETE FROM TABLE1");
+        commit();
+        doImportTable("APP", "TABLE1", dataFileName, null, null, "UTF-16",0);
+        //following should run into problem because of constraint on name1
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(1,22,222)");
+        //following should run into problem because of constraint on name2
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(3,11,333)");
+        //following should run into problem because of constraint on name3
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(4,44,111)");
+        stmt.executeUpdate("DROP TABLE TABLE1");    
+    	SupportFilesSetup.deleteFile(dataFileName);
+    }
+    
+    /**
+     * Bulk insert into a table should recreate the indexes correctly rather
+     * than ignoring the unique nullable property of the index.
+     * In the following test case, we have an empty table in which we are
+     * 	trying to do an import from an empty file with the REPLACE option.
+     * 	This combination used to cause bulk insert functionality to 
+     * 	recreate index incorrectly for unique nullable index. This allowed
+     * 	duplicate rows for unique nullable index. Fix for DERBY-4677 resolves
+     * 	the issue.
+     * @throws SQLException
+     */
+    public void testDerby4677BulkInsertWithReplace() throws SQLException {
+        Connection con = getConnection();
+        Statement stmt = con.createStatement();
+        stmt.executeUpdate("CREATE TABLE TABLE1(NAME1 INT UNIQUE, "+
+        		"name2 int unique not null, name3 int primary key)");
+        String emptyFileName =
+            (SupportFilesSetup.getReadWrite("empty_file.dat")).getPath();
+        //there is no data in TABLE1 so empty_file.dat will be empty 
+        //after export. Using following to just create an empty file
+        doExportTable("APP", "TABLE1", emptyFileName, null, null, "UTF-16");
+        commit();
+        doImportTable("APP", "TABLE1", emptyFileName, null, null, "UTF-16",1);
+        stmt.executeUpdate("INSERT INTO TABLE1 VALUES(1,11,111)");
+        //following should run into problem because of constraint on name1
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(1,22,222)");
+        //following should run into problem because of constraint on name2
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(3,11,333)");
+        //following should run into problem because of constraint on name3
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(4,44,111)");
+        stmt.executeUpdate("DROP TABLE TABLE1");    
+    	SupportFilesSetup.deleteFile(emptyFileName);
+    }
 
     
     /*
