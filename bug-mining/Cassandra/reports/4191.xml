<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 23:02:07 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-11053] COPY FROM on large datasets: fix progress report and optimize performance part 4</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-11053</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;h5&gt;&lt;a name=&quot;Description&quot;&gt;&lt;/a&gt;Description&lt;/h5&gt;

&lt;p&gt;Running COPY from on a large dataset (20G divided in 20M records) revealed two issues:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;The progress report is incorrect, it is very slow until almost the end of the test at which point it catches up extremely quickly.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;The performance in rows per second is similar to running smaller tests with a smaller cluster locally (approx 35,000 rows per second). As a comparison, cassandra-stress manages 50,000 rows per second under the same set-up, therefore resulting 1.5 times faster.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;See attached file &lt;em&gt;copy_from_large_benchmark.txt&lt;/em&gt; for the benchmark details.&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;DocimpactingchangestoCOPYFROMoptions&quot;&gt;&lt;/a&gt;Doc-impacting changes to COPY FROM options&lt;/h5&gt;

&lt;ul&gt;
	&lt;li&gt;A new option was added: PREPAREDSTATEMENTS - it indicates if prepared statements should be used; it defaults to true.&lt;/li&gt;
	&lt;li&gt;The default value of CHUNKSIZE changed from 1000 to 5000.&lt;/li&gt;
	&lt;li&gt;The default value of MINBATCHSIZE changed from 2 to 10.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12932942">CASSANDRA-11053</key>
            <summary>COPY FROM on large datasets: fix progress report and optimize performance part 4</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stefania">Stefania Alborghetti</assignee>
                                    <reporter username="stefania">Stefania Alborghetti</reporter>
                        <labels>
                            <label>doc-impacting</label>
                    </labels>
                <created>Thu, 21 Jan 2016 01:56:27 +0000</created>
                <updated>Wed, 15 Oct 2025 09:49:06 +0000</updated>
                            <resolved>Mon, 28 Mar 2016 18:03:20 +0000</resolved>
                                        <fixVersion>2.1.14</fixVersion>
                    <fixVersion>2.2.6</fixVersion>
                    <fixVersion>3.0.5</fixVersion>
                    <fixVersion>3.5</fixVersion>
                                    <component>Legacy/Tools</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>10</watches>
                                                                                                                <comments>
                            <comment id="15127778" author="stefania" created="Tue, 2 Feb 2016 06:49:25 +0000"  >&lt;p&gt;I&apos;ve repeated the test in the exact some conditions as described above with &lt;tt&gt;cProfile&lt;/tt&gt; profiling all processes. I am attaching full profile results (&lt;em&gt;worker_profiles.txt&lt;/em&gt; and &lt;em&gt;parent_profile.txt&lt;/em&gt;). &lt;/p&gt;

&lt;p&gt;The total test time was approx 15 minutes (900 seconds), of which 15 seconds were an artificial sleep in the parent to allow workers to dump their profile results.&lt;/p&gt;

&lt;p&gt;It is clear that with these large datasets we can no longer afford to read all data in the parent and dish out rows as it has been the approach so far. We spend in fact over 600 seconds in &lt;tt&gt;read_rows&lt;/tt&gt;. We also spend significant time in the worker processes receiving data (30 seconds). Distributing file names to workers and letting them do all the work is pretty easy to do and would solve these two issues. However it comes with some consequences:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;We would end up with one process per file unless we somehow split large files but splitting large files would take time and users can prepare their data themselves. Further, COPY TO can now export to multiple files. Therefore I think we should keep things simple and adapt our bulk tests to export to multiple files.&lt;/li&gt;
	&lt;li&gt;Either we change the meaning of the &lt;b&gt;max ingest rate&lt;/b&gt; and make it per worker process, or we would need to use a global lock which could become a bottleneck. I would prefer changing the meaning of max ingest rate as users can always specify a rate that is equal to &lt;tt&gt;max_rate / num_processes&lt;/tt&gt; if they really need to.&lt;/li&gt;
	&lt;li&gt;To keep things simple, retries would be best handled by worker processes and therefore if one process fails then the import fails at least partially; I think we can live with this.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In terms of the worker processes, there is room for improvement there too but it is not as straightforward. One interesting thing to do would be to use a cythonized driver version but this would not work out of the box due to the formatting hooks we inject in the driver. We spend a lot of time batching records, getting the replicas, binding parameters and hashing (_murmur3).&lt;/p&gt;

&lt;p&gt;WDYT &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pauloricardomg&quot; class=&quot;user-hover&quot; rel=&quot;pauloricardomg&quot;&gt;pauloricardomg&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thobbs&quot; class=&quot;user-hover&quot; rel=&quot;thobbs&quot;&gt;thobbs&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="15127864" author="stefania" created="Tue, 2 Feb 2016 08:00:48 +0000"  >&lt;p&gt;Reading from standard input and parameters like &lt;tt&gt;maxrows&lt;/tt&gt; and &lt;tt&gt;skiprows&lt;/tt&gt; also become problematic. &lt;tt&gt;skiprows&lt;/tt&gt; can be relative to a file but &lt;tt&gt;maxrows&lt;/tt&gt;, as well as other max parameters, would require synchronization across processes.&lt;/p&gt;

&lt;p&gt;I also would like to point out that the approach of cassandra-loader and COPY FROM are currently quite different:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;cassandra-loader treats every file independently; options such as maxRows and so forth are on a per file basis.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;COPY FROM treats files as a whole so options are on a global basis but this would have to change to achieve the same performance.&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="15127990" author="stefania" created="Tue, 2 Feb 2016 09:53:30 +0000"  >&lt;p&gt;Another approach I am looking at is to continue reading in the parent process, possibly via memory mapped files, and to only move the csv decoding to the worker processes. This would be less disruptive in the existing design. I also note that we will still need to improve worker processes performance as well, since they only spend about 30 seconds receiving, something else needs to improve. Since most of the time consuming methods are in the driver I would like to try and get the cythonized driver to work as well.&lt;/p&gt;

&lt;p&gt;Sorry for the long chain of comments. However I would really appreciate any further ideas, without taking too much of your time.&lt;/p&gt;</comment>
                            <comment id="15130041" author="stefania" created="Wed, 3 Feb 2016 08:44:12 +0000"  >&lt;p&gt;I&apos;ve repeated the benchmark after performing the following:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Moved csv decoding from parent to worker processes&lt;/li&gt;
	&lt;li&gt;Switched to a cythonized driver installation (for cassandra-2.1 we need to use version 2.7.2).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The patch is &lt;a href=&quot;https://github.com/stef1927/cassandra/tree/11053-2.1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The set-up and raw results are in &lt;em&gt;copy_from_large_benchmark_2.txt&lt;/em&gt; attached, along with the new profiler results, &lt;em&gt;parent_profile_2.txt&lt;/em&gt; and &lt;em&gt;worker_profiles_2.txt&lt;/em&gt;. The rate has increased from &lt;b&gt;35,000&lt;/b&gt; to &lt;b&gt;58,000&lt;/b&gt; rows per second for the 1KB test:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;cqlsh&amp;gt; COPY test.test1kb FROM &lt;span class=&quot;code-quote&quot;&gt;&apos;DSEBulkLoadTest/in/data1KB/*.csv&apos;&lt;/span&gt;;
Using 7 child processes

Starting copy of test.test1kb with columns [&lt;span class=&quot;code-quote&quot;&gt;&apos;pkey&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;ccol&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;data&apos;&lt;/span&gt;].
Processed: 20480000 rows; Rate:   63987 rows/s; Avg. rate:   58749 rows/s
20480000 rows imported from 20 files in 5 minutes and 48.605 seconds (0 skipped).
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;The progress reporting looks much better now,  because the parent process no longer spends time decoding csv data and it has therefore more time to receive data and update the progress.&lt;/p&gt;

&lt;p&gt;The parent process is fine now, even if we optimized it further it wouldn&apos;t matter since it spends most of its time receiving data (289 out of 437 seconds).&lt;/p&gt;

&lt;p&gt;The worker processes can still be improved, here is where we currently spend most of the time and what I am looking at improving:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    3.606    3.606  432.297  432.297 /data/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py:1743(run_normal)
   158538   86.237    0.001  245.629    0.002 /data/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py:1800(send_normal_batch)
   161485   67.401    0.000  167.543    0.001 /data/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py:1879(split_batches)
   158538   17.603    0.000   84.718    0.001 /data/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py:1820(convert_rows)
   158538   46.302    0.000   73.577    0.000 /data/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py:1874(execute_statement)
  2947000   37.470    0.000   61.277    0.000 /data/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py:1918(get_replica)
  2947000   27.978    0.000   60.145    0.000 /data/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py:1596(get_row_values)
  2947000    9.383    0.000   32.285    0.000 /data/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py:1625(get_row_partition_key_values)
  8841000   21.195    0.000   31.220    0.000 /data/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py:1600(convert)
  2947000   20.328    0.000   21.711    0.000 /data/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py:1630(serialize)
  2947000    9.220    0.000   20.478    0.000 {filter}
     2948    0.040    0.000   15.513    0.005 /usr/lib/python2.7/multiprocessing/queues.py:113(get)
     2948   12.770    0.004   12.770    0.004 {method &lt;span class=&quot;code-quote&quot;&gt;&apos;recv&apos;&lt;/span&gt; of &lt;span class=&quot;code-quote&quot;&gt;&apos;_multiprocessing.Connection&apos;&lt;/span&gt; objects}
  8841000   11.258    0.000   11.258    0.000 /data/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py:1925(&amp;lt;lambda&amp;gt;)
   158558    7.525    0.000   10.034    0.000 /usr/local/lib/python2.7/dist-packages/cassandra_driver-2.7.2-py2.7-linux-x86_64.egg/cassandra/io/libevreactor.py:355(push)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I note that 58,000 rows per second is an upper limit both locally against a single cassandra node running on the same laptop, or on an &lt;tt&gt;r3.2xlarge&lt;/tt&gt; AWS instance running against a large cassandra cluster of 8 nodes running on &lt;tt&gt;i2.2xlarge&lt;/tt&gt; AWS instances. So the bottleneck is still with the importer even after these initial improvements. The same is true for cassandra loader, it won&apos;t move much beyond 50,000 rows per second with the 1KB benchmark (using default parameters and a batch size of 8). &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;time ./cassandra-loader -f DSEBulkLoadTest/in/data1KB -host 172.31.16.79 -schema &lt;span class=&quot;code-quote&quot;&gt;&quot;test.test1kb(pkey,ccol,data)&quot;&lt;/span&gt; -batchSize 8
[...]
Lines Processed:        20480019  Rate:         50073.39608801956

real    6m50.633s
user    19m0.819s
sys     3m25.961s
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Is this the right command &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brianmhess&quot; class=&quot;user-hover&quot; rel=&quot;brianmhess&quot;&gt;brianmhess&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="15130553" author="brianmhess" created="Wed, 3 Feb 2016 15:27:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Stefania&quot; class=&quot;user-hover&quot; rel=&quot;stefania&quot;&gt;Stefania&lt;/a&gt; - I believe that is the correct invocation.  However, that performance is about half of what I saw when I ran against the same setup (r3.2xlarge client writing to a cluster of 8 i2.2xlarge machines).  The rate I had was 98K writes/sec (total time was 209 seconds).&lt;/p&gt;</comment>
                            <comment id="15131446" author="stefania" created="Thu, 4 Feb 2016 00:31:06 +0000"  >&lt;p&gt;Could you check the ctool invocations in &lt;em&gt;copy_from_large_benchmark_2.txt&lt;/em&gt; attached to see if there are any differences? I&apos;m running cassandra 2.1 from source but that should not make such a big difference. &lt;/p&gt;

&lt;p&gt;The data generation commands are also in the same file and repeated here:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;make dirs
make gen
make data100B 
make data1KB
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It&apos;s not indicated in the file but I also truncate the table in use before running a test.&lt;/p&gt;</comment>
                            <comment id="15133899" author="stefania" created="Fri, 5 Feb 2016 09:33:35 +0000"  >&lt;p&gt;I&apos;ve made some small optimizations and I&apos;ve cythonized the copyutil module in pylib. I&apos;ve also experimented with non-prepared statements since we spend most of the time parsing data and binding parameters.&lt;/p&gt;

&lt;p&gt;Here are the results for the 1KB test:&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;module cythonized&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Prepared Statements&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;rows per second&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;total time&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;None&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Yes&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;39,100&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 8&apos; 43&apos;&apos;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;None&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;No&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50,900&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 6&apos; 42&apos;&apos;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Driver&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Yes&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;64,300&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 5&apos; 18&apos;&apos;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Driver&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;No&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;77,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4&apos; 25&apos;&apos;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Driver + copyutil&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Yes&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;70,700&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 4&apos; 49&apos;&apos;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Driver + copyutil&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;No&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;87,300&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 3&apos; 54&apos;&apos;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;Please note that the non prepared statements code still needs cleaning up, specifically I need to add a check on missing primary key values so it might slow down slightly. Non prepared statements are faster in this set-up because the cluster is oversized. They may be terrible in other set-ups with smaller clusters, they not only move all the parsing to cassandra nodes but they also force each batch statement to be recompiled. I will add a flag to allow using non prepared statements but the default will stay with prepared statements enabled.&lt;/p&gt;

&lt;p&gt;We still also have an issue with real time reporting, the faster the performance gets the less accurate the real time reporting is. I need to address this.&lt;/p&gt;</comment>
                            <comment id="15143179" author="jbellis" created="Thu, 11 Feb 2016 18:12:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;We still also have an issue with real time reporting, the faster the performance gets the less accurate the real time reporting is. I need to address this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Worth splitting into a separate ticket?&lt;/p&gt;</comment>
                            <comment id="15144508" author="stefania" created="Fri, 12 Feb 2016 12:01:48 +0000"  >&lt;p&gt;Here are the latest results:&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MODULE CYTHONIZED&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;PREPARED STATEMENTS&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;NUM. WORKER PROCESSES&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;CHUNK SIZE&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AVERAGE ROWS / SEC&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;TOTAL TIME&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;APPROX ROWS / SEC IN REAL-TIME (50% -&amp;gt; 95%)&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NONE&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;44,115&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&apos; 44&apos;&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;43,700 -&amp;gt; 44,000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NONE&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NO&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;58,345&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5&apos; 51&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;57,800 -&amp;gt; 58,200&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;77,719&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&apos; 23&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;77,300 -&amp;gt; 77,600&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NO &amp;#40;*&amp;#41;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;94,508 &amp;#40;*&amp;#41;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&apos; 36&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;94,000 -&amp;gt; 95,000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;15&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;78,429&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&apos; 21&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;77,900 -&amp;gt; 78,300&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;78,746&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&apos; 20&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;78,000 -&amp;gt; 78,500&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;79,337&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&quot; 18&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;78,900 -&amp;gt; 79,200&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;81,636&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&apos; 10&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;80,900 -&amp;gt; 81,500&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;b&gt;82,584&lt;/b&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&apos; 8&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;82,000 -&amp;gt; 82,500&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;82,486&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&apos; 8&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;81,800 -&amp;gt; 82,400&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2500&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;82,013&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&apos; 9&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;81,500 -&amp;gt; 81,900&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER + COPYUTIL&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;b&gt;88,187&lt;/b&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&apos; 52&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;87,900 -&amp;gt; 88,100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER + COPYUTIL&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NO &amp;#40;*&amp;#41;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;87,860 &amp;#40;*&amp;#41;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&apos; 53&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99,600 -&amp;gt; 93,800&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;I&apos;ve also saved the results in a &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1XTE2fSDJkwHzpdaD5HI0HlsFuPCW1Kc1NeqauF6WX2s&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;spreadsheet&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The column on the right contains two approximate observations of the real-time rate at about half-way through and just before finishing. It&apos;s purpose is simply to verify that the real-time rate is fine now, it no longer lags behind as it used to do. &lt;/p&gt;

&lt;p&gt;The test runs with a &amp;#40;*&amp;#41; were affected by time outs, indicating the cluster had reached capacity. This is to be expected given that with non-prepared statements we shift the parsing burden to cassandra nodes forcing them to compile each batch statement as well. I don&apos;t consider this a particularly good thing to do, as it is only applicable when the cluster is over-sized and therefore I focused my efforts and search for optimal parameters to the case with prepared statements (the default). In the very last run, we can see how half-way through we had an average of 99,600 but it then plummeted just before finishing due to a long pause (there is an exponential back-off policy that kicks in on timeouts).&lt;/p&gt;

&lt;p&gt;The improvements over the &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-11053?focusedCommentId=15133899&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15133899&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;last set of results&lt;/a&gt; are mostly due to tailored optimizations of Python code via the Python &lt;a href=&quot;https://github.com/rkern/line_profiler&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;line profiler&lt;/a&gt;. I&apos;ve also reduced the amount of data sent from worker processes to the parent by aggregating results. This helped the real time reporting tremendously. I&apos;ve also added support for libev if it is installed, as described in the driver &lt;a href=&quot;https://datastax.github.io/python-driver/installation.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;installation guide&lt;/a&gt;. Finally, I fixed a problem with type formatting introduced by the cythonized driver.&lt;/p&gt;

&lt;p&gt;With these improvements, together with those previously adopted, worker and parent processes are no longer as tightly coupled and I therefore experimented with the number of worker processes and the chunk size. The default number of worker processes is 7 (num-cores minus 1). However it seems from observation that num-cores + 1 gives better results. I&apos;ve monitored vmstats with &lt;tt&gt;dstat&lt;/tt&gt; and the running tasks were reasonable (less than 2*num-cores). As for the chunk size, the default value of 1000 is probably too small, and it seems 5000 is a better value for this particular dataset and environment. However, I don&apos;t propose that we change the current default values as they are safer for smaller environments such as laptops.&lt;/p&gt;

&lt;p&gt;I&apos;ve also spent time trying to improve csv parsing times, by comparing alternatives based on &lt;a href=&quot;http://pandas.pydata.org/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;pandas&lt;/a&gt;, &lt;a href=&quot;http://www.numpy.org/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;numpy&lt;/a&gt; and &lt;a href=&quot;http://numba.pydata.org/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;numba&lt;/a&gt; but none were worth pursuing further, at least not for this benchmark with very simple type conversions (text and integers). For more complex data types, such as dates or collections, perhaps pure cython conversion functions would help significantly.&lt;/p&gt;

&lt;p&gt;Whilst I still have a new set of profiler results to analyse, I feel that we are reaching a point where our efforts could be better spent elsewhere due to diminishing returns. As a comparison, cassandra stress with approx 1KB partitions inserted 5M rows at a rate of 93k rows per second. As this is well within 10% of our results, I suggest we should consider focussing on alternative means of optimizations for wider user cases, such as supporting binary formats for COPY TO / FROM or optimizing text conversion of complex data types.&lt;/p&gt;</comment>
                            <comment id="15144509" author="stefania" created="Fri, 12 Feb 2016 12:02:07 +0000"  >&lt;p&gt;It is fine now thanks, see details below.&lt;/p&gt;</comment>
                            <comment id="15147601" author="jbellis" created="Mon, 15 Feb 2016 17:14:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;I feel that we are reaching a point where our efforts could be better spent elsewhere due to diminishing returns.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1, nice work!&lt;/p&gt;</comment>
                            <comment id="15148394" author="stefania" created="Tue, 16 Feb 2016 10:12:37 +0000"  >&lt;p&gt;I have experimented with CPU affinity by pinning each worker process to a core but whist this gave slightly better results locally, on AWS it actually made it worst. &lt;/p&gt;

&lt;p&gt;I&apos;ve also examined the &lt;tt&gt;strace&lt;/tt&gt; output locally and the most frequent system calls are &lt;tt&gt;futex, read, write and poll&lt;/tt&gt;. To reduce contention I&apos;ve replaced the python queue with multiple point-to-point pipes (the queue was implemented over a single pipe with interprocess locks). I didn&apos;t see much improvement locally but perhaps on AWS it matters more since locally I can only run 2 worker processes or I max out the cluster that also runs locally. By removing the Python queue I was also able to remove one thread, which in Python is a good thing due to the GIL (Global Interpreter Lock).&lt;/p&gt;

&lt;p&gt;I plan to test this implementation on AWS, together with an additional suggestion to increase time slicing (&lt;tt&gt;schedtool -B&lt;/tt&gt;), then if everything works as expected I will move the ticket to patch available.&lt;/p&gt;

&lt;p&gt;It&apos;s worth noting that the driver doesn&apos;t coalesce messages on the socket at present. This could be detrimental on virtualized environments like AWS, especially if &lt;a href=&quot;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html#other-linux-enhanced-networking-instance-store&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;enhanced networking&lt;/a&gt; is not available. However we would probably need to worry about this once our encoding functions are faster, at the moment the bottleneck is still encoding so I would leave this for a future ticket.&lt;/p&gt;</comment>
                            <comment id="15150253" author="stefania" created="Wed, 17 Feb 2016 10:31:35 +0000"  >&lt;p&gt;Here are the latest results:&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MODULE CYTHONIZED&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;PREPARED STATEMENTS&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;NUM. WORKER PROCESSES&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;CHUNK SIZE&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AVERAGE ROWS / SEC&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;TOTAL TIME&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;97,146&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&apos; 31&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;103,037&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&apos; 19&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;104,070&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&apos; 17&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;b&gt;104,498&lt;/b&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&apos; 16&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER COPYUTIL&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;89,123&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&apos; 48&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER COPYUTIL&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;107,897&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&apos; 10&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER COPYUTIL&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;b&gt;109,871&lt;/b&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&apos; 7&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER COPYUTIL&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;109,616&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&apos; 8&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;In addition to using separate pipes as mentioned above, I&apos;ve found one more optimization and I&apos;ve calibrated how much data the parent process sends to the worker processes. Two default parameters have changed: the max ingest rate is now 150k and the report frequency has changed from 4 times per second to 2. I&apos;ve run cqlsh with &lt;tt&gt;SCHED_BATCH&lt;/tt&gt; CPU scheduling (&lt;tt&gt;schedtool -B -e ./bin/cqlsh&lt;/tt&gt;) (it helps a little bit, maybe 2-3k rows/second) and I&apos;ve changed the clock source from &lt;tt&gt;xen&lt;/tt&gt; to &lt;tt&gt;tlc&lt;/tt&gt; (unsure if this helps but it doesn&apos;t hurt).&lt;/p&gt;

&lt;p&gt;I would like to repeat the tests on an AWS instance with twice the number of cores, to see how much we can scale. I&apos;ve already verified that if we half the number of cores (by fixing the affinity to only 4 cores) then the throughput also halves. I&apos;m thinking of testing on C4.4xlarge. So far I&apos;ve used R3.2xlarge but we don&apos;t need all that memory and so I would like to try a C4 instance instead. &lt;/p&gt;</comment>
                            <comment id="15154980" author="aholmber" created="Fri, 19 Feb 2016 22:15:20 +0000"  >&lt;p&gt;I have visited message coalescing in the driver a couple times, and I couldn&apos;t make it matter. It was in a more controlled environment than AWS, but I was trying to emulate network delay using local intervention.&lt;/p&gt;</comment>
                            <comment id="15154987" author="aholmber" created="Fri, 19 Feb 2016 22:17:18 +0000"  >&lt;p&gt;Curious, with the introduction of Cython, are you going to give the option to build, target a specific platform, or build for many and include extensions pre-built?&lt;/p&gt;</comment>
                            <comment id="15156755" author="stefania" created="Mon, 22 Feb 2016 10:43:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;I would like to repeat the tests on an AWS instance with twice the number of cores, to see how much we can scale. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ve tested with an &lt;tt&gt;r3.4xlarge&lt;/tt&gt; (16 cores) and with VNODES enabled (256 tokens per host). These tests have highlighted two further areas of improvement:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;One of the initial optimizations, batching by ring position, is not as effective with VNODES due to the increased number of ring positions: 2048 (8x256) positions means we cannot effectively batch a chunk size of 5000 if all partition keys are unique. Therefore I&apos;ve taken a step back and re-introduced batch by replica albeit in a way not to impact the case where we have sufficient rows for a given ring position. I&apos;ve also introduced a new load balancing policy to avoid converting a partition key into a token twice (once during batching and once when the driver queries the default token aware policy).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I noticed that the worker processes were spending too much time waiting to receive data on the larger machine. Having the parent process both read files and wait for results was becoming a careful balancing act of how much time to dedicate to receiving results: too much time and the processes get starved, too little and the progress report lags behind. Since in Python threads run sequentially due to the GIL, I decided to move reading of files into a separate child process.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I am currently testing these two optimizations. Initial results are encouraging, and consistent with &amp;gt; 100k rows/sec. I&apos;ve however noticed some time outs when VNODES are enabled, unless I increase the batch size. I am investigating this.&lt;/p&gt;

&lt;p&gt;&amp;#8211;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Curious, with the introduction of Cython, are you going to give the option to build, target a specific platform, or build for many and include extensions pre-built?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ve modified &lt;em&gt;setup.py&lt;/em&gt; with the option to build in place (&lt;tt&gt;python setup.py build_ext --inplace&lt;/tt&gt;). The idea is to write a blog and give instructions on how to boost performance by using an installed cythonized driver (&lt;tt&gt;export CQLSH_NO_BUNDLED=True&lt;/tt&gt;) and building copyutil. It&apos;s not my intention to modify the existing package for clqsh.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I have visited message coalescing in the driver a couple times, and I couldn&apos;t make it matter. It was in a more controlled environment than AWS, but I was trying to emulate network delay using local intervention.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As far as I have understood from &lt;a href=&quot;http://www.datastax.com/dev/blog/performance-doubling-with-message-coalescing&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this blog&lt;/a&gt;, it matters mostly on virtualized environments, especially AWS without enhanced networking. Another thing to note is that Nagle is not disabled. I did not appreciate this when I wrote my earlier comment.&lt;/p&gt;</comment>
                            <comment id="15162800" author="stefania" created="Wed, 24 Feb 2016 10:45:25 +0000"  >&lt;p&gt;The ticket is ready for review &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aholmber&quot; class=&quot;user-hover&quot; rel=&quot;aholmber&quot;&gt;aholmber&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The patch: &lt;a href=&quot;https://github.com/stef1927/cassandra/tree/11053-2.1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/stef1927/cassandra/tree/11053-2.1&lt;/a&gt;&lt;br/&gt;
The dtest branch: &lt;a href=&quot;https://github.com/stef1927/cassandra-dtest/tree/11053&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/stef1927/cassandra-dtest/tree/11053&lt;/a&gt;&lt;br/&gt;
The dtest results: &lt;a href=&quot;http://cassci.datastax.com/job/stef1927-11053-2.1-dtest/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/job/stef1927-11053-2.1-dtest/lastCompletedBuild/testReport/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The reason the patch targets 2.1 is mostly to compare with cassandra loader. We must decide whether we want this in 2.1 or 2.2. Technically it should be in 2.2 but the original COPY FROM performance ticket (&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9302&quot; title=&quot;Optimize cqlsh COPY FROM, part 3&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-9302&quot;&gt;&lt;del&gt;CASSANDRA-9302&lt;/del&gt;&lt;/a&gt;) was new functionality in 2.1 and hence I am not entirely sure, cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbellis&quot; class=&quot;user-hover&quot; rel=&quot;jbellis&quot;&gt;jbellis&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;Performanceresults&quot;&gt;&lt;/a&gt;Performance results&lt;/h3&gt;

&lt;p&gt;The full results are available in this &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1XTE2fSDJkwHzpdaD5HI0HlsFuPCW1Kc1NeqauF6WX2s/edit#gid=0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;spreadsheet&lt;/a&gt;.&lt;/p&gt;

&lt;h4&gt;&lt;a name=&quot;ExecutiveSummary&quot;&gt;&lt;/a&gt;Executive Summary&lt;/h4&gt;

&lt;p&gt;The optimizations introduced by this patch have increased the import speed (average rows per second) for the 1KB test (20,480,000 rows of 1kb, as specified in this &lt;a href=&quot;https://github.com/brianmhess/DSEBulkLoadTest.git&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;benchmark&lt;/a&gt;) from &lt;b&gt;35k&lt;/b&gt; to &lt;b&gt;117k&lt;/b&gt; on an 8 core VM and to &lt;b&gt;190k&lt;/b&gt; on a 16 core VM. To achieve this, the following points were adopted and are listed in order of importance:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;the driver must be installed with c extensions, cython and libev, and used by setting &lt;tt&gt;export CQLSH_NO_BUNDLED=TRUE&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;the number of worker processes and the chunk size COPY FROM options must be adjusted for maximum performance by looking at performance stats (&lt;tt&gt;dstat -lvrn 10&lt;/tt&gt;) and minimizing the CPU idle time&lt;/li&gt;
	&lt;li&gt;minimum and maximum batch size must be increased if close to cluster saturation or in the presence of VNODES&lt;/li&gt;
	&lt;li&gt;Linux CPU scheduling must be set to &lt;tt&gt;SCHED_BATCH&lt;/tt&gt; via &lt;tt&gt;schedtool -B&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;the cqlsh copyutil module must also be cythonized via &lt;tt&gt;python setup.py build_ext --inplace&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;the clock source must be set to &quot;tsc&quot;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;For further details refer to the setup instructions in the spreadsheet.&lt;/p&gt;

&lt;h4&gt;&lt;a name=&quot;Setup&quot;&gt;&lt;/a&gt;Setup&lt;/h4&gt;

&lt;p&gt;The spreadsheet above contains full setup details, including commands on how to launch and configure AWS instances. All tests were run on Ubuntu 14.04 with clock source set to tsc, using prepared statements. The client was running cassandra-2.1 with this ticket patch, and the servers were running cassandra-2.1 HEAD with the following customizations:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;batch_size_warn_threshold_in_kb: 65
compaction_throughput_mb_per_sec: 0
auto_snapshot: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;h4&gt;&lt;a name=&quot;R3.2XLARGEclientand8nodeI2.2XLARGEcluster&quot;&gt;&lt;/a&gt;R3.2XLARGE client and 8 node I2.2XLARGE cluster&lt;/h4&gt;

&lt;p&gt;This is the set-up that has been used so far. These tests give the final numbers and highlight the impact of cythonizing modules:&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MODULE CYTHONIZED&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;NUM WORKER PROCESSES&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;CHUNK SIZE&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AVG. ROWS / SEC&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NONE&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;70k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;110k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER + COPYUTIL&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;117k&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;The number of worker processes and chunk size were chosen optimally after several trials. It was noted that the optimal number of worker processes is slightly higher than the number of cores. CPU usage was observed with &lt;tt&gt;dstat&lt;/tt&gt; in order to minimize idle time, and increase network packets sent. &lt;/p&gt;

&lt;p&gt;Here is the impact of introducing VNODES with 256 tokens per node:&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MODULE CYTHONIZED&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;NUM WORKER PROCESSES&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;CHUNK SIZE&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;ADDITIONAL PARAMS&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AVG. ROWS / SEC&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;86k &amp;#40;T&amp;#41;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;68k &amp;#40;T&amp;#41;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;66k &amp;#40;T&amp;#41;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;40,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;63k &amp;#40;T&amp;#41;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;MIN_BATCH_SIZE=20 MAX_BATCH_SIZE=30&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95k &amp;#40;B&amp;#41;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;MIN_BATCH_SIZE=30 MAX_BATCH_SIZE=40&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;101k &amp;#40;B&amp;#41;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DRIVER&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;40,000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;MIN_BATCH_SIZE=30 MAX_BATCH_SIZE=40&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;105k &amp;#40;B&amp;#41;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;b&gt;&amp;#40;T&amp;#41;&lt;/b&gt; indicates timeouts, which resulted in degraded average performance. &lt;br/&gt;
&lt;b&gt;&amp;#40;B&amp;#41;&lt;/b&gt; indicates batch sizes higher than default values (MIN_BATCH_SIZE=10 MAX_BATCH_SIZE=20) and was a workaround adopted to mitigate the timeouts as indicated by the results.&lt;/p&gt;

&lt;p&gt;Another workaround for the timeouts was to increase cluster size and was adopted in the next set of tests.&lt;/p&gt;

&lt;h4&gt;&lt;a name=&quot;C3.2XLARGEclientand15nodeC3.2XLARGEcluster&quot;&gt;&lt;/a&gt;C3.2XLARGE client and 15 node C3.2XLARGE cluster&lt;/h4&gt;

&lt;p&gt;To investigate scaling and improvements with larger clusters we switched to AWS instances with less memory (COPY FROM doesn&apos;t need it) and less storage (by truncating the table after every measurement and setting &lt;tt&gt;auto_snapshot&lt;/tt&gt; to false in cassandra.yaml we were able to perform tests with the same dataset but less disk space). All tests were run with only the driver cythonized, not copyutil, and using prepared statements.&lt;/p&gt;

&lt;p&gt;This is the impact of batch CPU scheduling (&lt;tt&gt;schedtool -B&lt;/tt&gt;):&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;NUM WORKER PROCESSES&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;CHUNK SIZE&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MIN-MAX BATCH SIZE&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&lt;tt&gt;schedtool -B&lt;/tt&gt;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AVG. ROWS / SEC&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10-20 (default)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NO&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10-20 (default)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NO&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;97k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20-40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NO&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;111k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20-40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NO&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;109k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NO&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;114k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NO&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;113k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10-20 (default)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;107k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10-20 (default)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;106k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20-40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;117k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20-40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;115k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;117k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;YES&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;117k&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;This is the impact of VNODES (NUM TOKENS &amp;gt; 1), all measurements taken with &lt;tt&gt;schedtool -B&lt;/tt&gt;:&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;NUM TOKENS&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;NUM WORKER PROCESSES&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;CHUNK SIZE&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MIN-MAX BATCH SIZE&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AVG. ROWS / SEC&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;117k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;117k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;64&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;115k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;64&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;113k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;128&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;109k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;128&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;109k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;256&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;109k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;256&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;109k&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;Running with smaller batch sizes has an even higher impact, refer to the spreadsheet for details.&lt;/p&gt;

&lt;h4&gt;&lt;a name=&quot;C3.4XLARGEclientand16nodeC3.2XLARGEcluster&quot;&gt;&lt;/a&gt;C3.4XLARGE client and 16 node C3.2XLARGE cluster&lt;/h4&gt;

&lt;p&gt;Here the client was scaled by upgrading from 8 to 16 cores. All tests were run without VNODES (NUM TOKENS = 1) and with only the driver cythonized, using prepared statements.&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;NUM WORKER PROCESSES&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;CHUNK SIZE&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;MIN-MAX BATCH SIZE&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AVG. ROWS / SEC&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;NOTES&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;28&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10-20 (default)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100k to 190k&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;timeouts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;24&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10-20 (default)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100k to 190k&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;timeouts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10-20 (default)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100k to 190k&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;timeouts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;16&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10-20 (default)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100k to 190k&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;timeouts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10-20 (default)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;167k&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;INGESTRATE set to 170000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20-40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;192k, 181k&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;hardly any timeouts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;16&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20-40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;182k&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;hardly any timeouts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20-40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;181k&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;hardly any timeouts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;40000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20-40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;149k&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;hardly any timeouts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30-50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;192k, 191k&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;no timeouts&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;Due to timeouts, the average import rate was very inconsistent. Typically it would import 190k rows per second until about half of the dataset was imported, and then it would freeze for variable periods of time due to cluster saturation. &lt;/p&gt;

&lt;p&gt;Workarounds used to mitigate timeouts were to either fix the ingest rate, or increase the batch size. Fixing the ingest rate to 170k resulted in a sustainable import rate of 167k. &lt;/p&gt;

&lt;p&gt;Increasing the min batch size from the default of 10 to 30 and the max batch size from 20 to 50 resulted in a consistent rate of 190k.&lt;/p&gt;

&lt;p&gt;Overall, comparing these results to the previous test results without VNODES, indicates that COPY FROM is able to scale from 117k to 190k when switching from 8 to 16 cores.&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;Somepossiblefollowupsforfuturetickets&quot;&gt;&lt;/a&gt;Some possible follow ups for future tickets&lt;/h3&gt;

&lt;p&gt;Here are some suggestions for improving performance further:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Use the driver at a much lower level (messages and borrowed connections rather than statements and futures)&lt;/li&gt;
	&lt;li&gt;Read data from files and transfer it to worker processes faster, perhaps with shared memory&lt;/li&gt;
	&lt;li&gt;Support binary formats&lt;/li&gt;
	&lt;li&gt;Implement csv parsing and type conversion functions in cython (important for complex data types such as dates and collections)&lt;/li&gt;
	&lt;li&gt;Implement message coalescing&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15165662" author="aholmber" created="Wed, 24 Feb 2016 22:47:12 +0000"  >&lt;p&gt;Just starting on this. There are a lot of formatting changes (&lt;a href=&quot;https://github.com/apache/cassandra/commit/96fb585574199b84646c1d97cc8dd689f32d4687&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;96fb58&lt;/a&gt;, &lt;a href=&quot;https://github.com/apache/cassandra/commit/ce1504b78e64597a1a2251ef3ecedf0452609694&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;ce1504b&lt;/a&gt;, &lt;a href=&quot;https://github.com/apache/cassandra/commit/8553e1fee4069cec6c65090e9774b68ef0de2e6c&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;8553e1&lt;/a&gt;) that refer to the Cythonized driver. Can you help me understand what the issue was? It should not change return values. I think I&apos;m missing something.&lt;/p&gt;</comment>
                            <comment id="15166414" author="stefania" created="Thu, 25 Feb 2016 00:27:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;Can you help me understand what the issue was? It should not change return values. I think I&apos;m missing something.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;With cython extensions this line in cqlsh no longer works:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;cassandra.cqltypes.BytesType.deserialize = staticmethod(lambda byts, protocol_version: bytearray(byts))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So it no longer returns byte arrays for blobs and I needed a way to distinguish between blob and ascii types; they are both of type &lt;tt&gt;str&lt;/tt&gt; and it may well be that a blob contains only valid ascii bytes. At least for the time being I decided to look directly into the CQL type name and hence the parsing for composite types. We may want to add a new hook in the driver moving forward but I am no so sure how it would be possible with the cython extensions.&lt;/p&gt;</comment>
                            <comment id="15167777" author="aholmber" created="Thu, 25 Feb 2016 20:09:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;At least for the time being I decided to look directly into the CQL type name...but I am no so sure how it would be possible with the cython extensions.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Thanks for the explanation. I also think that makes cqlsh more robust. However, if you did want to avoid the extra complexity, there is a way to bypass Cython deserialization when that protocol handler is in use:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;del cassandra.deserializers.DesBytesType
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This causes the parser to default back to the patched cqltypes.BytesType.&lt;/p&gt;

&lt;p&gt;A few other thoughts...&lt;/p&gt;

&lt;p&gt;&lt;b&gt;cqlshlib.formatting.get_sub_types:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;+    &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;:
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; last &amp;lt; len(val) - 1:
+            ret.append(val[last:].strip())
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This block will always run since there is no break from the loop. Consider moving it out of the &lt;tt&gt;else&lt;/tt&gt; to make this clearer?&lt;/p&gt;

&lt;p&gt;&lt;b&gt;bin/cqlsh.Shell.print_static_result&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; table_meta:
+            cqltypes = [table_meta.columns[c].typestring &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; c in table_meta.columns &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; None &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; c in colnames]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There is an API change in driver 3.0 (C* cqlsh 2.2+) that will impact this.&lt;br/&gt;
This brings us to the question of targeting 2.1. cqlsh in 2.1 was diverging from 2.2+, and is even more so after &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-10513&quot; title=&quot;Update cqlsh for new driver execution API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-10513&quot;&gt;&lt;del&gt;CASSANDRA-10513&lt;/del&gt;&lt;/a&gt; (2.1 did not receive the driver 3.0 upgrade). I&apos;m interested to hear the input on whether this should go to 2.1.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;&quot;fix progress report&quot;&lt;/b&gt;&lt;br/&gt;
It&apos;s part of the summary, but I don&apos;t see anything in the &lt;a href=&quot;https://github.com/apache/cassandra/compare/cassandra-2.1...stef1927:11053-2.1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;changeset&lt;/a&gt; related to progress reporting. I ran an identical load with 2.1.13 and noticed that progress samples&lt;br/&gt;
are much less frequent on this branch (by a factor of 3). Both progressions were roughly linear. I don&apos;t suspect this change, but just thought I&apos;d mention in case something unintentional happened between 2.1.13 and here.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;side note&lt;/b&gt;&lt;br/&gt;
Unrelated to this change, but I stumbled upon an SO question at the same time as I was reviewing this ticket:&lt;br/&gt;
&lt;a href=&quot;http://stackoverflow.com/q/35632114/20688&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://stackoverflow.com/q/35632114/20688&lt;/a&gt;&lt;br/&gt;
I&apos;m now wondering: should we be using repr, or forcing high precision when doing copies to avoid loss of precision (or providing a precision option for COPY FROM)?&lt;/p&gt;</comment>
                            <comment id="15168411" author="stefania" created="Fri, 26 Feb 2016 04:18:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;&lt;tt&gt;del cassandra.deserializers.DesBytesType&lt;/tt&gt; causes the parser to default back to the patched cqltypes.BytesType&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s interesting. It definitely works. The performance of COPY TO for a benchmark with only blobs drops from 150k rows/sec to about 120k locally but the opposite would probably be true for a benchmark with CQL composite types. It would be very nice to remove the formatting changes from this patch, especially if it needs to go to 2.1. I&apos;ve got a &lt;a href=&quot;https://github.com/stef1927/cassandra/tree/11053-2.1-no-formatting&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;separated branch&lt;/a&gt; without the formatting changes. I&apos;m unsure what to do: parsing the CQL type is safer but it is also bolted onto an existing simpler logic that just relies on Python types and it makes this patch more complex than it needs to be. WDYT?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;b&gt;cqlshlib.formatting.get_sub_types:&lt;/b&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;+    &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;:
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; last &amp;lt; len(val) - 1:
+            ret.append(val[last:].strip())
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;

&lt;p&gt;Fixed, thank you.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;b&gt;bin/cqlsh.Shell.print_static_result&lt;/b&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; table_meta:
+            cqltypes = [table_meta.columns[c].typestring &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; c in table_meta.columns &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; None &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; c in colnames]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There is an API change in driver 3.0 (C* cqlsh 2.2+) that will impact this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m aware of this, I believe all that&apos;s needed is to replace &lt;tt&gt;typestring&lt;/tt&gt; with &lt;tt&gt;cql_type&lt;/tt&gt;. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This brings us to the question of targeting 2.1. cqlsh in 2.1 was diverging from 2.2+, and is even more so after &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-10513&quot; title=&quot;Update cqlsh for new driver execution API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-10513&quot;&gt;&lt;del&gt;CASSANDRA-10513&lt;/del&gt;&lt;/a&gt; (2.1 did not receive the driver 3.0 upgrade). I&apos;m interested to hear the input on whether this should go to 2.1.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ve asked offline regarding the target version, hopefully we&apos;ll know soon.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;b&gt;&quot;fix progress report&quot;&lt;/b&gt;&lt;br/&gt;
It&apos;s part of the summary, but I don&apos;t see anything in the changeset related to progress reporting. I ran an identical load with 2.1.13 and noticed that progress samples&lt;br/&gt;
are much less frequent on this branch&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The progress report was fixed by two things:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;the worker processes only feed aggregated results when the entire chunk is completed rather than for every batch; this decreased dramatically the number of results to be collected and also explains the change in frequency of the progress report. You will have noticed that now the progress increments by a multiple of the chunk size, rather than batch sizes. The report frequency is still 4 times per second but if no chunks were completed during this interval then it will not change, this is expected.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;the introduction of the feeder process; the only job of the parent process is now to collect results. Before it was sending data and collecting results; depending on ingest rate and polling sleep time, it could fall behind schedule.&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;b&gt;side note&lt;/b&gt;&lt;br/&gt;
should we be using repr, or forcing high precision when doing copies to avoid loss of precision (or providing a precision option for COPY FROM)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The problem isn&apos;t COPY FROM, it&apos;s COPY TO exporting with the precision of cqlsh, which by default is too low. I&apos;ve created &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-11255&quot; title=&quot;COPY TO should have higher double precision&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-11255&quot;&gt;&lt;del&gt;CASSANDRA-11255&lt;/del&gt;&lt;/a&gt; to add a new COPY TO option, since this is not related to performance and it&apos;s definitely a new feature.&lt;/p&gt;

&lt;p&gt;&amp;#8211;&lt;/p&gt;

&lt;p&gt;I&apos;m undecided on two more things:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;the default INGESTRATE: 200k may be a little bit too high and I&apos;m thinking of changing it back to 100k or maybe 120k-150k.&lt;/li&gt;
	&lt;li&gt;the number of default worker processes is no longer capped, I think it is safer to reintroduce the cap of 16, which people can override via NUMPROCESSES.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15169899" author="aholmber" created="Fri, 26 Feb 2016 21:47:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;The performance of COPY TO for a benchmark with only blobs drops from 150k rows/sec to about 120k&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I didn&apos;t expect it to be that punishing since there&apos;s no deserialization happening there. That must just be the cost of the dispatch back to Python. Here&apos;s another option: I could build in another deserializer for BytesType that returns a bytearray. You would then patch in as follows:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&amp;gt;&amp;gt;&amp;gt; deserializers.DesBytesType = deserializers.DesBytesTypeByteArray

&amp;gt;&amp;gt;&amp;gt; s.execute(&lt;span class=&quot;code-quote&quot;&gt;&apos;select c from test.t limit 1&apos;&lt;/span&gt;)[0]
    Row(c=bytearray(b&lt;span class=&quot;code-quote&quot;&gt;&apos;\xde\xad\xbe\xef&apos;&lt;/span&gt;))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I can get it in the upcoming release if it would be useful for this integration.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m unsure what to do: parsing the CQL type is safer but ...&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I was also on the fence due to the new complexity. I think I favor the cql type interpretation despite the complexity for one reason: this decouples formatting from driver return values. They don&apos;t change often, but when they have required specialization for evolving feature support (set-&amp;#45;&amp;gt;SortedSet, dict-&amp;#45;&amp;gt;OrderedMap), that would ripple into cqlsh. If we&apos;re basing formatting on cql, that is avoided.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The progress report was fixed by two things...&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Thanks. I figured out what my problem was. I was missing most of the diff because I overlooked on github: &quot;761 additions, 409 deletions not shown because the diff is too large.&quot; I have more to look at&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m undecided on two more things...default INGESTRATE...default worker processes&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I generally err on the side of caution. Reasonable limits would prevent someone from inadvertently crushing a server with a basic command. The command options make it easy enough to dial up for big load operations.&lt;/p&gt;</comment>
                            <comment id="15171292" author="stefania" created="Mon, 29 Feb 2016 01:40:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;ve asked offline regarding the target version, hopefully we&apos;ll know soon.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;From offline discussions it seems this patch can go into 2.1 provided the risk is not too high.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I could build in another deserializer for BytesType that returns a bytearray.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This would be helpful for 2.2 and 3.0 since for 2.1 we shouldn&apos;t upgrade the driver from 2.7.2 to 3.0 and for trunk we should keep the formatting changes, see next point.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think I favor the cql type interpretation despite the complexity for one reason: this decouples formatting from driver return values. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree but I prefer not to have these changes in older releases if they are not necessary for COPY FROM performance. Therefore I&apos;ve opened &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-11274&quot; title=&quot;cqlsh: interpret CQL type for formatting blob types&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-11274&quot;&gt;&lt;del&gt;CASSANDRA-11274&lt;/del&gt;&lt;/a&gt; to deliver these changes only on trunk. The formatting changes have also been removed from the main branch and the &lt;tt&gt;-no-formatting&lt;/tt&gt; branch has been deleted. The old branch however still exists with the postfix &lt;tt&gt;-with-formatting&lt;/tt&gt;.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I generally err on the side of caution. Reasonable limits would prevent someone from inadvertently crushing a server with a basic command. The command options make it easy enough to dial up for big load operations.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It makes sense, I&apos;ve reverted both values and fixed a spacing problem in the options documentation.&lt;/p&gt;</comment>
                            <comment id="15172106" author="aholmber" created="Mon, 29 Feb 2016 16:41:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://datastax-oss.atlassian.net/browse/PYTHON-503&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;PYTHON-503&lt;/a&gt; for the new deserializer in driver 3.1.0.&lt;/p&gt;</comment>
                            <comment id="15172187" author="aholmber" created="Mon, 29 Feb 2016 17:27:02 +0000"  >&lt;p&gt;Just a couple other minor comments:&lt;/p&gt;

&lt;p&gt;cqlshlib.copyutil.ExportSession.&amp;#95;&amp;#95;init&amp;#95;&amp;#95;&lt;br/&gt;
+&lt;br/&gt;
cqlshlib.copyutil.ImportProcess.session:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; LibevConnection:
        cluster.connection_class = LibevConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Did you find that the connection class was not defaulting properly when the extensions were built? It should take this value automatically if the extension is built.&lt;/p&gt;

&lt;p&gt;cqlshlib.copyutil.ExportTaskError:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An object send from child processes&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;small typo (send--&amp;gt;sent)&lt;br/&gt;
&amp;#8211;&lt;br/&gt;
+1 regardless of these&lt;/p&gt;</comment>
                            <comment id="15173201" author="stefania" created="Tue, 1 Mar 2016 04:04:48 +0000"  >&lt;p&gt;Thank you for your latest comments and for introducing &lt;tt&gt;deserializers.DesBytesTypeByteArray&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt; I&apos;ve fixed the typo, removed &lt;tt&gt;LibevConnection&lt;/tt&gt; (as it was already the default as you pointed out) and added &lt;tt&gt;DesBytesTypeByteArray&lt;/tt&gt; if available, in &lt;a href=&quot;https://github.com/stef1927/cassandra/commit/2d10a8dc7d369324ecfd5d2457c15cf716243d98&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this commit&lt;/a&gt;. I&apos;ve saved the commit history on this &lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-2.1-historical&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;historical branch&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&apos;ve squashed and up-merged:&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;2.1&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;2.2&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;2.2 win&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;3.0&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;3.5&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;trunk&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-2.1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-2.2&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-3.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-3.5&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-2.1-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-2.2-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-2.2-windows-dtest_win32/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;win dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-3.0-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-3.5-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;del&gt;No patch merges cleanly, all up-merges have conflicts.&lt;/del&gt;&lt;br/&gt;
There are conflicts all the way up to 3.5, only patch to merge cleanly is 3.5 into trunk.&lt;/p&gt;

&lt;p&gt;CI is still pending.&lt;/p&gt;</comment>
                            <comment id="15174842" author="stefania" created="Wed, 2 Mar 2016 01:50:17 +0000"  >&lt;p&gt;There are some tests failing on Windows, resuming progress.&lt;/p&gt;</comment>
                            <comment id="15174969" author="stefania" created="Wed, 2 Mar 2016 03:28:52 +0000"  >&lt;p&gt;The problem on Windows should be fixed now, I&apos;ve restarted all CI jobs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aholmber&quot; class=&quot;user-hover&quot; rel=&quot;aholmber&quot;&gt;aholmber&lt;/a&gt; the last 2 commits on &lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-2.1-historical&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this branch&lt;/a&gt; need reviewing, as well as the last commit on the &lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-3.0-historical&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;3.0 branch&lt;/a&gt; - which is the same as discussed on &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-11274&quot; title=&quot;cqlsh: interpret CQL type for formatting blob types&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-11274&quot;&gt;&lt;del&gt;CASSANDRA-11274&lt;/del&gt;&lt;/a&gt;. &lt;/p&gt;</comment>
                            <comment id="15176106" author="aholmber" created="Wed, 2 Mar 2016 18:03:22 +0000"  >&lt;p&gt;+1 @2aff646, 8c798c2&lt;br/&gt;
Sorry I missed the date overflow on the first pass here.&lt;/p&gt;</comment>
                            <comment id="15177068" author="stefania" created="Thu, 3 Mar 2016 03:06:42 +0000"  >&lt;p&gt;Thank you for the latest review. &lt;/p&gt;

&lt;p&gt;Unfortunately there was one more small problem; I noticed it on Windows but it is actually happening on Linux too. If a child process crashes, &lt;tt&gt;import_records&lt;/tt&gt; will not terminate because the parent process is unable to get the lock required to write termination messages to the pipes. The reason is that the feeder process is hanging on a send and not releasing the lock. To fix this properly, we would have to introduce a bounded semaphore to keep track of how many messages are in transit on a pipe. However, since the problem only occurs when a child process crashes, and in this case we just want to terminate, I simply added a workaround to avoid sending termination messages to processes if at least one has crashed. In this case the processes will simply terminate. The only consequence should be that any profiling results won&apos;t be available. &lt;/p&gt;

&lt;p&gt;Please check &lt;a href=&quot;https://github.com/stef1927/cassandra/commit/7186cf803fe6cff126b310d7b7785623688b9aa4&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this commit&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&apos;ve restarted CI on all branches.&lt;/p&gt;</comment>
                            <comment id="15177280" author="stefania" created="Thu, 3 Mar 2016 05:59:15 +0000"  >&lt;p&gt;One more test timing out, fix is &lt;a href=&quot;https://github.com/stef1927/cassandra/commit/28f77134bd1d96bc6a4235ba3232082db5f92043&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15178132" author="aholmber" created="Thu, 3 Mar 2016 17:03:33 +0000"  >&lt;p&gt;+1 @28f7713&lt;/p&gt;</comment>
                            <comment id="15179075" author="stefania" created="Fri, 4 Mar 2016 01:08:47 +0000"  >&lt;p&gt;Thank you, CI results are clean.&lt;/p&gt;

&lt;p&gt;This patch is ready for commit, merge information and patches available in the 7th comment above and repeated here:&lt;/p&gt;

&lt;blockquote&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;2.1&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;2.2&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;2.2 win&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;3.0&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;3.5&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;trunk&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-2.1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-2.2&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-3.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-3.5&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-2.1-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-2.2-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-2.2-windows-dtest_win32/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;win dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-3.0-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-3.5-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;There are conflicts all the way up to 3.5, only patch to merge cleanly is 3.5 into trunk.&lt;/p&gt;
&lt;/blockquote&gt;</comment>
                            <comment id="15184712" author="slebresne" created="Tue, 8 Mar 2016 09:27:23 +0000"  >&lt;p&gt;Committed, thanks.&lt;/p&gt;</comment>
                            <comment id="15200199" author="JIRAUSER308715" created="Thu, 17 Mar 2016 19:21:58 +0000"  >&lt;p&gt;On the following node:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Linux atest-55c62b1 3.13.0-74-generic #118-Ubuntu SMP Thu Dec 17 22:52:10 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Running cassandra-3.0 HEAD this copy change is broken for a simple test.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ cat kv.cql
create keyspace &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; not exists cvs_copy_ks with replication = {&lt;span class=&quot;code-quote&quot;&gt;&apos;class&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;SimpleStrategy&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;replication_factor&apos;&lt;/span&gt;:1};
create table &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; not exists cvs_copy_ks.kv (key &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; primary key, value text);
truncate cvs_copy_ks.kv;
copy cvs_copy_ks.kv (key, value) from &lt;span class=&quot;code-quote&quot;&gt;&apos;kv.csv&apos;&lt;/span&gt; with header=&lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&apos;&lt;/span&gt;;
select * from cvs_copy_ks.kv;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ cat kv.csv
key,value
1,&lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;
2,&lt;span class=&quot;code-quote&quot;&gt;&apos;b&apos;&lt;/span&gt;
3,&lt;span class=&quot;code-quote&quot;&gt;&apos;c&apos;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If I run that it just hangs.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;./cqlsh -f kv.cql
Using 1 child processes

Starting copy of cvs_copy_ks.kv with columns [&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;value&apos;&lt;/span&gt;].
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I added some debug and it hangs in spinning here &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/cassandra/blob/cassandra-3.0/pylib/cqlshlib/copyutil.py#L1166&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/cassandra/blob/cassandra-3.0/pylib/cqlshlib/copyutil.py#L1166&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Because channels is an empty list.&lt;/p&gt;</comment>
                            <comment id="15201120" author="stefania" created="Fri, 18 Mar 2016 07:51:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aholmber&quot; class=&quot;user-hover&quot; rel=&quot;aholmber&quot;&gt;aholmber&lt;/a&gt; the patch is ready, are you still available to review it?&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;2.1&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;2.2&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;2.2 win&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;3.0&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;3.5&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;trunk&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-2.1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-2.2&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-3.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053-3.5&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commits/11053&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-2.1-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-2.2-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-2.2-windows-dtest_win32/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;win dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-3.0-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-3.5-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-11053-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;The 2.1 patch merges cleanly up to 3.5, then there is a simple conflict into trunk.&lt;/p&gt;

&lt;p&gt;The issue reported above by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jjordan&quot; class=&quot;user-hover&quot; rel=&quot;jjordan&quot;&gt;jjordan&lt;/a&gt; was caused by the fact that the machine has only one core. There was a typo that caused the number of worker processes to be zero. This was easy to fix. However, I then introduced a bulk copy test by simulating a single core machine, see &lt;a href=&quot;https://github.com/riptano/cassandra-dtest/pull/869&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this pull request&lt;/a&gt;, and this highlighted a more serious deadlock in COPY TO. To fix this I had to introduce a new thread in the COPY TO worker processes.&lt;/p&gt;

&lt;p&gt;Incidentally, this bug means that the performance measurements taken above were running 1 worker process less than indicated.&lt;/p&gt;</comment>
                            <comment id="15201477" author="aholmber" created="Fri, 18 Mar 2016 13:36:27 +0000"  >&lt;p&gt;Planning to look at it today.&lt;/p&gt;</comment>
                            <comment id="15201500" author="JIRAUSER308715" created="Fri, 18 Mar 2016 14:04:33 +0000"  >&lt;p&gt;Didn&apos;t review the code, but this does fix COPY hanging on my simple test machine.  Thanks.&lt;/p&gt;</comment>
                            <comment id="15204297" author="aholmber" created="Mon, 21 Mar 2016 14:17:57 +0000"  >&lt;p&gt;A few comments on review:&lt;/p&gt;

&lt;p&gt;It is not clear to me why we&apos;re using deque+Event and not a &lt;a href=&quot;https://docs.python.org/2/library/queue.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Queue&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We may want to &lt;a href=&quot;https://docs.python.org/2/library/threading.html#threading.Thread.daemon&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;daemonize&lt;/a&gt; the feeder thread to avoid hanging on exit while the thread continues forever.&lt;/p&gt;

&lt;p&gt;Are there any recoverable exceptions that would warrant exception handling in that thread body?&lt;/p&gt;</comment>
                            <comment id="15205629" author="stefania" created="Tue, 22 Mar 2016 02:06:48 +0000"  >&lt;p&gt;Thank you for the review, I&apos;ve applied all 3 suggestions in &lt;a href=&quot;https://github.com/stef1927/cassandra/commit/07854f803e42f4a2afceff3585cdb27c16aad958&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this commit&lt;/a&gt;. It merges cleanly upwards to all branches.&lt;/p&gt;

&lt;p&gt;I wasn&apos;t aware of the Queue module, that&apos;s why I chose a lower level approach based on deque+Event. There aren&apos;t any recoverable exceptions as far as I can see, but I&apos;ve added exception handling anyway to be on the safe side.&lt;/p&gt;</comment>
                            <comment id="15206402" author="aholmber" created="Tue, 22 Mar 2016 14:00:53 +0000"  >&lt;p&gt;Changes look good. +1 at 07854f8&lt;/p&gt;</comment>
                            <comment id="15207669" author="stefania" created="Wed, 23 Mar 2016 01:18:39 +0000"  >&lt;p&gt;Thank you Adam. I&apos;ve rebased, squashed and restarted CI. I will change the status to ready to commit if CI is OK.&lt;/p&gt;</comment>
                            <comment id="15207770" author="stefania" created="Wed, 23 Mar 2016 02:33:25 +0000"  >&lt;p&gt;CI looks good, ready to commit. Merge information a few comments up.&lt;/p&gt;</comment>
                            <comment id="15214585" author="jmckenzie" created="Mon, 28 Mar 2016 18:03:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=cassandra.git;a=commit;h=a9b5422057054b0ba612164d56d7cce5567e48df&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Committed&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12945318">CASSANDRA-11274</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12961491">CASSANDRA-11630</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12944756">CASSANDRA-11255</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12945318">CASSANDRA-11274</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12827309">CASSANDRA-9302</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12957944">CASSANDRA-11549</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12958863">CASSANDRA-11574</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12794676" name="bisect_test.py" size="1467" author="stefania" created="Tue, 22 Mar 2016 03:01:12 +0000"/>
                            <attachment id="12785721" name="copy_from_large_benchmark.txt" size="2903" author="stefania" created="Tue, 2 Feb 2016 06:50:14 +0000"/>
                            <attachment id="12785985" name="copy_from_large_benchmark_2.txt" size="4715" author="stefania" created="Wed, 3 Feb 2016 08:27:27 +0000"/>
                            <attachment id="12785720" name="parent_profile.txt" size="9018" author="stefania" created="Tue, 2 Feb 2016 06:49:25 +0000"/>
                            <attachment id="12785979" name="parent_profile_2.txt" size="8958" author="stefania" created="Wed, 3 Feb 2016 07:57:11 +0000"/>
                            <attachment id="12785719" name="worker_profiles.txt" size="197383" author="stefania" created="Tue, 2 Feb 2016 06:49:25 +0000"/>
                            <attachment id="12785978" name="worker_profiles_2.txt" size="62041" author="stefania" created="Wed, 3 Feb 2016 07:57:11 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[stefania]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 34 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2rryf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>aholmber</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[aholmber]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>