<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:25:54 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-3427] CompressionMetadata is not shared across threads, we create a new one for each read</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-3427</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;The CompressionMetada holds the compressed block offsets in memory. Without being absolutely huge, this is still of non-negligible size as soon as you have a bit of data in the DB. Reallocating this for each read is a very bad idea.&lt;/p&gt;

&lt;p&gt;Note that this only affect range queries, since &quot;normal&quot; queries uses CompressedSegmentedFile that does reuse a unique CompressionMetadata instance.&lt;/p&gt;

&lt;p&gt;( Background: &lt;a href=&quot;http://thread.gmane.org/gmane.comp.db.cassandra.user/21362&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://thread.gmane.org/gmane.comp.db.cassandra.user/21362&lt;/a&gt; )&lt;/p&gt;</description>
                <environment></environment>
        <key id="12529483">CASSANDRA-3427</key>
            <summary>CompressionMetadata is not shared across threads, we create a new one for each read</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="slebresne">Sylvain Lebresne</assignee>
                                    <reporter username="slebresne">Sylvain Lebresne</reporter>
                        <labels>
                            <label>compression</label>
                    </labels>
                <created>Mon, 31 Oct 2011 13:57:36 +0000</created>
                <updated>Tue, 16 Apr 2019 09:32:47 +0000</updated>
                            <resolved>Mon, 31 Oct 2011 15:44:26 +0000</resolved>
                                        <fixVersion>1.0.2</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="13140207" author="michaelsembwever" created="Mon, 31 Oct 2011 15:01:48 +0000"  >&lt;p&gt;This is unfortunately a showstopper for our hadoop jobs querying our production cluster.&lt;/p&gt;

&lt;p&gt;With 1.0.1 is there any workaround for this issue?&lt;br/&gt;
Is it correct that this &quot;compressed block offsets&quot; totals to &lt;br/&gt;
  (&amp;lt;sstable-size&amp;gt; / &amp;lt;chunk_length&amp;gt;) * 8bytes&lt;/p&gt;

&lt;p&gt;Therefore a change to a higher chunk_length should be an intermediate workaround?&lt;/p&gt;</comment>
                            <comment id="13140221" author="slebresne" created="Mon, 31 Oct 2011 15:20:51 +0000"  >&lt;p&gt;Quite honestly, the best workaround is likely to apply the attached patch on top of 1.0.1 (you can wait for someone to review to get a bit more confidence).&lt;/p&gt;

&lt;p&gt;Because yes, a bigger chunk_length would diminish the problem, but if you do enough range_queries you would likely still OOM and there is point after which a chunk_length too big is just counter-productive. &lt;/p&gt;</comment>
                            <comment id="13140232" author="xedin" created="Mon, 31 Oct 2011 15:44:26 +0000"  >&lt;p&gt;Committed.&lt;/p&gt;</comment>
                            <comment id="13140515" author="michaelsembwever" created="Mon, 31 Oct 2011 20:10:58 +0000"  >&lt;p&gt;Rolled out into production. Works a charm! Even on 200Gb sstables.&lt;/p&gt;

&lt;p&gt;Sincere appreciations on this one.&lt;/p&gt;</comment>
                            <comment id="13142561" author="michaelsembwever" created="Wed, 2 Nov 2011 21:25:22 +0000"  >&lt;p&gt;Won&apos;t the cache here leak?&lt;br/&gt;
Many (most?) sstables are transient (gone after the next minor compaction), but this cache will just grow...&lt;/p&gt;</comment>
                            <comment id="13142568" author="xedin" created="Wed, 2 Nov 2011 21:30:59 +0000"  >&lt;p&gt;Oh yes, it seems like I missed that one - we should remove entry from the cache when SSTable gets compacted out. What do you think, Sylvain?&lt;/p&gt;</comment>
                            <comment id="13142576" author="michaelsembwever" created="Wed, 2 Nov 2011 21:38:07 +0000"  >&lt;p&gt;Or use a ConcurrentLinkedHashMap w/ fixed capacity?&lt;/p&gt;</comment>
                            <comment id="13142580" author="xedin" created="Wed, 2 Nov 2011 21:43:23 +0000"  >&lt;p&gt;yes but that will also imply that we should weight it in memory size instead of number of entries so need to use jamm which is calculation overhead, better just remove unused because we know precisely when to do that...&lt;/p&gt;</comment>
                            <comment id="13142838" author="michaelsembwever" created="Thu, 3 Nov 2011 04:55:37 +0000"  >&lt;p&gt;patch according to Pavel&apos;s suggestion&lt;/p&gt;</comment>
                            <comment id="13143039" author="slebresne" created="Thu, 3 Nov 2011 10:47:52 +0000"  >&lt;p&gt;Ok, I think using an object cache is ugly (I know that it was my idea).&lt;/p&gt;

&lt;p&gt;At first, I tried going with the natural idea, to add the compressionMetadata as a final field of SSTableReader and use that everywhere, ensuring we use one per sstable. Turned out that for SSTableWriter you need to have the metadata existing before the SSTableReader is created and that seemed like a bit of a mess so I backtracked and decided to go with an object cache in CompressionMetada, but more out of laziness than anything else.&lt;/p&gt;

&lt;p&gt;That was wrong of me to be lazy. We don&apos;t need that object cache and if its use is going to leak out of CompressionMetada (like hard coding the addition of the notifier in the DataTracker constructor; which defeats the purpose of the notifier abstraction in the first place) then it&apos;s not even clean as far as code is concerned.&lt;/p&gt;

&lt;p&gt;Attaching a v2 patch that remove the cache and do a slight modification of the initial idea, that is it just let CompressedSegmentedFile create the CompressionMetada and have the rest of the code use that. Turns out that once I plug my brain, it&apos;s only a few lines of code.&lt;/p&gt;</comment>
                            <comment id="13143188" author="xedin" created="Thu, 3 Nov 2011 14:09:39 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13143195" author="slebresne" created="Thu, 3 Nov 2011 14:17:52 +0000"  >&lt;p&gt;Alright, committed this new version, thanks&lt;/p&gt;</comment>
                            <comment id="13149279" author="michaelsembwever" created="Sun, 13 Nov 2011 11:39:51 +0000"  >&lt;p&gt;Handling jvm memory since upgrading to cassandra-1.0 and enabling compression is still a headache.&lt;br/&gt;
Where i used to be able to run w/ Xmx8G i&apos;m now struggling to run with Xmx20G (all caches are disabled) and during startup can hit&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.lang.OutOfMemoryError: Java heap space
        at org.apache.cassandra.utils.BigLongArray.&amp;lt;init&amp;gt;(BigLongArray.java:53)
        at org.apache.cassandra.utils.BigLongArray.&amp;lt;init&amp;gt;(BigLongArray.java:39)
        at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:122)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I could keep increasing chunk_length (it&apos;s already at 256) but this seems awkward just to get a cluster running smoothly. At minimum the calculations for memory requirements for cassandra should be re-written if compression is to take such a large chunk of heap.&lt;/p&gt;</comment>
                            <comment id="13149285" author="jbellis" created="Sun, 13 Nov 2011 13:33:31 +0000"  >&lt;p&gt;Does heap usage stay high-post startup?  Can you try forcing a full GC to check that?&lt;/p&gt;</comment>
                            <comment id="13149312" author="michaelsembwever" created="Sun, 13 Nov 2011 16:45:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;Does heap usage stay high-post startup? Can you try forcing a full GC to check that?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. GC doesn&apos;t seem to help, i&apos;ll attach a munin graph that shows it over time. It was running for a number of days just under 20G, but you can see from that how &quot;squeezed&quot; it was.&lt;/p&gt;

&lt;p&gt;(invoking full gc via jmx has no noticeable effect on heap used)&lt;/p&gt;</comment>
                            <comment id="13149314" author="michaelsembwever" created="Sun, 13 Nov 2011 16:55:09 +0000"  >&lt;p&gt;0.8 was running on Xmx8G up until week 44.&lt;br/&gt;
at that point we upgraded to 1.0 and enabled compression. The very high memory usage at the beginning of week 44 was to handle the change from chunk_length 16 to 256.&lt;br/&gt;
Then for most of week 44 and week 45 we ran with Xmx16G, but this was very &quot;squeezed&quot;. Now that&apos;s OOM, and raising it to 20G didn&apos;t help. Currently it&apos;s on 30G.&lt;/p&gt;

&lt;p&gt;Also note we&apos;re always used -XX:CMSInitiatingOccupancyFraction=60 for this cluster.&lt;br/&gt;
(full java opts are &quot;-Xss128k -XX:+UseThreadPriorities -XX:ThreadPriorityPolicy=42  -XX:SurvivorRatio=8  -XX:MaxTenuringThreshold=1  -XX:+UseParNewGC  -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction=60 -XX:+UseCMSInitiatingOccupancyOnly -Xmx30g -Xmx30g -Xmn800M   -XX:ParallelCMSThreads=4  -XX:+CMSIncrementalMode  -XX:+CMSIncrementalPacing  -XX:CMSIncrementalDutyCycleMin=0  -XX:CMSIncrementalDutyCycle=10&quot;. the last 5 were added during week 44 to try and help, ref &lt;a href=&quot;http://blog.mikiobraun.de/2010/08/cassandra-gc-tuning.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://blog.mikiobraun.de/2010/08/cassandra-gc-tuning.html&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="13149637" author="jbellis" created="Mon, 14 Nov 2011 14:12:49 +0000"  >&lt;p&gt;What version exactly are you running now?  1.0.2?  1.0.0 + 3427?  Something else?&lt;/p&gt;</comment>
                            <comment id="13149645" author="slebresne" created="Mon, 14 Nov 2011 14:25:36 +0000"  >&lt;p&gt;I&apos;ve attached a tiny patch (0001-debugging.patch) that prints in the log the size of the long array we allocate for the chunk offsets. Would you mind trying with this and attach a log of when startup hits one of the OOM you pasted earlier (feel free to use a 8GB heap if it&apos;s easier to reproduce). I&apos;d like to know if those offsets are indeed the problem.&lt;/p&gt;</comment>
                            <comment id="13149650" author="jbellis" created="Mon, 14 Nov 2011 14:30:20 +0000"  >&lt;p&gt;I can get you a place to upload the heap dump from an OOM too.  (8GB would be best, since heap analysis requires ram proportional to the heap size.)&lt;/p&gt;

&lt;p&gt;To rule out the obvious, have you tried running 1.0.x w/o compression?&lt;/p&gt;</comment>
                            <comment id="13149796" author="michaelsembwever" created="Mon, 14 Nov 2011 18:14:33 +0000"  >&lt;p&gt;version: 1.0.2 snapshot (pretty close to release date) + &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-3197&quot; title=&quot;Separate input and output connection details in ConfigHelper&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-3197&quot;&gt;&lt;del&gt;CASSANDRA-3197&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
w/o compression: that would require a full compact/scrub. that takes close to 24hrs &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
patch: i attach that and hopefully have output soon. a heap dump can be done at the same time...&lt;/p&gt;</comment>
                            <comment id="13149861" author="michaelsembwever" created="Mon, 14 Nov 2011 20:06:26 +0000"  >&lt;p&gt;startup log with debug (off 1.0.2 release)&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;INFO  48:34,688 DatabaseDescriptor: Loading settings from file:/iad/finn/countstatistics/conf/cassandra-prod.yaml
INFO  48:34,782 DatabaseDescriptor: DiskAccessMode &apos;auto&apos; determined to be mmap, indexAccessMode is mmap
INFO  48:34,792 DatabaseDescriptor: Global memtable threshold is enabled at 512MB
INFO  48:34,890 AbstractCassandraDaemon: JVM vendor/version: Java HotSpot(TM) 64-Bit Server VM/1.6.0_24
INFO  48:34,891 AbstractCassandraDaemon: Heap size: 760414208/8506048512
INFO  48:34,891 AbstractCassandraDaemon: Classpath: /iad/finn/countstatistics/jar/countstatistics.jar:/iad/common/apps/cassandra/lib/jamm-0.2.5.jar
INFO  48:37,158 CLibrary: JNA mlockall successful
INFO  48:37,879 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/system/Versions-h-42 (256 bytes)
INFO  48:37,879 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/system/Versions-h-41 (256 bytes)
INFO  48:37,879 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/system/Versions-h-40 (256 bytes)
INFO  48:37,959 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/system/IndexInfo-h-3 (223 bytes)
INFO  48:38,001 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/system/Schema-h-15 (34257 bytes)
INFO  48:38,045 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/system/Migrations-h-15 (78524 bytes)
INFO  48:38,096 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/system/LocationInfo-h-150 (80 bytes)
INFO  48:38,096 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/system/LocationInfo-h-149 (628 bytes)
INFO  48:38,096 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/system/LocationInfo-h-151 (163 bytes)
INFO  48:38,192 DatabaseDescriptor: Loading schema version 1940c630-0be4-11e1-0000-d1695892b1ff
INFO  51:35,136 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191473 (38646535 bytes)
INFO  51:35,136 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-190467 (2284524668 bytes)
INFO  51:35,136 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191469 (254927460 bytes)
INFO  51:35,136 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191475 (30477008 bytes)
INFO  51:35,136 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-114136 (156044360682 bytes)
INFO  51:35,137 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191294 (4585008988 bytes)
INFO  51:35,137 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-190415 (15857295280 bytes)
INFO  51:35,137 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-183183 (196289440978 bytes)
INFO  51:35,137 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191472 (1346076 bytes)
INFO  51:35,137 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-190736 (4626053255 bytes)
INFO  51:35,137 SSTableReader: Opening /iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191435 (1188223188 bytes)
INFO  51:35,187 CompressionMetadata: Allocating chunks index for 5745 chunks for uncompressed size of 1470519 (/iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191472-CompressionInfo.db)
INFO  51:35,421 CompressionMetadata: Allocating chunks index for 129646 chunks for uncompressed size of 33189311 (/iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191475-CompressionInfo.db)
INFO  51:35,544 CompressionMetadata: Allocating chunks index for 165602 chunks for uncompressed size of 42393918 (/iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191473-CompressionInfo.db)
INFO  51:37,171 CompressionMetadata: Allocating chunks index for 1091377 chunks for uncompressed size of 279392485 (/iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191469-CompressionInfo.db)
INFO  51:41,148 CompressionMetadata: Allocating chunks index for 5086138 chunks for uncompressed size of 1302051278 (/iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191435-CompressionInfo.db)
INFO  51:46,351 CompressionMetadata: Allocating chunks index for 9766541 chunks for uncompressed size of 2500234376 (/iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-190467-CompressionInfo.db)
INFO  51:56,717 CompressionMetadata: Allocating chunks index for 19828434 chunks for uncompressed size of 5076078986 (/iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-190736-CompressionInfo.db)
INFO  51:56,897 CompressionMetadata: Allocating chunks index for 19626358 chunks for uncompressed size of 5024347477 (/iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-191294-CompressionInfo.db)
INFO  52:21,670 CompressionMetadata: Allocating chunks index for 67865822 chunks for uncompressed size of 17373650297 (/iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-190415-CompressionInfo.db)
INFO  55:55,920 CompressionMetadata: Allocating chunks index for 666981588 chunks for uncompressed size of 170747286320 (/iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-114136-CompressionInfo.db)
INFO  56:49,620 CompressionMetadata: Allocating chunks index for 840404671 chunks for uncompressed size of 215143595584 (/iad/finn/countstatistics/cassandra-data/countstatisticsCount/thrift_no_finntech_countstats_count_Count_neg8589045746818385983-h-183183-CompressionInfo.db)
ERROR 57:51,112 AbstractCassandraDaemon: Fatal exception in thread Thread[SSTableBatchOpen:8,5,main]
java.lang.OutOfMemoryError: Java heap space
	at org.apache.cassandra.utils.BigLongArray.&amp;lt;init&amp;gt;(BigLongArray.java:53)
	at org.apache.cassandra.utils.BigLongArray.&amp;lt;init&amp;gt;(BigLongArray.java:39)
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:127)
        ...&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13149911" author="slebresne" created="Mon, 14 Nov 2011 21:01:45 +0000"  >&lt;p&gt;That&apos;s the stupidest bug ever. It happens we interpret the chunk_length_in_kb not in kb but in bytes.&lt;br/&gt;
Anyway, I&apos;ve created &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-3492&quot; title=&quot;Compression option chunk_length is not converted into KB as it should&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-3492&quot;&gt;&lt;del&gt;CASSANDRA-3492&lt;/del&gt;&lt;/a&gt; to address this.&lt;br/&gt;
Turns out if you don&apos;t update the chunk_length you&apos;re fine because the default is ok, but I guess hitting this issue initially has put you in the wrong spot &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12503620" name="0001-debugging.patch" size="1720" author="slebresne" created="Mon, 14 Nov 2011 14:22:15 +0000"/>
                            <attachment id="12501622" name="3427.patch" size="6311" author="slebresne" created="Mon, 31 Oct 2011 15:16:57 +0000"/>
                            <attachment id="12502124" name="3427_v2.patch" size="9802" author="slebresne" created="Thu, 3 Nov 2011 10:47:52 +0000"/>
                            <attachment id="12502099" name="CASSANDRA-3427.patch" size="2554" author="mck" created="Thu, 3 Nov 2011 04:55:36 +0000"/>
                            <attachment id="12503537" name="jmx_jvm_memory-month.png" size="23717" author="mck" created="Sun, 13 Nov 2011 16:55:09 +0000"/>
                            <attachment id="12503536" name="jmx_jvm_memory-week.png" size="22732" author="mck" created="Sun, 13 Nov 2011 16:55:09 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[slebresne]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>215343</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            14 years, 2 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0gjrj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>94632</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>xedin</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[xedin]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>