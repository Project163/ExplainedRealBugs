<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:40:37 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-5932] Speculative read performance data show unexpected results</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-5932</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;I&apos;ve done a series of stress tests with eager retries enabled that show undesirable behavior. I&apos;m grouping these behaviours into one ticket as they are most likely related.&lt;/p&gt;

&lt;p&gt;1) Killing off a node in a 4 node cluster actually increases performance.&lt;br/&gt;
2) Compactions make nodes slow, even after the compaction is done.&lt;br/&gt;
3) Eager Reads tend to lessen the &lt;b&gt;immediate&lt;/b&gt; performance impact of a node going down, but not consistently.&lt;/p&gt;

&lt;p&gt;My Environment:&lt;br/&gt;
1 stress machine: node0&lt;br/&gt;
4 C* nodes: node4, node5, node6, node7&lt;/p&gt;

&lt;p&gt;My script:&lt;br/&gt;
node0 writes some data: stress -d node4 -F 30000000 -n 30000000 -i 5 -l 2 -K 20&lt;br/&gt;
node0 reads some data: stress -d node4 -n 30000000 -o read -i 5 -K 20&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;Examples%3A&quot;&gt;&lt;/a&gt;Examples:&lt;/h3&gt;

&lt;h5&gt;&lt;a name=&quot;Anodegoingdownincreasesperformance%3A&quot;&gt;&lt;/a&gt;A node going down increases performance:&lt;/h5&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12599763/12599763_node-down-increase-performance.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.eager_retry.node_killed.just_20.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Data for this test here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;At 450s, I kill -9 one of the nodes. There is a brief decrease in performance as the snitch adapts, but then it recovers... to even higher performance than before.&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;Compactionsmakenodespermanentlyslow%3A&quot;&gt;&lt;/a&gt;Compactions make nodes permanently slow:&lt;/h5&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12599762/12599762_compaction-makes-slow.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12599771/12599771_compaction-makes-slow-stats.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The green and orange lines represent trials with eager retry enabled, they never recover their op-rate from before the compaction as the red and blue lines do.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.eager_retry.compaction.2.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Data for this test here&lt;/a&gt;&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;SpeculativeReadtendstolessentheimmediateimpact%3A&quot;&gt;&lt;/a&gt;Speculative Read tends to lessen the &lt;b&gt;immediate&lt;/b&gt; impact:&lt;/h5&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12599761/12599761_eager-read-looks-promising.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12599770/12599770_eager-read-looks-promising-stats.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;This graph looked the most promising to me, the two trials with eager retry, the green and orange line, at 450s showed the smallest dip in performance. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.eager_retry.node_killed.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Data for this test here&lt;/a&gt;&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;Butnotalways%3A&quot;&gt;&lt;/a&gt;But not always:&lt;/h5&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12599760/12599760_eager-read-not-consistent.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12599769/12599769_eager-read-not-consistent-stats.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;This is a retrial with the same settings as above, yet the 95percentile eager retry (red line) did poorly this time at 450s.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.eager_retry.node_killed.just_20.rc1.try2.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Data for this test here&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665353">CASSANDRA-5932</key>
            <summary>Speculative read performance data show unexpected results</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="aleksey">Aleksey Yeschenko</assignee>
                                    <reporter username="enigmacurry">Ryan McGuire</reporter>
                        <labels>
                    </labels>
                <created>Sat, 24 Aug 2013 00:51:07 +0000</created>
                <updated>Tue, 14 Oct 2025 12:13:57 +0000</updated>
                            <resolved>Thu, 26 Sep 2013 20:55:41 +0000</resolved>
                                        <fixVersion>2.0.2</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>13</watches>
                                                                                                                <comments>
                            <comment id="13768448" author="hubez" created="Mon, 16 Sep 2013 16:03:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enigmacurry&quot; class=&quot;user-hover&quot; rel=&quot;enigmacurry&quot;&gt;enigmacurry&lt;/a&gt;, what was your collection interval for the metrics you&apos;ve collected?&lt;/p&gt;

&lt;p&gt;I ask because I&apos;m observing results similar to yours for &quot;3) Eager Reads tend to lessen the immediate performance impact of a node going down, but not consistently.&quot;. However, I&apos;ve polled metrics @ a 1 second granularity to see that it&apos;s actually a multi-second stress-client outage - not just poor and inconsistent performance.&lt;/p&gt;

&lt;p&gt;Polling metrics @ a 1 second interval, has observations that a ~20 second read operations starvation outage occurs for the stress client for all data in the cluster (even with the lowest phi_convict_threshold=6).&lt;/p&gt;

&lt;p&gt;Analysis so far indicates that high-operations reads starve out all the C* client threads/connections, because they get stuck on awaiting for a server response whenever the key-space hits the node that is down (and by probability + high-operation reads, within 1 second each stress client thread will all hit the downed-node&apos;s key-space).&lt;/p&gt;



&lt;p&gt;So I&apos;m confirming that I&apos;m also seeing this bug that Speculative reads (even with an ALWAYS setting). It isn&apos;t solving this outage for clients during high-operation reads, and based on what I understand of the feature, it should.&lt;/p&gt;

&lt;p&gt;Thanks, guys!&lt;/p&gt;
</comment>
                            <comment id="13768536" author="enigmacurry" created="Mon, 16 Sep 2013 17:41:23 +0000"  >&lt;p&gt;I&apos;m using 5 second intervals in these charts. &apos;multi-second stress-client outage&apos; is a good way to put it, for both the case of speculative retry and not, the drop in performance after a node goes down is a duration of complete non-responsiveness (not degraded performance.) The addition of speculative retry consistently shortens this duration (it&apos;s always better), but this duration itself is inconsistent. &lt;/p&gt;</comment>
                            <comment id="13770170" author="kohlisankalp" created="Tue, 17 Sep 2013 23:39:26 +0000"  >&lt;p&gt;SpeculateAlwaysExecutor - Here we are not reading from more endpoints than normal. We are only reading data from two endpoints. We should be reading from one more endpoint if possible. &lt;/p&gt;</comment>
                            <comment id="13771139" author="hubez" created="Wed, 18 Sep 2013 19:28:52 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enigmacurry&quot; class=&quot;user-hover&quot; rel=&quot;enigmacurry&quot;&gt;enigmacurry&lt;/a&gt;. Sounds like you are seeing the same thing as us, so it&apos;s great to see it&apos;s getting attention!&lt;/p&gt;</comment>
                            <comment id="13776805" author="lizou" created="Tue, 24 Sep 2013 21:53:19 +0000"  >&lt;p&gt;Hello &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iamaleksey&quot; class=&quot;user-hover&quot; rel=&quot;iamaleksey&quot;&gt;iamaleksey&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;Thanks for the link to this jira and for your very detailed testing results. It confirms what we have seen in our lab testing for the Cassandra 2.0.0-rc2 &quot;Speculative Execution for Reads&quot;.&lt;/p&gt;

&lt;p&gt;We have a very simple data center setup consisting of four Cassandra nodes running on four server machines. A testing application (Cassandra client) is interacting with Cassandra nodes 1, 2 and 3. That is, the testing app does not directly connected to the Cassandra node 4.&lt;/p&gt;

&lt;p&gt;The keyspace Replication Factor is set to 3 and the client requested Consistency Level is set to CL_TWO.&lt;/p&gt;

&lt;p&gt;I have tested all of three configurations of the Speculative Execution for Reads (&apos;ALWAYS&apos;, &apos;85 PERCENTILE&apos;, &apos;50 MS&apos; / &apos;100 MS&apos;). It seems that none of them works as expected. From the test app log file point of view, they all give a 20-second window of outage immediately after the 4th node was killed. This behavior is consistent to Cassandra 1.2.4.&lt;/p&gt;

&lt;p&gt;I have done a quick code reading of the Cassandra Server implementation (Cassandra 2.0.0 tarball) and I have noticed some design issues. I would like to discuss them with you.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Issue 1&lt;/b&gt; - StorageProxy.fetchRows() may still block for as long as conf.read_request_timeout_in_ms, though the speculative retry did fire correctly after the Cassandra node 4 was killed.&lt;/p&gt;

&lt;p&gt;Take the speculative configuration of &apos;PERCENTILE&apos; / &apos;CUSTOM&apos; as example, after the Cassandra node 4 was killed, SpeculativeReadExecutor.speculate() would block for responses. If timed out, it would send out one more read request to an alternative node (from &lt;tt&gt;unfiltered&lt;/tt&gt;) and increment the speculativeRetry counter. This part should work.&lt;/p&gt;

&lt;p&gt;However, killing the 4th node would very likely cause inconsistency in the database and this will trigger the DigestMismatchException. In the fetchRows(), when handling DigestMismatchException, it uses handler.endpoints to send out digest mismatch retries and then block for responses. As we know that one of the endpoints was already killed, the handler.get() will block until it is timed out, which is 10 seconds.&lt;/p&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;                catch (DigestMismatchException ex)
                {
                    Tracing.trace(&quot;Digest mismatch: {}&quot;, ex);

                    ...

                    MessageOut&amp;lt;ReadCommand&amp;gt; message = exec.command.createMessage();
                    for (InetAddress endpoint : exec.handler.endpoints)
                    {
                        Tracing.trace(&quot;Enqueuing full data read to {}&quot;, endpoint);
                        MessagingService.instance().sendRR(message, endpoint, repairHandler);
                    }
                }
            }

            ...

            // read the results for the digest mismatch retries
            if (repairResponseHandlers != null)
            {
                for (int i = 0; i &amp;lt; repairCommands.size(); i++)
                {
                    ReadCommand command = repairCommands.get(i);
                    ReadCallback&amp;lt;ReadResponse, Row&amp;gt; handler = repairResponseHandlers.get(i);

                    Row row;
                    try
                    {
                        row = handler.get();
                    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;



&lt;p&gt;&lt;b&gt;Issue 2&lt;/b&gt; - The speculative &apos;ALWAYS&apos; does NOT send out any more read requests. Thus, in face of the failure of node 4, it will not help at all.&lt;/p&gt;

&lt;p&gt;The SpeculateAlwaysExecutor.executeAsync() only sends out handler.endpoints.size() number of read requests and it blocks for the responses to come back. If one of the nodes is killed, say node 4, this speculative retry &apos;ALWAYS&apos; will work the same way as Cassandra 1.2.4, i.e. it will block until timed out, which is 10 seconds.&lt;/p&gt;

&lt;p&gt;&lt;cite&gt;My understanding of this speculative retry &apos;ALWAYS&apos; should ALWAYS send out &quot;handler.endpoints.size() + 1&quot; number of read requests and block for handler.endpoints.size() number of responses&lt;/cite&gt;.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Issue 3&lt;/b&gt; - Since the ReadRepairDecison is determined by a Random() number, this speculative retry may not work as the ReadRepairDecision may be &lt;cite&gt;ReadRepairDecision.GLOBAL&lt;/cite&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Issue 4&lt;/b&gt; - For the ReadExecutor(s), the &lt;tt&gt;this.unfiltered&lt;/tt&gt; and &lt;tt&gt;this.endpoints&lt;/tt&gt; may not consistent. Thus, using &lt;tt&gt;this.unfiltered&lt;/tt&gt; and &lt;tt&gt;this.endpoints&lt;/tt&gt; for speculative retry may cause unexpected results. This is especially true when the Consistency Level is &lt;tt&gt;LOCAL_QUARUM&lt;/tt&gt; and the ReadRepairDecision is &lt;tt&gt;DC_LOCAL&lt;/tt&gt;.&lt;/p&gt;


</comment>
                            <comment id="13776807" author="iamaleksey" created="Tue, 24 Sep 2013 21:58:37 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lizou&quot; class=&quot;user-hover&quot; rel=&quot;lizou&quot;&gt;lizou&lt;/a&gt;. Yeah, I&apos;ve fixed most of these already (rewritten most of the ARE code, actually). Specifically issues 2,3,4. Will look into 1 too.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="13777059" author="iamaleksey" created="Wed, 25 Sep 2013 01:51:46 +0000"  >&lt;p&gt;Attaching 5932.txt that will hopefully fix this (&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enigmacurry&quot; class=&quot;user-hover&quot; rel=&quot;enigmacurry&quot;&gt;enigmacurry&lt;/a&gt; could you run the tests again, please, with the patch applied?)&lt;/p&gt;

&lt;p&gt;1. As noted by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lizou&quot; class=&quot;user-hover&quot; rel=&quot;lizou&quot;&gt;lizou&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kohlisankalp&quot; class=&quot;user-hover&quot; rel=&quot;kohlisankalp&quot;&gt;kohlisankalp&lt;/a&gt;, ALWAYS wasn&apos;t making an extra request, it was making an extra data request at the expense of one digest request. Fixed.&lt;/p&gt;

&lt;p&gt;2. SpecRetry wasn&apos;t working correctly with RRD.DC_LOCAL, as noted by @lizou, because the two lists will be in different order, and a retry might be sent to a node that already had a request sent to it. (Please note that LOCAL_QUORUM here does not affect anything - CL.filterForQuery() sorts in place, so the two lists would be in the same order, everything was working correct). RRD.DC_LOCAL handling was a legit issue though. Fixed.&lt;/p&gt;

&lt;p&gt;3. SpecRetry w/ RRD.GLOBAL is a noop, you can&apos;t speculate if you contact all the replicas in the first place. This is normal.&lt;/p&gt;

&lt;p&gt;4. The DME issue is semi-legit. Killing a node shouldn&apos;t trigger DME or increase the likelihood of DME happening. &lt;b&gt;HOWEVER&lt;/b&gt; when shooting requests for repair, we were not considering the case where one of the replies satisfying the original CL came from a SpecRetry attempt. The patch includes the extra replica in repair commands if SpecRetry had been triggered by the original request.&lt;/p&gt;


&lt;p&gt;5. SP.getRangeSlice() is not SpectRetry-aware as of now. I don&apos;t know if this is an omission or by design, but for now, please don&apos;t include that in the benchmarks, since it would only be misleading. &lt;/p&gt;</comment>
                            <comment id="13777682" author="jbellis" created="Wed, 25 Sep 2013 16:07:35 +0000"  >&lt;p&gt;Pushed some OCD of my own to &lt;a href=&quot;https://github.com/jbellis/cassandra/commits/5932&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/jbellis/cassandra/commits/5932&lt;/a&gt; on top of this.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;ALWAYS wasn&apos;t making an extra request, it was making an extra data request at the expense of one digest request&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not sure what the distinction is here.  Do you mean that if we weren&apos;t read-repairing, there would be no extra data request at all?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;SpecRetry w/ RRD.GLOBAL is a noop, you can&apos;t speculate if you contact all the replicas in the first place.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I dunno, I think we should turn a digest into a data for redundancy the way ALWAYS used to.&lt;/p&gt;</comment>
                            <comment id="13777749" author="iamaleksey" created="Wed, 25 Sep 2013 17:02:13 +0000"  >&lt;p&gt;Pushed even more OCD to &lt;a href=&quot;https://github.com/iamaleksey/cassandra/commits/5932&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/iamaleksey/cassandra/commits/5932&lt;/a&gt; on top of yours.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m not sure what the distinction is here. Do you mean that if we weren&apos;t read-repairing, there would be no extra data request at all?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Instead of making, for example 1 data request + 2 digest requests, ALWAYS was making 2 data requests + 1 digest request, instead of making 2 data requests + 2 digest requests, not really helping to satisfy the CL in case of node&apos;s failure.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I dunno, I think we should turn a digest into a data for redundancy the way ALWAYS used to.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Maybe.&lt;/p&gt;</comment>
                            <comment id="13778205" author="iamaleksey" created="Wed, 25 Sep 2013 23:03:45 +0000"  >&lt;p&gt;Force-pushed the &apos;final&apos; version to &lt;a href=&quot;https://github.com/iamaleksey/cassandra/commits/5932&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/iamaleksey/cassandra/commits/5932&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Among other things, properly handles RRD.GLOBAL and RRD.DC_LOCAL in 1-DC scenario.&lt;/p&gt;</comment>
                            <comment id="13779023" author="jbellis" created="Thu, 26 Sep 2013 17:54:24 +0000"  >&lt;p&gt;Pushed one more set of changes to mine, not forced: &lt;a href=&quot;https://github.com/jbellis/cassandra/commits/5932&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/jbellis/cassandra/commits/5932&lt;/a&gt;.  Goal is to make SRE less fragile when doing RR.&lt;/p&gt;</comment>
                            <comment id="13779192" author="iamaleksey" created="Thu, 26 Sep 2013 20:30:52 +0000"  >&lt;p&gt;+1, I&apos;m out of OCD juice.&lt;/p&gt;</comment>
                            <comment id="13779202" author="lizou" created="Thu, 26 Sep 2013 20:43:02 +0000"  >&lt;p&gt;Hello &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iamaleksey&quot; class=&quot;user-hover&quot; rel=&quot;iamaleksey&quot;&gt;iamaleksey&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbellis&quot; class=&quot;user-hover&quot; rel=&quot;jbellis&quot;&gt;jbellis&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I took a quick look at the code changes. The new code looks very good to me. But I saw one potential issue in &lt;tt&gt;AlwaysSpeculatingReadExecutor.executeAsync()&lt;/tt&gt;, in which it makes at least &lt;b&gt;two&lt;/b&gt; data / digest requests. This will cause problems for a data center with only one Cassandra server node (e.g. bring up an embedded Cassandra node in JVM for JUnit test) or a deployed production data center of two Cassandra server nodes with one node shut down for maintenance. In the above mentioned two cases, &lt;tt&gt;AbstractReadExecutor.getReadExecutor()&lt;/tt&gt; will return the &lt;tt&gt;AlwaysSpeculatingReadExecutor&lt;/tt&gt; as condition &lt;tt&gt;(targetReplicas.size() == allReplicas.size())&lt;/tt&gt; is met, though the tables may / may not be configured with &lt;cite&gt;Speculative ALWAYS&lt;/cite&gt;.&lt;/p&gt;

&lt;p&gt;It is true for our legacy products we are considering to deploy each data center with only two Cassandra server nodes with RF = 2 and CL = 1.&lt;/p&gt;</comment>
                            <comment id="13779217" author="jbellis" created="Thu, 26 Sep 2013 20:55:01 +0000"  >&lt;p&gt;The logic looks like this:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Figure out how many replicas we need to contact to satisfy the desired consistencyLevel + Read Repair settings&lt;/li&gt;
	&lt;li&gt;If that ends up being all the replicas, then use ASRE to get some redundancy on the data reads.  This will allow the read to succeed even if a digest for RR times out.  Of course if you are reading at CL.ALL and a replica times out there&apos;s nothing we can do.&lt;/li&gt;
	&lt;li&gt;Otherwise, use SRE and make an &quot;extra&quot; request later, if it looks like one of the minimal set isn&apos;t going to respond in time&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Note that performing extra data requests does not affect handler.blockfor &amp;#8211; just makes it possible for the request to proceed if it gets enough responses back, no matter which replicas they come from.&lt;/p&gt;</comment>
                            <comment id="13779218" author="jbellis" created="Thu, 26 Sep 2013 20:55:41 +0000"  >&lt;p&gt;(Committed after Aleksey&apos;s +1, incidentally.)&lt;/p&gt;</comment>
                            <comment id="13779233" author="lizou" created="Thu, 26 Sep 2013 21:04:25 +0000"  >&lt;p&gt;The logic for &lt;tt&gt;AlwaysSpeculatingReadExecutor&lt;/tt&gt; is good. What I meant in my previous comment is that when &lt;tt&gt;targetReplicas.size() == allReplicas.size()&lt;/tt&gt; and &lt;tt&gt;targetReplicas.size() == 1&lt;/tt&gt;, then &lt;tt&gt;AlwaysSpeculatingReadExecutor.executeAsync()&lt;/tt&gt; will throw an exception as there is only one endpoint in &lt;tt&gt;targetReplicas&lt;/tt&gt;, but it tries to access two endpoints in &lt;tt&gt;targetReplicas&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="13779240" author="jbellis" created="Thu, 26 Sep 2013 21:10:48 +0000"  >&lt;p&gt;I see what you mean.  Fixed in 7a87fc1186f39678382cf9b3e1dd224d9c71aead.&lt;/p&gt;</comment>
                            <comment id="13779994" author="enigmacurry" created="Fri, 27 Sep 2013 14:54:55 +0000"  >&lt;p&gt;The good news is that speculative read has improved across the board.&lt;/p&gt;

&lt;p&gt;However, this new batch of testing introduces some new mysteries.&lt;/p&gt;

&lt;p&gt;Here is all of the runs from 7a87fc1186f39678382cf9b3e1dd224d9c71aead:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12605459/12605459_5933-7a87fc11.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;All of the speculative retry runs are better than with 2.0.0-rc1. However, I can&apos;t explain why sr=NONE did better than ALWAYS and 95percentile. There is no visible indication that a node went down for sr=NONE. I have double checked the logs, and it did, in fact, go down. &lt;/p&gt;

&lt;p&gt;Compare this to the baseline of 1.2.8 and 2.0.0-rc1 (redone last night on same hardware as above):&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12605460/12605460_5933-128_and_200rc1.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;All of these have clear indications of the node going down.&lt;/p&gt;

&lt;p&gt;You can &lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.5933.node_killed.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see all the data here&lt;/a&gt; - you can double click the colored squares to toggle the visibility of the lines, as they do overlap.&lt;/p&gt;

&lt;p&gt;I&apos;ve uploaded logs from all these runs as 5933-logs.tar.gz.&lt;/p&gt;</comment>
                            <comment id="13779997" author="JIRAUSER308715" created="Fri, 27 Sep 2013 15:00:13 +0000"  >&lt;p&gt;Yeah. The graphs for ALWAYS and NONE look swapped from what I would expect.&lt;/p&gt;</comment>
                            <comment id="13779999" author="enigmacurry" created="Fri, 27 Sep 2013 15:02:06 +0000"  >&lt;p&gt;The other thing that I note, is that all of these runs are better than 1.2.8 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/biggrin.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; (further evidence that &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-5933&quot; title=&quot;2.0 read performance is slower than 1.2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-5933&quot;&gt;&lt;del&gt;CASSANDRA-5933&lt;/del&gt;&lt;/a&gt; may be invalid)&lt;/p&gt;</comment>
                            <comment id="13780003" author="jbellis" created="Fri, 27 Sep 2013 15:07:02 +0000"  >&lt;p&gt;Hmm.&lt;/p&gt;

&lt;p&gt;I wonder if it&apos;s just luck of the draw as to which replica dsnitch is preferring.  Here&apos;s a branch to randomize that, per-operation:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/jbellis/cassandra/commits/5932-randomized&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/jbellis/cassandra/commits/5932-randomized&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13780072" author="brandon.williams" created="Fri, 27 Sep 2013 16:28:10 +0000"  >&lt;p&gt;Couldn&apos;t we just do a run with the dsnitch disabled?&lt;/p&gt;</comment>
                            <comment id="13780074" author="jbellis" created="Fri, 27 Sep 2013 16:31:45 +0000"  >&lt;p&gt;That still gives you luck-of-the-draw as to which replica it prefers.  (Unlikely to be evenly distributed.)&lt;/p&gt;</comment>
                            <comment id="13780102" author="enigmacurry" created="Fri, 27 Sep 2013 17:14:29 +0000"  >&lt;p&gt;This looks exactly like what I was expecting:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12605480/12605480_5933-randomized-dsnitch-replica.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.5933.randomized-dsnitch.node_killed.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;data here&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13780113" author="jbellis" created="Fri, 27 Sep 2013 17:29:07 +0000"  >&lt;p&gt;That&apos;s awesome.&lt;/p&gt;

&lt;p&gt;Can you test 90th and 75th percentile too?&lt;/p&gt;</comment>
                            <comment id="13780228" author="enigmacurry" created="Fri, 27 Sep 2013 18:44:44 +0000"  >&lt;p&gt;Seems like it&apos;s quite tunable, but not a lot of difference under 90%:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12605518/12605518_5933-randomized-dsnitch-replica.2.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.5933.randomized-dsnitch.node_killed.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;data here&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13780298" author="jbellis" created="Fri, 27 Sep 2013 19:43:24 +0000"  >&lt;p&gt;Yeah, that makes sense.  70th..95th are all pretty damn close to median still.&lt;/p&gt;

&lt;p&gt;What I&apos;d like to do is get close to the 10ms performance hit (~none) as a percentile, and make that default in 2.1.  Try 99th and 99.9th?&lt;/p&gt;</comment>
                            <comment id="13780307" author="jbellis" created="Fri, 27 Sep 2013 19:54:22 +0000"  >&lt;p&gt;Also, did that stress patch work to get you failed request counts?  Would be good to get that too if we can show that even 10ms keeps requests from failing entirely.&lt;/p&gt;</comment>
                            <comment id="13780413" author="enigmacurry" created="Fri, 27 Sep 2013 21:14:45 +0000"  >&lt;p&gt;Here&apos;s 99th and 99.9th percentiles:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12605563/12605563_5933-randomized-dsnitch-replica.3.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;I&apos;ll look at that stress patch again, I seem to recall it not making a lot of sense to me when I last tried it, but will give it another go.&lt;/p&gt;</comment>
                            <comment id="13780457" author="jbellis" created="Fri, 27 Sep 2013 21:37:35 +0000"  >&lt;p&gt;Starting to think we still have a bug.  99.9 should be doing less retries than 10ms but the graph shows it doing more.&lt;/p&gt;</comment>
                            <comment id="13780473" author="lizou" created="Fri, 27 Sep 2013 21:47:54 +0000"  >&lt;p&gt;I did some more code reading and noticed some potential issues and possible improvement. I&apos;ve got to run now. I will get back to you guys Monday morning.&lt;/p&gt;

&lt;p&gt;My guess is that the &lt;cite&gt;Speculative NONE&lt;/cite&gt; is hit by the initial request reading path which is successfully resolved by the &lt;b&gt;Speculative Retry&lt;/b&gt;. The observed throughput performance hit when Speculative Retry is enabled is caused by the ReadRepair path which has some coding / design issues. I will talk to you next Monday.&lt;/p&gt;</comment>
                            <comment id="13780475" author="jbellis" created="Fri, 27 Sep 2013 21:49:13 +0000"  >&lt;p&gt;Maybe the problem is that we&apos;re using CF-level latency instead of StorageProxy.&lt;/p&gt;

&lt;p&gt;What does cfhistograms give for read latency?&lt;/p&gt;</comment>
                            <comment id="13780524" author="jbellis" created="Fri, 27 Sep 2013 22:40:34 +0000"  >&lt;p&gt;Pretty sure that&apos;s our smoking gun.  Pushed a commit to the -randomized branch that adds coordinator-level, per-cf latency tracking and uses that instead.&lt;/p&gt;

&lt;p&gt;Can you repeat the last test with that?  (Maybe throw in ALL as well if you&apos;re feeling optimistic that we&apos;ll have a measurable difference between ALL and 90%. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13781421" author="enigmacurry" created="Sun, 29 Sep 2013 16:15:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbellis&quot; class=&quot;user-hover&quot; rel=&quot;jbellis&quot;&gt;jbellis&lt;/a&gt; Here&apos;s your two runs:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.5933.dea27f84f40.node_killed.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dea27f84f40&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.5933.ded39c7e1c2fa.node_killed.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;ded39c7e1c2fa&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Logs for the second run are attached as 5932.ded39c7e1c2fa.logs.tar.gz&lt;/p&gt;</comment>
                            <comment id="13781459" author="jbellis" created="Sun, 29 Sep 2013 17:48:46 +0000"  >&lt;p&gt;The code to convert 99 into 0.99 was buggy and was actually converting to 0.0099.  Fix pushed, can you try it again?&lt;/p&gt;</comment>
                            <comment id="13781506" author="enigmacurry" created="Sun, 29 Sep 2013 21:26:45 +0000"  >&lt;p&gt;BINGO!&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12605828/12605828_5932-6692c50412ef7d.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.5933.6692c50412ef7d.node_killed.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;data here&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13781557" author="hubez" created="Mon, 30 Sep 2013 01:25:25 +0000"  >&lt;p&gt;Definitely the best results seen so far! Nice work!&lt;/p&gt;

&lt;p&gt;In my mind, during the transition period right after the killing of the node, I expected &quot;ALWAYS&quot; to have negligible impact, or at least the smallest impact of all of the other values. However, red (90%), and purple (75%) is having a smaller impact. Seems fishy. Do I misunderstand the intention of the &quot;ALWAYS&quot; setting?&lt;/p&gt;

&lt;p&gt;(Edited to clarify the period I&apos;m talking about.)&lt;/p&gt;</comment>
                            <comment id="13781587" author="jbellis" created="Mon, 30 Sep 2013 03:10:59 +0000"  >&lt;p&gt;It looks to me like 75/90/Always are about the same, with Always dropping from a lower baseline.  Which makes sense; it&apos;s still doing a lot of unnecessary work compared to the others.&lt;/p&gt;</comment>
                            <comment id="13781814" author="jbellis" created="Mon, 30 Sep 2013 13:49:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enigmacurry&quot; class=&quot;user-hover&quot; rel=&quot;enigmacurry&quot;&gt;enigmacurry&lt;/a&gt;, can you also re-test the uncapped compaction scenario with the same set of retry settings?&lt;/p&gt;</comment>
                            <comment id="13782027" author="lizou" created="Mon, 30 Sep 2013 17:24:17 +0000"  >&lt;p&gt;Hello &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iamaleksey&quot; class=&quot;user-hover&quot; rel=&quot;iamaleksey&quot;&gt;iamaleksey&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbellis&quot; class=&quot;user-hover&quot; rel=&quot;jbellis&quot;&gt;jbellis&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;It appears to me that the testing results have suggested that the &quot;&lt;em&gt;data read + speculative retry&lt;/em&gt;&quot; path work as expected. This &quot;&lt;em&gt;data read + speculative retry&lt;/em&gt;&quot; path has greatly minimized the throughput impact caused by the failure of one of Cassandra server nodes.&lt;/p&gt;

&lt;p&gt;The observed small degradation of throughput performance when &lt;em&gt;speculative retry&lt;/em&gt; is enabled is very likely to be caused by the &quot;&lt;b&gt;&lt;em&gt;read repair&lt;/em&gt;&lt;/b&gt;&quot; path. I did the code reading of this path last Friday and noticed some design / coding issues. I would like to discuss them with you.&lt;/p&gt;

&lt;p&gt;Please note that my code base is still the Cassandra 2.0.0 tarball, not updated with the latest code changes.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Issue 1&lt;/b&gt; &amp;#8211; When handling &lt;tt&gt;DigestMismatchException&lt;/tt&gt; in &lt;tt&gt;StorageProxy.fetchRows()&lt;/tt&gt;, all &lt;em&gt;data read requests&lt;/em&gt; are sent out using &lt;tt&gt;sendRR&lt;/tt&gt; without distinguishing remote nodes from the local node.&lt;/p&gt;

&lt;p&gt;Will this cause an issue, as &lt;tt&gt;MessagingService.instance().sendRR()&lt;/tt&gt; will send out enqueued messages for a specified remote node via its pre-established TCP socket connection. For local node, this should be done via &lt;tt&gt;LocalReadRunnable&lt;/tt&gt;, i.e. &lt;tt&gt;StageManager.getStage(Stage.READ).execute(new LocalReadRunnable(command, handler))&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;If this may cause an issue, the following wait may block.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;            // read the results for the digest mismatch retries
            if (repairResponseHandlers != null)
            {
                for (int i = 0; i &amp;lt; repairCommands.size(); i++)
                {
                    ReadCommand command = repairCommands.get(i);
                    ReadCallback&amp;lt;ReadResponse, Row&amp;gt; handler = repairResponseHandlers.get(i);

                    Row row;
                    try
                    {
                        row = handler.get();
                    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For two reasons.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The data read request for local node may never sent out&lt;/li&gt;
	&lt;li&gt;As one of the nodes is down (which triggered the Speculative Retry) will cause one missing response.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;b&gt;If missing two responses, this will block for 10 seconds&lt;/b&gt;. &lt;/p&gt;

&lt;p&gt;&lt;b&gt;Issue 2&lt;/b&gt; &amp;#8211; For &lt;em&gt;data repair&lt;/em&gt;, &lt;tt&gt;RowDataResolver.resolve()&lt;/tt&gt; has a similar issue as it calls  &lt;tt&gt;scheduleRepairs()&lt;/tt&gt; to send out  messages using sendRR() without distinguishing remote nodes from the local node.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Issue 3&lt;/b&gt; &amp;#8211; When handling &lt;em&gt;data repair&lt;/em&gt;, &lt;tt&gt;StorageProxy.fetchRows()&lt;/tt&gt; blocks waiting for acks to all of &lt;tt&gt;data repair&lt;/tt&gt; requests sent out using sendRR(). This may cause the thread to block.&lt;/p&gt;

&lt;p&gt;For &lt;em&gt;data repair&lt;/em&gt; path, &lt;b&gt;data requests&lt;/b&gt; are sent out and then compare / merge the received responses; send out the merged / diff version and then block for acks.&lt;/p&gt;

&lt;p&gt;How do we handle the case for &lt;em&gt;local node&lt;/em&gt;? Does the sendRR() and the corresponding receive part can handle the case for local node? If not, then this may block for 10 seconds.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;            if (repairResponseHandlers != null)
            {
                for (int i = 0; i &amp;lt; repairCommands.size(); i++)
                {
                    ReadCommand command = repairCommands.get(i);
                    ReadCallback&amp;lt;ReadResponse, Row&amp;gt; handler = repairResponseHandlers.get(i);

                    Row row;
                    try
                    {
                        row = handler.get();
                    }
                    catch (DigestMismatchException e)
                    ...
                    RowDataResolver resolver = (RowDataResolver)handler.resolver;
                    try
                    {
                        // wait for the repair writes to be acknowledged, to minimize impact on any replica that&apos;s
                        // behind on writes in case the out-of-sync row is read multiple times in quick succession
                        FBUtilities.waitOnFutures(resolver.repairResults, DatabaseDescriptor.getWriteRpcTimeout());
                    }
                    catch (TimeoutException e)
                    {
                        Tracing.trace(&quot;Timed out on digest mismatch retries&quot;);
                        int blockFor = consistency_level.blockFor(Keyspace.open(command.getKeyspace()));
                        throw new ReadTimeoutException(consistency_level, blockFor, blockFor, true);
                    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;b&gt;Question for waiting for the ack&lt;/b&gt; &amp;#8211; Do we really need to wait for the ack?&lt;/p&gt;

&lt;p&gt;We should assume the best effort approach, i.e. do the data repair and then return. No need to block waiting for the acks for confirmation.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Question for the Randomized approach&lt;/b&gt; &amp;#8211; Since the end points are randomized, the first node in the list is no likely the local node. This may cause a higher possibility of data repair.&lt;/p&gt;

&lt;p&gt;In the &lt;b&gt;Randomized Approach&lt;/b&gt;, the end points are reshuffled. Then, the first node in the list used for &lt;em&gt;data read request&lt;/em&gt; is not likely the local node. If this node happens to be the &lt;b&gt;DOWN&lt;/b&gt; node, then, we end with all digest responses without the data, which will block and eventually timed out.&lt;/p&gt;
</comment>
                            <comment id="13782218" author="iamaleksey" created="Mon, 30 Sep 2013 20:46:05 +0000"  >&lt;p&gt;First, let me thank you for your continued digging. Some of it helped. That said, you should probably look at the current cassandra-2.0 branch, and not the 2.0.0 tarball/branches here in the comments.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Issue 1 &#8211; When handling DigestMismatchException in StorageProxy.fetchRows(), all data read requests are sent out using sendRR without distinguishing remote nodes from the local node.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is not an issue, and it&apos;s not spec retry related. Using LRR for local read requests is merely an optimisation - there is nothing wrong with sendRR (not that it isn&apos;t worth optimising here - just noting that it&apos;s not an issue). This is also the answer to &quot;How do we handle the case for local node? Does the sendRR() and the corresponding receive part can handle the case for local node? If not, then this may block for 10 seconds.&quot; Same goes for Issue 2 and Issue 3.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The data read request for local node may never sent out. As one of the nodes is down (which triggered the Speculative Retry) will cause one missing response.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The former is not true, the latter won&apos;t, since the current cassandra-2.0 code will send requests to all the contacted replicas. So if a node triggered spec retry, that extra speculated replica will get the request as well, and we can still satisfy the CL.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;                    for (InetAddress endpoint : exec.getContactedReplicas())
                    {
                        Tracing.trace(&quot;Enqueuing full data read to {}&quot;, endpoint);
                        MessagingService.instance().sendRR(message, endpoint, repairHandler);
                    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;blockquote&gt;&lt;p&gt;Question for the Randomized approach &#8211; Since the end points are randomized, the first node in the list is no likely the local node. This may cause a higher possibility of data repair.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t see how the possibility of data repair is correlated with the locality of a target node, but, it doesn&apos;t matter. The &apos;randomised approach&apos; was an experiment, it wasn&apos;t committed as part of the fix. See the latest cassandra-2.0 branch code.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In the Randomized Approach, the end points are reshuffled. Then, the first node in the list used for data read request is not likely the local node. If this node happens to be the DOWN node, then, we end with all digest responses without the data, which will block and eventually timed out.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;See the above reply.&lt;/p&gt;

&lt;p&gt;TLDR: None of these seem to be issues, but we could optimise RR to use LRR for local reads to get slightly better performance for local requests (and to be consistent with the regular reads code).&lt;/p&gt;</comment>
                            <comment id="13782280" author="lizou" created="Mon, 30 Sep 2013 21:32:59 +0000"  >&lt;p&gt;Thanks for the clarification of the sendRR issue.&lt;/p&gt;

&lt;p&gt;Since the Randomized approach is not checked in, let us skip over it.&lt;/p&gt;

&lt;p&gt;For the &lt;em&gt;data repair&lt;/em&gt;, do we need to block waiting for the acks?&lt;/p&gt;</comment>
                            <comment id="13782306" author="iamaleksey" created="Mon, 30 Sep 2013 21:53:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;For the data repair, do we need to block waiting for the acks?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The reasons are listed in the comments, as you&apos;ve seen:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;// wait for the repair writes to be acknowledged, to minimize impact on any replica that&apos;s
// behind on writes in case the out-of-sync row is read multiple times in quick succession
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To reach that goal - yes, it&apos;s necessary. Is that scenario worth optimizing for or should we reconsider? Dunno. We are only writing to the replicas that we got the result from, though, so a known down replica wouldn&apos;t affect it.&lt;/p&gt;
</comment>
                            <comment id="13782317" author="iamaleksey" created="Mon, 30 Sep 2013 22:00:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lizou&quot; class=&quot;user-hover&quot; rel=&quot;lizou&quot;&gt;lizou&lt;/a&gt; see &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-4792&quot; title=&quot;Digest mismatch doesn&amp;#39;t wait for writes as intended&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-4792&quot;&gt;&lt;del&gt;CASSANDRA-4792&lt;/del&gt;&lt;/a&gt; (TLDR: yes)&lt;/p&gt;</comment>
                            <comment id="13783046" author="enigmacurry" created="Tue, 1 Oct 2013 15:15:49 +0000"  >&lt;p&gt;I had to double the test length to get a good compaction graph. I&apos;m not sure why it took so long, it didn&apos;t take as long in the original test.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12606117/12606117_5932.6692c50412ef7d.compaction.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.5933.6692c50412ef7d.compaction.2.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=4&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;data here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iamaleksey&quot; class=&quot;user-hover&quot; rel=&quot;iamaleksey&quot;&gt;iamaleksey&lt;/a&gt; your read_repair 0 / 1 tests are in progress...)&lt;/p&gt;</comment>
                            <comment id="13783292" author="enigmacurry" created="Tue, 1 Oct 2013 20:15:28 +0000"  >&lt;p&gt;Node killed while read_repair_chance=0. I accidentally left the test run to be 60M rows, so I chopped off the uninteresting bit.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12606179/12606179_5932.6692c50412ef7d.rr0.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.5933.6692c50412ef7d.node_killed.rr0.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;data here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(rr=1 is next..)&lt;/p&gt;</comment>
                            <comment id="13783613" author="jbellis" created="Wed, 2 Oct 2013 03:39:23 +0000"  >&lt;p&gt;The throughput is a wash in the compaction scenario, but the 99.9% latency looks a lot better with the retries.&lt;/p&gt;

&lt;p&gt;Any theories on why the percentile settings are posting better latency numbers than ALWAYS though?&lt;/p&gt;</comment>
                            <comment id="13784089" author="lizou" created="Wed, 2 Oct 2013 15:46:48 +0000"  >&lt;p&gt;This testing result is reasonable and what is expected.&lt;/p&gt;

&lt;p&gt;For PERCENTILE / CUSTOM configuration, the larger the &lt;tt&gt;cfs.sampleLatencyNanos&lt;/tt&gt; the smaller the throughput impact for normal operations before the outage. However, during the outage period, the situation is reversed, i.e. the smaller &lt;tt&gt;cfs.sampleLatencyNanos&lt;/tt&gt;, the smaller the throughput impact will be, as it times out quicker and triggers the speculative retries.&lt;/p&gt;

&lt;p&gt;For the ALWAYS configuration, as it always sends out one speculative in addition to the usual read requests, the throughput performance should be lower than those of PERCENTILE / CUSTOM for normal operations before the outage. Since it always sends out the speculative retries, the throughput impact during the outage period should be the smallest. The testing result indicates that this is true.&lt;/p&gt;</comment>
                            <comment id="13784094" author="enigmacurry" created="Wed, 2 Oct 2013 15:50:04 +0000"  >&lt;p&gt;With read_repair_chance = 1&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12606380/12606380_5932.6692c50412ef7d.rr1.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ryanmcguire.info/ds/graph/graph.html?stats=stats.5933.6692c50412ef7d.node_killed.rr1.json&amp;amp;metric=interval_op_rate&amp;amp;operation=stress-read&amp;amp;smoothing=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;data here&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13786585" author="lizou" created="Fri, 4 Oct 2013 20:34:46 +0000"  >&lt;p&gt;Have done some testing using today&apos;s trunk. Have observed following issues.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Issue 1&lt;/b&gt; &amp;#8211; The first method &lt;tt&gt;MessagingService.addCallback()&lt;/tt&gt; (i.e. without the ConsistencyLevel argument) asserts.&lt;/p&gt;

&lt;p&gt;Commenting out the assert statement seems to work. But the Cassandra servers themselves will produce 10-second outage (i.e. zero transactions from the client point of view) periodically.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Issue 2&lt;/b&gt; &amp;#8211; The Speculative Retry seems stop retrying during the outage window.&lt;/p&gt;

&lt;p&gt;During the outage window triggered either by killing one of Cassandra nodes or produced by Cassandra servers themselves, the JConsole shows that the JMX stats, SpeculativeRetry counter stops incrementing until the gossip figures out the outage issue.&lt;/p&gt;

&lt;p&gt;What is the reason for this? The Speculative Retry is meant to help during the outage period. This observed behavior is consistent with Cassandra 2.0.0-rc2.&lt;/p&gt;</comment>
                            <comment id="13786603" author="jbellis" created="Fri, 4 Oct 2013 20:47:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;MessagingService.addCallback&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Are you sure you have the latest code?  The only invocations of addCallback in 2.0/trunk include the consistencylevel argument as of late last night.&lt;/p&gt;</comment>
                            <comment id="13786613" author="lizou" created="Fri, 4 Oct 2013 20:58:05 +0000"  >&lt;p&gt;The trunk load I used for testing was pulled this noon. It has two addCallback() methods. One of them (i.e. without the ConsistencyLevel) asserts. &lt;/p&gt;

&lt;p&gt;I checked the MessagingService.java, there are two addCallback() methods.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The one without ConsistencyLevel is called by sendRR()&lt;/li&gt;
	&lt;li&gt;The one with ConsistencyLevel is called by sendMessageToNonLocalDC()&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13786622" author="lizou" created="Fri, 4 Oct 2013 21:06:48 +0000"  >&lt;p&gt;As for yesterday&apos;s trunk load, there were two addCallback() methods. But the one with ConsistencyLevel was not called by anyone. The one without ConsistencyLevel asserts.&lt;/p&gt;</comment>
                            <comment id="13786643" author="jbellis" created="Fri, 4 Oct 2013 21:27:15 +0000"  >&lt;p&gt;Are you doing counter updates?  That&apos;s the only use of sendRR for updates I see.&lt;/p&gt;

&lt;p&gt;Can you post the stack trace of the assertion error you&apos;re getting?&lt;/p&gt;</comment>
                            <comment id="13786653" author="jbellis" created="Fri, 4 Oct 2013 21:37:12 +0000"  >&lt;p&gt;(Pushed fix for mutateCounter in 3da10f469d6a328bad209d723a5997c932284344.)&lt;/p&gt;</comment>
                            <comment id="13788437" author="lizou" created="Mon, 7 Oct 2013 18:56:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbellis&quot; class=&quot;user-hover&quot; rel=&quot;jbellis&quot;&gt;jbellis&lt;/a&gt;, this morning&apos;s trunk load has a slightly different symptom, and is even more serious than last Friday&apos;s load, as this time just commenting out the assert statement in the &lt;tt&gt;MessagingService.addCallback()&lt;/tt&gt; will not help.&lt;/p&gt;

&lt;p&gt;I copy the &lt;tt&gt;/var/log/cassandra/system.log&lt;/tt&gt; exception errors below.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR [Thrift:12] 2013-10-07 14:42:39,396 Caller+0       at org.apache.cassandra.service.CassandraDaemon$2.uncaughtException(CassandraDaemon.java:134)
 - Exception in thread Thread[Thrift:12,5,main]
java.lang.AssertionError: null
        at org.apache.cassandra.net.MessagingService.addCallback(MessagingService.java:543) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.net.MessagingService.sendRR(MessagingService.java:591) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.net.MessagingService.sendRR(MessagingService.java:571) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.service.StorageProxy.sendToHintedEndpoints(StorageProxy.java:869) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.service.StorageProxy$2.apply(StorageProxy.java:123) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.service.StorageProxy.performWrite(StorageProxy.java:739) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.service.StorageProxy.mutate(StorageProxy.java:511) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.service.StorageProxy.mutateWithTriggers(StorageProxy.java:581) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.cql3.statements.ModificationStatement.executeWithoutCondition(ModificationStatement.java:379) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.cql3.statements.ModificationStatement.execute(ModificationStatement.java:363) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:126) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:267) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.thrift.CassandraServer.execute_prepared_cql3_query(CassandraServer.java:2061) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.thrift.Cassandra$Processor$execute_prepared_cql3_query.getResult(Cassandra.java:4502) ~[apache-cassandra-thrift-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.cassandra.thrift.Cassandra$Processor$execute_prepared_cql3_query.getResult(Cassandra.java:4486) ~[apache-cassandra-thrift-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.9.1.jar:0.9.1]
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.9.1.jar:0.9.1]
        at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:194) ~[apache-cassandra-2.1-SNAPSHOT.jar:2.1-SNAPSHOT]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_25]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_25]
        at java.lang.Thread.run(Thread.java:724) ~[na:1.7.0_25]

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="13788485" author="jbellis" created="Mon, 7 Oct 2013 19:35:58 +0000"  >&lt;p&gt;There&apos;s a ticket open for trunk over at &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6154&quot; title=&quot;Inserts are blocked in 2.1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-6154&quot;&gt;&lt;del&gt;CASSANDRA-6154&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13788613" author="lizou" created="Mon, 7 Oct 2013 21:40:18 +0000"  >&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;As this ticket is already fixed in 2.0.2, where can I get the 2.0.2 source code?&lt;/p&gt;

&lt;p&gt;Currently, my &quot;git tag&quot; only shows up to 2.0.1.&lt;/p&gt;</comment>
                            <comment id="13788622" author="jbellis" created="Mon, 7 Oct 2013 21:48:38 +0000"  >&lt;p&gt;the cassandra-2.0 branch is what will become 2.0.2&lt;/p&gt;</comment>
                            <comment id="13788654" author="lizou" created="Mon, 7 Oct 2013 22:34:31 +0000"  >&lt;p&gt;I even cannot see the cassandra-2.0 branch.&lt;br/&gt;
My &quot;git tag&quot; gives a list including following branches.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ git tag
1.2.8
1.2.8-tentative
cassandra-0.3.0-final
cassandra-0.3.0-rc1
cassandra-0.3.0-rc2
...
cassandra-1.2.4
cassandra-1.2.5
cassandra-1.2.6
cassandra-1.2.7
cassandra-1.2.8
cassandra-1.2.9
cassandra-2.0.0
cassandra-2.0.0-beta1
cassandra-2.0.0-beta2
cassandra-2.0.0-rc1
cassandra-2.0.0-rc2
cassandra-2.0.1
drivers
list
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There is no cassandra-2.0 branch. Where can I find it?&lt;/p&gt;</comment>
                            <comment id="13788674" author="jbellis" created="Mon, 7 Oct 2013 23:01:59 +0000"  >&lt;p&gt;Under &lt;tt&gt;git branch&lt;/tt&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12608763">CASSANDRA-4705</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12605828" name="5932-6692c50412ef7d.png" size="78070" author="enigmacurry" created="Sun, 29 Sep 2013 21:27:01 +0000"/>
                            <attachment id="12606117" name="5932.6692c50412ef7d.compaction.png" size="67325" author="enigmacurry" created="Tue, 1 Oct 2013 15:14:54 +0000"/>
                            <attachment id="12606179" name="5932.6692c50412ef7d.rr0.png" size="100919" author="enigmacurry" created="Tue, 1 Oct 2013 20:15:47 +0000"/>
                            <attachment id="12606380" name="5932.6692c50412ef7d.rr1.png" size="102276" author="enigmacurry" created="Wed, 2 Oct 2013 15:49:41 +0000"/>
                            <attachment id="12605805" name="5932.ded39c7e1c2fa.logs.tar.gz" size="548810" author="enigmacurry" created="Sun, 29 Sep 2013 16:16:17 +0000"/>
                            <attachment id="12604942" name="5932.txt" size="23512" author="aleksey" created="Wed, 25 Sep 2013 01:36:39 +0000"/>
                            <attachment id="12605460" name="5933-128_and_200rc1.png" size="78453" author="enigmacurry" created="Fri, 27 Sep 2013 14:55:29 +0000"/>
                            <attachment id="12605459" name="5933-7a87fc11.png" size="85031" author="enigmacurry" created="Fri, 27 Sep 2013 14:55:29 +0000"/>
                            <attachment id="12605461" name="5933-logs.tar.gz" size="578439" author="enigmacurry" created="Fri, 27 Sep 2013 14:55:29 +0000"/>
                            <attachment id="12605518" name="5933-randomized-dsnitch-replica.2.png" size="80992" author="enigmacurry" created="Fri, 27 Sep 2013 18:42:47 +0000"/>
                            <attachment id="12605563" name="5933-randomized-dsnitch-replica.3.png" size="69408" author="enigmacurry" created="Fri, 27 Sep 2013 21:13:28 +0000"/>
                            <attachment id="12605480" name="5933-randomized-dsnitch-replica.png" size="68945" author="enigmacurry" created="Fri, 27 Sep 2013 17:14:56 +0000"/>
                            <attachment id="12599771" name="compaction-makes-slow-stats.png" size="32834" author="enigmacurry" created="Sat, 24 Aug 2013 01:04:03 +0000"/>
                            <attachment id="12599762" name="compaction-makes-slow.png" size="50839" author="enigmacurry" created="Sat, 24 Aug 2013 00:51:35 +0000"/>
                            <attachment id="12599770" name="eager-read-looks-promising-stats.png" size="32002" author="enigmacurry" created="Sat, 24 Aug 2013 01:04:03 +0000"/>
                            <attachment id="12599761" name="eager-read-looks-promising.png" size="54352" author="enigmacurry" created="Sat, 24 Aug 2013 00:51:35 +0000"/>
                            <attachment id="12599769" name="eager-read-not-consistent-stats.png" size="31766" author="enigmacurry" created="Sat, 24 Aug 2013 01:04:03 +0000"/>
                            <attachment id="12599760" name="eager-read-not-consistent.png" size="62121" author="enigmacurry" created="Sat, 24 Aug 2013 00:51:35 +0000"/>
                            <attachment id="12599763" name="node-down-increase-performance.png" size="32259" author="enigmacurry" created="Sat, 24 Aug 2013 00:51:35 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>19.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[aleksey]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345293</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 7 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1njlz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345594</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Reproduced In</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12324787">2.0 rc1</customfieldvalue>
    <customfieldvalue id="12324946">2.0 rc2</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>jbellis</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[jbellis]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>