<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:54:40 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-9549] Memory leak in Ref.GlobalState due to pathological ConcurrentLinkedQueue.remove behaviour</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-9549</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;We have been experiencing a severe memory leak with Cassandra 2.1.5 that, over the period of a couple of days, eventually consumes all of the available JVM heap space, putting the JVM into GC hell where it keeps trying CMS collection but can&apos;t free up any heap space. This pattern happens for every node in our cluster and is requiring rolling cassandra restarts just to keep the cluster running. We have upgraded the cluster per Datastax docs from the 2.0 branch a couple of months ago and have been using the data from this cluster for more than a year without problem.&lt;/p&gt;

&lt;p&gt;As the heap fills up with non-GC-able objects, the CPU/OS load average grows along with it. Heap dumps reveal an increasing number of java.util.concurrent.ConcurrentLinkedQueue$Node objects. We took heap dumps over a 2 day period, and watched the number of Node objects go from 4M, to 19M, to 36M, and eventually about 65M objects before the node stops responding. The screen capture of our heap dump is from the 19M measurement.&lt;/p&gt;

&lt;p&gt;Load on the cluster is minimal. We can see this effect even with only a handful of writes per second. (See attachments for Opscenter snapshots during very light loads and heavier loads). Even with only 5 reads a sec we see this behavior.&lt;/p&gt;

&lt;p&gt;Log files show repeated errors in Ref.java:181 and Ref.java:279 and &quot;LEAK detected&quot; messages:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR [CompactionExecutor:557] 2015-06-01 18:27:36,978 Ref.java:279 - Error when closing &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.cassandra.io.sstable.SSTableReader$InstanceTidier@1302301946:/data1/data/ourtablegoeshere-ka-1150
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@32680b31 rejected from org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor@573464d6[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 1644]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR [Reference-Reaper:1] 2015-06-01 18:27:37,083 Ref.java:181 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@74b5df92) to &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.cassandra.io.sstable.SSTableReader$DescriptorTypeTidy@2054303604:/data2/data/ourtablegoeshere-ka-1151 was not released before the reference was garbage collected
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This might be related to &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8723&quot; title=&quot;Cassandra 2.1.2 Memory issue - java process memory usage continuously increases until process is killed by OOM killer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8723&quot;&gt;&lt;del&gt;CASSANDRA-8723&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</description>
                <environment>&lt;p&gt;Cassandra 2.1.5. 9 node cluster in EC2 (m1.large nodes, 2 cores 7.5G memory, 800G platter for cassandra data, root partition and commit log are on SSD EBS with sufficient IOPS), 3 nodes/availablity zone, 1 replica/zone&lt;/p&gt;

&lt;p&gt;JVM: /usr/java/jdk1.8.0_40/jre/bin/java &lt;br/&gt;
JVM Flags besides CP: -ea -javaagent:/usr/share/cassandra/lib/jamm-0.3.0.jar -XX:+CMSClassUnloadingEnabled -XX:+UseThreadPriorities -XX:ThreadPriorityPolicy=42 -Xms2G -Xmx2G -Xmn200M -XX:+HeapDumpOnOutOfMemoryError -Xss256k -XX:StringTableSize=1000003 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1 -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+UseTLAB -XX:CompileCommandFile=/etc/cassandra/conf/hotspot_compiler -XX:CMSWaitDuration=10000 -XX:+CMSParallelInitialMarkEnabled -XX:+CMSEdenChunksRecordAlways -XX:CMSWaitDuration=10000 -XX:+UseCondCardMark -Djava.net.preferIPv4Stack=true -Dcom.sun.management.jmxremote.port=7199 -Dcom.sun.management.jmxremote.rmi.port=7199 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dlogback.configurationFile=logback.xml -Dcassandra.logdir=/var/log/cassandra -Dcassandra.storagedir= -Dcassandra-pidfile=/var/run/cassandra/cassandra.pid &lt;/p&gt;

&lt;p&gt;Kernel: Linux 2.6.32-504.16.2.el6.x86_64 #1 SMP x86_64 x86_64 x86_64 GNU/Linux&lt;/p&gt;
</environment>
        <key id="12835471">CASSANDRA-9549</key>
            <summary>Memory leak in Ref.GlobalState due to pathological ConcurrentLinkedQueue.remove behaviour</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10000" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Urgent</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="benedict">Benedict Elliott Smith</assignee>
                                    <reporter username="ivar.thorson">Ivar Thorson</reporter>
                        <labels>
                    </labels>
                <created>Thu, 4 Jun 2015 17:41:53 +0000</created>
                <updated>Wed, 15 Oct 2025 09:49:04 +0000</updated>
                            <resolved>Wed, 17 Jun 2015 16:15:15 +0000</resolved>
                                        <fixVersion>2.1.7</fixVersion>
                                        <due></due>
                            <votes>2</votes>
                                    <watches>23</watches>
                                                                                                                <comments>
                            <comment id="14573400" author="benedict" created="Thu, 4 Jun 2015 19:02:40 +0000"  >&lt;p&gt;Looks like you&apos;ve called drain(), but the server is still up and trying to do work...&lt;/p&gt;

&lt;p&gt;A full system log (back until node startup) could help, but this situation should be pretty atypical. Restarting the node should be enough to correct it.&lt;/p&gt;</comment>
                            <comment id="14573404" author="philipthompson" created="Thu, 4 Jun 2015 19:05:56 +0000"  >&lt;p&gt;Original description says it&apos;s happening for every node in the cluster, and that they&apos;ve all been restarted.&lt;/p&gt;</comment>
                            <comment id="14573456" author="benedict" created="Thu, 4 Jun 2015 19:43:17 +0000"  >&lt;p&gt;It&apos;s possible there is a script in their envrionment running periodically, asking the servers to drain. There are really very few ways for that executor service to be shutdown (assuming it&apos;s the executor submitted to inside of the method throwing the REE; it&apos;s hard to say with absolute certainty because the stack trace has been compressed due to the frequency of the error generation): the shutdown hook indicating the VM is terminating, or the drain() command.&lt;/p&gt;

&lt;p&gt;As I said, though: more info, means we can say with greater certainty. That full log history since restart would be a great start. A thread dump would be the natural follow on if that was not sufficiently helpful.&lt;/p&gt;</comment>
                            <comment id="14573492" author="ivar.thorson" created="Thu, 4 Jun 2015 20:05:59 +0000"  >&lt;p&gt;Our sysadmin has been doing drain just before restarting, but it is not periodic. The only periodic crontab command is a weekly repair of each node, done in a rolling fashion. We looked for correlation with this memory leak problem and found none. Is there something else that would cause this drain-like behavior?&lt;/p&gt;</comment>
                            <comment id="14573506" author="benedict" created="Thu, 4 Jun 2015 20:23:34 +0000"  >&lt;p&gt;Without the log file there is very little more I can tell you. The only two places the ES is explicitly shutdown are:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;a drain; and&lt;/li&gt;
	&lt;li&gt;the VM executing its shutdown hooks&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;The only two places a drain occurs are:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;via NodeTool drain&lt;/li&gt;
	&lt;li&gt;receipt of a gossip remove node message (which should, by my understanding, only be triggered by a NodeTool remove command)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;It&apos;s possible something else is awry, but we have very little information to work with.&lt;/p&gt;

&lt;p&gt;Is it possible you are running an embedded cassandra, so that the Cassandra instance restarts without the JVM restarting? Or is it possible you are draining more nodes than you intend during the restart process?&lt;/p&gt;</comment>
                            <comment id="14573513" author="ivar.thorson" created="Thu, 4 Jun 2015 20:24:01 +0000"  >&lt;p&gt;I&apos;ll look at getting the log and thread dump.&lt;/p&gt;

&lt;p&gt;Is this related to changes for &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8707&quot; title=&quot;Move SegmentedFile, IndexSummary and BloomFilter to utilising RefCounted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8707&quot;&gt;&lt;del&gt;CASSANDRA-8707&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="14573528" author="ivar.thorson" created="Thu, 4 Jun 2015 20:37:49 +0000"  >&lt;p&gt;Log file uploaded. We&apos;re running the datastax rpms and restarting with &quot;service cassandra restart&quot;&lt;/p&gt;</comment>
                            <comment id="14573538" author="benedict" created="Thu, 4 Jun 2015 20:41:38 +0000"  >&lt;p&gt;Thanks.&lt;/p&gt;

&lt;p&gt;This error specifically is related to that change, but the underlying cause is most likely not. With the full log file we can probably glean enough information to suppress this &lt;em&gt;presentation&lt;/em&gt; of the problem, but the service would still be shutdown while the system is running and this would eventually lead to other problems.&lt;/p&gt;
</comment>
                            <comment id="14573567" author="benedict" created="Thu, 4 Jun 2015 20:56:21 +0000"  >&lt;p&gt;Thanks. Unfortunately that does not seem to be the complete log history. It would help a great deal to have logs from when the node actually started up.&lt;/p&gt;

&lt;p&gt;I can make an educated guess, though: it looks like the node was OOMing due to normal operational reasons (or perhaps some other issue, we cannot say), and we recently modified behaviour in this scenario to trigger a shutdown of the host. Unfortunately, it seems that the OOM is somehow delaying the shutdown from completing, or perhaps there is some other issue. Certainly the JVM thinks it is shutting down.&lt;/p&gt;

&lt;p&gt;The strange thing is that the shutdown hook must still have been run, since that is the only way the executor service could be shutdown, only we ask the shutdown hook to be removed in this event. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=JoshuaMcKenzie&quot; class=&quot;user-hover&quot; rel=&quot;JoshuaMcKenzie&quot;&gt;JoshuaMcKenzie&lt;/a&gt;, any ideas?&lt;/p&gt;

&lt;p&gt;More complete logs would help us.&lt;/p&gt;

&lt;p&gt;Increasing your heap space may fix the underlying problem. It may be that there is another underlying issue causing your heap to explode. To establish this we would need a heap dump during one of these events. If, however, you make extensive use of CQL row deletions, or CQL collections and perform overwrites of the entire collection, it may be that you are encountering &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9486&quot; title=&quot;LazilyCompactedRow accumulates all expired RangeTombstones&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-9486&quot;&gt;&lt;del&gt;CASSANDRA-9486&lt;/del&gt;&lt;/a&gt;, in which case a patch is available for that, and will be fixed in 2.1.6 to be released shortly.&lt;/p&gt;</comment>
                            <comment id="14573595" author="ivar.thorson" created="Thu, 4 Jun 2015 21:14:13 +0000"  >&lt;p&gt;We have tried increasing JVM heap size slightly to 3G, but we see the same issues. We cannot increase the heap size much more before reaching an unreasonably large fraction of total system memory (7.5G). We are not doing extensive deletions or overwrites. &lt;/p&gt;

&lt;p&gt;The log exceeds 20M when compressed, I will try to cut that down a bit and find the start point.&lt;/p&gt;</comment>
                            <comment id="14573640" author="ivar.thorson" created="Thu, 4 Jun 2015 21:46:13 +0000"  >&lt;p&gt;Uploaded a new log for our c7 node, after spending time finding when the node was last restarted. Let me know if I am still truncating the log at the wrong points.&lt;/p&gt;</comment>
                            <comment id="14574121" author="benedict" created="Fri, 5 Jun 2015 08:27:47 +0000"  >&lt;p&gt;That still seems to be missing the usual startup log messages, and must have been running for some time since the CompactionExecutor and MemtableFlusher pools both have thread ids above 100. &lt;/p&gt;

&lt;p&gt;It looks like it is already under significant heap pressure at that time. Unfortunately it is very hard to say why, likely even with the complete logs. At this point we really need a heap dump to analyse.&lt;/p&gt;</comment>
                            <comment id="14574811" author="ivar.thorson" created="Fri, 5 Jun 2015 16:50:23 +0000"  >&lt;p&gt;Sorry, I had difficulty figuring out where the log starts because I&apos;ve been working from a large, concatenated file, and keep mixing UTC and PST time zones. I uploaded c7fromboot.zip, which seems to start from the right place.&lt;/p&gt;</comment>
                            <comment id="14574905" author="jmckenzie" created="Fri, 5 Jun 2015 17:47:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8092&quot; title=&quot;Check for swallowed Throwable in CI environment&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8092&quot;&gt;CASSANDRA-8092&lt;/a&gt; is still open. We have quite a few more swallowed exceptions since last I went through the code-base and fixed them:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Total caught and rethrown as something other than Runtime: 82
Total caught and rethrown as Runtime: 68
Total Swallowed: 40
Total delegated to JVMStabilityInspector: 66
Total &apos;catch (Throwable ...)&apos; analyzed: 79
Total &apos;catch (Exception ...)&apos; analyzed: 177
Total catch clauses analyzed: 256
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So in this instance, I wouldn&apos;t bank on the shutdown hook having been unregistered.&lt;/p&gt;</comment>
                            <comment id="14575430" author="ivar.thorson" created="Sat, 6 Jun 2015 00:03:43 +0000"  >&lt;p&gt;I&apos;d be happy to provide a heap dump, but even zipped it&apos;s &amp;gt;200MB. FTP? Google drive?&lt;/p&gt;</comment>
                            <comment id="14575682" author="benedict" created="Sat, 6 Jun 2015 10:57:55 +0000"  >&lt;p&gt;Wherever is convenient for you to put it.&lt;/p&gt;</comment>
                            <comment id="14577420" author="ivar.thorson" created="Mon, 8 Jun 2015 16:22:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://drive.google.com/a/whibse.com/file/d/0BxS4YrlxXzqAODNaTHBqY2ZGZlE/view?usp=sharing&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://drive.google.com/a/whibse.com/file/d/0BxS4YrlxXzqAODNaTHBqY2ZGZlE/view?usp=sharing&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14586335" author="ivar.thorson" created="Mon, 15 Jun 2015 17:19:24 +0000"  >&lt;p&gt;As another data point, we upgraded our servers to 2.1.6 and see the same issue.&lt;/p&gt;</comment>
                            <comment id="14586425" author="jjirsa" created="Mon, 15 Jun 2015 18:14:28 +0000"  >&lt;p&gt;Throwing a me-too here, copying summary from IRC (on the topic of 2.1.6 showing weird memory behavior that feels like a leak). Other user was also using DTCS:&lt;/p&gt;

&lt;p&gt;11:07 &amp;lt; jeffj&amp;gt; opened &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9597&quot; title=&quot;DTCS should consider file SIZE in addition to time windowing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-9597&quot;&gt;&lt;del&gt;CASSANDRA-9597&lt;/del&gt;&lt;/a&gt; last night. dtcs + streaming = lots of sstables that won&apos;t compact efficiently and eventually (days after load is stopped) nodes end up ooming or in gc hell.&lt;br/&gt;
11:08 &amp;lt; jeffj&amp;gt; in our case, the PROBLEM is that sstables build up over time due to the weird way dtcs is selecting candidates to compact, but the symptom is very very very long gc pauses and eventual ooms.&lt;br/&gt;
11:10 &amp;lt; jeffj&amp;gt; i would very much believe there&apos;s a leak somewhere in 2.1.6. in our case, we saw the same behavior in 2.1.5, so i dont think it&apos;s a single minor version regression&lt;/p&gt;
</comment>
                            <comment id="14586460" author="rstrickland" created="Mon, 15 Jun 2015 18:36:09 +0000"  >&lt;p&gt;We also experience this issue on 2.1.5, and also running DTCS.&lt;/p&gt;</comment>
                            <comment id="14586549" author="benedict" created="Mon, 15 Jun 2015 19:42:18 +0000"  >&lt;p&gt;Sorry for the slow response. This one slipped off my work queue. I&apos;ve pushed a fix &lt;a href=&quot;https://github.com/belliottsmith/cassandra/tree/9549&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;. The problem is that I made erroneous assumptions about the behaviour of CLQ on remove (I&apos;ve read too many CLQ implementations to keep them all straight, I guess). The problem is that on remove, it does not unlink the node it has removed from, it only sets the item to null. This means we accumulate the CLQ nodes for the whole lifetime of the Ref (in this case an sstable). DTCS obviously exacerbates this by ensuring sstable lifetimes are infinite.&lt;/p&gt;

&lt;p&gt;This patch simply swaps that to a CLDeque. This has some undesirable properties, so we should probably hasten &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9379&quot; title=&quot;Use a collection supporting more efficient removal in Ref.GlobalState&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-9379&quot;&gt;CASSANDRA-9379&lt;/a&gt;. This would have prevented this, and will generally improve our management of Ref instances.&lt;/p&gt;

&lt;p&gt;I&apos;ve also filed a follow up ticket, &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9600&quot; title=&quot;DescriptorTypeTidy and GlobalTypeTidy do not benefit from being full fledged Ref instances&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-9600&quot;&gt;&lt;del&gt;CASSANDRA-9600&lt;/del&gt;&lt;/a&gt;, which would have mitigated this.&lt;/p&gt;</comment>
                            <comment id="14586556" author="benedict" created="Mon, 15 Jun 2015 19:47:38 +0000"  >&lt;p&gt;Actually, scratch that... it does look like CLQ should remove the node. And yet, it isn&apos;t doing so, if the heap dump is to be believed. I suspect the patched branch will fix the problem, but will see if I can puzzle out a plausible mechanism by which the nodes are accumulating.&lt;/p&gt;</comment>
                            <comment id="14586587" author="benedict" created="Mon, 15 Jun 2015 20:08:21 +0000"  >&lt;p&gt;Ahhh. So, there is a pathological case in CLQ.remove. If the item you delete was the last to be inserted, it will not expunge the node. However if it also does not expunge any deleted items en route to the end. So, if you retain the first to be inserted, and you always delete the last, you get an infinitely growing, but completely empty, middle of the CLQ. This is pretty easily avoided, so might be worth an upstream patch to the JDK. However for now the patch I uploaded should fix the problem (which I&apos;m more confident of, now there is an explanatory framework), and &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9379&quot; title=&quot;Use a collection supporting more efficient removal in Ref.GlobalState&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-9379&quot;&gt;CASSANDRA-9379&lt;/a&gt; remains the correct follow up to ensure no pathological list behaviours (e.g. with lots of extant Ref instances).&lt;/p&gt;</comment>
                            <comment id="14589537" author="benedict" created="Wed, 17 Jun 2015 09:32:11 +0000"  >&lt;p&gt;I&apos;ve added a regression test to the branch. Could I get a reviewer please, and can we ship this soon?&lt;/p&gt;</comment>
                            <comment id="14589683" author="krummas" created="Wed, 17 Jun 2015 12:05:19 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14589987" author="benedict" created="Wed, 17 Jun 2015 16:15:15 +0000"  >&lt;p&gt;Thanks!&lt;/p&gt;</comment>
                            <comment id="14589997" author="ivar.thorson" created="Wed, 17 Jun 2015 16:17:54 +0000"  >&lt;p&gt;We patched our 2.1.6 cluster on Wednesday and let it run for a day to let things accumulate. Looking at CPU activity and heap space for the last day suggests that the memory leak seems to have been fixed by the patch. Awesome work!&lt;/p&gt;</comment>
                            <comment id="14589999" author="benedict" created="Wed, 17 Jun 2015 16:21:10 +0000"  >&lt;p&gt;Great, glad to hear it&lt;/p&gt;</comment>
                            <comment id="14968882" author="maximp" created="Thu, 22 Oct 2015 09:51:43 +0000"  >&lt;p&gt;Is this bug fixed in Cassandra 2.2.0?&lt;/p&gt;</comment>
                            <comment id="15233823" author="stone" created="Sun, 10 Apr 2016 02:09:26 +0000"  >&lt;p&gt;could you take a summary after resolving the issue?&lt;br/&gt;
why this happen?,how to resolve?&lt;br/&gt;
actually,it&apos;s hard to find the answer when people met the same issue.&lt;/p&gt;</comment>
                            <comment id="15233832" author="benedict" created="Sun, 10 Apr 2016 02:41:43 +0000"  >&lt;p&gt;What is obtuse?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;how to resolve?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Move to a version &amp;gt;= fixVersion, i.e. 2.1.7&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;why this happen&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9549?focusedCommentId=14586587&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14586587&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;last comment  with more than one sentence&lt;/a&gt;, only six comments back, spells out what happened and why.&lt;/p&gt;

&lt;p&gt;I realise JIRA noise can be quite an issue in many cases, but in this instance it seems to me that just a modicum of effort was necessary to find the answers you sought.&lt;/p&gt;
</comment>
                            <comment id="15238615" author="stone" created="Wed, 13 Apr 2016 04:59:56 +0000"  >&lt;p&gt;@Benedict Thanks for your answer.&lt;br/&gt;
I got it.&lt;/p&gt;

&lt;p&gt;open a ticket &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-11460&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/CASSANDRA-11460&lt;/a&gt;&lt;br/&gt;
at first,I thought it same as this ticket,and now I realize I made a mistake.&lt;/p&gt;

&lt;p&gt;the ticket is opened about 2 weeks,but still no response,can you help a look.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12905907">CASSANDRA-10548</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12737683" name="c4_system.log" size="8916543" author="ivar.thorson" created="Thu, 4 Jun 2015 20:36:27 +0000"/>
                            <attachment id="12737986" name="c7fromboot.zip" size="5939678" author="ivar.thorson" created="Fri, 5 Jun 2015 16:47:56 +0000"/>
                            <attachment id="12737644" name="cassandra.yaml" size="35793" author="ivar.thorson" created="Thu, 4 Jun 2015 17:51:02 +0000"/>
                            <attachment id="12737640" name="cpu-load.png" size="58121" author="ivar.thorson" created="Thu, 4 Jun 2015 17:41:53 +0000"/>
                            <attachment id="12737641" name="memoryuse.png" size="48173" author="ivar.thorson" created="Thu, 4 Jun 2015 17:41:53 +0000"/>
                            <attachment id="12737682" name="ref-java-errors.jpeg" size="65420" author="ivar.thorson" created="Thu, 4 Jun 2015 20:35:44 +0000"/>
                            <attachment id="12737642" name="suspect.png" size="109385" author="ivar.thorson" created="Thu, 4 Jun 2015 17:41:53 +0000"/>
                            <attachment id="12737676" name="two-loads.png" size="209074" author="ivar.thorson" created="Thu, 4 Jun 2015 20:02:52 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[benedict]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10431"><![CDATA[Important]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 31 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2fn93:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Reproduced In</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329874">2.1.5</customfieldvalue>
    <customfieldvalue id="12332265">2.1.6</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>marcuse</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[marcuse]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12963"><![CDATA[Critical]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
                        <customfieldname>Since Version</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329874">2.1.5</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>