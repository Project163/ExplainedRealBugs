<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:41:50 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-6008] Getting &apos;This should never happen&apos; error at startup due to sstables missing</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-6008</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;Exception encountered during startup: &quot;Unfinished compactions reference missing sstables. This should never happen since compactions are marked finished before we start removing the old sstables&quot;&lt;/p&gt;

&lt;p&gt;This happens when sstables that have been compacted away are removed, but they still have entries in the system.compactions_in_progress table.&lt;/p&gt;

&lt;p&gt;Normally this should not happen because the entries in system.compactions_in_progress are deleted before the old sstables are deleted.&lt;/p&gt;

&lt;p&gt;However at startup recovery time, old sstables are deleted (NOT BEFORE they are removed from the compactions_in_progress table) and then after that is done it does a truncate using SystemKeyspace.discardCompactionsInProgress&lt;/p&gt;

&lt;p&gt;We ran into a case where the disk filled up and the node died and was bounced and then failed to truncate this table on startup, and then got stuck hitting this exception in ColumnFamilyStore.removeUnfinishedCompactionLeftovers.&lt;/p&gt;

&lt;p&gt;Maybe on startup we can delete from this table incrementally as we clean stuff up in the same way that compactions delete from this table before they delete old sstables.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12668155">CASSANDRA-6008</key>
            <summary>Getting &apos;This should never happen&apos; error at startup due to sstables missing</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="thobbs">Tom Hobbs</assignee>
                                    <reporter username="johnyoh">John Carrino</reporter>
                        <labels>
                    </labels>
                <created>Wed, 11 Sep 2013 21:50:16 +0000</created>
                <updated>Tue, 16 Apr 2019 09:32:05 +0000</updated>
                            <resolved>Tue, 17 Dec 2013 18:03:33 +0000</resolved>
                                                            <due></due>
                            <votes>6</votes>
                                    <watches>13</watches>
                                                                                                                <comments>
                            <comment id="13764847" author="johnyoh" created="Wed, 11 Sep 2013 22:03:22 +0000"  >&lt;p&gt;Now that I think about this more: Doesn&apos;t this new cleanup code make it hard to restore a CF from a backup?  If there was a compaction for this CF in progress when you took down the system, when you bring it back up with new sstables for this CF, then this check will prevent you from starting.&lt;/p&gt;</comment>
                            <comment id="13796983" author="ngrigoriev" created="Wed, 16 Oct 2013 16:59:36 +0000"  >&lt;p&gt;I have got the same issue on one of my nodes. I was running a long CQL query (probably too long to be completed successfully anyway) and restarted Cassandra while it was running. &lt;/p&gt;

&lt;p&gt;I am wondering if there is a way to restore that node? It consistently fails on startup with this error.&lt;/p&gt;</comment>
                            <comment id="13797088" author="johnyoh" created="Wed, 16 Oct 2013 18:33:54 +0000"  >&lt;p&gt;I think we worked around it by deleting all the data from system.compactions_in_progress&lt;/p&gt;</comment>
                            <comment id="13797141" author="ngrigoriev" created="Wed, 16 Oct 2013 19:11:07 +0000"  >&lt;p&gt;Thanks, I was able to recover the node. I could not truncate that table because the node was down but I have deleted all the rows. And I have got them back when I restarted the node and it crashed again with the same error &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; After looking briefly at the code I have decided to delete all the compaction directories on that node (&quot;compactions_in_progress&quot; ones), clean the table again and restart. That did seem to help &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13817760" author="jre" created="Fri, 8 Nov 2013 22:26:18 +0000"  >&lt;p&gt;Hi, we are able to consistently reproduce this issue:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR 23:14:06,001 Exception encountered during startup
java.lang.IllegalStateException: Unfinished compactions reference missing sstables. This should never happen since compactions are marked finished before we start removing the old sstables.
       at org.apache.cassandra.db.ColumnFamilyStore.removeUnfinishedCompactionLeftovers(ColumnFamilyStore.java:489)
       at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:264)
       at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:461)
       at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:504)
java.lang.IllegalStateException: Unfinished compactions reference missing sstables. This should never happen since compactions are marked finished before we start removing the old sstables.
       at org.apache.cassandra.db.ColumnFamilyStore.removeUnfinishedCompactionLeftovers(ColumnFamilyStore.java:489)
       at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:264)
       at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:461)
       at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:504)
Exception encountered during startup: Unfinished compactions reference missing sstables. This should never happen since compactions are marked finished before we start removing the old sstables.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here are the two ways in which we have found to reproduce this issue:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Buffer a large amount of CL.LOCAL_QUORUM writes into a Cassandra CF, then drop the CF while the writes are still buffered.&lt;/li&gt;
	&lt;li&gt;Buffer a large amount of CL.LOCAL_QUORUM writes into a Cassandra CF, then restart some nodes while before the buffer has finished draining.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13817765" author="jre" created="Fri, 8 Nov 2013 22:28:05 +0000"  >&lt;p&gt;We were able to recover the node by deleting all the data, commit, and saved_cache directories on the affected node and letting it rebuild.&lt;/p&gt;</comment>
                            <comment id="13827832" author="thobbs" created="Wed, 20 Nov 2013 16:43:28 +0000"  >&lt;p&gt;I can reproduce this fairly consistently (on trunk, at least) using only &lt;tt&gt;cassandra-stress&lt;/tt&gt;.  Just let it run for a few minutes, CTRL-C the cassandra process, then restart it.&lt;/p&gt;</comment>
                            <comment id="13832514" author="vongocminh" created="Tue, 26 Nov 2013 11:41:16 +0000"  >&lt;p&gt;Just for your information, we&apos;ve run into this issue with v2.0.2 on our dev environment and the workaround worked.&lt;/p&gt;

&lt;p&gt;Hope the fix could be included in the next patch v2.0.3.&lt;br/&gt;
Thanks a lot for your help.&lt;/p&gt;</comment>
                            <comment id="13844720" author="thobbs" created="Tue, 10 Dec 2013 22:01:42 +0000"  >&lt;p&gt;6008-trunk-v1.patch should resolve the issue on trunk.  I&apos;ll have a 2.0 patch shortly.&lt;/p&gt;

&lt;p&gt;The root of the problem was that LazilyCompactedRow was merging row tombstones incorrectly, essentially just discarding them.  There are a lot of documentation improvements in the patch (as it took me a while to understand everything sufficiently well to make a good fix); the only real code changes are in LazilyCompactedRow and a unit test to reproduce the issue.&lt;/p&gt;

&lt;p&gt;We should probably change the title of this ticket to match the actual problem instead of this particular symptom.&lt;/p&gt;</comment>
                            <comment id="13844806" author="thobbs" created="Tue, 10 Dec 2013 23:17:51 +0000"  >&lt;p&gt;2.0 patch is also attached.  I suspect there&apos;s a second cause for this in 2.0.  &lt;tt&gt;LazilyCompactedRow&lt;/tt&gt; should only be used when the row is over &lt;tt&gt;in_memory_compaction_limit_in_mb&lt;/tt&gt;, and compaction limits should prevent one row from exceeding that unless it&apos;s set to zero.&lt;/p&gt;</comment>
                            <comment id="13845821" author="jbellis" created="Wed, 11 Dec 2013 23:16:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;compaction limits should prevent one row from exceeding that unless it&apos;s set to zero&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m confused, I&apos;m reading this as &quot;LCR is not used in 2.0 unless imclib == 0&quot; but I&apos;m sure that&apos;s not what you meant.&lt;/p&gt;</comment>
                            <comment id="13845822" author="jbellis" created="Wed, 11 Dec 2013 23:16:33 +0000"  >&lt;p&gt;I don&apos;t suppose you have a branch that pulls the renames into a separate commit?&lt;/p&gt;</comment>
                            <comment id="13845823" author="jbellis" created="Wed, 11 Dec 2013 23:16:34 +0000"  >&lt;p&gt;(Looking at the 2.0 patch)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;You&apos;re right that hasIrrelevantData is just checking for tombstones to purge now...  it used to check for cells shadowed by tombstones as well.  Is it another regression that it does not?&lt;/li&gt;
	&lt;li&gt;Looks to me like dropping the shouldPurge check from LCR.write is a regression &amp;#8211; shouldPurge is what says &quot;we&apos;re sure there&apos;s no data in other sstables that should be shadowed by this tombstone.&quot;  Surprised we don&apos;t have a test that catches that.&lt;/li&gt;
	&lt;li&gt;I&apos;m not actually sure where the bug is in the original code.  I see that the Reducer fix will result in correctly purging range tombstones now, but I don&apos;t think that&apos;s the dropping-row-tombstones bug you referred to.  The code in the constructor is cleaner now but I don&apos;t see why the original didn&apos;t work as intended.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13845844" author="thobbs" created="Wed, 11 Dec 2013 23:29:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m confused, I&apos;m reading this as &quot;LCR is not used in 2.0 unless imclib == 0&quot; but I&apos;m sure that&apos;s not what you meant.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry, I meant LCR wouldn&apos;t be used when compacting &lt;tt&gt;system.compactions_in_progress&lt;/tt&gt; unless imclib == 0, because the max_compaction_threshold would prevent any row from getting that wide.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I don&apos;t suppose you have a branch that pulls the renames into a separate commit?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think what you&apos;re looking for is in &lt;a href=&quot;https://github.com/thobbs/cassandra/tree/CASSANDRA-6008&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this branch&lt;/a&gt;, specifically &lt;a href=&quot;https://github.com/thobbs/cassandra/commit/f0a68534835d76baf9fdec15438a178e0d8028b5&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this commit&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13845859" author="thobbs" created="Wed, 11 Dec 2013 23:53:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;You&apos;re right that hasIrrelevantData is just checking for tombstones to purge now... it used to check for cells shadowed by tombstones as well. Is it another regression that it does not?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;tt&gt;ColumnFamily.hasIrrelevantData()&lt;/tt&gt; still checks for cells shadowed by tombstones.  It just wasn&apos;t a good name for the DeletionInfo method, which is only checks for purgeable tombstones.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Looks to me like dropping the shouldPurge check from LCR.write is a regression &#8211; shouldPurge is what says &quot;we&apos;re sure there&apos;s no data in other sstables that should be shadowed by this tombstone.&quot; Surprised we don&apos;t have a test that catches that.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The &lt;tt&gt;shouldPurge&lt;/tt&gt; check in the LCR constructor handles that.  If shouldPurge is false, it will leave the tombstone in &lt;tt&gt;emptyColumnFamily&lt;/tt&gt;.  Then, in &lt;tt&gt;write()&lt;/tt&gt;, &lt;tt&gt;isMarkedForDelete()&lt;/tt&gt; will be true, meaning the tombstone will be written out.&lt;/p&gt;

&lt;p&gt;I can add a test to exercise this, if you&apos;d like.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m not actually sure where the bug is in the original code. I see that the Reducer fix will result in correctly purging range tombstones now, but I don&apos;t think that&apos;s the dropping-row-tombstones bug you referred to. The code in the constructor is cleaner now but I don&apos;t see why the original didn&apos;t work as intended.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There were a few different bugs.&lt;/p&gt;

&lt;p&gt;The first and main bug was related to the top-level tombstone being ignored.  I believe the original intention of the LCR code was for emptyColumnFamily to hold the DeletionInfo (or row tombstone, in earlier forms), resulting in cells being deleted during &lt;tt&gt;removeDeletedAndOldShards()&lt;/tt&gt;.  However, emptyColumnFamily is only cloned once (when creating the reducer), and then that clone is cleared and reused during each call to &lt;tt&gt;getReduced()&lt;/tt&gt;, so the DeletionInfo was lost after the first round.&lt;/p&gt;

&lt;p&gt;The second bug was that if the row tombstone had expired, it would be purged in the LCR constructor, so cells would not be considered deleted later during the merge/reduce process.&lt;/p&gt;

&lt;p&gt;The last bug was just a minor potential issue I spotted in &lt;tt&gt;reduce()&lt;/tt&gt; where we weren&apos;t necessarily picking the range tombstone with the highest timestamp, just the last range tombstone we saw.&lt;/p&gt;</comment>
                            <comment id="13845874" author="jbellis" created="Thu, 12 Dec 2013 00:00:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;emptyColumnFamily is only cloned once (when creating the reducer), and then that clone is cleared and reused during each call to &lt;tt&gt;getReduced()&lt;/tt&gt;, so the DeletionInfo was lost after the first round&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, but that should only affect purging range tombstones, since we write the row tombstone based on emptyColumnFamily, not on the Reducer container.&lt;/p&gt;</comment>
                            <comment id="13846460" author="thobbs" created="Thu, 12 Dec 2013 17:11:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;Right, but that should only affect purging range tombstones, since we write the row tombstone based on emptyColumnFamily, not on the Reducer container.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well, it&apos;s true that we&apos;ll still write out the row tombstone, but we&apos;ll fail to purge the cells that it shadows (except for the first one), so the delete will appear to have worked, but both the tombstone and cells will exist in the new sstable. After gcGrace has passed, the row tombstone will be purged and any cells that remain will be revived.&lt;/p&gt;</comment>
                            <comment id="13846492" author="jbellis" created="Thu, 12 Dec 2013 17:49:05 +0000"  >&lt;p&gt;How about this to clean it up a bit more? &lt;a href=&quot;https://github.com/jbellis/cassandra/tree/CASSANDRA-6008&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/jbellis/cassandra/tree/CASSANDRA-6008&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13846522" author="thobbs" created="Thu, 12 Dec 2013 18:08:55 +0000"  >&lt;p&gt;+1 on the cleanup&lt;/p&gt;</comment>
                            <comment id="13846612" author="jbellis" created="Thu, 12 Dec 2013 19:09:26 +0000"  >&lt;p&gt;Committed.&lt;/p&gt;

&lt;p&gt;But I think you&apos;re right that there&apos;s something else going on.  I think John correctly identified one scenario in his original description.&lt;/p&gt;</comment>
                            <comment id="13847890" author="thobbs" created="Fri, 13 Dec 2013 20:50:26 +0000"  >&lt;p&gt;6008-2.0-part2.patch (and &lt;a href=&quot;https://github.com/thobbs/cassandra/tree/CASSANDRA-6008-2.0-part2&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;branch&lt;/a&gt;) should apply to the 2.0 branch.  This deletes the entries from &lt;tt&gt;compactions_in_progress&lt;/tt&gt; before deleting the files, as suggested by John.&lt;/p&gt;

&lt;p&gt;I&apos;ll make a trunk version of the patch after review.&lt;/p&gt;</comment>
                            <comment id="13848078" author="jbellis" created="Fri, 13 Dec 2013 23:54:21 +0000"  >&lt;p&gt;This means that instead of throwing an error if we restart before removeUnfinishedCompactionLeftovers finishes, we&apos;ll leave both old and new sstables from unfinished compactions live, which defeats the purpose for counters.&lt;/p&gt;

&lt;p&gt;For 2.1 that would be okay (since we&apos;re assuming &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-4775&quot; title=&quot;Counters 2.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-4775&quot;&gt;&lt;del&gt;CASSANDRA-4775&lt;/del&gt;&lt;/a&gt; will be done before we release) but for 2.0 it isn&apos;t, unfortunately.&lt;/p&gt;

&lt;p&gt;I think the alternatives are&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Switch back to delete-first, and add a debug line instead of IllegalStateException.  (Can delete from compaction_log incrementally too to reduce the window of inconsistency.)&lt;/li&gt;
	&lt;li&gt;Do a dance of renaming back to .tmp instead of deleting, then removing compaction_log entry, then deleting.  .tmp will be included in the unfinished list, but if there is no corresponding compaction_log entry they can just be deleted&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I&apos;d lean towards saying the extra complexity of #2 isn&apos;t worth the security blanket of the ISE.&lt;/p&gt;</comment>
                            <comment id="13849672" author="ngrigoriev" created="Mon, 16 Dec 2013 20:12:24 +0000"  >&lt;p&gt;I am wondering if it is possible that because of this problem I ended up with this (&lt;a href=&quot;http://stackoverflow.com/questions/20589324/cassandra-2-0-3-endless-compactions-with-no-traffic&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://stackoverflow.com/questions/20589324/cassandra-2-0-3-endless-compactions-with-no-traffic&lt;/a&gt;) issue.&lt;/p&gt;

&lt;p&gt;I am constantly having this &quot;This should never happen&quot; problem with I restart my 2.0.3 cluster. Out of 6 nodes, if I restart it now for sure at least 2 will fail to start because of this condition. And to allow them to start I wipe the contents of system.compactions_in_progress table and delete all compactions_in_progress directories under my data directories on the node affected.&lt;/p&gt;</comment>
                            <comment id="13849697" author="johnyoh" created="Mon, 16 Dec 2013 20:32:57 +0000"  >&lt;p&gt;I&apos;m fine with leaving all the sstables live.  We use our own MVCC and only rely on cassandra to do durable writes and use QUORUM to ensure read what you wrote.  Is the only point of this table to ensure counters are handled correctly?&lt;/p&gt;

&lt;p&gt;Another possible issue may be when doing restore from backup.  If you do a shutdown while there are rows in compaction_log and then clear the current tables and replace with new ones you will get this error also.&lt;/p&gt;
</comment>
                            <comment id="13850697" author="ngrigoriev" created="Tue, 17 Dec 2013 17:27:18 +0000"  >&lt;p&gt;Not sure it is related, but I have noticed that I often have this issue when the node shuts down with this exception:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; INFO [RMI TCP Connection(8)-10.3.45.158] 2013-12-17 17:22:31,782 StorageService.java (line 941) DRAINED
ERROR [CompactionExecutor:2008] 2013-12-17 17:22:36,615 CassandraDaemon.java (line 187) Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[CompactionExecutor:2008,1,main]
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@16e10a93 rejected from org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor@107d44a1[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 130876]
        at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2048)
        at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:821)
        at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:325)
        at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:530)
        at java.util.concurrent.ScheduledThreadPoolExecutor.submit(ScheduledThreadPoolExecutor.java:629)
        at org.apache.cassandra.io.sstable.SSTableDeletingTask.schedule(SSTableDeletingTask.java:66)
        at org.apache.cassandra.io.sstable.SSTableReader.releaseReference(SSTableReader.java:1105)
        at org.apache.cassandra.db.DataTracker.removeOldSSTablesSize(DataTracker.java:388)
        at org.apache.cassandra.db.DataTracker.postReplace(DataTracker.java:353)
        at org.apache.cassandra.db.DataTracker.replace(DataTracker.java:347)
        at org.apache.cassandra.db.DataTracker.replaceCompactedSSTables(DataTracker.java:252)
        at org.apache.cassandra.db.ColumnFamilyStore.replaceCompactedSSTables(ColumnFamilyStore.java:1078)
        at org.apache.cassandra.db.compaction.CompactionTask.replaceCompactedSSTables(CompactionTask.java:296)
        at org.apache.cassandra.db.compaction.CompactionTask.runWith(CompactionTask.java:242)
        at org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAwareRunnable.java:48)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
        at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:60)
        at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59)
        at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionTask.run(CompactionManager.java:197)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
        at java.util.concurrent.FutureTask.run(FutureTask.java:166)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:724)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I do disable thrift,gossip and drain the node before stopping Cassandra process.&lt;/p&gt;</comment>
                            <comment id="13850705" author="thobbs" created="Tue, 17 Dec 2013 17:36:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;This means that instead of throwing an error if we restart before removeUnfinishedCompactionLeftovers finishes, we&apos;ll leave both old and new sstables from unfinished compactions live, which defeats the purpose for counters.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;D&apos;oh, you&apos;re right.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Switch back to delete-first, and add a debug line instead of IllegalStateException. (Can delete from compaction_log incrementally too to reduce the window of inconsistency.)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim&quot; class=&quot;user-hover&quot; rel=&quot;yukim&quot;&gt;yukim&lt;/a&gt;&apos;s patch on &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6086&quot; title=&quot;Node refuses to start with exception in ColumnFamilyStore.removeUnfinishedCompactionLeftovers when find that some to be removed files are already removed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-6086&quot;&gt;&lt;del&gt;CASSANDRA-6086&lt;/del&gt;&lt;/a&gt; basically does this (except for deleting incrementally) so we should pick one ticket or the other to do that under.&lt;/p&gt;</comment>
                            <comment id="13850709" author="thobbs" created="Tue, 17 Dec 2013 17:38:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;Another possible issue may be when doing restore from backup. If you do a shutdown while there are rows in compaction_log and then clear the current tables and replace with new ones you will get this error also.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=johnyoh&quot; class=&quot;user-hover&quot; rel=&quot;johnyoh&quot;&gt;johnyoh&lt;/a&gt; yes, that&apos;s another good argument for approach #1, in my opinion.&lt;/p&gt;</comment>
                            <comment id="13850727" author="jbellis" created="Tue, 17 Dec 2013 18:03:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;Yuki Morishita&apos;s patch on &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6086&quot; title=&quot;Node refuses to start with exception in ColumnFamilyStore.removeUnfinishedCompactionLeftovers when find that some to be removed files are already removed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-6086&quot;&gt;&lt;del&gt;CASSANDRA-6086&lt;/del&gt;&lt;/a&gt; basically does this (except for deleting incrementally) so we should pick one ticket or the other to do that under.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;All right, resolving this one as duplicate.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12670272">CASSANDRA-6086</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12618681" name="6008-2.0-part2.patch" size="18591" author="thobbs" created="Fri, 13 Dec 2013 20:50:26 +0000"/>
                            <attachment id="12618135" name="6008-2.0-v1.patch" size="33898" author="thobbs" created="Tue, 10 Dec 2013 23:17:51 +0000"/>
                            <attachment id="12618112" name="6008-trunk-v1.patch" size="35871" author="thobbs" created="Tue, 10 Dec 2013 22:01:42 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[thobbs]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>348089</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 49 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1o0sv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>348385</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>jbellis</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[jbellis]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>