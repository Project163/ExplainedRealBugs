<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:20:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-2324] Repair transfers more data than necessary</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-2324</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;To repro: 3 node cluster, stress.java 1M rows with -x KEYS and -l 2.  The index is enough to make some mutations drop (about 20-30k total in my tests).  Repair afterwards will repair a large amount of ranges the first time.  However, each subsequent run will repair the same set of small ranges every time.  INDEXED_RANGE_SLICE in stress never fully works.  Counting rows with sstablekeys shows there are 2M rows total as expected, however when trying to count the indexed keys, I get exceptions like:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Exception in thread &quot;main&quot; java.io.IOException: Key out of order! DecoratedKey(101571366040797913119296586470838356016, 0707ab782c5b5029d28a5e6d508ef72f0222528b5e28da3b7787492679dc51b96f868e0746073e54bc173be927049d0f51e25a6a95b3268213b8969abf40cea7d7) &amp;gt; DecoratedKey(12639574763031545147067490818595764132, 0bc414be3093348a2ad389ed28f18f0cc9a044b2e98587848a0d289dae13ed0ad479c74654900eeffc6236)
        at org.apache.cassandra.tools.SSTableExport.enumeratekeys(SSTableExport.java:206)
        at org.apache.cassandra.tools.SSTableExport.main(SSTableExport.java:388)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12501390">CASSANDRA-2324</key>
            <summary>Repair transfers more data than necessary</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="slebresne">Sylvain Lebresne</assignee>
                                    <reporter username="brandon.williams">Brandon Williams</reporter>
                        <labels>
                    </labels>
                <created>Mon, 14 Mar 2011 19:43:08 +0000</created>
                <updated>Tue, 16 Apr 2019 09:33:04 +0000</updated>
                            <resolved>Sun, 10 Apr 2011 18:16:27 +0000</resolved>
                                        <fixVersion>0.8 beta 1</fixVersion>
                                        <due></due>
                            <votes>2</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="13006591" author="jbellis" created="Mon, 14 Mar 2011 19:44:51 +0000"  >&lt;p&gt;Key out of order is because sstableexport doesn&apos;t know that index sstables use LocalPartitioner instead of the cluster partitioner RP or BOPP.&lt;/p&gt;</comment>
                            <comment id="13006640" author="brandon.williams" created="Mon, 14 Mar 2011 21:24:15 +0000"  >&lt;p&gt;It looks like INDEXED_RANGE_SLICE is broken in stress.java, so the only problem here is repair doing superfluous work.&lt;/p&gt;</comment>
                            <comment id="13012034" author="slebresne" created="Mon, 28 Mar 2011 12:57:17 +0000"  >&lt;p&gt;The problem is, the ranges repair hashes are not actual node ranges.&lt;/p&gt;

&lt;p&gt;Let&apos;s consider the following ring (RF=2), where I consider token being in &lt;span class=&quot;error&quot;&gt;&amp;#91;0..12&amp;#93;&lt;/span&gt; to simplify, and where everything is consistent:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;                  _.-&quot;&quot;&quot;&quot;-._
 C (token: 11)  .&apos;          `.
 [11,3][3,7]   /              \
              |                |
              |                | A(token: 3)
              |                | [3,7],[7,11]
               \              /
                `._        _.&apos;
       B (token: 7)`-....-&apos;
       [7,11],[11,3]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now say I run a repair on node A. The problem is that the Merkle tree ranges are built by dividing the full range by 2 recursively. This means that in this example, the ranges in the tree will for instance be &lt;span class=&quot;error&quot;&gt;&amp;#91;0,2&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;2, 4&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;4, 6&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;6, 8&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;8,10&amp;#93;&lt;/span&gt; and &lt;span class=&quot;error&quot;&gt;&amp;#91;10,12&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;If you compare the hashes for A and B on those ranges, changes are you&apos;ll find mismatches for &lt;span class=&quot;error&quot;&gt;&amp;#91;6,8&amp;#93;&lt;/span&gt; and &lt;span class=&quot;error&quot;&gt;&amp;#91;10,12&amp;#93;&lt;/span&gt; (because A don&apos;t have anyone on &lt;span class=&quot;error&quot;&gt;&amp;#91;11, 12&amp;#93;&lt;/span&gt; while B have, and B don&apos;t have anyone on &lt;span class=&quot;error&quot;&gt;&amp;#91;6, 7&amp;#93;&lt;/span&gt; while A have). As a consequence, the range &lt;span class=&quot;error&quot;&gt;&amp;#91;7,8&amp;#93;&lt;/span&gt; and &lt;span class=&quot;error&quot;&gt;&amp;#91;10,11&amp;#93;&lt;/span&gt; will be repaired, even though there is no inconsistencies.&lt;/p&gt;

&lt;p&gt;What that means in practice is that it will be very rare for anti-antropy to actually consider the nodes in sync, it will almost surely &quot;repair&quot; something, even if the nodes are perfectly consistent. It&apos;s Very easy to check btw: with a cluster right the one above (3 nodes, RF=2), with as few as 5 keys for the whole cluster I&apos;m able to have a repair do repairs over and over again.&lt;/p&gt;

&lt;p&gt;Now the good question is: how bad is it ? I&apos;m not sure, I depends a bit.&lt;/p&gt;

&lt;p&gt;On a 3 nodes cluster (RF=2), I tried inserting 1M keys with stress (stress -l 2) and triggered repair afterwards. The amount of (unnecessarily) repaired keys was around 150 keys for a given node (it varies slightly for run to run because there is some randomness in the creation of the Merkle tree), corresponding to ~44KB streamed (that is the amount transfered to the node where repair has been ran, so for the total operation its twice this, since we stream in both ways). That&apos;s ~0.02% of keys (a given node have ~666 666 keys).  It&apos;s bad to do useless work, but not a really big deal.&lt;/p&gt;

&lt;p&gt;However, the less keys we&apos;ll have, the worst it gets (and the bigger our rows are, the more useless transfer we do). With the same experiment inserting only 10K keys, there is 190 keys uselessly repaired. That&apos;s now close to 3% of the load. It also gets worst with increasing replication factor.&lt;/p&gt;


&lt;p&gt;To fix this, we would need for the range in the Merkle tree to &quot;share&quot; the node range boundaries. An interesting way to do this would be to have the coordinating node give a list a range for which to calculate Merkle trees, and the node would compute one tree by range (for the coordinating node, that would be #RF&apos;s tree). A nice think with this is that it would leave room to optimizing repair since a node would need to do a validation compaction only on the range asked for, which means that only the coordinator node would validate all its data. The neighbors would do less work.&lt;/p&gt;</comment>
                            <comment id="13012056" author="jbellis" created="Mon, 28 Mar 2011 13:44:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;To fix this, we would need for the range in the Merkle tree to &quot;share&quot; the node range boundaries&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;couldn&apos;t we just take the interesection of the computed ranges w/ the range actually being repaired? &lt;/p&gt;</comment>
                            <comment id="13012062" author="slebresne" created="Mon, 28 Mar 2011 13:58:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;couldn&apos;t we just take the interesection of the computed ranges w/ the range actually being repaired?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We do that. But the problem is: you&apos;re node A and you receive a merkle tree from B that in particular says that for the range &lt;span class=&quot;error&quot;&gt;&amp;#91;0..10&amp;#93;&lt;/span&gt; the hash is x. And on &lt;span class=&quot;error&quot;&gt;&amp;#91;0..10&amp;#93;&lt;/span&gt; your has is x&apos;. The problem is when &lt;span class=&quot;error&quot;&gt;&amp;#91;0..10&amp;#93;&lt;/span&gt; is partly one of your range, partly not. For instance it can be that you&apos;re a replica for &lt;span class=&quot;error&quot;&gt;&amp;#91;8..10&amp;#93;&lt;/span&gt; but not at all for &lt;span class=&quot;error&quot;&gt;&amp;#91;0..8&amp;#93;&lt;/span&gt;.&lt;br/&gt;
This is due to the fact that the ranges for which the hashes are computed are computed without concern for actual node ranges. So now you know there is some inconsistency on &lt;span class=&quot;error&quot;&gt;&amp;#91;0..10&amp;#93;&lt;/span&gt; but it may just be that B is responsible for &lt;span class=&quot;error&quot;&gt;&amp;#91;0..8&amp;#93;&lt;/span&gt; and have data for it (and we don&apos;t since we are not in charge of that).&lt;br/&gt;
In that case, the code do take the intersection of &lt;span class=&quot;error&quot;&gt;&amp;#91;0..10&amp;#93;&lt;/span&gt; with the local range and will stream only &lt;span class=&quot;error&quot;&gt;&amp;#91;8..10&amp;#93;&lt;/span&gt;. But it&apos;s still useless.&lt;/p&gt;</comment>
                            <comment id="13012071" author="jbellis" created="Mon, 28 Mar 2011 14:14:15 +0000"  >&lt;p&gt;I thought repair is per-token-range, i.e., if I say &quot;nodetool repair A&quot; then range (11, 3] and (3, 7] will be repaired independently.&lt;/p&gt;</comment>
                            <comment id="13012078" author="slebresne" created="Mon, 28 Mar 2011 14:34:42 +0000"  >&lt;p&gt;No, not if I read this code correctly (but I think it should, that&apos;s roughly what I&apos;m proposing to do).&lt;/p&gt;

&lt;p&gt;Actually thinking about it, there is probably no need to construct multiple merkle trees, it will be enough for neighbors to only add to the tree the keys that are in the range of the node asking for the tree.&lt;/p&gt;</comment>
                            <comment id="13012087" author="jbellis" created="Mon, 28 Mar 2011 14:47:23 +0000"  >&lt;p&gt;So what about this:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;change the atom of repair (in nodetool + StorageService) to be a single token range, so it&apos;s unambiguous what we&apos;re repairing.  This has the side benefit of making it enormously easier to repair an entire cluster w/o doing redundant work.&lt;/li&gt;
	&lt;li&gt;provide backwards compatibility w/ existing repair command by splitting it into RF repair ranges and waiting on each of those futures in StorageService mbean&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13012097" author="slebresne" created="Mon, 28 Mar 2011 15:00:30 +0000"  >&lt;p&gt;Sounds good, will do.&lt;/p&gt;</comment>
                            <comment id="13014641" author="slebresne" created="Fri, 1 Apr 2011 15:00:07 +0000"  >&lt;p&gt;Attached patch modify repair to operate on one token range at a time. Nodetool repair schedule as many repair session than the node have ranges to perform a full node repair. Note that this is more efficient than previously, since the neighbors of the node will only do a validation compaction on the range they have in common with the node coordinating the repair (instead of validating everything).&lt;/p&gt;

&lt;p&gt;This moreover makes it trivial to add an option to nodetool so that the node only repair it&apos;s primary range. That way, you can repair a full cluster by calling this operation on every node and there is no duplication of work. The patch doesn&apos;t add this option yet though.&lt;/p&gt;

&lt;p&gt;The patch is against trunk. Because the way we construct the merkleTree is fundamentally different, the trees created by 0.7 cannot be compared to the ones created with this patch. The strategy this patch adopts with respect to talking to 0.7 nodes is this:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;If a 0.7 node asks for a merkleTree, since we are still able to do a full compaction validation, we do it and answer with that.&lt;/li&gt;
	&lt;li&gt;Since a 0.7 node cannot do a merkleTree that would be ok for us, we simply exclude 0.7 nodes from the endpoints we ask merkleTree from.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I don&apos;t feel this is a trivially enough patch to go to the 0.7 branch.&lt;/p&gt;</comment>
                            <comment id="13014856" author="stuhood" created="Fri, 1 Apr 2011 22:24:35 +0000"  >&lt;p&gt;This change definitely makes sense: thanks for tackling it. The original implementation was intended to take advantage of naturally occurring compactions: I would still like to get in a position where that is possible, but living with the existing implementation until then isn&apos;t worth it.&lt;/p&gt;

&lt;p&gt;From a quick skim: forceTableRepair incorrectly reports that the session has failed if the client thread dies: the repair will continue in the background (or used to).&lt;/p&gt;</comment>
                            <comment id="13014866" author="stuhood" created="Fri, 1 Apr 2011 23:03:43 +0000"  >&lt;p&gt;I&apos;ll give this a more complete review over the weekend.&lt;/p&gt;</comment>
                            <comment id="13016754" author="stuhood" created="Thu, 7 Apr 2011 08:22:56 +0000"  >&lt;ul&gt;
	&lt;li&gt;SSTableBoundScanner might be much simpler if it iterates within a list of file offsets, as returned by SSTableReader.getPositionsForRanges&lt;/li&gt;
	&lt;li&gt;SSTableReader.getKeySamples could perform two binary searches for min and max rather than doing sequential comparisons to the keys&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Thanks again Sylvain: this is great!&lt;/p&gt;</comment>
                            <comment id="13017230" author="slebresne" created="Fri, 8 Apr 2011 01:29:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;SSTableBoundScanner might be much simpler if it iterates within a list of file offsets, as returned by SSTableReader.getPositionsForRanges&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Good call, that&apos;s much simpler. Thanks.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;SSTableReader.getKeySamples could perform two binary searches for min and max rather than doing sequential comparisons to the keys&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, realized getKeySamples was buggy anyway since it wasn&apos;t handling wrapping ranges correctly.&lt;/p&gt;

&lt;p&gt;Attaching patch that simplify the bounded scanner and fixes getKeySamples.&lt;/p&gt;</comment>
                            <comment id="13017274" author="stuhood" created="Fri, 8 Apr 2011 04:45:03 +0000"  >&lt;p&gt;+1&lt;br/&gt;
Thanks!&lt;/p&gt;</comment>
                            <comment id="13018124" author="slebresne" created="Sun, 10 Apr 2011 18:16:27 +0000"  >&lt;p&gt;Committed as r1090840. Thanks.&lt;/p&gt;</comment>
                            <comment id="13018132" author="hudson" created="Sun, 10 Apr 2011 18:37:30 +0000"  >&lt;p&gt;Integrated in Cassandra #844 (See &lt;a href=&quot;https://hudson.apache.org/hudson/job/Cassandra/844/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://hudson.apache.org/hudson/job/Cassandra/844/&lt;/a&gt;)&lt;br/&gt;
    Make repair work on a token range instead of the full ring&lt;br/&gt;
patch by slebresne; reviewed by stuhood for &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2324&quot; title=&quot;Repair transfers more data than necessary&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-2324&quot;&gt;&lt;del&gt;CASSANDRA-2324&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12501231">CASSANDRA-2316</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12475769" name="0001-Make-repair-operate-over-a-node-token-range-v2.patch" size="78629" author="slebresne" created="Fri, 8 Apr 2011 01:29:53 +0000"/>
                            <attachment id="12475228" name="0001-Make-repair-operate-over-a-node-token-range.patch" size="82794" author="slebresne" created="Fri, 1 Apr 2011 15:00:07 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[slebresne]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>20562</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            14 years, 33 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0gapj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>93165</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>stuhood</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[stuhood]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>