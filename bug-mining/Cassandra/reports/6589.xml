<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 23:31:18 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-20052] Size of CQL messages is not limited in V5 protocol logic</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-20052</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;Size of CQL messages is not limited in V5 protocol logic&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;After introducing of v5 frames we do not have any CQL message limit anymore, native_transport_max_frame_size_in_mb which had such limit in pre-V5 epoch is applicable now only to pre-V5 protocol sessions, otherwise it is applied only to the initial STARTUP/OPTIONS messages handling, it is not checked in any v5 logic. So, currently a v5 CQL message of any size can be sent to Cassandra server.&lt;/li&gt;
	&lt;li&gt;The overload logic just allows to process huge messages for free to avoid starvation, so it does not provide any protection against the most dangerous requests from a memory pressure point of view.&lt;/li&gt;
	&lt;li&gt;The situation even more dangerous: the v5 framing logic is enabled just after AUTH response, so we do not limit message size even for AUTH_RESPONSE messages from a client. It can be used as a DoS attack: a non-authenticated client can send a huge username/password to Cassandra server to cause troubles with GC or even kill it.&lt;br/&gt;
An easy example:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;TestBigAuthRequest {
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) {
        &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; password = getString(500_000_000, &lt;span class=&quot;code-quote&quot;&gt;&apos;-&apos;&lt;/span&gt;);
        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; (CqlSession session = CqlSession.builder()
                .addContactEndPoint(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DefaultEndPoint(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; InetSocketAddress(&lt;span class=&quot;code-quote&quot;&gt;&quot;localhost&quot;&lt;/span&gt;, 9042)))
                .withAuthCredentials(&lt;span class=&quot;code-quote&quot;&gt;&quot;cassandra&quot;&lt;/span&gt;, password)
                .withLocalDatacenter(&lt;span class=&quot;code-quote&quot;&gt;&quot;datacenter1&quot;&lt;/span&gt;)
                .build()) {
            session.execute(&lt;span class=&quot;code-quote&quot;&gt;&quot;select * from system.local&quot;&lt;/span&gt;);
        }
    }

    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; getString(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; length, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt; charToFill) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (length &amp;gt; 0) {
            &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;[] array = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;[length];
            Arrays.fill(array, charToFill);
            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;(array);
        }
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &quot;&quot;;
    }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;A thread stack of such invocation (captured to show the execution flow):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;nioEventLoopGroup-5-21@9164&quot;&lt;/span&gt; prio=10 tid=0x86 nid=NA runnable
  java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE
	  at org.apache.cassandra.transport.messages.AuthResponse$1.decode(AuthResponse.java:45)
	  at org.apache.cassandra.transport.messages.AuthResponse$1.decode(AuthResponse.java:39)
	  at org.apache.cassandra.transport.Message$Decoder.decodeMessage(Message.java:432)
	  at org.apache.cassandra.transport.Message$Decoder$RequestDecoder.decode(Message.java:467)
	  at org.apache.cassandra.transport.Message$Decoder$RequestDecoder.decode(Message.java:459)
	  at org.apache.cassandra.transport.CQLMessageHandler.processRequest(CQLMessageHandler.java:377)
	  at org.apache.cassandra.transport.CQLMessageHandler$LargeMessage.onComplete(CQLMessageHandler.java:755)
	  at org.apache.cassandra.net.AbstractMessageHandler$LargeMessage.supply(AbstractMessageHandler.java:561)
	  at org.apache.cassandra.net.AbstractMessageHandler.processSubsequentFrameOfLargeMessage(AbstractMessageHandler.java:257)
	  at org.apache.cassandra.net.AbstractMessageHandler.processIntactFrame(AbstractMessageHandler.java:229)
	  at org.apache.cassandra.net.AbstractMessageHandler.process(AbstractMessageHandler.java:216)
	  at org.apache.cassandra.transport.CQLMessageHandler.process(CQLMessageHandler.java:147)
	  at org.apache.cassandra.net.FrameDecoder.deliver(FrameDecoder.java:330)
	  at org.apache.cassandra.net.FrameDecoder.channelRead(FrameDecoder.java:294)
	  at org.apache.cassandra.net.FrameDecoder.channelRead(FrameDecoder.java:277)
	  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	  at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	  at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	  at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	  at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
	  at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
	  at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
	  at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	  at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	  at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	  at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	  at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:829)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The provided MR (&lt;a href=&quot;https://github.com/apache/cassandra/pull/3655&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/cassandra/pull/3655&lt;/a&gt;) contains a fix for the issue which introduces 2 new parameters:&lt;br/&gt;
native_transport_max_message_size - to limit any CQL message size&lt;br/&gt;
native_transport_max_auth_message_size (default = 128KiB) - to limit auth response message size more strictly and add an extra protection against a possible DoS attack.&lt;/p&gt;

&lt;p&gt;Design questions:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The current implementation closes a CQL connection if a message is bigger than the limits. A skip message body logic can be implemented to continue the connection usage but it is more complicated and error prone.&lt;/li&gt;
	&lt;li&gt;The tricky question is the default value for native_transport_max_message_size,&lt;br/&gt;
from one side - we want to have it not more than min(native_transport_max_request_data_in_flight_per_ip, native_transport_max_request_data_in_flight) to reduce chances to invoke the branch of logic when a error handling does not work&lt;br/&gt;
from another size - min(native_transport_max_request_data_in_flight_per_ip, native_transport_max_request_data_in_flight) can be too small and there is a chance to break a backward compatibility for existing deployments where people use large messages and small heaps (while it is not a good idea).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Related observations:&lt;br/&gt;
1) &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-16886&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/CASSANDRA-16886&lt;/a&gt; - Reduce native_transport_max_frame_size_in_mb (from 256M to 16M)&lt;/p&gt;

&lt;p&gt;2) A correspondent logic for Cassandra server internode protocol a message limit exists and rate limiting parameters are validated to be smaller than a single message max size:&lt;br/&gt;
internode_max_message_size = min(internode_application_receive_queue_reserve_endpoint_capacity, internode_application_send_queue_reserve_endpoint_capacity)&lt;/p&gt;

&lt;p&gt;internode_application_receive_queue_reserve_endpoint_capacity = 128MiB&lt;br/&gt;
internode_application_send_queue_reserve_endpoint_capacity = 128MiB&lt;/p&gt;

&lt;p&gt;internode_max_message_size &amp;lt;= internode_application_receive_queue_reserve_endpoint_capacity&lt;br/&gt;
internode_max_message_size &amp;lt;= internode_application_receive_queue_reserve_global_capacity&lt;br/&gt;
internode_max_message_size &amp;lt;= internode_application_send_queue_reserve_endpoint_capacity&lt;br/&gt;
internode_max_message_size &amp;lt;= internode_application_send_queue_reserve_global_capacity&lt;/p&gt;

&lt;p&gt;3) Request types according to CQL specification:&lt;br/&gt;
4.1.1. STARTUP, in normal cases should be small&lt;br/&gt;
4.1.2. AUTH_RESPONSE, in normal cases should be small&lt;br/&gt;
4.1.3. OPTIONS, in normal cases should be small&lt;br/&gt;
4.1.4. QUERY, in normal cases should be small&lt;br/&gt;
4.1.5. PREPARE, in normal cases should be small&lt;br/&gt;
4.1.6. EXECUTE &amp;lt;-- potentially large in case of inserts, max_mutation_size = commitlog_segment_size / 2; where commitlog_segment_size_in_mb = 32MiB&lt;br/&gt;
4.1.7. BATCH &amp;lt;-- potentially large, max_mutation_size = commitlog_segment_size / 2; where commitlog_segment_size_in_mb = 32MiB&lt;br/&gt;
4.1.8. REGISTER, in normal cases should be small&lt;/p&gt;</description>
                <environment></environment>
        <key id="13597673">CASSANDRA-20052</key>
            <summary>Size of CQL messages is not limited in V5 protocol logic</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dnk">Dmitry Konstantinov</assignee>
                                    <reporter username="dnk">Dmitry Konstantinov</reporter>
                        <labels>
                    </labels>
                <created>Mon, 4 Nov 2024 21:10:45 +0000</created>
                <updated>Thu, 30 Jan 2025 12:54:48 +0000</updated>
                            <resolved>Mon, 13 Jan 2025 12:05:42 +0000</resolved>
                                        <fixVersion>4.1.8</fixVersion>
                    <fixVersion>5.0.3</fixVersion>
                    <fixVersion>5.1</fixVersion>
                                    <component>Messaging/Client</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="18000">5h</timespent>
                                <comments>
                            <comment id="17895433" author="dnk" created="Mon, 4 Nov 2024 21:34:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=samt&quot; class=&quot;user-hover&quot; rel=&quot;samt&quot;&gt;samt&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict&quot; class=&quot;user-hover&quot; rel=&quot;benedict&quot;&gt;benedict&lt;/a&gt; - could you please help with a review if you have time.&lt;/p&gt;</comment>
                            <comment id="17895563" author="benedict" created="Tue, 5 Nov 2024 10:36:40 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dnk&quot; class=&quot;user-hover&quot; rel=&quot;dnk&quot;&gt;dnk&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;This looks like an important patch, and one I&apos;m happy to see you contribute - and a quick skim suggests it is reasonable. Unfortunately, I think this requires a greater-than-passing familiarity with the client server-side logic to ensure everything is correct, and I don&apos;t really have the time to familiarise myself. Sam would be the perfect reviewer, but if he&apos;s not free I&apos;ll see if I can help find somebody with more time and/or familiarity.&lt;/p&gt;</comment>
                            <comment id="17895574" author="dnk" created="Tue, 5 Nov 2024 12:00:33 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict&quot; class=&quot;user-hover&quot; rel=&quot;benedict&quot;&gt;benedict&lt;/a&gt; thank you for your answer!&lt;br/&gt;
Probably &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maedhroz&quot; class=&quot;user-hover&quot; rel=&quot;maedhroz&quot;&gt;maedhroz&lt;/a&gt; can be a good option as well.&lt;/p&gt;</comment>
                            <comment id="17895667" author="beobal" created="Tue, 5 Nov 2024 15:48:18 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dnk&quot; class=&quot;user-hover&quot; rel=&quot;dnk&quot;&gt;dnk&lt;/a&gt;. Thanks for raising this, I agree that it is a potential problem but it seems to me that the existing mechanisms should &lt;em&gt;almost&lt;/em&gt; be enough to guard against it, I think it&apos;s mainly that there are bugs in the implementation. I&apos;ll come back to the point raised in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-16886&quot; title=&quot;Reduce native_transport_max_frame_size_in_mb&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-16886&quot;&gt;&lt;del&gt;CASSANDRA-16886&lt;/del&gt;&lt;/a&gt; in a moment.&lt;/p&gt;

&lt;p&gt;The core of the problem is the behaviour with large messages where we always try to consume the entire message to avoid blocking the client. In &lt;tt&gt;processFirstFrameOfLargeMessage&lt;/tt&gt;, regardless of the &lt;tt&gt;throwOnOverload&lt;/tt&gt; setting, if we cannot acquire capacity to process the entire message, we buffer the initial frame by calling &lt;tt&gt;largeMessage.supply&lt;/tt&gt; and return &lt;tt&gt;true&lt;/tt&gt; to indicate that the pipeline should continue to read bytes from netty buffers. Subsequent frames of the message are then read and also buffered without any further checking, all of which seems obviously incorrect.&lt;/p&gt;

&lt;p&gt;If we fail to acquire capacity for the entire message when processing the first frame, perhaps it would be better to mark the &lt;tt&gt;LargeMessage&lt;/tt&gt; to indicate this and have it not do the buffering. Essentially, always throw an overloaded exception in this case, but also to override &lt;tt&gt;supply&lt;/tt&gt; in &lt;tt&gt;CQLMessageHandler.LargeMessage&lt;/tt&gt; so we can continue to consume from the netty buffers but don&apos;t call &lt;tt&gt;onIntactFrame&lt;/tt&gt; if marked in this way.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-16886&quot; title=&quot;Reduce native_transport_max_frame_size_in_mb&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-16886&quot;&gt;&lt;del&gt;CASSANDRA-16886&lt;/del&gt;&lt;/a&gt; makes the valid point that it is beneficial to filter out mutations which can never be applied because they are too large for the commit log as early as possible. We could incorporate this protection by treating this in the same way as a failure to acquire capacity, i.e. consume the remaining frames of the large message but drop them and return an error when done. This could be a check of the total message size from the header against &lt;tt&gt;Envelope.Decoder.MAX_TOTAL_LENGTH&lt;/tt&gt; (which is taken directly from &lt;tt&gt;DatabaseDescriptor::getNativeTransportMaxFrameSize&lt;/tt&gt;) or even against &lt;tt&gt;IMutation.MAX_MUTATION_SIZE&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;For small messages I don&apos;t think the same problem exists given the 128KiB hard limit on the size of a frame payload, so I&apos;m not sure any changes to &lt;tt&gt;processOneContainedMessage&lt;/tt&gt; should be necessary.&lt;/p&gt;</comment>
                            <comment id="17896467" author="dnk" created="Thu, 7 Nov 2024 20:40:08 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=samt&quot; class=&quot;user-hover&quot; rel=&quot;samt&quot;&gt;samt&lt;/a&gt;&#160;&lt;br/&gt;
Thank you for your answer!&lt;/p&gt;

&lt;p&gt;Please find my comments below.&lt;/p&gt;

&lt;p&gt;note: In the comments I refer to internode messaging logic several times for the following reason: client messaging and internode messaging have a common part (AbstractMessageHandler); internode messaging has a max message size check already, so for consistency I was trying to use the same approach and configuration style for client messaging as we have in internode messaging.&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;&lt;p&gt;it seems to me that the existing mechanisms should almost be enough to guard against it, I think it&apos;s mainly that there are bugs in the implementation.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I would slightly differentiate the cases:&lt;br/&gt;
1) rate limiting - we want to apply a back-pressure to a message flow, ideally in a transparent way (without errors) for application developers. Even in case of throwOnOverload = false the request it also expected as valid and retryable (normally a driver/client expects to do a retry later).&lt;/p&gt;

&lt;p&gt;2) max message size limit - we want to protect our server from an incorrect, potentially dangerous request and such request will not be consider later as valid in case of a retry. Here we want to fail and fail as early as possible to reduce amount of resources we spend for such requests.&lt;/p&gt;

&lt;p&gt;So, yes, some existing code infrastructure definitely can and should be re-used here but I am not sure if considering max message size limit as a special case of existing rate limiting is the best way, especially taking in account that the current rate limiting logic (throwOnOverload = false) is more a post-processing action while the message size limit is a pre-processing action.&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;&lt;p&gt;The core of the problem is the behaviour with large messages where we always try to consume the entire message to avoid blocking the client. In processFirstFrameOfLargeMessage, regardless of the throwOnOverload setting, if we cannot acquire capacity to process the entire message, we buffer the initial frame by calling largeMessage.supply and return true to indicate that the pipeline should continue to read bytes from netty buffers. Subsequent frames of the message are then read and also buffered without any further checking, all of which seems obviously incorrect.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I agree. Here is a diagram which I reverse-engineered from the source code some time ago. I am focusing on throwOnOverload = false branch because it is the default and mostly commonly used mode (if I remember correctly DataStax Java driver even does not support properly throwOnOverload = true mode but it can be out of date memories).&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/13072689/13072689_cassandra_rate_limit.svg&quot; title=&quot;cassandra_rate_limit.svg attached to CASSANDRA-20052&quot;&gt;cassandra_rate_limit.svg&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The tricky thing with the current rate limiting logic is that we read frames to memory first and only then we decide if we need to apply a back-pressure (so, it is applied to the next messages not the current one). As we have the current CQL message already loaded into memory the best that the current logic can do is to continue to process it. It works ok for small messages (the impact of passing through a small message is neglectable) but it can be an issue for large ones. Ideally we should read a message length first and then decide - do we have a capacity to process it but introducing frames makes it quite complicated to implement, so we read frames first and then decide what to do.&lt;/p&gt;

&lt;p&gt;As I see in the commit history: &lt;a href=&quot;https://github.com/beobal/cassandra/commit/0aae5b4921a3ce6c21a8a0e977624c877b19cd5b&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/beobal/cassandra/commit/0aae5b4921a3ce6c21a8a0e977624c877b19cd5b&lt;/a&gt;&lt;br/&gt;
originally we tried to pause the connection even for large messages but it causes starvation and the logic was changed to avoid it by sacrificing rate limiting logic itself.&lt;br/&gt;
Recently &quot;Could not aquire capacity while processing native protocol message&quot; error message has been added to this problematic branch as a part of &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-19534&quot; title=&quot;Unbounded queues in native transport requests lead to node instability&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-19534&quot;&gt;&lt;del&gt;CASSANDRA-19534&lt;/del&gt;&lt;/a&gt; but the logic itself is the same.&lt;/p&gt;

&lt;p&gt;Introducing a message limit should help to reduce the probability of this branch invocation but I think it will not help to avoid it completely without extra changes in rate limiting logic itself (because we may hit the same case when we receive several large enough messages each one smaller than a limit). Probably, if we have already checked and the message limit &amp;lt; min(native_transport_max_request_data_in_flight_per_ip, native_transport_max_request_data_in_flight) then we can stop to afraid the starvation and can start using pause connections again.&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;&lt;p&gt;If we fail to acquire capacity for the entire message when processing the first frame, perhaps it would be better to mark the LargeMessage to indicate this and have it not do the buffering. Essentially, always throw an overloaded exception in this case, but also to override supply in CQLMessageHandler.LargeMessage so we can continue to consume from the netty buffers but don&apos;t call onIntactFrame if marked in this way.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;We could incorporate this protection by treating this in the same way as a failure to acquire capacity, i.e. consume the remaining frames of the large message but drop them and return an error when done.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I was thinking about this &quot;skipping large message&quot; approach (it is similar to the legacy handler logic - org.apache.cassandra.transport.Envelope.Decoder#decode). &lt;br/&gt;
I am not sure if throwing overloaded exception exception is good response for message max size check - this exception/error response to a client is assumed as retryable while the message limit is a permanent failure. Probably we need to use here InvalidRequestException as we do in the legacy handler logic..&lt;/p&gt;

&lt;p&gt;I have not selected initially &quot;skipping large message&quot; way due to the following reasons:&lt;br/&gt;
1) it is more complicated and correspondently more error prone&lt;br/&gt;
2) there is no such logic in internode messaging code for the same use case&lt;/p&gt;

&lt;p&gt;At the same time I see an extra benefit for the skip logic: we will be able to complete and not to drop other normal in-fligh requests received from the same channel before if we do not close the channel after receiving of a too large message as I am doing now.&lt;br/&gt;
I will try to update my MR to add the skip logic.&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-16886&quot; title=&quot;Reduce native_transport_max_frame_size_in_mb&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-16886&quot;&gt;&lt;del&gt;CASSANDRA-16886&lt;/del&gt;&lt;/a&gt; makes the valid point that it is beneficial to filter out mutations which can never be applied because they are too large for the commit log as early as possible.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I agree, this is why I mentioned this ticket and related max_mutation_size parameter here.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This could be a check of the total message size from the header against Envelope.Decoder.MAX_TOTAL_LENGTH (which is taken directly from DatabaseDescriptor::getNativeTransportMaxFrameSize) or even against IMutation.MAX_MUTATION_SIZE.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I suppose an explicit parameter would be more useful:&lt;br/&gt;
1) it is less confusing: DatabaseDescriptor::getNativeTransportMaxFrameSize can be mixed up by users with V5 frame size due to a similar name.&lt;br/&gt;
2) it will give more flexibility for users if they want to tune the parameter&lt;/p&gt;

&lt;p&gt;Also, I think having a separate stricter limit for authentication messages is better from security point of view.&lt;/p&gt;

&lt;p&gt;At the same time I agree that it makes sense to consider IMutation.MAX_MUTATION_SIZE for a default value.&lt;br/&gt;
Currently I use the rate limit threshold native_transport_max_request_data_in_flight_per_ip as a default value for the following reasons:&lt;br/&gt;
1) To reduce the probability to get into that problematic branch of rate limiting logic&lt;br/&gt;
2) To align the logic with internode messaging which does the same&lt;/p&gt;

&lt;p&gt;Probably, the default value for this property should be like: min(max_mutation_size, native_transport_max_request_data_in_flight_per_ip, native_transport_max_request_data_in_flight).&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;&lt;p&gt;For small messages I don&apos;t think the same problem exists given the 128KiB hard limit on the size of a frame payload, so I&apos;m not sure any changes to processOneContainedMessage should be necessary.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I have the following thoughts in my mind when I added this check into processOneContainedMessage logic:&lt;br/&gt;
1) while normal CQL message check is definitely is not needed here - it maybe good to still check auth (AUTH_RESPONSE) message size here if somebody will set the limit for it low enough to get additional protection (less than a max frame size = 128KiB).&lt;br/&gt;
2) code symmetry to keep message processing for large and small messages as close as possible, similar logic in internode messaging actually does same kind of message size check in both branches.&lt;/p&gt;

&lt;p&gt;But I agree that it is not so needed and I am going to remove it to cause less questions.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;So, in total I am planning to apply the following changes in the MR (&lt;a href=&quot;https://github.com/apache/cassandra/pull/3655):&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/cassandra/pull/3655):&lt;/a&gt;&lt;br/&gt;
1) remove size check in processOneContainedMessage&lt;br/&gt;
2) add &quot;skipping large message&quot; logic instead of throwing a fatal error to close the channel&lt;br/&gt;
3) set default value for native_transport_max_message_size as min(max_mutation_size, native_transport_max_request_data_in_flight_per_ip, native_transport_max_request_data_in_flight)&lt;/p&gt;

&lt;p&gt;Please give me know what do you think about it?&lt;/p&gt;</comment>
                            <comment id="17896682" author="beobal" created="Fri, 8 Nov 2024 14:38:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;&#160;The tricky thing with the current rate limiting logic is that we read frames to memory first and only then we decide if we need to apply a back-pressure&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, what I was trying to say was that we &lt;b&gt;do&lt;/b&gt; know the size of the entire message when we have read the first frame but in the large message case, but if we don&apos;t have capacity for it we read and buffer the subsequent frames anyway. Then we may or may not process the message, depending on &lt;tt&gt;throwOnOverload&lt;/tt&gt; and/or whether rate limiting was also triggered by the number of requests in flight or the queue time.&#160;&lt;br/&gt;
My intention was to suggest that instead of doing that, if we don&apos;t have capacity to process the entire message we should just read &lt;b&gt;but not buffer&lt;/b&gt; the subsequent frames and then return an error response and not do &lt;em&gt;anything&lt;/em&gt; else. You&apos;re right that &lt;tt&gt;OverloadedException&lt;/tt&gt; may not be the right error if this signals to clients that they should retry again later. If that&apos;s the case then maybe we should use a generic &lt;tt&gt;InvalidRequestException&lt;/tt&gt;.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;introducing frames makes it quite complicated to implement&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t quite see why though, it&apos;s exactly the same as the &lt;tt&gt;throwOnOverload&lt;/tt&gt; case. We know by reading the first frame that we are overloaded so we decide we won&apos;t process the message and set a flag to that effect right away (we should just release &#160;the subsequent frames as we read them). How is this different? I&apos;m just saying we should do that regardless of &lt;tt&gt;throwOnOverload.&lt;/tt&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Introducing a message limit should help to reduce the probability of this branch invocation but I think it will not help to avoid it completely without extra changes in rate limiting logic itself (because we may hit the same case when we receive several large enough messages each one smaller than a limit).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;After the &lt;tt&gt;acquireCapacity&lt;/tt&gt; check, rate limiting is based on request rate/time in queue and not on message size, so I don&apos;t see what you mean here. If we receive a stream of large messages, we&apos;ll process them until we cannot acquire capacity and then we&apos;ll start rejecting them (assuming we implement what I said in the previous paragraphs). Rate limiting doesn&apos;t really come into it at this point.&lt;/p&gt;

&lt;p&gt;However, I &lt;b&gt;do&lt;/b&gt; think we should extend the &lt;tt&gt;acquireCapacity&lt;/tt&gt; check to also ensure that &lt;tt&gt;messageSize &amp;lt;= IMutation.MAX_MUTATION_SIZE&lt;/tt&gt;. If either condition evaluates to false, then we don&apos;t want to process that message.&lt;br/&gt;
e.g.&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!acquireCapacity(header, endpointReserve, globalReserve) || messageSize &amp;gt; IMutation.MAX_MUTATION_SIZE)
&#160; &#160; &#160; &#160; &#160; &lt;span class=&quot;code-comment&quot;&gt;// read subsequent frames, but don&apos;t buffer them. 
&lt;/span&gt;          &lt;span class=&quot;code-comment&quot;&gt;// When done, &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; error response (either OverloadedException 
&lt;/span&gt;          &lt;span class=&quot;code-comment&quot;&gt;// or InvalidRequestException, depending on connection config).&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I am mostly trying to understand whether there&apos;s a valid reason to introduce another configuration option specifically for max message size. If the server has capacity to process a message and any mutations in it are within the acceptable size boundaries, do we really need another setting in yaml?&lt;/p&gt;</comment>
                            <comment id="17896722" author="dnk" created="Fri, 8 Nov 2024 16:27:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;I don&apos;t quite see why though, it&apos;s exactly the same as the throwOnOverload case. We know by reading the first frame that we are overloaded so we decide we won&apos;t process the message and set a flag to that effect right away (we should just release &#160;the subsequent frames as we read them). How is this different? I&apos;m just saying we should do that regardless of throwOnOverload.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I meant the legacy logic which we had before frames concepts introduction. Currently we have them and the frames are read and processed in 2 steps:&lt;br/&gt;
1) we read frames from channel, parse them and accumulate them in org.apache.cassandra.net.FrameDecoder#frames to process later&lt;br/&gt;
2) when we process accumulated frames to extract messages from them (org.apache.cassandra.net.FrameDecoder#deliver)&lt;br/&gt;
So, at the moment when we parse the first frame as a part of a message extracting, you may have many frames read from the channel and stored in memory (limited by the amount of data Netty allows to read in one event loop round).&lt;/p&gt;

&lt;p&gt;In any case it is not a blocker to implement that you are suggesting, it was just a side note.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;After the&#160;&lt;tt&gt;acquireCapacity&lt;/tt&gt;&#160;check, rate limiting is based on request rate/time in queue and not on message size, so I don&apos;t see what you mean here. If we receive a stream of large messages, we&apos;ll process them until we cannot acquire capacity and then we&apos;ll start rejecting them (assuming we implement what I said in the previous paragraphs). Rate limiting doesn&apos;t really come into it at this point&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;I am mostly trying to understand whether there&apos;s a valid reason to introduce another configuration option specifically for max message size. If the server has capacity to process a message and any mutations in it are within the acceptable size boundaries, do we really need another setting in yaml?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Let me use an example to explain my concerns. Let&apos;s assume the following configuration:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;native_transport_max_request_data_in_flight = 256 MiB (for example, we have 2560 MiB heap)&lt;/li&gt;
	&lt;li&gt;native_transport_receive_queue_capacity = 1MiB (default)&lt;/li&gt;
	&lt;li&gt;native_transport_max_request_data_in_flight_per_ip - for simplicity lets forget about this limit for a while&lt;/li&gt;
	&lt;li&gt;max_mutation_size = 32 MiB&lt;/li&gt;
	&lt;li&gt;&lt;ins&gt;throwOnOverload = false&lt;/ins&gt; (the default mode which I suppose almost everybody uses..)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;1st case:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;a client sent 1 large message with size = 512 MiB. It is bigger total rate limit/capacity (native_transport_max_request_data_in_flight + native_transport_receive_queue_capacity) or max_mutation_size.&lt;/li&gt;
	&lt;li&gt;expected behaviour: return to the client a error (InvalidRequestException/the message is too big)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;2nd case:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;a client sent 1 large message with size = 64 MiB. It is less than total rate limit but bigger than max_mutation_size.&lt;/li&gt;
	&lt;li&gt;expected behaviour: return to the client a error (InvalidRequestException/the message is too big)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;3rd case:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;a client (or several clients) sent 32 messages with size = 16 MiB. Our total capacity = native_transport_max_request_data_in_flight + native_transport_receive_queue_capacity = 257 MiB, so&#160; we can acquire capacity for 16 messages (16 x 16 MiB) to consume the limit (1 MiB is remaining). For remaining 16 messages we want to pause processing and resume it when the in-flight messages will be processed and some acquire capacity will be released. We do not want to return an error for any of the 32 messages in this case.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So, for me the cases are different:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;1st and 2nd case: max message size limit - protection by rejecting early&lt;/li&gt;
	&lt;li&gt;3rd case: rate limiting - by flow control/back-pressure&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;By implementing logic using the mentioned approach:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!acquireCapacity(header, endpointReserve, globalReserve) || messageSize &amp;gt; IMutation.MAX_MUTATION_SIZE)
&#160; &#160; &#160; &#160; &#160; &lt;span class=&quot;code-comment&quot;&gt;// read subsequent frames, but don&apos;t buffer them. 
&lt;/span&gt;          &lt;span class=&quot;code-comment&quot;&gt;// When done, &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; error response (either OverloadedException 
&lt;/span&gt;          &lt;span class=&quot;code-comment&quot;&gt;// or InvalidRequestException, depending on connection config). &lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;we will make rate limiting failing for 3rd case while the expectation I suppose for this case is not to do it. Also for such if condition acquireCapacity may return true and when we will have to return it back, so the message size check should be done before acquireCapacity invocation.&lt;/p&gt;</comment>
                            <comment id="17896734" author="beobal" created="Fri, 8 Nov 2024 17:20:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;we will make rate limiting failing for 3rd case while the expectation I suppose for this case is not to do it&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I was expecting in the 3rd case to behave like the 1st and 2nd cases once we have consumed all the capacity with the first 16 messages.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;the message size check should be done before acquireCapacity invocation&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;unless we were to call &lt;tt&gt;handleErrorAndRelease&lt;/tt&gt; to send the error like we do for overloaded - but you are right, it&apos;s way simpler to just do those checks in the correct order.&lt;/p&gt;</comment>
                            <comment id="17897258" author="dnk" created="Mon, 11 Nov 2024 19:17:15 +0000"  >&lt;blockquote&gt;&lt;p&gt;I was expecting in the 3rd case to behave like the 1st and 2nd cases once we have consumed all the capacity with the first 16 messages.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;but is it a violation of basic (throwOnOverload = false) rate limiting semantic if we start to fail requests when we consume all capacity? My impression is that the whole idea of (throwOnOverload = false) rate limiting is not to throw exceptions as a way to limit the rate. For me there is no big difference between 32 &quot;large&quot; messages of 16 MiB,&#160; &#160;32 x 16 still &quot;large&quot; messages of 1 MiB and 8 x 32 x 16 &quot;small&quot; messages of 128 KiB .. Throwing of OverloadedException for some valid message sizes and not throwing it for others will be confusing for users (who actually expect not throwing OverloadedException at all) ..&lt;/p&gt;

&lt;p&gt;-------------------&lt;/p&gt;

&lt;p&gt;If we want to fix the rate limiting logic as well (actually it was not an intention for my PR originally, I wanted to solve the issues one by one &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;) then what is about the following approach?:&#160;&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Initially we check the message size against min(max_mutation_size, native_transport_max_request_data_in_flight_per_ip, native_transport_max_request_data_in_flight). If it is bigger - we raise InvalidRequestException error and skip the message.&lt;/li&gt;
	&lt;li&gt;Then we try to acquireCapacity(header, endpointReserve, globalReserve) and if it returns false - then we return false from processFirstFrameOfLargeMessage to pause the connection (actually to return back to the way how it was done before &lt;a href=&quot;https://github.com/beobal/cassandra/commit/0aae5b4921a3ce6c21a8a0e977624c877b19cd5b#diff-8e8dd0c6394bca7f4ac929d4b1471bd8877b222af1d48b2ebac331d458326de2R340&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/beobal/cassandra/commit/0aae5b4921a3ce6c21a8a0e977624c877b19cd5b#diff-8e8dd0c6394bca7f4ac929d4b1471bd8877b222af1d48b2ebac331d458326de2R340&lt;/a&gt;).&lt;br/&gt;
The difference with the old logic - we are sure now that the message size &amp;lt;= native_transport_max_request_data_in_flight_per_ip and native_transport_max_request_data_in_flight, so a starvation is not possible for the following case: a connection is blocked forever if somebody tries to send a single too big message &amp;gt; total capacity. Once other messages in the same or other CQL connections are processed and capacity is returned to the limits - we are sure that there is enough capacity to acquire it for the current large message ..&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17897466" author="beobal" created="Tue, 12 Nov 2024 11:14:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;what is about the following approach?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That sounds entirely reasonable to me, I think the addition of the fast failure/rejection in step 1 improves things greatly.&lt;/p&gt;</comment>
                            <comment id="17897471" author="dnk" created="Tue, 12 Nov 2024 11:20:29 +0000"  >&lt;p&gt;Good!, then I am starting to prepare a new version of MR based on the discussions&lt;/p&gt;</comment>
                            <comment id="17898884" author="dnk" created="Sat, 16 Nov 2024 15:22:36 +0000"  >&lt;p&gt;I have updated &lt;a href=&quot;https://github.com/apache/cassandra/pull/3655&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/cassandra/pull/3655&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17901252" author="beobal" created="Tue, 26 Nov 2024 16:18:56 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dnk&quot; class=&quot;user-hover&quot; rel=&quot;dnk&quot;&gt;dnk&lt;/a&gt;, I&apos;ve left some comments on the PR&lt;/p&gt;</comment>
                            <comment id="17901263" author="dnk" created="Tue, 26 Nov 2024 17:17:58 +0000"  >&lt;p&gt;Thank you!, checking&lt;/p&gt;</comment>
                            <comment id="17901565" author="dnk" created="Wed, 27 Nov 2024 19:21:09 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=samt&quot; class=&quot;user-hover&quot; rel=&quot;samt&quot;&gt;samt&lt;/a&gt;, I have applied the changes to address your comments, could you please take a look?&lt;br/&gt;
I am working on additional unit tests.&lt;/p&gt;</comment>
                            <comment id="17901969" author="beobal" created="Fri, 29 Nov 2024 18:17:52 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dnk&quot; class=&quot;user-hover&quot; rel=&quot;dnk&quot;&gt;dnk&lt;/a&gt;, sorry for the delay in getting to this. It looks pretty good now, I&apos;ll take a deeper pass at it early next week and run it through CI.  &lt;/p&gt;</comment>
                            <comment id="17902175" author="dnk" created="Mon, 2 Dec 2024 06:48:05 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=samt&quot; class=&quot;user-hover&quot; rel=&quot;samt&quot;&gt;samt&lt;/a&gt;, no worries, please take your time, thank you for helping with the fix review.&lt;/p&gt;</comment>
                            <comment id="17902599" author="beobal" created="Tue, 3 Dec 2024 11:43:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dnk&quot; class=&quot;user-hover&quot; rel=&quot;dnk&quot;&gt;dnk&lt;/a&gt;, the PR looks almost ready to merge, but there are a few related failures in the attached CI results. I haven&apos;t investigated them properly, but I think the modified logic is now causing request failures due to exceeding max message size rather than for the reasons expected by those tests. &lt;br/&gt;
I also left one minor refactoring suggestion, if you wouldn&apos;t mind taking a look.  &lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/13073174/13073174_ci_summary.html&quot; title=&quot;ci_summary.html attached to CASSANDRA-20052&quot;&gt;ci_summary.html&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt; &lt;/p&gt;</comment>
                            <comment id="17902761" author="dnk" created="Tue, 3 Dec 2024 20:06:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=samt&quot; class=&quot;user-hover&quot; rel=&quot;samt&quot;&gt;samt&lt;/a&gt; thank you for the update, I have applied the suggestion and checking now the failing tests.&lt;/p&gt;</comment>
                            <comment id="17902762" author="dnk" created="Tue, 3 Dec 2024 20:30:03 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I think the modified logic is now causing request failures due to exceeding max message size rather than for the reasons expected by those tests&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes, the tests are trying to emulate an overload use case by sending a single large message and facing the new message limit check. I am trying to find a way to adjust the tests to preserve the original logic expected to be tested.&lt;/p&gt;</comment>
                            <comment id="17902766" author="dnk" created="Tue, 3 Dec 2024 21:14:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=samt&quot; class=&quot;user-hover&quot; rel=&quot;samt&quot;&gt;samt&lt;/a&gt; I have submitted a fix for the failing tests by adjusting the tests logic: instead of just sending a single huge message to trigger an overload I have consumed initially some endpoint/global capacity to emulate another concurrent CQL message to cross the limits in total.&lt;/p&gt;</comment>
                            <comment id="17903617" author="beobal" created="Fri, 6 Dec 2024 10:40:29 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dnk&quot; class=&quot;user-hover&quot; rel=&quot;dnk&quot;&gt;dnk&lt;/a&gt;, that PR looks pretty much ready to merge. I&apos;ll re-run CI for 4.1 and do the same for 5.0/trunk. &lt;/p&gt;</comment>
                            <comment id="17904190" author="beobal" created="Mon, 9 Dec 2024 15:28:31 +0000"  >&lt;p&gt;The 5.0 and trunk merges were pretty trivial and the CI for both is clean (the dependency check failed as it couldn&apos;t reach maven central, but that is not related to this).&lt;br/&gt;
The 4.1 CI is running now and I expect that to also be clean. &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maedhroz&quot; class=&quot;user-hover&quot; rel=&quot;maedhroz&quot;&gt;maedhroz&lt;/a&gt; has kindly offered to give us a second review.&lt;/p&gt;</comment>
                            <comment id="17904204" author="dnk" created="Mon, 9 Dec 2024 15:57:29 +0000"  >&lt;p&gt;Thank you for the update&lt;/p&gt;</comment>
                            <comment id="17904870" author="maedhroz" created="Wed, 11 Dec 2024 17:24:35 +0000"  >&lt;p&gt;Going to try to get up to speed and review this by early next week. Thanks for your patience...&lt;/p&gt;</comment>
                            <comment id="17910350" author="dnk" created="Mon, 6 Jan 2025 18:13:53 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maedhroz&quot; class=&quot;user-hover&quot; rel=&quot;maedhroz&quot;&gt;maedhroz&lt;/a&gt;, could you please take a look then you have some time&lt;/p&gt;</comment>
                            <comment id="17910467" author="maedhroz" created="Tue, 7 Jan 2025 02:09:04 +0000"  >&lt;p&gt;Apologies for the delay. Just got back from winter break today. Will look at the patch this week...&lt;/p&gt;</comment>
                            <comment id="17910784" author="maedhroz" created="Tue, 7 Jan 2025 19:43:22 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Just fired a couple nits into the PR, but LGTM&lt;/p&gt;</comment>
                            <comment id="17911960" author="dnk" created="Fri, 10 Jan 2025 13:15:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=samt&quot; class=&quot;user-hover&quot; rel=&quot;samt&quot;&gt;samt&lt;/a&gt; &#160;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maedhroz&quot; class=&quot;user-hover&quot; rel=&quot;maedhroz&quot;&gt;maedhroz&lt;/a&gt; it looks like we have the review phase passed. Could you please help with CI running/merging if possible or please give me know if I need to find somebody else for it..&lt;/p&gt;</comment>
                            <comment id="17911967" author="beobal" created="Fri, 10 Jan 2025 13:27:16 +0000"  >&lt;p&gt;I&apos;ve run CI against 4.1/5.0/trunk &amp;amp; the results are already attached. I&apos;ll rebase and re-run them, then if all still looks good (as I expect it will) I&apos;ll merge.&lt;/p&gt;</comment>
                            <comment id="17911969" author="dnk" created="Fri, 10 Jan 2025 13:30:39 +0000"  >&lt;p&gt;Got it, thank you a lot!&lt;/p&gt;</comment>
                            <comment id="17912472" author="beobal" created="Mon, 13 Jan 2025 12:02:59 +0000"  >&lt;p&gt;The merges to 5.0/trunk were mostly trivial and the CI looks generally decent.&lt;/p&gt;

&lt;p&gt;On 4.1 &lt;a href=&quot;https://github.com/beobal/cassandra/tree/samt/20052-4.1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;branch&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;2 JVM dtest failures for &lt;tt&gt;testForcedNormalRepairWithOneNodeDown&lt;/tt&gt; are &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-18440&quot; title=&quot;Test failure: org.apache.cassandra.distributed.test.RepairTest.testForcedNormalRepairWithOneNodeDown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-18440&quot;&gt;&lt;del&gt;CASSANDRA-18440&lt;/del&gt;&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;3 python dtest/upgrade failures seem unrelated&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;On 5.0 &lt;a href=&quot;https://github.com/beobal/cassandra/tree/samt/20052-5.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;branch&lt;/a&gt;: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;JVM dtests looks like &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-18440&quot; title=&quot;Test failure: org.apache.cassandra.distributed.test.RepairTest.testForcedNormalRepairWithOneNodeDown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-18440&quot;&gt;&lt;del&gt;CASSANDRA-18440&lt;/del&gt;&lt;/a&gt; again&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;On trunk &lt;a href=&quot;https://github.com/beobal/cassandra/tree/samt/20052-trunk&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;branch&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;2 python dtest failures; &lt;tt&gt;test_compaction_throughput&lt;/tt&gt; is &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-20148&quot; title=&quot;Test failure: compaction_test.py::TestCompaction::test_compaction_throughput &quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-20148&quot;&gt;&lt;del&gt;CASSANDRA-20148&lt;/del&gt;&lt;/a&gt;. &lt;tt&gt;test_cqlsh_copy.py::TestCqlshCopy::test_round_trip_with_rate_file&lt;/tt&gt; seems unrelated and passes locally.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="17912479" author="beobal" created="Mon, 13 Jan 2025 12:08:36 +0000"  >&lt;p&gt;Committed, thanks for all the good work &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dnk&quot; class=&quot;user-hover&quot; rel=&quot;dnk&quot;&gt;dnk&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17912480" author="dnk" created="Mon, 13 Jan 2025 12:17:54 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=samt&quot; class=&quot;user-hover&quot; rel=&quot;samt&quot;&gt;samt&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maedhroz&quot; class=&quot;user-hover&quot; rel=&quot;maedhroz&quot;&gt;maedhroz&lt;/a&gt; for all your help&lt;/p&gt;</comment>
                            <comment id="17922351" author="JIRAUSER304687" created="Thu, 30 Jan 2025 12:07:25 +0000"  >&lt;p&gt;Hello! &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dnk&quot; class=&quot;user-hover&quot; rel=&quot;dnk&quot;&gt;dnk&lt;/a&gt;&#160; can you please add this new configuration parameters to config file cassandra.yaml and to web documentation &lt;a href=&quot;https://cassandra.apache.org/doc/stable/cassandra/configuration/cass_yaml_file.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;page&lt;/a&gt;? This changes are non trivial and little bit hard to understand, thanks! The most important question - Is default values of this parameters are not be broken existing highload clusters behavior?&lt;/p&gt;</comment>
                            <comment id="17922359" author="dnk" created="Thu, 30 Jan 2025 12:30:40 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=m.sherstyuk&quot; class=&quot;user-hover&quot; rel=&quot;m.sherstyuk&quot;&gt;m.sherstyuk&lt;/a&gt;, JFI, we have an on-going dev group discussion now about Config.java parameters documenting in general: &lt;a href=&quot;https://lists.apache.org/thread/ror3ynqthssf4yghq3o2hlbd9jyx8y0l&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://lists.apache.org/thread/ror3ynqthssf4yghq3o2hlbd9jyx8y0l&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As a part of the current ticket the following single parameter was added to cassandra.yaml: &lt;em&gt;native_transport_max_message_size&lt;/em&gt;&lt;br/&gt;
the default value for it:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
min(
  max_mutation_size,
  native_transport_max_request_data_in_flight,
  native_transport_max_request_data_in_flight_per_ip
)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
max_mutation_size &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; = commitlog_segment_size / 2 = 32MiB / 2 = 16 MiB
native_transport_max_request_data_in_flight &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; = Xmx/10
native_transport_max_request_data_in_flight_per_ip &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; = Xmx/40&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;so, if Xmx &amp;gt;= 1024M then native_transport_max_message_size by default will be 16 MiB. Taking in account what in any case such big messages will be rejected during a mutation creation - the default is not more restrictive than the older logic implicitly had, we just start to fail earlier.&lt;/p&gt;

&lt;p&gt;Regarding impact on existing highload clusters, I did not notice an impact from this change in synthetic stress test cases (like the test mentioned here &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-20165&quot; title=&quot;Reduce memory allocation in Cassandra write path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-20165&quot;&gt;CASSANDRA-20165&lt;/a&gt;) but if a processing of messages takes more time - it may be an impact from fixing of rate limiting logic introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-15013&quot; title=&quot;Prevent client requests from blocking on executor task queue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-15013&quot;&gt;&lt;del&gt;CASSANDRA-15013&lt;/del&gt;&lt;/a&gt;. Before the current ticket the actual rate limiting was not applied in cases when messages are more than a frame size = 131071 bytes and the amount of in-flight messages could be higher than expected and defined by native_transport_max_request_data_in_flight/native_transport_max_request_data_in_flight_per_ip. &lt;br/&gt;
If you face such case you can mitigate it by increasing native_transport_max_request_data_in_flight/native_transport_max_request_data_in_flight_per_ip values if you feel that it is ok to give more memory for in-flight messages (be careful, it can cause an OOM if you relax the thresholds too much).&lt;/p&gt;</comment>
                            <comment id="17922368" author="JIRAUSER304687" created="Thu, 30 Jan 2025 12:54:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dnk&quot; class=&quot;user-hover&quot; rel=&quot;dnk&quot;&gt;dnk&lt;/a&gt; awesome, wii be great to see all 112 missing parameters in config yaml file and please not forget to add description to &lt;a href=&quot;https://cassandra.apache.org/doc/stable/cassandra/configuration/cass_yaml_file.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;official documentation page&lt;/a&gt;. About &lt;em&gt;native_transport_max_message_size&lt;/em&gt; - i got it thanks!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="13072689" name="cassandra_rate_limit.svg" size="91157" author="dnk" created="Thu, 7 Nov 2024 20:26:33 +0000"/>
                            <attachment id="13073944" name="ci_summary-4.1.html" size="33685" author="samt" created="Mon, 13 Jan 2025 12:07:55 +0000"/>
                            <attachment id="13073945" name="ci_summary-5.0.html" size="29165" author="samt" created="Mon, 13 Jan 2025 12:07:55 +0000"/>
                            <attachment id="13073946" name="ci_summary-trunk.html" size="24646" author="samt" created="Mon, 13 Jan 2025 12:07:55 +0000"/>
                            <attachment id="13073174" name="ci_summary.html" size="23041" author="samt" created="Tue, 3 Dec 2024 11:43:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[dnk]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12313825" key="com.atlassian.jira.plugin.system.customfieldtypes:cascadingselect">
                        <customfieldname>Bug Category</customfieldname>
                        <customfieldvalues>
                                                    <customfieldvalue key="12985" cascade-level=""><![CDATA[Security]]></customfieldvalue>
                                <customfieldvalue key="13001" cascade-level="1"><![CDATA[Denial of Service]]></customfieldvalue>
            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12313821" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Complexity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12965"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313822" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Discovered By</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12977"><![CDATA[Adhoc Test]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12313922" key="jira.plugin.projectspecificselectfield.jpssf:multicftype">
                        <customfieldname>Impacts</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="13100"><![CDATA[None]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            40 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12313921" key="jira.plugin.projectspecificselectfield.jpssf:multicftype">
                        <customfieldname>Platform</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="13076"><![CDATA[All]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1sdcg:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[maedhroz]]></customfieldvalue>
        <customfieldvalue><![CDATA[samt]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
                        <customfieldname>Since Version</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12350367">4.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313924" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Source Control Link</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>&lt;p&gt;&lt;a href=&quot;https://github.com/apache/cassandra/commit/6f90e962f54c4b1a90ad6c3dc0bb6a224843abf0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/cassandra/commit/6f90e962f54c4b1a90ad6c3dc0bb6a224843abf0&lt;/a&gt;&lt;/p&gt;</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313823" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Test and Documentation Plan</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>&lt;p&gt;New unit tests, CI. &lt;/p&gt;</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>