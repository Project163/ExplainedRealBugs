<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:53:23 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-9295] Streaming not holding on to refs long enough.</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-9295</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;While doing some testing around adding/removing nodes under load with cassandra-2.1 head as of a few days ago (after was 2.1.5 tagged) I am seeing stream out errors with file not found exceptions.  The file in question just finished being compacted into a new file a few lines earlier in the log.  Seems that streaming isn&apos;t holding onto Ref&apos;s correctly for the stuff in the stream plans.&lt;/p&gt;

&lt;p&gt;I also see a &quot;corrupt sstable&quot; exception for the file the &quot;missing&quot; file was compacted to. Trimmed logs with just the compaction/streaming related stuff:&lt;br/&gt;
You can see the stream plan is initiated in between the compaction starting, and the compaction finishing.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;INFO  [MemtableFlushWriter:3] 2015-05-04 16:08:21,239  Memtable.java:380 - Completed flushing /mnt/cass_data_disks/data1/keyspace1/standard1-49f17b30f27711e4a438775021e2cd7f/keyspace1-standard1-ka-4-Data.db (60666088 bytes) for commitlog position ReplayPosition(segmentId=1430755416941, position=32294797)
INFO  [CompactionExecutor:4] 2015-05-04 16:08:40,856  CompactionTask.java:140 - Compacting [SSTableReader(path=&apos;/mnt/cass_data_disks/data1/keyspace1/standard1-49f17b30f27711e4a438775021e2cd7f/keyspace1-standard1-ka-4-Data.db&apos;), SSTableReader(path=&apos;/mnt/cass_data_disks/data1/keyspace1/standard1-49f17b30f27711e4a438775021e2cd7f/keyspace1-standard1-ka-3-Data.db&apos;)]
INFO  [STREAM-INIT-/10.240.213.56:53190] 2015-05-04 16:09:31,047  StreamResultFuture.java:109 - [Stream #f261c040-f277-11e4-a070-d126f0416bc9 ID#0] Creating new streaming plan for Rebuild
INFO  [STREAM-INIT-/10.240.213.56:53190] 2015-05-04 16:09:31,238  StreamResultFuture.java:116 - [Stream #f261c040-f277-11e4-a070-d126f0416bc9, ID#0] Received streaming plan for Rebuild
INFO  [STREAM-INIT-/10.240.213.56:53192] 2015-05-04 16:09:31,249  StreamResultFuture.java:116 - [Stream #f261c040-f277-11e4-a070-d126f0416bc9, ID#0] Received streaming plan for Rebuild
INFO  [STREAM-IN-/10.240.213.56] 2015-05-04 16:09:31,353  ColumnFamilyStore.java:882 - Enqueuing flush of standard1: 91768068 (19%) on-heap, 0 (0%) off-heap
INFO  [STREAM-IN-/10.240.213.56] 2015-05-04 16:09:37,425  ColumnFamilyStore.java:882 - Enqueuing flush of solr: 10012689 (2%) on-heap, 0 (0%) off-heap
INFO  [STREAM-IN-/10.240.213.56] 2015-05-04 16:09:38,073  StreamResultFuture.java:166 - [Stream #f261c040-f277-11e4-a070-d126f0416bc9 ID#0] Prepare completed. Receiving 0 files(0 bytes), sending 6 files(284288285 bytes)
INFO  [CompactionExecutor:4] 2015-05-04 16:10:11,047  CompactionTask.java:270 - Compacted 2 sstables to [/mnt/cass_data_disks/data1/keyspace1/standard1-49f17b30f27711e4a438775021e2cd7f/keyspace1-standard1-ka-5,/mnt/cass_data_disks/data1/keyspace1/standard1-49f17b30f27711e4a438775021e2cd7f/keyspace1-standard1-ka-8,].  182,162,816 bytes to 182,162,816 (~100% of original) in 90,188ms = 1.926243MB/s.  339,856 total partitions merged to 339,856.  Partition merge counts were {1:339856, }
ERROR [STREAM-OUT-/10.240.213.56] 2015-05-04 16:10:25,169  StreamSession.java:477 - [Stream #f261c040-f277-11e4-a070-d126f0416bc9] Streaming error occurred
java.io.IOException: Corrupted SSTable : /mnt/cass_data_disks/data1/keyspace1/standard1-49f17b30f27711e4a438775021e2cd7f/keyspace1-standard1-ka-5-Data.db
	at org.apache.cassandra.io.util.DataIntegrityMetadata$ChecksumValidator.validate(DataIntegrityMetadata.java:79) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.StreamWriter.write(StreamWriter.java:149) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.StreamWriter.write(StreamWriter.java:102) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.messages.OutgoingFileMessage$1.serialize(OutgoingFileMessage.java:58) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.messages.OutgoingFileMessage$1.serialize(OutgoingFileMessage.java:42) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.messages.StreamMessage.serialize(StreamMessage.java:45) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.sendMessage(ConnectionHandler.java:346) [cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.run(ConnectionHandler.java:318) [cassandra-all-2.1.5.426.jar:2.1.5.426]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]
INFO  [STREAM-OUT-/10.240.213.56] 2015-05-04 16:10:25,232  StreamResultFuture.java:180 - [Stream #f261c040-f277-11e4-a070-d126f0416bc9] Session with /10.240.213.56 is complete
WARN  [STREAM-OUT-/10.240.213.56] 2015-05-04 16:10:25,269  StreamResultFuture.java:207 - [Stream #f261c040-f277-11e4-a070-d126f0416bc9] Stream failed
ERROR [STREAM-OUT-/10.240.213.56] 2015-05-04 16:10:25,307  StreamSession.java:477 - [Stream #f261c040-f277-11e4-a070-d126f0416bc9] Streaming error occurred
java.lang.RuntimeException: java.io.FileNotFoundException: /mnt/cass_data_disks/data1/keyspace1/standard1-49f17b30f27711e4a438775021e2cd7f/keyspace1-standard1-ka-4-Data.db (No such file or directory)
	at org.apache.cassandra.io.util.RandomAccessReader.open(RandomAccessReader.java:124) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.io.util.RandomAccessReader.open(RandomAccessReader.java:107) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.io.util.SegmentedFile.createReader(SegmentedFile.java:99) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.io.sstable.SSTableReader.openDataReader(SSTableReader.java:1955) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.StreamWriter.write(StreamWriter.java:74) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.messages.OutgoingFileMessage$1.serialize(OutgoingFileMessage.java:58) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.messages.OutgoingFileMessage$1.serialize(OutgoingFileMessage.java:42) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.messages.StreamMessage.serialize(StreamMessage.java:45) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.sendMessage(ConnectionHandler.java:346) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.run(ConnectionHandler.java:326) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]
Caused by: java.io.FileNotFoundException: /mnt/cass_data_disks/data1/keyspace1/standard1-49f17b30f27711e4a438775021e2cd7f/keyspace1-standard1-ka-4-Data.db (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method) ~[na:1.8.0_40]
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316) ~[na:1.8.0_40]
	at java.io.RandomAccessFile.&amp;lt;init&amp;gt;(RandomAccessFile.java:243) ~[na:1.8.0_40]
	at org.apache.cassandra.io.util.RandomAccessReader.&amp;lt;init&amp;gt;(RandomAccessReader.java:64) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	at org.apache.cassandra.io.util.RandomAccessReader.open(RandomAccessReader.java:120) ~[cassandra-all-2.1.5.426.jar:2.1.5.426]
	... 10 common frames omitted
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12826996">CASSANDRA-9295</key>
            <summary>Streaming not holding on to refs long enough.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yukim">Yuki Morishita</assignee>
                                    <reporter username="jeremiah">Jeremiah Jordan</reporter>
                        <labels>
                    </labels>
                <created>Mon, 4 May 2015 18:12:07 +0000</created>
                <updated>Wed, 15 Oct 2025 09:48:55 +0000</updated>
                            <resolved>Sun, 17 May 2015 21:24:28 +0000</resolved>
                                        <fixVersion>2.1.6</fixVersion>
                    <fixVersion>2.2.0 beta 1</fixVersion>
                                    <component>Legacy/Streaming and Messaging</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="14526989" author="benedict" created="Mon, 4 May 2015 18:22:31 +0000"  >&lt;p&gt;This might help debug if the problem is with early release&lt;/p&gt;</comment>
                            <comment id="14527034" author="benedict" created="Mon, 4 May 2015 18:41:21 +0000"  >&lt;p&gt;Rebased against 2.1&lt;/p&gt;</comment>
                            <comment id="14527668" author="JIRAUSER308715" created="Tue, 5 May 2015 00:45:04 +0000"  >&lt;p&gt;Here are some logs from that patch for the corrupt sstable issue.  It isn&apos;t showing the &quot;missing file&quot; issue.  But I think its still showing an issue in ref management.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;INFO  [CompactionExecutor:4] 2015-05-04 22:44:10,104  CompactionTask.java:270 - Compacted 2 sstables to [/mnt/cass_data_disks/data1/keyspace1/standard1-31b786e0f2ae11e4b357c3b5cec66e30/keyspace1-standard1-ka-11,].  160,518,600 bytes to 160,518,600 (~100% of original) in 37,587ms = 4.072750MB/s.  299,475 total partitions merged to 299,475.  Partition merge counts were {1:299475, }
INFO  [CompactionExecutor:3] 2015-05-04 22:44:10,146  CompactionTask.java:140 - Compacting [SSTableReader(path=&apos;/mnt/cass_data_disks/data1/keyspace1/standard1-31b786e0f2ae11e4b357c3b5cec66e30/keyspace1-standard1-ka-11-Data.db&apos;), SSTableReader(path=&apos;/mnt/cass_data_disks/data1/keyspace1/standard1-31b786e0f2ae11e4b357c3b5cec66e30/keyspace1-standard1-ka-5-Data.db&apos;), SSTableReader(path=&apos;/mnt/cass_data_disks/data1/keyspace1/standard1-31b786e0f2ae11e4b357c3b5cec66e30/keyspace1-standard1-ka-6-Data.db&apos;), SSTableReader(path=&apos;/mnt/cass_data_disks/data1/keyspace1/standard1-31b786e0f2ae11e4b357c3b5cec66e30/keyspace1-standard1-ka-12-Data.db&apos;)]
ERROR [STREAM-OUT-/10.240.140.97] 2015-05-04 22:44:36,851  StreamSession.java:475 - [Stream #05469d70-f2af-11e4-a23d-e75fecbd7a98] Streaming error occurred
java.io.IOException: Corrupted SSTable : /mnt/cass_data_disks/data1/keyspace1/standard1-31b786e0f2ae11e4b357c3b5cec66e30/keyspace1-standard1-ka-11-Data.db
	at org.apache.cassandra.io.util.DataIntegrityMetadata$ChecksumValidator.validate(DataIntegrityMetadata.java:79) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.StreamWriter.write(StreamWriter.java:149) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.StreamWriter.write(StreamWriter.java:102) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.messages.OutgoingFileMessage$1.serialize(OutgoingFileMessage.java:58) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.messages.OutgoingFileMessage$1.serialize(OutgoingFileMessage.java:42) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.messages.StreamMessage.serialize(StreamMessage.java:45) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.sendMessage(ConnectionHandler.java:346) [cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.run(ConnectionHandler.java:318) [cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]
INFO  [STREAM-OUT-/10.240.140.97] 2015-05-04 22:44:36,875  StreamResultFuture.java:180 - [Stream #05469d70-f2af-11e4-a23d-e75fecbd7a98] Session with /10.240.140.97 is complete
WARN  [STREAM-OUT-/10.240.140.97] 2015-05-04 22:44:36,876  StreamResultFuture.java:207 - [Stream #05469d70-f2af-11e4-a23d-e75fecbd7a98] Stream failed
ERROR [STREAM-OUT-/10.240.140.97] 2015-05-04 22:44:36,881  Ref.java:210 - Allocate trace org.apache.cassandra.utils.concurrent.Ref$State@44977e69:
Thread[STREAM-IN-/10.240.140.97,5,main]
	at java.lang.Thread.getStackTrace(Thread.java:1552)
	at org.apache.cassandra.utils.concurrent.Ref$Debug.&amp;lt;init&amp;gt;(Ref.java:200)
	at org.apache.cassandra.utils.concurrent.Ref$State.&amp;lt;init&amp;gt;(Ref.java:133)
	at org.apache.cassandra.utils.concurrent.Ref.&amp;lt;init&amp;gt;(Ref.java:66)
	at org.apache.cassandra.utils.concurrent.Ref.tryRef(Ref.java:98)
	at org.apache.cassandra.io.sstable.SSTableReader.tryRef(SSTableReader.java:2008)
	at org.apache.cassandra.utils.concurrent.Refs.tryRef(Refs.java:186)
	at org.apache.cassandra.db.ColumnFamilyStore.selectAndReference(ColumnFamilyStore.java:1830)
	at org.apache.cassandra.streaming.StreamSession.getSSTableSectionsForRanges(StreamSession.java:304)
	at org.apache.cassandra.streaming.StreamSession.addTransferRanges(StreamSession.java:266)
	at org.apache.cassandra.streaming.StreamSession.prepare(StreamSession.java:491)
	at org.apache.cassandra.streaming.StreamSession.messageReceived(StreamSession.java:423)
	at org.apache.cassandra.streaming.ConnectionHandler$IncomingMessageHandler.run(ConnectionHandler.java:251)
	at java.lang.Thread.run(Thread.java:745)

ERROR [STREAM-OUT-/10.240.140.97] 2015-05-04 22:44:36,881  Ref.java:212 - Deallocate trace org.apache.cassandra.utils.concurrent.Ref$State@44977e69:
Thread[STREAM-OUT-/10.240.140.97,5,main]
	at java.lang.Thread.getStackTrace(Thread.java:1552)
	at org.apache.cassandra.utils.concurrent.Ref$Debug.deallocate(Ref.java:206)
	at org.apache.cassandra.utils.concurrent.Ref$State.release(Ref.java:187)
	at org.apache.cassandra.utils.concurrent.Ref.release(Ref.java:77)
	at org.apache.cassandra.streaming.StreamTransferTask.abort(StreamTransferTask.java:104)
	at org.apache.cassandra.streaming.StreamSession.closeSession(StreamSession.java:378)
	at org.apache.cassandra.streaming.StreamSession.onError(StreamSession.java:480)
	at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.sendMessage(ConnectionHandler.java:355)
	at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.run(ConnectionHandler.java:318)
	at java.lang.Thread.run(Thread.java:745)

ERROR [STREAM-OUT-/10.240.140.97] 2015-05-04 22:44:36,882  StreamSession.java:475 - [Stream #05469d70-f2af-11e4-a23d-e75fecbd7a98] Streaming error occurred
java.lang.AssertionError: null
	at org.apache.cassandra.utils.concurrent.Ref$State.assertNotReleased(Ref.java:150) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.utils.concurrent.Ref.get(Ref.java:92) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.messages.OutgoingFileMessage$1.serialize(OutgoingFileMessage.java:52) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.messages.OutgoingFileMessage$1.serialize(OutgoingFileMessage.java:42) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.messages.StreamMessage.serialize(StreamMessage.java:45) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.sendMessage(ConnectionHandler.java:346) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.run(ConnectionHandler.java:326) ~[cassandra-all-2.1.5.5182.jar:2.1.5.5182]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_40]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14527812" author="yukim" created="Tue, 5 May 2015 02:48:21 +0000"  >&lt;p&gt;I think there are two problems here: File corruption and SSTable ref release process in error handling.&lt;br/&gt;
I&apos;m not sure about the cause of the former. Does it just happen on uncompressed SSTables?&lt;/p&gt;

&lt;p&gt;For the latter, when some error occurred, streaming session is still holding refs to SSTable and trying to use them even after release.&lt;br/&gt;
StreamSession releases SSTable refs, but in outgoing message thread, there are already messages queued to be flushed out that holds the same refs.&lt;br/&gt;
I will post the patch for it.&lt;/p&gt;</comment>
                            <comment id="14527821" author="JIRAUSER308715" created="Tue, 5 May 2015 02:54:08 +0000"  >&lt;p&gt;I don&apos;t know.  Takes a bit to reproduce, and I haven&apos;t reproduced the &quot;missing file&quot; issue with the debug stuff on yet, so that it still to figure out.&lt;/p&gt;</comment>
                            <comment id="14527834" author="yukim" created="Tue, 5 May 2015 03:14:26 +0000"  >&lt;p&gt;&quot;missing file&quot; is caused by accessing already released file in error handling procedure.&lt;br/&gt;
It is the same as the latter problem I mentioned in my comment.&lt;/p&gt;</comment>
                            <comment id="14529309" author="yukim" created="Tue, 5 May 2015 21:21:41 +0000"  >&lt;p&gt;Attaching patch not to release reference while file is transferring.&lt;br/&gt;
This includes changes that Benedict made in 9295.debug.txt.&lt;br/&gt;
I&apos;m now invetigating file corruption (or CRC validation error) part as I obtained original files.&lt;/p&gt;</comment>
                            <comment id="14529326" author="benedict" created="Tue, 5 May 2015 21:32:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim&quot; class=&quot;user-hover&quot; rel=&quot;yukim&quot;&gt;yukim&lt;/a&gt; keep an eye out for &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8946&quot; title=&quot;Make SSTableScanner always respect its bound&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8946&quot;&gt;&lt;del&gt;CASSANDRA-8946&lt;/del&gt;&lt;/a&gt; imposing stricter bounds on the ranges being sent. I had a quick scan of the code and couldn&apos;t see an obvious place where this could cause a problem, but it seems like a viable candidate for interacting with streaming that was changed in this release.&lt;/p&gt;</comment>
                            <comment id="14531338" author="yukim" created="Wed, 6 May 2015 20:27:49 +0000"  >&lt;p&gt;I think I found the cause:&lt;br/&gt;
(0002-...patch for demonstration only.)&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;StreamSession is set up to transfer early opened (&apos;tmplink&apos;) SSTable during compaction.&lt;/li&gt;
	&lt;li&gt;Compaction finishes, and CRC.db is written.&lt;/li&gt;
	&lt;li&gt;StreamWriter checks if CRC file exists for tmplink SSTable. When SSTable is opened early, &lt;tt&gt;&amp;#45;tmplink&amp;#45;...CRC.db&lt;/tt&gt; does not exist, but its &lt;tt&gt;Descriptor&lt;/tt&gt; can point to normal CRC.db written in #2 above.&lt;/li&gt;
	&lt;li&gt;Checksum validation can fail validating last block of tmplinked SSTable file, since the block contains half of data while CRC assumes it contains full block since checksum is from #2.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Easy way to work around is not to validate when transferring tmplink file, as in 0003 patch.&lt;/p&gt;</comment>
                            <comment id="14531841" author="jbellis" created="Thu, 7 May 2015 01:11:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=JoshuaMcKenzie&quot; class=&quot;user-hover&quot; rel=&quot;JoshuaMcKenzie&quot;&gt;JoshuaMcKenzie&lt;/a&gt; to review&lt;/p&gt;</comment>
                            <comment id="14532319" author="benedict" created="Thu, 7 May 2015 09:27:47 +0000"  >&lt;p&gt;Perhaps we could just ignore the last block for validation? Or alternatively we could switch this to using only complete files, as we have for nearly all other non-request-serving operations (this might be better for the receiving node, but would churn the page cache more on the sending node)&lt;/p&gt;</comment>
                            <comment id="14532797" author="jmckenzie" created="Thu, 7 May 2015 14:52:41 +0000"  >&lt;p&gt;+1 for streaming complete files only. I think the risks associated with doing so (as illustrated here) outweigh potential benefits.&lt;/p&gt;</comment>
                            <comment id="14532951" author="yukim" created="Thu, 7 May 2015 16:28:41 +0000"  >&lt;p&gt;Ok, this version will skip opened early SSTable to be streamed.&lt;/p&gt;</comment>
                            <comment id="14532956" author="benedict" created="Thu, 7 May 2015 16:32:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim&quot; class=&quot;user-hover&quot; rel=&quot;yukim&quot;&gt;yukim&lt;/a&gt;: if you apply ColumnFamilyStore.CANONICAL_SSTABLES to the View first, you will only get non-early-opened sstablereaders, and repair won&apos;t unnecessarily exclude any readers.&lt;/p&gt;</comment>
                            <comment id="14538164" author="yukim" created="Mon, 11 May 2015 16:51:53 +0000"  >&lt;p&gt;This version (0003) uses CANNONICAL_SSTABLES to filter out SSTables to be streamed.&lt;/p&gt;</comment>
                            <comment id="14540885" author="benedict" created="Tue, 12 May 2015 22:12:43 +0000"  >&lt;p&gt;+1, but would be great to make that demonstration patch into a regression test.&lt;/p&gt;</comment>
                            <comment id="14541988" author="yukim" created="Wed, 13 May 2015 14:25:48 +0000"  >&lt;p&gt;Committed as &lt;tt&gt;9f7ab09f733659c94e918db03d72e6a860d654b4&lt;/tt&gt; except 0002, thanks.&lt;br/&gt;
The demonstration patch is actually seeing CRC validation error for early opened file.&lt;br/&gt;
Do you think it is worth treating as a bug and fix it? If so, I&apos;ll opened new JIRA and move 0002 there.&lt;/p&gt;</comment>
                            <comment id="14544773" author="yukim" created="Fri, 15 May 2015 01:58:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict&quot; class=&quot;user-hover&quot; rel=&quot;benedict&quot;&gt;benedict&lt;/a&gt; looks like we need to fix canonical view I filed in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9396&quot; title=&quot;Canonical view of compacting SSTables not working as expected&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-9396&quot;&gt;&lt;del&gt;CASSANDRA-9396&lt;/del&gt;&lt;/a&gt; in order this patch to work. Can you take a look?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12730613" name="0001-don-t-release-sstable-while-streaming.patch" size="14387" author="yukim" created="Tue, 5 May 2015 21:21:41 +0000"/>
                            <attachment id="12730948" name="0002-demonstrate-checksum-failure-of-early-opened-SSTable.patch" size="5652" author="yukim" created="Wed, 6 May 2015 20:27:49 +0000"/>
                            <attachment id="12731950" name="0003-Do-not-stream-early-opened-SSTable.patch" size="5375" author="yukim" created="Mon, 11 May 2015 16:51:53 +0000"/>
                            <attachment id="12730237" name="9295.debug.txt" size="9838" author="benedict" created="Mon, 4 May 2015 18:41:21 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[yukim]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 27 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2e9an:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Reproduced In</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329874">2.1.5</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>benedict</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[benedict]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>