<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:27:32 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-1034] Remove assumption that Key to Token is one-to-one</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-1034</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;get_range_slices assumes that Tokens do not collide and converts a KeyRange to an AbstractBounds. For RandomPartitioner, this assumption isn&apos;t safe, and would lead to a very weird heisenberg.&lt;/p&gt;

&lt;p&gt;Converting AbstractBounds to use a DecoratedKey would solve this, because the byte[] key portion of the DecoratedKey can act as a tiebreaker. Alternatively, we could make DecoratedKey extend Token, and then use DecoratedKeys in places where collisions are unacceptable.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12463287">CASSANDRA-1034</key>
            <summary>Remove assumption that Key to Token is one-to-one</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10003" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Low</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="slebresne">Sylvain Lebresne</assignee>
                                    <reporter username="stuhood">Stu Hood</reporter>
                        <labels>
                    </labels>
                <created>Thu, 29 Apr 2010 03:21:00 +0000</created>
                <updated>Tue, 16 Apr 2019 09:33:24 +0000</updated>
                            <resolved>Thu, 1 Dec 2011 10:14:43 +0000</resolved>
                                        <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>5</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="12862084" author="jbellis" created="Thu, 29 Apr 2010 04:12:36 +0000"  >&lt;p&gt;The problem is that we are using DK both for routing and for local key sorting, partly because it&apos;s very convenient to be able to use the &quot;natural&quot; compareTo to compare those two kinds of DK.&lt;/p&gt;

&lt;p&gt;If the only place we have DK with null key is for the routing case, then the right thing is to convert those usages to raw Tokens and make key non-optional in DK.&lt;/p&gt;

&lt;p&gt;i have a nagging feeling that there are more complications though.&lt;/p&gt;</comment>
                            <comment id="12862085" author="stuhood" created="Thu, 29 Apr 2010 04:13:16 +0000"  >&lt;p&gt;MD5 collisions are rare enough, so somebody would probably have to write their own partitioner to trigger this.&lt;/p&gt;</comment>
                            <comment id="12929953" author="jbellis" created="Tue, 9 Nov 2010 04:54:01 +0000"  >&lt;blockquote&gt;&lt;p&gt;it&apos;s very convenient to be able to use the &quot;natural&quot; compareTo to compare those two kinds of DK&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In particular, we generate (Token, null) DKs for range scans, at least in part because Hadoop thinks in terms of TokenRanges instead of DecoratedKeyRanges.  (Presumably it is still ok to assume that a partitioner generates many more tokens than there are nodes in the cluster; if not, this would need to change.)&lt;/p&gt;

&lt;p&gt;We might be able to still do this, if we just say that DK(T, null) always sorts before DK(T, non-null-key) for any given Token T.&lt;/p&gt;

&lt;p&gt;I still suspect we&apos;re using DK in some places where Token is all we really need.&lt;/p&gt;</comment>
                            <comment id="12929961" author="tjake" created="Tue, 9 Nov 2010 05:19:51 +0000"  >&lt;p&gt;Discovered the same issue with a partitioner that shares tokens for many keys.  This patch fixes the issue. all tests pass.&lt;/p&gt;</comment>
                            <comment id="12930181" author="stuhood" created="Tue, 9 Nov 2010 16:14:13 +0000"  >&lt;p&gt;Jake&apos;s patch is only a partial fix for this problem, so I&apos;ve moved it to #1720. The core of this ticket is either: changes to the class hierarchy, or changes to ranges.&lt;/p&gt;</comment>
                            <comment id="12930715" author="jbellis" created="Wed, 10 Nov 2010 19:07:47 +0000"  >&lt;p&gt;Can you elaborate as to what else needs to be fixed?&lt;/p&gt;

&lt;p&gt;As I said above, &quot;Presumably it is still ok to assume that a partitioner generates many more tokens than there are nodes in the cluster&quot; so I don&apos;t think we need to make Range a DK pair for granularity&apos;s sake.&lt;/p&gt;</comment>
                            <comment id="12930749" author="stuhood" created="Wed, 10 Nov 2010 19:52:00 +0000"  >&lt;p&gt;&amp;gt; Can you elaborate as to what else needs to be fixed?&lt;br/&gt;
I guess the larger problem here is that if a range query asks for 10 rows using a Token range, but there are 1000 rows sharing a particular token, which 10 rows do you return?&lt;/p&gt;</comment>
                            <comment id="12930778" author="jbellis" created="Wed, 10 Nov 2010 21:13:35 +0000"  >&lt;p&gt;Okay, so that is a problem because we create DK(Token, null) internally for range queries currently even when using the key-based API.&lt;/p&gt;

&lt;p&gt;Once that is fixed I&apos;m fine with saying &quot;the first 10&quot; (or if more convenient, &quot;that&apos;s undefined&quot;), since only Hadoop or similar iterate-over-everything approaches should be using Token-based range queries at the API level.  (Again, I&apos;m assuming that there are enough tokens to achieve sufficient granularity, iow, that the number of rows sharing a token is less than the InputSplit size.)&lt;/p&gt;</comment>
                            <comment id="13002145" author="slebresne" created="Thu, 3 Mar 2011 19:12:34 +0000"  >&lt;p&gt;Attaching a patch that I believe solves this. It makes Range accept both Token and DecoratedKey and makes those two compare together correctly.&lt;/p&gt;

&lt;p&gt;It introduces a new marker interface (RingPosition) instead of making DecoratedKey extends Token (for reason explained in the comments of RingPosition but to sum up: I think it&apos;s cleaner).&lt;/p&gt;

&lt;p&gt;The second patch attached is just a stupid partitioner that use for token the length of the key. It&apos;s just for testing and not meant for inclusion. But this shows that with the first patch, you can do correct range query that go from &apos;the middle of a token&apos; to the &apos;middle of another one&apos;.&lt;/p&gt;

&lt;p&gt;An important note is that this breaks the serialization unit tests, because now an AbstractBounds can use decoratedKeys, and thus serialized AbstractBounds are incompatible with previous version. Not sure how to deal with that though, I though we had a plan for dealing with that but I&apos;ll admit I don&apos;t remember the details.&lt;/p&gt;</comment>
                            <comment id="13007498" author="slebresne" created="Wed, 16 Mar 2011 14:53:30 +0000"  >&lt;p&gt;Patch rebased&lt;/p&gt;</comment>
                            <comment id="13010615" author="slebresne" created="Thu, 24 Mar 2011 09:47:56 +0000"  >&lt;p&gt;Rebased patch with code for binary backward compatibility. This still needs the first part of &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2361&quot; title=&quot;AES depends on java serialization&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-2361&quot;&gt;&lt;del&gt;CASSANDRA-2361&lt;/del&gt;&lt;/a&gt; to fully pass the serialization unit tests.&lt;/p&gt;</comment>
                            <comment id="13011306" author="jbellis" created="Fri, 25 Mar 2011 17:43:58 +0000"  >&lt;p&gt;What is LengthPartitioner for?&lt;/p&gt;</comment>
                            <comment id="13011327" author="slebresne" created="Fri, 25 Mar 2011 18:22:50 +0000"  >&lt;p&gt;Oh, it&apos;s just a stupid partitioner with tons of collision (and predictable ones) that I used for testing and attached so that other can test too. Not meant for inclusion.&lt;/p&gt;</comment>
                            <comment id="13011353" author="jbellis" created="Fri, 25 Mar 2011 18:58:02 +0000"  >&lt;p&gt;Initial feedback:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I&apos;m a fan of the RingPosition approach&lt;/li&gt;
	&lt;li&gt;Less of a fan of pretending that Tokens and DK are equal if the token component of DK is equal.  Shouldn&apos;t we force caller to ask Token.equals(DK.token) if that&apos;s what they mean? As you pointed out in RP docstring, there is not an is-a relationship there.&lt;/li&gt;
	&lt;li&gt;Should we add RP.isToken to encapsulate RP.asDecoratedKey.key == null checks?&lt;/li&gt;
	&lt;li&gt;DK docstring is obsolete now&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13011373" author="slebresne" created="Fri, 25 Mar 2011 19:24:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;Less of a fan of pretending that Tokens and DK are equal if the token component of DK is equal. Shouldn&apos;t we force caller to ask Token.equals(DK.token) if that&apos;s what they mean? As you pointed out in RP docstring, there is not an is-a relationship there.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The thing is, we need them to be equal for compareTo() (because we can&apos;t have token &amp;gt; keys nor token &amp;lt; keys, otherwise that would mess up our ranges). Then for the equals, the motivation is summed up by the Comparable documentation:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;It is strongly recommended (though not required) that natural orderings be consistent with equals. This is so because sorted sets (and sorted maps) without explicit comparators behave &quot;strangely&quot; when they are used with elements (or keys) whose natural ordering is inconsistent with equals. In particular, such a sorted set (or sorted map) violates the general contract for set (or map), which is defined in terms of the equals method.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;And I do fear that we would get something inconsistent at some point.&lt;br/&gt;
But I&apos;m not a super fan either, just felt the less evil of the two choices.&lt;br/&gt;
I&apos;m happy with suggestion though and I&apos;ll work out the other remarks.&lt;/p&gt;
</comment>
                            <comment id="13011386" author="jbellis" created="Fri, 25 Mar 2011 19:39:09 +0000"  >&lt;p&gt;I understand the Comparable docs, but &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;that&apos;s primarily concerned w/ compareTo + equals b/t members of the same class&lt;/li&gt;
	&lt;li&gt;it&apos;s valid to say &quot;these are tied for sorting purposes, and yet they are not equal&quot;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In other words I&apos;m more worried about subtle bugs if we allow the equals, than if we don&apos;t. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;The Map example is a good one &amp;#8211; if I set&lt;/p&gt;

&lt;p&gt;map&lt;span class=&quot;error&quot;&gt;&amp;#91;token(1)&amp;#93;&lt;/span&gt; = foo&lt;br/&gt;
map&lt;span class=&quot;error&quot;&gt;&amp;#91;dk(1, 1)&amp;#93;&lt;/span&gt; = bar&lt;/p&gt;

&lt;p&gt;I would expect two map entries, not one.  (If you want one, you explicitly use asToken, then there is no ambiguity.)&lt;/p&gt;

&lt;p&gt;How about if we add an assert to both equals to make sure we don&apos;t pass in the other kind of object?&lt;/p&gt;</comment>
                            <comment id="13011389" author="slebresne" created="Fri, 25 Mar 2011 19:44:20 +0000"  >&lt;p&gt;You&apos;re right, I&apos;m convinced, it&apos;s probably safer to have equals be a true equals.&lt;br/&gt;
I&apos;ll do the change.&lt;/p&gt;</comment>
                            <comment id="13011600" author="stuhood" created="Sat, 26 Mar 2011 10:13:25 +0000"  >&lt;p&gt;I was reaaally hoping we could subclass here... adding RingPosition leads to explicit conversions scattered all over that end up obscuring  implicit conversions.&lt;/p&gt;

&lt;p&gt;The hairiest part of subclassing would be renaming all of our Token subclasses with DecoratedKey subclasses, but it cleans up unnecessary references: for example, for a DecoratedKey for ByteOrderPartitioner or LocalPartitioner you have:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;DecoratedKey
   BytesToken token;
      ByteBuffer token;
   ByteBuffer key;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;... while with subclassing you could save two object references:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;DecoratedKey
   ByteBuffer keyAndToken;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Also, the Comparable dilemma is relatively straightforward with subclassing: Token implements Comparable&amp;lt;Token&amp;gt;, the subclasses override, call super.compare, and if their superclass is equal, fall back to instanceof(myclass) to see whether they can compare the key data.&lt;/p&gt;</comment>
                            <comment id="13013013" author="slebresne" created="Wed, 30 Mar 2011 15:21:12 +0000"  >&lt;p&gt;I realize that this is a little more subtle than I first though.&lt;/p&gt;

&lt;p&gt;You just cannot compare a Token and a DecoratedKey simply, because a Token is actually a range of keys. Hence dealing with a Range that mixes Token and DecoratedKey correctly is doable, but a bit complicated (typically, it involves declaring multiple different comparison functions). To take quick example, consider that if you mix DK and Token, you must have the following that stands:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    (T(2), T(8)] should not contain DK(T(2), &quot;foo&quot;) =&amp;gt; DK(T(2), &quot;foo&quot;) &amp;lt; T(2)
    [T(2), T(8)] should contain     DK(T(2), &quot;foo&quot;) =&amp;gt; DK(T(2), &quot;foo&quot;) &amp;gt;= T(2)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So there is no way to write a compareTo() function dealing with both DK and token.&lt;/p&gt;

&lt;p&gt;So I think that it will be simplest to not mix DK and Token in the same ranges. We&apos;ll have ranges of Token (for everything related to ring management) and ranges of DK (for rangeSlice and scan). This is what the patch does (and the patch &apos;generify&apos; AbstractBounds, Range and Bounds (a fair part of the patch) to keep type information around and avoid unnecessary casts all over the place).&lt;/p&gt;

&lt;p&gt;We still want to make a rangeSlice/scan over a range of token. To do that, we simply convert a range of Token to a range of DK. This involves declaring for a given token a smallest key and biggest key, and this in turn comes a slight complication related to the minimum token, but the detail are in the docstrings of the patch. I am reasonably confident on that new patch.&lt;/p&gt;

&lt;p&gt;(Note that this patch is much bigger than the previous one, but this is mostly due to the generification of Range)&lt;/p&gt;</comment>
                            <comment id="13013583" author="jbellis" created="Wed, 30 Mar 2011 18:57:06 +0000"  >&lt;p&gt;Can you break the generification out into a separate patch?&lt;/p&gt;</comment>
                            <comment id="13014751" author="slebresne" created="Fri, 1 Apr 2011 17:08:56 +0000"  >&lt;p&gt;Generification broken into a separate patch + some tiny code style update&lt;/p&gt;</comment>
                            <comment id="13015481" author="slebresne" created="Mon, 4 Apr 2011 16:16:42 +0000"  >&lt;p&gt;Attaching v2 for my second patch. There was some failure in the unit tests for getRestrictedRanges. This fix and improves those test and fix a small bug related to the handling of the minimum value for DecoratedKey.&lt;/p&gt;</comment>
                            <comment id="13015482" author="jbellis" created="Mon, 4 Apr 2011 16:18:43 +0000"  >&lt;p&gt;I think we are almost done.  A couple comments:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;DK.isEmpty seems like a bad method name for a Key object &amp;#8211; intuitively, keys are a specific point and should not contain other points except for the obvious identity case.  Would isMinimum be a better name?&lt;/li&gt;
	&lt;li&gt;I don&apos;t understand RP.toSplitValue or why DK would throw away information, when calling it.  More generally, I&apos;m unclear why we would have null keys in DK &amp;#8211; shouldn&apos;t you use a Token, if you don&apos;t have key information?&lt;/li&gt;
	&lt;li&gt;using MINIMUM_TOKEN for both sort-before-everything and sort-after-everything values has always been confusing.  Should we introduce a MAXIMUM_TOKEN value to clear that up?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13015636" author="slebresne" created="Mon, 4 Apr 2011 21:44:24 +0000"  >&lt;p&gt;Reattaching v2, previous had a stupid mistake, sorry about that.&lt;/p&gt;</comment>
                            <comment id="13017026" author="slebresne" created="Thu, 7 Apr 2011 16:24:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;DK.isEmpty seems like a bad method name for a Key object &#8211; intuitively, keys are a specific point and should not contain other points except for the obvious identity case. Would isMinimum be a better name?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually I don&apos;t even like isEmpty for token, so in favor of isMinimum for both DK and token.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;don&apos;t understand RP.toSplitValue or why DK would throw away information, when calling it. More generally, I&apos;m unclear why we would have null keys in DK &#8211; shouldn&apos;t you use a Token, if you don&apos;t have key information?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Current patch don&apos;t allow to mix token and DK in a range/bounds (because that comes with its whole sets of complications). However getRestrictedRange must be able to break a range of DK based on a node token. So RP.toSplitValue() returns for a given token the value that splits the range: for a token range it&apos;s the token itself, but for a DK range, it&apos;s the largest DK having this token.&lt;br/&gt;
The null keys is related: even though we don&apos;t mix DK and token in range, we need to be able to have a range of DK that includes everything from x token to y token. Hence, for a given token t, we need two DK: the smallest DK having t and the biggest DK having t. In the patch, slightly but not totally randomly, I use DK(t, EMPTY_BB) for the smallest key and DK(t, null) for the biggest one, hence the &quot;need&quot; for null keys. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;using MINIMUM_TOKEN for both sort-before-everything and sort-after-everything values has always been confusing. Should we introduce a MAXIMUM_TOKEN value to clear that up?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think that would make wrapping stuffs more complicated. Because then what would be the difference between the following ranges: (MIN, MIN], (MAX, MAX], (MIN, MAX] and (MAX, MIN]. For DK, the code is already enforcing that the we only have one minimum key (that is DK(MIN, EMPTY_BB)) and never ever use DK(MIN, null) because that poses problems. I think a MAX token would make that worst. &lt;/p&gt;</comment>
                            <comment id="13017638" author="jbellis" created="Fri, 8 Apr 2011 20:55:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;RP.toSplitValue() returns for a given token the value that splits the range: for a token range it&apos;s the token itself, but for a DK range, it&apos;s the largest DK having this token. The null keys is related: even though we don&apos;t mix DK and token in range, we need to be able to have a range of DK that includes everything from x token to y token&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This feels messy and error-prone to me. I wonder if we haven&apos;t found the right approach yet.&lt;/p&gt;</comment>
                            <comment id="13017948" author="stuhood" created="Sat, 9 Apr 2011 20:07:41 +0000"  >&lt;p&gt;I agree that using null is a necessary solution here: you need a max value for keys, since they are essentially the &quot;child&quot; of a one-token-range. The key range is bounded (since it has parents), but the token range is not, so I agree with sylvain that a MAX_TOKEN is probably not necessary.&lt;/p&gt;

&lt;p&gt;One way to remove toSplitValue would be to use DecoratedKey everywhere; DecoratedKey is a compound of the Token and the key blob. The equivalent of today&apos;s Token is a DecoratedKey for that token with a null key: it compares greater than all valid child keys, so it contains them.&lt;/p&gt;

&lt;p&gt;I hope that it won&apos;t muddy the water, but the &amp;lt;empty&amp;gt; as min and &amp;lt;null&amp;gt; as max approach is the same one I took forthe first cut of the file-format, and it worked very well. You can use the min/max values to find the beginning or end of a child range. See &lt;a href=&quot;https://github.com/stuhood/cassandra-old/blob/674/src/java/org/apache/cassandra/db/ColumnKey.java#L225&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;ColumnKey.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;EDIT: Actually... I&apos;m not so sure about not having MAX_TOKEN... it might actually clean things up quite a bit. Any time a range ends with what use to be the min token, you can make a direct translation to MAX_TOKEN.&lt;/p&gt;</comment>
                            <comment id="13046464" author="slebresne" created="Thu, 9 Jun 2011 11:01:19 +0000"  >&lt;p&gt;Patch rebased, this is against trunk.&lt;/p&gt;</comment>
                            <comment id="13046477" author="slebresne" created="Thu, 9 Jun 2011 11:32:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;One way to remove toSplitValue would be to use DecoratedKey everywhere;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not saying it&apos;s not possible, but I think this is overkill (in the changes it involves). Moreover, all the code that deals with topology really only care about token. That&apos;s the right abstraction for those part of the code. So I really (really) doubt using decorated key everywhere would be cleaner. Of course, anyone is free to actually do the experiment and prove me wrong. I also don&apos;t think it would remove the need for splitValue, it would just maybe call it differently.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The equivalent of today&apos;s Token is a DecoratedKey for that token with a null key&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is only true today because we assume key and token are one-to-one. The goal is to change that. If multiple keys can have the same token (by definition the token is really the hash of a key), then the statement above is false. If a token correspond to an infinite set of key (with is the case with md5 btw, we just ignore it), then replacing a token by given key &lt;b&gt;cannot&lt;/b&gt; work.&lt;/p&gt;

&lt;p&gt;Overall, it could be that there is better way to do this, but having spend some time on this, I have a reasonable confidence on that it fixes the issue at hand without being too disruptive (which is not saying there isn&apos;t a few points here and there that couldn&apos;t be improved).&lt;/p&gt;</comment>
                            <comment id="13088280" author="michaelsembwever" created="Sat, 20 Aug 2011 22:08:48 +0000"  >&lt;p&gt;What&apos;s the status on this? This issue and its relations back to &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2878&quot; title=&quot;Allow map/reduce to use server-side query filters&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-2878&quot;&gt;&lt;del&gt;CASSANDRA-2878&lt;/del&gt;&lt;/a&gt; are the only reason we&apos;re using OPP. I suspect other users setup with both cassandra and hadoop (or brisk) could be in the same boat. Not only does OPP leave an unbalanced ring (i&apos;ve had a case where all data went to one node because the keys/tokens were longer than normal) it leaves poor performance to hadoop jobs as tasks requirement on data locality has become stricter (w/ &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2388&quot; title=&quot;ColumnFamilyRecordReader fails for a given split because a host is down, even if records could reasonably be read from other replica.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-2388&quot;&gt;&lt;del&gt;CASSANDRA-2388&lt;/del&gt;&lt;/a&gt;). Apart from the plain preference to be using secondary indexes over OPP.&lt;/p&gt;</comment>
                            <comment id="13088313" author="jbellis" created="Sun, 21 Aug 2011 04:20:42 +0000"  >&lt;p&gt;Status is, I&apos;m hoping that someone comes up with a fix that doesn&apos;t look error prone.  Otherwise we&apos;ll probably end up with merging Sylvain&apos;s solution for 1.1.&lt;/p&gt;</comment>
                            <comment id="13119321" author="xedin" created="Mon, 3 Oct 2011 14:08:23 +0000"  >&lt;p&gt;I&apos;m thinking of making Token an interface and implementing two classes RoutingToken(token) and QueryToken(token, key) so all current token implementations LocalToken, StringToken, BytesToken, BigIntegerToken are going to extend QueryToken. RoutingToken is going to be used for operations where we don&apos;t need a key - bootstrap, midpoint calculation, TokenMetadata class; QueryToken is going to be a replacement for DK, that will allow us to remove DK completely and operate only on the token basis. Thoughts?&lt;/p&gt;</comment>
                            <comment id="13119327" author="slebresne" created="Mon, 3 Oct 2011 14:23:22 +0000"  >&lt;blockquote&gt;&lt;p&gt;Thoughts?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;From your comment only I don&apos;t see right away what you are proposing besides a renaming of Token -&amp;gt; RoutingToken and DecoratedKey -&amp;gt; QueryToken.&lt;/p&gt;</comment>
                            <comment id="13124465" author="xedin" created="Mon, 10 Oct 2011 20:42:44 +0000"  >&lt;p&gt;Patch removes DK and IPartitioner.decorateKey(ByteBuffer key), which is replaced by IPartitioner.getToken(ByteBuffer key), Token now takes second parameter - ByteBuffer key. Most of the patch are replacements for DK -&amp;gt; Token and decorateKey -&amp;gt; getToken. All tests (test, test-compression, long-test) pass.&lt;/p&gt;

&lt;p&gt;Rebased with the latest trunk (last commit 7624536ae7fea52bcf761c7dea212fe12d2f4586)&lt;/p&gt;</comment>
                            <comment id="13124468" author="tjake" created="Mon, 10 Oct 2011 20:57:13 +0000"  >&lt;p&gt;At first glancei  like this because it makes the Token first class and the key not required. cleaning up the code below.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;-        DecoratedKey startWith = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DecoratedKey(range.left, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;);
-        DecoratedKey stopAt = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DecoratedKey(range.right, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;);
+        Token startWith = range.left;
+        Token stopAt = range.right;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13124946" author="slebresne" created="Tue, 11 Oct 2011 11:42:23 +0000"  >&lt;p&gt;I have 2 major problems with that patch:&lt;/p&gt;

&lt;p&gt;The first one is I really dislike the idea of merging DK into Token (I disliked the idea of merging Token into DK and that roughly the same idea).  First, I fail to see how this is of any help in solving what this ticket is trying to solve. Second, I think it&apos;s a very bad use of types. A Token is not a Key. By merging those together we just weaken our type hierarchy, thus getting less insurance from types. Typically, with this patch, a function that really want a DK, could get a Token, i.e getKey() is not guaranteed to return a valid key. Now I know, we are already using &apos;false&apos; DK by feeding null as a key sometimes. Well, that is ugly and error prone. I don&apos;t think generalizing this everywhere while introducing a 300K patch is the right way to go, quite the contrary. Besides, it&apos;s inefficient. All the places were we do use only a Token, we&apos;ll now have a bigger structure with a useless pointer to the EMPTY_BYTE_BUFFER (granted this has probably little impact, but it&apos;s another sign that it&apos;s doing it wrong).&lt;/p&gt;

&lt;p&gt;The second problem is this doesn&apos;t work. This DK-&amp;gt;Token really just muddy the water but it doesn&apos;t solve anything. What we want is to fix the fact that the code identifies token and keys as a one to one mapping. In particular, this is forced in DK.compareTo(), which only compare the tokens, ignoring the keys.  Fixing that place is easy, and the patch does it, but it&apos;s really just a few lines change.&lt;/p&gt;

&lt;p&gt;The real problem is that the code make the assumption that key &amp;lt;-&amp;gt; token is one to one in other places. So making DK.compareTo takes key into account breaks other parts. For instance, in RowIteratorFactory, we have this:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;return startWith.compareTo(row.getKey()) &amp;lt;= 0
       &amp;amp;&amp;amp; (stopAt.isEmpty() || row.getKey().compareTo(stopAt) &amp;lt;= 0);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and say that startWith and stopAt are token only. The semantic is that this is supposed to be inclusive on both bound. With the last patch, this would include keys having the startWith token, but &lt;b&gt;not&lt;/b&gt; the ones having stopAt as token, because in the patch, a token compares strictly before all of the key having this token (concretely, the attached patch skips keys during range queries).&lt;/p&gt;

&lt;p&gt;And this is not the only places in the code where this problem manifest, because this is the symptom of a larger problem. If more than one key can have the same token, then tokens are a range of keys.&lt;br/&gt;
If you ask for the range of tokens &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 4&amp;#93;&lt;/span&gt;, then you expect that it will return all the keys having token 1, 2, 3 and 4. That excludes having a token comparing strictly before all the keys having this token (or having it compare strictly after all the keys having it as token for that matter). Merging Token and DK just doesn&apos;t work.&lt;/p&gt;

&lt;p&gt;At the risk of sounding cocky, I really encourage people to have another look at my patch. I do believe that once you&apos;ve realized what solving this problem entails, it&apos;s a solution that strike a reasonable balance in fixing the problem without a entire rewrite of Cassandra.&lt;/p&gt;</comment>
                            <comment id="13125379" author="tjake" created="Tue, 11 Oct 2011 20:50:49 +0000"  >&lt;p&gt;@Sylvain This is all really confusing and I agree the core of the ticket is to make key-&amp;gt;token 1:1&lt;/p&gt;

&lt;p&gt;The core of the problem initially was explained in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1733&quot; title=&quot;get_range_slices doesn&amp;#39;t return key from start_key in KeyRange any more&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1733&quot;&gt;&lt;del&gt;CASSANDRA-1733&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;A Range object (which Hadoop splits generate) is start-exclusive. A Bounds object (which normal user scan queries generate) is start-inclusive.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So by making Token the only way to deal with keys it feels like a more consistent api.  Since Key can be null it needs to be Token that becomes the primary internal class. &lt;/p&gt;

&lt;p&gt;In your impl we now have DK, Token, RingPosition which too me is more confusing than having one Token class.&lt;/p&gt;

</comment>
                            <comment id="13125709" author="slebresne" created="Wed, 12 Oct 2011 10:43:09 +0000"  >&lt;p&gt;I&apos;m not sure I&apos;m am completely clear, so allow me to try to improve that. I think there is two issues with the last patch that are largely orthogonal:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;the patch is broken (again, this is largely not related to the shoving of DK into Token)&lt;/li&gt;
	&lt;li&gt;I believe shoving DK into Token is a bad, error-prone idea that have no tangible advantages&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;But let&apos;s me first focus on the first issue, if only because it involves no opinion whatsoever: I&apos;m either right or wrong that it&apos;s broken (but i&apos;m pretty sure I&apos;m right). So let&apos;s be concrete and take an example.&lt;/p&gt;

&lt;p&gt;The patch &quot;merges&quot; Token and DecoratedKey together, so let me take the following notation:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;t(1, a) for what is the DecoratedKey a of token 1 in current but is is just a Token instance in the patch&lt;/li&gt;
	&lt;li&gt;t(1) for the &apos;pure&apos; token 1. In other word it&apos;s a shortcut for t(1, EMPTY_BYTE_BUFFER) in the attached patch and correspond to just a Token in the current code.&lt;br/&gt;
(as a side note, the fact that I have to speak of DecoratedKey and &apos;pure&apos; token to explain is imo yet another sign than melting everything into Token is a bad idea but I&apos;m diverging)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Since when Token are compared, the token is compared then the key is on token equality, we have t&amp;#40;n) &amp;lt; t(n, k) whatever the token n and key k are (since t&amp;#40;n) is t(n, EMPTY_BYTE_BUFFER) and EMPTY_BYTE_BUFFER &amp;lt; k for any valid key k) .&lt;/p&gt;

&lt;p&gt;Let&apos;s now take an example of multiple keys having the same token and say that I have the following keys in my cluster:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;tokens |   1   |     2     |   3
keys   | a | b | c | d | e | f | g
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In other words, a and b have the same token 1; c, d and e have the same token 2; ...&lt;/p&gt;

&lt;p&gt;The goal for this ticket is to support that situation correctly. Sor for instance, we should have that:&lt;br/&gt;
   range_slice(start=t(1), end=t(3)) returns c, d, e, f and g&lt;br/&gt;
(because range_slice with tokens is start exclusive).  However, with the attached patch:&lt;br/&gt;
   range_slice(start=t(1), end=t(3)) will return a, b, c, d and e&lt;/p&gt;

&lt;p&gt;The reason is fairly simple: we have that t(1) &amp;lt; t(1, k) for any k and t(3) &amp;lt; t(3, k) for any k.&lt;/p&gt;

&lt;p&gt;Another way to put it is that it breaks our token ranges: if you have a node that owns Range(t(1), t(3)), it&apos;s supposed to not contains any key with token 1 and all keys with token 3, but it fails at both.&lt;/p&gt;

&lt;p&gt;So it&apos;s broken. Now there is something we could be tempted to do. We could make it so that t&amp;#40;n) &amp;gt; t(n, k) for any token n and any key k. But in turn that would break Bounds (i.e, start inclusive) of &apos;pure&apos; tokens. I.e, Bounds(t(1), t(2)) is supposed to include all keys with token 1, but if t(1) &amp;gt; t(1, k) for any key k, it won&apos;t include it.&lt;/p&gt;

&lt;p&gt;One could argue however that this is still solution because I &lt;b&gt;think&lt;/b&gt; that right now we never really use a Bounds of &apos;pure&apos; tokens (more precisely, the current code does it, but only in place where we are actually doing a range slice between keys). And I &lt;b&gt;think&lt;/b&gt; that functions that take a startKey, when fed a &apos;pure&apos; token only do start exclusive. So I suppose we could assert that we never create Bounds of Token and put some assert here and there (in SSTableReader.getPosition() for instance) and go with that.&lt;/p&gt;

&lt;p&gt;But imho this is a bad idea. Because it&apos;s fragile and because this is ignoring a problem that may screw us up later. Why not fix it the right way now? What if tomorrow we do want to be able to query all the keys having a given token ? That is, what if we want to query &lt;span class=&quot;error&quot;&gt;&amp;#91;t(1), t(1)&amp;#93;&lt;/span&gt; ? We would not be able to, because if t(1) &amp;gt; t(1, k) for any k, then &lt;span class=&quot;error&quot;&gt;&amp;#91;t(1), t(1)&amp;#93;&lt;/span&gt; don&apos;t include anything.&lt;/p&gt;

&lt;p&gt;Again, all this is because a token actually correspond to a set of keys (once you acknowledge multiple keys can have the same token), and so if you want to do things correctly, you need for a given token n to have a representation for both:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the smallest key having token n&lt;/li&gt;
	&lt;li&gt;the greatest key having token n&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;With that, you can query all the keys having token n. Without, you can&apos;t. That is what my patch does and I believe fairly strongly is the right way to do it.&lt;/p&gt;


&lt;p&gt;Alright, that the first thing that a patch to this ticket must deal with. Then there is another thing: the current code only allow for AbstractBounds of Token (by typing), but we want for this patch that once you do a range_slice query with at startKey and endKey, you get a range of keys in ColumnFamilyStore.getRangeSlice(), so that you can precisely answer those queries. That means we must be able to construct AbstractBounds with keys in them. Note that it&apos;s basically just a typing problem.&lt;/p&gt;

&lt;p&gt;The answer to that of this patch is show DK into Token. So yeah, it fixes that problem, but what I&apos;m arguing is that:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;It&apos;s error-prone and make coding &lt;b&gt;more&lt;/b&gt; complicated. We&apos;re merging object that are not the same thing. Today if a methods takes a Token, you know it won&apos;t do anything at the granularity of keys (well today Token and keys have the same granularity but this ticket is supposed to change that). You lose that information if you merge DK and Token. And if a method takes a DecoratedKey, you know that it doesn&apos;t expect a Token (more precisely, Typing ensures it). Sure, we do already use a trick in a few places where we create &apos;fake&apos; DK(null, key). But at the very least, when we do that, we know we&apos;re doing something weird, and we are extra careful that methods we call on that fake DK handle that case correctly. If everything is Token, now the signature for a lot of method will suggest it is ok to give a &apos;pure&apos; Token. So what, all method should defensively assert this is not the case ? This is what types are for.&lt;/li&gt;
	&lt;li&gt;It&apos;s a ~300K patch. Sure it&apos;s mostly simple changes, but it&apos;s still that many changes that could introduce a typo somewhere that causes a bug.&lt;/li&gt;
	&lt;li&gt;It&apos;s a tad less efficient because each time we really only care about &apos;pure&apos; Token (and there is quite a bunch of code that does that), we would allocate a slightly larger structure for no reason. And I&apos;m pretty sure god kills a kitten each time you do that.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The solution to that very same type problem I&apos;m proposing (in my patch) is instead simply to generalize AbstractBound slightly so you can have both AbstractBound of Token and of DecoratedKey. That sound very reasonable to me.  After all we should be able to have AbstractBounds of anything that implements Comparable right ? Well, as it turns out our implementation of AbstractBound needs a little more than that (because our ranges wraps, we need Comparable but with a minimum value for instance) and that is what RingPosition is for.  But it&apos;s only a marker interface, and if you look at the code it&apos;s actually used in a small number of places, so I admit I fail to see how this make thing much more complicated.&lt;/p&gt;</comment>
                            <comment id="13125716" author="xedin" created="Wed, 12 Oct 2011 11:14:10 +0000"  >&lt;p&gt;Can you please define what do you mean by &quot;pure token&quot;? Aren&apos;t we supposed to generate token from key in all situations except initial token in config and middle point between tokens? So if you do a range slice using tokens instead of keys TokenFactory.fromString will force you to use correctly serialized token data which will also include key.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It&apos;s error-prone and make coding more complicated. We&apos;re merging object that are not the same thing etc...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If token is generated from key than for me it&apos;s natural to have a key as member. The thing is that you are enable to create a &quot;pure&quot; token, Partitioner will always give you a Token with valid key except for midpoint method so if partitioner is used to generate tokens you are guaranteed to have a valid key in the resulting token instance.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It&apos;s a ~300K patch. Sure it&apos;s mostly simple changes, but it&apos;s still that many changes that could introduce a typo somewhere that causes a bug.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The same thing I can say about your set of patches - it&apos;s 198 KB. Aren&apos;t we writing tests to catch such bugs?&lt;/p&gt;</comment>
                            <comment id="13125773" author="slebresne" created="Wed, 12 Oct 2011 12:23:11 +0000"  >
&lt;blockquote&gt;&lt;p&gt;Can you please define what do you mean by &quot;pure token&quot;?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In you patch, it&apos;s a Token whose key is EMPTY_BYTE_BUFFER (which is &lt;b&gt;not&lt;/b&gt; a valid row key, hence the &apos;pure&apos; token name).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Aren&apos;t we supposed to generate token from key in all situations except initial token in config and middle point between tokens?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;And? Is that not enough? There is tons of place in the code where we manipulate those tokens &apos;not created from a key&apos; (all the distribution code basically, which is a big part of Cassandra). Moreover, there is also range_slice that accept a range of token.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So if you do a range slice using tokens instead of keys TokenFactory.fromString will force you to use correctly serialized token data which will also include key.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;To what is this supposed to be an answer ?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If token is generated from key than for me it&apos;s natural to have a key as member. The thing is that you are enable to create a &quot;pure&quot; token, Partitioner will always give you a Token with valid key except for midpoint method so if partitioner is used to generate tokens you are guaranteed to have a valid key in the resulting token instance.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But it&apos;s not always generated from a key! There is nothing natural to a key member in all the Token object manipulated by TokenMetadata and other, since there is not such key.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The same thing I can say about your set of patches - it&apos;s 198 KB. Aren&apos;t we writing tests to catch such bugs?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well, in my patch, 148K of those are a type generification only (that&apos;s why I&apos;ve separated it). Because generics are erased at runtime, as long as it compile, there is &lt;b&gt;NO&lt;/b&gt; chance this can introduce a bug. As for trusting tests to catch bugs, I think it&apos;s being overconfident in tests. But in the end, I&apos;m happily taking back that objection as this is by far the less important.&lt;/p&gt;


&lt;p&gt;Let me try to put things graphically, everyone loves a graph: if I draw the set of all keys as this:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[-----------------------------------------------------------------------------[
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;i.e, the ring but as a line because I&apos;m ignoring wrapping for this.&lt;/p&gt;

&lt;p&gt;Now, if I display row keys (decorated or not, that doesn&apos;t matter, both are keys), I would have for instance:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[---------------------------|-------|---------------|---------------|---------[
                            k1      k2              k3              k4
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;A key is a point on the ring.&lt;/p&gt;

&lt;p&gt;Now if keys and tokens are a 1 to 1 mapping, then it could be ok to say that a token is a point on the ring, but once it&apos;s not the case, then it looks like that:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;                                t                     t&apos;              t&apos;&apos;
[-------------------------[*|*******|*]----------[**|****]-------[**|******]--[
                            k1      k2              k3              k4
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where t is the token for both k1 and k2 (and an infinite number of other keys (actually finite because we&apos;re working on a computer)), t&apos; the token of k3 (and an &apos;infinite&apos; number of other keys), etc...&lt;/p&gt;

&lt;p&gt;A token is intrinsically a range, a segment on the ring. Shoving DK and Token into the same class everywhere in the code is saying that we&apos;ll use the same class for a point and an interval. How can that be a good idea? How can that not backfire on us and be hard to work with, making it easy to introduce errors?&lt;/p&gt;</comment>
                            <comment id="13125781" author="tjake" created="Wed, 12 Oct 2011 12:33:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;A token is intrinsically a range, a segment on the ring. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But the whole point of the ticket is to remove this concept. Are you saying that can&apos;t be guaranteed?&lt;/p&gt;

&lt;p&gt;This should be possible by making a equals consider the token AND key.  The problem with &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1733&quot; title=&quot;get_range_slices doesn&amp;#39;t return key from start_key in KeyRange any more&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1733&quot;&gt;&lt;del&gt;CASSANDRA-1733&lt;/del&gt;&lt;/a&gt; is sometimes we don&apos;t specify a key since we have have Min token and an intrinsic Max token.  &lt;/p&gt;</comment>
                            <comment id="13125848" author="slebresne" created="Wed, 12 Oct 2011 13:34:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;But the whole point of the ticket is to remove this concept. Are you saying that can&apos;t be guaranteed?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There is a misunderstanding. The whole point of this ticket is to &lt;b&gt;enforce&lt;/b&gt; this concept. A token is a range, a segment on the ring, there is nothing we can do about it. It&apos;s like saying the point of the ticket is to remove the concept that a segment is different from a point.&lt;/p&gt;

&lt;p&gt;I&apos;m happy to discuss that, and that is clearly where we should start, but I&apos;m pretty sure that the &lt;b&gt;problem&lt;/b&gt; we want to fix is that the current code is pretending than a segment is equal to a point. The current code is pretending that a token t is the same thing than a key having this token. This only work if there is only one key have a given token, otherwise it&apos;s buggy, you identify all keys having the same token as equal, that is the problem.&lt;/p&gt;

&lt;p&gt;And saying that you&apos;ll change the comparison of DK to include the key and pretending that a token is the same thing that some fictive key that as far as key comparison is concerned would be before any key having the token (which is &lt;b&gt;exactly&lt;/b&gt; what Pavel&apos;s patch is doing) doesn&apos;t work either. As I&apos;ve said earlier with examples.&lt;/p&gt;

&lt;p&gt;I&apos;m saying that the right way to fix is to make the code treats Token as a segment (because you know, that&apos;s what it is) and a key as a point. Now that, imho, is not of a debatable nature: it&apos;s either true or false (and imho clearly true but maybe i&apos;m completely stupid). But at the very least we should agree on that first, even before thinking about how we will code it.&lt;/p&gt;

&lt;p&gt;Then, once we agree on the problem, there is the question of how we do it. And then, my second argument is that shoving a token (a segment) and a (decorated) key (a point) into the same class (that we would happen to call Token) is, why probably &quot;possible&quot;, likely an error-prone, confusing and frankly ugly idea. You can create a class representing both a segment and point, having it work correctly underneath and write code using that, but it will unlikely be beautiful nor easy to use. But it&apos;s &quot;possible&quot;. &lt;/p&gt;</comment>
                            <comment id="13125855" author="jbellis" created="Wed, 12 Oct 2011 13:46:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;The whole point of this ticket is to enforce this concept. A token is a range, a segment on the ring, there is nothing we can do about it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right.&lt;/p&gt;

&lt;p&gt;Is this still a fair summary of why we want to fix this?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;the problem is that we are using DK both for routing and for local key sorting&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13125883" author="tjake" created="Wed, 12 Oct 2011 14:31:54 +0000"  >&lt;p&gt;My view is a Key requires a Token in our system. I understand that you cant keep multiple keys from mapping to the same token, still I would have liked to see the code deal with Tokens with (optional) keys then a mix of keys and tokens.  I see now this idea is broken in the sense that sorting a list of tokens means different things depending on the context (partitioner bounds vs user defined range)&lt;/p&gt;</comment>
                            <comment id="13125891" author="slebresne" created="Wed, 12 Oct 2011 14:46:06 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Is this still a fair summary of why we want to fix this?&lt;/p&gt;

&lt;p&gt;the problem is that we are using DK both for routing and for local key sorting&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Hum, I would actually rephrase it with token instead of DK, in the sense that we don&apos;t really use DK for routing, DK is a key with it&apos;s token &quot;cached&quot; to speed up computing it, we&apos;re using only the token to route. The problem is we&apos;re also using only the token for local key sorting.&lt;/p&gt;

&lt;p&gt;But while we could/should be using token to route and the DK for local key sorting, we still need to be able to handle local key &lt;b&gt;search&lt;/b&gt; by token. And that is imho the difficulty of this ticket (if we always had an actual valid key to do local key search it would be much easier). And we need local search based on tokens because:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;we allow range_slices on a range of tokens (so this translate ultimately to local search by token)&lt;/li&gt;
	&lt;li&gt;even for range_slices by keys, we still end up splitting the key range by a token in getRestrictedRanges, hence resulting ultimately to a local search by token.&lt;br/&gt;
Then the problem is that since a token is a segment and a key (what we&apos;re searching for) a point, we can&apos;t really compare those, in the sense that a key is not necessarily either stricly greater, equal, or stricly lesser than a token. So you do have to consider both the &quot;bounds&quot; of the token, which are now point and that you can compare to keys.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13152888" author="slebresne" created="Fri, 18 Nov 2011 14:20:25 +0000"  >&lt;p&gt;Attaching rebased patch (against trunk).&lt;/p&gt;

&lt;p&gt;I&apos;ve slightly refactored the patches too. The first contains only the generification of AbstractBounds. It&apos;s obviously a bit &quot;dumb&quot; taken alone since it generify but doesn&apos;t allow anything else than tokens. The only other noticeable thing is the removal of the Range.compare() method (in favor of the compareTo method of Token). I have no idea what that method was about in the first place. The second patch does the rest of the work and has got some minor cleanups. I&apos;ve also tried to add some new comments to make it more digestible.  I also include a third patch with a small unit test.&lt;/p&gt;

&lt;p&gt;Having spend quite some time thinking about this issue, I do think that this is a good way to fix it, the alternative of allowing to mixing Token and DecoratedKey directly in a Range being (to have pursued it a bit before giving up) much more messy and error prone imho. Now I can&apos;t force anyone to like this solution but I also won&apos;t rebase this forever.&lt;/p&gt;</comment>
                            <comment id="13153240" author="jbellis" created="Fri, 18 Nov 2011 23:51:39 +0000"  >&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+    public static final DecoratedKey minKey = new DecoratedKey(partitioner.getMinimumToken(), false);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think I&apos;d rather have these in the partitioner.  (I know partitioner is cluster-global right now but it still feels wrong to &quot;hoist&quot; something partitioner dependent out and make it static final.)&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+        assert token != null &amp;amp;&amp;amp; key != null;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This feels odd when we go ahead and construct DKs with null key anyway in the other constructor.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Important&lt;/b&gt;: I think my biggest problem with this patch is that a DK may or may not have a key that when given to the partitioner, results in the Token in the DK.  And there&apos;s nothing to show that is the case, except that key == null or Empty.  So we&apos;re still pretending a Token &quot;is&quot; a key, we&apos;ve just made it more complicated.  Could we update the methods for whose benefits we&apos;re performing the Token -&amp;gt; DK conversion, to accept RingPosition instead?&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+        return token.hashCode() + (key == null ? 0 : key.hashCode());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I don&apos;t see a good reason to not use a &quot;real&quot; hashcode implementation (Objects.hashCode is useful here).&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+        // null is used as a &apos;end of range&apos; marker, so DK(t, k) is always before DK(t, null) unless k == null
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Still not a huge fan of using null to mean end of range, but I guess I don&apos;t have a better suggestion. There&apos;s clearly a lot of places in this patch where it&apos;s causing special case ugliness though, independent of its status as &quot;max.&quot;&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+        // minimunKey, see Token.upperBoundKey()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;typo.  (both occurrences.)&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;-        T min = (T)current.partitioner.getMinimumToken();
+        T min = (T)current.left.minimumValue(current.partitioner);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think the positives of making this Generic are outweighed by the negative of implying that minimum value for partitioner X depends on the RingPosition that is returning it.  I think I&apos;d rather accept the casting ugliness of having a Partitioner method that does instanceof checks to return the appropriate type.  &lt;/p&gt;

&lt;p&gt;&lt;b&gt;Serializer code&lt;/b&gt;: How does DK, AB, etc. code deal w/ backwards compatibility issues?  Looks like some (AES) can get by with saying &quot;we don&apos;t support mixed-version streaming&quot; but others (IndexScanCommand) cannot.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+        assert left.compareTo(right) &amp;lt;= 0 || right.isMinimum(partitioner) : &quot;[&quot; + left + &quot;,&quot; + right + &quot;]&quot;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What if we added a Partitioner reference so we could just ask isMinimum()?&lt;/p&gt;
</comment>
                            <comment id="13153250" author="jbellis" created="Sat, 19 Nov 2011 00:03:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think my biggest problem with this patch is that a DK may or may not have a key that when given to the partitioner, results in the Token in the DK.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Put another way: in my ideal world, DK.token would be purely an optimization to avoid calling partitioner.getToken(key) over and over.&lt;/p&gt;</comment>
                            <comment id="13154293" author="slebresne" created="Mon, 21 Nov 2011 16:54:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;Put another way: in my ideal world, DK.token would be purely an optimization to avoid calling partitioner.getToken(key) over and over.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I understand that, but I think there is two different things and I want to know exactly where the disagreement/problem is.&lt;/p&gt;

&lt;p&gt;The first problem, which is imho the core of this ticket, is that the code needs to be able somehow to deal with things like (where I use k for keys and t for tokens, and the term range for either Range or Bounds):&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Is key k in the range &lt;span class=&quot;error&quot;&gt;&amp;#91;k&amp;#39;, t&amp;#93;&lt;/span&gt; (or (t&apos;, k&apos;&apos;])? Because when you do a range_slice of &lt;span class=&quot;error&quot;&gt;&amp;#91;k&amp;#39;, k&amp;#39;&amp;#39;&amp;#93;&lt;/span&gt; and there is multiple nodes and &lt;span class=&quot;error&quot;&gt;&amp;#91;k&amp;#39;, k&amp;#39;&amp;#39;&amp;#93;&lt;/span&gt; spans multiple replica, we will end up requesting all keys in &lt;span class=&quot;error&quot;&gt;&amp;#91;k&amp;#39;, t&amp;#93;&lt;/span&gt; (for some t) or (t&apos;, k&apos;&apos;].&lt;/li&gt;
	&lt;li&gt;Is key k in range (t, t&apos;]? Because we&apos;re allowed to range query keys by a token range, but also a few other reason, like the fact that during validation compaction we hashes together keys within a token range.&lt;br/&gt;
Note that those are not trivial questions, because for instance &lt;span class=&quot;error&quot;&gt;&amp;#91;k&amp;#39;, t&amp;#93;&lt;/span&gt;, while we intuitively understand what it represents is a weird beast in that is a range a point and a segment?!&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Or in other words, as much as I&apos;d like the operations on Tokens and the ones on Keys to be two completely orthogonal sets of operation with no interaction whatsoever, it is not the case and we have to deal with it.&lt;/p&gt;

&lt;p&gt;Dealing with the case where we need tokens and we have keys is trivial (we just call Key.getToken() and boom, we&apos;re back in the case with only tokens).&lt;/p&gt;

&lt;p&gt;The problem is when we fundamentally work on keys, but have only token to start with. Today (i.e. before this ticket), we take a simplification by doing essentially the same thing that in the &apos;needs token but got keys&apos; case by having a sort of Token.getKey() (it&apos;s more ugly in practice, we inline calls to new DecoratedKey(t, null), but that&apos;s the same thing). But doing that forces in itself the fact that key an token are in bijection and we want to lift that.&lt;/p&gt;

&lt;p&gt;One solution could be to try to keep Token as long as we can, even in places where we really need a key and have the code deal with that. I can understand that on the surface that could look clean, but in practice the code to do that correctly would a pure nightmare. Just trying to implement a Range that would mix token and keys (like the &lt;span class=&quot;error&quot;&gt;&amp;#91;k&amp;#39;, t&amp;#93;&lt;/span&gt; range above) is a complete mess.&lt;/p&gt;

&lt;p&gt;So what this patch does is realizing that you could characterize the set of keys that a token t represents with only two keys: the smallest key having token t, and the biggest key having token t.&lt;/p&gt;

&lt;p&gt;Now, supposing we agree on what is above, the rest is implementation details and that&apos;s probably a much simpler discussion. Note that above I&apos;m not talking of DecoratedKey, only key. But the question is, how do you represent those two new keys (for each token). The patch uses special values of the key field of DK to deal with those. I can agree this is not the cleanest thing ever and I&apos;m fine looking for a different encoding, but I just don&apos;t have a much better idea, and frankly I don&apos;t find that horrible either.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think I&apos;d rather have these in the partitioner&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Good idea.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;his feels odd when we go ahead and construct DKs with null key anyway in the other constructor.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The goal here is to avoid constructing one of the two &apos;fake&apos; keys by accident For that the second constructor is dedicated to their construction and as the commnet says, you&apos;re not even supposed to use this second constructor, but use Token.&lt;/p&gt;
{upper|lower}
&lt;p&gt;Bound instead. Actually, the assert should check for the EMPTY_BYTE_BUFFER.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Could we update the methods for whose benefits we&apos;re performing the Token -&amp;gt; DK conversion, to accept RingPosition instead?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Frankly, and as argumented above, no, not without &lt;b&gt;huge&lt;/b&gt; pain. We only do that conversion in places where we will have to do it at some point, and trying to push Tokens deeper would only serve in having operations that make no real sense for Tokens be able to actually deal with Token. As one example, we would have to make Range with a mix of Token and Keys, and frankly that will be a total mess to code.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I don&apos;t see a good reason to not use a &quot;real&quot; hashcode implementation (Objects.hashCode is useful here)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not sure I follow but ByteBuffer.hashCode() does hash the content of the buffer if that was what you meant.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;There&apos;s clearly a lot of places in this patch where it&apos;s causing special case ugliness though, independent of its status as &quot;max.&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Again, I would be open to better encoding. But is there really that much places? The patch tried to make it so that no code outside of DecoratedKey really have to deal with it. If not perfect, I actually think it&apos;s better contained that before the patch.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think the positives of making this Generic are outweighed by the negative of implying that minimum value for partitioner X depends on the RingPosition that is returning it. I think I&apos;d rather accept the casting ugliness of having a Partitioner method that does instanceof checks to return the appropriate type.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think you&apos;re right.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Serializer code: How does DK, AB, etc. code deal w/ backwards compatibility issues?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Basically, old version only understand AbstractBounds of Token, while new version generates/accept AbstractBounds of either token, or keys. When old sends to new and keys are expected, new convert the range/bounds of token as range/bounds of keys. When new sends to old, it converts any range/bounds of keys to range/bounds of token.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What if we added a Partitioner reference so we could just ask isMinimum()?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Do you mean to have the DK to have a reference to the partioner? If so, I agree that it&apos;s probably something we should, but it&apos;s nothing specific to that patch so I&apos;d rather leave it to another ticket.&lt;/p&gt;</comment>
                            <comment id="13154335" author="jbellis" created="Mon, 21 Nov 2011 18:16:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;in practice, we inline calls to new DecoratedKey(t, null)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right.  I must be missing something crucial, because that&apos;s exactly what it looks like we&apos;re still doing in this patch, only with a special constructor.&lt;/p&gt;</comment>
                            <comment id="13154533" author="slebresne" created="Mon, 21 Nov 2011 21:17:14 +0000"  >&lt;p&gt;No, no, the patch does use the same think. I merely said that the patch does some attempt at a better encapsulation, as it seems better to use the Token.&lt;/p&gt;
{upper|lower}BoundKey to creates those fake keys that inlining the call to the constructor all over the code (which we do now). It makes the use of null more of an internal detail of DecoratedKey (not completely, granted, but it&apos;s a little bit better). It also makes it simpler to check we don&apos;t accidentally construct a DK with a null key by accident (the goal of the assertion in the first DK constructor in the patch).&lt;br/&gt;
&lt;br/&gt;
But let it be clear that I&apos;m not making any claim that this patch &quot;cleans&quot; some ugliness in the current code. It mainly try to solve the problem at hand, which is basically to be able to do range_slices and getting the right result even when multiple keys have the same token.&lt;br/&gt;
&lt;br/&gt;
This is not saying it wouldn&apos;t be good to fix any current ugliness at the same time if possible, but in truth, I don&apos;t find that using special DK to represent special keys is such an ugly hack (not either claiming it&apos;s super beautiful, I just don&apos;t have a particular hatred of this). Besides, I don&apos;t have tons of ideas to fix the issue at end (the priority) and make the code clearly cleaner. And I do think that whatever ugliness the current have, this patch doesn&apos;t make it worst.&lt;br/&gt;
&lt;br/&gt;
Anyway, I&apos;ll try to see if I can improve the encapsulation of the Token.{upper|lower}
&lt;p&gt;BoundKey representation and see if I can come with something slightly cleaner.&lt;/p&gt;</comment>
                            <comment id="13154553" author="jbellis" created="Mon, 21 Nov 2011 21:28:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;the patch does some attempt at a better encapsulation, as it seems better to use the Token.{upper|lower}BoundKey to creates those fake keys that inlining the call to the constructor all over the code (which we do now). &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Okay, I&apos;ll buy that.  It&apos;s an awful lot of code churn for IMO a relatively minor win, but I see where you&apos;re going with that.&lt;/p&gt;

&lt;p&gt;Help me understand this patchset a different way: which is the part without which &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1600&quot; title=&quot;Merge get_indexed_slices with get_range_slices&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1600&quot;&gt;&lt;del&gt;CASSANDRA-1600&lt;/del&gt;&lt;/a&gt; is impossible?&lt;/p&gt;</comment>
                            <comment id="13155934" author="slebresne" created="Wed, 23 Nov 2011 16:06:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;Help me understand this patchset a different way: which is the part without which &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1600&quot; title=&quot;Merge get_indexed_slices with get_range_slices&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1600&quot;&gt;&lt;del&gt;CASSANDRA-1600&lt;/del&gt;&lt;/a&gt; is impossible?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1600&quot; title=&quot;Merge get_indexed_slices with get_range_slices&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1600&quot;&gt;&lt;del&gt;CASSANDRA-1600&lt;/del&gt;&lt;/a&gt; requires that the row key range requested be known by CFS.getRangeSlice/search, while today it only gest the corresponding tokens.  We could possibly do what your first patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1600&quot; title=&quot;Merge get_indexed_slices with get_range_slices&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1600&quot;&gt;&lt;del&gt;CASSANDRA-1600&lt;/del&gt;&lt;/a&gt; did and add the keys separately. You&apos;ll have to deal with wrapping and such, but that&apos;s probably doable.&lt;/p&gt;

&lt;p&gt;What this patchset does is make getRangeSlice/search actually take keys, so this greatly simplify &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1600&quot; title=&quot;Merge get_indexed_slices with get_range_slices&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1600&quot;&gt;&lt;del&gt;CASSANDRA-1600&lt;/del&gt;&lt;/a&gt;. But &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1600&quot; title=&quot;Merge get_indexed_slices with get_range_slices&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1600&quot;&gt;&lt;del&gt;CASSANDRA-1600&lt;/del&gt;&lt;/a&gt; is probably doable without this, it&apos;s just the logical first step before getting a clean implementation. Now for the specific parts, as said we need to be able to have keys for getRangeSlice/search, which basically require the bulk of this patchset (i.e. for &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1600&quot; title=&quot;Merge get_indexed_slices with get_range_slices&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1600&quot;&gt;&lt;del&gt;CASSANDRA-1600&lt;/del&gt;&lt;/a&gt;, we could still have DecoratedKey.compareTo() to only compare the tokens and not the keys, but that&apos;s probably it)&lt;/p&gt;

&lt;p&gt;But truth being told, &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1600&quot; title=&quot;Merge get_indexed_slices with get_range_slices&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1600&quot;&gt;&lt;del&gt;CASSANDRA-1600&lt;/del&gt;&lt;/a&gt; is by far not my main motivation for this. My main motivation is &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1684&quot; title=&quot;Entity groups&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1684&quot;&gt;&lt;del&gt;CASSANDRA-1684&lt;/del&gt;&lt;/a&gt;. For the latter, if we want to do it &apos;natively&apos;, we will have lots of key having the same token, so this ticket is an absolute requirement before even getting started. And there is also the problem of md5 collision &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13155936" author="slebresne" created="Wed, 23 Nov 2011 16:07:19 +0000"  >&lt;p&gt;I&apos;ve tried finding a better encapsulation for the &apos;fake&apos; keys of the patch.  The idea being to restrict DK to &apos;true&apos; row key, i.e. the ones that can be written on disk and create a new class (Token.KeyBound) to represent the two &quot;fake&quot; key for each token representing the smallest/biggest key having the token. To make it work together, they share the new RowPosition interface.&lt;/p&gt;

&lt;p&gt;Some of the methods accepts a RowPosition (instead of DecoratedKey) to indicate that it can accept a &apos;fake&apos; key for purpose of selecting true keys.  So for instance SSTableReader.getPosition() accepts a RowPosition. However, SSTableReader.getCachedPosition() only accepts a DK, because the key cache can only contain a &quot;true&quot; row key.&lt;/p&gt;

&lt;p&gt;Anyway, I actually end up liking this. With that, we never ever create a DK with a null key (nor even an empty one, which wouldn&apos;t be a true key either).  This is more clear and avoids mistakes. Unfortunately the patch got bigger &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13158480" author="jbellis" created="Mon, 28 Nov 2011 14:49:02 +0000"  >&lt;p&gt;+1 on the KeyBound approach.  This is exactly what I was hoping for.&lt;/p&gt;

&lt;p&gt;Returning to a minor point:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;bq. I don&apos;t see a good reason to not use a &quot;real&quot; hashcode implementation (Objects.hashCode is useful here)&lt;/p&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;&lt;p&gt;Not sure I follow but ByteBuffer.hashCode() does hash the content of the buffer if that was what you meant.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I mean that straight addition is a weak hashcode combination since X + Y is the same as Y + X.  &quot;return Objects.hashCode(X, Y)&quot; is an easy way to do it &quot;right&quot; with no more code than the weak approach.  Doesn&apos;t matter much here but it&apos;s good practice imo.&lt;/p&gt;

&lt;p&gt;Another nit: should we be using a enum for RowPosition.kind?&lt;/p&gt;

&lt;p&gt;Meta observation: I&apos;m glad we&apos;re not doing this a week before freeze. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13159307" author="slebresne" created="Tue, 29 Nov 2011 15:10:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;I mean that straight addition is a weak hashcode combination since X + Y is the same as Y + X. &quot;return Objects.hashCode(X, Y)&quot; is an easy way to do it &quot;right&quot; with no more code than the weak approach. Doesn&apos;t matter much here but it&apos;s good practice imo.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Make sense. I made the DK hashcode be only based on the key hashcode though (since the token is just a cached value for getToken() &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;). The hashCode method of Token.KeyBound don&apos;t use Objects.hasCode(), but I really think that in that case it doesn&apos;t matter at all and it avoids the boxing of the boolean. I can change it though if that&apos;s the only problem remaining.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Another nit: should we be using a enum for RowPosition.kind?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What do you mean exactly by that? Are you talking of the kind use in RowPositionSerializer? To have an enum to distinguish between DK and Token.KeyBound instance of doing the instanceof? If so why not, but I&apos;m not sure it buys us anything.&lt;/p&gt;</comment>
                            <comment id="13159312" author="jbellis" created="Tue, 29 Nov 2011 15:24:38 +0000"  >&lt;p&gt;Okay, we can skip the hashcode change if you&apos;re worried about boxing.&lt;/p&gt;

&lt;p&gt;Yes, that&apos;s what I&apos;m referring to for &quot;kind.&quot;  Seeing code like &quot;if kind == 0&quot; means I have to go back to the kind method to see what a return value of 0 means.&lt;/p&gt;</comment>
                            <comment id="13159965" author="slebresne" created="Wed, 30 Nov 2011 10:44:59 +0000"  >&lt;p&gt;Attaching v3, rebased and using an enum for the RowPosition kind. I could have changed a few &lt;tt&gt;assert key instanceof DecoratedKey&lt;/tt&gt; by &lt;tt&gt;assert key.kind() == RowPosition.Kind.ROW_KEY&lt;/tt&gt; I suppose, but I prefered keeping the instanceof since each time the next line do a cast to DK, so this feels more coherent like that.&lt;/p&gt;</comment>
                            <comment id="13160063" author="jbellis" created="Wed, 30 Nov 2011 14:05:15 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13160764" author="hudson" created="Thu, 1 Dec 2011 09:25:23 +0000"  >&lt;p&gt;Integrated in Cassandra #1229 (See &lt;a href=&quot;https://builds.apache.org/job/Cassandra/1229/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Cassandra/1229/&lt;/a&gt;)&lt;br/&gt;
    remove assumption that key and token are in bijection&lt;br/&gt;
patch by slebresne; reviewed by jbellis for &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1034&quot; title=&quot;Remove assumption that Key to Token is one-to-one&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1034&quot;&gt;&lt;del&gt;CASSANDRA-1034&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;slebresne : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1208993&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1208993&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/cassandra/trunk/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/client/RingCache.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/config/DatabaseDescriptor.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/cql/QueryProcessor.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/DecoratedKey.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/HintedHandOffManager.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/IndexScanCommand.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/Memtable.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/RangeSliceCommand.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/RowIteratorFactory.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/RowPosition.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/compaction/CompactionManager.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/compaction/LeveledManifest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/index/SecondaryIndexManager.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/index/SecondaryIndexSearcher.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/index/keys/KeysSearcher.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/db/marshal/LocalByPartionerType.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/AbstractBounds.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/AbstractByteOrderedPartitioner.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/AbstractPartitioner.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/BootStrapper.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/Bounds.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/IPartitioner.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/LocalPartitioner.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/OrderPreservingPartitioner.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/RandomPartitioner.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/Range.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/RingPosition.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/dht/Token.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/hadoop/ColumnFamilyInputFormat.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordWriter.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/io/sstable/IndexSummary.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/io/sstable/SSTableBoundedScanner.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/io/sstable/SSTableLoader.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/io/sstable/SSTableReader.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/io/sstable/SSTableScanner.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/locator/AbstractReplicationStrategy.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/locator/TokenMetadata.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/net/MessagingService.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/service/AntiEntropyService.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/service/StorageProxy.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/service/StorageService.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/service/StorageServiceMBean.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/streaming/StreamIn.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/streaming/StreamOut.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/streaming/StreamRequestMessage.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/streaming/StreamingRepairTask.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/thrift/CassandraServer.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/thrift/ThriftValidation.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/tools/BulkLoader.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/utils/FBUtilities.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/src/java/org/apache/cassandra/utils/MerkleTree.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/Util.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/db/CleanupTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/db/KeyCollisionTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/db/SerializationsTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/dht/AbstractBoundsTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/dht/BootStrapperTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/dht/PartitionerTestCase.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/dht/RangeTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/io/CompactSerializerTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/service/AntiEntropyServiceTestAbstract.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/service/MoveTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/service/SerializationsTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/service/StorageProxyTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/streaming/SerializationsTest.java&lt;/li&gt;
	&lt;li&gt;/cassandra/trunk/test/unit/org/apache/cassandra/streaming/StreamingTransferTest.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13160794" author="slebresne" created="Thu, 1 Dec 2011 10:14:43 +0000"  >&lt;p&gt;Committed \o/&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12476968">CASSANDRA-1600</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12467280">CASSANDRA-1205</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12495430">CASSANDRA-1978</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12504886" name="0001-Generify-AbstractBounds-v2.patch" size="175481" author="slebresne" created="Wed, 23 Nov 2011 16:07:18 +0000"/>
                            <attachment id="12505606" name="0001-Generify-AbstractBounds-v3.patch" size="175567" author="slebresne" created="Wed, 30 Nov 2011 10:44:59 +0000"/>
                            <attachment id="12504214" name="0001-Generify-AbstractBounds.patch" size="175481" author="slebresne" created="Fri, 18 Nov 2011 14:20:25 +0000"/>
                            <attachment id="12504887" name="0002-Remove-assumption-that-token-and-keys-are-one-to-one-v2.patch" size="116933" author="slebresne" created="Wed, 23 Nov 2011 16:07:18 +0000"/>
                            <attachment id="12505607" name="0002-Remove-assumption-that-token-and-keys-are-one-to-one-v3.patch" size="117500" author="slebresne" created="Wed, 30 Nov 2011 10:44:59 +0000"/>
                            <attachment id="12504215" name="0002-Remove-assumption-that-token-and-keys-are-one-to-one.patch" size="91464" author="slebresne" created="Fri, 18 Nov 2011 14:20:25 +0000"/>
                            <attachment id="12504888" name="0003-unit-test-v2.patch" size="9518" author="slebresne" created="Wed, 23 Nov 2011 16:07:18 +0000"/>
                            <attachment id="12505608" name="0003-unit-test-v3.patch" size="9518" author="slebresne" created="Wed, 30 Nov 2011 10:44:59 +0000"/>
                            <attachment id="12504216" name="0003-unit-test.patch" size="9519" author="slebresne" created="Fri, 18 Nov 2011 14:20:25 +0000"/>
                            <attachment id="12459138" name="1034_v1.txt" size="1738" author="tjake" created="Tue, 9 Nov 2010 05:19:50 +0000"/>
                            <attachment id="12498465" name="CASSANDRA-1034.patch" size="303134" author="xedin" created="Mon, 10 Oct 2011 20:42:44 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[slebresne]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14985</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            13 years, 51 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0g2lj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>91851</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>jbellis</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[jbellis]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12961"><![CDATA[Low]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>