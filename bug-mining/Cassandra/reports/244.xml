<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:12:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-603] pending range collision between nodes</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-603</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;We bootstrapped 5 nodes on the east coast from an existing cluster (5) on west. We waited at least 60 seconds before starting up each node so it would start bootstrapping. We started seeing these types of errors:&lt;/p&gt;

&lt;p&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;GMFD:1&amp;#93;&lt;/span&gt; 2009-12-04 01:45:42,065 Gossiper.java (line 568) Node /X.X.X.140 has now joined.&lt;br/&gt;
ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;GMFD:1&amp;#93;&lt;/span&gt; 2009-12-04 01:46:14,371 DebuggableThreadPoolExecutor.java (line 127) Error in ThreadPoolExecutor&lt;br/&gt;
java.lang.RuntimeException: pending range collision between /X.X.X.139 and /X.X.X.140&lt;br/&gt;
        at org.apache.cassandra.locator.TokenMetadata.addPendingRange(TokenMetadata.java:242)&lt;br/&gt;
        at org.apache.cassandra.service.StorageService.updateBootstrapRanges(StorageService.java:481)&lt;br/&gt;
        at org.apache.cassandra.service.StorageService.onChange(StorageService.java:402)&lt;br/&gt;
        at org.apache.cassandra.gms.Gossiper.doNotifications(Gossiper.java:692)&lt;br/&gt;
        at org.apache.cassandra.gms.Gossiper.applyApplicationStateLocally(Gossiper.java:657)&lt;br/&gt;
        at org.apache.cassandra.gms.Gossiper.applyStateLocally(Gossiper.java:610)&lt;br/&gt;
        at org.apache.cassandra.gms.GossipDigestAckVerbHandler.doVerb(Gossiper.java:978)&lt;br/&gt;
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:38)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:619)&lt;br/&gt;
ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;GMFD:1&amp;#93;&lt;/span&gt; 2009-12-04 01:46:14,378 CassandraDaemon.java (line 71) Fatal exception in thread Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;GMFD:1,5,main&amp;#93;&lt;/span&gt;   &lt;br/&gt;
java.lang.RuntimeException: pending range collision between /X.X.X.139 and /X.X.X.140&lt;br/&gt;
java.lang.RuntimeException: pending range collision between /X.X.X.139 and /X.X.X.140&lt;br/&gt;
        at org.apache.cassandra.locator.TokenMetadata.addPendingRange(TokenMetadata.java:242)&lt;br/&gt;
        at org.apache.cassandra.service.StorageService.updateBootstrapRanges(StorageService.java:481)&lt;br/&gt;
        at org.apache.cassandra.service.StorageService.onChange(StorageService.java:402)&lt;br/&gt;
        at org.apache.cassandra.gms.Gossiper.doNotifications(Gossiper.java:692)&lt;br/&gt;
        at org.apache.cassandra.gms.Gossiper.applyApplicationStateLocally(Gossiper.java:657)&lt;br/&gt;
        at org.apache.cassandra.gms.Gossiper.applyStateLocally(Gossiper.java:610)&lt;br/&gt;
        at org.apache.cassandra.gms.GossipDigestAckVerbHandler.doVerb(Gossiper.java:978)&lt;br/&gt;
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:38)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:619) &lt;/p&gt;</description>
                <environment></environment>
        <key id="12442507">CASSANDRA-603</key>
            <summary>pending range collision between nodes</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jaakko">Jaakko Laine</assignee>
                                    <reporter username="lenn0x">Chris Goffinet</reporter>
                        <labels>
                    </labels>
                <created>Fri, 4 Dec 2009 20:45:10 +0000</created>
                <updated>Tue, 16 Apr 2019 09:33:31 +0000</updated>
                            <resolved>Wed, 16 Dec 2009 18:13:31 +0000</resolved>
                                        <fixVersion>0.5</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                <comments>
                            <comment id="12786747" author="jaakko" created="Mon, 7 Dec 2009 00:47:38 +0000"  >&lt;p&gt;Pending range collision check is currently too trigger-happy and should be relaxed a bit. At the moment pending range collision happens if any of the node&apos;s ranges clash, although it should happen only if the primary range node is booting to clashes.&lt;/p&gt;

&lt;p&gt;However, if your nodes already had finished bootstrapping, then this is another issue completely. Haven&apos;t seen such case myself, but I&apos;ll have a look.&lt;/p&gt;</comment>
                            <comment id="12786897" author="jaakko" created="Mon, 7 Dec 2009 13:02:24 +0000"  >&lt;p&gt;Could you please check if the nodes in question (.139 and .140) had already completed bootstrap (log entry &quot;Bootstrap completed...&quot; on INFO level)?&lt;/p&gt;</comment>
                            <comment id="12787002" author="lenn0x" created="Mon, 7 Dec 2009 17:29:15 +0000"  >&lt;p&gt;No they did not. The messages started showing up a few minutes after I believe, anticompaction was still running.&lt;/p&gt;</comment>
                            <comment id="12787449" author="jaakko" created="Tue, 8 Dec 2009 13:16:38 +0000"  >&lt;p&gt;For now it is best to wait until one bootstrap has finished before starting another one. As mentioned pending ranges clash is relatively easy to get (happens if any of replica ranges are the same), so before this one is fixed, you might easily see this even &quot;without reason&quot;.&lt;/p&gt;</comment>
                            <comment id="12787452" author="jaakko" created="Tue, 8 Dec 2009 13:28:04 +0000"  >&lt;p&gt;As for the fix, there are two (at least) two options I think:&lt;/p&gt;

&lt;p&gt;(1) Add a list of pending primary ranges (or tokens) to token metadata. Currently primary and replica pending ranges are all in one list, so there is no way to check afterwards if primary ranges collide.&lt;/p&gt;

&lt;p&gt;(2) Ditch pending ranges completely and convert it to pending tokens. Problem with pending ranges is that it is static structure (determined at the time of bootstrap/leaving) and does not react to token changes during the operation. This introduces a number of difficult-to-prove-that-it-works-correctly and difficult-to-handle-correctly corner cases regarding node movement as proved by various mail and JIRA discussions recently. If we had a list of pending tokens instead, it would adapt to any changes that happen during the move operation. There are currently issues in pending range handling (not cleaned up correctly in all cases, thread/atomicy issues, leaving coordination, etc) that would mostly go away if we swiched to pending tokens instead, I think. Might be that I&apos;m overlooking something obvious here, but to me it seems like dynamically adapting pending token list would be more suitable for this.&lt;/p&gt;</comment>
                            <comment id="12787588" author="lenn0x" created="Tue, 8 Dec 2009 17:26:16 +0000"  >&lt;p&gt;Jaakko,&lt;/p&gt;

&lt;p&gt;Just curious, for all the node movement coordination operations, would Zookeeper make any of this a bit easier to manage?&lt;/p&gt;</comment>
                            <comment id="12788712" author="jaakko" created="Thu, 10 Dec 2009 13:23:17 +0000"  >&lt;p&gt;It certainly is worth considering. For now I think we can do without, but with automatic load balancing coordination issues will become more complex.&lt;/p&gt;

&lt;p&gt;I&apos;m going to have a look at this pending range issue tomorrow.&lt;/p&gt;</comment>
                            <comment id="12789250" author="jaakko" created="Fri, 11 Dec 2009 11:32:02 +0000"  >&lt;p&gt;Patch attached. Modifications:&lt;/p&gt;

&lt;p&gt;Keep track of booting and leaving tokens and calculate pending ranges again every time there is status change. This will keep them up to date. To ensure that pending ranges cover node&apos;s final range, following reasoning is used in calculation:&lt;/p&gt;

&lt;p&gt;(1) When in doubt, it is better to write too much to a node than too little. That is, if there are multiple nodes moving, calculate the biggest ranges a node could have. Cleaning up unneeded data afterwards is better than missing writes during movement.&lt;/p&gt;

&lt;p&gt;(2) When a node leaves, ranges for other nodes can only grow (a node might get additional ranges, but it will not lose any of its current ranges as a result of a leave). Therefore we will first remove &lt;em&gt;all&lt;/em&gt; leaving tokens for the sake of calculation and then check what ranges would go where if all nodes are to leave. This way we get the biggest possible ranges with regard current leave operations, covering all subsets of possible final range values.&lt;/p&gt;

&lt;p&gt;(3) When a node bootstraps, ranges of other nodes can only get smaller. Without doing complex calculations to see if multiple bootstraps overlap, we simply base calculations on the same token ring used before (reflecting situation after all leave operations have completed). Bootstrapping nodes will be added and removed one by one to that metadata and checked what their ranges would be. This will give us the biggest possible ranges the node could have. It might be that other bootstraps make our actual final ranges smaller, but it does not matter as we can clean up the data afterwards.&lt;/p&gt;

&lt;p&gt;Bootstrap Token collision (old pending range collision) is thrown now only if bootstrap tokens are identical.&lt;/p&gt;

&lt;p&gt;Calculating pending ranges is rather heavy operation, but since it is done only once when a node changes state in the cluster, it should be manageable.&lt;/p&gt;

&lt;p&gt;This patch would make #572 cleaner to do, since we now know which way a node is going and can update pending ranges according to any changes.&lt;/p&gt;

&lt;p&gt;Edit: this also removes nodeprobe cancelpendingranges. That would be pointless now. If there is a node/token that has not finished move operation, nodeprobe removetoken will do the trick.&lt;/p&gt;</comment>
                            <comment id="12790419" author="jbellis" created="Mon, 14 Dec 2009 22:32:56 +0000"  >&lt;p&gt;1, 2, and 3 are all how the existing code works in my mind (which may not be how it works in reality &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.  What does the extra tracking of bootstrap tokens &amp;amp; leaving endpoints buy us?  As you said, pending ranges shouldn&apos;t overlap in the first place unless there is a token collision.&lt;/p&gt;</comment>
                            <comment id="12790575" author="jaakko" created="Tue, 15 Dec 2009 05:55:59 +0000"  >&lt;p&gt;Unfortunately it doesn&apos;t quite work that way &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;First the case of leaving nodes:&lt;/p&gt;

&lt;p&gt;Problem with current implementation is that pending ranges is calculated only once at the time of leaving. Suppose there is a ring of nodes A, B, C, D and E with replication factor 2. Ring status is this:&lt;/p&gt;

&lt;p&gt;(primary, replica)&lt;br/&gt;
E-A, D-E&lt;br/&gt;
A-B, E-A&lt;br/&gt;
B-C, A-B&lt;br/&gt;
C-D, B-C&lt;br/&gt;
D-E, C-D&lt;/p&gt;

&lt;p&gt;Suppose C prepares to leave. After hearing STATE_LEAVING from C, ring status will be:&lt;/p&gt;

&lt;p&gt;(primary, replica, pending)&lt;br/&gt;
E-A, D-E&lt;br/&gt;
A-B, E-A&lt;br/&gt;
B-C, A-B&lt;br/&gt;
C-D, B-C, A-B&lt;br/&gt;
D-E, C-D, B-C&lt;/p&gt;

&lt;p&gt;Now suppose also B leaves. After receiving STATE_LEAVING, ring status with current implementation will be:&lt;br/&gt;
E-A, D-E&lt;br/&gt;
A-B, E-A&lt;br/&gt;
B-C, A-B, E-A&lt;br/&gt;
C-D, B-C, A-B&lt;br/&gt;
D-E, C-D, B-C&lt;/p&gt;

&lt;p&gt;This is clearly wrong, as (1) E-A is being streamed to C, even though it is leaving and (2) D is not getting this range, even if it is supposed to.&lt;/p&gt;

&lt;p&gt;In order to do this right, we will need to know at all times what nodes are leaving and calculate ranges accordingly. An anonymous pending ranges list is not enough, as that does not tell which node is leaving and/or if the ranges are there because of bootstrap or leave operation.&lt;/p&gt;


&lt;p&gt;As for bootstrapping and pending range collision:&lt;/p&gt;

&lt;p&gt;Suppose that there is a ring of nodes A, C and E, with replication factor 3. Node D bootstraps between C and E, so its pending ranges will be E-A, A-C and C-D. Now suppose node B bootstraps between A and C at the same time. Its pending ranges would be C-E, E-A and A-B. Now both nodes have pending range E-A in their list, which will cause pending range collision even though we&apos;re only talking about replica range, not even primary range. The same thing happens for any nodes that boot simultaneously between same two nodes. For this we cannot simply make pending ranges a multimap, since that would make us unable to notice the real problem of two nodes trying to boot using the same token. In order to do this properly, we need to know what tokens are booting at any time.&lt;/p&gt;</comment>
                            <comment id="12790955" author="jbellis" created="Tue, 15 Dec 2009 21:14:38 +0000"  >&lt;p&gt;Thanks for the explanation.  Committed, w/ parts of the above as comments to TokenMetadata.&lt;/p&gt;

&lt;p&gt;One minor quibble is, I&apos;d really prefer to avoid having this circular TM &amp;lt;-&amp;gt; ReplicationStrategy dependency cycle.  (Which is part of the reason the code was structured the way it was: RS would pass TM the info it needed to do its thing in a concurrency-safe fashion, w/o needing to reach into RS itself which makes auditing for thread-safety much harder).  So if you think of a way to refactor that, even better. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12790956" author="jbellis" created="Tue, 15 Dec 2009 21:15:55 +0000"  >&lt;p&gt;Oops, I take back the &quot;committed&quot; part &amp;#8211; I&apos;m getting test failures.  I think they just need to be updated to use the new method signatures.&lt;/p&gt;</comment>
                            <comment id="12791253" author="jaakko" created="Wed, 16 Dec 2009 07:44:06 +0000"  >&lt;p&gt;New version:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Moved calculatePendingRanges to StorageService&lt;/li&gt;
	&lt;li&gt;fixed test errors&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12791500" author="jbellis" created="Wed, 16 Dec 2009 18:13:31 +0000"  >&lt;p&gt;committed to 0.5 and trunk&lt;/p&gt;</comment>
                            <comment id="12792157" author="hudson" created="Thu, 17 Dec 2009 22:03:03 +0000"  >&lt;p&gt;Integrated in Cassandra #291 (See &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Cassandra/291/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://hudson.zones.apache.org/hudson/job/Cassandra/291/&lt;/a&gt;)&lt;/p&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12428139" name="603.patch" size="30887" author="jaakko" created="Wed, 16 Dec 2009 07:44:06 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[jaakko]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>19774</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            15 years, 49 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0fzy7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>91422</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>