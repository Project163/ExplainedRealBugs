<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 23:04:52 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-11670] Rebuilding or streaming MV generates mutations larger than max_mutation_size_in_kb</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-11670</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;I have in cluster 2 DC, in each DC - 2 Nodes. I wanted to add 1 node to each DC. One node has been added successfully after I had made scrubing. &lt;br/&gt;
Now I&apos;m trying to add node to another DC, but get error: org.apache.cassandra.streaming.StreamException: Stream failed. &lt;br/&gt;
After scrubing and repair I get the same error.  &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR [StreamReceiveTask:5] 2016-04-27 00:33:21,082 Keyspace.java:492 - Unknown exception caught while attempting to update MaterializedView! messages_dump.messages
java.lang.IllegalArgumentException: Mutation of 34974901 bytes is too large for the maxiumum size of 33554432
	at org.apache.cassandra.db.commitlog.CommitLog.add(CommitLog.java:264) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:469) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:384) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.applyFuture(Mutation.java:205) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:217) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.batchlog.BatchlogManager.store(BatchlogManager.java:146) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.StorageProxy.mutateMV(StorageProxy.java:724) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.view.ViewManager.pushViewReplicaUpdates(ViewManager.java:149) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:487) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:384) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.applyFuture(Mutation.java:205) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:217) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.applyUnsafe(Mutation.java:236) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamReceiveTask$OnCompletionRunnable.run(StreamReceiveTask.java:169) [apache-cassandra-3.0.5.jar:3.0.5]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_11]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_11]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_11]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_11]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_11]
ERROR [StreamReceiveTask:5] 2016-04-27 00:33:21,082 StreamReceiveTask.java:214 - Error applying streamed data: 
java.lang.IllegalArgumentException: Mutation of 34974901 bytes is too large for the maxiumum size of 33554432
	at org.apache.cassandra.db.commitlog.CommitLog.add(CommitLog.java:264) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:469) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:384) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.applyFuture(Mutation.java:205) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:217) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.batchlog.BatchlogManager.store(BatchlogManager.java:146) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.StorageProxy.mutateMV(StorageProxy.java:724) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.view.ViewManager.pushViewReplicaUpdates(ViewManager.java:149) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:487) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:384) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.applyFuture(Mutation.java:205) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:217) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.applyUnsafe(Mutation.java:236) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamReceiveTask$OnCompletionRunnable.run(StreamReceiveTask.java:169) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_11]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_11]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_11]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_11]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_11]
ERROR [StreamReceiveTask:5] 2016-04-27 00:33:21,082 StreamSession.java:520 - [Stream #f849ffe0-0bee-11e6-9b5f-d16a1b9764ab] Streaming error occurred
java.lang.IllegalArgumentException: Mutation of 34974901 bytes is too large for the maxiumum size of 33554432
	at org.apache.cassandra.db.commitlog.CommitLog.add(CommitLog.java:264) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:469) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:384) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.applyFuture(Mutation.java:205) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:217) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.batchlog.BatchlogManager.store(BatchlogManager.java:146) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.StorageProxy.mutateMV(StorageProxy.java:724) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.view.ViewManager.pushViewReplicaUpdates(ViewManager.java:149) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:487) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:384) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.applyFuture(Mutation.java:205) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:217) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.db.Mutation.applyUnsafe(Mutation.java:236) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamReceiveTask$OnCompletionRunnable.run(StreamReceiveTask.java:169) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_11]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_11]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_11]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_11]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_11]
DEBUG [StreamReceiveTask:5] 2016-04-27 00:33:21,082 ConnectionHandler.java:110 - [Stream #f849ffe0-0bee-11e6-9b5f-d16a1b9764ab] Closing stream connection handler on /88.9.99.92
DEBUG [STREAM-OUT-/88.9.99.92] 2016-04-27 00:33:21,082 ConnectionHandler.java:341 - [Stream #f849ffe0-0bee-11e6-9b5f-d16a1b9764ab] Sending Session Failed
INFO  [StreamReceiveTask:5] 2016-04-27 00:33:21,082 StreamResultFuture.java:182 - [Stream #f849ffe0-0bee-11e6-9b5f-d16a1b9764ab] Session with /88.9.99.92 is complete
WARN  [StreamReceiveTask:5] 2016-04-27 00:33:21,182 StreamResultFuture.java:209 - [Stream #f849ffe0-0bee-11e6-9b5f-d16a1b9764ab] Stream failed
ERROR [main] 2016-04-27 00:33:21,259 StorageService.java:1300 - Error while waiting on bootstrap to complete. Bootstrap will have to be restarted.
java.util.concurrent.ExecutionException: org.apache.cassandra.streaming.StreamException: Stream failed
	at com.google.common.util.concurrent.AbstractFuture$Sync.getValue(AbstractFuture.java:299) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:286) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:116) ~[guava-18.0.jar:na]
	at org.apache.cassandra.service.StorageService.bootstrap(StorageService.java:1295) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:971) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:745) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:610) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:333) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:551) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:679) [apache-cassandra-3.0.5.jar:3.0.5]
Caused by: org.apache.cassandra.streaming.StreamException: Stream failed
	at org.apache.cassandra.streaming.management.StreamEventJMXNotifier.onFailure(StreamEventJMXNotifier.java:85) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at com.google.common.util.concurrent.Futures$6.run(Futures.java:1310) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:457) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.ExecutionList.execute(ExecutionList.java:145) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:202) ~[guava-18.0.jar:na]
	at org.apache.cassandra.streaming.StreamResultFuture.maybeComplete(StreamResultFuture.java:210) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamResultFuture.handleSessionComplete(StreamResultFuture.java:186) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamSession.closeSession(StreamSession.java:430) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamSession.onError(StreamSession.java:525) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamReceiveTask$OnCompletionRunnable.run(StreamReceiveTask.java:216) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_11]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_11]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_11]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_11]
	at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_11]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I set commitlog_segment_size_in_mb: 128, but it didn&apos;t help. &lt;/p&gt;
</description>
                <environment></environment>
        <key id="12962923">CASSANDRA-11670</key>
            <summary>Rebuilding or streaming MV generates mutations larger than max_mutation_size_in_kb</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="pauloricardomg">Paulo Motta</assignee>
                                    <reporter username="anastasia">Anastasia Braginsky</reporter>
                        <labels>
                    </labels>
                <created>Wed, 27 Apr 2016 08:35:19 +0000</created>
                <updated>Tue, 16 Apr 2019 09:30:34 +0000</updated>
                            <resolved>Wed, 21 Sep 2016 23:35:06 +0000</resolved>
                                        <fixVersion>3.0.10</fixVersion>
                    <fixVersion>3.10</fixVersion>
                                    <component>Feature/Materialized Views</component>
                    <component>Legacy/Streaming and Messaging</component>
                    <component>Local/Config</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>14</watches>
                                                                                                                <comments>
                            <comment id="15260041" author="pauloricardomg" created="Wed, 27 Apr 2016 12:26:16 +0000"  >&lt;p&gt;This is strange, can you double check that none of your nodes in any data center have a custom &lt;tt&gt;commitlog_segment_size_in_mb&lt;/tt&gt; or &lt;tt&gt;max_mutation_size_in_kb&lt;/tt&gt; configuration set?&lt;/p&gt;

&lt;p&gt;Also, can you verify during node initialization on &lt;tt&gt;system.log&lt;/tt&gt; that &lt;tt&gt;commitlog_segment_size_in_mb=128&lt;/tt&gt; was picked up by configuration when you changed and that &lt;tt&gt;max_mutation_size_in_kb=null&lt;/tt&gt;? Maybe check that on other nodes as well to see if you find any strange combination.&lt;/p&gt;</comment>
                            <comment id="15260338" author="anastasia" created="Wed, 27 Apr 2016 15:42:05 +0000"  >&lt;p&gt;I had no more Mutation of Y bytes is too large for the maxiumum size of X, but I got again Error: &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR [main] 2016-04-27 17:32:24,714 StorageService.java:1300 - Error while waiting on bootstrap to complete. Bootstrap will have to be restarted.
java.util.concurrent.ExecutionException: org.apache.cassandra.streaming.StreamException: Stream failed
	at com.google.common.util.concurrent.AbstractFuture$Sync.getValue(AbstractFuture.java:299) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:286) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:116) ~[guava-18.0.jar:na]
	at org.apache.cassandra.service.StorageService.bootstrap(StorageService.java:1295) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:971) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:745) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:610) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:333) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:551) [apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:679) [apache-cassandra-3.0.5.jar:3.0.5]
Caused by: org.apache.cassandra.streaming.StreamException: Stream failed
	at org.apache.cassandra.streaming.management.StreamEventJMXNotifier.onFailure(StreamEventJMXNotifier.java:85) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at com.google.common.util.concurrent.Futures$6.run(Futures.java:1310) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:457) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.ExecutionList.execute(ExecutionList.java:145) ~[guava-18.0.jar:na]
	at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:202) ~[guava-18.0.jar:na]
	at org.apache.cassandra.streaming.StreamResultFuture.maybeComplete(StreamResultFuture.java:210) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamResultFuture.handleSessionComplete(StreamResultFuture.java:186) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamSession.closeSession(StreamSession.java:430) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamSession.maybeCompleted(StreamSession.java:707) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamSession.taskCompleted(StreamSession.java:668) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at org.apache.cassandra.streaming.StreamReceiveTask$OnCompletionRunnable.run(StreamReceiveTask.java:210) ~[apache-cassandra-3.0.5.jar:3.0.5]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_11]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_11]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_11]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_11]
	at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_11]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15274059" author="pauloricardomg" created="Fri, 6 May 2016 13:55:51 +0000"  >&lt;p&gt;are you still facing this? if so, you&apos;ll probably need to provide more details on why the stream session failed (this should appear right before this in the logs)&lt;/p&gt;</comment>
                            <comment id="15274075" author="aheiss" created="Fri, 6 May 2016 14:07:48 +0000"  >&lt;p&gt;In our cassandra.yaml we have a &lt;b&gt;commitlog_segment_size_in_mb&lt;/b&gt; of 32 (the default) and no &lt;b&gt;max_mutation_size_in_kb&lt;/b&gt;&lt;br/&gt;
In the system.log it says &lt;b&gt;max_mutation_size_in_kb=null&lt;/b&gt; and &lt;b&gt;commitlog_segment_size_in_mb=32&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;The Config file and log output is the same on every Server in the Cluster.&lt;/p&gt;</comment>
                            <comment id="15275062" author="pauloricardomg" created="Sat, 7 May 2016 03:51:30 +0000"  >&lt;p&gt;The problem here is that during streaming we can potentially receive more than &lt;tt&gt;max_mutation_size&lt;/tt&gt; updates for a single partition, and MV updates are later grouped into a single batchlog which in this case will exceed &lt;tt&gt;max_mutation_size&lt;/tt&gt; and fail streaming/bootstrap/repair since it cannot be written to the commit log.  I created a &lt;a href=&quot;https://github.com/pauloricardomg/cassandra-dtest/commit/e7670ef78011a946d096aac2a3e9be43bba70530&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt; to reproduce it.&lt;/p&gt;

&lt;p&gt;I see two ways of solving this:&lt;br/&gt;
1) Split large updates for a single partition received during streaming into multiple mutations, smaller than &lt;tt&gt;max_mutation_size&lt;/tt&gt; on &lt;tt&gt;StreamReceiveTask.OnCompletionRunnable&lt;/tt&gt;&lt;br/&gt;
2) Split large MV updates into multiple batchlogs smaller than &lt;tt&gt;max_mutation_size&lt;/tt&gt; on &lt;tt&gt;StorageProxy.mutateMV&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Upside of 1) is that we deal with it earlier. Downsides are: have to handle deletions when splitting mutations and we cannot know in advance what the batchlog size will be so will need to estimate batchlog size or use a conservative value to split updates into mutations.&lt;br/&gt;
Upside of 2) is to split batchlogs more precisely. Downsides are having to special case this in the MV Path.&lt;/p&gt;

&lt;p&gt;I initially considered only bootstrap (while this can also happen with repairs), and did an &lt;a href=&quot;https://github.com/apache/cassandra/compare/trunk...pauloricardomg:trunk-11670&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;initial implementation&lt;/a&gt; based on 2, but supporting repair which goes through the ordinary MV path  will probably make this more messy so I&apos;m now leaning more towards 1.&lt;/p&gt;

&lt;p&gt;WDYT &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=carlyeks&quot; class=&quot;user-hover&quot; rel=&quot;carlyeks&quot;&gt;carlyeks&lt;/a&gt; ?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aheiss&quot; class=&quot;user-hover&quot; rel=&quot;aheiss&quot;&gt;aheiss&lt;/a&gt; as a interim workaround you can try manually applying this &lt;a href=&quot;https://github.com/apache/cassandra/compare/trunk...pauloricardomg:trunk-11670&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this preliminary patch&lt;/a&gt; on cassandra-3.0.5, or a more brute force approach without patching is to increase &lt;tt&gt;max_mutation_size_in_kb&lt;/tt&gt; or &lt;tt&gt;commitlog_segment_size_in_mb&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="15276234" author="aheiss" created="Mon, 9 May 2016 11:22:48 +0000"  >&lt;p&gt;We raised the &lt;b&gt;commitlog_segment_size_in_mb&lt;/b&gt; to 128&lt;br/&gt;
Now we get another error:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ERROR 10:30:29 &lt;a href=&quot;#9e733a20-15be-11e6-9bb1-31c0715c4db0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Stream #9e733a20-15be-11e6-9bb1-31c0715c4db0&lt;/a&gt; Streaming error occurred&lt;br/&gt;
java.io.IOException: CF 64aecb30-11f7-11e6-89d2-9d1dd801d7e2 was dropped during streaming&lt;br/&gt;
	at org.apache.cassandra.streaming.compress.CompressedStreamReader.read(CompressedStreamReader.java:76) ~&lt;span class=&quot;error&quot;&gt;&amp;#91;apache-cassandra-3.0.5.jar:3.0.5&amp;#93;&lt;/span&gt;&lt;br/&gt;
	at org.apache.cassandra.streaming.messages.IncomingFileMessage$1.deserialize(IncomingFileMessage.java:50) ~&lt;span class=&quot;error&quot;&gt;&amp;#91;apache-cassandra-3.0.5.jar:3.0.5&amp;#93;&lt;/span&gt;&lt;br/&gt;
	at org.apache.cassandra.streaming.messages.IncomingFileMessage$1.deserialize(IncomingFileMessage.java:39) ~&lt;span class=&quot;error&quot;&gt;&amp;#91;apache-cassandra-3.0.5.jar:3.0.5&amp;#93;&lt;/span&gt;&lt;br/&gt;
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:59) ~&lt;span class=&quot;error&quot;&gt;&amp;#91;apache-cassandra-3.0.5.jar:3.0.5&amp;#93;&lt;/span&gt;&lt;br/&gt;
	at org.apache.cassandra.streaming.ConnectionHandler$IncomingMessageHandler.run(ConnectionHandler.java:268) ~&lt;span class=&quot;error&quot;&gt;&amp;#91;apache-cassandra-3.0.5.jar:3.0.5&amp;#93;&lt;/span&gt;&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745) &lt;span class=&quot;error&quot;&gt;&amp;#91;na:1.8.0_11&amp;#93;&lt;/span&gt;&lt;br/&gt;
INFO  10:30:29 &lt;a href=&quot;#9e733a20-15be-11e6-9bb1-31c0715c4db0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Stream #9e733a20-15be-11e6-9bb1-31c0715c4db0&lt;/a&gt; Session with /176.9.99.140 is complete&lt;br/&gt;
WARN  10:30:29 &lt;a href=&quot;#9e733a20-15be-11e6-9bb1-31c0715c4db0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Stream #9e733a20-15be-11e6-9bb1-31c0715c4db0&lt;/a&gt; Stream failed&lt;br/&gt;
ERROR 10:30:29 Error while waiting on bootstrap to complete. Bootstrap will have to be restarted.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Approximately 2 Hours after the Bootstrap starts (2 Hours is the &lt;b&gt;streaming_socket_timeout_in_ms&lt;/b&gt; could that have something to to with the problem ?)&lt;/p&gt;</comment>
                            <comment id="15281623" author="pauloricardomg" created="Thu, 12 May 2016 15:36:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;Now we get another error:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Did you drop any table during bootstrap by any chance? Does this happens always or only one time? Did you get around it?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Approximately 2 Hours after the Bootstrap starts (2 Hours is the streaming_socket_timeout_in_ms could that have something to to with the problem ?)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;s possible, but you should see &lt;tt&gt;StreamingSocketTimeout&lt;/tt&gt; in the logs of some node. If you see this then you might be hitting &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8343&quot; title=&quot;Secondary index creation causes moves/bootstraps to fail&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8343&quot;&gt;&lt;del&gt;CASSANDRA-8343&lt;/del&gt;&lt;/a&gt;, so you should increase &lt;tt&gt;stream_socket_timeout_in_ms&lt;/tt&gt; as a temporary workaround.&lt;/p&gt;</comment>
                            <comment id="15281655" author="aheiss" created="Thu, 12 May 2016 16:06:00 +0000"  >&lt;p&gt;After many tries and with &lt;b&gt;commitlog_segment_size_in_mb&lt;/b&gt; of 512 and a * streaming_socket_timeout_in_ms* of 12 Hours the Bootstrap process was successfull and the two new nodes are in the cluster.&lt;/p&gt;</comment>
                            <comment id="15281662" author="pauloricardomg" created="Thu, 12 May 2016 16:09:42 +0000"  >&lt;p&gt;Great! I&apos;ll try to get this fixed by next release. Also, after bootstrap is finished you should probably do a nodetool flush + nodetool drain and reset the &lt;tt&gt;commitlog_segment_size&lt;/tt&gt; to the default value&lt;/p&gt;

&lt;p&gt;I&apos;m still curious about the &lt;tt&gt;CF 64aecb30-11f7-11e6-89d2-9d1dd801d7e2 was dropped during streaming&lt;/tt&gt; issue though. Is there any chance this table was dropped during bootstrap?&lt;/p&gt;

&lt;p&gt;If not, it would be nice if you could attach debug logs from stream session #9e733a20-15be-11e6-9bb1-31c0715c4db0 on source and receiver nodes to help investigate this.&lt;/p&gt;</comment>
                            <comment id="15281802" author="carlyeks" created="Thu, 12 May 2016 17:29:20 +0000"  >&lt;p&gt;This points to a more general issue with MV potentially creating large mutations, not just during streaming.&lt;/p&gt;

&lt;p&gt;It would be possible to create a situation where the non-MV mutation is under the max size, some set of replicas will accept the write (thus accepting the write into the cluster), but a replica with a different set of data would fail and never be able to apply that mutation. This wouldn&apos;t be an issue with normal batchlogs as they would universally reject that batch on all replicas.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pauloricardomg&quot; class=&quot;user-hover&quot; rel=&quot;pauloricardomg&quot;&gt;pauloricardomg&lt;/a&gt; Where did you run into problems with the multi-batch solution? I think that would solve this problem more universally for MV.&lt;/p&gt;</comment>
                            <comment id="15281896" author="pauloricardomg" created="Thu, 12 May 2016 18:37:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=carlyeks&quot; class=&quot;user-hover&quot; rel=&quot;carlyeks&quot;&gt;carlyeks&lt;/a&gt; Thanks for your feedback. I didn&apos;t run into any particular problem, my only concern was if there was any MV guarantee that could be broken by splitting a view update into multiple batchlogs in the general case, but if there isn&apos;t I will go ahead with this approach.&lt;/p&gt;</comment>
                            <comment id="15290085" author="pauloricardomg" created="Wed, 18 May 2016 23:30:04 +0000"  >&lt;p&gt;Attaching initial patch for review.&lt;/p&gt;

&lt;p&gt;Basic idea is to introduce a &lt;tt&gt;BatchlogBuilder&lt;/tt&gt;, that can be instantiated with a maximum size, and creates new batchlogs as mutation are added to it if it exceeds the specified maximum size. Based on this, I added a &lt;tt&gt;BatchlogManager.storeMultiBatch&lt;/tt&gt; method that receives a list of mutations and stores them in multiple batches, respecting the maximum size of (90%*max_mutation_size_in_kb) per batch. This method is used when &lt;a href=&quot;https://github.com/pauloricardomg/cassandra/blob/63c5001e7cde2a6296fe3b14e96bb9225d893585/src/java/org/apache/cassandra/service/StorageProxy.java#L721&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;storing views on a bootstrapping or moving node&lt;/a&gt;, since we skip the normal MV path if there are pending endpoint.&lt;/p&gt;

&lt;p&gt;When adding mutations via the normal MV path, a &lt;tt&gt;BatchlogBuilder&lt;/tt&gt; is created and &lt;a href=&quot;https://github.com/pauloricardomg/cassandra/blob/63c5001e7cde2a6296fe3b14e96bb9225d893585/src/java/org/apache/cassandra/service/StorageProxy.java#L738&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;mutations are appended to it&lt;/a&gt; as the view write response handlers are created. Each time a new batchlog is created, a new &lt;tt&gt;BatchlogCleanup&lt;/tt&gt; callback object is &lt;a href=&quot;https://github.com/pauloricardomg/cassandra/blob/63c5001e7cde2a6296fe3b14e96bb9225d893585/src/java/org/apache/cassandra/service/StorageProxy.java#L742&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;created&lt;/a&gt;, so it removes each batchlog independently after all of its mutations are written. Since we don&apos;t know the amount of mutations a batchlog will contain ahead of time, we increase the mutation count in the &lt;tt&gt;BatchlogCleanup&lt;/tt&gt; as they are added to the &lt;tt&gt;BatchlogBuilder&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;I noticed that when we apply the view mutation locally we don&apos;t currently decrease the &lt;tt&gt;mutationsWaitingFor&lt;/tt&gt; on &lt;tt&gt;BatchlogCleanup&lt;/tt&gt;, so does this mean we never clean up view batchlogs when there are local paired mutations? In order to avoid this in the new approach I incremented the number of mutations in the &lt;tt&gt;BatchlogCleanup&lt;/tt&gt; &lt;a href=&quot;https://github.com/pauloricardomg/cassandra/blob/63c5001e7cde2a6296fe3b14e96bb9225d893585/src/java/org/apache/cassandra/service/StorageProxy.java#L766&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;only if the replica is not applied locally&lt;/a&gt;. Can we further optimize this and only add the replica to the batchlog if it&apos;s not local?&lt;/p&gt;

&lt;p&gt;I added a &lt;a href=&quot;https://github.com/riptano/cassandra-dtest/compare/master...pauloricardomg:11670&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt; that reproduces this issue and it is fixed by this approach.  If it looks good I will add more thorough testing and documentation to &lt;tt&gt;BatchlogBuilder&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Patch and tests available below:&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;3.0&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;dtest&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/apache/cassandra/compare/cassandra-3.0...pauloricardomg:3.0-11670&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;branch&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/riptano/cassandra-dtest/compare/master...pauloricardomg:11670&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;branch&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/paulomotta/job/pauloricardomg-3.0-11670-testall/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;testall&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/paulomotta/job/pauloricardomg-3.0-11670-dtest/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
</comment>
                            <comment id="15304152" author="iamaleksey" created="Fri, 27 May 2016 14:58:35 +0000"  >&lt;p&gt;I could be wrong, but I&apos;m not sure this is correct. If you are splitting a batch, then you need to ensure that you don&apos;t remove any part of it until all of the parts got replayed.&lt;/p&gt;</comment>
                            <comment id="15314029" author="carlyeks" created="Fri, 3 Jun 2016 12:13:22 +0000"  >&lt;p&gt;Another potential issue for this in MV is that parts of the batchlog write would succeed, then we would fail. That would mean that the batchlog would be in an inconsistent state - parts of the mutations had been written, but the underlying data had not yet been.&lt;/p&gt;

&lt;p&gt;A way we could split this out without losing the guarantees of batches would be by writing the batchlog to a single partition key, once they are have all been written, before we respond that it was written successfully, we would write a new mutation that updates a &quot;ready to be batched&quot; for the whole partition (could even be a static column).&lt;/p&gt;

&lt;p&gt;Then the batchlog manager could check that column, and if null or true, would replay and then delete the entire partition. On restart, if there are any batchlogs with false for that column, they could also be deleted.&lt;/p&gt;</comment>
                            <comment id="15314034" author="iamaleksey" created="Fri, 3 Jun 2016 12:23:58 +0000"  >&lt;p&gt;Indeed. This would weaken already non-strong atomicity-ish semantics of logged batches.&lt;/p&gt;

&lt;p&gt;As Carl mentions, it&apos;s possible that if batch foo were to be split into foo1 and foo2, the write of either of them could succeed, and the other one failed, and as such only part of the batch would be replayed.&lt;/p&gt;

&lt;p&gt;Other similar scenarios:&lt;/p&gt;

&lt;p&gt;1. A BL sstable got corrupted, foo1 got lost to scrub, foo2 survived and got replayed on its own&lt;br/&gt;
2. foo1 and foo2 sstables went to different disks, one of them got lost, only part of the batch got replayed&lt;/p&gt;

&lt;p&gt;Deletion on replay is more of an existing problem rather than a new one. Imagine replaying a non-split batch foo, and succeeding partially - the batch not removed; then for one reason or another, we lose the sstable or just corrupt foo - the remaining bits will not be replayed.&lt;/p&gt;</comment>
                            <comment id="15314043" author="iamaleksey" created="Fri, 3 Jun 2016 12:31:32 +0000"  >&lt;p&gt;One way to deal with the issue that comes to mind would be to split batchlog entries into two parts - for large batches only: a metadata entry with references to the mutations in the batch - as a set of uuids, and mutations stored separately in a different table. On replay you&apos;d fetch metadata first, then all the referenced mutations, and fail the whole batch if you cannot obtain them all.&lt;/p&gt;</comment>
                            <comment id="15359128" author="pauloricardomg" created="Fri, 1 Jul 2016 15:30:08 +0000"  >&lt;p&gt;Instead of having separate paths for small and large batches, I think it&apos;s simpler and cleaner to redesign our batchlog table to expand the current &lt;tt&gt;list&amp;lt;mutation&amp;gt;&lt;/tt&gt; column into clustered rows, so we can append mutations individually to the same batchlog partition without being restricted to &lt;tt&gt;max_mutation_size_in_kb&lt;/tt&gt; for the total batchlog size.&lt;/p&gt;

&lt;p&gt;The idea is to have something like&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;CREATE TABLE Batches (
    id timeuuid,
    idx bigint,
    mutation blob,
    version int static,
    active boolean static,
    PRIMARY KEY ((id), idx)
)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So, creating a batch is a matter of populating a partition with mutations and then setting the &lt;tt&gt;active&lt;/tt&gt; flag to true, what will indicate the batch is ready to be potentially replayed (building on &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=carlyeks&quot; class=&quot;user-hover&quot; rel=&quot;carlyeks&quot;&gt;carlyeks&lt;/a&gt;&apos;s suggestion).&lt;/p&gt;

&lt;p&gt;In order to verify the potential performance impact of this change, I ran 3 cstar tests with 3 different implementations and the throughput/latency doesn&apos;t seem to be impacted with this change.&lt;/p&gt;

&lt;p&gt;The 3 compared branches are:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://github.com/pauloricardomg/cassandra/tree/3.0-noreplay&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;3.0-noreplay&lt;/a&gt; (3.0 with disabled batchlog replay - so it&apos;s comparable with others)&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://github.com/pauloricardomg/cassandra/tree/3.0-11670-v2&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;11670-v2&lt;/a&gt; (table above)&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://github.com/pauloricardomg/cassandra/tree/3.0-11670-v3&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;11670-v3&lt;/a&gt; (alternative design where table is clustered, but mutations are stored as a &lt;tt&gt;list&amp;lt;blob&amp;gt;&lt;/tt&gt; in order to have fewer rows - schema below)
	&lt;ul&gt;
		&lt;li&gt;&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;CREATE TABLE Batches (
    id timeuuid,
    idx bigint,&quot;
    mutations list&amp;lt;blob&amp;gt;,&quot;
    version int static,&quot;
    active boolean static,&quot;
    PRIMARY KEY ((id), idx)
)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The cstar tests are:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;http://cstar.datastax.com/graph?command=one_job&amp;amp;stats=01de5e5e-3ed3-11e6-8a53-0256e416528f&amp;amp;metric=op_rate&amp;amp;operation=1_user&amp;amp;smoothing=1&amp;amp;show_aggregates=true&amp;amp;xmin=0&amp;amp;xmax=2690.27&amp;amp;ymin=0&amp;amp;ymax=70239.4&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;1 materialized view&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;http://cstar.datastax.com/graph?command=one_job&amp;amp;stats=0a632460-3edd-11e6-85ce-0256e416528f&amp;amp;metric=op_rate&amp;amp;operation=1_user&amp;amp;smoothing=1&amp;amp;show_aggregates=true&amp;amp;xmin=0&amp;amp;xmax=5128.86&amp;amp;ymin=0&amp;amp;ymax=2832.5&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;3 materialized views&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;http://cstar.datastax.com/graph?command=one_job&amp;amp;stats=0a632460-3edd-11e6-85ce-0256e416528f&amp;amp;metric=op_rate&amp;amp;operation=1_user&amp;amp;smoothing=1&amp;amp;show_aggregates=true&amp;amp;xmin=0&amp;amp;xmax=5128.86&amp;amp;ymin=0&amp;amp;ymax=2832.5&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;cqlstress-example.yaml (multi-partition batches)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;As said before, from these results there doesn&apos;t seem to be any impact on throughput/latency from switching to this approach. If we decide to go with this little change will be necessary in the batchlog handling code to support it, most of the effort will probably on supporting upgrade to this new scheme.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure if there any other potential issues with turning the batchlog into a wide table and applying mutations individually, but if not I think we should go with this approach. WDYT &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=carlyeks&quot; class=&quot;user-hover&quot; rel=&quot;carlyeks&quot;&gt;carlyeks&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iamaleksey&quot; class=&quot;user-hover&quot; rel=&quot;iamaleksey&quot;&gt;iamaleksey&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="15395602" author="carlyeks" created="Wed, 27 Jul 2016 12:42:53 +0000"  >&lt;p&gt;This looks good to me, but I&apos;d also like to get &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=blambov&quot; class=&quot;user-hover&quot; rel=&quot;blambov&quot;&gt;blambov&lt;/a&gt;&apos;s opinion as he did the work on &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-7237&quot; title=&quot;Optimize batchlog manager to avoid full scans&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-7237&quot;&gt;&lt;del&gt;CASSANDRA-7237&lt;/del&gt;&lt;/a&gt; to make improvements to batchlog.&lt;/p&gt;</comment>
                            <comment id="15395654" author="blambov" created="Wed, 27 Jul 2016 13:18:39 +0000"  >&lt;p&gt;The wide partition approach sounds good to me and should perform well enough.&lt;/p&gt;

&lt;p&gt;Caveats: Data in legacy tables will have to be converted on startup, and probably also when sending data to older versions with which the node must be interoperable.&lt;/p&gt;</comment>
                            <comment id="15506775" author="pauloricardomg" created="Tue, 20 Sep 2016 14:44:03 +0000"  >&lt;p&gt;I started implementing the new batchlog table modelling as discussed previously, and modifying the batchlog write and replay path accordingly to add and retrieve mutations to the batchlog table iteratively without caching them in memory. But in order to define the batch gcgs, all mutations need to be iterated, so there are 3 options here:&lt;br/&gt;
1. Calculate the gcgs on the write path, storing them as a batch attribute.&lt;br/&gt;
2. Calculate the gcgs on the replay path as done currently, by holding all mutations in memory and calculating the minimum gcgs of all mutations.&lt;br/&gt;
3. Calculate the gsgs on the replay path by iterating on the batch mutations once to retrieve the min gcgs, and again to replay the batches.&lt;/p&gt;

&lt;p&gt;1 would require a change of the batch wire format, which cannot be done before 4.0. 2 would probably move the current size limitation from disk to memory, what could be much more dangerous. 3 would not be very efficient since for every batch (or at least for bigger batches) you would need to iterated on it twice during replay.&lt;/p&gt;

&lt;p&gt;I think we could do 3 while waiting for 1 to be feasible, but while investigating an alternative to this, I verified that the refactor of &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-11475&quot; title=&quot;MV code refactor&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-11475&quot;&gt;&lt;del&gt;CASSANDRA-11475&lt;/del&gt;&lt;/a&gt; batches multiple mutations for the same partition key in a single mutation, what raises the max limit of mutations per MV batch from a few hundred (100) to a few thousand rows per partition key (3000), what already mitigates this problem considerably for ordinary MV updates.&lt;/p&gt;

&lt;p&gt;For MV updates originated from streaming, I noticed that we apply these mutations unsafely (skipping the commit log), since we flush before completing the stream session, but we don&apos;t propagate &lt;tt&gt;writeCommitlog=false&lt;/tt&gt; flag to &lt;tt&gt;pushViewReplicaUpdates&lt;/tt&gt; due to the addition of the &lt;tt&gt;isClReplay&lt;/tt&gt; flag by &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-10164&quot; title=&quot;Re-apply MV updates on commitlog replay&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-10164&quot;&gt;&lt;del&gt;CASSANDRA-10164&lt;/del&gt;&lt;/a&gt;, so we only consider the latter flag. So, a very simple fix to avoid this problem during streaming (where it&apos;s most likely to happen) is to simply propagate the  &lt;tt&gt;writeCommitlog=false&lt;/tt&gt; flag to &lt;tt&gt;pushViewReplicaUpdates&lt;/tt&gt; on &lt;tt&gt;Keyspace.apply&lt;/tt&gt; by changing the original condition from &lt;tt&gt;!isClReplay&lt;/tt&gt; to &lt;tt&gt;writeCommitLog &amp;amp;&amp;amp; !isClReplay&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;I added regression dtests with very wide partitions and submitted a &lt;a href=&quot;https://github.com/riptano/cassandra-dtest/pull/1331&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;pull request&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In order to increase further the maximum number of MV updates in a single batch for ordinary updates, I propose we do the approach 1 above as an improvement after changing the messaging service version.&lt;/p&gt;

&lt;p&gt;Setting this to patch available. Below is the patch and tests with the proposed fix:&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;3.0&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;trunk&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;dtest&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&lt;a href=&quot;https://github.com/apache/cassandra/compare/cassandra-3.0...pauloricardomg:3.0-11670&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;branch&lt;/a&gt;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&lt;a href=&quot;https://github.com/apache/cassandra/compare/trunk...pauloricardomg:trunk-11670&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;branch&lt;/a&gt;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&lt;a href=&quot;https://github.com/riptano/cassandra-dtest/compare/master...pauloricardomg:11670&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;branch&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/paulomotta/job/pauloricardomg-3.0-11670-testall/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;testall&lt;/a&gt;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/paulomotta/job/pauloricardomg-trunk-11670-testall/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;testall&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/paulomotta/job/pauloricardomg-3.0-11670-dtest/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/paulomotta/job/pauloricardomg-trunk-11670-dtest/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
</comment>
                            <comment id="15511487" author="iamaleksey" created="Wed, 21 Sep 2016 23:12:03 +0000"  >&lt;p&gt;+1 to the proposed streaming fix, will commit shortly. Thank you.&lt;/p&gt;

&lt;p&gt;Also agreed re: requiring a wire change to solve the more general issue of batchlog entry sizes being limited the way it is.&lt;/p&gt;</comment>
                            <comment id="15511528" author="iamaleksey" created="Wed, 21 Sep 2016 23:34:52 +0000"  >&lt;p&gt;Committed as &lt;a href=&quot;https://github.com/apache/cassandra/commit/88d47911dd9f590a335af7429b128ffc726dc5ff&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;88d47911dd9f590a335af7429b128ffc726dc5ff&lt;/a&gt; to 3.0 and merged into trunk.&lt;/p&gt;</comment>
                            <comment id="15894128" author="brstgt" created="Fri, 3 Mar 2017 10:49:15 +0000"  >&lt;p&gt;Hmmm I guess this possibly breaks consistency in repair streams + MVs&lt;br/&gt;
In StreamReceiveTasks mutations are applied without commitlog because cf is flushed at the end. But MVs are not flushed.&lt;/p&gt;

&lt;p&gt;Either:&lt;br/&gt;
Also flush all MVs at the end of the stream task - it is not said that this is actually required for all MVs as we do not know where view replica updates eventually go.&lt;/p&gt;

&lt;p&gt;Or:&lt;br/&gt;
Enable commitlog for view replica updates even if base table does not commit log writes.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12965594">CASSANDRA-11727</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13048374">CASSANDRA-13299</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[pauloricardomg]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 37 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2wt27:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>carlyeks</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[carlyeks]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>