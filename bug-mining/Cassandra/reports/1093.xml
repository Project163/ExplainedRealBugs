<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:22:40 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-2433] Failed Streams Break Repair</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-2433</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;Running repair in cases where a stream fails we are seeing multiple problems.&lt;/p&gt;

&lt;p&gt;1. Although retry is initiated and completes, the old stream doesn&apos;t seem to clean itself up and repair hangs.&lt;br/&gt;
2. The temp files are left behind and multiple failures can end up filling up the data partition.&lt;/p&gt;

&lt;p&gt;These issues together are making repair very difficult for nearly everyone running repair on a non-trivial sized data set.&lt;/p&gt;

&lt;p&gt;This issue is also being worked on w.r.t &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2088&quot; title=&quot;Clean up after failed (repair) streaming operation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-2088&quot;&gt;&lt;del&gt;CASSANDRA-2088&lt;/del&gt;&lt;/a&gt;, however that was moved to 0.8 for a few reasons. This ticket is to fix the immediate issues that we are seeing in 0.7.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12503646">CASSANDRA-2433</key>
            <summary>Failed Streams Break Repair</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="slebresne">Sylvain Lebresne</assignee>
                                    <reporter username="bcoverston">Benjamin Coverston</reporter>
                        <labels>
                            <label>repair</label>
                    </labels>
                <created>Thu, 7 Apr 2011 15:40:10 +0000</created>
                <updated>Tue, 16 Apr 2019 09:33:02 +0000</updated>
                            <resolved>Wed, 31 Aug 2011 16:36:59 +0000</resolved>
                                        <fixVersion>0.8.5</fixVersion>
                                        <due></due>
                            <votes>5</votes>
                                    <watches>10</watches>
                                                                                                                <comments>
                            <comment id="13022722" author="slebresne" created="Thu, 21 Apr 2011 11:45:12 +0000"  >&lt;p&gt;Attached patches are against 0.8.&lt;/p&gt;

&lt;p&gt;This tries to catch what can go wrong with repair and reports it back to the user by making the full repair throw an exception. More precisely:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;patch 0001: add a method to repair for reporting failure and propagate that up to the repair session. This puts repair session on a specific stage (instead of having RepairSession be a Thread) and use a future to allow waiting on completion. This allows a cleaner API to deal with errors (the Future.get() simply throw an ExecutionException) and this add the advantage of stage management to repair sessions.&lt;/li&gt;
	&lt;li&gt;patch 0002: Make repair session register through gossip to be informed of node dying and failing the session when that happens.&lt;/li&gt;
	&lt;li&gt;patch 0003: Reports errors during streaming to the repair session. This actually introduces a generic way to handle streaming failures and after that we should probably update the other user of streaming to deal correctly with failure too.&lt;/li&gt;
	&lt;li&gt;patch 004: Catch errors during validation compaction and push them up to repair (whether those happens on the coordinator of the repair or not).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Note that this includes streaming failures and thus includes stuffs from the patch of Aaron Morton attached on &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2088&quot; title=&quot;Clean up after failed (repair) streaming operation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-2088&quot;&gt;&lt;del&gt;CASSANDRA-2088&lt;/del&gt;&lt;/a&gt;, but contrarily to that patch, it takes the approach of failing fast. This means that if streaming fails on a file, it fails the streaming altogether (same for repair). I think this is simpler code-wise and more useful from the point of view of the user, since a failure means the use will have to retry anyway.&lt;/p&gt;

&lt;p&gt;Last but not least, this makes some modification to messages. So either this goes into 0.8.0 (which I think it should, because this really is a bug fix and fixes something that is a pain for users), or we should had a new messaging version for 0.8.0 and modify this to take it into account (we should probably add a 0.8.0 version to the messaging service anyway).&lt;/p&gt;</comment>
                            <comment id="13035013" author="slebresne" created="Tue, 17 May 2011 20:01:42 +0000"  >&lt;p&gt;Attaching rebased patch (against 0.8.1). It also change the behavior a little bit so as to not fail repair right away if a problem occur (it still throw an exception at the end if any problem had occured). It turns out to be slightly simpler that way. Especially for &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1610&quot; title=&quot;Pluggable Compaction&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1610&quot;&gt;&lt;del&gt;CASSANDRA-1610&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13038181" author="stuhood" created="Mon, 23 May 2011 20:09:40 +0000"  >&lt;p&gt;0001&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Since we&apos;re not trying to control throughput or monitor sessions, could we just use Stage.MISC?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;0002&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I think RepairSession.exception needs to be volatile to ensure that the awoken thread sees it&lt;/li&gt;
	&lt;li&gt;Would it be better if RepairSession implemented IEndpointStateChangeSubscriber directly?&lt;/li&gt;
	&lt;li&gt;The endpoint set needs to be threadsafe, since it will be modified by the endpoint state change thread, and the AE_STAGE thread&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;0003&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Should StreamInSession.retries be volatile/atomic? (likely they won&apos;t retry quickly enough for it to be a problem, but...)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;0004&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Playing devil&apos;s advocate: would sending a half-built tree in case of failure still be useful?&lt;/li&gt;
	&lt;li&gt;success might need to be volatile as well&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Thanks Sylvain!&lt;/p&gt;</comment>
                            <comment id="13046557" author="slebresne" created="Thu, 9 Jun 2011 14:09:31 +0000"  >&lt;p&gt;Attaching v3 rebased (on 0.8).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Since we&apos;re not trying to control throughput or monitor sessions, could we just use Stage.MISC?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The thing is that repair session are very long lived. And MISC is single threaded. So that would block other task that are not supposed to block. We could make MISC multi-threaded but even then it&apos;s not a good idea to mix short lived and long lived task on the same stage.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think RepairSession.exception needs to be volatile to ensure that the awoken thread sees it&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Done in v3.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Would it be better if RepairSession implemented IEndpointStateChangeSubscriber directly?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Good idea, it&apos;s slightly simpler, done in v3.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The endpoint set needs to be threadsafe, since it will be modified by the endpoint state change thread, and the AE_STAGE thread&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Done in v3. That will probably change with &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2610&quot; title=&quot;Have the repair of a range repair *all* the replica for that range&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-2610&quot;&gt;&lt;del&gt;CASSANDRA-2610&lt;/del&gt;&lt;/a&gt; anyway (which I have to update)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Should StreamInSession.retries be volatile/atomic? (likely they won&apos;t retry quickly enough for it to be a problem, but...)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I did not change that, but if it&apos;s a problem for retries to not be volatile, I suspect having StreamInSession.current not volatile is also a problem. But really I&apos;d be curious to see that be a problem.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Playing devil&apos;s advocate: would sending a half-built tree in case of failure still be useful?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think it is. Or more precisely, if you do send half-built tree, you&apos;ll have to be careful that the other doesn&apos;t consider what&apos;s missing as ranges not being in sync (I don&apos;t think people will be happy with tons of data being stream just because we happen to have a bug that make compaction throw an exception during the validation). So I think you cannot do much with a half-built tree, and it will add complication. For a case where people will need to restart a repair anyway once whatever happened is fixed&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;success might need to be volatile as well&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Done in v3.&lt;/p&gt;</comment>
                            <comment id="13049746" author="slebresne" created="Wed, 15 Jun 2011 12:27:21 +0000"  >&lt;p&gt;Attaching v4 that is rebased and simply set the reties variable in StreamInSession volatile after all (I&apos;ve removed old version because it was a mess).&lt;/p&gt;</comment>
                            <comment id="13066839" author="stuhood" created="Mon, 18 Jul 2011 08:08:22 +0000"  >&lt;p&gt;Hey Sylvain: sorry it took me so long to get back to this one. Would you mind rebasing it?&lt;/p&gt;</comment>
                            <comment id="13078309" author="slebresne" created="Tue, 2 Aug 2011 17:52:47 +0000"  >&lt;p&gt;Attaching a rebase of the two previous first patches as &apos;2433.patch&apos;. That is, this patch adds registering in gossip so that repair fails and report it to the user when a node participating to the repair dies. Compared to the previous version, it fails fast because it&apos;s the easier thing to do now and a better option imho.&lt;/p&gt;

&lt;p&gt;I should mention that while it is lame that repair get stuck when a node dies and we should fix it, this means that if a node is wrongly marked down, we will fail repair for no reason (but I suppose it&apos;s a failure detector problem).&lt;/p&gt;

&lt;p&gt;Attached patch is against 0.8. This has no upgrade consequence of any sort and is a reasonably simple patch, so I think it could be worth committing in 0.8.&lt;br/&gt;
The rest of what was in previous patch 0003 and 0004 cannot go into 0.8 because it changes the wire protocol, so I will rebase against trunk directly, and maybe in another ticket. Having this first patch committed would help with that though &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13081085" author="jbellis" created="Mon, 8 Aug 2011 17:46:58 +0000"  >&lt;p&gt;Yuki, can you review this patch?&lt;/p&gt;</comment>
                            <comment id="13093812" author="slebresne" created="Tue, 30 Aug 2011 15:25:15 +0000"  >&lt;p&gt;Attached v2 is rebased and use a higher conviction threshold before deciding to fail the repair, as the goal here is to avoid having a repair getting stuck for hours, but we want to avoid stopping a repair just because a node got into a longer than usual GC pause.&lt;/p&gt;

&lt;p&gt;The threshold used is twice the configured phi_convict_threshold. This give 16 by default, which if I trust the original &apos;phi accrual failure detection&apos; should give an order of magnitude less false positive than 8 (for about an order of magnitude in the detection time though). It feels reasonable to me but if a FD specialist want to voice his opinion, please do.&lt;/p&gt;</comment>
                            <comment id="13093832" author="jbellis" created="Tue, 30 Aug 2011 15:42:06 +0000"  >&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Why do we need the new AE_SESSIONS stage?&lt;/li&gt;
	&lt;li&gt;I prefer using WrappedRunnable to a Callable when you want to allow exceptions but don&apos;t care about a return value&lt;/li&gt;
	&lt;li&gt;I think we can avoid a bunch of no-op onConvicts if RepairSession were to subscribe to FD directly instead of going through Gossip (i.e., leave IEndpointStateChangeSubscriber unchanged and expose convict in IFailureDetectionEventListener for when we need to go low-level).  Gossip is about high-level &quot;events&quot; which doesn&apos;t really fit here.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13093874" author="slebresne" created="Tue, 30 Aug 2011 16:37:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why do we need the new AE_SESSIONS stage?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If you mean &quot;why AE_SESSIONS when we already have the AE stage?&quot;, then it is because repair push stuffs on the AE stage that it wait for, so we would deadlock. If you mean &quot;why a stage?&quot;, it felt cleaner that just a Thread now that we want to check for exception at the end of the exception. If you mean &quot;why a stage rather than a simple ThreadExecutor?&quot;, it is a good question. I guess it was just some reflex of mine to get a JMXEnabledThreadPool, but it&apos;s probably not worth a stage, not even the jmx enabledness maybe.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I prefer using WrappedRunnable to a Callable when you want to allow exceptions but don&apos;t care about a return value&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed. I&apos;ll update the patch.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think we can avoid a bunch of no-op onConvicts if RepairSession were to subscribe to FD directly instead of going through Gossip&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, I kind of started with that but the problem is that we must deal with the case of a node restarting before it has been convicted (especially if the conviction threshold is higher), which the FD won&apos;t see. We could deal of that last situation separately and have Gossip call some trigger into AntiEntropy on a gossip generation change to indicate to stop every started session involving the given endpoint, but creating a dependency of gossip to anti-entropy didn&apos;t felt like a good idea a priori.&lt;/p&gt;</comment>
                            <comment id="13093881" author="jbellis" created="Tue, 30 Aug 2011 16:44:22 +0000"  >&lt;blockquote&gt;&lt;p&gt;it&apos;s probably not worth a stage, not even the jmx enabledness maybe&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Someone&apos;s probably going to want the JMX information but let&apos;s keep Stages for Verb-associated tasks.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;the problem is that we must deal with the case of a node restarting before it has been convicted (especially if the conviction threshold is higher), which the FD won&apos;t see&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How about splitting onDead and onRestart in EndpointStateChange, then?  Then RS could implement convict and onRestart (ignoring onDead); other ESCS listeners could implement onRestart == onDead.  That would maintain the &quot;ESCS is about events, FDEL is low-level convict information&quot; separation of roles.&lt;/p&gt;</comment>
                            <comment id="13094585" author="slebresne" created="Wed, 31 Aug 2011 14:46:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;Someone&apos;s probably going to want the JMX information but let&apos;s keep Stages for Verb-associated tasks&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds good, updated patch add a new executor directly into AntiEntropy.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;How about splitting onDead and onRestart in EndpointStateChange, then?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Done.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I prefer using WrappedRunnable to a Callable&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I changed to use WrappedRunnable. However, we still need to have access to both the repair session and the future from the executor so the implementation returns a pair of those two objects. I&apos;m only marginally convinced this is cleaner than the previous solution...&lt;/p&gt;</comment>
                            <comment id="13094587" author="slebresne" created="Wed, 31 Aug 2011 14:52:17 +0000"  >&lt;p&gt;(Sorry, I had attached the wrong version of v3, corrected now)&lt;/p&gt;</comment>
                            <comment id="13094591" author="jbellis" created="Wed, 31 Aug 2011 14:56:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;we still need to have access to both the repair session and the future from the executor so the implementation returns a pair of those two objects&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You can still use the RepairFuture approach, just use the FutureTask(Runnable, V) constructor&lt;/p&gt;</comment>
                            <comment id="13094626" author="slebresne" created="Wed, 31 Aug 2011 15:46:43 +0000"  >&lt;p&gt;You&apos;re right, don&apos;t know why I got carried away like that. v4 &quot;fixes&quot; this.&lt;/p&gt;</comment>
                            <comment id="13094631" author="jbellis" created="Wed, 31 Aug 2011 15:51:38 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13094672" author="slebresne" created="Wed, 31 Aug 2011 16:36:59 +0000"  >&lt;p&gt;Committed, thanks.&lt;/p&gt;

&lt;p&gt;This probably solves most of the case where repair was hanging infinitely. I&apos;ve created &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-3112&quot; title=&quot;Make repair fail when an unexpected error occurs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-3112&quot;&gt;&lt;del&gt;CASSANDRA-3112&lt;/del&gt;&lt;/a&gt; to handle the remaining cases, but it is much less urgent imho. Marking that one as resolved&lt;/p&gt;</comment>
                            <comment id="13094701" author="hudson" created="Wed, 31 Aug 2011 17:16:01 +0000"  >&lt;p&gt;Integrated in Cassandra-0.8 #306 (See &lt;a href=&quot;https://builds.apache.org/job/Cassandra-0.8/306/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Cassandra-0.8/306/&lt;/a&gt;)&lt;br/&gt;
    Make repair report failure when a participating node dies&lt;br/&gt;
patch by slebresne; reviewed by jbellis for &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2433&quot; title=&quot;Failed Streams Break Repair&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-2433&quot;&gt;&lt;del&gt;CASSANDRA-2433&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;slebresne : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1163677&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1163677&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/cassandra/branches/cassandra-0.8/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/gms/FailureDetector.java&lt;/li&gt;
	&lt;li&gt;/cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/gms/Gossiper.java&lt;/li&gt;
	&lt;li&gt;/cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/gms/IEndpointStateChangeSubscriber.java&lt;/li&gt;
	&lt;li&gt;/cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/gms/IFailureDetectionEventListener.java&lt;/li&gt;
	&lt;li&gt;/cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/service/AntiEntropyService.java&lt;/li&gt;
	&lt;li&gt;/cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/service/MigrationManager.java&lt;/li&gt;
	&lt;li&gt;/cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/service/StorageLoadBalancer.java&lt;/li&gt;
	&lt;li&gt;/cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/service/StorageService.java&lt;/li&gt;
	&lt;li&gt;/cassandra/branches/cassandra-0.8/test/unit/org/apache/cassandra/service/AntiEntropyServiceTestAbstract.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12506274">CASSANDRA-2610</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12482658" name="0001-Put-repair-session-on-a-Stage-and-add-a-method-to-re-v4.patch" size="16179" author="slebresne" created="Wed, 15 Jun 2011 12:27:20 +0000"/>
                            <attachment id="12482659" name="0002-Register-in-gossip-to-handle-node-failures-v4.patch" size="10687" author="slebresne" created="Wed, 15 Jun 2011 12:27:20 +0000"/>
                            <attachment id="12482660" name="0003-Report-streaming-errors-back-to-repair-v4.patch" size="31901" author="slebresne" created="Wed, 15 Jun 2011 12:27:20 +0000"/>
                            <attachment id="12482661" name="0004-Reports-validation-compaction-errors-back-to-repair-v4.patch" size="9430" author="slebresne" created="Wed, 15 Jun 2011 12:27:21 +0000"/>
                            <attachment id="12489094" name="2433.patch" size="23618" author="slebresne" created="Tue, 2 Aug 2011 17:52:46 +0000"/>
                            <attachment id="12492251" name="2433_v2.patch" size="30185" author="slebresne" created="Tue, 30 Aug 2011 15:25:15 +0000"/>
                            <attachment id="12492464" name="2433_v3.patch" size="28412" author="slebresne" created="Wed, 31 Aug 2011 14:52:17 +0000"/>
                            <attachment id="12492468" name="2433_v4.patch" size="28545" author="slebresne" created="Wed, 31 Aug 2011 15:46:43 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[slebresne]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>20622</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            14 years, 12 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0gbcn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>93269</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>jbellis</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[jbellis]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>