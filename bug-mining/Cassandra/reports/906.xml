<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:21:06 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-2401] getColumnFamily() return null, which is not checked in ColumnFamilyStore.java scan() method, causing Timeout Exception in query</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-2401</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;ColumnFamilyStore.java, line near 1680, &quot;ColumnFamily data = getColumnFamily(new QueryFilter(dk, path, firstFilter))&quot;, the data is returned null, causing NULL exception in &quot;satisfies(data, clause, primary)&quot; which is not captured. The callback got timeout and return a Timeout exception to Hector.&lt;/p&gt;

&lt;p&gt;The data is empty, as I traced, I have the the columns Count as 0 in removeDeletedCF(), which return the null there. (I am new and trying to understand the logics around still). Instead of crash to NULL, could we bypass the data?&lt;/p&gt;

&lt;p&gt;About my test:&lt;br/&gt;
A stress-test program to add, modify and delete data to keyspace. I have 30 threads simulate concurrent users to perform the actions above, and do a query to all rows periodically. I have Column Family with rows (as File) and columns as index (e.g. userID, fileType).&lt;/p&gt;

&lt;p&gt;No issue on the first day of test, and stopped for 3 days. I restart the test on 4th day, 1 of the users failed to query the files (timeout exception received). Most of the users are still okay with the query.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Hector 0.7.0-28, Cassandra 0.7.4, Windows 7, Eclipse&lt;/p&gt;</environment>
        <key id="12502672">CASSANDRA-2401</key>
            <summary>getColumnFamily() return null, which is not checked in ColumnFamilyStore.java scan() method, causing Timeout Exception in query</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jbellis">Jonathan Ellis</assignee>
                                    <reporter username="karshiang">Tey Kar Shiang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 29 Mar 2011 07:15:33 +0000</created>
                <updated>Tue, 16 Apr 2019 09:33:03 +0000</updated>
                            <resolved>Sat, 14 May 2011 15:03:01 +0000</resolved>
                                        <fixVersion>0.7.6</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="13012475" author="jbellis" created="Tue, 29 Mar 2011 13:35:25 +0000"  >&lt;p&gt;Are you querying for zero columns?&lt;/p&gt;</comment>
                            <comment id="13012542" author="karshiang" created="Tue, 29 Mar 2011 16:19:21 +0000"  >&lt;p&gt;Hi, nope. &lt;/p&gt;

&lt;p&gt;It is a query for 4 columns. &lt;/p&gt;

&lt;p&gt;I cheked that only 1 row has this problem (no column found), out of the 948 records returned; I skipped the row with zero columns. &lt;/p&gt;

&lt;p&gt;In my stress-test, all rows have 4 columns; i.e. row is the file, the 4 columns (index) are like its version, modified time, type, etc. I added all the columns when added each file. The addition should be working since there is no such exception on day 1, and I start and stop the stress tests until each users have around 1500 files. Row with 0 column only found on the 4th day after I continue to run it.&lt;/p&gt;

&lt;p&gt;I will keep picking up cassandra logics, as I have little understanding about how data loaded, stored and deleted. Any suggestion / guide on how I should go on with my study is greatly appreciated. Thank you!&lt;/p&gt;

&lt;p&gt;Btw, for this test, I have not yet going to 2 nodes / 3 nodes. It is only a single-node cassandra runnning on my localhost.&lt;/p&gt;</comment>
                            <comment id="13012547" author="jbellis" created="Tue, 29 Mar 2011 16:32:23 +0000"  >&lt;p&gt;Is there any data from earlier than 0.7.4?&lt;/p&gt;</comment>
                            <comment id="13012804" author="karshiang" created="Wed, 30 Mar 2011 01:15:06 +0000"  >&lt;p&gt;Hi, &lt;br/&gt;
This is a clean 0.7.4 setup, with zero data to start with. Dynamically, the keyspace schema is creted on the run, when required keyspace does not exist.&lt;/p&gt;</comment>
                            <comment id="13012821" author="karshiang" created="Wed, 30 Mar 2011 02:18:04 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;New finding here:&lt;br/&gt;
For the 0-column data, it is because it is never read from the file. As I step through the line, here it returns -1 position from org.apache.cassandra.io.sstable.SSTableReader.java::getPosition(DecoratedKey decoratedKey, Operator op), line 448 (bf.isPresent(decoratedKey.key) is returning false) - key is missing.&lt;/p&gt;

&lt;p&gt;There seem to be a missing record which is indexed or indexed column itself not updated when the record is removed &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. &lt;/p&gt;

&lt;p&gt;As for the data returned with 0-column, simply because a container is always created (final ColumnFamily returnCF = ColumnFamily.create(metadata)) and returned from getTopLevelColumns even if there is no read taken.&lt;/p&gt;

&lt;p&gt;As for this case, it causes Timeout exception to Hector when null exception thrown without captured.&lt;/p&gt;</comment>
                            <comment id="13015193" author="rjtg" created="Sun, 3 Apr 2011 18:55:32 +0000"  >&lt;p&gt;can you provide some unit tests that reproduce your error? i&apos;d like to look into it, but i am not sure whether i understand the issue correctly.&lt;/p&gt;</comment>
                            <comment id="13015816" author="karshiang" created="Tue, 5 Apr 2011 09:42:19 +0000"  >&lt;p&gt;Hi Roland,&lt;/p&gt;

&lt;p&gt;Sure, as we are trying to do that. In the mean time, I would like to update you more about our findings:&lt;br/&gt;
We built a test case on the PC with the existing DB and to produce same issue, without hector API. The test case works (able to create null exception) on the original PC. &lt;/p&gt;

&lt;p&gt;java.lang.NullPointerException&lt;br/&gt;
	at org.apache.cassandra.db.ColumnFamilyStore.satisfies(ColumnFamilyStore.java:1787)&lt;br/&gt;
	at org.apache.cassandra.db.ColumnFamilyStore.scan(ColumnFamilyStore.java:1727)&lt;br/&gt;
	at TestScan.main(TestScan.java:74)&lt;/p&gt;

&lt;p&gt;line 1787: IColumn column = data.getColumn(expression.column_name); where data is NULL&lt;/p&gt;


&lt;p&gt;Zipping the 0.7.4 cassandra data to another new PC gives the same issue, but the missing key order may slightly different, e.g. on original PC it is at 430th, on the new PC it is 431th. Both keys appears to be same though (content in ByteBuffer).&lt;br/&gt;
(Edited: the new PC also found the problem - which makes more sense)&lt;/p&gt;

&lt;p&gt;We will continue to check if it is due to the &quot;if (column.isMarkedForDelete())&quot; is not working on the PC with have the null encountered. Since we checked that, both PCs have the same number of columns returned in &quot;scan&quot; method at line &quot;ColumnFamily indexRow = indexCFS.getColumnFamily(indexFilter);&quot;, where &quot;indexRow.getColumnCount()&quot; both giving 1996, with some rows already deleted as tombstones. &lt;/p&gt;</comment>
                            <comment id="13015819" author="karshiang" created="Tue, 5 Apr 2011 09:47:04 +0000"  >&lt;p&gt;Some information i missed in update:&lt;br/&gt;
In the PC with NULL exception, I do a continue when found &quot;data&quot; is null, and ignore that. I will get 1040 columns returned. On the 2nd (new) PC, without the NULL exception nor additional code to bypass null data, it is getting 1040 records as well. From here, we will study more our DB to find out where it went wrong/different.&lt;/p&gt;</comment>
                            <comment id="13015876" author="rjtg" created="Tue, 5 Apr 2011 11:33:02 +0000"  >&lt;p&gt;Sounds As if the Index is still pointing to deleted entriss. &lt;/p&gt;</comment>
                            <comment id="13015932" author="karshiang" created="Tue, 5 Apr 2011 14:23:53 +0000"  >&lt;p&gt;hi, yes. it seems to me so. Here, we create a table &quot;FileMap&quot;, in which we store columns e.g. &quot;content&quot;, &quot;authorID&quot;, &quot;Version&quot;, &quot;Modified Time&quot;, &quot;File Type&quot;, etc. Among them, sorted indices are &quot;authorID&quot; (as UserIndex), &quot;File Type&quot;, &quot;Modified Time&quot;, and &quot;CassType&quot;; where CassType means generally &apos;file type&apos; here in our case. It is not used though.&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;03/30/2011  09:34 AM        11,366,878 FileMap-f-53-Data.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  09:34 AM            78,496 FileMap-f-53-Filter.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  09:34 AM           735,930 FileMap-f-53-Index.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  09:34 AM             4,264 FileMap-f-53-Statistics.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM             4,055 FileMap-f-54-Data.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM                40 FileMap-f-54-Filter.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM               270 FileMap-f-54-Index.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM             4,264 FileMap-f-54-Statistics.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM            24,068 FileMap-f-55-Data.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM               200 FileMap-f-55-Filter.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM             1,746 FileMap-f-55-Index.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM             4,264 FileMap-f-55-Statistics.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM           961,808 FileMap.CassTypeIndex-f-53-Data.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM             1,936 FileMap.CassTypeIndex-f-53-Filter.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM                11 FileMap.CassTypeIndex-f-53-Index.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM             4,264 FileMap.CassTypeIndex-f-53-Statistics.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/29/2011  02:52 PM           961,386 FileMap.FileTypeIndex-f-50-Data.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/29/2011  02:52 PM             1,936 FileMap.FileTypeIndex-f-50-Filter.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/29/2011  02:52 PM                11 FileMap.FileTypeIndex-f-50-Index.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/29/2011  02:52 PM             4,264 FileMap.FileTypeIndex-f-50-Statistics.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM               404 FileMap.FileTypeIndex-f-51-Data.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM                16 FileMap.FileTypeIndex-f-51-Filter.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM                11 FileMap.FileTypeIndex-f-51-Index.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM             4,264 FileMap.FileTypeIndex-f-51-Statistics.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM             2,358 FileMap.FileTypeIndex-f-52-Data.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM                16 FileMap.FileTypeIndex-f-52-Filter.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM                11 FileMap.FileTypeIndex-f-52-Index.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM             4,264 FileMap.FileTypeIndex-f-52-Statistics.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/29/2011  02:52 PM         3,298,947 FileMap.ModifiedIndex-f-50-Data.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/29/2011  02:52 PM            78,016 FileMap.ModifiedIndex-f-50-Filter.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/29/2011  02:52 PM           731,106 FileMap.ModifiedIndex-f-50-Index.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/29/2011  02:52 PM             4,264 FileMap.ModifiedIndex-f-50-Statistics.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM             2,065 FileMap.ModifiedIndex-f-51-Data.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM                64 FileMap.ModifiedIndex-f-51-Filter.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM               450 FileMap.ModifiedIndex-f-51-Index.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;03/30/2011  05:37 PM             4,264 FileMap.ModifiedIndex-f-51-Statistics.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM            13,835 FileMap.ModifiedIndex-f-52-Data.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM               328 FileMap.ModifiedIndex-f-52-Filter.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM             3,006 FileMap.ModifiedIndex-f-52-Index.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM             4,264 FileMap.ModifiedIndex-f-52-Statistics.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM           962,874 FileMap.UserIndex-f-53-Data.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM             1,936 FileMap.UserIndex-f-53-Filter.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM               420 FileMap.UserIndex-f-53-Index.db&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;04/04/2011  04:07 PM             4,264 FileMap.UserIndex-f-53-Statistics.db&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;In the search, we are using IndexClause as:&lt;br/&gt;
		ByteBuffer field_author = ByteBuffer.wrap(new byte[]&lt;/p&gt;
{&apos;a&apos;}
&lt;p&gt;);&lt;br/&gt;
		ByteBuffer author_1 = IntegerSerializer.get().toByteBuffer(1);&lt;/p&gt;

&lt;p&gt;		ByteBuffer file_type = ByteBuffer.wrap(new byte[]&lt;/p&gt;
{&apos;t&apos;}
&lt;p&gt;);&lt;br/&gt;
		ByteBuffer filetype_3 = ByteBuffer.wrap(new byte[]&lt;/p&gt;
{3}
&lt;p&gt;); //file type 3&lt;/p&gt;

&lt;p&gt;		IndexClause indexClause = new IndexClause();&lt;br/&gt;
		indexClause.setCount(3000);&lt;br/&gt;
		ArrayList&amp;lt;IndexExpression&amp;gt; expressions = new ArrayList();&lt;br/&gt;
		expressions.add(new IndexExpression(field_author, IndexOperator.EQ, author_1)); //user ID = 1&lt;br/&gt;
		expressions.add(new IndexExpression(file_type, IndexOperator.EQ, filetype_3)); //file type = 3&lt;/p&gt;

&lt;p&gt;		indexClause.setExpressions(expressions);&lt;br/&gt;
		indexClause.setStart_key(new byte[]{});&lt;/p&gt;

&lt;p&gt;}}&lt;br/&gt;
In the search, it scans all the indices from &quot;FileMap.UserIndex&quot;, within which there seems having a key (index) which is not found in the table &quot;FileMap&quot;; and I roughly get that it breaks at data retrieval with &quot;FileMap-f-53-Data&quot;, when the position for the key is not found / available in &quot;FileMap-f-53-Data&quot;.&lt;/p&gt;</comment>
                            <comment id="13021382" author="jbellis" created="Tue, 19 Apr 2011 02:46:02 +0000"  >&lt;p&gt;So when you created the data, you did not use any expiring columns (TTL), correct?&lt;/p&gt;</comment>
                            <comment id="13021387" author="jbellis" created="Tue, 19 Apr 2011 02:52:30 +0000"  >&lt;p&gt;The more I think about it, the more I think that there is a rare race condition here &amp;#8211; we do a kind of row lock during updates of indexed data, but we do not lock during reads. So it&apos;s possible for an index read to say &quot;row X has this value&quot; and then have that value deleted (by another client&apos;s request) before we can read row X.&lt;/p&gt;

&lt;p&gt;BUT that does not look like what you are seeing because if I understand correctly you are seeing that the index has permanently missed a delete operation.&lt;/p&gt;</comment>
                            <comment id="13021391" author="karshiang" created="Tue, 19 Apr 2011 03:03:14 +0000"  >&lt;p&gt;hi Jon,&lt;/p&gt;

&lt;p&gt;sorry for less updates for past few days as we were busy on other tasks. We are thinking to stress-test with 0.7.5 when it is out.&lt;/p&gt;

&lt;p&gt;In the test, we have all operations e.g. &quot;insert, replace, and delete&quot;. If not wrong, we have simulated 20-users to run concurrently, however, they likely not able to delete key of different user. I think there is no such a case when 1 user is modifying his record, when another user deleting the record.&lt;/p&gt;

&lt;p&gt;There is no expiring columns (TTL) in this test.&lt;/p&gt;

&lt;p&gt;Same data on another PC will able to give the same exception, though we found the index position (n variable) can be shifted by 1 or 2.&lt;/p&gt;

&lt;p&gt;Thanks, Jon and your team for the gd work!&lt;/p&gt;</comment>
                            <comment id="13021394" author="karshiang" created="Tue, 19 Apr 2011 03:11:03 +0000"  >&lt;p&gt;Hi Jon,&lt;/p&gt;

&lt;p&gt;Allow me to add more information:&lt;/p&gt;

&lt;p&gt;Each simulated user thread will do the following in repeatitive manner:&lt;/p&gt;

&lt;p&gt;loop = 0;&lt;br/&gt;
while( running )&lt;br/&gt;
{&lt;br/&gt;
    if( loop % 5 ==0 ) &lt;/p&gt;
{ list all files in folder; }

&lt;p&gt;    create around 4~10 files but cap the total files around 2000 files only.&lt;br/&gt;
    modified around 20 files;&lt;br/&gt;
    delete 1~4 files;&lt;/p&gt;

&lt;p&gt;    loop ++;&lt;br/&gt;
}&lt;/p&gt;

&lt;p&gt;The &quot;list all files in folder&quot; is the scan action, where it will later for 1 or 2 users giving us &quot;no file&quot; in return after the next few days when restarted the same test, without resetting data. Found out it is due to the issue above. &lt;/p&gt;</comment>
                            <comment id="13021583" author="rjtg" created="Tue, 19 Apr 2011 13:36:24 +0000"  >&lt;p&gt;i just looked a little closer at your index expressions again.&lt;br/&gt;
If i understand them correctly they are subject to &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2347&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/CASSANDRA-2347&lt;/a&gt;&lt;br/&gt;
Although i don&apos;t really think it is the issue you are describing it would be nice if you could apply the patch and see if the error still occurs.&lt;/p&gt;

&lt;p&gt;You are creating the bytebuffers for author_id and file_type in a different way. Is this a mistake? &lt;/p&gt;</comment>
                            <comment id="13021941" author="karshiang" created="Wed, 20 Apr 2011 03:46:22 +0000"  >&lt;p&gt;Hi Roland,&lt;/p&gt;

&lt;p&gt;The &apos;mistake&apos; is intended by reusing some Hector API code.&lt;/p&gt;

&lt;p&gt;Hector has a Integer Serializer, which will generate 4-byte[] from given integer. The file_type is a 1-byte array. It is to produce exact effected client call into a test case, solely running cassandra. &lt;/p&gt;</comment>
                            <comment id="13021955" author="karshiang" created="Wed, 20 Apr 2011 04:24:31 +0000"  >&lt;p&gt;for issue: &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2347&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/CASSANDRA-2347&lt;/a&gt;, I suspect we encountered that in another case. It has a validation failure at times.&lt;/p&gt;

&lt;p&gt;I applied the change. As expected, the error is still there, data is missing or indexed key extra then throw NULL exception out.&lt;/p&gt;</comment>
                            <comment id="13028857" author="jbellis" created="Wed, 4 May 2011 17:47:43 +0000"  >&lt;p&gt;I found &lt;b&gt;a&lt;/b&gt; bug that could cause this: Cassandra will re-create a deleted index entry if it gets a write with an obsolete timestamp, but the data row tombstone will correctly suppress an update there. (So when you do an index query for value=X, and the index says &quot;row K has that value,&quot; then you get an error trying to read row K that doesn&apos;t exist.)&lt;/p&gt;

&lt;p&gt;I don&apos;t think this is the bug Tey Kar is hitting, though, because unless I&apos;m mistaken you won&apos;t get this NPE until after the data row tombstone is removed by compaction after gc_grace_seconds.  4 days isn&apos;t enough to see that unless you&apos;ve tweaked gc_g_s.&lt;/p&gt;

&lt;p&gt;Still, it&apos;s worth fixing.  Patch attached.  (Also adds an assert w/ more information if/when another way of triggering this is found.)&lt;/p&gt;</comment>
                            <comment id="13029005" author="cywjackson" created="Wed, 4 May 2011 22:07:34 +0000"  >&lt;p&gt;I have an existing data that was resulting similar NPE  before the patch. After applying the patch, the following observed:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;DEBUG [ReadStage:82] 2011-05-04 21:23:27,114 ColumnFamilyStore.java (line 1514) fetched data row ColumnFamily(inode -deleted at 1304363600008- [70617468:false:49@1304363600219,])
DEBUG [ReadStage:82] 2011-05-04 21:23:27,114 ColumnFamilyStore.java (line 1532) row ColumnFamily(inode -deleted at 1304363600008- [70617468:false:49@1304363600219,]) satisfies all clauses
DEBUG [ReadStage:82] 2011-05-04 21:23:27,115 ColumnFamilyStore.java (line 1514) fetched data row ColumnFamily(inode [70617468:false:10@1304353355296,])
ERROR [ReadStage:82] 2011-05-04 21:23:27,115 AbstractCassandraDaemon.java (line 112) Fatal exception in thread Thread[ReadStage:82,5,main]
java.lang.AssertionError: No data found for NamesQueryFilter(columns=java.nio.HeapByteBuffer[pos=12 lim=16 cap=17]) in DecoratedKey(29842926756667498147838693957802723793, 3134346637326336393966396130336561376538623330316566383561616131):QueryPath(columnFamilyName=&apos;inode&apos;, superColumnName=&apos;null&apos;, columnName=&apos;null&apos;) (original filter NamesQueryFilter(columns=java.nio.HeapByteBuffer[pos=12 lim=16 cap=17])) from expression 73656e74696e656cEQ78
    at org.apache.cassandra.db.ColumnFamilyStore.scan(ColumnFamilyStore.java:1512)
    at org.apache.cassandra.service.IndexScanVerbHandler.doVerb(IndexScanVerbHandler.java:42)
    at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:72)
    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    at java.lang.Thread.run(Thread.java:662)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;was the fix intend to avoid future problem, as such existing problem would need a workaround solution?&lt;/p&gt;</comment>
                            <comment id="13029021" author="jbellis" created="Wed, 4 May 2011 22:48:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;was the fix intend to avoid future problem&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yes.  as discussed above, once you corrupt your index this way the corruption is recorded permanently and you need to drop the index and recreate it.&lt;/p&gt;</comment>
                            <comment id="13029366" author="slebresne" created="Thu, 5 May 2011 15:19:19 +0000"  >&lt;p&gt;Comments on the patch:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;ignoreObsoleteMutation() now forgot to actually remove the obsolete mutation from cf.&lt;/li&gt;
	&lt;li&gt;not sure why mutatedIndexColumns need to be concurrent. There is no concurrency in ignoreObsoleteMutation, is there ?&lt;/li&gt;
	&lt;li&gt;really minor: change to debug log &quot;Scanning index row %s ...&quot; seems misleading since the first argument is not a row name.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Other than that, I do agree with you that there is quite probably a race between reads and concurrent writes. But also agree that it doesn&apos;t seem to be the problem here&lt;/p&gt;</comment>
                            <comment id="13029394" author="jbellis" created="Thu, 5 May 2011 15:54:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;ignoreObsoleteMutation() now forgot to actually remove the obsolete mutation from cf&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;this isn&apos;t actually necessary, though, since if it&apos;s taken out of the list of mutated index columns the obsolete columns will only be applied to the &quot;main&quot; data row, and including obsolete columns there is harmless.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;not sure why mutatedIndexColumns need to be concurrent&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;because we might remove from the collection while iterating over it.  treeset will throw concurrentmodificationexception.  but maybe iterator.remove would work, now that you mention it?&lt;/p&gt;</comment>
                            <comment id="13029422" author="slebresne" created="Thu, 5 May 2011 16:35:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;this isn&apos;t actually necessary, though, since if it&apos;s taken out of the list of mutated index columns the obsolete columns will only be applied to the &quot;main&quot; data row, and including obsolete columns there is harmless.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Very true.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;but maybe iterator.remove would work&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think it will&lt;/p&gt;</comment>
                            <comment id="13029442" author="jbellis" created="Thu, 5 May 2011 17:12:38 +0000"  >&lt;p&gt;v2 attached w/ iterator/Set change.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;change to debug log &quot;Scanning index row %s ...&quot; seems misleading since the first argument is not a row name&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;it actually is the same CF+row as before, I just encapsulated it in getExpressionString so I can re-use the method in case of assertion failure later. Tweaked format a bit in v2, here&apos;s an example debug output:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Scanning index &apos;world2 EQ 15&apos; starting with
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13029446" author="slebresne" created="Thu, 5 May 2011 17:20:29 +0000"  >&lt;p&gt;+1 v2&lt;/p&gt;</comment>
                            <comment id="13029453" author="jbellis" created="Thu, 5 May 2011 17:35:31 +0000"  >&lt;p&gt;Oops, that&apos;s actually column + value, not CF.&lt;/p&gt;

&lt;p&gt;For the record, v3 adds CF:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Scanning index &apos;CF1.world2 EQ 15&apos; starting with
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Will commit based on v2 +1.&lt;/p&gt;</comment>
                            <comment id="13029477" author="hudson" created="Thu, 5 May 2011 18:14:18 +0000"  >&lt;p&gt;Integrated in Cassandra-0.7 #470 (See &lt;a href=&quot;https://builds.apache.org/hudson/job/Cassandra-0.7/470/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/hudson/job/Cassandra-0.7/470/&lt;/a&gt;)&lt;br/&gt;
    improve ignoring of obsoletemutations in index maintenance&lt;br/&gt;
patch by jbellis; reviewed by slebresne for &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2401&quot; title=&quot;getColumnFamily() return null, which is not checked in ColumnFamilyStore.java scan() method, causing Timeout Exception in query&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-2401&quot;&gt;&lt;del&gt;CASSANDRA-2401&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13030425" author="cywjackson" created="Sat, 7 May 2011 23:40:40 +0000"  >&lt;p&gt;Here is 1 way that i could 100% reproduce the issue with data being null:&lt;/p&gt;

&lt;p&gt;Need 2 nodes, 1 is gonna to autobootstrap to the other. Also assuming completely clean start (blow up the /var/lib/cassandra/ or where ever data are stored&lt;/p&gt;

&lt;p&gt;i am also using brisk beta to test&lt;/p&gt;

&lt;p&gt;to start:&lt;br/&gt;
node-A:&lt;br/&gt;
1) get brisk&lt;br/&gt;
2) start brisk  with -t (jobtracker)&lt;br/&gt;
3) run a simple hive query : &lt;br/&gt;
 3a) bin/brisk hive &lt;br/&gt;
 3b) create table foo (bar INT);&lt;br/&gt;
 3c) select count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; from foo;&lt;br/&gt;
 3d) exit;&lt;br/&gt;
4) every thing should be so far so good, let the brisk node continue to be up&lt;/p&gt;

&lt;p&gt;node-B:&lt;br/&gt;
1) get brisk&lt;br/&gt;
2) modify the resources/cassandra/conf/cassandra.yaml:&lt;br/&gt;
 2a) to enable autobootstrap. &lt;br/&gt;
 2b) point seeds to node-A&lt;/p&gt;

&lt;p&gt;3) put a sleep or break point in o.a.c.service.StorageService.joinTokenRing method, right after &quot;Map&amp;lt;InetAddress, Double&amp;gt; loadinfo = StorageLoadBalancer.instance.getLoadInfo();&quot; (personal preference: log a sleep line, add a thread.sleep(a_long_time))&lt;br/&gt;
4) start brisk with -t on node-B &lt;br/&gt;
5) wait till the log line &quot;Joining: getting bootstrap token&quot; , it should now reaches your break point (or zz)&lt;br/&gt;
6) crash the jvm (personal preference: kill -9 &amp;lt;pid&amp;gt;)&lt;/p&gt;

&lt;p&gt;back to node-A&lt;br/&gt;
1) exit the jvm (BriskDaemon) &quot;normally&quot; (kill &amp;lt;pid&amp;gt;)&lt;br/&gt;
2) start the brisk node again (with -t):&lt;/p&gt;

&lt;p&gt;log from node-A: &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; INFO 23:25:00,213 Logging initialized
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/riptano/work/brisk/resources/cassandra/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/riptano/work/brisk/resources/hadoop/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
 INFO 23:25:00,235 Heap size: 510263296/511311872
 INFO 23:25:00,237 JNA not found. Native methods will be disabled.
 INFO 23:25:00,263 Loading settings from file:/home/riptano/work/brisk/resources/cassandra/conf/cassandra.yaml
 INFO 23:25:00,470 DiskAccessMode &apos;auto&apos; determined to be mmap, indexAccessMode is mmap
 INFO 23:25:00,496 Detected Hadoop trackers are enabled, setting my DC to Brisk
 INFO 23:25:00,696 Global memtable threshold is enabled at 162MB
 INFO 23:25:00,846 Opening /var/lib/cassandra/data/system/IndexInfo-f-1
 INFO 23:25:00,912 Opening /var/lib/cassandra/data/system/Schema-f-2
 INFO 23:25:00,926 Opening /var/lib/cassandra/data/system/Schema-f-1
 INFO 23:25:00,951 Opening /var/lib/cassandra/data/system/Migrations-f-2
 INFO 23:25:00,954 Opening /var/lib/cassandra/data/system/Migrations-f-1
 INFO 23:25:00,970 Opening /var/lib/cassandra/data/system/LocationInfo-f-2
 INFO 23:25:00,989 Opening /var/lib/cassandra/data/system/LocationInfo-f-1
 INFO 23:25:01,089 Loading schema version c4fd2440-7900-11e0-0000-ba846f9adcf7
 INFO 23:25:01,499 Creating new commitlog segment /var/lib/cassandra/commitlog/CommitLog-1304810701499.log
 INFO 23:25:01,530 Replaying /var/lib/cassandra/commitlog/CommitLog-1304810455288.log
 INFO 23:25:01,675 Finished reading /var/lib/cassandra/commitlog/CommitLog-1304810455288.log
 INFO 23:25:01,730 Enqueuing flush of Memtable-MetaStore@102170028(869/1086 serialized/live bytes, 3 ops)
 INFO 23:25:01,735 Writing Memtable-MetaStore@102170028(869/1086 serialized/live bytes, 3 ops)
 INFO 23:25:01,743 Enqueuing flush of Memtable-sblocks@1075051425(3044096/3805120 serialized/live bytes, 17 ops)
 INFO 23:25:01,747 Enqueuing flush of Memtable-inode.path@780298059(2848/3560 serialized/live bytes, 59 ops)
 INFO 23:25:01,748 Enqueuing flush of Memtable-inode.sentinel@1934329031(2848/3560 serialized/live bytes, 59 ops)
 INFO 23:25:01,748 Enqueuing flush of Memtable-inode@1660575731(6393/7991 serialized/live bytes, 134 ops)
 INFO 23:25:01,821 Completed flushing /var/lib/cassandra/data/HiveMetaStore/MetaStore-f-1-Data.db (989 bytes)
 INFO 23:25:01,832 Writing Memtable-sblocks@1075051425(3044096/3805120 serialized/live bytes, 17 ops)
 INFO 23:25:01,927 Completed flushing /var/lib/cassandra/data/cfs/sblocks-f-1-Data.db (3045448 bytes)
 INFO 23:25:01,928 Writing Memtable-inode.path@780298059(2848/3560 serialized/live bytes, 59 ops)
 INFO 23:25:01,968 Completed flushing /var/lib/cassandra/data/cfs/inode.path-f-1-Data.db (5346 bytes)
 INFO 23:25:01,969 Writing Memtable-inode.sentinel@1934329031(2848/3560 serialized/live bytes, 59 ops)
 INFO 23:25:02,035 Completed flushing /var/lib/cassandra/data/cfs/inode.sentinel-f-1-Data.db (1735 bytes)
 INFO 23:25:02,036 Writing Memtable-inode@1660575731(6393/7991 serialized/live bytes, 134 ops)
 INFO 23:25:02,085 Completed flushing /var/lib/cassandra/data/cfs/inode-f-1-Data.db (8582 bytes)
 INFO 23:25:02,087 Log replay complete
 INFO 23:25:02,092 Cassandra version: 0.8.0-beta2-SNAPSHOT
 INFO 23:25:02,092 Thrift API version: 19.10.0
 INFO 23:25:02,092 Loading persisted ring state
 INFO 23:25:02,092 load token size: 0
 INFO 23:25:02,093 Starting up server gossip
 INFO 23:25:02,104 Enqueuing flush of Memtable-LocationInfo@22262475(29/36 serialized/live bytes, 1 ops)
 INFO 23:25:02,105 Writing Memtable-LocationInfo@22262475(29/36 serialized/live bytes, 1 ops)
 INFO 23:25:02,127 Completed flushing /var/lib/cassandra/data/system/LocationInfo-f-3-Data.db (80 bytes)
 INFO 23:25:02,149 Starting Messaging Service on port 7000
 INFO 23:25:02,172 Using saved token 152036150612811635197207268153837644139
 INFO 23:25:02,173 Enqueuing flush of Memtable-LocationInfo@1977026981(53/66 serialized/live bytes, 2 ops)
 INFO 23:25:02,174 Writing Memtable-LocationInfo@1977026981(53/66 serialized/live bytes, 2 ops)
 INFO 23:25:02,190 Completed flushing /var/lib/cassandra/data/system/LocationInfo-f-4-Data.db (163 bytes)
 INFO 23:25:02,193 Compacting Major: [SSTableReader(path=&apos;/var/lib/cassandra/data/system/LocationInfo-f-2-Data.db&apos;), SSTableReader(path=&apos;/var/lib/cassandra/data/system/LocationInfo-f-1-Data.db&apos;), SSTableReader(path=&apos;/var/lib/cassandra/data/system/LocationInfo-f-3-Data.db&apos;), SSTableReader(path=&apos;/var/lib/cassandra/data/system/LocationInfo-f-4-Data.db&apos;)]
 INFO 23:25:02,196 Will not load MX4J, mx4j-tools.jar is not in the classpath
 INFO 23:25:02,196 Starting up Hadoop trackers
 INFO 23:25:02,197 Waiting for gossip to start
 INFO 23:25:02,225 Major@1830423861(system, LocationInfo, 438/741) now compacting at 16777 bytes/ms.
 INFO 23:25:02,257 Compacted to /var/lib/cassandra/data/system/LocationInfo-tmp-f-5-Data.db.  741 to 447 (~60% of original) bytes for 3 keys.  Time: 64ms.
 INFO 23:25:07,272 Chose seed 10.179.96.212 as jobtracker
 WARN 23:25:09,331 Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties, hadoop-metrics2.properties
 INFO 23:25:09,994 Chose seed 10.179.96.212 as jobtracker
 INFO 23:25:10,139 Updating the current master key for generating delegation tokens
 INFO 23:25:10,143 Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
 INFO 23:25:10,143 Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
 INFO 23:25:10,144 Updating the current master key for generating delegation tokens
 INFO 23:25:10,145 Refreshing hosts (include/exclude) list
 INFO 23:25:10,223 Starting jobtracker with owner as riptano
 INFO 23:25:10,245 Starting SocketReader
 INFO 23:25:10,374 Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
 INFO 23:25:10,623 Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
 INFO 23:25:10,673 Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
 INFO 23:25:10,673 listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
 INFO 23:25:10,674 Jetty bound to port 50030
 INFO 23:25:10,674 jetty-6.1.21
 INFO 23:25:11,140 Started SelectChannelConnector@0.0.0.0:50030
 INFO 23:25:11,147 JobTracker up at: 8012
 INFO 23:25:11,147 JobTracker webserver: 50030
 WARN 23:25:11,276 Incorrect permissions on cassandra://localhost:9160/tmp/hadoop-riptano/mapred/system. Setting it to rwx------
ERROR 23:25:11,321 Fatal exception in thread Thread[ReadStage:4,5,main]
java.lang.AssertionError: No data found for NamesQueryFilter(columns=java.nio.HeapByteBuffer[pos=12 lim=16 cap=17]) in DecoratedKey(55249227080490826413412398468829851220, 3165333533353736613164333836353061346636333465656437326131353939):QueryPath(columnFamilyName=&apos;inode&apos;, superColumnName=&apos;null&apos;, columnName=&apos;null&apos;) (original filter NamesQueryFilter(columns=java.nio.HeapByteBuffer[pos=12 lim=16 cap=17])) from expression &apos;inode.73656e74696e656c EQ 78&apos;
        at org.apache.cassandra.db.ColumnFamilyStore.scan(ColumnFamilyStore.java:1513)
        at org.apache.cassandra.service.IndexScanVerbHandler.doVerb(IndexScanVerbHandler.java:46)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:72)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
 INFO 23:25:20,059 Deleted /var/lib/cassandra/data/system/LocationInfo-f-3
 INFO 23:25:20,060 Deleted /var/lib/cassandra/data/system/LocationInfo-f-4
 INFO 23:25:20,576 Deleted /var/lib/cassandra/data/system/LocationInfo-f-1
 INFO 23:25:20,577 Deleted /var/lib/cassandra/data/system/LocationInfo-f-2
 INFO 23:25:21,297 problem cleaning system directory: cassandra://localhost:9160/tmp/hadoop-riptano/mapred/system
java.io.IOException: TimedOutException()
        at org.apache.cassandra.hadoop.fs.CassandraFileSystemThriftStore.listDeepSubPaths(CassandraFileSystemThriftStore.java:523)
        at org.apache.cassandra.hadoop.fs.CassandraFileSystemThriftStore.listSubPaths(CassandraFileSystemThriftStore.java:529)
        at org.apache.cassandra.hadoop.fs.CassandraFileSystem.listStatus(CassandraFileSystem.java:171)
        at org.apache.hadoop.mapred.JobTracker.&amp;lt;init&amp;gt;(JobTracker.java:2374)
        at org.apache.hadoop.mapred.JobTracker.&amp;lt;init&amp;gt;(JobTracker.java:2174)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:303)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:294)
        at org.apache.cassandra.hadoop.trackers.TrackerInitializer$1.run(TrackerInitializer.java:93)
        at java.lang.Thread.run(Thread.java:662)
Caused by: TimedOutException()
        at org.apache.cassandra.thrift.CassandraServer.get_indexed_slices(CassandraServer.java:673)
        at org.apache.cassandra.hadoop.fs.CassandraFileSystemThriftStore.listDeepSubPaths(CassandraFileSystemThriftStore.java:506)
        ... 8 more
 WARN 23:25:31,300 Incorrect permissions on cassandra://localhost:9160/tmp/hadoop-riptano/mapred/system. Setting it to rwx------
ERROR 23:25:31,315 Fatal exception in thread Thread[ReadStage:6,5,main]
java.lang.AssertionError: No data found for NamesQueryFilter(columns=java.nio.HeapByteBuffer[pos=12 lim=16 cap=17]) in DecoratedKey(55249227080490826413412398468829851220, 3165333533353736613164333836353061346636333465656437326131353939):QueryPath(columnFamilyName=&apos;inode&apos;, superColumnName=&apos;null&apos;, columnName=&apos;null&apos;) (original filter NamesQueryFilter(columns=java.nio.HeapByteBuffer[pos=12 lim=16 cap=17])) from expression &apos;inode.73656e74696e656c EQ 78&apos;
        at org.apache.cassandra.db.ColumnFamilyStore.scan(ColumnFamilyStore.java:1513)
        at org.apache.cassandra.service.IndexScanVerbHandler.doVerb(IndexScanVerbHandler.java:46)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:72)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
 INFO 23:25:41,303 problem cleaning system directory: cassandra://localhost:9160/tmp/hadoop-riptano/mapred/system
java.io.IOException: TimedOutException()
        at org.apache.cassandra.hadoop.fs.CassandraFileSystemThriftStore.listDeepSubPaths(CassandraFileSystemThriftStore.java:523)
        at org.apache.cassandra.hadoop.fs.CassandraFileSystemThriftStore.listSubPaths(CassandraFileSystemThriftStore.java:529)
        at org.apache.cassandra.hadoop.fs.CassandraFileSystem.listStatus(CassandraFileSystem.java:171)
        at org.apache.hadoop.mapred.JobTracker.&amp;lt;init&amp;gt;(JobTracker.java:2374)
        at org.apache.hadoop.mapred.JobTracker.&amp;lt;init&amp;gt;(JobTracker.java:2174)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:303)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:294)
        at org.apache.cassandra.hadoop.trackers.TrackerInitializer$1.run(TrackerInitializer.java:93)
        at java.lang.Thread.run(Thread.java:662)
Caused by: TimedOutException()
        at org.apache.cassandra.thrift.CassandraServer.get_indexed_slices(CassandraServer.java:673)
        at org.apache.cassandra.hadoop.fs.CassandraFileSystemThriftStore.listDeepSubPaths(CassandraFileSystemThriftStore.java:506)
        ... 8 more
 WARN 23:25:51,308 Incorrect permissions on cassandra://localhost:9160/tmp/hadoop-riptano/mapred/system. Setting it to rwx------
ERROR 23:25:51,321 Fatal exception in thread Thread[ReadStage:8,5,main]
java.lang.AssertionError: No data found for NamesQueryFilter(columns=java.nio.HeapByteBuffer[pos=12 lim=16 cap=17]) in DecoratedKey(55249227080490826413412398468829851220, 3165333533353736613164333836353061346636333465656437326131353939):QueryPath(columnFamilyName=&apos;inode&apos;, superColumnName=&apos;null&apos;, columnName=&apos;null&apos;) (original filter NamesQueryFilter(columns=java.nio.HeapByteBuffer[pos=12 lim=16 cap=17])) from expression &apos;inode.73656e74696e656c EQ 78&apos;
        at org.apache.cassandra.db.ColumnFamilyStore.scan(ColumnFamilyStore.java:1513)
        at org.apache.cassandra.service.IndexScanVerbHandler.doVerb(IndexScanVerbHandler.java:46)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:72)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="13030446" author="jbellis" created="Sun, 8 May 2011 02:36:54 +0000"  >&lt;p&gt;kill -9 w/o the bootstrap is not sufficient to cause the problem?&lt;/p&gt;

&lt;p&gt;If you allow the bootstrap to finish does it work correctly if you kill -9 node A?&lt;/p&gt;

&lt;p&gt;Bootstrap shouldn&apos;t cause anything to be written to node A (except the presence of a new node, to system table) so I&apos;m inclined to think the kill -9 of A is the important part.&lt;/p&gt;</comment>
                            <comment id="13030447" author="jbellis" created="Sun, 8 May 2011 02:41:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;Bootstrap shouldn&apos;t cause anything to be written to node A&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm, but it does cause A to flush. I wonder if that&apos;s the connection.&lt;/p&gt;

&lt;p&gt;Can you try with invoking nodetool flush against A, instead of doing a bootstrap?&lt;/p&gt;</comment>
                            <comment id="13030451" author="jbellis" created="Sun, 8 May 2011 03:15:01 +0000"  >&lt;p&gt;Another thing to try: after kill -9 of A but before restarting it, remove the commitlog &lt;b&gt;header&lt;/b&gt; files (just the header ones). This should force full CL replay on restart.&lt;/p&gt;</comment>
                            <comment id="13032542" author="slebresne" created="Thu, 12 May 2011 17:54:12 +0000"  >&lt;p&gt;From irc:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;pcmanus : jbellis: do you know what&apos;s up with #2401 ?
jbellis : jackson can&apos;t reproduce anymore either, but he wants to test more before calling it fixed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So I&apos;m going to mark this resolved as this fixed a legit bug and I don&apos;t want to push it 0.7.7.&lt;br/&gt;
If there is still related problems, let&apos;s open another ticket.&lt;/p&gt;</comment>
                            <comment id="13033331" author="thobbs" created="Fri, 13 May 2011 21:53:37 +0000"  >&lt;p&gt;With these changes, using a count of 0 in the SlicePredicate produces the following AssertionError (and a TimedOutExc for the client):&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR 16:13:38,864 Fatal exception in thread Thread[ReadStage:16,5,main]
java.lang.AssertionError: No data found for SliceQueryFilter(start=java.nio.HeapByteBuffer[pos=10 lim=10 cap=30], finish=java.nio.HeapByteBuffer[pos=17 lim=17 cap=30], reversed=false, count=0] in DecoratedKey(81509516161424251288255223397843705139, 6b657931):QueryPath(columnFamilyName=&apos;cf&apos;, superColumnName=&apos;null&apos;, columnName=&apos;null&apos;) (original filter SliceQueryFilter(start=java.nio.HeapByteBuffer[pos=10 lim=10 cap=30], finish=java.nio.HeapByteBuffer[pos=17 lim=17 cap=30], reversed=false, count=0]) from expression &apos;cf.626972746864617465 EQ 1&apos;
	at org.apache.cassandra.db.ColumnFamilyStore.scan(ColumnFamilyStore.java:1517)
	at org.apache.cassandra.service.IndexScanVerbHandler.doVerb(IndexScanVerbHandler.java:42)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:72)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This was during a get_indexed_slices().&lt;/p&gt;</comment>
                            <comment id="13033543" author="jbellis" created="Sat, 14 May 2011 15:03:01 +0000"  >&lt;p&gt;Created &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2653&quot; title=&quot;index scan errors out when zero columns are requested&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-2653&quot;&gt;&lt;del&gt;CASSANDRA-2653&lt;/del&gt;&lt;/a&gt; to address this, since it will probably be in a different release than the original 2401 fix.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12478298" name="2401-v2.txt" size="8866" author="jbellis" created="Thu, 5 May 2011 17:12:38 +0000"/>
                            <attachment id="12478303" name="2401-v3.txt" size="8973" author="jbellis" created="Thu, 5 May 2011 17:31:56 +0000"/>
                            <attachment id="12478188" name="2401.txt" size="9321" author="jbellis" created="Wed, 4 May 2011 17:47:43 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[jbellis]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>20603</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            14 years, 28 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0gb5r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>93238</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>slebresne</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[slebresne]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>