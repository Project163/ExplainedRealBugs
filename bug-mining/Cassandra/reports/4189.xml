<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 23:02:04 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-11383] Avoid index segment stitching in RAM which lead to OOM on big SSTable files</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-11383</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;13 bare metal machines&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;6 cores CPU (12 HT)&lt;/li&gt;
	&lt;li&gt;64Gb RAM&lt;/li&gt;
	&lt;li&gt;4 SSD in RAID0&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; JVM settings:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;G1 GC&lt;/li&gt;
	&lt;li&gt;Xms32G, Xmx32G&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Data set:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&#8776; 100Gb/per node&lt;/li&gt;
	&lt;li&gt;1.3 Tb cluster-wide&lt;/li&gt;
	&lt;li&gt;&#8776; 20Gb for all SASI indices&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;C* settings:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;concurrent_compactors: 1&lt;/li&gt;
	&lt;li&gt;compaction_throughput_mb_per_sec: 256&lt;/li&gt;
	&lt;li&gt;memtable_heap_space_in_mb: 2048&lt;/li&gt;
	&lt;li&gt;memtable_offheap_space_in_mb: 2048&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I created 9 SASI indices&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;8 indices with text field, NonTokenizingAnalyser,  PREFIX mode, case-insensitive&lt;/li&gt;
	&lt;li&gt;1 index with numeric field, SPARSE mode&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; After a while, the nodes just gone OOM.&lt;/p&gt;

&lt;p&gt; I attach log files. You can see a lot of GC happening while index segments are flush to disk. At some point the node OOM ...&lt;/p&gt;

&lt;p&gt;/cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt;&lt;/p&gt;</description>
                <environment>&lt;p&gt;C* 3.4&lt;/p&gt;</environment>
        <key id="12951602">CASSANDRA-11383</key>
            <summary>Avoid index segment stitching in RAM which lead to OOM on big SSTable files</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jwest">Jordan West</assignee>
                                    <reporter username="doanduyhai">DuyHai Doan</reporter>
                        <labels>
                            <label>sasi</label>
                    </labels>
                <created>Fri, 18 Mar 2016 19:42:46 +0000</created>
                <updated>Tue, 16 Apr 2019 09:30:39 +0000</updated>
                            <resolved>Sun, 27 Mar 2016 22:33:09 +0000</resolved>
                                        <fixVersion>3.5</fixVersion>
                                    <component>Legacy/CQL</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="15202027" author="xedin" created="Fri, 18 Mar 2016 19:50:44 +0000"  >&lt;p&gt;What is your memtable size? all of the index building is currently happening in fixed chunk sizes in memory, in case of flushing from memtable size of the every individual segment is going to be set to the size of memtable, so if you have big memtable and a bunch of indexes at this point it all depends on how fast can you flush and it looks like flush itself takes about 0.5 second.&lt;/p&gt;</comment>
                            <comment id="15202042" author="doanduyhai" created="Fri, 18 Mar 2016 19:53:04 +0000"  >&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;memtable_heap_space_in_mb: 2048&lt;/li&gt;
	&lt;li&gt;memtable_offheap_space_in_mb: 2048&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15202070" author="doanduyhai" created="Fri, 18 Mar 2016 20:14:20 +0000"  >&lt;p&gt;I try to create indices ONE by ONE, but same result.&lt;/p&gt;

&lt;p&gt;new JVM settings:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;CMS&lt;/li&gt;
	&lt;li&gt;Xms8G, Xmx8G&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;after some time, the node goes long Old GC and then crashes:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;632936; Par Survivor Space: 125829120 -&amp;gt; 120349752
WARN  [Service Thread] 2016-03-18 21:02:45,237 GCInspector.java:282 - ConcurrentMarkSweep GC in 10417ms.  Par Eden Space: 1006632952 -&amp;gt; 1006632928; Par Survivor Space: 125829120 -&amp;gt; 120921320
WARN  [Service Thread] 2016-03-18 21:02:56,969 GCInspector.java:282 - ConcurrentMarkSweep GC in 11675ms.  Par Survivor Space: 125829112 -&amp;gt; 121748224
WARN  [Service Thread] 2016-03-18 21:03:07,359 GCInspector.java:282 - ConcurrentMarkSweep GC in 10327ms.  CMS Old Gen: 7331643344 -&amp;gt; 7331643392; Par Eden Space: 1006632960 -&amp;gt; 1006632864; Par Survivor Space: 125828928 -&amp;gt; 122147720
WARN  [Service Thread] 2016-03-18 21:03:50,019 GCInspector.java:282 - ConcurrentMarkSweep GC in 42574ms.  CMS Old Gen: 7331643392 -&amp;gt; 7331643368; Par Eden Space: 1006632960 -&amp;gt; 1006632824; Par Survivor Space: 125829120 -&amp;gt; 122651640
WARN  [Service Thread] 2016-03-18 21:05:01,704 GCInspector.java:282 - ConcurrentMarkSweep GC in 71592ms.  Par Eden Space: 1006632960 -&amp;gt; 1006632928; Par Survivor Space: 125829112 -&amp;gt; 123069400
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15202072" author="doanduyhai" created="Fri, 18 Mar 2016 20:15:36 +0000"  >&lt;p&gt;If someone want the routine to generate the dataset, I have everything available. I used co-located Spark for the job of inserting randomized massive data&lt;/p&gt;</comment>
                            <comment id="15202079" author="doanduyhai" created="Fri, 18 Mar 2016 20:21:28 +0000"  >&lt;p&gt;I attach the new log file for OOM occuring for CMS 8Gb heap settings. All other settings remain the same&lt;/p&gt;</comment>
                            <comment id="15202080" author="jkrupan" created="Fri, 18 Mar 2016 20:22:46 +0000"  >&lt;p&gt;1. How large are each of the text fields being indexed? Are they fairly short or are some quite long (and not tokenized, either)? I&apos;m wondering if maybe a wide column is causing difficulty.&lt;br/&gt;
2. Does OOM occur if SASI indexes are created one at a time - serially, waiting for full index to build before moving on to the next?&lt;br/&gt;
3. Do you need a 32G heap to build just one index? I cringe when I see a heap larger than 14G. See if you can get a single SASI index build to work in 10-12G or less.&lt;/p&gt;</comment>
                            <comment id="15202084" author="xedin" created="Fri, 18 Mar 2016 20:24:11 +0000"  >&lt;p&gt;Ok, so it&apos;s going to be 1G * 9 per memtable and memtable itself is pretty big and I am assuming that all of the 9 columns there are only columns you have defined in the row, which means that a couple of flushed can potentially consume your while heap. You can try minimizing the memtable size to make it flush more frequently and let compaction deal with it, I&apos;m attaching the patch to make memtable flush segment sizes configurable (and default of 128 MB) (you can specify max_memtable_flush_memory_in_mb in index options if you want to make it even smaller).&lt;/p&gt;</comment>
                            <comment id="15202088" author="doanduyhai" created="Fri, 18 Mar 2016 20:29:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jkrupan&quot; class=&quot;user-hover&quot; rel=&quot;jkrupan&quot;&gt;jkrupan&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;1. Not that large, see below the Spark script to generate randomized data:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    import java.util.UUID
    import com.datastax.spark.connector._
    case class Resource(dsrId:UUID, relSeq:Long, seq:Long, dspReleaseCode:String,
                        commercialOfferCode:String, transferCode:String, mediaCode:String,
                        modelCode:String, unicWork:String,
                        title:String, status:String, contributorsName:List[String],
                        periodEndMonthInt:Int, dspCode:String, territoryCode:String,
                        payingNetQty:Long, authorizedSocietiesTxt: String, relType:String)

    val allDsps = List(&quot;youtube&quot;, &quot;itunes&quot;, &quot;spotify&quot;, &quot;deezer&quot;, &quot;vevo&quot;, &quot;google-play&quot;, &quot;7digital&quot;, &quot;spotify&quot;, &quot;youtube&quot;, &quot;spotify&quot;, &quot;youtube&quot;, &quot;youtube&quot;, &quot;youtube&quot;)
    val allCountries = List(&quot;FR&quot;, &quot;UK&quot;, &quot;BE&quot;, &quot;IT&quot;, &quot;NL&quot;, &quot;ES&quot;, &quot;FR&quot;, &quot;FR&quot;)
    val allPeriodsEndMonths:Seq[Int] = for(year &amp;lt;- 2013 to 2015; month &amp;lt;- 1 to 12) yield (year.toString + f&quot;$month%02d&quot;).toInt
    val allModelCodes = List(&quot;PayAsYouGo&quot;, &quot;AdFunded&quot;, &quot;Subscription&quot;)
    val allMediaCodes = List(&quot;Music&quot;,&quot;Ringtone&quot;)
    val allTransferCodes = List(&quot;Streaming&quot;,&quot;Download&quot;)
    val allCommercialOffers = List(&quot;Premium&quot;,&quot;Free&quot;)
    val status = &quot;Declared&quot;
    val authorizedSocietiesTxt: String=&quot;sacem sgae&quot;
    val relType = &quot;whatever&quot;
    val titlesAndContributors: Array[(String, String)] = sc.textFile(&quot;/tmp/top_100.csv&quot;).map(line =&amp;gt; {val split = line.split(&quot;;&quot;); (split(1),split(2))}).distinct.collect

    for(i&amp;lt;- 1 to 100) {
        sc.parallelize((1 to 40000000).map(i =&amp;gt; UUID.randomUUID)).
          map(dsrId =&amp;gt; {
            val r = new java.util.Random(System.currentTimeMillis())

            val relSeq = r.nextLong()
            val seq = r.nextLong()
            val dspReleaseCode = seq.toString
            val dspCode = allDsps(r.nextInt(allDsps.size))
            val periodEndMonth = allPeriodsEndMonths(r.nextInt(allPeriodsEndMonths.size))
            val territoryCode = allCountries(r.nextInt(allCountries.size))
            val modelCode = allModelCodes(r.nextInt(allModelCodes.size))
            val mediaCode = allMediaCodes(r.nextInt(allMediaCodes.size))
            val transferCode = allTransferCodes(r.nextInt(allTransferCodes.size))
            val commercialOffer = allCommercialOffers(r.nextInt(allCommercialOffers.size))
            val titleAndContributor: (String, String) = titlesAndContributors(r.nextInt(titlesAndContributors.size))
            val title = titleAndContributor._1
            val contributorsName = titleAndContributor._2.split(&quot;,&quot;).toList
            val unicWork = title + &quot;|&quot; + titleAndContributor._2
            val payingNetQty = r.nextInt(100).toLong
            Resource(dsrId, relSeq, seq, dspReleaseCode, commercialOffer, transferCode, mediaCode, modelCode,
              unicWork, title, status, contributorsName, periodEndMonth, dspCode, territoryCode, payingNetQty,
              authorizedSocietiesTxt, relType)

          }).
          saveToCassandra(&quot;keyspace&quot;, &quot;resource&quot;)

        Thread.sleep(500)
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The indices&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;CREATE CUSTOM INDEX resource_territory_code_idx ON sharon.resource_bench (territory_code) USING &apos;org.apache.cassandra.index.sasi.SASIIndex&apos; WITH OPTIONS = {&apos;analyzer_class&apos;: &apos;org.apache.cassandra.index.sasi.analyzer.NonTokenizingAnalyzer&apos;, &apos;case_sensitive&apos;: &apos;false&apos;};

CREATE CUSTOM INDEX resource_dsp_code_idx ON sharon.resource_bench (dsp_code) USING &apos;org.apache.cassandra.index.sasi.SASIIndex&apos; WITH OPTIONS = {&apos;analyzer_class&apos;: &apos;org.apache.cassandra.index.sasi.analyzer.NonTokenizingAnalyzer&apos;, &apos;case_sensitive&apos;: &apos;false&apos;};

CREATE CUSTOM INDEX resource_commercial_offer_code_idx ON sharon.resource_bench (commercial_offer_code) USING &apos;org.apache.cassandra.index.sasi.SASIIndex&apos; WITH OPTIONS = {&apos;analyzer_class&apos;: &apos;org.apache.cassandra.index.sasi.analyzer.NonTokenizingAnalyzer&apos;, &apos;case_sensitive&apos;: &apos;false&apos;};

CREATE CUSTOM INDEX resource_authorized_societies_txt_idx ON sharon.resource_bench (authorized_societies_txt) USING &apos;org.apache.cassandra.index.sasi.SASIIndex&apos; WITH OPTIONS = {&apos;analyzer_class&apos;: &apos;org.apache.cassandra.index.sasi.analyzer.StandardAnalyzer&apos;, &apos;tokenization_normalize_lowercase&apos;: &apos;true&apos;, &apos;mode&apos;: &apos;PREFIX&apos;, &apos;analyzed&apos;: &apos;true&apos;, &apos;tokenization_enable_stemming&apos;: &apos;true&apos;};

CREATE CUSTOM INDEX resource_transfer_code_idx ON sharon.resource_bench (transfer_code) USING &apos;org.apache.cassandra.index.sasi.SASIIndex&apos; WITH OPTIONS = {&apos;analyzer_class&apos;: &apos;org.apache.cassandra.index.sasi.analyzer.NonTokenizingAnalyzer&apos;, &apos;case_sensitive&apos;: &apos;false&apos;};

CREATE CUSTOM INDEX resource_rel_type_idx ON sharon.resource_bench (rel_type) USING &apos;org.apache.cassandra.index.sasi.SASIIndex&apos; WITH OPTIONS = {&apos;analyzer_class&apos;: &apos;org.apache.cassandra.index.sasi.analyzer.NonTokenizingAnalyzer&apos;, &apos;case_sensitive&apos;: &apos;false&apos;};

CREATE CUSTOM INDEX resource_period_end_month_int_idx ON sharon.resource_bench (period_end_month_int) USING &apos;org.apache.cassandra.index.sasi.SASIIndex&apos; WITH OPTIONS = {&apos;mode&apos;: &apos;SPARSE&apos;};

CREATE CUSTOM INDEX resource_media_code_idx ON sharon.resource_bench (media_code) USING &apos;org.apache.cassandra.index.sasi.SASIIndex&apos; WITH OPTIONS = {&apos;analyzer_class&apos;: &apos;org.apache.cassandra.index.sasi.analyzer.NonTokenizingAnalyzer&apos;, &apos;case_sensitive&apos;: &apos;false&apos;};

CREATE CUSTOM INDEX resource_model_code_idx ON sharon.resource_bench (model_code) USING &apos;org.apache.cassandra.index.sasi.SASIIndex&apos; WITH OPTIONS = {&apos;analyzer_class&apos;: &apos;org.apache.cassandra.index.sasi.analyzer.NonTokenizingAnalyzer&apos;, &apos;case_sensitive&apos;: &apos;false&apos;};
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2. Does OOM occur if SASI indexes are created one at a time - serially, waiting for full index to build before moving on to the next?  --&amp;gt; &lt;b&gt;Yes it does&lt;/b&gt;, see log file with CMS settings attached above&lt;/p&gt;

&lt;p&gt;3. Do you need a 32G heap to build just one index? I cringe when I see a heap larger than 14G. See if you can get a single SASI index build to work in 10-12G or less.&lt;/p&gt;

&lt;p&gt; --&amp;gt; Well the 32Gb heap was for analytics use-cases and I was using G1 GC. But changing to CMS with 8Gb heap has the same result, OOM. see log file with CMS settings attached above&lt;/p&gt;</comment>
                            <comment id="15202094" author="doanduyhai" created="Fri, 18 Mar 2016 20:32:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; I dropped all the indices and recreated them one by one but with no avail, it eventually OOM after a while, see the second log file attached with CMS settings. The node was building only 1 index&lt;/p&gt;</comment>
                            <comment id="15202101" author="doanduyhai" created="Fri, 18 Mar 2016 20:35:23 +0000"  >&lt;p&gt;By the way, I can use the hardware for the whole weekend so if your guys have ideas to test (drop index, re-create with different index settings or C* settings) just tell me&lt;/p&gt;</comment>
                            <comment id="15202117" author="xedin" created="Fri, 18 Mar 2016 20:43:18 +0000"  >&lt;p&gt;It would be very helpful if you could share the sstables from a single machine through AWS or something so I can load them locally and try everything. &lt;/p&gt;</comment>
                            <comment id="15202134" author="xedin" created="Fri, 18 Mar 2016 20:46:49 +0000"  >&lt;p&gt;Btw, how big is ma-1831-big-SI sstable itself and how big are the index components it flushed? It&apos;s pretty weird to see 82 segments flushed.&lt;/p&gt;</comment>
                            <comment id="15202141" author="jkrupan" created="Fri, 18 Mar 2016 20:51:14 +0000"  >&lt;blockquote&gt;&lt;p&gt;recreated them one by one but with no avail, it eventually OOM after a while&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But are you waiting for each to finish its build before proceeding to the next? I mean, can even one index alone complete a build?&lt;/p&gt;

&lt;p&gt;Or, can you create the first 2 or 3 and let them run in parallel to completion before proceeding to the next. Maybe there is some practical limit to how many indexes you can build in parallel before the rate of garbage generation exceeds the rate of GC with all of this going on in parallel.&lt;/p&gt;</comment>
                            <comment id="15202156" author="doanduyhai" created="Fri, 18 Mar 2016 20:57:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; I can&apos;t promis anything but I&apos;m going to find a way to share data. We&apos;re talking of 100Gb to upload ...&lt;br/&gt;
Below is the ma-1831 standard files:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;root@ns3033877:~# ll /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-* | grep -v &quot;SI&quot;
-rw-r--r-- 1 cassandra cassandra     4081363 Mar 17 21:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-CompressionInfo.db
-rw-r--r-- 1 cassandra cassandra 16350922629 Mar 17 21:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-Data.db
-rw-r--r-- 1 cassandra cassandra          10 Mar 17 21:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-Digest.crc32
-rw-r--r-- 1 cassandra cassandra   150496120 Mar 17 21:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-Filter.db
-rw-r--r-- 1 cassandra cassandra  4678909890 Mar 17 21:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-Index.db
-rw-r--r-- 1 cassandra cassandra       12601 Mar 17 21:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-Statistics.db
-rw-r--r-- 1 cassandra cassandra    40410476 Mar 17 21:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-Summary.db
-rw-r--r-- 1 cassandra cassandra          92 Mar 17 21:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-TOC.txt
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And the SASI indices:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;-rw-r--r-- 1 cassandra cassandra       97 Mar 18 20:57 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:20 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_0
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:20 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_1
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:25 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_10
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:26 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_11
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:26 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_12
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:26 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_13
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:27 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_14
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:27 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_15
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:27 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_16
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:28 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_17
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:28 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_18
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:29 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_19
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:21 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_2
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:29 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_20
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:30 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_21
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:30 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_22
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:31 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_23
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:31 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_24
-rw-r--r-- 1 cassandra cassandra 24813592 Mar 18 20:31 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_25
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:32 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_26
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:32 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_27
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:32 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_28
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:33 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_29
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:21 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_3
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:33 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_30
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:34 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_31
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:34 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_32
-rw-r--r-- 1 cassandra cassandra 24813592 Mar 18 20:35 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_33
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:35 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_34
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:36 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_35
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:36 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_36
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:37 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_37
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:37 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_38
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:37 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_39
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:22 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_4
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:38 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_40
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:39 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_41
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:39 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_42
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_43
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_44
-rw-r--r-- 1 cassandra cassandra 24829976 Mar 18 20:41 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_45
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:41 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_46
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:42 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_47
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:42 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_48
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:43 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_49
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:23 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_5
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:43 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_50
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:44 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_51
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:44 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_52
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:45 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_53
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:45 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_54
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:45 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_55
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:46 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_56
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:47 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_57
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:47 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_58
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:47 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_59
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:23 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_6
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:48 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_60
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:48 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_61
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:49 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_62
-rw-r--r-- 1 cassandra cassandra 24813592 Mar 18 20:49 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_63
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:50 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_64
-rw-r--r-- 1 cassandra cassandra 24813592 Mar 18 20:50 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_65
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:51 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_66
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:51 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_67
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:51 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_68
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:52 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_69
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:24 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_7
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:52 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_70
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:53 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_71
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:53 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_72
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:54 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_73
-rw-r--r-- 1 cassandra cassandra 24813592 Mar 18 20:54 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_74
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:55 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_75
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:55 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_76
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:55 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_77
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:56 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_78
-rw-r--r-- 1 cassandra cassandra 24825880 Mar 18 20:56 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_79
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:25 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_8
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:57 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_80
-rw-r--r-- 1 cassandra cassandra 24821784 Mar 18 20:57 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_81
-rw-r--r-- 1 cassandra cassandra 14512152 Mar 18 20:57 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_82
-rw-r--r-- 1 cassandra cassandra 24817688 Mar 18 20:25 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_dsp_code_idx.db_9
-rw-r--r-- 1 cassandra cassandra       90 Mar 18 14:14 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db
-rw-r--r-- 1 cassandra cassandra 49766436 Mar 18 14:37 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_0
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:37 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_1
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 13:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_10
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 13:40 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_11
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 13:41 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_12
-rw-r--r-- 1 cassandra cassandra 49745956 Mar 18 13:41 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_13
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 13:42 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_14
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 13:42 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_15
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 13:43 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_16
-rw-r--r-- 1 cassandra cassandra 49745956 Mar 18 13:43 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_17
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 13:44 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_18
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 13:44 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_19
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:38 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_2
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 13:45 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_20
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 13:45 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_21
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 13:46 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_22
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 13:46 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_23
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 13:47 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_24
-rw-r--r-- 1 cassandra cassandra 49745956 Mar 18 13:47 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_25
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 13:48 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_26
-rw-r--r-- 1 cassandra cassandra 49766436 Mar 18 13:49 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_27
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 13:49 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_28
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 13:50 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_29
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 13:36 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_3
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 13:51 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_30
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 13:51 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_31
-rw-r--r-- 1 cassandra cassandra 49745956 Mar 18 13:51 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_32
-rw-r--r-- 1 cassandra cassandra 49770532 Mar 18 13:52 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_33
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 13:53 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_34
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 13:54 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_35
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 13:54 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_36
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 13:55 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_37
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 13:55 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_38
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 13:56 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_39
-rw-r--r-- 1 cassandra cassandra 49745956 Mar 18 13:37 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_4
-rw-r--r-- 1 cassandra cassandra 49745956 Mar 18 13:57 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_40
-rw-r--r-- 1 cassandra cassandra 49770532 Mar 18 13:57 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_41
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 13:58 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_42
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 13:58 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_43
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 13:59 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_44
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 13:59 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_45
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 14:00 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_46
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 14:00 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_47
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:01 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_48
-rw-r--r-- 1 cassandra cassandra 49745956 Mar 18 14:01 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_49
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 13:38 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_5
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:02 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_50
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:02 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_51
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 14:03 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_52
-rw-r--r-- 1 cassandra cassandra 49741860 Mar 18 14:04 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_53
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:04 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_54
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 14:04 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_55
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 14:05 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_56
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 14:05 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_57
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 14:06 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_58
-rw-r--r-- 1 cassandra cassandra 49741860 Mar 18 14:06 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_59
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 13:38 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_6
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 14:07 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_60
-rw-r--r-- 1 cassandra cassandra 49770532 Mar 18 14:07 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_61
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:07 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_62
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:08 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_63
-rw-r--r-- 1 cassandra cassandra 49766436 Mar 18 14:08 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_64
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 14:08 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_65
-rw-r--r-- 1 cassandra cassandra 49766436 Mar 18 14:09 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_66
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 14:09 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_67
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 14:10 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_68
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 14:10 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_69
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 13:38 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_7
-rw-r--r-- 1 cassandra cassandra 49745956 Mar 18 14:10 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_70
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:11 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_71
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 14:11 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_72
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:11 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_73
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 14:12 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_74
-rw-r--r-- 1 cassandra cassandra 49758244 Mar 18 14:12 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_75
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:12 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_76
-rw-r--r-- 1 cassandra cassandra 49745956 Mar 18 14:13 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_77
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:13 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_78
-rw-r--r-- 1 cassandra cassandra 49745956 Mar 18 14:13 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_79
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 13:39 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_8
-rw-r--r-- 1 cassandra cassandra 49750052 Mar 18 14:14 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_80
-rw-r--r-- 1 cassandra cassandra 49754148 Mar 18 14:14 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_81
-rw-r--r-- 1 cassandra cassandra 29237284 Mar 18 14:14 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_82
-rw-r--r-- 1 cassandra cassandra 49762340 Mar 18 13:39 /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_9
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15202162" author="doanduyhai" created="Fri, 18 Mar 2016 21:01:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jkrupan&quot; class=&quot;user-hover&quot; rel=&quot;jkrupan&quot;&gt;jkrupan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&quot;I mean, can even one index alone complete a build?&quot; --&amp;gt; I&apos;m afraid that even one Index build will lead to OOM eventually because the table is big. I&apos;m going to DROP all indices and recreate just ONE and let it build the whole night to see if tomorrow morning it will OOM or not.&lt;/p&gt;

&lt;p&gt; I&apos;ll set &lt;b&gt;max_memtable_flush_memory_in_mb&lt;/b&gt; to something small like 128Mb as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt; recommended to see if it can helps C* finishing the index build&lt;/p&gt;</comment>
                            <comment id="15202196" author="jkrupan" created="Fri, 18 Mar 2016 21:33:06 +0000"  >&lt;p&gt;Just to make sure I understand what&apos;s going on...&lt;/p&gt;

&lt;p&gt;1. The first index is for the territory_code column, whose values are simple 2-character country codes from allCountries which has 8 entries, with &apos;FR&apos; repeated 3 times in that list of 8 country codes.&lt;br/&gt;
2. How many rows are generated per machine - is it 100 * 40,000,000 = 4 billion?&lt;br/&gt;
3. That means that the SASI index will have six unique index values, each with roughly 4 billion / 8 = 500 million rows, correct? (Actually, 5 of the 6 unique values will have 500 million rows and the 6th will have 1.5 billion rows (3 times 500 million.) Sounds like a great stress test for SASI!&lt;br/&gt;
4. That&apos;s just for the territory_code column.&lt;br/&gt;
5. Some of the columns have only 2 unique values, like commercial_offer_code. That would mean 2 billion rows for each indexed unique value. An even more excellent stress test for SASI!&lt;/p&gt;</comment>
                            <comment id="15202206" author="doanduyhai" created="Fri, 18 Mar 2016 21:40:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jkrupan&quot; class=&quot;user-hover&quot; rel=&quot;jkrupan&quot;&gt;jkrupan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;1. --&amp;gt; Yes correct&lt;br/&gt;
2. Originally we targeted 4 billions but we stop after 80 iterations (instead of 100) so it gave us something like 3.4 billions&lt;br/&gt;
3. Yes correct. But this territory_code is not meant to be used alone but in combination with the resource_period_end_month_int_idx index and others to cut down the number of rows to be fetched&lt;br/&gt;
4. and 5. Same answer as above&lt;/p&gt;

&lt;p&gt; Indeed, those indices are designed to support an user-search form to perform TopK aggregation with dynamic filtering.&lt;/p&gt;

&lt;p&gt; SASI is used for the filtering part and Spark for the TopK aggregation&lt;/p&gt;

&lt;p&gt; Indeed, the &lt;b&gt;resource_period_end_month&lt;/b&gt; filter is mandatory for the user and usually people put a month or a range of 1 year at most. This cuts down the whole dataset to a reasonable subset over which we apply other filters&lt;/p&gt;</comment>
                            <comment id="15202223" author="doanduyhai" created="Fri, 18 Mar 2016 21:47:31 +0000"  >&lt;p&gt;Ok&lt;/p&gt;

&lt;p&gt;1. drop all indices&lt;br/&gt;
2. clean all &lt;b&gt;idx&lt;/b&gt; files on all machines&lt;br/&gt;
3. &lt;tt&gt;CREATE CUSTOM INDEX resource_period_end_month_int_idx ON sharon.resource_bench (period_end_month_int) USING &apos;org.apache.cassandra.index.sasi.SASIIndex&apos; WITH OPTIONS = {&apos;mode&apos;: &apos;SPARSE&apos;, &apos;max_compaction_flush_memory_in_mb&apos;: &apos;128&apos;};&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;Now let it just run for the night and let&apos;s see tomorrow morning&lt;/p&gt;</comment>
                            <comment id="15202241" author="jkrupan" created="Fri, 18 Mar 2016 21:57:21 +0000"  >&lt;p&gt;What&apos;s the table schema? Is period_end_month_int text or int?&lt;/p&gt;

&lt;p&gt;period_end_month_int has 3 years times 12 months = 36 unique values, so 3.4 billion / 36 = 94.44 million rows for each indexed unique value.&lt;/p&gt;</comment>
                            <comment id="15202245" author="xedin" created="Fri, 18 Mar 2016 22:02:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; So it actually happens when existing sstable being indexed, it&apos;s size is 16G and segment sizes are about 30MB which looks totally fine to me, there might be a bug I introduced while porting SASI to 3.x. I don&apos;t actually need whole dataset in this case since it&apos;s OOM indexing a single sstable, can you please just share that one sstable instead which is just 16G data?&lt;/p&gt;</comment>
                            <comment id="15202259" author="doanduyhai" created="Fri, 18 Mar 2016 22:11:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;OK, I&apos;m trying to fetch the sstable with its data files&lt;/p&gt;

&lt;p&gt;In the meantime, I just re-create one index as shown above using &lt;b&gt;max_compaction_flush_memory_in_mb&lt;/b&gt; = 128 and SASI flushes thousands of index files (of ~16kb each) and eventually the server dies maybe because too many file handles&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;INFO  [SASI-General:1] 2016-03-18 22:45:37,480 PerSSTableIndexWriter.java:258 - Flushed index segment /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_130370, took 0 ms.
INFO  [SASI-General:1] 2016-03-18 22:45:37,581 PerSSTableIndexWriter.java:258 - Flushed index segment /home/cassandra/data/sharon/resource_bench-4d065db0ebbc11e5995bd129cfce5717/ma-1831-big-SI_resource_period_end_month_int_idx.db_130371, took 101 ms.
ERROR [SASI-General:1] 2016-03-18 22:45:37,582 CassandraDaemon.java:195 - Exception in thread Thread[SASI-General:1,5,main]
org.apache.cassandra.io.FSReadError: java.io.IOException: Map failed
       at org.apache.cassandra.io.util.ChannelProxy.map(ChannelProxy.java:156) ~[apache-cassandra-3.4.jar:3.4]
        at org.apache.cassandra.index.sasi.utils.MappedBuffer.&amp;lt;init&amp;gt;(MappedBuffer.java:78) ~[apache-cassandra-3.4.jar:3.4]
        at org.apache.cassandra.index.sasi.utils.MappedBuffer.&amp;lt;init&amp;gt;(MappedBuffer.java:57) ~[apache-cassandra-3.4.jar:3.4]
        at org.apache.cassandra.index.sasi.disk.OnDiskIndex.&amp;lt;init&amp;gt;(OnDiskIndex.java:142) ~[apache-cassandra-3.4.jar:3.4]
        at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter$Index.lambda$scheduleSegmentFlush$260(PerSSTableIndexWriter.java:253) ~[apache-cassandra-3.4.jar:3.4]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_74]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_74]
        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_74]
Caused by: java.io.IOException: Map failed
        at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:940) ~[na:1.8.0_74]
        at org.apache.cassandra.io.util.ChannelProxy.map(ChannelProxy.java:152) ~[apache-cassandra-3.4.jar:3.4]
        ... 8 common frames omitted
Caused by: java.lang.OutOfMemoryError: Map failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15202262" author="doanduyhai" created="Fri, 18 Mar 2016 22:12:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jkrupan&quot; class=&quot;user-hover&quot; rel=&quot;jkrupan&quot;&gt;jkrupan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; Below is the schema:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;create table if not exists sharon.resource_bench ( 
 dsr_id uuid,
 rel_seq bigint,
 seq bigint,
 dsp_code varchar,
 model_code varchar,
 media_code varchar,
 transfer_code varchar,
 commercial_offer_code varchar,
 territory_code varchar,
 period_end_month_int int,
 authorized_societies_txt text,
 rel_type text,
 status text,
 dsp_release_code text,
 title text,
 contributors_name list&amp;lt;text&amp;gt;,
 unic_work text,
 paying_net_qty bigint,
PRIMARY KEY ((dsr_id, rel_seq), seq)
) WITH CLUSTERING ORDER BY (seq ASC); 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15202281" author="xedin" created="Fri, 18 Mar 2016 22:30:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; Ok yeah, it looks like there are too many index components. I suspect that there is something wrong with index builder there because we have sstable files which are over 100G in size and have about 20 indexes attached to them without a problem, merging 24M sized segments should never be a problem, so it would be very helpful if you could share that ma-big-1831 sstable somehow so I can run couple of experiments and see where the things are.&lt;/p&gt;</comment>
                            <comment id="15202353" author="doanduyhai" created="Fri, 18 Mar 2016 23:20:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Upload is on the way, here is the Google Drive folder for the data + schema + C* config: &lt;a href=&quot;https://drive.google.com/folderview?id=0B6wR2aj4Cb6wdm03TFZtcXllX2M&amp;amp;usp=sharing&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://drive.google.com/folderview?id=0B6wR2aj4Cb6wdm03TFZtcXllX2M&amp;amp;usp=sharing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; The big &lt;b&gt;Data&lt;/b&gt; file (23Gb) is being uploaded, it will be available in &#8776; 45mins. I hope you have fiber optic to download it ...&lt;/p&gt;</comment>
                            <comment id="15202377" author="xedin" created="Fri, 18 Mar 2016 23:46:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; Thanks! I&apos;ve already started downloading everything. Meanwhile what you can also try is to switch to LCS with max sstable size of 1G or lower and try to re-create the data with all of the indexes defined. &lt;/p&gt;</comment>
                            <comment id="15202575" author="xedin" created="Sat, 19 Mar 2016 05:28:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; I&apos;ve successfully downloaded the sstable and was able to run re-index and it looks like everything is good until all of the segments are stitched together into actual index file, trying to figure out what is going with that.&lt;/p&gt;</comment>
                            <comment id="15202669" author="xedin" created="Sat, 19 Mar 2016 09:07:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; I&apos;ve figured out what is going on and first of all period_end_month_int index is not sparse - at least first term in that index has ~11M tokens assigned to it, that&apos;s where the source of the problem is - because it&apos;s sparse + composite combined TokenTreeBuilder has to pull a lot of stuff into memory when stitching segments together, I&apos;m trying to figure out if there is a way to make it less memory intensive.&lt;/p&gt;

&lt;p&gt;Temporary fix for this situation is switching to LCS with fixed maximum sstable size, as I mentioned in my previous comment.&lt;/p&gt;</comment>
                            <comment id="15202712" author="doanduyhai" created="Sat, 19 Mar 2016 10:44:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;ve figured out what is going on and first of all period_end_month_int index is not sparse - at least first term in that index has ~11M tokens assigned to it&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt; You&apos;re right, &lt;tt&gt;period_end_month_int&lt;/tt&gt; is not &lt;b&gt;parse&lt;/b&gt; in the sense we mean it in English but SASI index mode &lt;tt&gt;SPARSE&lt;/tt&gt; is the only one allowed for numeric fields, &lt;tt&gt;PREFIX&lt;/tt&gt; and &lt;tt&gt;CONTAINS&lt;/tt&gt; are reserved to text fields. So we have a fundamental issue here, how to index &lt;b&gt;dense&lt;/b&gt; numeric values ?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Temporary fix for this situation is switching to LCS with fixed maximum sstable size, as I mentioned in my previous comment.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt; Can you elaborate further ? What, in LCS, makes it work with current situation compared to STCS ? Is it the total number of SSTables ? (currently with STCS there less than 100 SSTables per node so it&apos;s not really a big issue) Is it the fact that a partition is guanrateed to be in a single SSTable with LCS ? (again considering the schema we have mostly tiny rows but a lot of them)&lt;/p&gt;

&lt;p&gt; For now I&apos;m going to switch to LCS to see if we can finish building the index without OOM. For long term,  LCS is not the solution because this table size will increase quickly over time and having tombstones in level &amp;gt; L3 will make them rarely compacted&lt;/p&gt;</comment>
                            <comment id="15202816" author="jkrupan" created="Sat, 19 Mar 2016 15:43:51 +0000"  >&lt;p&gt;The terminology is a bit confusing here - everybody understands what a sparse matrix is, but exactly what constitutes sparseness in a column is very unclear. What is clear is that  the cardinality (number of distinct values) is low for that int field. A naive person (okay... me) would have thought that sparse data meant few distinct values, which is what the int field is (36 distinct values.)&lt;/p&gt;

&lt;p&gt;I decided to check the doc to see what it says about SPARSE, but discovered that the doc doesn&apos;t exist yet in the main Cassandra doc - I sent a message to docs@datastax.com about that (turns out, they sync the doc to the DataStax Distribution of Cassandra (DDC) and DDC 3.4 is not out yet, coming soon.) So I went back to the orginal, pre-integration doc (&lt;a href=&quot;https://github.com/xedin/sasi&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/xedin/sasi&lt;/a&gt;) and see that there is separate, non-integrated doc for SASI in the Cassandra source tree - &lt;a href=&quot;https://github.com/apache/cassandra/blob/trunk/doc/SASI.md&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/cassandra/blob/trunk/doc/SASI.md&lt;/a&gt;, which makes clear that &quot;SPARSE, which is meant to improve performance of querying large, dense number ranges like timestamps for data inserted every millisecond.&quot; Oops... SPARSE=dense, but in any case SPARSE is designed for high cardinality of distinct values, which the int field is clearly not.&lt;/p&gt;

&lt;p&gt;I would argue that SASI should give a strongly-worded warning if the column data for a SPARSE index has low cardinality - low number of distinct column values and high number of index values per column value.&lt;/p&gt;</comment>
                            <comment id="15202851" author="doanduyhai" created="Sat, 19 Mar 2016 17:02:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jkrupan&quot; class=&quot;user-hover&quot; rel=&quot;jkrupan&quot;&gt;jkrupan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; Other than terminology and wording/documentation about &lt;tt&gt;SPARSE&lt;/tt&gt; mode, what interests me more is how SASI can deal with &lt;tt&gt;DENSE&lt;/tt&gt; index e.g. few indexed value for millions/billions of matching primary keys.&lt;/p&gt;

&lt;p&gt; The original secondary index was not adapted for &lt;/p&gt;

&lt;p&gt;1. very low cardinality (index on email to search for user for example) because it does not scale well with cluster size. In worst case you&apos;ll need to scan N/RF nodes to fetch 0 or at most 1 user so the ratio effort vs result is bad&lt;/p&gt;

&lt;p&gt;2. very high cardinality (user gender for example) because for each distinct indexed value, you can have many matching users and it creates ultra wide-rows, an anti-pattern&lt;/p&gt;

&lt;p&gt; With SASI, although point 1. still holds (that&apos;s the common issue with all *&lt;b&gt;distributed&lt;/b&gt;* index systems, even Solr or ES) I had hoped that limitation 2. will be lifted since SASI stores data in its own structures&lt;/p&gt;

&lt;p&gt; One can argue that having an index on &lt;tt&gt;DENSE&lt;/tt&gt; fields like country code (only 7-8 distinct values for the whole dataset) is a bad idea but they are meant to be used in conjunction with other indices to cut down the matching dataset and I rely on SASI query planner for this job&lt;/p&gt;</comment>
                            <comment id="15202876" author="jkrupan" created="Sat, 19 Mar 2016 17:35:57 +0000"  >&lt;p&gt;The int field could easily be made a text field if that would make SASI work better (you can even do prefix query by year then.)&lt;/p&gt;

&lt;p&gt;Point 1 is precisely what SASI SPARSE is designed for. It also is what Materialized Views (formerly Global Indexes) is for and MV is even better for since it eliminates the need to scan multiple nodes since the rows get collected based on the new partition key that can include the indexed data value.&lt;/p&gt;

&lt;p&gt;You&apos;re using cardinality backwards - it is supposed to be a measure of the number of distinct values in a column, not the number of rows containing each value. See: &lt;a href=&quot;https://en.wikipedia.org/wiki/Cardinality_%28SQL_statements%29&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://en.wikipedia.org/wiki/Cardinality_%28SQL_statements%29&lt;/a&gt;. Granted, in ERD cardinality is the count of rows in a second table for each column value in a given table (one to n, n to one, etc.), but in the context of an index there is only one table involved, although you could consider the index to be a table, but that would be a little odd. In any case, best to stick with the standard SQL meaning of the cardinality of data values in a column. So, to be clear, an email address is high cardinality and gender is low cardinality. And the end of month int field is low cardinality or not dense in the original SASI doc terminology.&lt;/p&gt;</comment>
                            <comment id="15202877" author="jkrupan" created="Sat, 19 Mar 2016 17:37:33 +0000"  >&lt;p&gt;Sorry for any extra noise I may have generated here - &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt; has the info he needs without me.&lt;/p&gt;</comment>
                            <comment id="15202934" author="xedin" created="Sat, 19 Mar 2016 19:41:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; Let me first elaborate what I mean by &quot;it&apos;s not sparse&quot; - SPARSE meant to be used when there are a lot index &lt;b&gt;values&lt;/b&gt; and each of the values has &lt;b&gt;less than 5 keys&lt;/b&gt; so it&apos;s *SPARSE*ly found in the index. SPARSE have to do more with keys/tokens than values, that&apos;s why example uses &quot;created_at&quot; since that would have a lot of values and each of the values would, most likely, only have a single token/key attached to it. We actually detect this situation and actual index is going to be constructed correctly even if SPARSE mode was set on not sparse column.&lt;/p&gt;

&lt;p&gt;Regarding LCS - it&apos;s LeveledCompactionStrategy where you can set maximum sstable size, I would suggest you make it something like 1G or less because stitching and OOM you see is directly related to the size of sstable file. &lt;/p&gt;

&lt;p&gt;Meanwhile I working on the fix for current situation.&lt;/p&gt;</comment>
                            <comment id="15202951" author="doanduyhai" created="Sat, 19 Mar 2016 20:40:16 +0000"  >&lt;p&gt;Ok it&apos;s clear now thanks for the clarification &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15203172" author="doanduyhai" created="Sun, 20 Mar 2016 08:56:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Last update from the testing. I put the cluster in &lt;b&gt;ideal&lt;/b&gt; conditions as you recommended.&lt;/p&gt;

&lt;p&gt;JVM settings:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;CMS&lt;/li&gt;
	&lt;li&gt;Xmx8g, Xms8G&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;C* settings:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;concurrent_compactors: 6&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Test conditions:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;cluster &lt;b&gt;idle&lt;/b&gt; (no write, no read)&lt;/li&gt;
	&lt;li&gt;LCS with &lt;b&gt;sstable_size_in_mb&lt;/b&gt; = 1024 (1Gb)&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;no compaction ongoing&lt;/b&gt; (took a whole night to compact for LCS)&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;CREATE CUSTOM INDEX resource_period_end_month_int_idx ON sharon.resource_bench (period_end_month_int) USING &apos;org.apache.cassandra.index.sasi.SASIIndex&apos; WITH OPTIONS = {&apos;mode&apos;: &apos;SPARSE&apos;};&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Observations:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I/O idle, CPU not exceeding 20% on average (&lt;a href=&quot;http://postimg.org/image/f664wm8dp/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://postimg.org/image/f664wm8dp/&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;nodetool compactionstats&lt;/tt&gt; only show 1 index rebuild ongoing per node
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;id                                   compaction type       keyspace table          completed  total       unit  progress
d8b4f4b0-ee6a-11e5-81f5-bd5584064785 Secondary index build sharon   resource_bench 9535985318 18920482745 bytes 50.40%
id                                   compaction type       keyspace table          completed  total       unit  progress
d8b65440-ee6a-11e5-b44b-4deeb5ac98a3 Secondary index build sharon   resource_bench 9464081317 20988668046 bytes 45.09%
id                                   compaction type       keyspace table          completed  total       unit  progress
d8b3bc30-ee6a-11e5-a152-db40f4fbe6b8 Secondary index build sharon   resource_bench 9471325678 17061191471 bytes 55.51%
id                                   compaction type       keyspace table          completed  total       unit  progress
d8b45870-ee6a-11e5-b26b-53ed13e9667e Secondary index build sharon   resource_bench 9120598050 18921737677 bytes 48.20%
id                                   compaction type       keyspace table          completed  total       unit  progress
d8b45870-ee6a-11e5-b2a3-331c04173c53 Secondary index build sharon   resource_bench 8943568835 20591008789 bytes 43.43%
id                                   compaction type       keyspace table          completed   total       unit  progress
d8b47f80-ee6a-11e5-9fc8-0597212274c1 Secondary index build sharon   resource_bench 10172038156 21422242706 bytes 47.48%
id                                   compaction type       keyspace table          completed   total       unit  progress
d8b34700-ee6a-11e5-a642-6dee841e75e5 Secondary index build sharon   resource_bench 10161205385 18730171060 bytes 54.25%
id                                   compaction type       keyspace table          completed  total       unit  progress
d8b6f080-ee6a-11e5-8da4-bd70732fdab1 Secondary index build sharon   resource_bench 9961529350 21294352899 bytes 46.78%
id                                   compaction type       keyspace table          completed  total       unit  progress
d8b43160-ee6a-11e5-8ac9-f59d626eedfa Secondary index build sharon   resource_bench 9160286080 22153527929 bytes 41.35%
id                                   compaction type       keyspace table          completed  total       unit  progress
d8b51bc0-ee6a-11e5-8aa0-b9e611280aba Secondary index build sharon   resource_bench 9397690505 22791700212 bytes 41.23%
id                                   compaction type       keyspace table          completed   total       unit  progress
d8b542d0-ee6a-11e5-8521-fbd14b018db6 Secondary index build sharon   resource_bench 10029096174 18910334578 bytes 53.04%
id                                   compaction type       keyspace table          completed   total       unit  progress
d8b40a50-ee6a-11e5-a7b2-4b114ced0935 Secondary index build sharon   resource_bench 10118551269 16938426769 bytes 59.74%
id                                   compaction type       keyspace table          completed  total       unit  progress
d8b039c0-ee6a-11e5-9a98-ff9a6f2af762 Secondary index build sharon   resource_bench 9003236945 18252472495 bytes 49.33%
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;there are still A LOT of GC&lt;/b&gt; (with some ConcurrentMarkSweep lasting up to 10 secs!)
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;INFO  [Service Thread] 2016-03-20 09:46:44,695 GCInspector.java:284 - ParNew GC in 455ms.  CMS Old Gen: 2964960608 -&amp;gt; 3487392640; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:46:47,250 GCInspector.java:284 - ParNew GC in 460ms.  CMS Old Gen: 3487392640 -&amp;gt; 3990379824; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125829120 -&amp;gt; 125828160
INFO  [Service Thread] 2016-03-20 09:46:49,452 GCInspector.java:284 - ParNew GC in 414ms.  CMS Old Gen: 3990379824 -&amp;gt; 4445691424; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125828160 -&amp;gt; 125827840
INFO  [Service Thread] 2016-03-20 09:46:52,328 GCInspector.java:284 - ParNew GC in 484ms.  CMS Old Gen: 4445691424 -&amp;gt; 4968532112; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125827840 -&amp;gt; 125827440
INFO  [Service Thread] 2016-03-20 09:46:54,940 GCInspector.java:284 - ParNew GC in 495ms.  CMS Old Gen: 4968532112 -&amp;gt; 5462199544; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125827440 -&amp;gt; 125829120
INFO  [Service Thread] 2016-03-20 09:46:57,406 GCInspector.java:284 - ParNew GC in 463ms.  CMS Old Gen: 5462199544 -&amp;gt; 5924296504; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125829120 -&amp;gt; 125828160
INFO  [Service Thread] 2016-03-20 09:47:12,521 GCInspector.java:284 - ParNew GC in 670ms.  CMS Old Gen: 5924296504 -&amp;gt; 5985242088; Par Survivor Space: 125828160 -&amp;gt; 125827760
WARN  [Service Thread] 2016-03-20 09:47:12,528 GCInspector.java:282 - ConcurrentMarkSweep GC in 11108ms.  CMS Old Gen: 5985242088 -&amp;gt; 4121205176; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125827760 -&amp;gt; 0
INFO  [Service Thread] 2016-03-20 09:47:41,050 GCInspector.java:284 - ParNew GC in 209ms.  CMS Old Gen: 4748643432 -&amp;gt; 4955516288; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:49:29,246 GCInspector.java:284 - ParNew GC in 206ms.  CMS Old Gen: 3790280880 -&amp;gt; 3996984480; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:49:39,634 GCInspector.java:284 - ParNew GC in 272ms.  CMS Old Gen: 4361111240 -&amp;gt; 4620112304; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 45286592 -&amp;gt; 125829120
INFO  [Service Thread] 2016-03-20 09:49:41,290 GCInspector.java:284 - ParNew GC in 289ms.  CMS Old Gen: 4620112304 -&amp;gt; 4937794000; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:49:43,160 GCInspector.java:284 - ParNew GC in 383ms.  CMS Old Gen: 4937794000 -&amp;gt; 5426684640; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:49:45,309 GCInspector.java:284 - ParNew GC in 431ms.  CMS Old Gen: 5426684640 -&amp;gt; 5947461904; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:49:47,370 GCInspector.java:284 - ParNew GC in 402ms.  CMS Old Gen: 5947461904 -&amp;gt; 6398462800; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:49:49,857 GCInspector.java:284 - ParNew GC in 423ms.  CMS Old Gen: 5444204224 -&amp;gt; 5937269640; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:49:52,407 GCInspector.java:284 - ParNew GC in 455ms.  CMS Old Gen: 3157064816 -&amp;gt; 3668162472; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:49:54,572 GCInspector.java:284 - ParNew GC in 400ms.  CMS Old Gen: 2840515104 -&amp;gt; 3287142872; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:49:57,162 GCInspector.java:284 - ParNew GC in 465ms.  CMS Old Gen: 3287142872 -&amp;gt; 3792393832; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:49:59,862 GCInspector.java:284 - ParNew GC in 470ms.  CMS Old Gen: 3792393832 -&amp;gt; 4304257848; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125829120 -&amp;gt; 125828240
INFO  [Service Thread] 2016-03-20 09:50:02,071 GCInspector.java:284 - ParNew GC in 418ms.  CMS Old Gen: 4304257848 -&amp;gt; 4743542344; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125828240 -&amp;gt; 125828000
INFO  [Service Thread] 2016-03-20 09:50:04,859 GCInspector.java:284 - ParNew GC in 502ms.  CMS Old Gen: 4743542344 -&amp;gt; 5263286088; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125828000 -&amp;gt; 125827760
INFO  [Service Thread] 2016-03-20 09:50:07,747 GCInspector.java:284 - ParNew GC in 492ms.  CMS Old Gen: 5263286088 -&amp;gt; 5773111032; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125827760 -&amp;gt; 125827520
INFO  [Service Thread] 2016-03-20 09:50:10,679 GCInspector.java:284 - ParNew GC in 383ms.  CMS Old Gen: 5773111032 -&amp;gt; 6032633936; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125827520 -&amp;gt; 125827280
INFO  [Service Thread] 2016-03-20 09:50:14,371 GCInspector.java:284 - ParNew GC in 212ms.  CMS Old Gen: 5728973400 -&amp;gt; 5854698504; Par Eden Space: 1006632960 -&amp;gt; 0; Par Survivor Space: 125827280 -&amp;gt; 125826960
INFO  [Service Thread] 2016-03-20 09:50:38,495 GCInspector.java:284 - ParNew GC in 205ms.  CMS Old Gen: 5019081080 -&amp;gt; 5235117656; Par Eden Space: 1006632960 -&amp;gt; 0;
INFO  [Service Thread] 2016-03-20 09:51:05,133 GCInspector.java:284 - ParNew GC in 206ms.  CMS Old Gen: 947772192 -&amp;gt; 1118731384; Par Eden Space: 1006632960 -&amp;gt; 0;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The GC activity is quite worrisome because if the cluster was not IDLE and have active reads/writes/compactions, I would bet that such GC will bring it down completely ...&lt;/p&gt;

&lt;p&gt;Do you think memory management for index build is going to be fixed along side with current OOM issue or do you want me to open a separate JIRA ticket to address the issue ?&lt;/p&gt;

&lt;p&gt; I can upload all the necessary logs (system.log, gc.log). I took care to clean all the logs right &lt;b&gt;before&lt;/b&gt; starting the index creation so that we can have a clear view and log messages for this process&lt;/p&gt;</comment>
                            <comment id="15203216" author="xedin" created="Sun, 20 Mar 2016 10:10:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; Yes I think I will be able to at least minimize memory requirement for the stitching stage that should be able to solve most of it and once again - &quot;period_end_month_int&quot; is &lt;b&gt;not&lt;/b&gt; a SPARSE index and numerical indexes are not required to be always marked as SPARSE only in cases where each (or most) of the keys have unique value for such columns e.g. timestamp where each key is going to have milli-/micro-second value which is almost guaranteed to be unique for every given row.&lt;/p&gt;</comment>
                            <comment id="15203226" author="xedin" created="Sun, 20 Mar 2016 10:21:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; It looks like to me that currently SPARSE creates more confusion than good, I&apos;m going to remove that mode as part of this patch and will look into maybe having different index type for columns like timestamp if that proves to be a problem for people.&lt;/p&gt;</comment>
                            <comment id="15203241" author="doanduyhai" created="Sun, 20 Mar 2016 10:59:17 +0000"  >&lt;p&gt;Attached are the logs (&lt;b&gt;SASI_Index_build_LCS_1G_Max_SSTable_Size_logs.tar.gz&lt;/b&gt;)  of an idle cluster just building the &lt;tt&gt;periode_end_month&lt;/tt&gt; index with a lot of GC&lt;/p&gt;</comment>
                            <comment id="15203243" author="doanduyhai" created="Sun, 20 Mar 2016 11:07:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;and numerical indexes are not required to be always marked as SPARSE&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt; I missed this. I thought that mode &lt;tt&gt;PREFIX&lt;/tt&gt; is only reserved to &lt;tt&gt;text&lt;/tt&gt; types&lt;/p&gt;
</comment>
                            <comment id="15204144" author="doanduyhai" created="Mon, 21 Mar 2016 13:03:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; Ok last update from testing:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;LCS 1Gb max_sstable_size&lt;/li&gt;
	&lt;li&gt;only PREFIX index modes&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; The cluster is running fine with index build. I can even build multiple indices at the same time&lt;/p&gt;

&lt;p&gt; If you decide to remove &lt;tt&gt;SPARSE&lt;/tt&gt; mode, how will SASI deal with real &lt;b&gt;sparse&lt;/b&gt; numerical values (like the index for  &lt;tt&gt;created_at&lt;/tt&gt; in the example ?) Or does SASI auto-detect sparse-ness and adapt its data structure ?&lt;/p&gt;</comment>
                            <comment id="15204881" author="xedin" created="Mon, 21 Mar 2016 18:48:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; We are currently working on fixing the stitching step memory footprint, it kind of looks like we probably not going to remove SPARSE but rather we are just going to fail index build if SPARSE is set but it&apos;s requirements are not met, so operators will be able to manually change the schema and trigger index rebuild. Also it&apos;s not necessary to explicitly set mode at all, it will be PREFIX by default which works fine for both text and numeric fields.&lt;/p&gt;</comment>
                            <comment id="15204917" author="doanduyhai" created="Mon, 21 Mar 2016 19:11:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;we probably not going to remove SPARSE but rather we are just going to fail index build if SPARSE is set but it&apos;s requirements are not met, so operators will be able to manually change the schema and trigger index rebuild&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt; I prefer this alternative. I believe there is a real need for &lt;tt&gt;SPARSE&lt;/tt&gt; indices. &lt;/p&gt;</comment>
                            <comment id="15209928" author="xedin" created="Thu, 24 Mar 2016 07:54:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; As an update, all of the changes are &lt;a href=&quot;https://github.com/xedin/cassandra/tree/CASSANDRA-11383&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;complete against 3.5 branch&lt;/a&gt; and testall/dtest are currently running. Patchset consists of changes to SPARSE mode to fail if it detects that it&apos;s property is not satisfied (a single term is attached to more than N keys). TokenTreeBuilder has been split into Dynamic and Static, the latter is used in the index segment stitching phase which makes it O( 1 ) memory overhead because building a TokenTree is streaming instead of pre-caching as before.&lt;/p&gt;

&lt;p&gt;We have tested everything against the 26GB file I got from you but you are also welcome to try the code out before I merge everything.&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;branch&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;testall&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;dtest&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;https://github.com/xedin/cassandra/tree/CASSANDRA-11383&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;CASSANDRA-11383&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/job/xedin-CASSANDRA-11383-testall/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;testall&lt;/a&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;a href=&quot;http://cassci.datastax.com/job/xedin-CASSANDRA-11383-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dtest&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
</comment>
                            <comment id="15210365" author="doanduyhai" created="Thu, 24 Mar 2016 15:11:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt; Sure thing. I will test the patch this weekend:&lt;/p&gt;

&lt;p&gt;1. build a huge SSTable (with manual STCS compaction) and then create the index&lt;br/&gt;
2. create the index first, fill in data and then trigger manual STCS compaction&lt;/p&gt;
</comment>
                            <comment id="15213089" author="doanduyhai" created="Sat, 26 Mar 2016 16:18:21 +0000"  >&lt;p&gt;Ok first batch of test results:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Test case 1&lt;/b&gt;: 2 SSTables of 32Gb each,  &lt;tt&gt;DENSE&lt;/tt&gt; numeric index build took 3h without OOM, regular and stable G1 Young GC&lt;/p&gt;</comment>
                            <comment id="15213154" author="doanduyhai" created="Sat, 26 Mar 2016 18:51:14 +0000"  >&lt;p&gt;Second test result:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Test case 2&lt;/b&gt; : 2 SSTables of 32Gb each, &lt;tt&gt;SPARSE&lt;/tt&gt; numeric index (e.g. few matching pks for each indexed value). The build took 3h15 without OOM but very frequent G1 Young GC and some nodes are unresponsive (&lt;tt&gt;nodetool status&lt;/tt&gt; show them as DOWN whereas local &lt;tt&gt;nodetool&lt;/tt&gt; command is working)&lt;/p&gt;

&lt;p&gt; One interesting remark, there are some error messages in the logs:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.io.IOException: Term - &apos;-9223371550879758195&apos; belongs to more than 5 keys in SPARSE mode, which is not allowed.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt; It is working as designed I guess, but my question is &lt;tt&gt;does the &apos;5 keys&apos; a hard-coded threshold or is it configurable&lt;/tt&gt; ?&lt;/p&gt;</comment>
                            <comment id="15213157" author="doanduyhai" created="Sat, 26 Mar 2016 19:00:56 +0000"  >&lt;p&gt;Another remark for test case &lt;b&gt;2&lt;/b&gt;. On &lt;b&gt;live&lt;/b&gt; nodes, when doing a &lt;tt&gt;nodetool netstats&lt;/tt&gt;, the &lt;tt&gt;Gossip messages&lt;/tt&gt; count keeps increasing, which is normal. &lt;/p&gt;

&lt;p&gt;On the nodes that are marked &lt;tt&gt;DOWN&lt;/tt&gt;, the &lt;tt&gt;Gossip messages&lt;/tt&gt; count seems idle and keeps the same value for a very looooong time. Don&apos;t know if it&apos;s a bug related to SASI or a Gossip bug per-se.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;root@ns3037976:~# nodetool netstats
Mode: NORMAL
Not sending any streams.
Read Repair Statistics:
Attempted: 0
Mismatch (Blocking): 0
Mismatch (Background): 0
Pool Name                    Active   Pending      Completed
Large messages                  n/a         2              0
Small messages                  n/a         2             14
Gossip messages                 n/a         0          47229
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15213161" author="doanduyhai" created="Sat, 26 Mar 2016 19:17:26 +0000"  >&lt;p&gt;&lt;b&gt;Test case 2&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Ok &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt;, I&apos;ve found something really &lt;b&gt;fishy&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;On the seed node, in the logs:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;INFO  [GossipStage:1] 2016-03-26 16:35:22,020 Gossiper.java:1009 - InetAddress /46.105.104.166 is now DOWN
INFO  [GossipStage:1] 2016-03-26 16:36:18,474 Gossiper.java:1009 - InetAddress /5.39.73.149 is now DOWN
INFO  [GossipStage:1] 2016-03-26 16:36:27,285 Gossiper.java:1009 - InetAddress /5.39.72.230 is now DOWN
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Inside system.log of &lt;b&gt;46.105.104.166&lt;/b&gt;, around &lt;b&gt;2016-03-26 16:35:22,020&lt;/b&gt;:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR [SASI-General:2] 2016-03-26 16:35:22,017 CassandraDaemon.java:195 - Exception in thread Thread[SASI-General:2,5,main]
org.apache.cassandra.io.FSWriteError: java.io.IOException: Term - &apos;-9140913758573873094&apos; belongs to more than 5 keys in SPARSE mode, which is not allowed.
        at org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder.finish(OnDiskIndexBuilder.java:301) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder.finish(OnDiskIndexBuilder.java:244) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder.finish(OnDiskIndexBuilder.java:227) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter$Index.lambda$scheduleSegmentFlush$262(PerSSTableIndexWriter.java:262) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_74]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_74]
        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_74]
Caused by: java.io.IOException: Term - &apos;-9140913758573873094&apos; belongs to more than 5 keys in SPARSE mode, which is not allowed.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Inside system.log of &lt;b&gt;5.39.73.149&lt;/b&gt;, around &lt;b&gt;2016-03-26 16:36:18,474&lt;/b&gt;:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR [SASI-General:2] 2016-03-26 16:36:18,473 CassandraDaemon.java:195 - Exception in thread Thread[SASI-General:2,5,main]
org.apache.cassandra.io.FSWriteError: java.io.IOException: Term - &apos;-8889829184905116393&apos; belongs to more than 5 keys in SPARSE mode, which is not allowed.
        at org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder.finish(OnDiskIndexBuilder.java:301) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder.finish(OnDiskIndexBuilder.java:244) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder.finish(OnDiskIndexBuilder.java:227) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter$Index.lambda$scheduleSegmentFlush$262(PerSSTableIndexWriter.java:262) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_74]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_74]
        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_74]
Caused by: java.io.IOException: Term - &apos;-8889829184905116393&apos; belongs to more than 5 keys in SPARSE mode, which is not allowed.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Inside system.log of &lt;b&gt;5.39.72.230&lt;/b&gt;, around &lt;b&gt;2016-03-26 16:36:27,285&lt;/b&gt;:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR [SASI-General:2] 2016-03-26 16:36:27,281 CassandraDaemon.java:195 - Exception in thread Thread[SASI-General:2,5,main]
org.apache.cassandra.io.FSWriteError: java.io.IOException: Term - &apos;-8574128631854799776&apos; belongs to more than 5 keys in SPARSE mode, which is not allowed.
        at org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder.finish(OnDiskIndexBuilder.java:301) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder.finish(OnDiskIndexBuilder.java:244) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder.finish(OnDiskIndexBuilder.java:227) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter$Index.lambda$scheduleSegmentFlush$262(PerSSTableIndexWriter.java:262) ~[apache-cassandra-3.5-SNAPSHOT.jar:3.5-SNAPSHOT]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_74]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_74]
        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_74]
Caused by: java.io.IOException: Term - &apos;-8574128631854799776&apos; belongs to more than 5 keys in SPARSE mode, which is not allowed.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt; I checked a couple of other nodes and the same error pattern is seen ...&lt;/p&gt;

&lt;p&gt; Look like the SASI exception raised on &lt;tt&gt;SPARSE&lt;/tt&gt; index just kill the gossip. I don&apos;t see how, maybe the exception just bubble up the stack and kill the gossip stage ?&lt;/p&gt;</comment>
                            <comment id="15213180" author="xedin" created="Sat, 26 Mar 2016 20:05:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;2016-03-26 16:36:27,281 CassandraDaemon.java:195 - Exception in thread Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;SASI-General:2,5,main&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is an oversight on my part, I&apos;ve fixed that and pushed it rebased with latest 3.5 to my branch and kicked-off the build. I will let everything stay in the branch until Sunday evening PST if you want to re-run your tests. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It is working as designed I guess, but my question is does the &apos;5 keys&apos; a hard-coded threshold or is it configurable ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, it&apos;s a max optimal number of keys per term since we know how many terms in the worst case fits into one index block and who big combined index is allowed to be. Ideally it should be 1-1 but we still allow 1-5 max since some of the timestamps even can overlap sometimes.&lt;/p&gt;</comment>
                            <comment id="15213190" author="doanduyhai" created="Sat, 26 Mar 2016 20:29:08 +0000"  >&lt;p&gt;Ok &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin&quot; class=&quot;user-hover&quot; rel=&quot;xedin&quot;&gt;xedin&lt;/a&gt;, I&apos;ll retest &lt;b&gt;test case 2&lt;/b&gt; with your fix (the branch is &lt;a href=&quot;https://github.com/xedin/cassandra/tree/CASSANDRA-11383&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt; right) ?&lt;/p&gt;

&lt;p&gt; This bug can kill down a cluster in a permanent state. Upon node reboot the index build kicks in and falls into the exception against and kill the gossip stage again. Dropping the index is not possible if you have some nodes marked &lt;tt&gt;DOWN&lt;/tt&gt; (schema agreement fails). The only work-around I&apos;ve found to recover my cluster was:&lt;/p&gt;

&lt;p&gt;1. reboot the &lt;tt&gt;DOWN&lt;/tt&gt; node&lt;br/&gt;
2. execute quickly and repeatedly &lt;tt&gt;nodetool status&lt;/tt&gt;&lt;br/&gt;
3. as soon as &lt;tt&gt;nodetool status&lt;/tt&gt; is replying, issue quickly a &lt;tt&gt;nodetool stop INDEX_BUILD&lt;/tt&gt; before index build can kick in&lt;br/&gt;
4. repeat 1 to 3 on all nodes marked &lt;tt&gt;DOWN&lt;/tt&gt;&lt;br/&gt;
5. wait for gossip to recover &lt;br/&gt;
6. use cqlsh to drop index&lt;/p&gt;</comment>
                            <comment id="15213195" author="xedin" created="Sat, 26 Mar 2016 20:48:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; That&apos;s right, it&apos;s the same place but has been force pushed to. And that bug has been fixed but that commit.&lt;/p&gt;</comment>
                            <comment id="15213433" author="doanduyhai" created="Sun, 27 Mar 2016 11:45:08 +0000"  >&lt;p&gt;&lt;b&gt;Test case 3&lt;/b&gt;: Insert 3.2 billions rows in an empty table with a &lt;tt&gt;DENSE&lt;/tt&gt; numerical index created before the insert. The insert was successful without OOM. The insert tooks 9h30&lt;/p&gt;</comment>
                            <comment id="15213516" author="doanduyhai" created="Sun, 27 Mar 2016 16:19:24 +0000"  >&lt;p&gt;&lt;b&gt;Test case 2&lt;/b&gt;: after installing the latest fix, building &lt;tt&gt;SPARSE&lt;/tt&gt; numerical index is now working without OOM and without Gossip issue&lt;/p&gt;</comment>
                            <comment id="15213613" author="xedin" created="Sun, 27 Mar 2016 20:10:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt; Thanks! I will be merging today, testall/dtest where run without problems as well.&lt;/p&gt;</comment>
                            <comment id="15213640" author="xedin" created="Sun, 27 Mar 2016 22:33:09 +0000"  >&lt;p&gt;Merged.&lt;/p&gt;</comment>
                            <comment id="15216168" author="jkrupan" created="Tue, 29 Mar 2016 15:18:20 +0000"  >&lt;p&gt;1. Was the conclusion that a SPARSE SASI index would work well even for low cardinality data (as in the original reported case, for period_end_month_int), or was there some application-level change required to adapt to a SASI change as well?&lt;/p&gt;

&lt;p&gt;2. Is it now official that a non-SPARSE SASI index (e.g., PREFIX) can be used for non-TEXT data (int in particular), at least for the case of exact match lookup?&lt;/p&gt;</comment>
                            <comment id="15216185" author="doanduyhai" created="Tue, 29 Mar 2016 15:34:51 +0000"  >&lt;p&gt;1. &lt;tt&gt;SPARSE&lt;/tt&gt; index (in the sense for 1 index value, there are very few matching pk) is working well. During indexing process, if there are more than 5 partition keys for the same index value, SASI will throw an exception and skip indexing the current value to move on the next value&lt;/p&gt;

&lt;p&gt;2. mode &lt;tt&gt;PREFIX&lt;/tt&gt; is working fine for &lt;tt&gt;DENSE&lt;/tt&gt; numerical index (period_end_month_int). The index supports equality and range queries&lt;/p&gt;</comment>
                            <comment id="15216186" author="jrwest" created="Tue, 29 Mar 2016 15:35:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;Was the conclusion that a SPARSE SASI index would work well even for low cardinality data (as in the original reported case, for period_end_month_int), or was there some application-level change required to adapt to a SASI change as well?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;tt&gt;period_end_month_int&lt;/tt&gt; is still the incorrect use case for &lt;tt&gt;SPARSE&lt;/tt&gt;. That did not change. &lt;tt&gt;SPARSE&lt;/tt&gt; is still intended for indexes/terms where there are a large number of terms and a low number of tokens/keys per term (the token trees in the index are sparse). The &lt;tt&gt;period_end_month_int&lt;/tt&gt; use-case is a dense index: there are few terms and each term has a large number of tokens/keys (the token trees in the index are dense). The merged patch improves memory overhead in either case when building indexes from a large sstable. &lt;/p&gt;

&lt;p&gt;What was modified is that indexes marked &lt;tt&gt;SPARSE&lt;/tt&gt; that have more than 5 tokens for any term in the index will fail to build and an exception will be logged. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Is it now official that a non-SPARSE SASI index (e.g., PREFIX) can be used for non-TEXT data (int in particular), at least for the case of exact match lookup?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;tt&gt;PREFIX&lt;/tt&gt; mode has always been supported for numeric data and was/continues to be the default mode if none is specified. PREFIX mode should be considered &quot;NOT SPARSE&quot; for numerical data. &lt;/p&gt;</comment>
                            <comment id="15216233" author="jkrupan" created="Tue, 29 Mar 2016 16:04:03 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jrwest&quot; class=&quot;user-hover&quot; rel=&quot;jrwest&quot;&gt;jrwest&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=doanduyhai&quot; class=&quot;user-hover&quot; rel=&quot;doanduyhai&quot;&gt;doanduyhai&lt;/a&gt;. I think I finally have the SASI terminology down now - SPARSE modes means that the index is sparse (few index entries per original column value) while the column data is dense (many distinct values.) And that non-SPARSE (AKA PREFIX) mode, the default mode, supports any cardinality of data, especially the low cardinality data that SPARSE mode does not support.&lt;/p&gt;

&lt;p&gt;Maybe that leaves one last question as to whether non-SPARSE (PREFIX) mode is considered advisable/recommended for high cardinality column data, where SPARSE mode is nominally a better choice. Maybe that is strictly a matter of whether the prefix/LIKE feature is to be utilized - if so, than PREFIX mode is required, but if not, SPARSE mode sounds like the better choice. But I don&apos;t have a handle on the internal index structures to know if that&apos;s absolutely the case - that a PREFIX index for SPARSE data would necessarily be larger and/or slower than a SPARSE index for high cardinality data. I would hope so, but it would be good to have that confirmed.&lt;/p&gt;</comment>
                            <comment id="15216337" author="jrwest" created="Tue, 29 Mar 2016 17:01:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;Maybe that leaves one last question as to whether non-SPARSE (PREFIX) mode is considered advisable/recommended for high cardinality column data, where SPARSE mode is nominally a better choice. Maybe that is strictly a matter of whether the prefix/LIKE feature is to be utilized - if so, than PREFIX mode is required, but if not, SPARSE mode sounds like the better choice. But I don&apos;t have a handle on the internal index structures to know if that&apos;s absolutely the case - that a PREFIX index for SPARSE data would necessarily be larger and/or slower than a SPARSE index for high cardinality data. I would hope so, but it would be good to have that confirmed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;tt&gt;SPARSE&lt;/tt&gt; is only for numeric data so LIKE queries do not apply. For data that is sparse (every term/column value has less than 5 matching keys), such as indexing the &lt;tt&gt;created_at&lt;/tt&gt; field in time series data (where there is typically few matching rows/events per &lt;tt&gt;created_at&lt;/tt&gt; timestamp), it is best to use &lt;tt&gt;SPARSE&lt;/tt&gt;, always, and especially in cases where range queries are used. &lt;tt&gt;SPARSE&lt;/tt&gt; is primarily an optimization for range queries on this sort of data. Its biggest effect is visible on large ranges (e.g. spanning multiple days of time series data). &lt;/p&gt;

&lt;p&gt;The decision process for whether or not to use &lt;tt&gt;SPARSE&lt;/tt&gt; should be:&lt;br/&gt;
1. is the data a numeric type?&lt;br/&gt;
2. is it expected that there will be a large (millions or more) number of terms (column values) in the index with each term having a small (5 or less) set of matching tokens (partition keys)?&lt;br/&gt;
3. will range queries be performed against this index?&lt;/p&gt;

&lt;p&gt;If the answer to all three questions is Yes then use &lt;tt&gt;SPARSE&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;From the docs (&lt;a href=&quot;https://github.com/xedin/cassandra/blob/trunk/doc/SASI.md#ondiskindexbuilder):&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/xedin/cassandra/blob/trunk/doc/SASI.md#ondiskindexbuilder):&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The SPARSE mode differs from PREFIX in that for every 64 blocks of terms a TokenTree is built merging all the TokenTrees for each term into a single one. This copy of the data is used for efficient iteration of large ranges of e.g. timestamps. The index &quot;mode&quot; is configurable per column at index creation time.&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="15216763" author="jkrupan" created="Tue, 29 Mar 2016 20:12:07 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jrwest&quot; class=&quot;user-hover&quot; rel=&quot;jrwest&quot;&gt;jrwest&lt;/a&gt;. I think that I finally don&apos;t have any additional questions!&lt;/p&gt;

&lt;p&gt;BTW, the DataStax Distribution of Cassandra (DDC) for 3.4 is out now, so the DataStax Cassandra doc has been updated for 3.4, including SASI:&lt;br/&gt;
&lt;a href=&quot;https://docs.datastax.com/en/cql/3.3/cql/cql_using/useSASIIndexConcept.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://docs.datastax.com/en/cql/3.3/cql/cql_using/useSASIIndexConcept.html&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://docs.datastax.com/en/cql/3.3/cql/cql_using/useSASIIndex.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://docs.datastax.com/en/cql/3.3/cql/cql_using/useSASIIndex.html&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://docs.datastax.com/en/cql/3.3/cql/cql_reference/refCreateSASIIndex.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://docs.datastax.com/en/cql/3.3/cql/cql_reference/refCreateSASIIndex.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;That happened four days ago, so maybe some of our recent discussion since then should get cycled into the doc. For example, your comments about range queries on SPARSE data. I&apos;ll pings docs to alert them of the discussion here, but you guys are free to highlight whatever info you think users should know about.&lt;/p&gt;</comment>
                            <comment id="15216827" author="lorina@datastax.com" created="Tue, 29 Mar 2016 20:59:42 +0000"  >&lt;p&gt;Some summary of how the docs should be changed would be appreciated. The commentary is rather long and involved. I can sort it out, but it will take me quite a bit of time to do so. I&apos;m creating a ticket to make changes.&lt;/p&gt;</comment>
                            <comment id="15216917" author="jrwest" created="Tue, 29 Mar 2016 21:53:42 +0000"  >&lt;p&gt;The docs look pretty comprehensive. Thanks! I&apos;ll make a more detailed pass through them when I get a chance. I think the only thing we would like to clarify, based on the discussion in this ticket, is when to choose &lt;tt&gt;SPARSE&lt;/tt&gt; over &lt;tt&gt;PREFIX&lt;/tt&gt; for numerical data. My last comment (&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-11383?focusedCommentId=15216337&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15216337&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/CASSANDRA-11383?focusedCommentId=15216337&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15216337&lt;/a&gt;) mentions a way to do that. &lt;/p&gt;

&lt;p&gt;Otherwise, specific to &lt;tt&gt;SPARSE&lt;/tt&gt; the only recommendation I have is that the &lt;tt&gt;SPARSE&lt;/tt&gt; example on the &quot;CREATE CUSTOM INDEX (SASI)&quot; page (&lt;a href=&quot;https://docs.datastax.com/en/cql/3.3/cql/cql_reference/refCreateSASIIndex.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://docs.datastax.com/en/cql/3.3/cql/cql_reference/refCreateSASIIndex.html&lt;/a&gt;) uses &lt;tt&gt;age&lt;/tt&gt;, which typically would not be a good candidate for a &lt;tt&gt;SPARSE&lt;/tt&gt; index (the answer to question number 2 in my linked comment would be: no, there are not millions of ages with each term having a small number of matching keys). &lt;/p&gt;</comment>
                            <comment id="15216937" author="jkrupan" created="Tue, 29 Mar 2016 22:08:07 +0000"  >&lt;p&gt;+1 for using &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jrwest&quot; class=&quot;user-hover&quot; rel=&quot;jrwest&quot;&gt;jrwest&lt;/a&gt;&apos;s most recent two comments here as the source for the doc changes that I myself was referring to here.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12794250" name="CASSANDRA-11383.patch" size="6231" author="xedin" created="Fri, 18 Mar 2016 20:24:33 +0000"/>
                            <attachment id="12794401" name="SASI_Index_build_LCS_1G_Max_SSTable_Size_logs.tar.gz" size="2332542" author="doanduyhai" created="Sun, 20 Mar 2016 10:59:17 +0000"/>
                            <attachment id="12794249" name="new_system_log_CMS_8GB_OOM.log" size="339956" author="doanduyhai" created="Fri, 18 Mar 2016 20:21:28 +0000"/>
                            <attachment id="12794242" name="system.log_sasi_build_oom" size="1435781" author="doanduyhai" created="Fri, 18 Mar 2016 19:42:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[jwest]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 34 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2uw9b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Reproduced In</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12334622">3.4</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>xedin</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[xedin]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
                        <customfieldname>Since Version</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12334622">3.4</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>